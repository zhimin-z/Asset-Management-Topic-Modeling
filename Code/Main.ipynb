{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\",\n",
    "              None, 'display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = os.path.join(os.path.dirname(os.getcwd()), 'Dataset')\n",
    "\n",
    "path_result = os.path.join(os.path.dirname(os.getcwd()), 'Result')\n",
    "if not os.path.exists(path_result):\n",
    "    os.makedirs(path_result)\n",
    "\n",
    "path_general = os.path.join(path_result, 'General')\n",
    "if not os.path.exists(path_general):\n",
    "    os.makedirs(path_general)\n",
    "\n",
    "path_challenge = os.path.join(path_result, 'Challenge')\n",
    "if not os.path.exists(path_challenge):\n",
    "    os.makedirs(path_challenge)\n",
    "\n",
    "path_solution = os.path.join(path_result, 'Solution')\n",
    "if not os.path.exists(path_solution):\n",
    "    os.makedirs(path_solution)\n",
    "\n",
    "path_challenge_information = os.path.join(path_challenge, 'Information')\n",
    "if not os.path.exists(path_challenge_information):\n",
    "    os.makedirs(path_challenge_information)\n",
    "\n",
    "path_solution_information = os.path.join(path_solution, 'Information')\n",
    "if not os.path.exists(path_solution_information):\n",
    "    os.makedirs(path_solution_information)\n",
    "\n",
    "path_challenge_evolution = os.path.join(path_challenge, 'Evolution')\n",
    "if not os.path.exists(path_challenge_evolution):\n",
    "    os.makedirs(path_challenge_evolution)\n",
    "\n",
    "path_solution_evolution = os.path.join(path_solution, 'Evolution')\n",
    "if not os.path.exists(path_solution_evolution):\n",
    "    os.makedirs(path_solution_evolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine issues and questions\n",
    "\n",
    "import re\n",
    "import spacy\n",
    "# Refer to https://textacy.readthedocs.io/en/stable/api_reference/text_stats.html\n",
    "from textacy import text_stats\n",
    "\n",
    "import subprocess\n",
    "cmd_str = \"python -m spacy download en_core_web_trf -q\"\n",
    "subprocess.run(cmd_str, shell=True)\n",
    "\n",
    "nlp = spacy.load('en_core_web_trf')\n",
    "link_pattern = '(?P<url>ftp|https?://[^\\s]+)'\n",
    "\n",
    "df_issues = pd.read_json(os.path.join(path_dataset, 'issues.json'))\n",
    "\n",
    "df_issues['Solution_word_count'] = np.nan\n",
    "df_issues['Solution_unique_word_count'] = np.nan\n",
    "df_issues['Solution_sentence_count'] = np.nan\n",
    "df_issues['Solution_information_entropy'] = np.nan\n",
    "df_issues['Solution_readability'] = np.nan\n",
    "df_issues['Solution_link_count'] = np.nan\n",
    "\n",
    "for index, row in df_issues.iterrows():\n",
    "    df_issues.at[index, 'Challenge_link'] = row['Issue_link']\n",
    "    df_issues.at[index, 'Challenge_original_content'] = row['Issue_original_content']\n",
    "    df_issues.at[index, 'Challenge_preprocessed_content'] = row['Issue_preprocessed_content']\n",
    "    df_issues.at[index, 'Challenge_gpt_summary'] = row['Issue_gpt_summary']\n",
    "    df_issues.at[index, 'Challenge_creation_time'] = row['Issue_creation_time']\n",
    "    df_issues.at[index, 'Challenge_answer_count'] = row['Issue_answer_count']\n",
    "    df_issues.at[index, 'Challenge_score'] = row['Issue_upvote_count'] - row['Issue_downvote_count']\n",
    "    df_issues.at[index, 'Challenge_closed_time'] = row['Issue_closed_time']\n",
    "    \n",
    "    challenge_content = row['Issue_title'] + '. ' + str(row['Issue_body'])\n",
    "    challenge_content_nlp = nlp(challenge_content)\n",
    "    df_issues.at[index, 'Challenge_word_count'], df_issues.at[index, 'Challenge_unique_word_count'] = text_stats.utils.compute_n_words_and_types(challenge_content_nlp)\n",
    "    df_issues.at[index, 'Challenge_sentence_count'] = text_stats.basics.n_sents(challenge_content_nlp)\n",
    "    df_issues.at[index, 'Challenge_information_entropy'] = text_stats.basics.entropy(challenge_content_nlp)\n",
    "    df_issues.at[index, 'Challenge_readability'] = text_stats.readability.automated_readability_index(challenge_content_nlp)\n",
    "    df_issues.at[index, 'Challenge_link_count'] = len(re.findall(link_pattern, challenge_content))\n",
    "    \n",
    "    df_issues.at[index, 'Solution_original_content'] = row['Answer_original_content']\n",
    "    df_issues.at[index, 'Solution_preprocessed_content'] = row['Answer_preprocessed_content']\n",
    "    df_issues.at[index, 'Solution_gpt_summary'] = row['Answer_gpt_summary']\n",
    "    \n",
    "    discussion = row['Answer_body']\n",
    "    \n",
    "    if pd.notna(discussion):\n",
    "        discussion_nlp = nlp(discussion)\n",
    "        df_issues.at[index, 'Solution_word_count'], df_issues.at[index, 'Solution_unique_word_count'] = text_stats.utils.compute_n_words_and_types(discussion_nlp)\n",
    "        df_issues.at[index, 'Solution_sentence_count'] = text_stats.basics.n_sents(discussion_nlp)\n",
    "        df_issues.at[index, 'Solution_information_entropy'] = text_stats.basics.entropy(discussion_nlp)\n",
    "        df_issues.at[index, 'Solution_readability'] = text_stats.readability.automated_readability_index(discussion_nlp)\n",
    "        df_issues.at[index, 'Solution_link_count'] = len(re.findall(link_pattern, discussion))\n",
    "\n",
    "df_questions = pd.read_json(os.path.join(path_dataset, 'questions.json'))\n",
    "\n",
    "df_questions['Solution_word_count'] = np.nan\n",
    "df_questions['Solution_unique_word_count'] = np.nan\n",
    "df_questions['Solution_sentence_count'] = np.nan\n",
    "df_questions['Solution_information_entropy'] = np.nan\n",
    "df_questions['Solution_readability'] = np.nan\n",
    "df_questions['Solution_link_count'] = np.nan\n",
    "\n",
    "for index, row in df_questions.iterrows():\n",
    "    df_questions.at[index, 'Challenge_link'] = row['Question_link']\n",
    "    df_questions.at[index, 'Challenge_original_content'] = row['Question_original_content']\n",
    "    df_questions.at[index, 'Challenge_preprocessed_content'] = row['Question_preprocessed_content']\n",
    "    df_questions.at[index, 'Challenge_gpt_summary'] = row['Question_gpt_summary']\n",
    "    df_questions.at[index, 'Challenge_creation_time'] = row['Question_creation_time']\n",
    "    df_questions.at[index, 'Challenge_answer_count'] = row['Question_answer_count']\n",
    "    df_questions.at[index, 'Challenge_comment_count'] = row['Question_comment_count']\n",
    "    df_questions.at[index, 'Challenge_score'] = row['Question_score']\n",
    "    df_questions.at[index, 'Challenge_closed_time'] = row['Question_closed_time']\n",
    "    df_questions.at[index, 'Challenge_favorite_count'] = row['Question_favorite_count']\n",
    "    df_questions.at[index, 'Challenge_last_edit_time'] = row['Question_last_edit_time']\n",
    "    df_questions.at[index, 'Challenge_view_count'] = row['Question_view_count']\n",
    "    df_questions.at[index, 'Challenge_follower_count'] = row['Question_follower_count']\n",
    "    df_questions.at[index, 'Challenge_converted_from_issue'] = row['Question_converted_from_issue']\n",
    "    \n",
    "    challenge_content = row['Question_title'] + '. ' + str(row['Question_body'])\n",
    "    challenge_content_nlp = nlp(challenge_content)\n",
    "    df_questions.at[index, 'Challenge_word_count'], df_questions.at[index, 'Challenge_unique_word_count'] = text_stats.utils.compute_n_words_and_types(challenge_content_nlp)\n",
    "    df_questions.at[index, 'Challenge_sentence_count'] = text_stats.basics.n_sents(challenge_content_nlp)\n",
    "    df_questions.at[index, 'Challenge_information_entropy'] = text_stats.basics.entropy(challenge_content_nlp)\n",
    "    df_questions.at[index, 'Challenge_readability'] = text_stats.readability.automated_readability_index(challenge_content_nlp)\n",
    "    df_questions.at[index, 'Challenge_link_count'] = len(re.findall(link_pattern, challenge_content))\n",
    "    \n",
    "    df_questions.at[index, 'Solution_comment_count'] = row['Answer_comment_count']\n",
    "    df_questions.at[index, 'Solution_last_edit_time'] = row['Answer_last_edit_time']\n",
    "    df_questions.at[index, 'Solution_score'] = row['Answer_score']\n",
    "    df_questions.at[index, 'Solution_original_content'] = row['Answer_original_content']\n",
    "    df_questions.at[index, 'Solution_preprocessed_content'] = row['Answer_preprocessed_content']\n",
    "    df_questions.at[index, 'Solution_gpt_summary'] = row['Answer_gpt_summary']\n",
    "    \n",
    "    discussion = row['Answer_body']\n",
    "        \n",
    "    if discussion:\n",
    "        discussion_nlp = nlp(discussion)\n",
    "        df_questions.at[index, 'Solution_word_count'], df_questions.at[index, 'Solution_unique_word_count'] = text_stats.utils.compute_n_words_and_types(discussion_nlp)\n",
    "        df_questions.at[index, 'Solution_sentence_count'] = text_stats.basics.n_sents(discussion_nlp)\n",
    "        df_questions.at[index, 'Solution_information_entropy'] = text_stats.basics.entropy(discussion_nlp)\n",
    "        df_questions.at[index, 'Solution_readability'] = text_stats.readability.automated_readability_index(discussion_nlp)\n",
    "        df_questions.at[index, 'Solution_link_count'] = len(re.findall(link_pattern, discussion))\n",
    "\n",
    "del df_issues['Issue_title']\n",
    "del df_issues['Issue_body']\n",
    "del df_issues['Issue_link']\n",
    "del df_issues['Issue_creation_time']\n",
    "del df_issues['Issue_answer_count']\n",
    "del df_issues['Issue_upvote_count']\n",
    "del df_issues['Issue_downvote_count']\n",
    "del df_issues['Issue_original_content']\n",
    "del df_issues['Issue_preprocessed_content']\n",
    "del df_issues['Issue_gpt_summary_original']\n",
    "del df_issues['Issue_gpt_summary']\n",
    "del df_issues['Issue_closed_time']\n",
    "\n",
    "del df_issues['Answer_body']\n",
    "del df_issues['Answer_list']\n",
    "del df_issues['Answer_original_content']\n",
    "del df_issues['Answer_preprocessed_content']\n",
    "del df_issues['Answer_gpt_summary_original']\n",
    "del df_issues['Answer_gpt_summary']\n",
    "\n",
    "del df_questions['Question_title']\n",
    "del df_questions['Question_body']\n",
    "del df_questions['Question_link']\n",
    "del df_questions['Question_creation_time']\n",
    "del df_questions['Question_answer_count']\n",
    "del df_questions['Question_comment_count']\n",
    "del df_questions['Question_score']\n",
    "del df_questions['Question_original_content']\n",
    "del df_questions['Question_preprocessed_content']\n",
    "del df_questions['Question_gpt_summary_original']\n",
    "del df_questions['Question_gpt_summary']\n",
    "del df_questions['Question_closed_time']\n",
    "del df_questions['Question_view_count']\n",
    "del df_questions['Question_favorite_count']\n",
    "del df_questions['Question_last_edit_time']\n",
    "del df_questions['Question_follower_count']\n",
    "del df_questions['Question_converted_from_issue']\n",
    "\n",
    "del df_questions['Answer_body']\n",
    "del df_questions['Answer_list']\n",
    "del df_questions['Answer_comment_count']\n",
    "del df_questions['Answer_last_edit_time']\n",
    "del df_questions['Answer_score']\n",
    "del df_questions['Answer_original_content']\n",
    "del df_questions['Answer_preprocessed_content']\n",
    "del df_questions['Answer_gpt_summary_original']\n",
    "del df_questions['Answer_gpt_summary']\n",
    "\n",
    "df_all = pd.concat([df_issues, df_questions], ignore_index=True)\n",
    "df_all = df_all.reindex(sorted(df_all.columns), axis=1)\n",
    "df_all.to_json(os.path.join(path_dataset, 'original.json'),\n",
    "               indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Platform</th>\n",
       "      <th>Tool</th>\n",
       "      <th>State</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Github</td>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>closed</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Github</td>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>open</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Github</td>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>closed</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Github</td>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>open</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Github</td>\n",
       "      <td>ClearML</td>\n",
       "      <td>closed</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Github</td>\n",
       "      <td>ClearML</td>\n",
       "      <td>open</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Github</td>\n",
       "      <td>Comet</td>\n",
       "      <td>closed</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Github</td>\n",
       "      <td>Comet</td>\n",
       "      <td>open</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Github</td>\n",
       "      <td>DVC</td>\n",
       "      <td>closed</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Github</td>\n",
       "      <td>DVC</td>\n",
       "      <td>open</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Github</td>\n",
       "      <td>Kedro</td>\n",
       "      <td>closed</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Github</td>\n",
       "      <td>Kedro</td>\n",
       "      <td>open</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Github</td>\n",
       "      <td>MLflow</td>\n",
       "      <td>closed</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Github</td>\n",
       "      <td>MLflow</td>\n",
       "      <td>open</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Github</td>\n",
       "      <td>Neptune</td>\n",
       "      <td>closed</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Github</td>\n",
       "      <td>Neptune</td>\n",
       "      <td>open</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Github</td>\n",
       "      <td>Optuna</td>\n",
       "      <td>closed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Github</td>\n",
       "      <td>SigOpt</td>\n",
       "      <td>closed</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Github</td>\n",
       "      <td>SigOpt</td>\n",
       "      <td>open</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Github</td>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>closed</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Github</td>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>open</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Github</td>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>closed</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Github</td>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>open</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Gitlab</td>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>open</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Stack Overflow</td>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>closed</td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Stack Overflow</td>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>open</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Stack Overflow</td>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>closed</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Stack Overflow</td>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>open</td>\n",
       "      <td>952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Stack Overflow</td>\n",
       "      <td>ClearML</td>\n",
       "      <td>closed</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Stack Overflow</td>\n",
       "      <td>ClearML</td>\n",
       "      <td>open</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Stack Overflow</td>\n",
       "      <td>Comet</td>\n",
       "      <td>closed</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Stack Overflow</td>\n",
       "      <td>Comet</td>\n",
       "      <td>open</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Stack Overflow</td>\n",
       "      <td>DVC</td>\n",
       "      <td>closed</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Stack Overflow</td>\n",
       "      <td>DVC</td>\n",
       "      <td>open</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Stack Overflow</td>\n",
       "      <td>Kedro</td>\n",
       "      <td>closed</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Stack Overflow</td>\n",
       "      <td>Kedro</td>\n",
       "      <td>open</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Stack Overflow</td>\n",
       "      <td>MLflow</td>\n",
       "      <td>closed</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Stack Overflow</td>\n",
       "      <td>MLflow</td>\n",
       "      <td>open</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Stack Overflow</td>\n",
       "      <td>Neptune</td>\n",
       "      <td>closed</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Stack Overflow</td>\n",
       "      <td>Neptune</td>\n",
       "      <td>open</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Stack Overflow</td>\n",
       "      <td>Optuna</td>\n",
       "      <td>closed</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Stack Overflow</td>\n",
       "      <td>Optuna</td>\n",
       "      <td>open</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Stack Overflow</td>\n",
       "      <td>Sacred</td>\n",
       "      <td>closed</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Stack Overflow</td>\n",
       "      <td>Sacred</td>\n",
       "      <td>open</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Stack Overflow</td>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>closed</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Stack Overflow</td>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>open</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Stack Overflow</td>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>closed</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Stack Overflow</td>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>open</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Tool-specific</td>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>closed</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Tool-specific</td>\n",
       "      <td>Amazon SageMaker</td>\n",
       "      <td>open</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Tool-specific</td>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>closed</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Tool-specific</td>\n",
       "      <td>Azure Machine Learning</td>\n",
       "      <td>open</td>\n",
       "      <td>1086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Tool-specific</td>\n",
       "      <td>DVC</td>\n",
       "      <td>open</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Tool-specific</td>\n",
       "      <td>Domino</td>\n",
       "      <td>open</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Tool-specific</td>\n",
       "      <td>Guild AI</td>\n",
       "      <td>open</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Tool-specific</td>\n",
       "      <td>MLflow</td>\n",
       "      <td>open</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Tool-specific</td>\n",
       "      <td>Polyaxon</td>\n",
       "      <td>open</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Tool-specific</td>\n",
       "      <td>SigOpt</td>\n",
       "      <td>open</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Tool-specific</td>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>closed</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Tool-specific</td>\n",
       "      <td>Vertex AI</td>\n",
       "      <td>open</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Tool-specific</td>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>closed</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Tool-specific</td>\n",
       "      <td>Weights &amp; Biases</td>\n",
       "      <td>open</td>\n",
       "      <td>617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Platform                    Tool   State  value\n",
       "0           Github        Amazon SageMaker  closed     61\n",
       "1           Github        Amazon SageMaker    open     15\n",
       "2           Github  Azure Machine Learning  closed     47\n",
       "3           Github  Azure Machine Learning    open     27\n",
       "4           Github                 ClearML  closed      2\n",
       "5           Github                 ClearML    open      1\n",
       "6           Github                   Comet  closed     20\n",
       "7           Github                   Comet    open      2\n",
       "8           Github                     DVC  closed     22\n",
       "9           Github                     DVC    open      7\n",
       "10          Github                   Kedro  closed     15\n",
       "11          Github                   Kedro    open      4\n",
       "12          Github                  MLflow  closed     93\n",
       "13          Github                  MLflow    open     18\n",
       "14          Github                 Neptune  closed     12\n",
       "15          Github                 Neptune    open      2\n",
       "16          Github                  Optuna  closed      1\n",
       "17          Github                  SigOpt  closed      3\n",
       "18          Github                  SigOpt    open      1\n",
       "19          Github               Vertex AI  closed      8\n",
       "20          Github               Vertex AI    open      1\n",
       "21          Github        Weights & Biases  closed     36\n",
       "22          Github        Weights & Biases    open      2\n",
       "23          Gitlab        Amazon SageMaker    open      1\n",
       "24  Stack Overflow        Amazon SageMaker  closed    739\n",
       "25  Stack Overflow        Amazon SageMaker    open   1509\n",
       "26  Stack Overflow  Azure Machine Learning  closed    594\n",
       "27  Stack Overflow  Azure Machine Learning    open    952\n",
       "28  Stack Overflow                 ClearML  closed     20\n",
       "29  Stack Overflow                 ClearML    open     20\n",
       "30  Stack Overflow                   Comet  closed      4\n",
       "31  Stack Overflow                   Comet    open      6\n",
       "32  Stack Overflow                     DVC  closed     49\n",
       "33  Stack Overflow                     DVC    open     42\n",
       "34  Stack Overflow                   Kedro  closed     60\n",
       "35  Stack Overflow                   Kedro    open     89\n",
       "36  Stack Overflow                  MLflow  closed    129\n",
       "37  Stack Overflow                  MLflow    open    423\n",
       "38  Stack Overflow                 Neptune  closed      3\n",
       "39  Stack Overflow                 Neptune    open      5\n",
       "40  Stack Overflow                  Optuna  closed     37\n",
       "41  Stack Overflow                  Optuna    open    104\n",
       "42  Stack Overflow                  Sacred  closed      7\n",
       "43  Stack Overflow                  Sacred    open      3\n",
       "44  Stack Overflow               Vertex AI  closed    112\n",
       "45  Stack Overflow               Vertex AI    open    229\n",
       "46  Stack Overflow        Weights & Biases  closed     22\n",
       "47  Stack Overflow        Weights & Biases    open     55\n",
       "48   Tool-specific        Amazon SageMaker  closed    167\n",
       "49   Tool-specific        Amazon SageMaker    open    361\n",
       "50   Tool-specific  Azure Machine Learning  closed    342\n",
       "51   Tool-specific  Azure Machine Learning    open   1086\n",
       "52   Tool-specific                     DVC    open    348\n",
       "53   Tool-specific                  Domino    open     13\n",
       "54   Tool-specific                Guild AI    open    118\n",
       "55   Tool-specific                  MLflow    open    279\n",
       "56   Tool-specific                Polyaxon    open     41\n",
       "57   Tool-specific                  SigOpt    open     14\n",
       "58   Tool-specific               Vertex AI  closed     26\n",
       "59   Tool-specific               Vertex AI    open    259\n",
       "60   Tool-specific        Weights & Biases  closed    117\n",
       "61   Tool-specific        Weights & Biases    open    617"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Draw sankey diagram of tool and platform\n",
    "\n",
    "df_all = pd.read_json(os.path.join(path_dataset, 'original.json'))\n",
    "df_all['State'] = df_all['Challenge_closed_time'].apply(lambda x: 'closed' if not pd.isna(x) else 'open')\n",
    "\n",
    "categories = ['Platform', 'Tool', 'State']\n",
    "\n",
    "df_all = df_all.groupby(categories).size().reset_index(name='value')\n",
    "df_all.to_json(os.path.join(path_general, 'Tool platform info.json'),\n",
    "               indent=4, orient='records')\n",
    "\n",
    "newDf = pd.DataFrame()\n",
    "for i in range(len(categories)-1):\n",
    "    tempDf = df_all[[categories[i], categories[i+1], 'value']]\n",
    "    tempDf.columns = ['source', 'target', 'value']\n",
    "    newDf = pd.concat([newDf, tempDf])\n",
    "newDf = newDf.groupby(['source', 'target']).agg({'value': 'sum'}).reset_index()\n",
    "\n",
    "label = list(np.unique(df_all[categories].values))\n",
    "source = newDf['source'].apply(lambda x: label.index(x))\n",
    "target = newDf['target'].apply(lambda x: label.index(x))\n",
    "value = newDf['value']\n",
    "\n",
    "link = dict(source=source, target=target, value=value)\n",
    "node = dict(label=label)\n",
    "data = go.Sankey(link=link, node=node)\n",
    "\n",
    "fig = go.Figure(data)\n",
    "fig.update_layout(width=1000, height=1000, font_size=20)\n",
    "fig.write_image(os.path.join(\n",
    "    path_general, 'Tool platform sankey.png'))\n",
    "\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['confus']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# left for stop words tuning purposes\n",
    "\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "preprocess_string(\"confusing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove custom stop words from challenges and solutions\n",
    "\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "stop_words_custom = [\n",
    "    'altern',\n",
    "    'amaz',\n",
    "    'amazon',\n",
    "    'answer',\n",
    "    'appear',\n",
    "    # 'api',\n",
    "    'applic',\n",
    "    'appreci',\n",
    "    'approach',\n",
    "    'aris',\n",
    "    'ask',\n",
    "    'assum',\n",
    "    'astonish',\n",
    "    'attempt',\n",
    "    'aw',\n",
    "    'awesom',\n",
    "    'azur',\n",
    "    'bad',\n",
    "    # 'begin',\n",
    "    'behavior',\n",
    "    'behaviour',\n",
    "    'best',\n",
    "    'better',\n",
    "    'case',\n",
    "    'categori',\n",
    "    'caus',\n",
    "    'challeng',\n",
    "    'cloudera',\n",
    "    # 'close',\n",
    "    'code',\n",
    "    'command',\n",
    "    'confus',\n",
    "    'consid',\n",
    "    'contain',\n",
    "    'content',\n",
    "    'correct',\n",
    "    'correctli',\n",
    "    'correspond',\n",
    "    'couldn',\n",
    "    'curiou',\n",
    "    'custom',\n",
    "    'deep',\n",
    "    'demand',\n",
    "    'demo',\n",
    "    'despit',\n",
    "    'differ',\n",
    "    'differenti',\n",
    "    'difficult',\n",
    "    'difficulti',\n",
    "    'discuss',\n",
    "    'distinguish',\n",
    "    'easi',\n",
    "    'effect',\n",
    "    'emerg',\n",
    "    'encount',\n",
    "    # 'end',\n",
    "    'enquiri',\n",
    "    'error',\n",
    "    'especi',\n",
    "    'exampl',\n",
    "    'excit',\n",
    "    'expect',\n",
    "    'experi',\n",
    "    'databrick',\n",
    "    'domo',\n",
    "    'face',\n",
    "    'fascin',\n",
    "    'fail',\n",
    "    'failur',\n",
    "    'fairli',\n",
    "    'favorit',\n",
    "    'favourit',\n",
    "    'feel',\n",
    "    'firstli',\n",
    "    'fix',\n",
    "    'gcp',\n",
    "    'given',\n",
    "    'good',\n",
    "    'googl',\n",
    "    'gurante',\n",
    "    'happen',\n",
    "    'hard',\n",
    "    'hei',\n",
    "    'hello',\n",
    "    'help',\n",
    "    'ibm',\n",
    "    'impli',\n",
    "    'implic',\n",
    "    'includ',\n",
    "    'incorrect',\n",
    "    'incorrectli',\n",
    "    'incred',\n",
    "    'indic',\n",
    "    'info',\n",
    "    'inform',\n",
    "    'inquiri',\n",
    "    'insight',\n",
    "    'instead',\n",
    "    'interest',\n",
    "    'invalid',\n",
    "    'issu',\n",
    "    'kind',\n",
    "    'know',\n",
    "    'lead',\n",
    "    'learn',\n",
    "    'like',\n",
    "    'look',\n",
    "    'machin',\n",
    "    'main',\n",
    "    'major',\n",
    "    'manner',\n",
    "    'marvel',\n",
    "    'mean',\n",
    "    'meaning',\n",
    "    'meaningfulli',\n",
    "    'meaningless',\n",
    "    'mention',\n",
    "    'method',\n",
    "    'microsoft',\n",
    "    'mind',\n",
    "    'mistak',\n",
    "    'mistakenli',\n",
    "    # 'multipl',\n",
    "    'need',\n",
    "    'new',\n",
    "    'non',\n",
    "    'notice',\n",
    "    'occas',\n",
    "    'occasion',\n",
    "    'occur',\n",
    "    'offer',\n",
    "    'old',\n",
    "    'own',\n",
    "    # 'open',\n",
    "    'oracl',\n",
    "    'ought',\n",
    "    'outcom',\n",
    "    'particular',\n",
    "    'particularli',\n",
    "    'perceive',\n",
    "    'perspect',\n",
    "    'point',\n",
    "    'pointless',\n",
    "    'possibl',\n",
    "    'pretty',\n",
    "    'problem',\n",
    "    'product',\n",
    "    # 'program',\n",
    "    'project',\n",
    "    'provid',\n",
    "    'python',\n",
    "    'pytorch',\n",
    "    'question',\n",
    "    'realize',\n",
    "    'recognize',\n",
    "    'refer',\n",
    "    'regard',\n",
    "    'requir',\n",
    "    'resolv',\n",
    "    'respond',\n",
    "    'result',\n",
    "    'right',\n",
    "    'rightli',\n",
    "    'scenario',\n",
    "    'scikit',\n",
    "    'script',\n",
    "    'second',\n",
    "    'secondli',\n",
    "    'seek',\n",
    "    'seen',\n",
    "    'shall',\n",
    "    'shan',\n",
    "    'shock',\n",
    "    'shouldn',\n",
    "    'similar',\n",
    "    'situat',\n",
    "    'sklearn',\n",
    "    'snippet',\n",
    "    'snowflak',\n",
    "    'solut',\n",
    "    'solv',\n",
    "    'sound',\n",
    "    # 'sourc',\n",
    "    'special',\n",
    "    'specif',\n",
    "    # 'start',\n",
    "    'startl',\n",
    "    'strang',\n",
    "    'struggl',\n",
    "    'stun',\n",
    "    'succe',\n",
    "    'success',\n",
    "    'suggest',\n",
    "    'super',\n",
    "    'talk',\n",
    "    'tensorflow',\n",
    "    'thank',\n",
    "    'think',\n",
    "    'thirdli',\n",
    "    'thought',\n",
    "    'topic',\n",
    "    'try',\n",
    "    'unabl',\n",
    "    'understand',\n",
    "    'unexpect',\n",
    "    'us',\n",
    "    'user',\n",
    "    'usual',\n",
    "    'valid',\n",
    "    'view',\n",
    "    'viewpoint',\n",
    "    'wai',\n",
    "    'want',\n",
    "    'weird',\n",
    "    'worst',\n",
    "    'won',\n",
    "    'wonder',\n",
    "    'work',\n",
    "    'wors',\n",
    "    'wouldn',\n",
    "    'wrong',\n",
    "    'wrongli',\n",
    "    'ye',\n",
    "] \n",
    "\n",
    "df_all = pd.read_json(os.path.join(path_dataset, 'original.json'))\n",
    "\n",
    "for index, row in df_all.iterrows():\n",
    "    df_all.at[index, 'Challenge_original_content'] = remove_stopwords(row['Challenge_original_content'], stopwords=stop_words_custom)\n",
    "    df_all.at[index, 'Challenge_preprocessed_content'] = remove_stopwords(row['Challenge_preprocessed_content'], stopwords=stop_words_custom)\n",
    "    df_all.at[index, 'Challenge_gpt_summary'] = remove_stopwords(row['Challenge_gpt_summary'], stopwords=stop_words_custom)\n",
    "\n",
    "    if row['Solution_gpt_summary']:\n",
    "        df_all.at[index, 'Solution_original_content'] = remove_stopwords(row['Solution_original_content'], stopwords=stop_words_custom)\n",
    "        df_all.at[index, 'Solution_preprocessed_content'] = remove_stopwords(row['Solution_preprocessed_content'], stopwords=stop_words_custom)\n",
    "        df_all.at[index, 'Solution_gpt_summary'] = remove_stopwords(row['Solution_gpt_summary'], stopwords=stop_words_custom)\n",
    "\n",
    "df_all.to_json(os.path.join(path_dataset, 'preprocessed.json'),\n",
    "               indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post-process the clustered topics out of the best training model \n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_general, 'topics.json'))\n",
    "df_topics = df_topics[df_topics['Solution_topic'] > -1]\n",
    "\n",
    "# as if we assign the topic id as the label\n",
    "label_challenge_original = df_topics['Challenge_topic'].unique().tolist()\n",
    "label_challenge_refined = [f'c_{label}' for label in label_challenge_original]\n",
    "label_challenge_map = dict(\n",
    "    zip(label_challenge_original, label_challenge_refined))\n",
    "\n",
    "label_solution_original = df_topics['Solution_topic'].unique().tolist()\n",
    "label_solution_refined = [f's_{label}' for label in label_solution_original]\n",
    "label_solution_map = dict(zip(label_solution_original, label_solution_refined))\n",
    "\n",
    "df_topics = df_topics.replace(\n",
    "    {'Challenge_topic': label_challenge_map, 'Solution_topic': label_solution_map})\n",
    "\n",
    "categories = ['Challenge_topic', 'Solution_topic']\n",
    "df_topics = df_topics.groupby(categories).size().reset_index(name='value')\n",
    "\n",
    "# we only visualize large topics\n",
    "df_topics = df_topics[df_topics['value'] > 20]\n",
    "\n",
    "newDf = pd.DataFrame()\n",
    "for i in range(len(categories)-1):\n",
    "    tempDf = df_topics[[categories[i], categories[i+1], 'value']]\n",
    "    tempDf.columns = ['source', 'target', 'value']\n",
    "    newDf = pd.concat([newDf, tempDf])\n",
    "newDf = newDf.groupby(['source', 'target']).agg({'value': 'sum'}).reset_index()\n",
    "\n",
    "label = list(np.unique(df_topics[categories].values))\n",
    "source = newDf['source'].apply(lambda x: label.index(x))\n",
    "target = newDf['target'].apply(lambda x: label.index(x))\n",
    "value = newDf['value']\n",
    "\n",
    "link = dict(source=source, target=target, value=value)\n",
    "node = dict(label=label)\n",
    "data = go.Sankey(link=link, node=node)\n",
    "\n",
    "fig = go.Figure(data)\n",
    "fig.update_layout(height=1000, width=1000, font=dict(size=30))\n",
    "fig.write_image(os.path.join(path_challenge_information,\n",
    "                'Challenge solution sankey.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenge topic distribution tree map\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_general, 'Topics.json'))\n",
    "df_topics['Challenge_participation_count'] = df_topics['Challenge_answer_count'] + \\\n",
    "    df_topics['Challenge_comment_count']\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=['Tool', 'Platform'],\n",
    "    values='Challenge_participation_count',\n",
    "    color='Challenge_topic',\n",
    "    width=2000,\n",
    "    height=1000,\n",
    ")\n",
    "fig.write_image(os.path.join(path_challenge_information,\n",
    "                'Challenge_topic_distribution.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create solution topic distribution tree map\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_general, 'Topics.json'))\n",
    "df_topics = df_topics[df_topics['Solution_topic'] > -1]\n",
    "df_topics['Challenge_participation_count'] = df_topics['Challenge_answer_count'] + \\\n",
    "    df_topics['Challenge_comment_count']\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=['Tool', 'Platform'],\n",
    "    values='Challenge_participation_count',\n",
    "    color='Solution_topic',\n",
    "    width=2000,\n",
    "    height=1000,\n",
    ")\n",
    "fig.write_image(os.path.join(path_solution_information,\n",
    "                'Solution_topic_distribution.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect challenge statistics information\n",
    "\n",
    "df_challenge = pd.read_json(os.path.join(path_general, 'Topics.json'))\n",
    "df_challenge = df_challenge[df_challenge['Challenge_topic'] > -1]\n",
    "\n",
    "df_challenge['Challenge_comment_count'] = df_challenge['Challenge_comment_count'].fillna(0)\n",
    "df_challenge['Challenge_solved_time'] = df_challenge['Challenge_closed_time'] - \\\n",
    "    df_challenge['Challenge_creation_time']\n",
    "df_challenge['Challenge_adjusted_solved_time'] = df_challenge['Solution_last_edit_time'] - \\\n",
    "    df_challenge['Challenge_last_edit_time']\n",
    "df_challenge['Challenge_participation_count'] = df_challenge['Challenge_answer_count'] + \\\n",
    "    df_challenge['Challenge_comment_count']\n",
    "\n",
    "total_count = df_challenge['Challenge_topic'].count()\n",
    "df_topics = []\n",
    "\n",
    "for name, group in df_challenge.groupby('Challenge_topic'):\n",
    "    Mean_score = group['Challenge_score'].mean()\n",
    "    Mean_favorite_count = group['Challenge_favorite_count'].mean()\n",
    "    Mean_follower_count = group['Challenge_follower_count'].mean()\n",
    "    Mean_link_count = group['Challenge_link_count'].mean()\n",
    "    Mean_information_entropy = group['Challenge_information_entropy'].mean()\n",
    "    Mean_readability = group['Challenge_readability'].mean()\n",
    "    Mean_sentence_count = group['Challenge_sentence_count'].mean()\n",
    "    Mean_word_count = group['Challenge_word_count'].mean()\n",
    "    Mean_unique_word_count = group['Challenge_unique_word_count'].mean()\n",
    "    Mean_view_count = group['Challenge_view_count'].mean()\n",
    "    Mean_answer_count = group['Challenge_answer_count'].mean()\n",
    "    Mean_comment_count = group['Challenge_comment_count'].mean()\n",
    "    Mean_participation_count = Mean_answer_count + Mean_comment_count\n",
    "    Score_participation_ratio = Mean_score / Mean_participation_count\n",
    "    Score_participation_weighted_product = (\n",
    "        group['Challenge_score'] * group['Challenge_participation_count']).mean()\n",
    "    Count = group['Challenge_topic'].count()\n",
    "    Count_ratio = Count / total_count * 100\n",
    "    Solved_ratio = group['Challenge_closed_time'].notna().sum() / Count\n",
    "    Mean_solved_time = group['Challenge_solved_time'].mean(\n",
    "    ) / pd.Timedelta(hours=1)\n",
    "    Median_solved_time = group['Challenge_solved_time'].median(\n",
    "    ) / pd.Timedelta(hours=1)\n",
    "    Mean_adjusted_solved_time = group['Challenge_adjusted_solved_time'].mean(\n",
    "    ) / pd.Timedelta(hours=1)\n",
    "    Median_adjusted_solved_time = group['Challenge_adjusted_solved_time'].median(\n",
    "    ) / pd.Timedelta(hours=1)\n",
    "    topic_info = {\n",
    "        'Challenge_topic': name,\n",
    "        'Mean_score': Mean_score,\n",
    "        'Mean_favorite_count': Mean_favorite_count,\n",
    "        'Mean_follower_count': Mean_follower_count,\n",
    "        'Mean_link_count': Mean_link_count,\n",
    "        'Mean_information_entropy': Mean_information_entropy,\n",
    "        'Mean_readability': Mean_readability,\n",
    "        'Mean_sentence_count': Mean_sentence_count,\n",
    "        'Mean_word_count': Mean_word_count,\n",
    "        'Mean_unique_word_count': Mean_unique_word_count,\n",
    "        'Mean_view_count': Mean_view_count,\n",
    "        'Mean_answer_count': Mean_answer_count,\n",
    "        'Mean_comment_count': Mean_comment_count,\n",
    "        'Score_participation_ratio': Score_participation_ratio,\n",
    "        'Score_participation_weighted_product': Score_participation_weighted_product,\n",
    "        'Count_ratio': Count_ratio,\n",
    "        'Solved_ratio': Solved_ratio,\n",
    "        'Mean_solved_time': Mean_solved_time,\n",
    "        'Median_solved_time': Median_solved_time,\n",
    "        'Mean_adjusted_solved_time': Mean_adjusted_solved_time,\n",
    "        'Median_adjusted_solved_time': Median_adjusted_solved_time,\n",
    "    }\n",
    "    df_topics.append(topic_info)\n",
    "\n",
    "df_topics = pd.DataFrame(df_topics)\n",
    "df_topics.to_json(os.path.join(path_challenge_information,\n",
    "                  'general.json'), indent=4, orient='records')\n",
    "df_topics = df_topics.set_index('Challenge_topic')\n",
    "\n",
    "fig = df_topics.sort_values('Mean_score', ascending=False)['Mean_score'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean score', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Mean_score.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_favorite_count', ascending=False)['Mean_favorite_count'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean favorite count', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Mean_favorite_count.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_follower_count', ascending=False)['Mean_follower_count'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean follower count', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Mean_follower_count.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_link_count', ascending=False)['Mean_link_count'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean link count', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Mean_link_count.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_information_entropy', ascending=False)['Mean_information_entropy'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean info entropy', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Mean_information_entropy.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_readability', ascending=False)['Mean_readability'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean readability', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Mean_readability.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_sentence_count', ascending=False)['Mean_sentence_count'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean sentence count', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Mean_sentence_count.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_word_count', ascending=False)['Mean_word_count'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean word count', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Mean_word_count.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_unique_word_count', ascending=False)['Mean_unique_word_count'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean unique word count', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Mean_unique_word_count.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_view_count', ascending=False)['Mean_view_count'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean view count', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Mean_view_count.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_answer_count', ascending=False)['Mean_answer_count'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean answer count', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Mean_answer_count.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_comment_count', ascending=False)['Mean_comment_count'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean comment count', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Mean_comment_count.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Score_participation_ratio', ascending=False)['Score_participation_ratio'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge score participation ratio', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information,\n",
    "            'Score_participation_ratio.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Score_participation_weighted_product', ascending=False)['Score_participation_weighted_product'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge score participation weighted product', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information,\n",
    "            'Score_participation_weighted_product.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Count_ratio', ascending=False)['Count_ratio'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge count ratio', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Count_ratio.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Solved_ratio')['Solved_ratio'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge Solved ratio', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'solved_ratio.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_solved_time', ascending=False)['Mean_solved_time'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge median solved time', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'mean_solved_time.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Median_solved_time', ascending=False)['Median_solved_time'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean solved time', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'median_solved_time.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_adjusted_solved_time', ascending=False)['Mean_adjusted_solved_time'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean adjusted solved time', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Mean_adjusted_solved_time.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Median_adjusted_solved_time', ascending=False)['Median_adjusted_solved_time'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge median adjusted solved time', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Median_adjusted_solved_time.png'))\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect solution statistics information\n",
    "\n",
    "df_solution = pd.read_json(os.path.join(path_general, 'Topics.json'))\n",
    "df_solution = df_solution[df_solution['Solution_topic'] > -1]\n",
    "\n",
    "total_count = df_challenge['Solution_topic'].count()\n",
    "df_topics = []\n",
    "\n",
    "for name, group in df_challenge.groupby('Solution_topic'):\n",
    "    Mean_score = group['Solution_score'].mean()\n",
    "    Mean_link_count = group['Solution_link_count'].mean()\n",
    "    Mean_information_entropy = group['Solution_information_entropy'].mean()\n",
    "    Mean_readability = group['Solution_readability'].mean()\n",
    "    Mean_sentence_count = group['Solution_sentence_count'].mean()\n",
    "    Mean_word_count = group['Solution_word_count'].mean()\n",
    "    Mean_unique_word_count = group['Solution_unique_word_count'].mean()\n",
    "    Mean_comment_count = group['Solution_comment_count'].mean()\n",
    "    Count_ratio = group['Solution_topic'].count() / total_count * 100\n",
    "    topic_info = {\n",
    "        'Solution_topic': name,\n",
    "        'Mean_score': Mean_score,\n",
    "        'Mean_link_count': Mean_link_count,\n",
    "        'Mean_information_entropy': Mean_information_entropy,\n",
    "        'Mean_readability': Mean_readability,\n",
    "        'Mean_sentence_count': Mean_sentence_count,\n",
    "        'Mean_word_count': Mean_word_count,\n",
    "        'Mean_unique_word_count': Mean_unique_word_count,\n",
    "        'Mean_comment_count': Mean_comment_count,\n",
    "        'Count_ratio': Count_ratio,\n",
    "    }\n",
    "    df_topics.append(topic_info)\n",
    "\n",
    "df_topics = pd.DataFrame(df_topics)\n",
    "df_topics.to_json(os.path.join(path_solution_information,\n",
    "                  'general.json'), indent=4, orient='records')\n",
    "df_topics = df_topics.set_index('Solution_topic')\n",
    "\n",
    "fig = df_topics.sort_values('Mean_score', ascending=False)['Mean_score'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Solution mean score', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_solution_information, 'Mean_score.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_link_count', ascending=False)['Mean_link_count'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Solution mean link count', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_solution_information, 'Mean_link_count.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_information_entropy', ascending=False)['Mean_information_entropy'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Solution mean info entropy', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_solution_information, 'Mean_information_entropy.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_readability', ascending=False)['Mean_readability'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Solution mean readability', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_solution_information, 'Mean_readability.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_sentence_count', ascending=False)['Mean_sentence_count'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Solution mean sentence count', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_solution_information, 'Mean_sentence_count.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_word_count', ascending=False)['Mean_word_count'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Solution mean word count', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_solution_information, 'Mean_word_count.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_unique_word_count', ascending=False)['Mean_unique_word_count'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Solution mean unique word count', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_solution_information, 'Mean_unique_word_count.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_comment_count', ascending=False)['Mean_comment_count'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Solution mean comment count', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_solution_information, 'Mean_comment_count.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Count_ratio', ascending=False)['Count_ratio'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Solution count ratio', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_solution_information, 'Count_ratio.png'))\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.interpolate\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess as sm_lowess\n",
    "\n",
    "\n",
    "def smooth(x, y, xgrid, lowess_kw=None):\n",
    "    samples = np.random.choice(len(x), 50, replace=True)\n",
    "    y_s = y[samples]\n",
    "    x_s = x[samples]\n",
    "    y_sm = sm_lowess(y_s, x_s, **lowess_kw)\n",
    "    # regularly sample it onto the grid\n",
    "    y_grid = scipy.interpolate.interp1d(\n",
    "        x_s, y_sm, fill_value='extrapolate')(xgrid)\n",
    "    return y_grid\n",
    "\n",
    "\n",
    "def lowess_with_confidence_bounds(x, y, conf_interval=0.95, lowess_kw=None):\n",
    "    \"\"\"\n",
    "    Perform Lowess regression and determine a confidence interval by bootstrap resampling\n",
    "    \"\"\"\n",
    "    xgrid = np.linspace(x.min(), x.max())\n",
    "\n",
    "    K = 100\n",
    "    smooths = np.stack([smooth(x, y, xgrid, lowess_kw) for _ in range(K)]).T\n",
    "\n",
    "    mean = np.nanmean(smooths, axis=1)\n",
    "    stderr = scipy.stats.sem(smooths, axis=1)\n",
    "\n",
    "    clower = np.nanpercentile(smooths, (1-conf_interval)*50, axis=1)\n",
    "    cupper = np.nanpercentile(smooths, (1+conf_interval)*50, axis=1)\n",
    "\n",
    "    return xgrid, mean, stderr, clower, cupper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2014-08-08 14:04:22.160000'),\n",
       " Timestamp('2023-02-22 01:36:03.995000'))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.read_json(os.path.join(path_general, 'Topics.json'))\n",
    "df_challenge = df_all[df_all['Challenge_topic'] > -1]\n",
    "# BigQuery Stack Overflow public dataset is updated until Nov 24, 2022, 1:39:22PM UTC-5\n",
    "min(df_challenge['Challenge_creation_time']), max(df_challenge['Challenge_creation_time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore challenge topics evolution\n",
    "\n",
    "df_challenge = pd.read_json(os.path.join(path_general, 'Topics.json'))\n",
    "df_challenge = df_challenge[df_challenge['Challenge_topic'] > -1]\n",
    "df_challenge = df_challenge[(df_challenge['Challenge_creation_time'] > '2014-09-14')\n",
    "                            & (df_challenge['Challenge_creation_time'] < '2022-11-21')]\n",
    "\n",
    "for name, group in df_challenge.groupby('Challenge_topic'):\n",
    "    group = group.groupby(pd.Grouper(key='Challenge_creation_time', freq='2W')).agg(\n",
    "        Count=('Challenge_topic', 'count')).reset_index()\n",
    "    x = pd.to_datetime(group['Challenge_creation_time']).values\n",
    "    x = np.array([i.astype('datetime64[D]').astype(int) for i in x])\n",
    "    y = group['Count'].values\n",
    "    # 95% confidence interval\n",
    "    xgrid, mean, stderr, clower, cupper = lowess_with_confidence_bounds(\n",
    "        x, y, conf_interval=0.95, lowess_kw={\"frac\": 0.5, \"it\": 5, \"return_sorted\": False})\n",
    "    x = pd.to_datetime(group['Challenge_creation_time']).values\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    plt.plot(x, y, 'k.', label='Observations')\n",
    "    plt.plot(xgrid, mean, color='tomato', label='LOWESS')\n",
    "    plt.fill_between(xgrid, clower, cupper, alpha=0.3,\n",
    "                     label='LOWESS uncertainty')\n",
    "    plt.legend(loc='best')\n",
    "    fig.savefig(os.path.join(path_challenge_evolution,\n",
    "                f'Topic_{name}'), bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2014-09-14 22:12:24.493000'),\n",
       " Timestamp('2023-02-21 18:36:06.284000'))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.read_json(os.path.join(path_general, 'Topics.json'))\n",
    "df_solution = df_all[df_all['Solution_topic'] > -1]\n",
    "# BigQuery Stack Overflow public dataset is updated until Nov 24, 2022, 1:39:22PM UTC-5\n",
    "min(df_solution['Challenge_creation_time']), max(\n",
    "    df_solution['Challenge_creation_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore solution topics evolution\n",
    "\n",
    "df_solution = pd.read_json(os.path.join(path_general, 'Topics.json'))\n",
    "df_solution = df_solution[df_solution['Solution_topic'] > -1]\n",
    "df_solution = df_solution[(df_solution['Challenge_creation_time'] > '2014-09-14')\n",
    "                          & (df_solution['Challenge_creation_time'] < '2022-11-21')]\n",
    "\n",
    "for name, group in df_solution.groupby('Solution_topic'):\n",
    "    group = group.groupby(pd.Grouper(key='Challenge_closed_time', freq='W')).agg(\n",
    "        Count=('Solution_topic', 'count')).reset_index()\n",
    "    x = pd.to_datetime(group['Challenge_closed_time']).values\n",
    "    x = np.array([i.astype('datetime64[D]').astype(int) for i in x])\n",
    "    y = group['Count'].values\n",
    "    # 95% confidence interval\n",
    "    xgrid, mean, stderr, clower, cupper = lowess_with_confidence_bounds(\n",
    "        x, y, conf_interval=0.95, lowess_kw={\"frac\": 0.5, \"it\": 5, \"return_sorted\": False})\n",
    "    x = pd.to_datetime(group['Challenge_closed_time']).values\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    plt.plot(x, y, 'k.', label='Observations')\n",
    "    plt.plot(xgrid, mean, color='tomato', label='LOWESS')\n",
    "    plt.fill_between(xgrid, clower, cupper, alpha=0.3,\n",
    "                     label='LOWESS uncertainty')\n",
    "    plt.legend(loc='best')\n",
    "    fig.savefig(os.path.join(path_solution_evolution,\n",
    "                f'Topic_{name}'), bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
