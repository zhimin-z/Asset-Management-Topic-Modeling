{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\",\n",
    "              None, 'display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = os.path.join(os.path.dirname(os.getcwd()), 'Dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess issues and questions\n",
    "\n",
    "df_issues = pd.read_json(os.path.join(path_dataset, 'issues_original.json'))\n",
    "df_questions = pd.read_json(os.path.join(\n",
    "    path_dataset, 'questions_original.json'))\n",
    "\n",
    "stop_words = ['user', 'encounter', 'attempt', 'unable', 'try', 'seek', 'look', 'face', 'facing',\n",
    "              'experienc', 'struggl', 'challenge', 'difficulty', 'issue', 'error', 'problem', 'question']\n",
    "\n",
    "for index, row in df_issues.iterrows():\n",
    "    df_issues.at[index, 'Issue_original_content'] = row['Issue_original_content'].replace(\n",
    "        'Title: ', '').replace('; Content:', '')\n",
    "    df_issues.at[index, 'Issue_preprocessed_content'] = row['Issue_preprocessed_content'].replace(\n",
    "        'Title: ', '').replace('; Content:', '')\n",
    "    gpt_summary = row['Issue_original_content_gpt_summary']\n",
    "    for word in stop_words:\n",
    "        gpt_summary = gpt_summary.replace(word, '')\n",
    "    df_issues.at[index, 'Issue_original_content_gpt_summary'] = gpt_summary\n",
    "\n",
    "for index, row in df_questions.iterrows():\n",
    "    df_questions.at[index, 'Question_original_content'] = row['Question_original_content'].replace(\n",
    "        'Title: ', '').replace('; Content:', '')\n",
    "    df_questions.at[index, 'Question_preprocessed_content'] = row['Question_preprocessed_content'].replace(\n",
    "        'Title: ', '').replace('; Content:', '')\n",
    "    gpt_summary = row['Question_original_content_gpt_summary']\n",
    "    for word in stop_words:\n",
    "        gpt_summary = gpt_summary.replace(word, '')\n",
    "    df_questions.at[index,\n",
    "                    'Question_original_content_gpt_summary'] = gpt_summary\n",
    "\n",
    "df_issues['Challenge_link'] = df_issues['Issue_link']\n",
    "df_issues['Challenge_original_content'] = df_issues['Issue_original_content']\n",
    "df_issues['Challenge_original_content_gpt_summary'] = df_issues['Issue_original_content_gpt_summary']\n",
    "df_issues['Challenge_preprocessed_content'] = df_issues['Issue_preprocessed_content']\n",
    "df_issues['Challenge_creation_time'] = df_issues['Issue_creation_time']\n",
    "df_issues['Challenge_comment_count'] = df_issues['Issue_comment_count']\n",
    "df_issues['Challenge_score'] = df_issues['Issue_upvote_count'] - df_issues['Issue_downvote_count']\n",
    "\n",
    "df_questions['Challenge_link'] = df_questions['Question_link']\n",
    "df_questions['Challenge_original_content'] = df_questions['Question_original_content']\n",
    "df_questions['Challenge_original_content_gpt_summary'] = df_questions['Question_original_content_gpt_summary']\n",
    "df_questions['Challenge_preprocessed_content'] = df_questions['Question_preprocessed_content']\n",
    "df_questions['Challenge_creation_time'] = df_questions['Question_creation_time']\n",
    "df_questions['Challenge_comment_count'] = df_questions['Question_comment_count']\n",
    "df_questions['Challenge_score'] = df_questions['Question_score']\n",
    "\n",
    "df_questions['Solution_original_content'] = df_questions['Answer_original_content']\n",
    "df_questions['Solution_original_content_gpt_summary'] = df_questions['Answer_original_content_gpt_summary']\n",
    "df_questions['Solution_preprocessed_content'] = df_questions['Answer_preprocessed_content']\n",
    "\n",
    "del df_issues['Issue_title']\n",
    "del df_issues['Issue_body']\n",
    "del df_issues['Issue_link']\n",
    "del df_issues['Issue_creation_time']\n",
    "del df_issues['Issue_comment_count']\n",
    "del df_issues['Issue_upvote_count']\n",
    "del df_issues['Issue_downvote_count']\n",
    "del df_issues['Issue_original_content']\n",
    "del df_issues['Issue_original_content_gpt_summary']\n",
    "del df_issues['Issue_preprocessed_content']\n",
    "\n",
    "del df_questions['Question_title']\n",
    "del df_questions['Question_body']\n",
    "del df_questions['Question_link']\n",
    "del df_questions['Question_creation_time']\n",
    "del df_questions['Question_comment_count']\n",
    "del df_questions['Question_score']\n",
    "del df_questions['Question_original_content']\n",
    "del df_questions['Question_original_content_gpt_summary']\n",
    "del df_questions['Question_preprocessed_content']\n",
    "\n",
    "del df_questions['Answer_original_content']\n",
    "del df_questions['Answer_original_content_gpt_summary']\n",
    "del df_questions['Answer_preprocessed_content']\n",
    "\n",
    "df_all = pd.concat([df_issues, df_questions], ignore_index=True)\n",
    "df_all.to_json(os.path.join(path_dataset, 'all_original.json'),\n",
    "               indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error loading\n",
      "fix import issue\n",
      "logger none\n",
      "i solved it, thank you.\n",
      "azurebug1 point\n",
      "you can try https://docs.microsoft.com/en-us/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments\n",
      "this is now solved. thanks!\n",
      "try this in postman.\n",
      "answered on github\n",
      "yes that looks correct!\n",
      "thank you! all fixed.\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.read_json(os.path.join(path_dataset, 'all_original.json'))\n",
    "\n",
    "# remove issues with uninformed content\n",
    "for index, row in df_all.iterrows():\n",
    "    if len(row['Challenge_original_content'].split()) < 4 or len(row['Challenge_original_content']) < 20:\n",
    "        print(row['Challenge_original_content'])\n",
    "        df_all.drop(index, inplace=True)\n",
    "    elif row['Solution_original_content'] and (len(row['Solution_original_content'].split()) < 6 or len(row['Solution_original_content']) < 30):\n",
    "        print(row['Solution_original_content'])\n",
    "        df_all.drop(index, inplace=True)\n",
    "\n",
    "df_all.to_json(os.path.join(path_dataset, 'all_filtered.json'),\n",
    "               indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_json(os.path.join(path_dataset, 'all_topics.json'))\n",
    "df_all['Challenge_creation_date'] = ''\n",
    "# dates = []\n",
    "\n",
    "for index, row in df_all.iterrows():\n",
    "    if 'Git' in row['Platform']:\n",
    "        date = pd.to_datetime(row['Issue_creation_time'])\n",
    "    else:\n",
    "        date = pd.to_datetime(row['Question_creation_time'])\n",
    "    df_all.at[index, 'Challenge_creation_date'] = date.date()\n",
    "    # dates.append(date.date())\n",
    "\n",
    "# min(dates), max(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_challenge = df_all.groupby(\n",
    "    'Challenge_topic').size().reset_index(name='Count')\n",
    "df_challenge\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
