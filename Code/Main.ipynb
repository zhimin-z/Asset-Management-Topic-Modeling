{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\",\n",
    "              None, 'display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = os.path.join(os.path.dirname(os.getcwd()), 'Dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove \"title\" and \"content\" from the content\n",
    "# remove \"The user\" from the beginning of the summary\n",
    "\n",
    "df_issues = pd.read_json(os.path.join(path_dataset, 'issues_original.json'))\n",
    "df_questions = pd.read_json(os.path.join(\n",
    "    path_dataset, 'questions_original.json'))\n",
    "\n",
    "stop_words = ['user', 'encounter', 'attempt', 'unable', 'try', 'seek', 'look', 'face', 'facing',\n",
    "              'experienc', 'struggl', 'challenge', 'difficulty', 'issue', 'error', 'problem', 'question']\n",
    "\n",
    "for index, row in df_issues.iterrows():\n",
    "    df_issues.at[index, 'Issue_original_content'] = row['Issue_original_content'].replace(\n",
    "        'Title: ', '').replace('; Content:', '')\n",
    "    df_issues.at[index, 'Issue_preprocessed_content'] = row['Issue_preprocessed_content'].replace(\n",
    "        'Title: ', '').replace('; Content:', '')\n",
    "    gpt_summary = row['Issue_original_content_gpt_summary']\n",
    "    for word in stop_words:\n",
    "        gpt_summary = gpt_summary.replace(word, '')\n",
    "    df_issues.at[index, 'Issue_original_content_gpt_summary'] = gpt_summary\n",
    "\n",
    "for index, row in df_questions.iterrows():\n",
    "    df_questions.at[index, 'Question_original_content'] = row['Question_original_content'].replace(\n",
    "        'Title: ', '').replace('; Content:', '')\n",
    "    df_questions.at[index, 'Question_preprocessed_content'] = row['Question_preprocessed_content'].replace(\n",
    "        'Title: ', '').replace('; Content:', '')\n",
    "    gpt_summary = row['Question_original_content_gpt_summary']\n",
    "    for word in stop_words:\n",
    "        gpt_summary = gpt_summary.replace(word, '')\n",
    "    df_questions.at[index,\n",
    "                    'Question_original_content_gpt_summary'] = gpt_summary\n",
    "\n",
    "df_issues['Challenge_original_content'] = df_issues['Issue_original_content']\n",
    "df_issues['Challenge_original_content_gpt_summary'] = df_issues['Issue_original_content_gpt_summary']\n",
    "df_issues['Challenge_preprocessed_content'] = df_issues['Issue_preprocessed_content']\n",
    "# df_issues['Challenge_creation_time'] = df_issues['Issue_creation_time']\n",
    "\n",
    "df_questions['Challenge_original_content'] = df_questions['Question_original_content']\n",
    "df_questions['Challenge_original_content_gpt_summary'] = df_questions['Question_original_content_gpt_summary']\n",
    "df_questions['Challenge_preprocessed_content'] = df_questions['Question_preprocessed_content']\n",
    "# df_questions['Challenge_creation_time'] = df_questions['Question_creation_time']\n",
    "\n",
    "df_questions['Solution_original_content'] = df_questions['Answer_original_content']\n",
    "df_questions['Solution_original_content_gpt_summary'] = df_questions['Answer_original_content_gpt_summary']\n",
    "df_questions['Solution_preprocessed_content'] = df_questions['Answer_preprocessed_content']\n",
    "\n",
    "\n",
    "# df_questions['Solution_original_content'] = df_questions['Answer_original_content']\n",
    "\n",
    "del df_issues['Issue_original_content']\n",
    "del df_issues['Issue_original_content_gpt_summary']\n",
    "del df_issues['Issue_preprocessed_content']\n",
    "\n",
    "del df_questions['Question_original_content']\n",
    "del df_questions['Question_original_content_gpt_summary']\n",
    "del df_questions['Question_preprocessed_content']\n",
    "\n",
    "del df_questions['Answer_original_content']\n",
    "del df_questions['Answer_original_content_gpt_summary']\n",
    "del df_questions['Answer_preprocessed_content']\n",
    "\n",
    "df_all = pd.concat([df_issues, df_questions], ignore_index=True)\n",
    "df_all.to_json(os.path.join(path_dataset, 'all_original.json'),\n",
    "               indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error loading\n",
      "fix import issue\n",
      "logger none\n",
      "i solved it, thank you.\n",
      "azurebug1 point\n",
      "you can try https://docs.microsoft.com/en-us/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments\n",
      "this is now solved. thanks!\n",
      "try this in postman.\n",
      "answered on github\n",
      "yes that looks correct!\n",
      "thank you! all fixed.\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.read_json(os.path.join(path_dataset, 'all_original.json'))\n",
    "\n",
    "# remove issues with uninformed content\n",
    "for index, row in df_all.iterrows():\n",
    "    if len(row['Challenge_original_content'].split()) < 4 or len(row['Challenge_original_content']) < 20:\n",
    "        print(row['Challenge_original_content'])\n",
    "        df_all.drop(index, inplace=True)\n",
    "    elif row['Solution_original_content'] and (len(row['Solution_original_content'].split()) < 6 or len(row['Solution_original_content']) < 30):\n",
    "        print(row['Solution_original_content'])\n",
    "        df_all.drop(index, inplace=True)\n",
    "\n",
    "df_all.to_json(os.path.join(path_dataset, 'all_filtered.json'),\n",
    "               indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>4870</td>\n",
       "      <td>-1_error attempting_error message_azure_endpoint user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>332</td>\n",
       "      <td>0_accessing s3_s3 bucket_access s3_s3 buckets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>297</td>\n",
       "      <td>1_git repository_git lfs_git repo_version control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>272</td>\n",
       "      <td>2_line plots_plot user_line chart_bar chart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>261</td>\n",
       "      <td>3_file batch_dataset csv_batch transform_csv format</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>237</td>\n",
       "      <td>4_running pytorch_pytorch_model bin_deploy pytorch_deploying pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>201</td>\n",
       "      <td>5_modulenotfounderror attempting_encountering modulenotfounderror_encountering importerror_encountered modulenotfounderror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>192</td>\n",
       "      <td>6_jupyter notebooks_jupyter notebook_managed jupyter_executing jupyter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>182</td>\n",
       "      <td>7_annotation job_labelling job_labeling job_labeling task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>182</td>\n",
       "      <td>8_dataset azure_azure file_azure blob_azure data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>9_rstudio application_rlang package_challenge rstudio_rstudio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>147</td>\n",
       "      <td>10_deploying tensorflow_deploy tensorflow_deployed tensorflow_tensorflow aws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>121</td>\n",
       "      <td>11_endpoint failed_model endpoint_occurred modelerror_endpoint model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>119</td>\n",
       "      <td>12_automl forecasting_forecasting automl_timeseries forecasting_challenges forecasting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>112</td>\n",
       "      <td>13_apache spark_sparkmagic pyspark_pysparkprocessor_deploying spark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>111</td>\n",
       "      <td>14_tree regression_decision tree_forest classifier_decision trees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15</td>\n",
       "      <td>108</td>\n",
       "      <td>15_aws lambda_lambda endpoint_lambda api_endpoint lambda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>108</td>\n",
       "      <td>16_custom docker_model docker_docker environment_creating docker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td>99</td>\n",
       "      <td>17_xgboost model_model xgboost_xgboost load_model_using xgboost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>91</td>\n",
       "      <td>18_create pipeline_pipeline desired_data pipeline_pipeline parameters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19</td>\n",
       "      <td>81</td>\n",
       "      <td>19_translation api_api translate_translate api_cloud translation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20</td>\n",
       "      <td>77</td>\n",
       "      <td>20_guild file_guild yml_pythonpath guild_overwriting guild_home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>21</td>\n",
       "      <td>74</td>\n",
       "      <td>21_ai ml_ml platform_requesting organization_user requesting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22</td>\n",
       "      <td>72</td>\n",
       "      <td>22_hyperparameter tuning_hyperparameter optimization_hyperparameters train_hyperparameters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>23</td>\n",
       "      <td>67</td>\n",
       "      <td>23_azure kubernetes_deploying kubernetes_kubernetes service_kubernetes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>24</td>\n",
       "      <td>65</td>\n",
       "      <td>24_aws identity_amazonfullaccess policy_accessdeniedexception attempting_receiving accessdeniedexception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>25</td>\n",
       "      <td>63</td>\n",
       "      <td>25_job stuck_job running_stop_training_job_challenges cancelling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>26</td>\n",
       "      <td>63</td>\n",
       "      <td>26_logging tensorboard_tensorboard logs_tensorboard custom_logged tensorboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>27</td>\n",
       "      <td>55</td>\n",
       "      <td>27_pipeline run_running pipeline_pipeline successfully_run pipeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>28</td>\n",
       "      <td>53</td>\n",
       "      <td>28_parameters sweep_sweep agent_agent sweep_sweep agents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>29</td>\n",
       "      <td>52</td>\n",
       "      <td>29_azure automated_azure cloud_deploy azure_microsoft azure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>30</td>\n",
       "      <td>49</td>\n",
       "      <td>30_workspace user_access workspace_workspace despite_connect workspace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>31</td>\n",
       "      <td>48</td>\n",
       "      <td>31_model databricks_models databricks_databricks workspace_databricks using</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "      <td>32_gcp user_using gcp_gcp project_gcp endpoints</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "      <td>33_delete experiments_deleting runs_run deleting_deleting run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>34</td>\n",
       "      <td>37</td>\n",
       "      <td>34_deleted user_delete user_account deleted_user unable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>35_encountering memoryerror_memoryerror_memoryerror attempting_encountered memoryerror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36_huggingface model_bert model_deploy huggingface_using huggingface</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>37</td>\n",
       "      <td>35</td>\n",
       "      <td>37_roles azure_workspace azure_account azure_azure account</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count  \\\n",
       "0      -1   4870   \n",
       "1       0    332   \n",
       "2       1    297   \n",
       "3       2    272   \n",
       "4       3    261   \n",
       "5       4    237   \n",
       "6       5    201   \n",
       "7       6    192   \n",
       "8       7    182   \n",
       "9       8    182   \n",
       "10      9    159   \n",
       "11     10    147   \n",
       "12     11    121   \n",
       "13     12    119   \n",
       "14     13    112   \n",
       "15     14    111   \n",
       "16     15    108   \n",
       "17     16    108   \n",
       "18     17     99   \n",
       "19     18     91   \n",
       "20     19     81   \n",
       "21     20     77   \n",
       "22     21     74   \n",
       "23     22     72   \n",
       "24     23     67   \n",
       "25     24     65   \n",
       "26     25     63   \n",
       "27     26     63   \n",
       "28     27     55   \n",
       "29     28     53   \n",
       "30     29     52   \n",
       "31     30     49   \n",
       "32     31     48   \n",
       "33     32     42   \n",
       "34     33     40   \n",
       "35     34     37   \n",
       "36     35     36   \n",
       "37     36     36   \n",
       "38     37     35   \n",
       "\n",
       "                                                                                                                          Name  \n",
       "0                                                                        -1_error attempting_error message_azure_endpoint user  \n",
       "1                                                                                0_accessing s3_s3 bucket_access s3_s3 buckets  \n",
       "2                                                                            1_git repository_git lfs_git repo_version control  \n",
       "3                                                                                  2_line plots_plot user_line chart_bar chart  \n",
       "4                                                                          3_file batch_dataset csv_batch transform_csv format  \n",
       "5                                                         4_running pytorch_pytorch_model bin_deploy pytorch_deploying pytorch  \n",
       "6   5_modulenotfounderror attempting_encountering modulenotfounderror_encountering importerror_encountered modulenotfounderror  \n",
       "7                                                       6_jupyter notebooks_jupyter notebook_managed jupyter_executing jupyter  \n",
       "8                                                                    7_annotation job_labelling job_labeling job_labeling task  \n",
       "9                                                                             8_dataset azure_azure file_azure blob_azure data  \n",
       "10                                                               9_rstudio application_rlang package_challenge rstudio_rstudio  \n",
       "11                                                10_deploying tensorflow_deploy tensorflow_deployed tensorflow_tensorflow aws  \n",
       "12                                                        11_endpoint failed_model endpoint_occurred modelerror_endpoint model  \n",
       "13                                      12_automl forecasting_forecasting automl_timeseries forecasting_challenges forecasting  \n",
       "14                                                         13_apache spark_sparkmagic pyspark_pysparkprocessor_deploying spark  \n",
       "15                                                           14_tree regression_decision tree_forest classifier_decision trees  \n",
       "16                                                                    15_aws lambda_lambda endpoint_lambda api_endpoint lambda  \n",
       "17                                                            16_custom docker_model docker_docker environment_creating docker  \n",
       "18                                                             17_xgboost model_model xgboost_xgboost load_model_using xgboost  \n",
       "19                                                       18_create pipeline_pipeline desired_data pipeline_pipeline parameters  \n",
       "20                                                            19_translation api_api translate_translate api_cloud translation  \n",
       "21                                                             20_guild file_guild yml_pythonpath guild_overwriting guild_home  \n",
       "22                                                                21_ai ml_ml platform_requesting organization_user requesting  \n",
       "23                                  22_hyperparameter tuning_hyperparameter optimization_hyperparameters train_hyperparameters  \n",
       "24                                                      23_azure kubernetes_deploying kubernetes_kubernetes service_kubernetes  \n",
       "25                    24_aws identity_amazonfullaccess policy_accessdeniedexception attempting_receiving accessdeniedexception  \n",
       "26                                                            25_job stuck_job running_stop_training_job_challenges cancelling  \n",
       "27                                               26_logging tensorboard_tensorboard logs_tensorboard custom_logged tensorboard  \n",
       "28                                                         27_pipeline run_running pipeline_pipeline successfully_run pipeline  \n",
       "29                                                                    28_parameters sweep_sweep agent_agent sweep_sweep agents  \n",
       "30                                                                 29_azure automated_azure cloud_deploy azure_microsoft azure  \n",
       "31                                                      30_workspace user_access workspace_workspace despite_connect workspace  \n",
       "32                                                 31_model databricks_models databricks_databricks workspace_databricks using  \n",
       "33                                                                             32_gcp user_using gcp_gcp project_gcp endpoints  \n",
       "34                                                               33_delete experiments_deleting runs_run deleting_deleting run  \n",
       "35                                                                     34_deleted user_delete user_account deleted_user unable  \n",
       "36                                      35_encountering memoryerror_memoryerror_memoryerror attempting_encountered memoryerror  \n",
       "37                                                        36_huggingface model_bert model_deploy huggingface_using huggingface  \n",
       "38                                                                  37_roles azure_workspace azure_account azure_azure account  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_json(os.path.join(path_dataset, 'all_filtered.json'))\n",
    "df_all['Challenge_topic'] = ''\n",
    "\n",
    "for index, row in df_all.iterrows():\n",
    "    df_all.at[index, 'Challenge_topic'] = new_topics_challenge.pop(0)\n",
    "\n",
    "df_all.to_json(os.path.join(path_dataset, 'all_topics.json'),\n",
    "               indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>2076</td>\n",
       "      <td>-1_ai platform_lifecycle configuration_ml_aws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>207</td>\n",
       "      <td>0_bar chart_line chart_plot user_metrics run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "      <td>1_data git_git lfs_local git_version control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>2_accessing s3_access s3_s3 bucket_s3 user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>134</td>\n",
       "      <td>3_hyperparameter sweep_parameters sweep_hyperparameter search_hyperparameter tuning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "      <td>4_azure blob_azure dataset_dataset azure_azure data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>99</td>\n",
       "      <td>5_azure kubernetes_endpoint deployment_deploying azure_deploying ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>77</td>\n",
       "      <td>6_launching jupyterlabs_jupyter notebooks_run jupyter_running jupyter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>77</td>\n",
       "      <td>7_web services_web service_webservice_webservice using</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>75</td>\n",
       "      <td>8_azure automl_azure auto_automl forecasting_azure automated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>74</td>\n",
       "      <td>9_azure cloud_azure data_using azure_azure iot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>69</td>\n",
       "      <td>10_docker container_docker images_custom docker_docker image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>64</td>\n",
       "      <td>11_steps pipeline_creating pipeline_step pipeline_integrate pipelines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>60</td>\n",
       "      <td>12_pytorch cuda_conda_pytorch_p36_conda_pytorch_p36 kernel_deploy pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>60</td>\n",
       "      <td>13_issue rstudio_rstudio_script azure_requests azure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>59</td>\n",
       "      <td>14_tensorflow aws_tensorflow serving_deploy tensorflow_deploying tensorflow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15</td>\n",
       "      <td>57</td>\n",
       "      <td>15_memoryerror attempting_encountering memoryerror_memoryerror_memory error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>53</td>\n",
       "      <td>16_pythonpath guild_guild yml_guild file_specifying guild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td>51</td>\n",
       "      <td>17_forest classifier_random forest_forest algorithm_forest implementation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>47</td>\n",
       "      <td>18_model registry_registering model_registermodel command_service model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19</td>\n",
       "      <td>45</td>\n",
       "      <td>19_workspace azure_existing azure_azure account_create azure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20</td>\n",
       "      <td>45</td>\n",
       "      <td>20_xgboost container_deployed xgboost_run xgboost_xgboost model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>21</td>\n",
       "      <td>43</td>\n",
       "      <td>21_gpu utilization_gpu memory_average gpu_gpus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>22_speech api_google speech_text speech_speech service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>23</td>\n",
       "      <td>43</td>\n",
       "      <td>23_submitting pipeline_pipeline failing_submit pipeline_pipeline stuck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>24</td>\n",
       "      <td>42</td>\n",
       "      <td>24_manually deleting_remote deleting_deleting runs_delete runs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>25</td>\n",
       "      <td>42</td>\n",
       "      <td>25_text recognition_custom ocr_ocr_make ocr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "      <td>26_lambda endpoint_endpoint lambda_aws lambda_lambda api</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>27</td>\n",
       "      <td>39</td>\n",
       "      <td>27_gcp api_endpoint gcp_gcp endpoints_pipeline gcp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>28</td>\n",
       "      <td>38</td>\n",
       "      <td>28_logging tensorboard_data tensorboard_run tensorboard_running tensorboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>29</td>\n",
       "      <td>37</td>\n",
       "      <td>29_instance segmentation_labeling job_semantic segmentation_images labeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>30_quota ncast4_v3_lack quota_access compute_quota cpu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>31</td>\n",
       "      <td>35</td>\n",
       "      <td>31_process stuck_run stuck_running message_run issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "      <td>32_translation api_translate api_google translator_cloud translation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33_deleted user_delete user_account deleted_account user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>34_ai ml_learning agent_learning artificial_intelligence ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>35_pyspark kernel_issue pyspark_parameters pysparkprocessor_spark session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>36</td>\n",
       "      <td>31</td>\n",
       "      <td>36_endpoints security_endpoint publicly_endpoint url_securing rest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>37</td>\n",
       "      <td>29</td>\n",
       "      <td>37_json csv_json format_csv file_process json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>38</td>\n",
       "      <td>29</td>\n",
       "      <td>38_multimodel endpoint_model endpoint_container endpoints_endpoint multiple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>39</td>\n",
       "      <td>26</td>\n",
       "      <td>39_log_model_log_model function_log kerasclassifier_does log_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>40</td>\n",
       "      <td>26</td>\n",
       "      <td>40_conda install_conda environment_conda env_conda dependencies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>41</td>\n",
       "      <td>25</td>\n",
       "      <td>41_azure databricks_databricks user_databricks workspace_parameters databricksstep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>42</td>\n",
       "      <td>25</td>\n",
       "      <td>42_issue pandas_dataset to_pandas_dataframe_to_pandas_dataframe_pandas parquetdataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>43</td>\n",
       "      <td>24</td>\n",
       "      <td>43_python dependency_import python_python module_modulenotfounderror attempting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>44</td>\n",
       "      <td>22</td>\n",
       "      <td>44_deploy pickled_pickle error_runtimeerror load_pickle file</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>45</td>\n",
       "      <td>21</td>\n",
       "      <td>45_network error_encountering connecttimeout_user experiencing_error connecttimeout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>46</td>\n",
       "      <td>21</td>\n",
       "      <td>46_pip packages_package python_install pip3_python package</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>47</td>\n",
       "      <td>20</td>\n",
       "      <td>47_understanding cost_cost data_pricing documentation_pricing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>48</td>\n",
       "      <td>19</td>\n",
       "      <td>48_parameters yaml_params yaml_yaml file_parameters yml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>49</td>\n",
       "      <td>19</td>\n",
       "      <td>49_colab create_colab file_gcp colab_initialise colab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>50</td>\n",
       "      <td>18</td>\n",
       "      <td>50_learning automl_automl model_automl specifically_automl optimize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>51</td>\n",
       "      <td>17</td>\n",
       "      <td>51_dialogflow cx_dialogflow integrating_integrating dialogflow_dialogflow user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>52</td>\n",
       "      <td>17</td>\n",
       "      <td>52_encountering performance_processing time_performance issue_performance running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>53</td>\n",
       "      <td>16</td>\n",
       "      <td>53_missing values_missing data_refactor dataset_dataset columns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>54</td>\n",
       "      <td>15</td>\n",
       "      <td>54_azure powerbi_model powerbi_interfacing powerbi_powerbi model</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count  \\\n",
       "0      -1   2076   \n",
       "1       0    207   \n",
       "2       1    192   \n",
       "3       2    160   \n",
       "4       3    134   \n",
       "5       4     99   \n",
       "6       5     99   \n",
       "7       6     77   \n",
       "8       7     77   \n",
       "9       8     75   \n",
       "10      9     74   \n",
       "11     10     69   \n",
       "12     11     64   \n",
       "13     12     60   \n",
       "14     13     60   \n",
       "15     14     59   \n",
       "16     15     57   \n",
       "17     16     53   \n",
       "18     17     51   \n",
       "19     18     47   \n",
       "20     19     45   \n",
       "21     20     45   \n",
       "22     21     43   \n",
       "23     22     43   \n",
       "24     23     43   \n",
       "25     24     42   \n",
       "26     25     42   \n",
       "27     26     39   \n",
       "28     27     39   \n",
       "29     28     38   \n",
       "30     29     37   \n",
       "31     30     35   \n",
       "32     31     35   \n",
       "33     32     34   \n",
       "34     33     33   \n",
       "35     34     32   \n",
       "36     35     31   \n",
       "37     36     31   \n",
       "38     37     29   \n",
       "39     38     29   \n",
       "40     39     26   \n",
       "41     40     26   \n",
       "42     41     25   \n",
       "43     42     25   \n",
       "44     43     24   \n",
       "45     44     22   \n",
       "46     45     21   \n",
       "47     46     21   \n",
       "48     47     20   \n",
       "49     48     19   \n",
       "50     49     19   \n",
       "51     50     18   \n",
       "52     51     17   \n",
       "53     52     17   \n",
       "54     53     16   \n",
       "55     54     15   \n",
       "\n",
       "                                                                                     Name  \n",
       "0                                           -1_ai platform_lifecycle configuration_ml_aws  \n",
       "1                                            0_bar chart_line chart_plot user_metrics run  \n",
       "2                                            1_data git_git lfs_local git_version control  \n",
       "3                                              2_accessing s3_access s3_s3 bucket_s3 user  \n",
       "4     3_hyperparameter sweep_parameters sweep_hyperparameter search_hyperparameter tuning  \n",
       "5                                     4_azure blob_azure dataset_dataset azure_azure data  \n",
       "6                     5_azure kubernetes_endpoint deployment_deploying azure_deploying ml  \n",
       "7                   6_launching jupyterlabs_jupyter notebooks_run jupyter_running jupyter  \n",
       "8                                  7_web services_web service_webservice_webservice using  \n",
       "9                            8_azure automl_azure auto_automl forecasting_azure automated  \n",
       "10                                         9_azure cloud_azure data_using azure_azure iot  \n",
       "11                           10_docker container_docker images_custom docker_docker image  \n",
       "12                  11_steps pipeline_creating pipeline_step pipeline_integrate pipelines  \n",
       "13              12_pytorch cuda_conda_pytorch_p36_conda_pytorch_p36 kernel_deploy pytorch  \n",
       "14                                   13_issue rstudio_rstudio_script azure_requests azure  \n",
       "15            14_tensorflow aws_tensorflow serving_deploy tensorflow_deploying tensorflow  \n",
       "16            15_memoryerror attempting_encountering memoryerror_memoryerror_memory error  \n",
       "17                              16_pythonpath guild_guild yml_guild file_specifying guild  \n",
       "18              17_forest classifier_random forest_forest algorithm_forest implementation  \n",
       "19                18_model registry_registering model_registermodel command_service model  \n",
       "20                           19_workspace azure_existing azure_azure account_create azure  \n",
       "21                        20_xgboost container_deployed xgboost_run xgboost_xgboost model  \n",
       "22                                         21_gpu utilization_gpu memory_average gpu_gpus  \n",
       "23                                 22_speech api_google speech_text speech_speech service  \n",
       "24                 23_submitting pipeline_pipeline failing_submit pipeline_pipeline stuck  \n",
       "25                         24_manually deleting_remote deleting_deleting runs_delete runs  \n",
       "26                                            25_text recognition_custom ocr_ocr_make ocr  \n",
       "27                               26_lambda endpoint_endpoint lambda_aws lambda_lambda api  \n",
       "28                                     27_gcp api_endpoint gcp_gcp endpoints_pipeline gcp  \n",
       "29            28_logging tensorboard_data tensorboard_run tensorboard_running tensorboard  \n",
       "30             29_instance segmentation_labeling job_semantic segmentation_images labeled  \n",
       "31                                 30_quota ncast4_v3_lack quota_access compute_quota cpu  \n",
       "32                                   31_process stuck_run stuck_running message_run issue  \n",
       "33                   32_translation api_translate api_google translator_cloud translation  \n",
       "34                               33_deleted user_delete user_account deleted_account user  \n",
       "35                            34_ai ml_learning agent_learning artificial_intelligence ai  \n",
       "36              35_pyspark kernel_issue pyspark_parameters pysparkprocessor_spark session  \n",
       "37                     36_endpoints security_endpoint publicly_endpoint url_securing rest  \n",
       "38                                          37_json csv_json format_csv file_process json  \n",
       "39            38_multimodel endpoint_model endpoint_container endpoints_endpoint multiple  \n",
       "40                     39_log_model_log_model function_log kerasclassifier_does log_model  \n",
       "41                        40_conda install_conda environment_conda env_conda dependencies  \n",
       "42     41_azure databricks_databricks user_databricks workspace_parameters databricksstep  \n",
       "43  42_issue pandas_dataset to_pandas_dataframe_to_pandas_dataframe_pandas parquetdataset  \n",
       "44        43_python dependency_import python_python module_modulenotfounderror attempting  \n",
       "45                           44_deploy pickled_pickle error_runtimeerror load_pickle file  \n",
       "46    45_network error_encountering connecttimeout_user experiencing_error connecttimeout  \n",
       "47                             46_pip packages_package python_install pip3_python package  \n",
       "48                          47_understanding cost_cost data_pricing documentation_pricing  \n",
       "49                                48_parameters yaml_params yaml_yaml file_parameters yml  \n",
       "50                                  49_colab create_colab file_gcp colab_initialise colab  \n",
       "51                    50_learning automl_automl model_automl specifically_automl optimize  \n",
       "52         51_dialogflow cx_dialogflow integrating_integrating dialogflow_dialogflow user  \n",
       "53      52_encountering performance_processing time_performance issue_performance running  \n",
       "54                        53_missing values_missing data_refactor dataset_dataset columns  \n",
       "55                       54_azure powerbi_model powerbi_interfacing powerbi_powerbi model  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_json(os.path.join(path_dataset, 'all_topics.json'))\n",
    "df_all['Solution_topic'] = -1\n",
    "\n",
    "for index, row in df_all.iterrows():\n",
    "    if not row['Solution_original_content_gpt_summary']:\n",
    "        continue\n",
    "    df_all.at[index, 'Solution_topic'] = new_topics_solution.pop(0)\n",
    "\n",
    "df_all.to_json(os.path.join(path_dataset, 'all_topics.json'),\n",
    "               indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_json(os.path.join(path_dataset, 'all_topics.json'))\n",
    "df_all['Challenge_creation_date'] = ''\n",
    "# dates = []\n",
    "\n",
    "for index, row in df_all.iterrows():\n",
    "    if 'Git' in row['Platform']:\n",
    "        date = pd.to_datetime(row['Issue_creation_time'])\n",
    "    else:\n",
    "        date = pd.to_datetime(row['Question_creation_time'])\n",
    "    df_all.at[index, 'Challenge_creation_date'] = date.date()\n",
    "    # dates.append(date.date())\n",
    "\n",
    "# min(dates), max(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_challenge = df_all.groupby(\n",
    "    'Challenge_topic').size().reset_index(name='Count')\n",
    "df_challenge\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
