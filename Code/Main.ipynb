{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\",\n",
    "              None, 'display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = os.path.join(os.path.dirname(os.getcwd()), 'Dataset')\n",
    "\n",
    "path_result = os.path.join(os.path.dirname(os.getcwd()), 'Result')\n",
    "if not os.path.exists(path_result):\n",
    "    os.makedirs(path_result)\n",
    "\n",
    "path_general = os.path.join(path_result, 'General')\n",
    "if not os.path.exists(path_general):\n",
    "    os.makedirs(path_general)\n",
    "\n",
    "path_challenge = os.path.join(path_result, 'Challenge')\n",
    "if not os.path.exists(path_challenge):\n",
    "    os.makedirs(path_challenge)\n",
    "\n",
    "path_solution = os.path.join(path_result, 'Solution')\n",
    "if not os.path.exists(path_solution):\n",
    "    os.makedirs(path_solution)\n",
    "\n",
    "path_challenge_information = os.path.join(path_challenge, 'Information')\n",
    "if not os.path.exists(path_challenge_information):\n",
    "    os.makedirs(path_challenge_information)\n",
    "\n",
    "path_solution_information = os.path.join(path_solution, 'Information')\n",
    "if not os.path.exists(path_solution_information):\n",
    "    os.makedirs(path_solution_information)\n",
    "\n",
    "path_challenge_evolution = os.path.join(path_challenge, 'Evolution')\n",
    "if not os.path.exists(path_challenge_evolution):\n",
    "    os.makedirs(path_challenge_evolution)\n",
    "\n",
    "path_solution_evolution = os.path.join(path_solution, 'Evolution')\n",
    "if not os.path.exists(path_solution_evolution):\n",
    "    os.makedirs(path_solution_evolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine issues and questions\n",
    "\n",
    "import re\n",
    "from scipy.stats import entropy\n",
    "\n",
    "link_pattern = '(?P<url>https?://[^\\s]+)'\n",
    "\n",
    "df_issues = pd.read_json(os.path.join(path_dataset, 'issues.json'))\n",
    "df_questions = pd.read_json(os.path.join(path_dataset, 'questions.json'))\n",
    "\n",
    "df_issues['Challenge_link'] = df_issues['Issue_link']\n",
    "df_issues['Challenge_original_content'] = df_issues['Issue_original_content']\n",
    "df_issues['Challenge_preprocessed_content'] = df_issues['Issue_preprocessed_content']\n",
    "df_issues['Challenge_summary'] = df_issues['Issue_gpt_summary']\n",
    "df_issues['Challenge_creation_time'] = df_issues['Issue_creation_time']\n",
    "df_issues['Challenge_answer_count'] = df_issues['Issue_answer_count']\n",
    "df_issues['Challenge_comment_count'] = 0\n",
    "df_issues['Challenge_score'] = df_issues['Issue_upvote_count'] - \\\n",
    "    df_issues['Issue_downvote_count']\n",
    "df_issues['Challenge_closed_time'] = df_issues['Issue_closed_time']\n",
    "df_issues['Challenge_info_entropy'] = (df_issues['Issue_title'] + ' ' + df_issues['Issue_body'].astype(\n",
    "    str)).apply(lambda x: entropy([x.count(c) / len(x) for c in set(x)], base=2))\n",
    "df_issues['Challenge_link_count'] = (df_issues['Issue_title'] + ' ' + df_issues['Issue_body'].astype(\n",
    "    str)).apply(lambda x: len(re.findall(link_pattern, x))) \n",
    "df_issues['Solution_summary'] = df_issues['Fix_manual_summary']\n",
    "\n",
    "df_questions['Challenge_link'] = df_questions['Question_link']\n",
    "df_questions['Challenge_original_content'] = df_questions['Question_original_content']\n",
    "df_questions['Challenge_preprocessed_content'] = df_questions['Question_preprocessed_content']\n",
    "df_questions['Challenge_summary'] = df_questions['Question_gpt_summary']\n",
    "df_questions['Challenge_creation_time'] = df_questions['Question_creation_time']\n",
    "df_questions['Challenge_answer_count'] = df_questions['Question_answer_count']\n",
    "df_questions['Challenge_comment_count'] = df_questions['Question_comment_count']\n",
    "df_questions['Challenge_score'] = df_questions['Question_score']\n",
    "df_questions['Challenge_closed_time'] = df_questions['Question_closed_time']\n",
    "df_questions['Challenge_info_entropy'] = (df_questions['Question_title'] + ' ' + df_questions['Question_body'].astype(\n",
    "    str)).apply(lambda x: entropy([x.count(c) / len(x) for c in set(x)], base=2))\n",
    "df_questions['Challenge_link_count'] = (df_questions['Question_title'] + ' ' + df_questions['Question_body'].astype(\n",
    "    str)).apply(lambda x: len(re.findall(link_pattern, x)))\n",
    "df_questions['Solution_original_content'] = df_questions['Answer_original_content']\n",
    "df_questions['Solution_preprocessed_content'] = df_questions['Answer_preprocessed_content']\n",
    "df_questions['Solution_summary'] = df_questions['Answer_gpt_summary']\n",
    "df_questions['Solution_info_entropy'] = df_questions['Answer_body'].apply(lambda x: entropy([x.count(c) / len(x) for c in set(x)], base=2) if not pd.isna(x) else None)\n",
    "df_questions['Solution_link_count'] = df_questions['Answer_body'].astype(str).apply(lambda x: len(re.findall(link_pattern, x)))\n",
    "\n",
    "del df_issues['Issue_title']\n",
    "del df_issues['Issue_body']\n",
    "del df_issues['Issue_link']\n",
    "del df_issues['Issue_creation_time']\n",
    "del df_issues['Issue_answer_count']\n",
    "del df_issues['Issue_upvote_count']\n",
    "del df_issues['Issue_downvote_count']\n",
    "del df_issues['Issue_original_content']\n",
    "del df_issues['Issue_preprocessed_content']\n",
    "del df_issues['Issue_gpt_summary_original']\n",
    "del df_issues['Issue_gpt_summary']\n",
    "del df_issues['Issue_closed_time']\n",
    "del df_issues['Fix_manual_summary_original']\n",
    "del df_issues['Fix_manual_summary']\n",
    "\n",
    "del df_questions['Question_title']\n",
    "del df_questions['Question_body']\n",
    "del df_questions['Question_link']\n",
    "del df_questions['Question_creation_time']\n",
    "del df_questions['Question_answer_count']\n",
    "del df_questions['Question_comment_count']\n",
    "del df_questions['Question_score']\n",
    "del df_questions['Question_original_content']\n",
    "del df_questions['Question_preprocessed_content']\n",
    "del df_questions['Question_gpt_summary_original']\n",
    "del df_questions['Question_gpt_summary']\n",
    "del df_questions['Question_closed_time']\n",
    "del df_questions['Answer_body']\n",
    "del df_questions['Answer_list']\n",
    "del df_questions['Answer_original_content']\n",
    "del df_questions['Answer_preprocessed_content']\n",
    "del df_questions['Answer_gpt_summary_original']\n",
    "del df_questions['Answer_gpt_summary']\n",
    "\n",
    "df_all = pd.concat([df_issues, df_questions], ignore_index=True)\n",
    "df_all.to_json(os.path.join(path_dataset, 'original.json'),\n",
    "               indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw sankey diagram of tool and platform\n",
    "\n",
    "df_all = pd.read_json(os.path.join(path_dataset, 'original.json'))\n",
    "\n",
    "categories = ['Platform', 'Tool']\n",
    "df_all = df_all.groupby(categories).size().reset_index(name='value')\n",
    "\n",
    "newDf = pd.DataFrame()\n",
    "for i in range(len(categories)-1):\n",
    "    tempDf = df_all[[categories[i], categories[i+1], 'value']]\n",
    "    tempDf.columns = ['source', 'target', 'value']\n",
    "    newDf = pd.concat([newDf, tempDf])\n",
    "newDf = newDf.groupby(['source', 'target']).agg({'value': 'sum'}).reset_index()\n",
    "\n",
    "label = list(np.unique(df_all[categories].values))\n",
    "source = newDf['source'].apply(lambda x: label.index(x))\n",
    "target = newDf['target'].apply(lambda x: label.index(x))\n",
    "value = newDf['value']\n",
    "\n",
    "link = dict(source=source, target=target, value=value)\n",
    "node = dict(label=label)\n",
    "data = go.Sankey(link=link, node=node)\n",
    "\n",
    "fig = go.Figure(data)\n",
    "fig.update_layout(width=1000, height=1000, font_size=20)\n",
    "fig.write_image(os.path.join(\n",
    "    path_general, 'Tool platform sankey.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove custom stop words from challenges and solutions\n",
    "\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "# Refer to https://venturebeat.com/data-infrastructure/top-10-data-lake-solution-vendors-in-2022/\n",
    "stop_words_custom = [\n",
    "    'altern',\n",
    "    'amazon',\n",
    "    'answer',\n",
    "    # 'api',\n",
    "    'applic',\n",
    "    'appreci',\n",
    "    'approach',\n",
    "    'aris',\n",
    "    'ask',\n",
    "    'assum',\n",
    "    'attempt',\n",
    "    'aw',\n",
    "    'azur',\n",
    "    'bad',\n",
    "    # 'begin',\n",
    "    'behavior',\n",
    "    'behaviour',\n",
    "    'best',\n",
    "    'better',\n",
    "    'caus',\n",
    "    'challeng',\n",
    "    'cloudera',\n",
    "    # 'close',\n",
    "    'code',\n",
    "    'command',\n",
    "    'consid',\n",
    "    'contain',\n",
    "    'content',\n",
    "    'correct',\n",
    "    'correctli',\n",
    "    'correspond',\n",
    "    'couldn',\n",
    "    'curiou',\n",
    "    'custom',\n",
    "    'deep',\n",
    "    'demand',\n",
    "    'demo',\n",
    "    'despit',\n",
    "    'differ',\n",
    "    'differenti',\n",
    "    'difficult',\n",
    "    'difficulti',\n",
    "    'distinguish',\n",
    "    'easi',\n",
    "    'effect',\n",
    "    'encount',\n",
    "    # 'end',\n",
    "    'enquiri',\n",
    "    'error',\n",
    "    'especi',\n",
    "    'exampl',\n",
    "    'expect',\n",
    "    'experi',\n",
    "    'databrick',\n",
    "    'domo',\n",
    "    'face',\n",
    "    'fail',\n",
    "    'failur',\n",
    "    'firstli',\n",
    "    'fix',\n",
    "    'gcp',\n",
    "    'given',\n",
    "    'good',\n",
    "    'googl',\n",
    "    'gurante',\n",
    "    'happen',\n",
    "    'hard',\n",
    "    'hei',\n",
    "    'hello',\n",
    "    'help',\n",
    "    'ibm',\n",
    "    'includ',\n",
    "    'incorrect',\n",
    "    'incorrectli',\n",
    "    'info',\n",
    "    'inform',\n",
    "    'inquiri',\n",
    "    'insight',\n",
    "    'instead',\n",
    "    'intern',\n",
    "    'invalid',\n",
    "    'issu',\n",
    "    'lead',\n",
    "    'learn',\n",
    "    'like',\n",
    "    'look',\n",
    "    'machin',\n",
    "    'main',\n",
    "    'major',\n",
    "    'manner',\n",
    "    'mention',\n",
    "    'method',\n",
    "    'microsoft',\n",
    "    'mind',\n",
    "    'mistak',\n",
    "    'mistakenli',\n",
    "    # 'multipl',\n",
    "    'need',\n",
    "    'new',\n",
    "    'non',\n",
    "    'occur',\n",
    "    'offer',\n",
    "    'old',\n",
    "    'own',\n",
    "    # 'open',\n",
    "    'oracl',\n",
    "    'ought',\n",
    "    'outcom',\n",
    "    'particular',\n",
    "    'particularli',\n",
    "    'perspect',\n",
    "    'possibl',\n",
    "    'problem',\n",
    "    'product',\n",
    "    # 'program',\n",
    "    'project',\n",
    "    'provid',\n",
    "    'python',\n",
    "    'pytorch',\n",
    "    'question',\n",
    "    'requir',\n",
    "    'resolv',\n",
    "    'respond',\n",
    "    'result',\n",
    "    'right',\n",
    "    'rightli',\n",
    "    'scikit',\n",
    "    'script',\n",
    "    'second',\n",
    "    'secondli',\n",
    "    'seek',\n",
    "    'seen',\n",
    "    'shall',\n",
    "    'shan',\n",
    "    'shouldn',\n",
    "    'similar',\n",
    "    'sklearn',\n",
    "    'snippet',\n",
    "    'snowflak',\n",
    "    'solut',\n",
    "    'solv',\n",
    "    # 'sourc',\n",
    "    'special',\n",
    "    'specif',\n",
    "    # 'start',\n",
    "    'strang',\n",
    "    'struggl',\n",
    "    'succe',\n",
    "    'success',\n",
    "    'suggest',\n",
    "    'tensorflow',\n",
    "    'thank',\n",
    "    'think',\n",
    "    'thirdli',\n",
    "    'thought',\n",
    "    'topic',\n",
    "    'try',\n",
    "    'unabl',\n",
    "    'understand',\n",
    "    'unexpect',\n",
    "    'us',\n",
    "    'user',\n",
    "    'valid',\n",
    "    'view',\n",
    "    'viewpoint',\n",
    "    'wai',\n",
    "    'want',\n",
    "    'weird',\n",
    "    'worst',\n",
    "    'won',\n",
    "    'wonder',\n",
    "    'work',\n",
    "    'wors',\n",
    "    'wouldn',\n",
    "    'wrong',\n",
    "    'wrongli',\n",
    "]\n",
    "\n",
    "df_all = pd.read_json(os.path.join(path_dataset, 'original.json'))\n",
    "\n",
    "for index, row in df_all.iterrows():\n",
    "    df_all.at[index, 'Challenge_original_content'] = remove_stopwords(row['Challenge_original_content'].replace(\n",
    "        'Title: ', '').replace('Answer: ', ''), stopwords=stop_words_custom)\n",
    "    df_all.at[index, 'Challenge_preprocessed_content'] = remove_stopwords(\n",
    "        row['Challenge_preprocessed_content'].replace('Title: ', '').replace('Answer: ', ''), stopwords=stop_words_custom)\n",
    "    df_all.at[index, 'Challenge_summary'] = remove_stopwords(\n",
    "        row['Challenge_summary'], stopwords=stop_words_custom)\n",
    "\n",
    "    if row['Solution_original_content']:\n",
    "        df_all.at[index, 'Solution_original_content'] = remove_stopwords(row['Solution_original_content'].replace(\n",
    "            'Title: ', '').replace('Answer: ', ''), stopwords=stop_words_custom)\n",
    "        df_all.at[index, 'Solution_preprocessed_content'] = remove_stopwords(\n",
    "            row['Solution_preprocessed_content'].replace('Title: ', '').replace('Answer: ', ''), stopwords=stop_words_custom)\n",
    "        df_all.at[index, 'Solution_summary'] = remove_stopwords(\n",
    "            row['Solution_summary'], stopwords=stop_words_custom)\n",
    "\n",
    "df_all.to_json(os.path.join(path_dataset, 'preprocessed.json'),\n",
    "               indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initi studio lab titl\n",
      "modulenotfounderror modul tensorboard\n",
      "combin param param work\n",
      "access allow access member given\n",
      "load\n",
      "deploy\n",
      "log val loss\n",
      "import\n",
      "tensorboard default logger option\n",
      "logger\n",
      "connect databas ye connect databas\n",
      "afraid moment set built autopilot\n",
      "run end run finish creat\n",
      "vpc endpoint api api st\n",
      "support hive adl\n",
      "cloudform templat sure\n",
      "csv file folder recordio\n",
      "littl involv ye\n",
      "file pin azurestor\n",
      "processingstep uri locat refer\n",
      "leav case come accross\n",
      "pipelin moment\n",
      "cli sdk\n",
      "let know happen\n",
      "delet creat endpoint\n",
      "report appear bug team investig\n",
      "work\n",
      "like templat run creat instanc\n",
      "passau refer visual studio magazin\n",
      "bug got todai close\n",
      "upgrad sqlalchemi\n",
      "file path ensur path\n",
      "tri work let file transient\n",
      "think chang log stream servic\n",
      "strang instal pip instal\n",
      "situat chang git avail\n",
      "sdk support automl sdk support\n",
      "actual come smdebug version downgrad\n",
      "updat core\n",
      "forc gpu devic devic gpu\n",
      "begin list\n",
      "accord document maximum\n",
      "randomcutforest rcf lean randomforest algorithm\n",
      "sure estim framework version version\n",
      "web termin import delet\n",
      "ye maxtrialscallback exact featur situat\n",
      "mayb http github com\n",
      "add run flush end\n",
      "fit pass paramet job yourjobnam\n",
      "version sdk\n",
      "current confid interv\n",
      "version\n",
      "current bring data server\n",
      "upgrad sdk latest version like\n",
      "cursor text open edit awai\n",
      "convert dataset modul\n",
      "notebook instanc edit neelam\n",
      "run notebook develop notebook wai\n",
      "local comput pipelin articl\n",
      "close wrong\n",
      "current metric publish\n",
      "resourc cloudform crossov hope regard\n",
      "region connect east region east\n",
      "merg singl attach notebook instanc\n",
      "network set\n",
      "chang bucket file work\n",
      "confirm avail jumpstart step undertaken\n",
      "tri paramet registermodel step\n",
      "kernel run syntax highlight work\n",
      "multi attach support\n",
      "http stackoverflow com\n",
      "explain insid lambda\n",
      "experienc updat tip\n",
      "updat forum updat run\n",
      "luka add document sampl\n",
      "add set automl set auto\n",
      "featur current support thread roadmap\n",
      "compon expert bug studio bug\n",
      "shoaibakhtarshaikh column shown\n",
      "studio subscript studio pass subscript\n",
      "mateuszmacia instal ident\n",
      "support distribut gpu plan date\n",
      "updat\n",
      "model state deploi web servic\n",
      "srin troubleshoot document\n",
      "disappear dont migrat design access\n",
      "build bot build bot hand book\n",
      "specif conda instal pywin\n",
      "bokkerslarlar dataset creat blob datastor\n",
      "rerun work fine\n",
      "believ subscript level owner contributor\n",
      "work framework dont document good\n",
      "copi workspac duplic workspac debug\n",
      "kamilasoko got follow tutori\n",
      "doabl explor time add document\n",
      "updat support storag roadmap\n",
      "updat base doc avail\n",
      "compat\n",
      "dont think ramr msft\n",
      "sourc pipelin notebook demonstr hyperdrivestep\n",
      "like work normal\n",
      "jona bug sdk version updat\n",
      "incas increas comput memori avoid\n",
      "modifi web servic uri\n",
      "mapinputport execut maml mapinputport studio\n",
      "reach browser tri browser\n",
      "follow thread\n",
      "explor diferenti privaci ipynb exam\n",
      "ad screenshot hope regard\n",
      "like memori reduc train set\n",
      "better check excel blank row\n",
      "regard offici document\n",
      "uninstal reinstal xgboost version continu\n",
      "anomali detect drop menu\n",
      "duplic review respons\n",
      "observ troubleshoot step\n",
      "nevermind work workspac\n",
      "east region continu studi region\n",
      "postman\n",
      "path parquet path field work\n",
      "graph dataset graph dataset\n",
      "github\n",
      "api document api interact programmat\n",
      "categori\n",
      "run follow run pull\n",
      "record discuss discord discord network\n",
      "ruchita share traceback run add\n",
      "troubleshoot categori gener gener\n",
      "workaround yaml anchor\n",
      "good scientif notat report releas\n",
      "ye\n",
      "sorri reason region credenti utc\n",
      "version tell tri upgrad mlflw\n",
      "databas believ heard configur dan\n",
      "report url workspac richard\n",
      "start server server like server\n",
      "awar felt write time soon\n",
      "param\n",
      "http com doc autom build\n",
      "think ye share thought\n",
      "share\n",
      "pai support wai free support\n",
      "creat shop cart base dialogflow\n",
      "noankmari dialogflow\n",
      "automl model start letter\n",
      "reproduc reproduct step reproduc end\n",
      "research research offer\n",
      "contact support tell praneeth\n",
      "gpu nvidia price butnvidia tesla\n",
      "contact cloud\n",
      "lauren vdv post regist\n",
      "previous stack overflow post\n",
      "follow step follow codelab\n",
      "file tracker accord behavior shown\n",
      "text speech text speech work\n",
      "read documentationabout label vision\n",
      "document appsheet offer\n",
      "shivaaycan context\n",
      "think nlp hardest subset build\n",
      "wai download automl model train\n",
      "optim tabl set center imag\n",
      "told support post transpar\n",
      "weekend\n",
      "remov team like remov tesm\n",
      "revers delet restor delet artifact\n",
      "ahhh entiti drob drob\n",
      "lucasventura like\n",
      "attributeerror enumtypewrapp object attribut reslov\n",
      "access studi group fastai\n",
      "harveen convers continu\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.read_json(os.path.join(path_dataset, 'preprocessed.json'))\n",
    "\n",
    "# remove issues with uninformed content\n",
    "for index, row in df_all.iterrows():\n",
    "    if len(row['Challenge_original_content'].split()) < 6 or len(row['Challenge_original_content']) < 30:\n",
    "        print(row['Challenge_original_content'])\n",
    "        df_all.drop(index, inplace=True)\n",
    "    elif row['Solution_original_content'] and (len(row['Solution_original_content'].split()) < 6 or len(row['Solution_original_content']) < 30):\n",
    "        print(row['Solution_original_content'])\n",
    "        df_all.drop(index, inplace=True)\n",
    "\n",
    "df_all.to_json(os.path.join(path_dataset, 'filtered.json'),\n",
    "               indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_dataset, 'topics.json'))\n",
    "df_topics = df_topics[df_topics['Solution_topic'] > -1]\n",
    "\n",
    "# as if we assign the topic id as the label\n",
    "label_challenge_original = df_topics['Challenge_topic'].unique().tolist()\n",
    "label_challenge_refined = [f'c_{label}' for label in label_challenge_original]\n",
    "label_challenge_map = dict(\n",
    "    zip(label_challenge_original, label_challenge_refined))\n",
    "\n",
    "label_solution_original = df_topics['Solution_topic'].unique().tolist()\n",
    "label_solution_refined = [f's_{label}' for label in label_solution_original]\n",
    "label_solution_map = dict(zip(label_solution_original, label_solution_refined))\n",
    "\n",
    "df_topics = df_topics.replace(\n",
    "    {'Challenge_topic': label_challenge_map, 'Solution_topic': label_solution_map})\n",
    "\n",
    "categories = ['Challenge_topic', 'Solution_topic']\n",
    "df_topics = df_topics.groupby(categories).size().reset_index(name='value')\n",
    "\n",
    "# we only visualize large topics\n",
    "df_topics = df_topics[df_topics['value'] > 50]\n",
    "\n",
    "newDf = pd.DataFrame()\n",
    "for i in range(len(categories)-1):\n",
    "    tempDf = df_topics[[categories[i], categories[i+1], 'value']]\n",
    "    tempDf.columns = ['source', 'target', 'value']\n",
    "    newDf = pd.concat([newDf, tempDf])\n",
    "newDf = newDf.groupby(['source', 'target']).agg({'value': 'sum'}).reset_index()\n",
    "\n",
    "label = list(np.unique(df_topics[categories].values))\n",
    "source = newDf['source'].apply(lambda x: label.index(x))\n",
    "target = newDf['target'].apply(lambda x: label.index(x))\n",
    "value = newDf['value']\n",
    "\n",
    "link = dict(source=source, target=target, value=value)\n",
    "node = dict(label=label)\n",
    "data = go.Sankey(link=link, node=node)\n",
    "\n",
    "fig = go.Figure(data)\n",
    "fig.update_layout(height=1000, width=1000, font=dict(size=30))\n",
    "fig.write_image(os.path.join(path_challenge_information,\n",
    "                'Challenge solution sankey.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenge topic distribution tree map\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_dataset, 'topics.json'))\n",
    "df_topics['Challenge_participation_count'] = df_topics['Challenge_answer_count'] + \\\n",
    "    df_topics['Challenge_comment_count']\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=['Tool', 'Platform'],\n",
    "    values='Challenge_participation_count',\n",
    "    color='Challenge_topic',\n",
    "    width=2000,\n",
    "    height=1000,\n",
    ")\n",
    "fig.write_image(os.path.join(path_challenge_information,\n",
    "                'Challenge_topic_distribution.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create solution topic distribution tree map\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_dataset, 'topics.json'))\n",
    "df_topics = df_topics[df_topics['Solution_topic'] > -1]\n",
    "df_topics['Challenge_participation_count'] = df_topics['Challenge_answer_count'] + \\\n",
    "    df_topics['Challenge_comment_count']\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=['Tool', 'Platform'],\n",
    "    values='Challenge_participation_count',\n",
    "    color='Solution_topic',\n",
    "    width=2000,\n",
    "    height=1000,\n",
    ")\n",
    "fig.write_image(os.path.join(path_solution_information,\n",
    "                'Solution_topic_distribution.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect challenge statistics information\n",
    "\n",
    "df_challenge = pd.read_json(os.path.join(path_dataset, 'topics.json'))\n",
    "df_challenge['Challenge_solved_time'] = df_challenge['Challenge_closed_time'] - \\\n",
    "    df_challenge['Challenge_creation_time']\n",
    "df_challenge['Challenge_participation_count'] = df_challenge['Challenge_answer_count'] + \\\n",
    "    df_challenge['Challenge_comment_count']\n",
    "\n",
    "total_count = df_challenge['Challenge_topic'].count()\n",
    "df_topics = []\n",
    "\n",
    "for name, group in df_challenge.groupby('Challenge_topic'):\n",
    "    Mean_score = group['Challenge_score'].mean()\n",
    "    Mean_link_count = group['Challenge_link_count'].mean()\n",
    "    Mean_info_entropy = group['Challenge_info_entropy'].mean()\n",
    "    Mean_answer_count = group['Challenge_answer_count'].mean()\n",
    "    Mean_comment_count = group['Challenge_comment_count'].mean()\n",
    "    Mean_participation_count = Mean_answer_count + Mean_comment_count\n",
    "    Score_participation_ratio = Mean_score / Mean_participation_count\n",
    "    Score_participation_weighted_product = (\n",
    "        group['Challenge_score'] * group['Challenge_participation_count']).mean()\n",
    "    Count = group['Challenge_topic'].count()\n",
    "    Count_ratio = Count / total_count * 100\n",
    "    Solved_ratio = group['Challenge_closed_time'].notna().sum() / Count\n",
    "    Mean_solved_time = group['Challenge_solved_time'].mean(\n",
    "    ) / pd.Timedelta(hours=1)\n",
    "    Median_solved_time = group['Challenge_solved_time'].median(\n",
    "    ) / pd.Timedelta(hours=1)\n",
    "    topic_info = {\n",
    "        'Challenge_topic': name,\n",
    "        'Mean_score': Mean_score,\n",
    "        'Mean_link_count': Mean_link_count,\n",
    "        'Mean_info_entropy': Mean_info_entropy,\n",
    "        'Mean_answer_count': Mean_answer_count,\n",
    "        'Mean_comment_count': Mean_comment_count,\n",
    "        'Score_participation_ratio': Score_participation_ratio,\n",
    "        'Score_participation_weighted_product': Score_participation_weighted_product,\n",
    "        'Count_ratio': Count_ratio,\n",
    "        'Solved_ratio': Solved_ratio,\n",
    "        'Mean_solved_time': Mean_solved_time,\n",
    "        'Median_solved_time': Median_solved_time,\n",
    "    }\n",
    "    df_topics.append(topic_info)\n",
    "\n",
    "df_topics = pd.DataFrame(df_topics)\n",
    "df_topics.to_json(os.path.join(path_challenge_information,\n",
    "                  'general.json'), indent=4, orient='records')\n",
    "df_topics = df_topics.set_index('Challenge_topic')\n",
    "\n",
    "fig = df_topics.sort_values('Mean_score', ascending=False)['Mean_score'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean score', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Mean_score.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_link_count', ascending=False)['Mean_link_count'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean link count', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Mean_link_count.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_info_entropy', ascending=False)['Mean_info_entropy'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean info entropy', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Mean_info_entropy.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_answer_count', ascending=False)['Mean_answer_count'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean answer count', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Mean_answer_count.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_comment_count', ascending=False)['Mean_comment_count'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean comment count', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Mean_comment_count.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Score_participation_ratio', ascending=False)['Score_participation_ratio'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge score participation ratio', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information,\n",
    "            'Score_participation_ratio.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Score_participation_weighted_product', ascending=False)['Score_participation_weighted_product'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge score participation weighted product', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information,\n",
    "            'Score_participation_weighted_product.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Count_ratio', ascending=False)['Count_ratio'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge count ratio', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Count_ratio.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Solved_ratio')['Solved_ratio'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge Solved ratio', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'solved_ratio.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_solved_time', ascending=False)['Mean_solved_time'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge median solved time', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'mean_solved_time.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Median_solved_time', ascending=False)['Median_solved_time'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean solved time', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'median_solved_time.png'))\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect solution statistics information\n",
    "\n",
    "df_solution = pd.read_json(os.path.join(path_dataset, 'topics.json'))\n",
    "df_solution = df_solution[df_solution['Solution_topic'] > -1]\n",
    "\n",
    "total_count = df_challenge['Solution_topic'].count()\n",
    "df_topics = []\n",
    "\n",
    "for name, group in df_challenge.groupby('Solution_topic'):\n",
    "    Mean_score = group['Answer_score'].mean()\n",
    "    Mean_link_count = group['Solution_link_count'].mean()\n",
    "    Mean_info_entropy = group['Solution_info_entropy'].mean()\n",
    "    Count_ratio = group['Solution_topic'].count() / total_count * 100\n",
    "    topic_info = {\n",
    "        'Challenge_topic': name,\n",
    "        'Mean_score': Mean_score,\n",
    "        'Mean_link_count': Mean_link_count,\n",
    "        'Mean_info_entropy': Mean_info_entropy,\n",
    "        'Count_ratio': Count_ratio,\n",
    "    }\n",
    "    df_topics.append(topic_info)\n",
    "\n",
    "df_topics = pd.DataFrame(df_topics)\n",
    "df_topics.to_json(os.path.join(path_solution_information,\n",
    "                  'general.json'), indent=4, orient='records')\n",
    "df_topics = df_topics.set_index('Challenge_topic')\n",
    "\n",
    "fig = df_topics.sort_values('Mean_score', ascending=False)['Mean_score'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean score', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_solution_information, 'Mean_score.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_link_count', ascending=False)['Mean_link_count'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean link count', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_solution_information, 'Mean_link_count.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_info_entropy', ascending=False)['Mean_info_entropy'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean info entropy', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_solution_information, 'Mean_info_entropy.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Count_ratio', ascending=False)['Count_ratio'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge count ratio', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_solution_information, 'Count_ratio.png'))\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.interpolate\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess as sm_lowess\n",
    "\n",
    "\n",
    "def smooth(x, y, xgrid, lowess_kw=None):\n",
    "    samples = np.random.choice(len(x), 50, replace=True)\n",
    "    y_s = y[samples]\n",
    "    x_s = x[samples]\n",
    "    y_sm = sm_lowess(y_s, x_s, **lowess_kw)\n",
    "    # regularly sample it onto the grid\n",
    "    y_grid = scipy.interpolate.interp1d(\n",
    "        x_s, y_sm, fill_value='extrapolate')(xgrid)\n",
    "    return y_grid\n",
    "\n",
    "\n",
    "def lowess_with_confidence_bounds(x, y, conf_interval=0.95, lowess_kw=None):\n",
    "    \"\"\"\n",
    "    Perform Lowess regression and determine a confidence interval by bootstrap resampling\n",
    "    \"\"\"\n",
    "    xgrid = np.linspace(x.min(), x.max())\n",
    "\n",
    "    K = 100\n",
    "    smooths = np.stack([smooth(x, y, xgrid, lowess_kw) for _ in range(K)]).T\n",
    "\n",
    "    mean = np.nanmean(smooths, axis=1)\n",
    "    stderr = scipy.stats.sem(smooths, axis=1)\n",
    "\n",
    "    clower = np.nanpercentile(smooths, (1-conf_interval)*50, axis=1)\n",
    "    cupper = np.nanpercentile(smooths, (1+conf_interval)*50, axis=1)\n",
    "\n",
    "    return xgrid, mean, stderr, clower, cupper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2014-09-14 22:12:24.493000'),\n",
       " Timestamp('2023-02-21 18:36:06.284000'))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.read_json(os.path.join(path_dataset, 'topics.json'))\n",
    "# BigQuery Stack Overflow public dataset is updated until Nov 24, 2022, 1:39:22 PM UTC-5\n",
    "min(df_all['Challenge_creation_time']), max(df_all['Challenge_creation_time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore challenge topics evolution\n",
    "\n",
    "df_challenge = pd.read_json(os.path.join(path_dataset, 'topics.json'))\n",
    "df_challenge = df_challenge[(df_challenge['Challenge_creation_time'] > '2014-09-14')\n",
    "                            & (df_challenge['Challenge_creation_time'] < '2022-11-21')]\n",
    "\n",
    "for name, group in df_challenge.groupby('Challenge_topic'):\n",
    "    group = group.groupby(pd.Grouper(key='Challenge_creation_time', freq='2W')).agg(\n",
    "        Count=('Challenge_topic', 'count')).reset_index()\n",
    "    x = pd.to_datetime(group['Challenge_creation_time']).values\n",
    "    x = np.array([i.astype('datetime64[D]').astype(int) for i in x])\n",
    "    y = group['Count'].values\n",
    "    # 95% confidence interval\n",
    "    xgrid, mean, stderr, clower, cupper = lowess_with_confidence_bounds(\n",
    "        x, y, conf_interval=0.95, lowess_kw={\"frac\": 0.5, \"it\": 5, \"return_sorted\": False})\n",
    "    x = pd.to_datetime(group['Challenge_creation_time']).values\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    plt.plot(x, y, 'k.', label='Observations')\n",
    "    plt.plot(xgrid, mean, color='tomato', label='LOWESS')\n",
    "    plt.fill_between(xgrid, clower, cupper, alpha=0.3,\n",
    "                     label='LOWESS uncertainty')\n",
    "    plt.legend(loc='best')\n",
    "    fig.savefig(os.path.join(path_challenge_evolution,\n",
    "                f'Topic_{name}'), bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2014-09-14 22:12:24.493000'),\n",
       " Timestamp('2023-02-21 18:36:06.284000'))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.read_json(os.path.join(path_dataset, 'topics.json'))\n",
    "df_solution = df_all[df_all['Solution_topic'] > -1]\n",
    "# BigQuery Stack Overflow public dataset is updated until Nov 24, 2022, 1:39:22 PM UTC-5\n",
    "min(df_solution['Challenge_creation_time']), max(\n",
    "    df_solution['Challenge_creation_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore solution topics evolution\n",
    "\n",
    "df_solution = pd.read_json(os.path.join(path_dataset, 'topics.json'))\n",
    "df_solution = df_solution[df_solution['Solution_topic'] > -1]\n",
    "df_solution = df_solution[(df_solution['Challenge_creation_time'] > '2014-09-14')\n",
    "                          & (df_solution['Challenge_creation_time'] < '2022-11-21')]\n",
    "\n",
    "for name, group in df_solution.groupby('Solution_topic'):\n",
    "    group = group.groupby(pd.Grouper(key='Challenge_closed_time', freq='W')).agg(\n",
    "        Count=('Solution_topic', 'count')).reset_index()\n",
    "    x = pd.to_datetime(group['Challenge_closed_time']).values\n",
    "    x = np.array([i.astype('datetime64[D]').astype(int) for i in x])\n",
    "    y = group['Count'].values\n",
    "    # 95% confidence interval\n",
    "    xgrid, mean, stderr, clower, cupper = lowess_with_confidence_bounds(\n",
    "        x, y, conf_interval=0.95, lowess_kw={\"frac\": 0.5, \"it\": 5, \"return_sorted\": False})\n",
    "    x = pd.to_datetime(group['Challenge_closed_time']).values\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    plt.plot(x, y, 'k.', label='Observations')\n",
    "    plt.plot(xgrid, mean, color='tomato', label='LOWESS')\n",
    "    plt.fill_between(xgrid, clower, cupper, alpha=0.3,\n",
    "                     label='LOWESS uncertainty')\n",
    "    plt.legend(loc='best')\n",
    "    fig.savefig(os.path.join(path_solution_evolution,\n",
    "                f'Topic_{name}'), bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
