{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import openai\n",
    "import textstat\n",
    "import webbrowser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = '../../Dataset'\n",
    "path_result = '../../Result'\n",
    "\n",
    "path_rq12 = os.path.join(path_result, 'RQ12')\n",
    "path_rq3 = os.path.join(path_result, 'RQ3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_resolution_summary(link):\n",
    "    webbrowser.open(link)\n",
    "    user_input = input(\"Please input a summary for the opened link: \")\n",
    "    return user_input\n",
    "\n",
    "def find_duplicates(in_list):  \n",
    "    duplicates = []\n",
    "    unique = set(in_list)\n",
    "    for each in unique:\n",
    "        count = in_list.count(each)\n",
    "        if count > 1:\n",
    "            duplicates.append(each)\n",
    "    return duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/21zz42/Asset-Management-Topic-Modeling/.venv/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:557: RuntimeWarning: invalid value encountered in cast\n",
      "  arr, tz_parsed = tslib.array_with_unit_to_datetime(arg, unit, errors=errors)\n",
      "/home/21zz42/Asset-Management-Topic-Modeling/.venv/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:557: RuntimeWarning: invalid value encountered in cast\n",
      "  arr, tz_parsed = tslib.array_with_unit_to_datetime(arg, unit, errors=errors)\n",
      "/home/21zz42/Asset-Management-Topic-Modeling/.venv/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:557: RuntimeWarning: invalid value encountered in cast\n",
      "  arr, tz_parsed = tslib.array_with_unit_to_datetime(arg, unit, errors=errors)\n",
      "/home/21zz42/Asset-Management-Topic-Modeling/.venv/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:557: RuntimeWarning: invalid value encountered in cast\n",
      "  arr, tz_parsed = tslib.array_with_unit_to_datetime(arg, unit, errors=errors)\n",
      "/home/21zz42/Asset-Management-Topic-Modeling/.venv/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:557: RuntimeWarning: invalid value encountered in cast\n",
      "  arr, tz_parsed = tslib.array_with_unit_to_datetime(arg, unit, errors=errors)\n",
      "/home/21zz42/Asset-Management-Topic-Modeling/.venv/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:557: RuntimeWarning: invalid value encountered in cast\n",
      "  arr, tz_parsed = tslib.array_with_unit_to_datetime(arg, unit, errors=errors)\n",
      "/home/21zz42/Asset-Management-Topic-Modeling/.venv/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:557: RuntimeWarning: invalid value encountered in cast\n",
      "  arr, tz_parsed = tslib.array_with_unit_to_datetime(arg, unit, errors=errors)\n",
      "/home/21zz42/Asset-Management-Topic-Modeling/.venv/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:557: RuntimeWarning: invalid value encountered in cast\n",
      "  arr, tz_parsed = tslib.array_with_unit_to_datetime(arg, unit, errors=errors)\n",
      "/home/21zz42/Asset-Management-Topic-Modeling/.venv/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:557: RuntimeWarning: invalid value encountered in cast\n",
      "  arr, tz_parsed = tslib.array_with_unit_to_datetime(arg, unit, errors=errors)\n",
      "/home/21zz42/Asset-Management-Topic-Modeling/.venv/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:557: RuntimeWarning: invalid value encountered in cast\n",
      "  arr, tz_parsed = tslib.array_with_unit_to_datetime(arg, unit, errors=errors)\n"
     ]
    }
   ],
   "source": [
    "file_new = 'macro-topics'\n",
    "file_old = 'labels'\n",
    "\n",
    "df_new = pd.read_json(os.path.join(path_rq12, f'{file_new}.json'))\n",
    "df_new = df_new[df_new['Challenge_resolved_time'].notna()]\n",
    "df_old = pd.read_json(os.path.join(path_rq3, f'{file_old}.json'))\n",
    "\n",
    "df_git = df_old[df_old['Platform'].str.contains('Git')]\n",
    "df_stack = df_old[df_old['Platform'].str.contains('Stack')]\n",
    "df_tool = df_old[df_old['Platform'].str.contains('Tool')]\n",
    "\n",
    "for index, row in df_new.iterrows():\n",
    "    if 'Git' in row['Platform']:\n",
    "        for i2, r2 in df_git.iterrows():\n",
    "            if row['Challenge_link'] == r2['Challenge_link']:\n",
    "                df_new.at[index, 'Resolution_summary'] = r2['Resolution_summary']\n",
    "                break\n",
    "    elif 'Stack' in row['Platform']:\n",
    "        for i2, r2 in df_stack.iterrows():\n",
    "            if row['Challenge_link'] == r2['Challenge_link']:\n",
    "                df_new.at[index, 'Resolution_summary'] = r2['Resolution_summary']\n",
    "                break\n",
    "    else:\n",
    "        for i2, r2 in df_tool.iterrows():\n",
    "            if row['Challenge_link'] == r2['Challenge_link']:\n",
    "                df_new.at[index, 'Resolution_summary'] = r2['Resolution_summary']\n",
    "                break\n",
    "\n",
    "df_new.to_json(os.path.join(path_rq3, f'{file_old}.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(os.path.join(path_rq12, 'macro-topics.json'))\n",
    "df = df[df['Challenge_solved_time'].notna()]\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    df.at[index, 'Resolution_summary'] = input_resolution_summary(row['Challenge_link'])\n",
    "    if index % 50 == 49:\n",
    "        df.to_json(os.path.join(path_rq3, 'labels.json'), indent=4, orient='records')\n",
    "\n",
    "df.to_json(os.path.join(path_rq3, 'labels.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(path_rq12, 'macro-topics.json'))\n",
    "# df = df[df['Challenge_solved_time'].notna()]\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     if 'Issue' not in row['Platform']:\n",
    "#         continue\n",
    "#     df.at[index, 'Resolution_summary'] = input_resolution_summary(row['Challenge_link'])\n",
    "#     if index % 50 == 49:\n",
    "#         df.to_json(os.path.join(path_rq3, 'labels.json'), indent=4, orient='records')\n",
    "\n",
    "# df.to_json(os.path.join(path_rq3, 'labels.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(path_rq3, 'labels.json'))\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     if 'Issue' in row['Platform']:\n",
    "#         continue\n",
    "#     if row['Resolution_summary'] == 'na':\n",
    "#         print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_dataset = '../../Dataset'\n",
    "# df = pd.read_json(os.path.join(path_dataset, 'preprocessed.json'))\n",
    "# df = df[df['Challenge_solved_time'].notna()]\n",
    "# df.to_json(os.path.join(path_rq3, 'labels_new.json'), indent=4, orient='records')\n",
    "\n",
    "# df = pd.read_json(os.path.join(path_rq3, 'labels.json'))\n",
    "# df_new = pd.read_json(os.path.join(path_rq3, 'labels_new.json'))\n",
    "\n",
    "# # df_all = pd.concat([df, df_new], ignore_index=True)\n",
    "# # df_diff = df_all.drop_duplicates(subset=['Challenge_link'], keep=False)\n",
    "# df_diff = pd.concat([df, df_new, df_new]).drop_duplicates(subset=['Challenge_link'], keep=False)\n",
    "# # df_diff = pd.concat([df_new, df, df]).drop_duplicates(subset=['Challenge_link'], keep=False)\n",
    "# df_diff['Challenge_link'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_dataset = '../../Dataset'\n",
    "# df = pd.read_json(os.path.join(path_dataset, 'preprocessed.json'))\n",
    "# df = df[df['Challenge_solved_time'].notna()]\n",
    "# df['Resolution_summary'] = 'na'\n",
    "# df.to_json(os.path.join(path_rq3, 'labels.json'), orient='records', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_old = pd.read_json(os.path.join(path_rq3, 'labels.json'))\n",
    "# df_old.sort_values(by=['Challenge_link'], inplace=True)\n",
    "# df_old.to_json(os.path.join(path_rq3, 'labels.json'), orient='records', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(path_rq3, 'labels.json'))\n",
    "# df_old = pd.read_json(os.path.join(path_rq3, 'labels_closed.json'))\n",
    "\n",
    "# # df_difference = pd.concat([df_old, df, df]).drop_duplicates('Challenge_link', keep=False, ignore_index=True)\n",
    "# df_difference = pd.concat([df, df_old, df_old]).drop_duplicates('Challenge_link', keep=False, ignore_index=True)\n",
    "\n",
    "# df_all = pd.concat([df_old, df], ignore_index=True)\n",
    "# df_duplicate = df_all[df_all.duplicated(['Challenge_link'], keep='last')]\n",
    "\n",
    "# df_new = pd.concat([df_difference, df_duplicate], ignore_index=True)\n",
    "# df_new.to_json(os.path.join(path_rq3, 'labels+.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(path_rq3, 'labels.json'))\n",
    "\n",
    "# regex_digit = r\"[0-9]\"\n",
    "\n",
    "# regex_error = r\"[a-zA-Z0-9]+[eE]rror[^a-zA-Z]\"\n",
    "# regex_exception = r\"[a-zA-Z0-9]+[eE]xception[^a-zA-Z]\"\n",
    "\n",
    "# regex_error_leading = r\"[a-zA-Z0-9]+[eE]rror[a-zA-Z]+\"\n",
    "# regex_exception_leading = r\"[a-zA-Z0-9]+[eE]xception[a-zA-Z]+\"\n",
    "\n",
    "# false_positive_list = []\n",
    "\n",
    "# def camel_case_split(str):\n",
    "#     words = [[str[0].lower()]]\n",
    " \n",
    "#     for c in str[1:]:\n",
    "#         if (words[-1][-1].islower() or words[-1][-1].isdigit()) and c.isupper():\n",
    "#             words.append(list(c.lower()))\n",
    "#         else:\n",
    "#             words[-1].append(c)\n",
    "#     return ' '.join([''.join(word) for word in words])\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     challenge = row['Challenge_title'] + ' ' + row['Challenge_body']\n",
    "#     challenge = challenge.replace('\\n', ' ')\n",
    "#     error_list = re.findall(regex_error, challenge)\n",
    "#     if len(error_list):\n",
    "#         if row['Challenge_type'] != 'problem':\n",
    "#             df.at[index, 'Challenge_type'] = 'problem'\n",
    "#             false_positive_list.append(row['Challenge_link'])\n",
    "#         error = max(error_list, key = len)\n",
    "#         if len(re.findall(regex_digit, error)):\n",
    "#             print(row['Challenge_title'])\n",
    "#         else:\n",
    "#             error = re.sub(r'error.+', 'error', camel_case_split(error))\n",
    "#             df.at[index, 'Challenge_summary'] = error\n",
    "#     else:\n",
    "#         exception_list = re.findall(regex_exception, challenge)\n",
    "#         if len(exception_list):\n",
    "#             if row['Challenge_type'] != 'problem':\n",
    "#                 df.at[index, 'Challenge_type'] = 'problem'\n",
    "#                 false_positive_list.append(row['Challenge_link'])\n",
    "#             exception = max(exception_list, key = len)\n",
    "#             if len(re.findall(regex_digit, exception)):\n",
    "#                 print(row['Challenge_title'])\n",
    "#             else:\n",
    "#                 exception = re.sub(r'exception.+', 'exception', camel_case_split(exception))\n",
    "#                 df.at[index, 'Challenge_summary'] = exception\n",
    "#         else:\n",
    "#             error_list_leading = re.findall(regex_error_leading, challenge)\n",
    "#             if len(error_list_leading):\n",
    "#                 print(row['Challenge_title'])\n",
    "#             else:\n",
    "#                 exception_list_leading = re.findall(regex_exception_leading, challenge)\n",
    "#                 if len(exception_list_leading):\n",
    "#                     print(row['Challenge_title'])\n",
    "                    \n",
    "# df.to_json(os.path.join(path_rq3, 'anomaly.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(path_rq3, 'labels.json'))\n",
    "\n",
    "# regex_digit = r\"[0-9]\"\n",
    "\n",
    "# regex_error = r\"[a-zA-Z0-9]+[eE]rror[^a-zA-Z]\"\n",
    "# regex_exception = r\"[a-zA-Z0-9]+[eE]xception[^a-zA-Z]\"\n",
    "\n",
    "# regex_error_leading = r\"[a-zA-Z0-9]+[eE]rror[a-zA-Z]+\"\n",
    "# regex_exception_leading = r\"[a-zA-Z0-9]+[eE]xception[a-zA-Z]+\"\n",
    "\n",
    "# def camel_case_split(str):\n",
    "#     words = [[str[0].lower()]]\n",
    " \n",
    "#     for c in str[1:]:\n",
    "#         if (words[-1][-1].islower() or words[-1][-1].isdigit()) and c.isupper():\n",
    "#             words.append(list(c.lower()))\n",
    "#         else:\n",
    "#             words[-1].append(c)\n",
    "#     return ' '.join([''.join(word) for word in words])\n",
    "\n",
    "# titles = []\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     if row['Challenge_title'] in titles:\n",
    "#         continue\n",
    "#     challenge = row['Challenge_title'] + ' ' + row['Challenge_body']\n",
    "#     challenge = challenge.replace('\\n', ' ').lower()\n",
    "#     if (' 403 ' in challenge) or ('[403]' in challenge) or ('(403)' in challenge) or (' 403,' in challenge) or ('forbidden' in challenge):\n",
    "#         pass\n",
    "#         # print(row['Challenge_title'])\n",
    "#         # df.at[index, 'Challenge_type'] = 'problem'\n",
    "#         # df.at[index, 'Challenge_summary'] = 'forbidden error'\n",
    "#     elif (' 404 ' in challenge) or ('[404]' in challenge) or ('(404)' in challenge) or (' 404,' in challenge) or ('not found' in challenge):\n",
    "#         print(row['Challenge_title'])\n",
    "        \n",
    "# # df.to_json(os.path.join(path_rq3, 'labels.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_topic = '''You will be given a set of topics refering to specific empirical software engineering resolution. Please summarize each topic in a phrase and attach one sentence description in the MLOps context. Also, you must guarantee that those phrases are not duplicate with one another.###\\n'''\n",
    "\n",
    "with open(os.path.join(path_rq3, 'Topic terms.pickle'), 'rb') as handle:\n",
    "    topic_terms = pickle.load(handle)\n",
    "\n",
    "    topic_term_list = []\n",
    "    for index, topic in enumerate(topic_terms):\n",
    "        terms = ', '.join([term[0] for term in topic])\n",
    "        topic_term = f'Resolution {index}: {terms}'\n",
    "        topic_term_list.append(topic_term)\n",
    "\n",
    "    prompt = prompt_topic + '\\n'.join(topic_term_list) + '\\n###\\n'\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "        temperature=0,\n",
    "        max_tokens=4000,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        timeout=300,\n",
    "        stream=False)\n",
    "\n",
    "    topics = completion.choices[0].message.content\n",
    "    print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = ''''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_entries = [topic for topic in topics.split('Topic ') if topic]\n",
    "\n",
    "topic_list = []\n",
    "topic_mapping = {}\n",
    "\n",
    "for index, topic_entry in enumerate(topic_entries):\n",
    "    topic_name, topic_info = topic_entry.split(' - ')\n",
    "    topic_name = topic_name.split(': ')[-1]\n",
    "    topic_description, topic_description_mlops = topic_info.split('MLOps Context: ')\n",
    "    topic = {\n",
    "        'Index': index + 1,\n",
    "        'Topic': topic_name,\n",
    "        'Description': topic_description.strip(),\n",
    "        # 'Description (MLOps)': topic_description_mlops.strip(),\n",
    "    }\n",
    "    topic_list.append(topic)\n",
    "    topic_mapping[index] = topic_name\n",
    "    \n",
    "topic_df = pd.DataFrame(topic_list)\n",
    "print(topic_df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_topic2index_list = [\n",
    "    ('Code Development', []),\n",
    "    # ('Code Management', []),\n",
    "    ('Cost Management', []),\n",
    "    ('Compute Management', []),\n",
    "    ('Data Development', []),\n",
    "    ('Data Management', []),\n",
    "    ('Environment Management', []),\n",
    "    ('Experiment Management', []),\n",
    "    ('File Management', []),\n",
    "    ('Model Development', []),\n",
    "    ('Model Management', []),\n",
    "    ('Model Serving', []),\n",
    "    ('Network Management', []),\n",
    "    ('Observability Management', []),\n",
    "    ('Pipeline Management', []),\n",
    "    ('Quality Assurance Management', []),\n",
    "    ('Security Management', []),\n",
    "    # ('User Interface Management', []),\n",
    "]\n",
    "\n",
    "topic_list = []\n",
    "macro_topic_mapping = {}\n",
    "macro_topic_indexing = {}\n",
    "macro_topic2index_dict = {}\n",
    "for index, topic_set in enumerate(macro_topic2index_list):\n",
    "    macro_topic2index_dict[topic_set[0]] = topic_set[1]\n",
    "    macro_topic_indexing[index] = topic_set[0]\n",
    "    topic_list.extend(topic_set[1])\n",
    "    for topic in topic_set[1]:\n",
    "        macro_topic_mapping[topic] = index\n",
    "\n",
    "print(find_duplicates(topic_list))\n",
    "print(len(topic_df) == len(topic_list))\n",
    "print(set(range(len(topic_list))).difference(set(range(topic_df.shape[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # topic_list = [topic for topic in solution_topics.split('\\n') if topic]\n",
    "# solution_macro_topic_mapping_inverse = {\n",
    "#     \"-1: No Solution\": [-1],\n",
    "#     \"1: Artifact Management\": [1,15,36,42,44,48,49],\n",
    "#     \"2: Dependency and Environment Configuration\": [2,3,6,7,8,11,12,17,18,20,22,32,34,38,39,45,47],\n",
    "#     \"4: Deployment and Lifecycle Management\": [10,16,24,41],\n",
    "#     \"5: Maintenance and Support Management\": [5,26,29,30,43],\n",
    "#     \"6: Recommandation and Best Practices\": [9,21,23,25,35],\n",
    "#     \"7: Network and Access Control\": [4,14,27,31,33],\n",
    "#     \"8: Observability Management\": [0,28],\n",
    "#     \"10: Compute and Resource Management\": [13,37,40],\n",
    "#     \"11: Script Handling\": [19,46],\n",
    "#     # \"9: Experiment Management\": [],\n",
    "#     # \"12: Function Usage\": [],#???\n",
    "#     # \"13: Algorithm Improvement\": [],\n",
    "#     # \"14: Difference Comparison\": [],#?\n",
    "#     # \"15: Account Management\": [],\n",
    "#     # \"16: Details Request\": [54],#?\n",
    "#     # \"17: Exception handling\": [],\n",
    "#     # \"Identifier Management\": [],\n",
    "# }\n",
    "\n",
    "# solution_topic_indexing = {}\n",
    "# solution_macro_topic_list = []\n",
    "# solution_macro_topic_mapping = {}\n",
    "# solution_macro_topic_indexing = {}\n",
    "# for macro_topic, sub_topics in solution_macro_topic_mapping_inverse.items():\n",
    "#     index, name = int(macro_topic.split(': ')[0]), macro_topic.split(': ')[1]\n",
    "#     solution_macro_topic_indexing[index] = name\n",
    "#     solution_macro_topic_list.extend(sub_topics)\n",
    "#     # macro_topic_list = []\n",
    "#     for topic in sub_topics:\n",
    "#         # macro_topic_list.append(topic_list[topic].split(' -')[0].split(': ')[-1])\n",
    "#         solution_macro_topic_mapping[topic] = macro_topic\n",
    "        \n",
    "# # print(find_duplicates(solution_macro_topic_list))\n",
    "# # print(len(solution_macro_topic_list) == 50)\n",
    "# # print(set(range(50)).difference(set(solution_macro_topic_list)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign human-readable & high-level topics to challenges & solutions\n",
    "\n",
    "df = pd.read_json(os.path.join(path_rq3, 'topics.json'))\n",
    "df['Resolution_summary_topic_macro'] = -1\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['Challenge_topic'] in macro_topic_mapping:\n",
    "        df.at[index, 'Resolution_summary_topic_macro'] = int(macro_topic_mapping[row['Resolution_summary_topic']])\n",
    "    else:\n",
    "        df.drop(index, inplace=True)\n",
    "\n",
    "df.to_json(os.path.join(path_rq3, 'macro-topics.json'), indent=4, orient='records')\n",
    "\n",
    "df_number = pd.DataFrame()\n",
    "\n",
    "values = []\n",
    "labels = []\n",
    "\n",
    "for index, group in df.groupby('Resolution_summary_topic_macro'):\n",
    "    topic_list = [topic + 1 for topic in macro_topic2index_dict[macro_topic_indexing[index]]]\n",
    "    entry = {\n",
    "        'Index': index + 1,\n",
    "        'Macro-topic': macro_topic_indexing[index],\n",
    "        'Percentage (%)': round(len(group)/len(df)*100, 2),\n",
    "        'Topic list': topic_list,\n",
    "    }\n",
    "    df_number = pd.concat([df_number, pd.DataFrame([entry])], ignore_index=True)\n",
    "    labels.append(macro_topic_indexing[index])\n",
    "    values.append(len(group))\n",
    "\n",
    "print(df_number.to_latex(float_format=\"%.2f\", index=False))\n",
    "fig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.3)])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import math\n",
    "\n",
    "df = pd.read_json(os.path.join(path_rq3, 'macro-topics.json'))\n",
    "\n",
    "color_map = {\n",
    "    'Problem': 'blue',\n",
    "    'Knowledge': 'red',\n",
    "}\n",
    "rows = cols = math.ceil(math.sqrt(df['Resolution_summary_topic_macro'].nunique()))\n",
    "fig = make_subplots(rows=rows, cols=cols, subplot_titles=[macro_topic_indexing[i] for i in df['Resolution_summary_topic_macro'].unique()])\n",
    "\n",
    "for macro_name, macro_group in df.groupby('Resolution_summary_topic_macro'):\n",
    "    categories = []\n",
    "    frequency_p = []\n",
    "    frequency_k = [] \n",
    "    \n",
    "    for name, group in macro_group.groupby('Resolution_summary_topic'):\n",
    "        categories.append(topic_mapping[name])\n",
    "        frequency_p.append(len(group[group['Challenge_type'] == 'problem']))\n",
    "        frequency_k.append(len(group[group['Challenge_type'] == 'knowledge']))\n",
    "    \n",
    "    row = macro_name // 4 + 1\n",
    "    col = macro_name % 4 + 1\n",
    "    show_legend = True if (row == 1 and col == 1) else False\n",
    "    \n",
    "    fig.add_trace(go.Bar(\n",
    "        name='Problem', \n",
    "        x=categories, \n",
    "        y=frequency_p, \n",
    "        legendgroup='Problem', \n",
    "        marker_color=color_map['Problem'],\n",
    "        showlegend=show_legend\n",
    "    ), row=row, col=col)\n",
    "    fig.add_trace(go.Bar(\n",
    "        name='Knowledge', \n",
    "        x=categories, \n",
    "        y=frequency_k, \n",
    "        legendgroup='Knowledge', \n",
    "        marker_color=color_map['Knowledge'],\n",
    "        showlegend=show_legend\n",
    "    ), row=row, col=col)\n",
    "    fig.update_xaxes(\n",
    "            tickangle=90,  # Lay font horizontally\n",
    "            # tickfont=dict(size=10),  # Shrink font size\n",
    "            row=row, \n",
    "            col=col\n",
    "    )\n",
    "    \n",
    "fig.update_layout(\n",
    "    barmode='overlay',\n",
    "    width=800,  # Adjust the width as needed\n",
    "    height=800,  # Adjust the height as needed\n",
    "    margin=go.layout.Margin(\n",
    "        l=20,  # left margin\n",
    "        r=20,  # right margin\n",
    "        b=20,  # bottom margin\n",
    "        t=20,  # top margin\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(path_rq3, 'Macro-topics group frequency histogram.pdf'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topics = pd.read_json(os.path.join(path_rq3, 'macro-topics.json'))\n",
    "df_topics = df_topics[df_topics['Challenge_type'] == 'problem']\n",
    "df_topics = df_topics[df_topics['Resolution_summary_topic_macro'] != -1]\n",
    "\n",
    "df = df_topics[['Challenge_topic_macro', 'Resolution_summary_topic_macro']].value_counts().reset_index(name='count')\n",
    "df_grouped = df.groupby('Challenge_topic_macro')['count'].sum().reset_index()\n",
    "df_grouped.rename(columns={'count': 'sum'}, inplace=True)\n",
    "df_merged = pd.merge(df, df_grouped, on='Challenge_topic_macro')\n",
    "df_merged['normalized_count'] = df_merged['count'] / df_merged['sum']\n",
    "\n",
    "df_heatmap = df_merged.pivot_table(values='normalized_count', index='Resolution_summary_topic_macro', columns='Challenge_topic_macro', aggfunc=np.mean)\n",
    "ax = sns.heatmap(df_heatmap, cmap=\"GnBu\")\n",
    "ax.invert_yaxis()\n",
    "plt.xlabel('Problem')\n",
    "plt.ylabel('Resolution')\n",
    "plt.savefig(os.path.join(path_rq3, 'Problem_resolution_heatmap_column.pdf'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_topics = pd.read_json(os.path.join(path_rq3, 'macro-topics.json'))\n",
    "# df_topics = df_topics[df_topics['Challenge_type'] == 'problem']\n",
    "# df_topics = df_topics[df_topics['Resolution_summary_topic_macro'] != -1]\n",
    "\n",
    "# df = df_topics[['Challenge_topic_macro', 'Resolution_summary_topic_macro']].value_counts().reset_index(name='count')\n",
    "# df_grouped = df.groupby('Resolution_summary_topic_macro')['count'].sum().reset_index()\n",
    "# df_grouped.rename(columns={'count': 'sum'}, inplace=True)\n",
    "# df_merged = pd.merge(df, df_grouped, on='Resolution_summary_topic_macro')\n",
    "# df_merged['normalized_count'] = df_merged['count'] / df_merged['sum']\n",
    "\n",
    "# df_heatmap = df_merged.pivot_table(values='normalized_count', index='Resolution_summary_topic_macro', columns='Challenge_topic_macro', aggfunc=np.mean)\n",
    "# ax = sns.heatmap(df_heatmap, cmap=\"GnBu\")\n",
    "# ax.invert_yaxis()\n",
    "# plt.xlabel('Problem')\n",
    "# plt.ylabel('Resolution')\n",
    "# plt.savefig(os.path.join(path_rq3, 'Problem_resolution_heatmap_row.pdf'), bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topics = pd.read_json(os.path.join(path_rq3, 'macro-topics.json'))\n",
    "df_topics = df_topics[df_topics['Challenge_type'] == 'knowledge']\n",
    "df_topics = df_topics[df_topics['Resolution_summary_topic_macro'] != -1]\n",
    "\n",
    "df = df_topics[['Challenge_topic_macro', 'Resolution_summary_topic_macro']].value_counts().reset_index(name='count')\n",
    "df_grouped = df.groupby('Challenge_topic_macro')['count'].sum().reset_index()\n",
    "df_grouped.rename(columns={'count': 'sum'}, inplace=True)\n",
    "df_merged = pd.merge(df, df_grouped, on='Challenge_topic_macro')\n",
    "df_merged['normalized_count'] = df_merged['count'] / df_merged['sum']\n",
    "\n",
    "df_heatmap = df_merged.pivot_table(values='normalized_count', index='Resolution_summary_topic_macro', columns='Challenge_topic_macro', aggfunc=np.mean)\n",
    "ax = sns.heatmap(df_heatmap, cmap=\"GnBu\")\n",
    "ax.invert_yaxis()\n",
    "plt.xlabel('Knowledge')\n",
    "plt.ylabel('Resolution')\n",
    "plt.savefig(os.path.join(path_rq3, 'Knowledge_resolution_heatmap_column.pdf'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_topics = pd.read_json(os.path.join(path_rq3, 'macro-topics.json'))\n",
    "# df_topics = df_topics[df_topics['Challenge_type'] == 'knowledge']\n",
    "# df_topics = df_topics[df_topics['Resolution_summary_topic_macro'] != -1]\n",
    "\n",
    "# df = df_topics[['Challenge_topic_macro', 'Resolution_summary_topic_macro']].value_counts().reset_index(name='count')\n",
    "# df_grouped = df.groupby('Resolution_summary_topic_macro')['count'].sum().reset_index()\n",
    "# df_grouped.rename(columns={'count': 'sum'}, inplace=True)\n",
    "# df_merged = pd.merge(df, df_grouped, on='Resolution_summary_topic_macro')\n",
    "# df_merged['normalized_count'] = df_merged['count'] / df_merged['sum']\n",
    "\n",
    "# df_heatmap = df_merged.pivot_table(values='normalized_count', index='Resolution_summary_topic_macro', columns='Challenge_topic_macro', aggfunc=np.mean)\n",
    "# ax = sns.heatmap(df_heatmap, cmap=\"GnBu\")\n",
    "# ax.invert_yaxis()\n",
    "# plt.xlabel('Knowledge')\n",
    "# plt.ylabel('Resolution')\n",
    "# plt.savefig(os.path.join(path_rq3, 'Knowledge_resolution_heatmap_row.pdf'), bbox_inches='tight')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
