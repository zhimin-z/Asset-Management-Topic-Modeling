{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import openai\n",
    "import textstat\n",
    "import webbrowser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = '../../Dataset'\n",
    "path_result = '../../Result'\n",
    "\n",
    "path_rq12 = os.path.join(path_result, 'RQ12')\n",
    "path_rq3 = os.path.join(path_result, 'RQ3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_resolution_summary(link):\n",
    "    webbrowser.open(link)\n",
    "    user_input = input(\"Please input a summary for the opened link: \")\n",
    "    return user_input\n",
    "\n",
    "def find_duplicates(in_list):  \n",
    "    duplicates = []\n",
    "    unique = set(in_list)\n",
    "    for each in unique:\n",
    "        count = in_list.count(each)\n",
    "        if count > 1:\n",
    "            duplicates.append(each)\n",
    "    return duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/21zz42/Asset-Management-Topic-Modeling/.venv/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:557: RuntimeWarning: invalid value encountered in cast\n",
      "  arr, tz_parsed = tslib.array_with_unit_to_datetime(arg, unit, errors=errors)\n",
      "/home/21zz42/Asset-Management-Topic-Modeling/.venv/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:557: RuntimeWarning: invalid value encountered in cast\n",
      "  arr, tz_parsed = tslib.array_with_unit_to_datetime(arg, unit, errors=errors)\n",
      "/home/21zz42/Asset-Management-Topic-Modeling/.venv/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:557: RuntimeWarning: invalid value encountered in cast\n",
      "  arr, tz_parsed = tslib.array_with_unit_to_datetime(arg, unit, errors=errors)\n",
      "/home/21zz42/Asset-Management-Topic-Modeling/.venv/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:557: RuntimeWarning: invalid value encountered in cast\n",
      "  arr, tz_parsed = tslib.array_with_unit_to_datetime(arg, unit, errors=errors)\n",
      "/home/21zz42/Asset-Management-Topic-Modeling/.venv/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:557: RuntimeWarning: invalid value encountered in cast\n",
      "  arr, tz_parsed = tslib.array_with_unit_to_datetime(arg, unit, errors=errors)\n",
      "/home/21zz42/Asset-Management-Topic-Modeling/.venv/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:557: RuntimeWarning: invalid value encountered in cast\n",
      "  arr, tz_parsed = tslib.array_with_unit_to_datetime(arg, unit, errors=errors)\n",
      "/home/21zz42/Asset-Management-Topic-Modeling/.venv/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:557: RuntimeWarning: invalid value encountered in cast\n",
      "  arr, tz_parsed = tslib.array_with_unit_to_datetime(arg, unit, errors=errors)\n",
      "/home/21zz42/Asset-Management-Topic-Modeling/.venv/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:557: RuntimeWarning: invalid value encountered in cast\n",
      "  arr, tz_parsed = tslib.array_with_unit_to_datetime(arg, unit, errors=errors)\n",
      "/home/21zz42/Asset-Management-Topic-Modeling/.venv/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:557: RuntimeWarning: invalid value encountered in cast\n",
      "  arr, tz_parsed = tslib.array_with_unit_to_datetime(arg, unit, errors=errors)\n",
      "/home/21zz42/Asset-Management-Topic-Modeling/.venv/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:557: RuntimeWarning: invalid value encountered in cast\n",
      "  arr, tz_parsed = tslib.array_with_unit_to_datetime(arg, unit, errors=errors)\n"
     ]
    }
   ],
   "source": [
    "file_new = 'macro-topics'\n",
    "file_old = 'labels'\n",
    "\n",
    "df_new = pd.read_json(os.path.join(path_rq12, f'{file_new}.json'))\n",
    "df_new = df_new[df_new['Challenge_resolved_time'].notna()]\n",
    "df_old = pd.read_json(os.path.join(path_rq3, f'{file_old}.json'))\n",
    "\n",
    "df_git = df_old[df_old['Platform'].str.contains('Git')]\n",
    "df_stack = df_old[df_old['Platform'].str.contains('Stack')]\n",
    "df_tool = df_old[df_old['Platform'].str.contains('Tool')]\n",
    "\n",
    "for index, row in df_new.iterrows():\n",
    "    if 'Git' in row['Platform']:\n",
    "        for i2, r2 in df_git.iterrows():\n",
    "            if row['Challenge_link'] == r2['Challenge_link']:\n",
    "                df_new.at[index, 'Resolution_summary'] = r2['Resolution_summary']\n",
    "                break\n",
    "    elif 'Stack' in row['Platform']:\n",
    "        for i2, r2 in df_stack.iterrows():\n",
    "            if row['Challenge_link'] == r2['Challenge_link']:\n",
    "                df_new.at[index, 'Resolution_summary'] = r2['Resolution_summary']\n",
    "                break\n",
    "    else:\n",
    "        for i2, r2 in df_tool.iterrows():\n",
    "            if row['Challenge_link'] == r2['Challenge_link']:\n",
    "                df_new.at[index, 'Resolution_summary'] = r2['Resolution_summary']\n",
    "                break\n",
    "\n",
    "df_new.to_json(os.path.join(path_rq3, f'{file_old}.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(os.path.join(path_rq12, 'macro-topics.json'))\n",
    "df = df[df['Challenge_solved_time'].notna()]\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    df.at[index, 'Resolution_summary'] = input_resolution_summary(row['Challenge_link'])\n",
    "    if index % 50 == 49:\n",
    "        df.to_json(os.path.join(path_rq3, 'labels.json'), indent=4, orient='records')\n",
    "\n",
    "df.to_json(os.path.join(path_rq3, 'labels.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(path_rq12, 'macro-topics.json'))\n",
    "# df = df[df['Challenge_solved_time'].notna()]\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     if 'Issue' not in row['Platform']:\n",
    "#         continue\n",
    "#     df.at[index, 'Resolution_summary'] = input_resolution_summary(row['Challenge_link'])\n",
    "#     if index % 50 == 49:\n",
    "#         df.to_json(os.path.join(path_rq3, 'labels.json'), indent=4, orient='records')\n",
    "\n",
    "# df.to_json(os.path.join(path_rq3, 'labels.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(path_rq3, 'labels.json'))\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     if 'Issue' in row['Platform']:\n",
    "#         continue\n",
    "#     if row['Resolution_summary'] == 'na':\n",
    "#         print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_dataset = '../../Dataset'\n",
    "# df = pd.read_json(os.path.join(path_dataset, 'preprocessed.json'))\n",
    "# df = df[df['Challenge_solved_time'].notna()]\n",
    "# df.to_json(os.path.join(path_rq3, 'labels_new.json'), indent=4, orient='records')\n",
    "\n",
    "# df = pd.read_json(os.path.join(path_rq3, 'labels.json'))\n",
    "# df_new = pd.read_json(os.path.join(path_rq3, 'labels_new.json'))\n",
    "\n",
    "# # df_all = pd.concat([df, df_new], ignore_index=True)\n",
    "# # df_diff = df_all.drop_duplicates(subset=['Challenge_link'], keep=False)\n",
    "# df_diff = pd.concat([df, df_new, df_new]).drop_duplicates(subset=['Challenge_link'], keep=False)\n",
    "# # df_diff = pd.concat([df_new, df, df]).drop_duplicates(subset=['Challenge_link'], keep=False)\n",
    "# df_diff['Challenge_link'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_dataset = '../../Dataset'\n",
    "# df = pd.read_json(os.path.join(path_dataset, 'preprocessed.json'))\n",
    "# df = df[df['Challenge_solved_time'].notna()]\n",
    "# df['Resolution_summary'] = 'na'\n",
    "# df.to_json(os.path.join(path_rq3, 'labels.json'), orient='records', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_old = pd.read_json(os.path.join(path_rq3, 'labels.json'))\n",
    "# df_old.sort_values(by=['Challenge_link'], inplace=True)\n",
    "# df_old.to_json(os.path.join(path_rq3, 'labels.json'), orient='records', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(path_rq3, 'labels.json'))\n",
    "# df_old = pd.read_json(os.path.join(path_rq3, 'labels_closed.json'))\n",
    "\n",
    "# # df_difference = pd.concat([df_old, df, df]).drop_duplicates('Challenge_link', keep=False, ignore_index=True)\n",
    "# df_difference = pd.concat([df, df_old, df_old]).drop_duplicates('Challenge_link', keep=False, ignore_index=True)\n",
    "\n",
    "# df_all = pd.concat([df_old, df], ignore_index=True)\n",
    "# df_duplicate = df_all[df_all.duplicated(['Challenge_link'], keep='last')]\n",
    "\n",
    "# df_new = pd.concat([df_difference, df_duplicate], ignore_index=True)\n",
    "# df_new.to_json(os.path.join(path_rq3, 'labels+.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(path_rq3, 'labels.json'))\n",
    "\n",
    "# regex_digit = r\"[0-9]\"\n",
    "\n",
    "# regex_error = r\"[a-zA-Z0-9]+[eE]rror[^a-zA-Z]\"\n",
    "# regex_exception = r\"[a-zA-Z0-9]+[eE]xception[^a-zA-Z]\"\n",
    "\n",
    "# regex_error_leading = r\"[a-zA-Z0-9]+[eE]rror[a-zA-Z]+\"\n",
    "# regex_exception_leading = r\"[a-zA-Z0-9]+[eE]xception[a-zA-Z]+\"\n",
    "\n",
    "# false_positive_list = []\n",
    "\n",
    "# def camel_case_split(str):\n",
    "#     words = [[str[0].lower()]]\n",
    " \n",
    "#     for c in str[1:]:\n",
    "#         if (words[-1][-1].islower() or words[-1][-1].isdigit()) and c.isupper():\n",
    "#             words.append(list(c.lower()))\n",
    "#         else:\n",
    "#             words[-1].append(c)\n",
    "#     return ' '.join([''.join(word) for word in words])\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     challenge = row['Challenge_title'] + ' ' + row['Challenge_body']\n",
    "#     challenge = challenge.replace('\\n', ' ')\n",
    "#     error_list = re.findall(regex_error, challenge)\n",
    "#     if len(error_list):\n",
    "#         if row['Challenge_type'] != 'problem':\n",
    "#             df.at[index, 'Challenge_type'] = 'problem'\n",
    "#             false_positive_list.append(row['Challenge_link'])\n",
    "#         error = max(error_list, key = len)\n",
    "#         if len(re.findall(regex_digit, error)):\n",
    "#             print(row['Challenge_title'])\n",
    "#         else:\n",
    "#             error = re.sub(r'error.+', 'error', camel_case_split(error))\n",
    "#             df.at[index, 'Challenge_summary'] = error\n",
    "#     else:\n",
    "#         exception_list = re.findall(regex_exception, challenge)\n",
    "#         if len(exception_list):\n",
    "#             if row['Challenge_type'] != 'problem':\n",
    "#                 df.at[index, 'Challenge_type'] = 'problem'\n",
    "#                 false_positive_list.append(row['Challenge_link'])\n",
    "#             exception = max(exception_list, key = len)\n",
    "#             if len(re.findall(regex_digit, exception)):\n",
    "#                 print(row['Challenge_title'])\n",
    "#             else:\n",
    "#                 exception = re.sub(r'exception.+', 'exception', camel_case_split(exception))\n",
    "#                 df.at[index, 'Challenge_summary'] = exception\n",
    "#         else:\n",
    "#             error_list_leading = re.findall(regex_error_leading, challenge)\n",
    "#             if len(error_list_leading):\n",
    "#                 print(row['Challenge_title'])\n",
    "#             else:\n",
    "#                 exception_list_leading = re.findall(regex_exception_leading, challenge)\n",
    "#                 if len(exception_list_leading):\n",
    "#                     print(row['Challenge_title'])\n",
    "                    \n",
    "# df.to_json(os.path.join(path_rq3, 'anomaly.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(path_rq3, 'labels.json'))\n",
    "\n",
    "# regex_digit = r\"[0-9]\"\n",
    "\n",
    "# regex_error = r\"[a-zA-Z0-9]+[eE]rror[^a-zA-Z]\"\n",
    "# regex_exception = r\"[a-zA-Z0-9]+[eE]xception[^a-zA-Z]\"\n",
    "\n",
    "# regex_error_leading = r\"[a-zA-Z0-9]+[eE]rror[a-zA-Z]+\"\n",
    "# regex_exception_leading = r\"[a-zA-Z0-9]+[eE]xception[a-zA-Z]+\"\n",
    "\n",
    "# def camel_case_split(str):\n",
    "#     words = [[str[0].lower()]]\n",
    " \n",
    "#     for c in str[1:]:\n",
    "#         if (words[-1][-1].islower() or words[-1][-1].isdigit()) and c.isupper():\n",
    "#             words.append(list(c.lower()))\n",
    "#         else:\n",
    "#             words[-1].append(c)\n",
    "#     return ' '.join([''.join(word) for word in words])\n",
    "\n",
    "# titles = []\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     if row['Challenge_title'] in titles:\n",
    "#         continue\n",
    "#     challenge = row['Challenge_title'] + ' ' + row['Challenge_body']\n",
    "#     challenge = challenge.replace('\\n', ' ').lower()\n",
    "#     if (' 403 ' in challenge) or ('[403]' in challenge) or ('(403)' in challenge) or (' 403,' in challenge) or ('forbidden' in challenge):\n",
    "#         pass\n",
    "#         # print(row['Challenge_title'])\n",
    "#         # df.at[index, 'Challenge_type'] = 'problem'\n",
    "#         # df.at[index, 'Challenge_summary'] = 'forbidden error'\n",
    "#     elif (' 404 ' in challenge) or ('[404]' in challenge) or ('(404)' in challenge) or (' 404,' in challenge) or ('not found' in challenge):\n",
    "#         print(row['Challenge_title'])\n",
    "        \n",
    "# # df.to_json(os.path.join(path_rq3, 'labels.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolution 0: Bug Fixing - In MLOps, this refers to the process of identifying, diagnosing, and resolving issues or bugs in the software or machine learning model.\n",
      "Resolution 1: Parameter Modification - This involves changing or updating parameters in the machine learning model or software to improve performance or functionality.\n",
      "Resolution 2: Configuration Update - In MLOps, this refers to the process of changing or updating the configuration settings of the software or machine learning model.\n",
      "Resolution 3: Support Request Handling - This involves dealing with support tickets or requests raised by users or team members in the MLOps process.\n",
      "Resolution 4: Package Upgrading - This refers to the process of updating or upgrading software packages or libraries used in the machine learning model or software.\n",
      "Resolution 5: Logging Implementation - In MLOps, this involves using or implementing logging methods to track and record the performance or issues of the machine learning model or software.\n",
      "Resolution 6: Filepath Update - This involves changing or correcting the filepaths used in the software or machine learning model.\n",
      "Resolution 7: Permission Management - This refers to the process of assigning or granting necessary permissions or roles in the MLOps process.\n",
      "Resolution 8: Model Registration - In MLOps, this involves registering or creating machine learning models in the model registry.\n",
      "Resolution 9: Version Management - This refers to the process of checking, releasing, or upgrading versions of the software or machine learning model.\n",
      "Resolution 10: Dataset Creation - In MLOps, this involves creating or using datasets for training or testing the machine learning model.\n",
      "Resolution 11: Credential Management - This refers to the process of creating or using credentials for authentication in the MLOps process.\n",
      "Resolution 12: Docker Modification - In MLOps, this involves changing or updating Docker images or Dockerfiles used in the software or machine learning model.\n",
      "Resolution 13: Web Service Implementation - This refers to the process of creating or using web services or APIs in the MLOps process.\n",
      "Resolution 14: Data Transformation - In MLOps, this involves converting or transforming data types or formats for the machine learning model.\n",
      "Resolution 15: Server Adjustment - This refers to the process of adjusting server or network settings in the MLOps process.\n",
      "Resolution 16: Python Upgrade - In MLOps, this involves upgrading or changing the Python version or Python packages used in the software or machine learning model.\n",
      "Resolution 17: Wait Implementation - This refers to the process of adding or implementing wait methods or delays in the MLOps process.\n",
      "Resolution 18: SDK Upgrade - In MLOps, this involves updating or upgrading the Software Development Kit (SDK) used in the software or machine learning model.\n",
      "Resolution 19: Job Processing - This refers to the process of scheduling or executing processing jobs or tasks in the MLOps process.\n",
      "Resolution 20: Notebook Restart - In MLOps, this involves restarting or updating Jupyter notebooks used in the software or machine learning model.\n",
      "Resolution 21: Distributed Training - This refers to the process of implementing distributed or parallel training methods in the machine learning model.\n",
      "Resolution 22: Package Recommendation - In MLOps, this involves recommending or using specific packages or components, such as TensorFlow, in the machine learning model.\n",
      "Resolution 23: Storage Upload - This refers to the process of uploading data or files to local or cloud storage in the MLOps process.\n",
      "Resolution 24: Script Retry - In MLOps, this involves retrying or running scripts or commands in the software or machine learning model.\n",
      "Resolution 25: Custom Container Creation - This refers to the process of creating or using custom containers in the MLOps process.\n",
      "Resolution 26: Module Installation - In MLOps, this involves installing or adding modules in the software or machine learning model.\n",
      "Resolution 27: Pipeline Creation - This refers to the process of creating or updating pipelines in the MLOps process.\n",
      "Resolution 28: Package Installation - In MLOps, this involves installing software packages or libraries used in the machine learning model or software.\n",
      "Resolution 29: Environment Creation - This refers to the process of creating or using different environments in the MLOps process.\n",
      "Resolution 30: Resource Limit Increase - In MLOps, this involves increasing the capacity, quota, or memory resources used in the software or machine learning model.\n",
      "Resolution 31: Environment Variable Setting - This refers to the process of setting or configuring environment variables in the MLOps process.\n",
      "Resolution 32: Endpoint Invocation - In MLOps, this involves invoking or triggering endpoints in the software or machine learning model.\n",
      "Resolution 33: Experiment Creation - This refers to the process of creating or specifying experiments in the MLOps process.\n",
      "Resolution 34: Command Line Usage - In MLOps, this involves using the command line or terminal for executing commands or scripts.\n",
      "Resolution 35: Dictionary Handling - This refers to the process of handling or using dictionaries for data formatting or mapping in the MLOps process.\n",
      "Resolution 36: Instance Management - In MLOps, this involves creating or customizing compute instances used in the software or machine learning model.\n",
      "Resolution 37: Prediction Implementation - This refers to the process of implementing prediction methods or algorithms in the machine learning model.\n",
      "Resolution 38: Deployment Creation - In MLOps, this involves creating or automating deployments in the software or machine learning model.\n",
      "Resolution 39: Code Modification - This refers to the process of changing or modifying code in the software or machine learning model.\n",
      "Resolution 40: Tool Recommendation - In MLOps, this involves recommending or suggesting tools, frameworks, or methods for the machine learning model.\n",
      "Resolution 41: File Cleanup - This refers to the process of deleting or removing files or cookies in the MLOps process.\n",
      "Resolution 42: Model Download - In MLOps, this involves downloading or uploading machine learning models or model files.\n",
      "Resolution 43: Step Implementation - This refers to the process of implementing or using steps or functions in the MLOps process.\n",
      "Resolution 44: Feature Importance Analysis - In MLOps, this involves analyzing or checking the importance of features in the machine learning model.\n",
      "Resolution 45: Package Uninstallation - This refers to the process of uninstalling or removing software packages or libraries in the MLOps process.\n",
      "Resolution 46: Metrics Implementation - In MLOps, this involves implementing or checking metrics for evaluating the performance of the machine learning model.\n",
      "Resolution 47: Package Addition - This refers to the process of adding or installing missing packages in the software or machine learning model.\n",
      "Resolution 48: Extension Upgrade - In MLOps, this involves upgrading or updating extensions used in the software or machine learning model.\n"
     ]
    }
   ],
   "source": [
    "prompt_topic = '''You will be given a set of topics refering to specific empirical software engineering resolution. Please summarize each topic in a phrase and attach one sentence description in the MLOps context. Also, you must guarantee that those phrases are not duplicate with one another.###\\n'''\n",
    "\n",
    "with open(os.path.join(path_rq3, 'Topic terms.pickle'), 'rb') as handle:\n",
    "    topic_terms = pickle.load(handle)\n",
    "\n",
    "    topic_term_list = []\n",
    "    for index, topic in enumerate(topic_terms):\n",
    "        terms = ', '.join([term[0] for term in topic])\n",
    "        topic_term = f'Resolution {index}: {terms}'\n",
    "        topic_term_list.append(topic_term)\n",
    "\n",
    "    prompt = prompt_topic + '\\n'.join(topic_term_list) + '\\n###\\n'\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "        temperature=0,\n",
    "        max_tokens=4000,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        timeout=300,\n",
    "        stream=False)\n",
    "\n",
    "    topics = completion.choices[0].message.content\n",
    "    print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = '''Resolution 0: Bug Fixing - In MLOps, this refers to the process of identifying, diagnosing, and resolving issues or bugs in the software or machine learning model.\n",
    "Resolution 1: Parameter Modification - This involves changing or updating parameters in the machine learning model or software to improve performance or functionality.\n",
    "Resolution 2: Configuration Update - In MLOps, this refers to the process of changing or updating the configuration settings of the software or machine learning model.\n",
    "Resolution 3: Support Request Handling - This involves dealing with support tickets or requests raised by users or team members in the MLOps process.\n",
    "Resolution 4: Package Upgrading - This refers to the process of updating or upgrading software packages or libraries used in the machine learning model or software.\n",
    "Resolution 5: Logging Implementation - In MLOps, this involves using or implementing logging methods to track and record the performance or issues of the machine learning model or software.\n",
    "Resolution 6: Filepath Update - This involves changing or correcting the filepaths used in the software or machine learning model.\n",
    "Resolution 7: Permission Management - This refers to the process of assigning or granting necessary permissions or roles in the MLOps process.\n",
    "Resolution 8: Model Registration - In MLOps, this involves registering or creating machine learning models in the model registry.\n",
    "Resolution 9: Version Management - This refers to the process of checking, releasing, or upgrading versions of the software or machine learning model.\n",
    "Resolution 10: Dataset Creation - In MLOps, this involves creating or using datasets for training or testing the machine learning model.\n",
    "Resolution 11: Credential Management - This refers to the process of creating or using credentials for authentication in the MLOps process.\n",
    "Resolution 12: Docker Modification - In MLOps, this involves changing or updating Docker images or Dockerfiles used in the software or machine learning model.\n",
    "Resolution 13: Web Service Implementation - This refers to the process of creating or using web services or APIs in the MLOps process.\n",
    "Resolution 14: Data Transformation - In MLOps, this involves converting or transforming data types or formats for the machine learning model.\n",
    "Resolution 15: Server Adjustment - This refers to the process of adjusting server or network settings in the MLOps process.\n",
    "Resolution 16: Python Upgrade - In MLOps, this involves upgrading or changing the Python version or Python packages used in the software or machine learning model.\n",
    "Resolution 17: Wait Implementation - This refers to the process of adding or implementing wait methods or delays in the MLOps process.\n",
    "Resolution 18: SDK Upgrade - In MLOps, this involves updating or upgrading the Software Development Kit (SDK) used in the software or machine learning model.\n",
    "Resolution 19: Job Processing - This refers to the process of scheduling or executing processing jobs or tasks in the MLOps process.\n",
    "Resolution 20: Notebook Restart - In MLOps, this involves restarting or updating Jupyter notebooks used in the software or machine learning model.\n",
    "Resolution 21: Distributed Training - This refers to the process of implementing distributed or parallel training methods in the machine learning model.\n",
    "Resolution 22: Package Recommendation - In MLOps, this involves recommending or using specific packages or components, such as TensorFlow, in the machine learning model.\n",
    "Resolution 23: Storage Upload - This refers to the process of uploading data or files to local or cloud storage in the MLOps process.\n",
    "Resolution 24: Script Retry - In MLOps, this involves retrying or running scripts or commands in the software or machine learning model.\n",
    "Resolution 25: Custom Container Creation - This refers to the process of creating or using custom containers in the MLOps process.\n",
    "Resolution 26: Module Installation - In MLOps, this involves installing or adding modules in the software or machine learning model.\n",
    "Resolution 27: Pipeline Creation - This refers to the process of creating or updating pipelines in the MLOps process.\n",
    "Resolution 28: Package Installation - In MLOps, this involves installing software packages or libraries used in the machine learning model or software.\n",
    "Resolution 29: Environment Creation - This refers to the process of creating or using different environments in the MLOps process.\n",
    "Resolution 30: Resource Limit Increase - In MLOps, this involves increasing the capacity, quota, or memory resources used in the software or machine learning model.\n",
    "Resolution 31: Environment Variable Setting - This refers to the process of setting or configuring environment variables in the MLOps process.\n",
    "Resolution 32: Endpoint Invocation - In MLOps, this involves invoking or triggering endpoints in the software or machine learning model.\n",
    "Resolution 33: Experiment Creation - This refers to the process of creating or specifying experiments in the MLOps process.\n",
    "Resolution 34: Command Line Usage - In MLOps, this involves using the command line or terminal for executing commands or scripts.\n",
    "Resolution 35: Dictionary Handling - This refers to the process of handling or using dictionaries for data formatting or mapping in the MLOps process.\n",
    "Resolution 36: Instance Management - In MLOps, this involves creating or customizing compute instances used in the software or machine learning model.\n",
    "Resolution 37: Prediction Implementation - This refers to the process of implementing prediction methods or algorithms in the machine learning model.\n",
    "Resolution 38: Deployment Creation - In MLOps, this involves creating or automating deployments in the software or machine learning model.\n",
    "Resolution 39: Code Modification - This refers to the process of changing or modifying code in the software or machine learning model.\n",
    "Resolution 40: Tool Recommendation - In MLOps, this involves recommending or suggesting tools, frameworks, or methods for the machine learning model.\n",
    "Resolution 41: File Cleanup - This refers to the process of deleting or removing files or cookies in the MLOps process.\n",
    "Resolution 42: Model Download - In MLOps, this involves downloading or uploading machine learning models or model files.\n",
    "Resolution 43: Step Implementation - This refers to the process of implementing or using steps or functions in the MLOps process.\n",
    "Resolution 44: Feature Importance Analysis - In MLOps, this involves analyzing or checking the importance of features in the machine learning model.\n",
    "Resolution 45: Package Uninstallation - This refers to the process of uninstalling or removing software packages or libraries in the MLOps process.\n",
    "Resolution 46: Metrics Implementation - In MLOps, this involves implementing or checking metrics for evaluating the performance of the machine learning model.\n",
    "Resolution 47: Package Addition - This refers to the process of adding or installing missing packages in the software or machine learning model.\n",
    "Resolution 48: Extension Upgrade - In MLOps, this involves upgrading or updating extensions used in the software or machine learning model.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rll}\n",
      "\\toprule\n",
      " Index &                        Topic &                                        Description \\\\\n",
      "\\midrule\n",
      "     1 &                   Bug Fixing & In MLOps, this refers to the process of identif... \\\\\n",
      "     2 &       Parameter Modification & This involves changing or updating parameters i... \\\\\n",
      "     3 &         Configuration Update & In MLOps, this refers to the process of changin... \\\\\n",
      "     4 &     Support Request Handling & This involves dealing with support tickets or r... \\\\\n",
      "     5 &            Package Upgrading & This refers to the process of updating or upgra... \\\\\n",
      "     6 &       Logging Implementation & In MLOps, this involves using or implementing l... \\\\\n",
      "     7 &              Filepath Update & This involves changing or correcting the filepa... \\\\\n",
      "     8 &        Permission Management & This refers to the process of assigning or gran... \\\\\n",
      "     9 &           Model Registration & In MLOps, this involves registering or creating... \\\\\n",
      "    10 &           Version Management & This refers to the process of checking, releasi... \\\\\n",
      "    11 &             Dataset Creation & In MLOps, this involves creating or using datas... \\\\\n",
      "    12 &        Credential Management & This refers to the process of creating or using... \\\\\n",
      "    13 &          Docker Modification & In MLOps, this involves changing or updating Do... \\\\\n",
      "    14 &   Web Service Implementation & This refers to the process of creating or using... \\\\\n",
      "    15 &          Data Transformation & In MLOps, this involves converting or transform... \\\\\n",
      "    16 &            Server Adjustment & This refers to the process of adjusting server ... \\\\\n",
      "    17 &               Python Upgrade & In MLOps, this involves upgrading or changing t... \\\\\n",
      "    18 &          Wait Implementation & This refers to the process of adding or impleme... \\\\\n",
      "    19 &                  SDK Upgrade & In MLOps, this involves updating or upgrading t... \\\\\n",
      "    20 &               Job Processing & This refers to the process of scheduling or exe... \\\\\n",
      "    21 &             Notebook Restart & In MLOps, this involves restarting or updating ... \\\\\n",
      "    22 &         Distributed Training & This refers to the process of implementing dist... \\\\\n",
      "    23 &       Package Recommendation & In MLOps, this involves recommending or using s... \\\\\n",
      "    24 &               Storage Upload & This refers to the process of uploading data or... \\\\\n",
      "    25 &                 Script Retry & In MLOps, this involves retrying or running scr... \\\\\n",
      "    26 &    Custom Container Creation & This refers to the process of creating or using... \\\\\n",
      "    27 &          Module Installation & In MLOps, this involves installing or adding mo... \\\\\n",
      "    28 &            Pipeline Creation & This refers to the process of creating or updat... \\\\\n",
      "    29 &         Package Installation & In MLOps, this involves installing software pac... \\\\\n",
      "    30 &         Environment Creation & This refers to the process of creating or using... \\\\\n",
      "    31 &      Resource Limit Increase & In MLOps, this involves increasing the capacity... \\\\\n",
      "    32 & Environment Variable Setting & This refers to the process of setting or config... \\\\\n",
      "    33 &          Endpoint Invocation & In MLOps, this involves invoking or triggering ... \\\\\n",
      "    34 &          Experiment Creation & This refers to the process of creating or speci... \\\\\n",
      "    35 &           Command Line Usage & In MLOps, this involves using the command line ... \\\\\n",
      "    36 &          Dictionary Handling & This refers to the process of handling or using... \\\\\n",
      "    37 &          Instance Management & In MLOps, this involves creating or customizing... \\\\\n",
      "    38 &    Prediction Implementation & This refers to the process of implementing pred... \\\\\n",
      "    39 &          Deployment Creation & In MLOps, this involves creating or automating ... \\\\\n",
      "    40 &            Code Modification & This refers to the process of changing or modif... \\\\\n",
      "    41 &          Tool Recommendation & In MLOps, this involves recommending or suggest... \\\\\n",
      "    42 &                 File Cleanup & This refers to the process of deleting or remov... \\\\\n",
      "    43 &               Model Download & In MLOps, this involves downloading or uploadin... \\\\\n",
      "    44 &          Step Implementation & This refers to the process of implementing or u... \\\\\n",
      "    45 &  Feature Importance Analysis & In MLOps, this involves analyzing or checking t... \\\\\n",
      "    46 &       Package Uninstallation & This refers to the process of uninstalling or r... \\\\\n",
      "    47 &       Metrics Implementation & In MLOps, this involves implementing or checkin... \\\\\n",
      "    48 &             Package Addition & This refers to the process of adding or install... \\\\\n",
      "    49 &            Extension Upgrade & In MLOps, this involves upgrading or updating e... \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2441264/576590139.py:17: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(topic_df.to_latex(index=False))\n"
     ]
    }
   ],
   "source": [
    "topic_list = []\n",
    "topic_mapping = {}\n",
    "\n",
    "for index, topic_entry in enumerate(topics.split('\\n')):\n",
    "    topic_name, topic_info = topic_entry.split(' - ')\n",
    "    topic_name = topic_name.split(': ')[-1]\n",
    "    topic = {\n",
    "        'Index': index + 1,\n",
    "        'Topic': topic_name,\n",
    "        'Description': topic_info,\n",
    "        # 'Description (MLOps)': topic_description_mlops.strip(),\n",
    "    }\n",
    "    topic_list.append(topic)\n",
    "    topic_mapping[index] = topic_name\n",
    "    \n",
    "topic_df = pd.DataFrame(topic_list)\n",
    "print(topic_df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "True\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "macro_topic2index_list = [\n",
    "    (\"Artifact and File Management\", [6,8,10,14,23,42]),\n",
    "    (\"Compute and Resource Management\", [30,36]),\n",
    "    (\"Dependency and Environment Configuration\", [2,4,9,12,16,18,20,25,26,28,29,31,45,47,48]),\n",
    "    (\"Deployment and Lifecycle Management\", [19,27,32,37,38,43]),\n",
    "    (\"Experiment and Training Management\", [21,33,44]),\n",
    "    (\"Maintenance and Support Management\", [0,3]),\n",
    "    (\"Network and Access Control\", [7,11,13,15,41]),\n",
    "    (\"No Resolution\", [-1]),\n",
    "    (\"Observability Management\", [5,46]),\n",
    "    (\"Recommandation and Best Practices\", [22,40]),\n",
    "    (\"Script Handling\", [1,17,24,34,35,39]),\n",
    "    # \"12: Function Usage\": [],#???\n",
    "    # \"13: Algorithm Improvement\": [],\n",
    "    # \"14: Difference Comparison\": [],#?\n",
    "    # \"15: Account Management\": [],\n",
    "    # \"16: Details Request\": [54],#?\n",
    "    # \"17: Exception handling\": [],\n",
    "    # \"Identifier Management\": [],\n",
    "]\n",
    "\n",
    "macro_topic2index_list = [\n",
    "    ('Code Development', [1,17,24,34,35,39]),\n",
    "    ('Data Development', [14,44]),\n",
    "    ('Data Management', [10,23]),\n",
    "    ('Environment Management', [2,9,12,16,18,20,25,26,31,47,48]),\n",
    "    ('Experiment Management', [33,45]),\n",
    "    ('File Management', [6]),\n",
    "    ('Maintenance and Support', [0,3,4]),\n",
    "    ('Model Development', [21]),\n",
    "    ('Model Management', [8,42]),\n",
    "    ('Model Serving', [32,37,38,43]),\n",
    "    ('Network Management', [13,15]),\n",
    "    ('Observability Management', [5,46]),\n",
    "    ('Pipeline Management', [19,27,28,29]),\n",
    "    # ('Quality Assurance Management', []),\n",
    "    ('Resource Management', [30,36]),\n",
    "    ('Security Management', [7,11,41]),\n",
    "    ('User Recommandation', [22,40]),\n",
    "    # ('User Interface Management', []),\n",
    "]\n",
    "\n",
    "topic_list = []\n",
    "macro_topic_mapping = {}\n",
    "macro_topic_indexing = {}\n",
    "macro_topic2index_dict = {}\n",
    "for index, topic_set in enumerate(macro_topic2index_list):\n",
    "    macro_topic2index_dict[topic_set[0]] = topic_set[1]\n",
    "    macro_topic_indexing[index] = topic_set[0]\n",
    "    topic_list.extend(topic_set[1])\n",
    "    for topic in topic_set[1]:\n",
    "        macro_topic_mapping[topic] = index\n",
    "\n",
    "print(find_duplicates(topic_list))\n",
    "print(len(topic_df) == len(topic_list))\n",
    "print(set(range(len(topic_list))).difference(set(range(topic_df.shape[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # topic_list = [topic for topic in solution_topics.split('\\n') if topic]\n",
    "# solution_macro_topic_mapping_inverse = {\n",
    "#     \"-1: No Solution\": [-1],\n",
    "#     \"1: Artifact Management\": [1,15,36,42,44,48,49],\n",
    "#     \"2: Dependency and Environment Configuration\": [2,3,6,7,8,11,12,17,18,20,22,32,34,38,39,45,47],\n",
    "#     \"4: Deployment and Lifecycle Management\": [10,16,24,41],\n",
    "#     \"5: Maintenance and Support Management\": [5,26,29,30,43],\n",
    "#     \"6: Recommandation and Best Practices\": [9,21,23,25,35],\n",
    "#     \"7: Network and Access Control\": [4,14,27,31,33],\n",
    "#     \"8: Observability Management\": [0,28],\n",
    "#     \"10: Compute and Resource Management\": [13,37,40],\n",
    "#     \"11: Script Handling\": [19,46],\n",
    "#     # \"9: Experiment Management\": [],\n",
    "#     # \"12: Function Usage\": [],#???\n",
    "#     # \"13: Algorithm Improvement\": [],\n",
    "#     # \"14: Difference Comparison\": [],#?\n",
    "#     # \"15: Account Management\": [],\n",
    "#     # \"16: Details Request\": [54],#?\n",
    "#     # \"17: Exception handling\": [],\n",
    "#     # \"Identifier Management\": [],\n",
    "# }\n",
    "\n",
    "# solution_topic_indexing = {}\n",
    "# solution_macro_topic_list = []\n",
    "# solution_macro_topic_mapping = {}\n",
    "# solution_macro_topic_indexing = {}\n",
    "# for macro_topic, sub_topics in solution_macro_topic_mapping_inverse.items():\n",
    "#     index, name = int(macro_topic.split(': ')[0]), macro_topic.split(': ')[1]\n",
    "#     solution_macro_topic_indexing[index] = name\n",
    "#     solution_macro_topic_list.extend(sub_topics)\n",
    "#     # macro_topic_list = []\n",
    "#     for topic in sub_topics:\n",
    "#         # macro_topic_list.append(topic_list[topic].split(' -')[0].split(': ')[-1])\n",
    "#         solution_macro_topic_mapping[topic] = macro_topic\n",
    "        \n",
    "# # print(find_duplicates(solution_macro_topic_list))\n",
    "# # print(len(solution_macro_topic_list) == 50)\n",
    "# # print(set(range(50)).difference(set(solution_macro_topic_list)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/21zz42/Asset-Management-Topic-Modeling/.venv/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:557: RuntimeWarning: invalid value encountered in cast\n",
      "  arr, tz_parsed = tslib.array_with_unit_to_datetime(arg, unit, errors=errors)\n",
      "/home/21zz42/Asset-Management-Topic-Modeling/.venv/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:557: RuntimeWarning: invalid value encountered in cast\n",
      "  arr, tz_parsed = tslib.array_with_unit_to_datetime(arg, unit, errors=errors)\n",
      "/home/21zz42/Asset-Management-Topic-Modeling/.venv/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:557: RuntimeWarning: invalid value encountered in cast\n",
      "  arr, tz_parsed = tslib.array_with_unit_to_datetime(arg, unit, errors=errors)\n",
      "/home/21zz42/Asset-Management-Topic-Modeling/.venv/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:557: RuntimeWarning: invalid value encountered in cast\n",
      "  arr, tz_parsed = tslib.array_with_unit_to_datetime(arg, unit, errors=errors)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Challenge_topic'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Asset-Management-Topic-Modeling/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Asset-Management-Topic-Modeling/.venv/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Asset-Management-Topic-Modeling/.venv/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Challenge_topic'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mResolution_summary_topic_macro\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m index, row \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39miterrows():\n\u001b[0;32m----> 7\u001b[0m     \u001b[39mif\u001b[39;00m row[\u001b[39m'\u001b[39;49m\u001b[39mChallenge_topic\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39min\u001b[39;00m macro_topic_mapping:\n\u001b[1;32m      8\u001b[0m         df\u001b[39m.\u001b[39mat[index, \u001b[39m'\u001b[39m\u001b[39mResolution_summary_topic_macro\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(macro_topic_mapping[row[\u001b[39m'\u001b[39m\u001b[39mResolution_summary_topic\u001b[39m\u001b[39m'\u001b[39m]])\n\u001b[1;32m      9\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Asset-Management-Topic-Modeling/.venv/lib/python3.10/site-packages/pandas/core/series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m    983\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    984\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/Asset-Management-Topic-Modeling/.venv/lib/python3.10/site-packages/pandas/core/series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1088\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1089\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1090\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m~/Asset-Management-Topic-Modeling/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Challenge_topic'"
     ]
    }
   ],
   "source": [
    "# assign human-readable & high-level topics to challenges & solutions\n",
    "\n",
    "df = pd.read_json(os.path.join(path_rq3, 'topics.json'))\n",
    "df['Resolution_summary_topic_macro'] = -1\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['Challenge_topic'] in macro_topic_mapping:\n",
    "        df.at[index, 'Resolution_summary_topic_macro'] = int(macro_topic_mapping[row['Resolution_summary_topic']])\n",
    "    else:\n",
    "        df.drop(index, inplace=True)\n",
    "\n",
    "df.to_json(os.path.join(path_rq3, 'macro-topics.json'), indent=4, orient='records')\n",
    "\n",
    "df_number = pd.DataFrame()\n",
    "\n",
    "values = []\n",
    "labels = []\n",
    "\n",
    "for index, group in df.groupby('Resolution_summary_topic_macro'):\n",
    "    topic_list = [topic + 1 for topic in macro_topic2index_dict[macro_topic_indexing[index]]]\n",
    "    entry = {\n",
    "        'Index': index + 1,\n",
    "        'Macro-topic': macro_topic_indexing[index],\n",
    "        'Percentage (%)': round(len(group)/len(df)*100, 2),\n",
    "        'Topic list': topic_list,\n",
    "    }\n",
    "    df_number = pd.concat([df_number, pd.DataFrame([entry])], ignore_index=True)\n",
    "    labels.append(macro_topic_indexing[index])\n",
    "    values.append(len(group))\n",
    "\n",
    "print(df_number.to_latex(float_format=\"%.2f\", index=False))\n",
    "fig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.3)])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import math\n",
    "\n",
    "df = pd.read_json(os.path.join(path_rq3, 'macro-topics.json'))\n",
    "\n",
    "color_map = {\n",
    "    'Problem': 'blue',\n",
    "    'Knowledge': 'red',\n",
    "}\n",
    "rows = cols = math.ceil(math.sqrt(df['Resolution_summary_topic_macro'].nunique()))\n",
    "fig = make_subplots(rows=rows, cols=cols, subplot_titles=[macro_topic_indexing[i] for i in df['Resolution_summary_topic_macro'].unique()])\n",
    "\n",
    "for macro_name, macro_group in df.groupby('Resolution_summary_topic_macro'):\n",
    "    categories = []\n",
    "    frequency_p = []\n",
    "    frequency_k = [] \n",
    "    \n",
    "    for name, group in macro_group.groupby('Resolution_summary_topic'):\n",
    "        categories.append(topic_mapping[name])\n",
    "        frequency_p.append(len(group[group['Challenge_type'] == 'problem']))\n",
    "        frequency_k.append(len(group[group['Challenge_type'] == 'knowledge']))\n",
    "    \n",
    "    row = macro_name // 4 + 1\n",
    "    col = macro_name % 4 + 1\n",
    "    show_legend = True if (row == 1 and col == 1) else False\n",
    "    \n",
    "    fig.add_trace(go.Bar(\n",
    "        name='Problem', \n",
    "        x=categories, \n",
    "        y=frequency_p, \n",
    "        legendgroup='Problem', \n",
    "        marker_color=color_map['Problem'],\n",
    "        showlegend=show_legend\n",
    "    ), row=row, col=col)\n",
    "    fig.add_trace(go.Bar(\n",
    "        name='Knowledge', \n",
    "        x=categories, \n",
    "        y=frequency_k, \n",
    "        legendgroup='Knowledge', \n",
    "        marker_color=color_map['Knowledge'],\n",
    "        showlegend=show_legend\n",
    "    ), row=row, col=col)\n",
    "    fig.update_xaxes(\n",
    "            tickangle=90,  # Lay font horizontally\n",
    "            tickfont=dict(size=8),  # Shrink font size\n",
    "            row=row, \n",
    "            col=col\n",
    "    )\n",
    "    \n",
    "fig.update_layout(\n",
    "    barmode='stack',\n",
    "    width=800,  # Adjust the width as needed\n",
    "    height=800,  # Adjust the height as needed\n",
    "    margin=go.layout.Margin(\n",
    "        l=20,  # left margin\n",
    "        r=20,  # right margin\n",
    "        b=20,  # bottom margin\n",
    "        t=20,  # top margin\n",
    "    )\n",
    ")\n",
    "fig.update_annotations(dict(font_size=10))\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(path_rq3, 'Macro-topics group frequency histogram.pdf'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topics = pd.read_json(os.path.join(path_rq3, 'macro-topics.json'))\n",
    "df_topics = df_topics[df_topics['Challenge_type'] == 'problem']\n",
    "df_topics = df_topics[df_topics['Resolution_summary_topic_macro'] != -1]\n",
    "\n",
    "df = df_topics[['Challenge_topic_macro', 'Resolution_summary_topic_macro']].value_counts().reset_index(name='count')\n",
    "df_grouped = df.groupby('Challenge_topic_macro')['count'].sum().reset_index()\n",
    "df_grouped.rename(columns={'count': 'sum'}, inplace=True)\n",
    "df_merged = pd.merge(df, df_grouped, on='Challenge_topic_macro')\n",
    "df_merged['normalized_count'] = df_merged['count'] / df_merged['sum']\n",
    "\n",
    "df_heatmap = df_merged.pivot_table(values='normalized_count', index='Resolution_summary_topic_macro', columns='Challenge_topic_macro', aggfunc=np.mean)\n",
    "ax = sns.heatmap(df_heatmap, cmap=\"GnBu\")\n",
    "ax.invert_yaxis()\n",
    "plt.xlabel('Problem')\n",
    "plt.ylabel('Resolution')\n",
    "plt.savefig(os.path.join(path_rq3, 'Problem_resolution_heatmap_column.pdf'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_topics = pd.read_json(os.path.join(path_rq3, 'macro-topics.json'))\n",
    "# df_topics = df_topics[df_topics['Challenge_type'] == 'problem']\n",
    "# df_topics = df_topics[df_topics['Resolution_summary_topic_macro'] != -1]\n",
    "\n",
    "# df = df_topics[['Challenge_topic_macro', 'Resolution_summary_topic_macro']].value_counts().reset_index(name='count')\n",
    "# df_grouped = df.groupby('Resolution_summary_topic_macro')['count'].sum().reset_index()\n",
    "# df_grouped.rename(columns={'count': 'sum'}, inplace=True)\n",
    "# df_merged = pd.merge(df, df_grouped, on='Resolution_summary_topic_macro')\n",
    "# df_merged['normalized_count'] = df_merged['count'] / df_merged['sum']\n",
    "\n",
    "# df_heatmap = df_merged.pivot_table(values='normalized_count', index='Resolution_summary_topic_macro', columns='Challenge_topic_macro', aggfunc=np.mean)\n",
    "# ax = sns.heatmap(df_heatmap, cmap=\"GnBu\")\n",
    "# ax.invert_yaxis()\n",
    "# plt.xlabel('Problem')\n",
    "# plt.ylabel('Resolution')\n",
    "# plt.savefig(os.path.join(path_rq3, 'Problem_resolution_heatmap_row.pdf'), bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topics = pd.read_json(os.path.join(path_rq3, 'macro-topics.json'))\n",
    "df_topics = df_topics[df_topics['Challenge_type'] == 'knowledge']\n",
    "df_topics = df_topics[df_topics['Resolution_summary_topic_macro'] != -1]\n",
    "\n",
    "df = df_topics[['Challenge_topic_macro', 'Resolution_summary_topic_macro']].value_counts().reset_index(name='count')\n",
    "df_grouped = df.groupby('Challenge_topic_macro')['count'].sum().reset_index()\n",
    "df_grouped.rename(columns={'count': 'sum'}, inplace=True)\n",
    "df_merged = pd.merge(df, df_grouped, on='Challenge_topic_macro')\n",
    "df_merged['normalized_count'] = df_merged['count'] / df_merged['sum']\n",
    "\n",
    "df_heatmap = df_merged.pivot_table(values='normalized_count', index='Resolution_summary_topic_macro', columns='Challenge_topic_macro', aggfunc=np.mean)\n",
    "ax = sns.heatmap(df_heatmap, cmap=\"GnBu\")\n",
    "ax.invert_yaxis()\n",
    "plt.xlabel('Knowledge')\n",
    "plt.ylabel('Resolution')\n",
    "plt.savefig(os.path.join(path_rq3, 'Knowledge_resolution_heatmap_column.pdf'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_topics = pd.read_json(os.path.join(path_rq3, 'macro-topics.json'))\n",
    "# df_topics = df_topics[df_topics['Challenge_type'] == 'knowledge']\n",
    "# df_topics = df_topics[df_topics['Resolution_summary_topic_macro'] != -1]\n",
    "\n",
    "# df = df_topics[['Challenge_topic_macro', 'Resolution_summary_topic_macro']].value_counts().reset_index(name='count')\n",
    "# df_grouped = df.groupby('Resolution_summary_topic_macro')['count'].sum().reset_index()\n",
    "# df_grouped.rename(columns={'count': 'sum'}, inplace=True)\n",
    "# df_merged = pd.merge(df, df_grouped, on='Resolution_summary_topic_macro')\n",
    "# df_merged['normalized_count'] = df_merged['count'] / df_merged['sum']\n",
    "\n",
    "# df_heatmap = df_merged.pivot_table(values='normalized_count', index='Resolution_summary_topic_macro', columns='Challenge_topic_macro', aggfunc=np.mean)\n",
    "# ax = sns.heatmap(df_heatmap, cmap=\"GnBu\")\n",
    "# ax.invert_yaxis()\n",
    "# plt.xlabel('Knowledge')\n",
    "# plt.ylabel('Resolution')\n",
    "# plt.savefig(os.path.join(path_rq3, 'Knowledge_resolution_heatmap_row.pdf'), bbox_inches='tight')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
