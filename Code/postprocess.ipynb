{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\",\n",
    "              None, 'display.max_colwidth', None)\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = os.path.join(os.path.dirname(os.getcwd()), 'Dataset')\n",
    "\n",
    "path_result = os.path.join(os.path.dirname(os.getcwd()), 'Result')\n",
    "if not os.path.exists(path_result):\n",
    "    os.makedirs(path_result)\n",
    "\n",
    "path_general = os.path.join(path_result, 'General')\n",
    "if not os.path.exists(path_general):\n",
    "    os.makedirs(path_general)\n",
    "\n",
    "path_challenge = os.path.join(path_result, 'Challenge')\n",
    "if not os.path.exists(path_challenge):\n",
    "    os.makedirs(path_challenge)\n",
    "\n",
    "path_solution = os.path.join(path_result, 'Solution')\n",
    "if not os.path.exists(path_solution):\n",
    "    os.makedirs(path_solution)\n",
    "\n",
    "path_challenge_information = os.path.join(path_challenge, 'Information')\n",
    "if not os.path.exists(path_challenge_information):\n",
    "    os.makedirs(path_challenge_information)\n",
    "\n",
    "path_solution_information = os.path.join(path_solution, 'Information')\n",
    "if not os.path.exists(path_solution_information):\n",
    "    os.makedirs(path_solution_information)\n",
    "\n",
    "path_challenge_evolution = os.path.join(path_challenge, 'Evolution')\n",
    "if not os.path.exists(path_challenge_evolution):\n",
    "    os.makedirs(path_challenge_evolution)\n",
    "\n",
    "path_solution_evolution = os.path.join(path_solution, 'Evolution')\n",
    "if not os.path.exists(path_solution_evolution):\n",
    "    os.makedirs(path_solution_evolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topics = pd.read_json(os.path.join(path_general, 'topics.json'))\n",
    "df_topics = df_topics[df_topics['Solution_topic'] > -1]\n",
    "\n",
    "# as if we assign the topic id as the label\n",
    "label_challenge_original = df_topics['Challenge_topic'].unique().tolist()\n",
    "label_challenge_refined = [f'c_{label}' for label in label_challenge_original]\n",
    "label_challenge_map = dict(\n",
    "    zip(label_challenge_original, label_challenge_refined))\n",
    "\n",
    "label_solution_original = df_topics['Solution_topic'].unique().tolist()\n",
    "label_solution_refined = [f's_{label}' for label in label_solution_original]\n",
    "label_solution_map = dict(zip(label_solution_original, label_solution_refined))\n",
    "\n",
    "df_topics = df_topics.replace(\n",
    "    {'Challenge_topic': label_challenge_map, 'Solution_topic': label_solution_map})\n",
    "\n",
    "categories = ['Challenge_topic', 'Solution_topic']\n",
    "df_topics = df_topics.groupby(categories).size().reset_index(name='value')\n",
    "\n",
    "# we only visualize large topics\n",
    "df_topics = df_topics[df_topics['value'] > 20]\n",
    "\n",
    "newDf = pd.DataFrame()\n",
    "for i in range(len(categories)-1):\n",
    "    tempDf = df_topics[[categories[i], categories[i+1], 'value']]\n",
    "    tempDf.columns = ['source', 'target', 'value']\n",
    "    newDf = pd.concat([newDf, tempDf])\n",
    "newDf = newDf.groupby(['source', 'target']).agg({'value': 'sum'}).reset_index()\n",
    "\n",
    "label = list(np.unique(df_topics[categories].values))\n",
    "source = newDf['source'].apply(lambda x: label.index(x))\n",
    "target = newDf['target'].apply(lambda x: label.index(x))\n",
    "value = newDf['value']\n",
    "\n",
    "link = dict(source=source, target=target, value=value)\n",
    "node = dict(label=label)\n",
    "data = go.Sankey(link=link, node=node)\n",
    "\n",
    "fig = go.Figure(data)\n",
    "fig.update_layout(height=1000, width=1000, font=dict(size=30))\n",
    "fig.write_image(os.path.join(path_challenge_information,\n",
    "                'Challenge solution sankey.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenge topic distribution tree map\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_general, 'Topics.json'))\n",
    "df_topics['Challenge_participation_count'] = df_topics['Challenge_answer_count'] + \\\n",
    "    df_topics['Challenge_comment_count']\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=['Tool', 'Platform'],\n",
    "    values='Challenge_participation_count',\n",
    "    color='Challenge_topic',\n",
    "    width=2000,\n",
    "    height=1000,\n",
    ")\n",
    "fig.write_image(os.path.join(path_challenge_information,\n",
    "                'Challenge_topic_distribution.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create solution topic distribution tree map\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_general, 'Topics.json'))\n",
    "df_topics = df_topics[df_topics['Solution_topic'] > -1]\n",
    "df_topics['Challenge_participation_count'] = df_topics['Challenge_answer_count'] + \\\n",
    "    df_topics['Challenge_comment_count']\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=['Tool', 'Platform'],\n",
    "    values='Challenge_participation_count',\n",
    "    color='Solution_topic',\n",
    "    width=2000,\n",
    "    height=1000,\n",
    ")\n",
    "fig.write_image(os.path.join(path_solution_information,\n",
    "                'Solution_topic_distribution.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect challenge statistics information\n",
    "\n",
    "df_challenge = pd.read_json(os.path.join(path_general, 'Topics.json'))\n",
    "df_challenge = df_challenge[df_challenge['Challenge_topic'] > -1]\n",
    "\n",
    "df_challenge['Challenge_comment_count'] = df_challenge['Challenge_comment_count'].fillna(0)\n",
    "df_challenge['Challenge_solved_time'] = df_challenge['Challenge_closed_time'] - \\\n",
    "    df_challenge['Challenge_creation_time']\n",
    "df_challenge['Challenge_adjusted_solved_time'] = df_challenge['Solution_last_edit_time'] - \\\n",
    "    df_challenge['Challenge_last_edit_time']\n",
    "df_challenge['Challenge_participation_count'] = df_challenge['Challenge_answer_count'] + \\\n",
    "    df_challenge['Challenge_comment_count']\n",
    "\n",
    "total_count = df_challenge['Challenge_topic'].count()\n",
    "df_topics = []\n",
    "\n",
    "for name, group in df_challenge.groupby('Challenge_topic'):\n",
    "    Mean_score = group['Challenge_score'].mean()\n",
    "    Mean_favorite_count = group['Challenge_favorite_count'].mean()\n",
    "    Mean_follower_count = group['Challenge_follower_count'].mean()\n",
    "    Mean_link_count = group['Challenge_link_count'].mean()\n",
    "    Mean_information_entropy = group['Challenge_information_entropy'].mean()\n",
    "    Mean_readability = group['Challenge_readability'].mean()\n",
    "    Mean_sentence_count = group['Challenge_sentence_count'].mean()\n",
    "    Mean_word_count = group['Challenge_word_count'].mean()\n",
    "    Mean_unique_word_count = group['Challenge_unique_word_count'].mean()\n",
    "    Mean_view_count = group['Challenge_view_count'].mean()\n",
    "    Mean_answer_count = group['Challenge_answer_count'].mean()\n",
    "    Mean_comment_count = group['Challenge_comment_count'].mean()\n",
    "    Mean_participation_count = Mean_answer_count + Mean_comment_count\n",
    "    Score_participation_ratio = Mean_score / Mean_participation_count\n",
    "    Score_participation_weighted_product = (\n",
    "        group['Challenge_score'] * group['Challenge_participation_count']).mean()\n",
    "    Count = group['Challenge_topic'].count()\n",
    "    Count_ratio = Count / total_count * 100\n",
    "    Solved_ratio = group['Challenge_closed_time'].notna().sum() / Count\n",
    "    Mean_solved_time = group['Challenge_solved_time'].mean(\n",
    "    ) / pd.Timedelta(hours=1)\n",
    "    Median_solved_time = group['Challenge_solved_time'].median(\n",
    "    ) / pd.Timedelta(hours=1)\n",
    "    Mean_adjusted_solved_time = group['Challenge_adjusted_solved_time'].mean(\n",
    "    ) / pd.Timedelta(hours=1)\n",
    "    Median_adjusted_solved_time = group['Challenge_adjusted_solved_time'].median(\n",
    "    ) / pd.Timedelta(hours=1)\n",
    "    topic_info = {\n",
    "        'Challenge_topic': name,\n",
    "        'Mean_score': Mean_score,\n",
    "        'Mean_favorite_count': Mean_favorite_count,\n",
    "        'Mean_follower_count': Mean_follower_count,\n",
    "        'Mean_link_count': Mean_link_count,\n",
    "        'Mean_information_entropy': Mean_information_entropy,\n",
    "        'Mean_readability': Mean_readability,\n",
    "        'Mean_sentence_count': Mean_sentence_count,\n",
    "        'Mean_word_count': Mean_word_count,\n",
    "        'Mean_unique_word_count': Mean_unique_word_count,\n",
    "        'Mean_view_count': Mean_view_count,\n",
    "        'Mean_answer_count': Mean_answer_count,\n",
    "        'Mean_comment_count': Mean_comment_count,\n",
    "        'Score_participation_ratio': Score_participation_ratio,\n",
    "        'Score_participation_weighted_product': Score_participation_weighted_product,\n",
    "        'Count_ratio': Count_ratio,\n",
    "        'Solved_ratio': Solved_ratio,\n",
    "        'Mean_solved_time': Mean_solved_time,\n",
    "        'Median_solved_time': Median_solved_time,\n",
    "        'Mean_adjusted_solved_time': Mean_adjusted_solved_time,\n",
    "        'Median_adjusted_solved_time': Median_adjusted_solved_time,\n",
    "    }\n",
    "    df_topics.append(topic_info)\n",
    "\n",
    "df_topics = pd.DataFrame(df_topics)\n",
    "df_topics.to_json(os.path.join(path_challenge_information,\n",
    "                  'general.json'), indent=4, orient='records')\n",
    "df_topics = df_topics.set_index('Challenge_topic')\n",
    "\n",
    "fig = df_topics.sort_values('Mean_score', ascending=False)['Mean_score'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean score', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Mean_score.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_favorite_count', ascending=False)['Mean_favorite_count'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean favorite count', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Mean_favorite_count.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_follower_count', ascending=False)['Mean_follower_count'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean follower count', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Mean_follower_count.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_link_count', ascending=False)['Mean_link_count'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean link count', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Mean_link_count.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_information_entropy', ascending=False)['Mean_information_entropy'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean info entropy', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Mean_information_entropy.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_readability', ascending=False)['Mean_readability'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean readability', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Mean_readability.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_sentence_count', ascending=False)['Mean_sentence_count'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean sentence count', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Mean_sentence_count.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_word_count', ascending=False)['Mean_word_count'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean word count', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Mean_word_count.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_unique_word_count', ascending=False)['Mean_unique_word_count'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean unique word count', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Mean_unique_word_count.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_view_count', ascending=False)['Mean_view_count'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean view count', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Mean_view_count.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_answer_count', ascending=False)['Mean_answer_count'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean answer count', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Mean_answer_count.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_comment_count', ascending=False)['Mean_comment_count'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean comment count', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Mean_comment_count.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Score_participation_ratio', ascending=False)['Score_participation_ratio'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge score participation ratio', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information,\n",
    "            'Score_participation_ratio.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Score_participation_weighted_product', ascending=False)['Score_participation_weighted_product'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge score participation weighted product', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information,\n",
    "            'Score_participation_weighted_product.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Count_ratio', ascending=False)['Count_ratio'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge count ratio', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Count_ratio.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Solved_ratio')['Solved_ratio'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge Solved ratio', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'solved_ratio.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_solved_time', ascending=False)['Mean_solved_time'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge median solved time', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'mean_solved_time.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Median_solved_time', ascending=False)['Median_solved_time'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean solved time', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'median_solved_time.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_adjusted_solved_time', ascending=False)['Mean_adjusted_solved_time'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge mean adjusted solved time', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Mean_adjusted_solved_time.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Median_adjusted_solved_time', ascending=False)['Median_adjusted_solved_time'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Challenge median adjusted solved time', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_challenge_information, 'Median_adjusted_solved_time.png'))\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect solution statistics information\n",
    "\n",
    "df_solution = pd.read_json(os.path.join(path_general, 'Topics.json'))\n",
    "df_solution = df_solution[df_solution['Solution_topic'] > -1]\n",
    "\n",
    "total_count = df_challenge['Solution_topic'].count()\n",
    "df_topics = []\n",
    "\n",
    "for name, group in df_challenge.groupby('Solution_topic'):\n",
    "    Mean_score = group['Solution_score'].mean()\n",
    "    Mean_link_count = group['Solution_link_count'].mean()\n",
    "    Mean_information_entropy = group['Solution_information_entropy'].mean()\n",
    "    Mean_readability = group['Solution_readability'].mean()\n",
    "    Mean_sentence_count = group['Solution_sentence_count'].mean()\n",
    "    Mean_word_count = group['Solution_word_count'].mean()\n",
    "    Mean_unique_word_count = group['Solution_unique_word_count'].mean()\n",
    "    Mean_comment_count = group['Solution_comment_count'].mean()\n",
    "    Count_ratio = group['Solution_topic'].count() / total_count * 100\n",
    "    topic_info = {\n",
    "        'Solution_topic': name,\n",
    "        'Mean_score': Mean_score,\n",
    "        'Mean_link_count': Mean_link_count,\n",
    "        'Mean_information_entropy': Mean_information_entropy,\n",
    "        'Mean_readability': Mean_readability,\n",
    "        'Mean_sentence_count': Mean_sentence_count,\n",
    "        'Mean_word_count': Mean_word_count,\n",
    "        'Mean_unique_word_count': Mean_unique_word_count,\n",
    "        'Mean_comment_count': Mean_comment_count,\n",
    "        'Count_ratio': Count_ratio,\n",
    "    }\n",
    "    df_topics.append(topic_info)\n",
    "\n",
    "df_topics = pd.DataFrame(df_topics)\n",
    "df_topics.to_json(os.path.join(path_solution_information,\n",
    "                  'general.json'), indent=4, orient='records')\n",
    "df_topics = df_topics.set_index('Solution_topic')\n",
    "\n",
    "fig = df_topics.sort_values('Mean_score', ascending=False)['Mean_score'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Solution mean score', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_solution_information, 'Mean_score.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_link_count', ascending=False)['Mean_link_count'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Solution mean link count', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_solution_information, 'Mean_link_count.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_information_entropy', ascending=False)['Mean_information_entropy'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Solution mean info entropy', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_solution_information, 'Mean_information_entropy.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_readability', ascending=False)['Mean_readability'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Solution mean readability', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_solution_information, 'Mean_readability.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_sentence_count', ascending=False)['Mean_sentence_count'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Solution mean sentence count', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_solution_information, 'Mean_sentence_count.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_word_count', ascending=False)['Mean_word_count'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Solution mean word count', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_solution_information, 'Mean_word_count.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_unique_word_count', ascending=False)['Mean_unique_word_count'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Solution mean unique word count', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_solution_information, 'Mean_unique_word_count.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Mean_comment_count', ascending=False)['Mean_comment_count'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Solution mean comment count', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_solution_information, 'Mean_comment_count.png'))\n",
    "plt.close()\n",
    "\n",
    "fig = df_topics.sort_values('Count_ratio', ascending=False)['Count_ratio'].plot(\n",
    "    kind='bar', figsize=(15, 8), title='Solution count ratio', rot=15).get_figure()\n",
    "fig.savefig(os.path.join(path_solution_information, 'Count_ratio.png'))\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.interpolate\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess as sm_lowess\n",
    "\n",
    "\n",
    "def smooth(x, y, xgrid, lowess_kw=None):\n",
    "    samples = np.random.choice(len(x), 50, replace=True)\n",
    "    y_s = y[samples]\n",
    "    x_s = x[samples]\n",
    "    y_sm = sm_lowess(y_s, x_s, **lowess_kw)\n",
    "    # regularly sample it onto the grid\n",
    "    y_grid = scipy.interpolate.interp1d(\n",
    "        x_s, y_sm, fill_value='extrapolate')(xgrid)\n",
    "    return y_grid\n",
    "\n",
    "\n",
    "def lowess_with_confidence_bounds(x, y, conf_interval=0.95, lowess_kw=None):\n",
    "    \"\"\"\n",
    "    Perform Lowess regression and determine a confidence interval by bootstrap resampling\n",
    "    \"\"\"\n",
    "    xgrid = np.linspace(x.min(), x.max())\n",
    "\n",
    "    K = 100\n",
    "    smooths = np.stack([smooth(x, y, xgrid, lowess_kw) for _ in range(K)]).T\n",
    "\n",
    "    mean = np.nanmean(smooths, axis=1)\n",
    "    stderr = scipy.stats.sem(smooths, axis=1)\n",
    "\n",
    "    clower = np.nanpercentile(smooths, (1-conf_interval)*50, axis=1)\n",
    "    cupper = np.nanpercentile(smooths, (1+conf_interval)*50, axis=1)\n",
    "\n",
    "    return xgrid, mean, stderr, clower, cupper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2014-08-08 14:04:22.160000'),\n",
       " Timestamp('2023-02-22 01:36:03.995000'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.read_json(os.path.join(path_general, 'Topics.json'))\n",
    "df_challenge = df_all[df_all['Challenge_topic'] > -1]\n",
    "# BigQuery Stack Overflow public dataset is updated until Nov 24, 2022, 1:39:22 PM UTC-5\n",
    "min(df_challenge['Challenge_creation_time']), max(df_challenge['Challenge_creation_time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore challenge topics evolution\n",
    "\n",
    "df_challenge = pd.read_json(os.path.join(path_general, 'Topics.json'))\n",
    "df_challenge = df_challenge[df_challenge['Challenge_topic'] > -1]\n",
    "df_challenge = df_challenge[(df_challenge['Challenge_creation_time'] > '2014-09-14')\n",
    "                            & (df_challenge['Challenge_creation_time'] < '2022-11-21')]\n",
    "\n",
    "for name, group in df_challenge.groupby('Challenge_topic'):\n",
    "    group = group.groupby(pd.Grouper(key='Challenge_creation_time', freq='2W')).agg(\n",
    "        Count=('Challenge_topic', 'count')).reset_index()\n",
    "    x = pd.to_datetime(group['Challenge_creation_time']).values\n",
    "    x = np.array([i.astype('datetime64[D]').astype(int) for i in x])\n",
    "    y = group['Count'].values\n",
    "    # 95% confidence interval\n",
    "    xgrid, mean, stderr, clower, cupper = lowess_with_confidence_bounds(\n",
    "        x, y, conf_interval=0.95, lowess_kw={\"frac\": 0.5, \"it\": 5, \"return_sorted\": False})\n",
    "    x = pd.to_datetime(group['Challenge_creation_time']).values\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    plt.plot(x, y, 'k.', label='Observations')\n",
    "    plt.plot(xgrid, mean, color='tomato', label='LOWESS')\n",
    "    plt.fill_between(xgrid, clower, cupper, alpha=0.3,\n",
    "                     label='LOWESS uncertainty')\n",
    "    plt.legend(loc='best')\n",
    "    fig.savefig(os.path.join(path_challenge_evolution,\n",
    "                f'Topic_{name}'), bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2014-09-14 22:12:24.493000'),\n",
       " Timestamp('2023-02-21 18:36:06.284000'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.read_json(os.path.join(path_general, 'Topics.json'))\n",
    "df_solution = df_all[df_all['Solution_topic'] > -1]\n",
    "# BigQuery Stack Overflow public dataset is updated until Nov 24, 2022, 1:39:22 PM UTC-5\n",
    "min(df_solution['Challenge_creation_time']), max(\n",
    "    df_solution['Challenge_creation_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore solution topics evolution\n",
    "\n",
    "df_solution = pd.read_json(os.path.join(path_general, 'Topics.json'))\n",
    "df_solution = df_solution[df_solution['Solution_topic'] > -1]\n",
    "df_solution = df_solution[(df_solution['Challenge_creation_time'] > '2014-09-14')\n",
    "                          & (df_solution['Challenge_creation_time'] < '2022-11-21')]\n",
    "\n",
    "for name, group in df_solution.groupby('Solution_topic'):\n",
    "    group = group.groupby(pd.Grouper(key='Challenge_closed_time', freq='W')).agg(\n",
    "        Count=('Solution_topic', 'count')).reset_index()\n",
    "    x = pd.to_datetime(group['Challenge_closed_time']).values\n",
    "    x = np.array([i.astype('datetime64[D]').astype(int) for i in x])\n",
    "    y = group['Count'].values\n",
    "    # 95% confidence interval\n",
    "    xgrid, mean, stderr, clower, cupper = lowess_with_confidence_bounds(\n",
    "        x, y, conf_interval=0.95, lowess_kw={\"frac\": 0.5, \"it\": 5, \"return_sorted\": False})\n",
    "    x = pd.to_datetime(group['Challenge_closed_time']).values\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    plt.plot(x, y, 'k.', label='Observations')\n",
    "    plt.plot(xgrid, mean, color='tomato', label='LOWESS')\n",
    "    plt.fill_between(xgrid, clower, cupper, alpha=0.3,\n",
    "                     label='LOWESS uncertainty')\n",
    "    plt.legend(loc='best')\n",
    "    fig.savefig(os.path.join(path_solution_evolution,\n",
    "                f'Topic_{name}'), bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
