{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shap\n",
    "import time\n",
    "import pickle\n",
    "import openai\n",
    "import textstat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import missingno as msno\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from plotly.colors import n_colors\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder, RobustScaler\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "from scipy.stats import kruskal, shapiro, spearmanr, kendalltau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The significance level indicates the probability of rejecting the null hypothesis when it is true.\n",
    "alpha = 0.05\n",
    "\n",
    "link_pattern = r'https?://[^\\s]+'\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None, 'display.max_colwidth', None)\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY', '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')\n",
    "\n",
    "keywords_patch = {\n",
    "    'pull',\n",
    "}\n",
    "\n",
    "keywords_issue = {\n",
    "    'answers',\n",
    "    'discussions',\n",
    "    'forums',\n",
    "    'issues',\n",
    "    'questions',\n",
    "    'stackoverflow',\n",
    "}\n",
    "\n",
    "keywords_tool = {\n",
    "    'github',\n",
    "    'gitlab',\n",
    "    'pypi',\n",
    "}\n",
    "\n",
    "keywords_doc = {\n",
    "    'developers',\n",
    "    'docs',\n",
    "    'documentation',\n",
    "    'features',\n",
    "    'library',\n",
    "    'org',\n",
    "    'wiki',\n",
    "}\n",
    "\n",
    "keywords_tutorial = {\n",
    "    'guide',\n",
    "    'learn',\n",
    "    'tutorial',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_result = '../../Result'\n",
    "\n",
    "path_result_rq1 = os.path.join(path_result, 'RQ1')\n",
    "path_result_rq2 = os.path.join(path_result, 'RQ2')\n",
    "path_code_rq2 = os.path.join('..', 'RQ2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add different metrics to each post\n",
    "\n",
    "df = pd.read_json(os.path.join(path_result_rq1, 'filtered.json'))\n",
    "\n",
    "df['Solution_word_count'] = np.nan\n",
    "df['Solution_sentence_count'] = np.nan\n",
    "df['Solution_readability'] = np.nan\n",
    "df['Solution_reading_time'] = np.nan\n",
    "df['Solution_link_count'] = np.nan\n",
    "\n",
    "df['Challenge_solved_time'] = np.nan\n",
    "df['Challenge_adjusted_solved_time'] = np.nan\n",
    "\n",
    "df['Solution_link_docs'] = np.nan\n",
    "df['Solution_link_issues'] = np.nan\n",
    "df['Solution_link_patches'] = np.nan\n",
    "df['Solution_link_tools'] = np.nan\n",
    "df['Solution_link_tutorials'] = np.nan\n",
    "df['Solution_link_examples'] = np.nan\n",
    "\n",
    "df['Challenge_created_time'] = pd.to_datetime(df['Challenge_created_time'])\n",
    "df['Challenge_closed_time'] = pd.to_datetime(df['Challenge_closed_time'])\n",
    "df['Challenge_last_edit_time'] = pd.to_datetime(df['Challenge_last_edit_time'])\n",
    "df['Solution_last_edit_time'] = pd.to_datetime(df['Solution_last_edit_time'])\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    challenge_content = row['Challenge_title'] + '.' + str(row['Challenge_body'])\n",
    "    df.at[index, 'Challenge_word_count'] = textstat.lexicon_count(challenge_content)\n",
    "    df.at[index, 'Challenge_sentence_count'] = textstat.sentence_count(challenge_content)\n",
    "    df.at[index, 'Challenge_readability'] = textstat.flesch_kincaid_grade(challenge_content)\n",
    "    df.at[index, 'Challenge_reading_time'] = textstat.reading_time(challenge_content)\n",
    "    \n",
    "    links = list(set(re.findall(link_pattern, challenge_content)))\n",
    "    df.at[index, 'Challenge_link_count'] = len(links)\n",
    "\n",
    "    solution_content = row['Solution_body']\n",
    "\n",
    "    if pd.notna(solution_content):\n",
    "        df.at[index, 'Solution_word_count'] = textstat.lexicon_count(solution_content)\n",
    "        df.at[index, 'Solution_sentence_count'] = textstat.sentence_count(solution_content)\n",
    "        df.at[index, 'Solution_readability'] = textstat.flesch_kincaid_grade(solution_content)\n",
    "        df.at[index, 'Solution_reading_time'] = textstat.reading_time(solution_content)\n",
    "        \n",
    "        links = list(set(re.findall(link_pattern, solution_content)))\n",
    "        df.at[index, 'Solution_link_count'] = len(links)\n",
    "        \n",
    "        link_docs = 0\n",
    "        link_tools = 0\n",
    "        link_issues = 0\n",
    "        link_patches = 0\n",
    "        link_tutorials = 0\n",
    "        link_examples = 0\n",
    "    \n",
    "        for link in links:\n",
    "            if any([patch in link for patch in keywords_patch]):\n",
    "                link_patches += 1\n",
    "            elif any([issue in link for issue in keywords_issue]):\n",
    "                link_issues += 1\n",
    "            elif any([tool in link for tool in keywords_tool]):\n",
    "                link_tools += 1\n",
    "            elif any([doc in link for doc in keywords_doc]):\n",
    "                link_docs += 1\n",
    "            elif any([tool in link for tool in keywords_tutorial]):\n",
    "                link_tutorials += 1\n",
    "            else:\n",
    "                link_examples += 1\n",
    "                \n",
    "        df.at[index, 'Solution_link_docs'] = link_docs\n",
    "        df.at[index, 'Solution_link_issues'] = link_issues\n",
    "        df.at[index, 'Solution_link_patches'] = link_patches\n",
    "        df.at[index, 'Solution_link_tools'] = link_tools\n",
    "        df.at[index, 'Solution_link_tutorials'] = link_tutorials\n",
    "        df.at[index, 'Solution_link_examples'] = link_examples\n",
    "        \n",
    "    creation_time = row['Challenge_created_time']\n",
    "    closed_time = row['Challenge_closed_time']\n",
    "    if pd.notna(creation_time) and pd.notna(closed_time) and (closed_time > creation_time):\n",
    "        df.at[index, 'Challenge_solved_time'] = (closed_time - creation_time) / pd.Timedelta(hours=1)\n",
    "\n",
    "    creation_time = row['Challenge_last_edit_time'] if pd.notna(row['Challenge_last_edit_time']) else creation_time\n",
    "    closed_time = row['Solution_last_edit_time'] if pd.notna(row['Solution_last_edit_time']) else closed_time\n",
    "    if pd.notna(creation_time) and pd.notna(closed_time) and (closed_time > creation_time):\n",
    "        df.at[index, 'Challenge_adjusted_solved_time'] = (closed_time - creation_time) / pd.Timedelta(hours=1)\n",
    "    else:\n",
    "        df.at[index, 'Challenge_adjusted_solved_time'] = df.at[index, 'Challenge_solved_time']\n",
    "\n",
    "df['Challenge_comment_count'] = df['Challenge_comment_count'].fillna(0)\n",
    "df['Challenge_answer_count'] = df['Challenge_answer_count'].fillna(0)\n",
    "df['Challenge_participation_count'] = df['Challenge_answer_count'] + df['Challenge_comment_count']\n",
    "\n",
    "df = df.reindex(sorted(df.columns), axis=1)\n",
    "df.to_json(os.path.join(path_result_rq2, 'metrics.json'), indent=4, orient='records')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
