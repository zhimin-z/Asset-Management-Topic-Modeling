{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import openai\n",
    "import textstat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from gensim.parsing.preprocessing import remove_stopwords, stem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The significance level indicates the probability of rejecting the null hypothesis when it is true.\n",
    "alpha = 0.05\n",
    "\n",
    "link_pattern = r'https?://[^\\s]+'\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None, 'display.max_colwidth', None)\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY', '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')\n",
    "\n",
    "keywords_patch = {\n",
    "    'pull',\n",
    "}\n",
    "\n",
    "keywords_issue = {\n",
    "    'answers',\n",
    "    'discussions',\n",
    "    'forums',\n",
    "    'issues',\n",
    "    'questions',\n",
    "    'stackoverflow',\n",
    "}\n",
    "\n",
    "keywords_tool = {\n",
    "    'github',\n",
    "    'gitlab',\n",
    "    'pypi',\n",
    "}\n",
    "\n",
    "keywords_doc = {\n",
    "    'developers',\n",
    "    'docs',\n",
    "    'documentation',\n",
    "    'features',\n",
    "    'library',\n",
    "    'org',\n",
    "    'wiki',\n",
    "}\n",
    "\n",
    "keywords_tutorial = {\n",
    "    'guide',\n",
    "    'learn',\n",
    "    'tutorial',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_result = '../../Result'\n",
    "\n",
    "path_result_rq1 = os.path.join(path_result, 'RQ1')\n",
    "path_code_rq1 = os.path.join('..', 'RQ1')\n",
    "\n",
    "path_general_output = os.path.join(path_result_rq1, 'General Topics')\n",
    "path_special_output = os.path.join(path_result_rq1, 'Special Topics')\n",
    "\n",
    "path_general_topic = os.path.join(path_code_rq1, 'General Topic Modeling')\n",
    "path_special_topic = os.path.join(path_code_rq1, 'Special Topic Modeling')\n",
    "\n",
    "path_anomaly = os.path.join(path_special_topic, 'Anomaly')\n",
    "path_root_cause = os.path.join(path_special_topic, 'Root Cause')\n",
    "path_solution = os.path.join(path_special_topic, 'Solution')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_weighted_sum(df, sort_column):\n",
    "    df_new = df.sort_values(sort_column, ascending=False)\n",
    "    n = len(df)\n",
    "    center_idx = (n - 1) // 2\n",
    "    direction = -1\n",
    "    distance = 0\n",
    "\n",
    "    for _, row in df_new.iterrows():\n",
    "        # Calculate the new index\n",
    "        new_idx = center_idx + direction * distance\n",
    "        \n",
    "        # Place the element from the sorted list into the new list\n",
    "        df.iloc[new_idx] = row\n",
    "\n",
    "        # If we've just moved to the left, increase the distance\n",
    "        if direction == -1:\n",
    "            distance += 1\n",
    "\n",
    "        # Switch the direction\n",
    "        direction *= -1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: Model Management - Handling and manipulation of models including training, saving, importing, and exporting.\n",
      "Topic 1: Data Pipelining - The process of managing and processing data through multiple pipelines.\n",
      "Topic 2: Package Installation - The process of installing, importing, and managing software packages using pip.\n",
      "Topic 3: Logging - The process of creating, tracking, and managing logs during model training.\n",
      "Topic 4: Docker Operations - Building, running, and managing Docker images and files.\n",
      "Topic 5: Access Management - Managing access permissions, roles, and tokens for secure operations.\n",
      "Topic 6: Data Labeling - The process of labeling data for training and object recognition.\n",
      "Topic 7: Git Operations - Managing data, files, and version control using Git.\n",
      "Topic 8: Bucket Operations - Managing files, data, and paths in storage buckets.\n",
      "Topic 9: Sweep Operations - Configuring, running, and managing multiple sweeps.\n",
      "Topic 10: Quota Management - Managing request quotas and handling limit exceptions.\n",
      "Topic 11: Remote Operations - Configuring, running, and connecting to remote files and executions.\n",
      "Topic 12: Batch Processing - Managing and processing data, files, and jobs in batches.\n",
      "Topic 13: Lambda Functions - Invoking and processing data using Lambda functions.\n",
      "Topic 14: Database Operations - Connecting, importing, and running operations on databases.\n",
      "Topic 15: Language Translation - Translating documents and languages using models.\n",
      "Topic 16: Panda Operations - Managing and converting files using Panda.\n",
      "Topic 17: Speech Processing - Handling audio files, generating speech, and transcribing services.\n",
      "Topic 18: Spark Operations - Configuring, implementing, and managing data using Spark.\n",
      "Topic 19: Instance Management - Creating, managing, and removing instances.\n",
      "Topic 20: Column Operations - Managing, cleaning, and visualizing data in columns.\n"
     ]
    }
   ],
   "source": [
    "prompt_topic = '''You will be given a list of stemmed words refering to specific software engineering topics. Please summarize each topic in terms and attach a one-liner description based on the stemmed words. Also, you must guarantee that the summaries are exclusive to one another.###\\n'''\n",
    "\n",
    "with open(os.path.join(path_general_topic, 'Topic terms.pickle'), 'rb') as handle:\n",
    "    topic_terms = pickle.load(handle)\n",
    "\n",
    "    topic_term_list = []\n",
    "    for index, topic in enumerate(topic_terms):\n",
    "        terms = ', '.join([term[0] for term in topic])\n",
    "        topic_term = f'Topic {index}: {terms}]'\n",
    "        topic_term_list.append(topic_term)\n",
    "\n",
    "    prompt = prompt_topic + '\\n'.join(topic_term_list) + '\\n###\\n'\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "        temperature=0,\n",
    "        max_tokens=3000,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        timeout=300,\n",
    "        stream=False)\n",
    "\n",
    "    topics = completion.choices[0].message.content\n",
    "    print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topics = '''Topic 0: Model Management - Handling and manipulation of models including training, saving, importing, and exporting.\n",
    "# Topic 1: Pipeline Configuration - The process of managing and processing data through multiple pipelines.\n",
    "# Topic 2: Package Management - The process of installing, importing, and managing software packages using pip.\n",
    "# Topic 3: Log Management - The process of creating, tracking, and managing logs during model training.\n",
    "# Topic 4: Docker Configuration - Building, running, and managing Docker images and files.\n",
    "# Topic 5: Access Control - Managing access permissions, roles, and tokens for secure operations.\n",
    "# Topic 6: Label Management - The process of creating, adding, and modifying labels for raw data.\n",
    "# Topic 7: Git Configuration - Managing data, files, and version control using Git.\n",
    "# Topic 8: Bucket Management - Managing files, data, and paths in storage buckets.\n",
    "# Topic 9: Sweep Management - Configuring, running, and managing multiple sweeps.\n",
    "# Topic 10: Quota Management - Managing request quotas and handling limit exceptions.\n",
    "# Topic 11: Remote Configuration - Configuring, running, and connecting to remote files and executions.\n",
    "# Topic 12: Batch Processing - Managing and processing data, files, and jobs in batches.\n",
    "# Topic 13: Lambda Configuration - Invoking and processing data using Lambda functions.\n",
    "# Topic 14: Database Management - Connecting, importing, and running operations on databases.\n",
    "# Topic 15: Language Translation - Translating documents and languages using models.\n",
    "# Topic 16: Tabular Data Manipulation - Managing and converting files using Pandas.\n",
    "# Topic 17: Speech Processing - Handling audio files, generating speech, and transcribing services.\n",
    "# Topic 18: Spark Configuration - Configuring, implementing, and managing data using Spark.\n",
    "# Topic 19: Instance Management - Creating, managing, and removing instances.\n",
    "# Topic 20: Columnar Data Manipulation - Managing, cleaning, and visualizing data in columns.'''\n",
    "\n",
    "# index = 0\n",
    "# topic_dict = {-1: 'NA'}\n",
    "\n",
    "# for topic in topics.split('\\n'):\n",
    "#     topic_dict[index] = topic.split('-')[0].split(':')[-1].strip()\n",
    "#     index += 1\n",
    "    \n",
    "# topic_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pip instal, instal pip, instal packag, packag instal, pip environ, packag pip, import instal, pip packag, instal import, import packagdocker imag, build docker, docker build, docker file, imag docker, run docker, file docker, docker run, built docker, docker dockerinvok lambda, data lambda, lambda process, function lambda, lambda function, job lambda, lambda lambda, model lambda, infer lambda, lambdainstanc creat, creat instanc, type instanc, instanc instanc, instanc type, regular instanc, model instanc, instanc modul, stop instanc, instanc remov'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with open(os.path.join(path_general_topic, 'Topic terms.pickle'), 'rb') as handle:\n",
    "#     topic_terms = pickle.load(handle)\n",
    "\n",
    "#     terms = ''\n",
    "#     for index, topic in enumerate(topic_terms):\n",
    "#         if index in [2, 4, 19, 13]:\n",
    "#             terms += ', '.join([term[0] for term in topic])\n",
    "# terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# macro_topic_mapping_inverse = {\n",
    "#     # These topics are all related to the management of permissions and connectivity.\n",
    "#     1: ('Access Management', ['Access Control', 'Remote Configuration']),\n",
    "#     # These topics are all related to the management of source code.\n",
    "#     8: ('Code Management', ['Git Configuration']),\n",
    "#     # These topics are all related to the management of data and datasets.\n",
    "#     2: ('Compute Management', ['Batch Processing', 'Spark Configuration', 'Sweep Management']),\n",
    "#     # These topics are all related to the management of services.\n",
    "#     3: ('Data Management', ['Bucket Management', 'Columnar Data Manipulation', 'Database Management', 'Label Management', 'Tabular Data Manipulation']),\n",
    "#     # These topics are all related to the management of packages and distributions.\n",
    "#     4: ('Environment Management', ['Package Management', 'Docker Configuration', 'Instance Management', 'Lambda Configuration']),\n",
    "#     # These topics are all related to the management of pipelines.\n",
    "#     7: ('Lifecycle Management', ['Pipeline Configuration']),\n",
    "#     # These topics are all related to the management of machine learning models.\n",
    "#     5: ('Model Management', ['Model Management']),\n",
    "#     # These topics are all related to the management of logs and metrics.\n",
    "#     6: ('Performance Management', ['Log Management', 'Quota Management']),\n",
    "# }\n",
    "\n",
    "macro_topic_mapping_inverse = {\n",
    "    # These topics are all related to the management of permissions and connectivity.\n",
    "    1: ('Access Management', [5, 11]),\n",
    "    # These topics are all related to the management of source code.\n",
    "    8: ('Code Management', [7]),\n",
    "    # These topics are all related to the management of data and datasets.\n",
    "    2: ('Compute Management', [9, 12, 18]),\n",
    "    # These topics are all related to the management of services.\n",
    "    3: ('Data Management', [6, 8, 14, 16, 20]),\n",
    "    # These topics are all related to the management of packages and distributions.\n",
    "    4: ('Environment Management', [2, 4, 13, 19]),\n",
    "    # These topics are all related to the management of pipelines.\n",
    "    7: ('Lifecycle Management', [1]),\n",
    "    # These topics are all related to the management of machine learning models.\n",
    "    5: ('Model Management', [0]),\n",
    "    # These topics are all related to the management of logs and metrics.\n",
    "    6: ('Performance Management', [3, 10]),\n",
    "}\n",
    "\n",
    "\n",
    "macro_topic_mapping = {}\n",
    "macro_topic_index_mapping = {}\n",
    "for key, (macro_topic, topics) in macro_topic_mapping_inverse.items():\n",
    "    macro_topic_index_mapping[macro_topic] = key\n",
    "    for topic in topics:\n",
    "        macro_topic_mapping[topic] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Number</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Access Management</td>\n",
       "      <td>872</td>\n",
       "      <td>7.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Compute Management</td>\n",
       "      <td>1106</td>\n",
       "      <td>9.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Management</td>\n",
       "      <td>1460</td>\n",
       "      <td>13.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Environment Management</td>\n",
       "      <td>2730</td>\n",
       "      <td>24.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Model Management</td>\n",
       "      <td>2378</td>\n",
       "      <td>21.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Performance Management</td>\n",
       "      <td>1122</td>\n",
       "      <td>10.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lifecycle Management</td>\n",
       "      <td>1105</td>\n",
       "      <td>9.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Code Management</td>\n",
       "      <td>344</td>\n",
       "      <td>3.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Topic  Number  Percentage\n",
       "0       Access Management     872        7.84\n",
       "1      Compute Management    1106        9.95\n",
       "2         Data Management    1460       13.13\n",
       "3  Environment Management    2730       24.56\n",
       "4        Model Management    2378       21.39\n",
       "5  Performance Management    1122       10.09\n",
       "6    Lifecycle Management    1105        9.94\n",
       "7         Code Management     344        3.09"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign human-readable & high-level topics to challenges & solutions\n",
    "\n",
    "df = pd.read_json(os.path.join(path_general_output, 'topics.json'))\n",
    "df['Challenge_topic_macro'] = -1\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['Challenge_topic'] in macro_topic_mapping:\n",
    "        df.at[index, 'Challenge_topic_macro'] = macro_topic_mapping[row['Challenge_topic']]\n",
    "    else:\n",
    "        df.drop(index, inplace=True)\n",
    "\n",
    "df.to_json(os.path.join(path_general_output, 'filtered.json'), indent=4, orient='records')\n",
    "\n",
    "df_number = pd.DataFrame()\n",
    "\n",
    "for key, (macro_topic, topics) in macro_topic_mapping_inverse.items():\n",
    "    entry = {\n",
    "        'Topic': macro_topic,\n",
    "        'Number': len(df[df[\"Challenge_topic_macro\"] == key]),\n",
    "        'Percentage': round(len(df[df[\"Challenge_topic_macro\"] == key]) / len(df) * 100, 2),\n",
    "    }\n",
    "    df_number = pd.concat([df_number, pd.DataFrame([entry])], ignore_index=True)\n",
    "\n",
    "minimize_weighted_sum(df_number, 'Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "# df['Challenge_topic_macro'] = -1\n",
    "# for index, row in df.iterrows():\n",
    "#     if topic_dict[row['Challenge_topic']] in macro_topic_mapping:\n",
    "#         df.at[index, 'Challenge_topic_macro'] = macro_topic_mapping[topic_dict[row['Challenge_topic']]]\n",
    "#     else:\n",
    "#         df.drop(index, inplace=True)\n",
    "\n",
    "# df.to_json(os.path.join(path_special_output, 'labels.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(os.path.join(path_general_output, 'filtered.json'))\n",
    "\n",
    "df['Challenge_type'] = 'na'\n",
    "df['Challenge_summary'] = 'na'\n",
    "df['Challenge_root_cause'] = 'na'\n",
    "df['Solution'] = 'na'\n",
    "\n",
    "df.to_json(os.path.join(path_special_output, 'labels.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['Challenge_summary'] != 'na':\n",
    "        text = remove_stopwords(row['Challenge_summary'])\n",
    "        df.at[index, 'Challenge_summary'] = stem_text(text)\n",
    "    if row['Challenge_root_cause'] != 'na':\n",
    "        text = remove_stopwords(row['Challenge_root_cause'])\n",
    "        df.at[index, 'Challenge_root_cause'] = stem_text(text)\n",
    "    if row['Solution'] != 'na':\n",
    "        text = remove_stopwords(row['Solution'])\n",
    "        df.at[index, 'Solution'] = stem_text(text)\n",
    "\n",
    "df.to_json(os.path.join(path_special_output, 'preprocessed.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': 2029,\n",
       " 'missing': 783,\n",
       " 'import': 318,\n",
       " 'file': 234,\n",
       " 'invalid': 232,\n",
       " 'type': 180,\n",
       " 'attribute': 179,\n",
       " 'value': 175,\n",
       " 'model': 162,\n",
       " 'unresponsive': 140,\n",
       " 'exception': 128,\n",
       " 'denied': 127,\n",
       " 'validation': 120,\n",
       " 'access': 116,\n",
       " 'slow': 99,\n",
       " 'wrong': 98,\n",
       " 'connection': 92,\n",
       " 'deployment': 87,\n",
       " 'data': 86,\n",
       " 'timeout': 84,\n",
       " 'forbidden': 83,\n",
       " 'request': 75,\n",
       " 'unsupported': 74,\n",
       " 'run': 69,\n",
       " 'empty': 67,\n",
       " 'exhausted': 64,\n",
       " 'job': 63,\n",
       " 'endpoint': 61,\n",
       " 'configuration': 60,\n",
       " 'training': 59,\n",
       " 'server': 59,\n",
       " 'bad': 55,\n",
       " 'key': 55,\n",
       " 'memory': 52,\n",
       " 'failed': 51,\n",
       " 'permission': 51,\n",
       " 'load': 50,\n",
       " 'pipeline': 48,\n",
       " 'creation': 46,\n",
       " 'output': 46,\n",
       " 'unexpected': 46,\n",
       " 'internal': 46,\n",
       " 'image': 45,\n",
       " 'incomplete': 44,\n",
       " 'broken': 44,\n",
       " 'parameter': 43,\n",
       " 'inaccessible': 43,\n",
       " 'input': 42,\n",
       " 'execution': 41,\n",
       " 'overflow': 41,\n",
       " 'command': 40,\n",
       " 'argument': 39,\n",
       " 'size': 38,\n",
       " 'version': 38,\n",
       " 'kernel': 38,\n",
       " 'dependency': 37,\n",
       " 'install': 37,\n",
       " 'notebook': 36,\n",
       " 'unrecognized': 35,\n",
       " 'dataset': 34,\n",
       " 'path': 34,\n",
       " 'log': 33,\n",
       " 'format': 33,\n",
       " 'incompatible': 32,\n",
       " 'name': 32,\n",
       " 'decode': 32,\n",
       " 'insufficient': 32,\n",
       " 'gpu': 31,\n",
       " 'credential': 31,\n",
       " 'package': 31,\n",
       " 'unauthorized': 31,\n",
       " 'environment': 31,\n",
       " 'inconsistent': 30,\n",
       " 'unknown': 30,\n",
       " 'experiment': 30,\n",
       " 'service': 30,\n",
       " 'directory': 28,\n",
       " 'quota': 27,\n",
       " 'files': 27,\n",
       " 'token': 26,\n",
       " 'mismatched': 26,\n",
       " 'metrics': 25,\n",
       " 'logging': 24,\n",
       " 'function': 23,\n",
       " 'not': 23,\n",
       " 'artifact': 23,\n",
       " 'object': 22,\n",
       " 'installation': 22,\n",
       " 'initialization': 22,\n",
       " 'authentication': 22,\n",
       " 'instance': 21,\n",
       " 'prediction': 21,\n",
       " 'invocation': 20,\n",
       " 'link': 20,\n",
       " 'system': 20,\n",
       " 'persistent': 20,\n",
       " 'upload': 20,\n",
       " 'metric': 19,\n",
       " 'variable': 19,\n",
       " 'update': 19,\n",
       " 'malfunctioning': 19,\n",
       " 'storage': 19,\n",
       " 'login': 18,\n",
       " 'runs': 18,\n",
       " 'unremovable': 18,\n",
       " 'outdated': 17,\n",
       " 'project': 17,\n",
       " 'ignored': 17,\n",
       " 'serialization': 17,\n",
       " 'plot': 17,\n",
       " 'url': 17,\n",
       " 'user': 17,\n",
       " 'compute': 17,\n",
       " 'index': 16,\n",
       " 'restricted': 16,\n",
       " 'inactive': 16,\n",
       " 'different': 16,\n",
       " 'implemented': 16,\n",
       " 'limit': 16,\n",
       " 'check': 15,\n",
       " 'resource': 15,\n",
       " 'blank': 15,\n",
       " 'process': 15,\n",
       " 'feature': 15,\n",
       " 'response': 15,\n",
       " 'docker': 15,\n",
       " 'results': 15,\n",
       " 'operation': 15,\n",
       " 'column': 15,\n",
       " 'download': 15,\n",
       " 'option': 15,\n",
       " 'start': 14,\n",
       " 'invisible': 14,\n",
       " 'launch': 14,\n",
       " 'pull': 14,\n",
       " 'unlogged': 14,\n",
       " 'conflicting': 14,\n",
       " 'ssl': 14,\n",
       " 'set': 14,\n",
       " 'syntax': 13,\n",
       " 'extension': 13,\n",
       " 'compilation': 13,\n",
       " 'library': 13,\n",
       " 'read-only': 13,\n",
       " 'ping': 12,\n",
       " 'unregistered': 12,\n",
       " 'push': 12,\n",
       " 'large': 12,\n",
       " 'session': 12,\n",
       " 'undefined': 12,\n",
       " 'cluster': 12,\n",
       " 'ineffective': 12,\n",
       " 'uri': 12,\n",
       " 'disabled': 12,\n",
       " 'comm': 12,\n",
       " 'label': 12,\n",
       " 'class': 12,\n",
       " 'bucket': 11,\n",
       " 'status': 11,\n",
       " 'deprecated': 11,\n",
       " 'build': 11,\n",
       " 'setup': 11,\n",
       " 'read': 11,\n",
       " 'unavailable': 11,\n",
       " 'table': 11,\n",
       " 'algorithm': 11,\n",
       " 'predictions': 11,\n",
       " 'out': 11,\n",
       " 'unstable': 11,\n",
       " 'inference': 11,\n",
       " 'driver': 10,\n",
       " 'unsuccessful': 10,\n",
       " 'unmatched': 10,\n",
       " 'space': 10,\n",
       " 'module': 10,\n",
       " 'unresolved': 10,\n",
       " 'display': 10,\n",
       " 'result': 10,\n",
       " 'workspace': 10,\n",
       " 'distribution': 10,\n",
       " 'warning': 10,\n",
       " 'parameters': 10,\n",
       " 'nested': 10,\n",
       " 'interface': 10,\n",
       " 'container': 10,\n",
       " 'usage': 10,\n",
       " 'sweep': 10,\n",
       " 'allocation': 10,\n",
       " 'repeated': 10,\n",
       " 'columns': 10,\n",
       " 'timed': 10,\n",
       " 'local': 9,\n",
       " 'refused': 9,\n",
       " 'method': 9,\n",
       " 'http': 9,\n",
       " 'repository': 9,\n",
       " 'artifacts': 9,\n",
       " 'performance': 9,\n",
       " 'schema': 9,\n",
       " 'parsing': 9,\n",
       " 'database': 9,\n",
       " 'button': 9,\n",
       " 'resources': 9,\n",
       " 'parallel': 9,\n",
       " 'role': 9,\n",
       " 'faulty': 8,\n",
       " 'order': 8,\n",
       " 'hyperparameter': 8,\n",
       " 'conflict': 8,\n",
       " 'existing': 8,\n",
       " 'unpickle': 8,\n",
       " 'deserialization': 8,\n",
       " 'changed': 8,\n",
       " 'tracking': 8,\n",
       " 'integration': 8,\n",
       " 'improper': 8,\n",
       " 'step': 8,\n",
       " 'unsaved': 8,\n",
       " 'time': 8,\n",
       " 'gateway': 8,\n",
       " 'inner': 8,\n",
       " 'reset': 8,\n",
       " 'blocked': 7,\n",
       " 'pipe': 7,\n",
       " 'duplicate': 7,\n",
       " 'python': 7,\n",
       " 'exceeded': 7,\n",
       " 'domain': 7,\n",
       " 'page': 7,\n",
       " 'logs': 7,\n",
       " 'flag': 7,\n",
       " 'terminal': 7,\n",
       " 'duplicated': 7,\n",
       " 'multiple': 7,\n",
       " 'mount': 7,\n",
       " 'expired': 7,\n",
       " 'logger': 7,\n",
       " 'experiments': 7,\n",
       " 'change': 7,\n",
       " 'remote': 7,\n",
       " 'transfer': 7,\n",
       " 'deleted': 7,\n",
       " 'limited': 7,\n",
       " 'win': 7,\n",
       " 'history': 7,\n",
       " 'selection': 7,\n",
       " 'rpc': 7,\n",
       " 'values': 7,\n",
       " 'region': 7,\n",
       " 'unconnected': 7,\n",
       " 'unchanged': 7,\n",
       " 'cache': 7,\n",
       " 'unviewable': 7,\n",
       " 'undetected': 7,\n",
       " 'unsynchronized': 7,\n",
       " 'inaccurate': 7,\n",
       " 'unimplemented': 6,\n",
       " 'runtime': 6,\n",
       " 'unopenable': 6,\n",
       " 'single': 6,\n",
       " 'assertion': 6,\n",
       " 'reference': 6,\n",
       " 'stuck': 6,\n",
       " 'difficult': 6,\n",
       " 'synchronization': 6,\n",
       " 'save': 6,\n",
       " 'test': 6,\n",
       " 'loading': 6,\n",
       " 'incorrectly': 6,\n",
       " 'datastore': 6,\n",
       " 'requirement': 6,\n",
       " 'corrupted': 6,\n",
       " 'tag': 6,\n",
       " 'executable': 6,\n",
       " 'immutable': 6,\n",
       " 'requirements': 6,\n",
       " 'crashing': 6,\n",
       " 'api': 6,\n",
       " 'loop': 6,\n",
       " 'parse': 6,\n",
       " 'target': 6,\n",
       " 'labels': 6,\n",
       " 'processing': 6,\n",
       " 'batch': 6,\n",
       " 'shape': 6,\n",
       " 'pending': 6,\n",
       " 'authorization': 6,\n",
       " 'account': 6,\n",
       " 'disappearing': 6,\n",
       " 'provisioning': 6,\n",
       " 'confusing': 6,\n",
       " 'disconnected': 6,\n",
       " 'unbound': 5,\n",
       " 'checkpoint': 5,\n",
       " 'operational': 5,\n",
       " 'progress': 5,\n",
       " 'clone': 5,\n",
       " 'signature': 5,\n",
       " 'transform': 5,\n",
       " 'client': 5,\n",
       " 'code': 5,\n",
       " 'report': 5,\n",
       " 'lock': 5,\n",
       " 'query': 5,\n",
       " 'throttling': 5,\n",
       " 'unidentified': 5,\n",
       " 'automatic': 5,\n",
       " 'redirection': 5,\n",
       " 'uninstalled': 5,\n",
       " 'outputs': 5,\n",
       " 'default': 5,\n",
       " 'list': 5,\n",
       " 'removal': 5,\n",
       " 'field': 5,\n",
       " 'message': 5,\n",
       " 'commands': 5,\n",
       " 'closed': 5,\n",
       " 'content': 5,\n",
       " 'metadata': 5,\n",
       " 'cudnn': 5,\n",
       " 'custom': 5,\n",
       " 'uninstallable': 5,\n",
       " 'export': 5,\n",
       " 'git': 5,\n",
       " 'stopped': 5,\n",
       " 'unhealthy': 5,\n",
       " 'saving': 5,\n",
       " 'channel': 5,\n",
       " 'repetitive': 5,\n",
       " 'random': 5,\n",
       " 'unused': 5,\n",
       " 'labeling': 5,\n",
       " 'plots': 5,\n",
       " 'underutilized': 5,\n",
       " 'separate': 5,\n",
       " 'group': 5,\n",
       " 'untracked': 5,\n",
       " 'track': 5,\n",
       " 'deletion': 5,\n",
       " 'frozen': 5,\n",
       " 'team': 5,\n",
       " 'subscription': 5,\n",
       " 'string': 4,\n",
       " 'preprocessing': 4,\n",
       " 'unnecessary': 4,\n",
       " 'graph': 4,\n",
       " 'recording': 4,\n",
       " 'vulnerable': 4,\n",
       " 'convert': 4,\n",
       " 'support': 4,\n",
       " 'misconfigured': 4,\n",
       " 'stack': 4,\n",
       " 'loader': 4,\n",
       " 'eof': 4,\n",
       " 'script': 4,\n",
       " 'addition': 4,\n",
       " 'panel': 4,\n",
       " 'dashboard': 4,\n",
       " 'skipped': 4,\n",
       " 'entry': 4,\n",
       " 'poor': 4,\n",
       " 'paths': 4,\n",
       " 'stage': 4,\n",
       " 'view': 4,\n",
       " 'cli': 4,\n",
       " 'range': 4,\n",
       " 'problem': 4,\n",
       " 'flavor': 4,\n",
       " 'datasets': 4,\n",
       " 'crashed': 4,\n",
       " 'impossible': 4,\n",
       " 'confusion': 4,\n",
       " 'policy': 4,\n",
       " 'shutdown': 4,\n",
       " 'registration': 4,\n",
       " 'unseen': 4,\n",
       " 'fitted': 4,\n",
       " 'pickling': 4,\n",
       " 'application': 4,\n",
       " 'customer': 4,\n",
       " 'trials': 4,\n",
       " 'serving': 4,\n",
       " 'event': 4,\n",
       " 'terminated': 4,\n",
       " 'behavior': 4,\n",
       " 'handle': 4,\n",
       " 'silent': 4,\n",
       " 'stop': 4,\n",
       " 'unsatisfiable': 4,\n",
       " 'copy': 4,\n",
       " 'cuda': 4,\n",
       " 'score': 4,\n",
       " 'conversion': 4,\n",
       " 'host': 4,\n",
       " 'running': 4,\n",
       " 'malformed': 4,\n",
       " 'scaling': 4,\n",
       " 'repeating': 4,\n",
       " 'hidden': 4,\n",
       " 'text': 4,\n",
       " 'jobs': 4,\n",
       " 'transitioning': 4,\n",
       " 'web': 4,\n",
       " 'encoding': 4,\n",
       " 'unclear': 4,\n",
       " 'collection': 4,\n",
       " 'shared': 4,\n",
       " 'ownership': 4,\n",
       " 'scoring': 4,\n",
       " 'images': 4,\n",
       " 'unexplained': 4,\n",
       " 'flags': 4,\n",
       " 'utilization': 3,\n",
       " 'bar': 3,\n",
       " 'unrendered': 3,\n",
       " 'unrecorded': 3,\n",
       " 'tensor': 3,\n",
       " 'unutilized': 3,\n",
       " 'names': 3,\n",
       " 'uninitialized': 3,\n",
       " 'versions': 3,\n",
       " 'dependent': 3,\n",
       " 'endless': 3,\n",
       " 'overriding': 3,\n",
       " 'automated': 3,\n",
       " 'submission': 3,\n",
       " 'locked': 3,\n",
       " 'required': 3,\n",
       " 'failing': 3,\n",
       " 'unignorable': 3,\n",
       " 'lockfile': 3,\n",
       " 'external': 3,\n",
       " 'duplication': 3,\n",
       " 'reproduce': 3,\n",
       " 'structure': 3,\n",
       " 'overridden': 3,\n",
       " 'store': 3,\n",
       " 'hardcoded': 3,\n",
       " 'unpopulated': 3,\n",
       " 'new': 3,\n",
       " 'misplaced': 3,\n",
       " 'logged': 3,\n",
       " 'models': 3,\n",
       " 'termination': 3,\n",
       " 'documentation': 3,\n",
       " 'capture': 3,\n",
       " 'tool': 3,\n",
       " 'comparison': 3,\n",
       " 'overwriting': 3,\n",
       " 'types': 3,\n",
       " 'overwritten': 3,\n",
       " 'uninstall': 3,\n",
       " 'matrix': 3,\n",
       " 'is-directory': 3,\n",
       " 'trial': 3,\n",
       " 'scheduled': 3,\n",
       " 'main': 3,\n",
       " 'tab': 3,\n",
       " 'queued': 3,\n",
       " 'events': 3,\n",
       " 'unwanted': 3,\n",
       " 'epoch': 3,\n",
       " 'filesystem': 3,\n",
       " 'split': 3,\n",
       " 'simple': 3,\n",
       " 'instances': 3,\n",
       " 'requests': 3,\n",
       " 'trouble': 3,\n",
       " 'manifest': 3,\n",
       " 'studio': 3,\n",
       " 'canceled': 3,\n",
       " 'frustrating': 3,\n",
       " 'restarting': 3,\n",
       " 'null': 3,\n",
       " 'point': 3,\n",
       " 'unready': 3,\n",
       " 'strange': 3,\n",
       " 'line': 3,\n",
       " 'write': 3,\n",
       " 'site': 3,\n",
       " 'unconsumable': 3,\n",
       " 'screen': 3,\n",
       " 'pandas': 3,\n",
       " 'unlisted': 3,\n",
       " 'graphs': 3,\n",
       " 'low': 3,\n",
       " 'machine': 3,\n",
       " 'characters': 3,\n",
       " 'non-retrievable': 3,\n",
       " 'packages': 3,\n",
       " 'tutorial': 3,\n",
       " 'networking': 3,\n",
       " 'keyword': 3,\n",
       " 'catalog': 3,\n",
       " 'evaluation': 3,\n",
       " 'payload': 3,\n",
       " 'chart': 3,\n",
       " 'unpredictable': 3,\n",
       " 'password': 3,\n",
       " 'active': 3,\n",
       " 'lengthy': 3,\n",
       " 'join': 3,\n",
       " 'unlinked': 3,\n",
       " 'callback': 3,\n",
       " 'infinite': 3,\n",
       " 'inefficient': 3,\n",
       " 'indefinite': 3,\n",
       " 'limitation': 3,\n",
       " 'block': 3,\n",
       " 'charges': 3,\n",
       " 'annotation': 3,\n",
       " 'intent': 3,\n",
       " 'misaligned': 3,\n",
       " 'icon': 3,\n",
       " 'transient': 3,\n",
       " 'restart': 3,\n",
       " 'character': 3,\n",
       " 'scalar': 3,\n",
       " 'unaccepted': 2,\n",
       " 'nonfunctional': 2,\n",
       " 'pattern': 2,\n",
       " 'unrecoverable': 2,\n",
       " 'lab': 2,\n",
       " 'standard': 2,\n",
       " 'sample': 2,\n",
       " 'lambda': 2,\n",
       " 'removed': 2,\n",
       " 'older': 2,\n",
       " 'notebooks': 2,\n",
       " 'disk': 2,\n",
       " 'tags': 2,\n",
       " 'weird': 2,\n",
       " 'archive': 2,\n",
       " 'delete': 2,\n",
       " 'unmounted': 2,\n",
       " 'study': 2,\n",
       " 'insecure': 2,\n",
       " 'undesired': 2,\n",
       " 'trainer': 2,\n",
       " 'cluttered': 2,\n",
       " 'private': 2,\n",
       " 'computation': 2,\n",
       " 'high': 2,\n",
       " 'numbers': 2,\n",
       " 'dataframe': 2,\n",
       " 'unexecutable': 2,\n",
       " 'unusable': 2,\n",
       " 'immediate': 2,\n",
       " 'excessive': 2,\n",
       " 'modification': 2,\n",
       " 'reproducible': 2,\n",
       " 'helpful': 2,\n",
       " 'stages': 2,\n",
       " 'clear': 2,\n",
       " 'tests': 2,\n",
       " 'source': 2,\n",
       " 'annoying': 2,\n",
       " 'permanent': 2,\n",
       " 'detected': 2,\n",
       " 'checksum': 2,\n",
       " 'success': 2,\n",
       " 'redundant': 2,\n",
       " 'breaking': 2,\n",
       " 'entrypoint': 2,\n",
       " 'nodes': 2,\n",
       " 'profile': 2,\n",
       " 'visible': 2,\n",
       " 'protocol': 2,\n",
       " 'arguments': 2,\n",
       " 'integrity': 2,\n",
       " 'misleading': 2,\n",
       " 'copied': 2,\n",
       " 'timestamp': 2,\n",
       " 'constant': 2,\n",
       " 'delayed': 2,\n",
       " 'loss': 2,\n",
       " 'backend': 2,\n",
       " 'exists': 2,\n",
       " 'probability': 2,\n",
       " 'stale': 2,\n",
       " 'misdirected': 2,\n",
       " 'template': 2,\n",
       " 'inappropriate': 2,\n",
       " 'deadline': 2,\n",
       " 'unhandled': 2,\n",
       " 'pipelines': 2,\n",
       " 'ugly': 2,\n",
       " 'escape': 2,\n",
       " 'unstoppable': 2,\n",
       " 'encode': 2,\n",
       " 'entity': 2,\n",
       " 'refresh': 2,\n",
       " 'remove': 2,\n",
       " 'unsatisfied': 2,\n",
       " 'segmentation': 2,\n",
       " 'cyclic': 2,\n",
       " 'unrepsonsive': 2,\n",
       " 'row': 2,\n",
       " 'backoff': 2,\n",
       " 'sparse': 2,\n",
       " 'classification': 2,\n",
       " 'enabled': 2,\n",
       " 'scheme': 2,\n",
       " 'writing': 2,\n",
       " 'property': 2,\n",
       " 'detection': 2,\n",
       " 'freezing': 2,\n",
       " 'profiling': 2,\n",
       " 'mismatch': 2,\n",
       " 'worker': 2,\n",
       " 'action': 2,\n",
       " 'iteration': 2,\n",
       " 'media': 2,\n",
       " 'warnings': 2,\n",
       " 'exit': 2,\n",
       " 'unreproducible': 2,\n",
       " 'suppressed': 2,\n",
       " 'java': 2,\n",
       " 'charts': 2,\n",
       " 'overloaded': 2,\n",
       " 'discrepant': 2,\n",
       " 'fix': 2,\n",
       " 'unassigned': 2,\n",
       " 'restored': 2,\n",
       " 'messed': 2,\n",
       " 'ports': 2,\n",
       " 'waiter': 2,\n",
       " 'recommendation': 2,\n",
       " 'detached': 2,\n",
       " 'stalled': 2,\n",
       " 'cell': 2,\n",
       " 'bloated': 2,\n",
       " 'blob': 2,\n",
       " 'killed': 2,\n",
       " 'kill': 2,\n",
       " 'unspecified': 2,\n",
       " 'train': 2,\n",
       " 'secret': 2,\n",
       " 'same': 2,\n",
       " 'imbalanced': 2,\n",
       " 'audio': 2,\n",
       " 'task': 2,\n",
       " 'passing': 2,\n",
       " 'username': 2,\n",
       " 'pickle': 2,\n",
       " 'variables': 2,\n",
       " 'setting': 2,\n",
       " 'drivers': 2,\n",
       " 'halted': 2,\n",
       " 'browser': 2,\n",
       " 'extract': 2,\n",
       " 'byte': 2,\n",
       " 'tuning': 2,\n",
       " 'purge': 2,\n",
       " 'manager': 2,\n",
       " 'printing': 2,\n",
       " 'datetime': 2,\n",
       " 'displayed': 2,\n",
       " 'rows': 2,\n",
       " 'violation': 2,\n",
       " 'return': 2,\n",
       " 'uncreatable': 2,\n",
       " 'invoke': 2,\n",
       " 'visualization': 2,\n",
       " 'increasing': 2,\n",
       " 'javascript': 2,\n",
       " 'offline': 2,\n",
       " 'truncated': 2,\n",
       " 'unreferenced': 2,\n",
       " 'terrible': 2,\n",
       " 'completed': 2,\n",
       " 'consumption': 2,\n",
       " 'libraries': 2,\n",
       " 'identity': 2,\n",
       " 'binary': 2,\n",
       " 'number': 2,\n",
       " 'untrained': 2,\n",
       " 'testing': 2,\n",
       " 'challenging': 2,\n",
       " 'iterable': 2,\n",
       " 'port': 2,\n",
       " 'ever-starting': 2,\n",
       " 'misinterpreted': 2,\n",
       " 'dying': 2,\n",
       " 'programming': 2,\n",
       " 'sql': 2,\n",
       " 'body': 2,\n",
       " 'bigger': 2,\n",
       " 'normalized': 2,\n",
       " 'boxes': 2,\n",
       " 'datalake': 2,\n",
       " 'upgrade': 2,\n",
       " 'filter': 2,\n",
       " 'alert': 2,\n",
       " 'ip': 2,\n",
       " 'address': 2,\n",
       " 'steps': 2,\n",
       " 'retrieval': 2,\n",
       " 'unreadable': 2,\n",
       " 'stripped': 2,\n",
       " 'precondition': 2,\n",
       " 'search': 2,\n",
       " 'capacity': 2,\n",
       " 'non-scaling': 2,\n",
       " 'specific': 2,\n",
       " 'print': 2,\n",
       " 'certificate': 2,\n",
       " 'state': 2,\n",
       " 'overlapping': 2,\n",
       " 'tracked': 2,\n",
       " 'coordinates': 2,\n",
       " 'admin': 2,\n",
       " 'preview': 2,\n",
       " 'simultaneous': 2,\n",
       " 'provision': 2,\n",
       " 'changes': 2,\n",
       " 'problematic': 2,\n",
       " 'cost': 2,\n",
       " 'finish': 2,\n",
       " 'retry': 2,\n",
       " 'count': 2,\n",
       " 'mask': 2,\n",
       " 'uncreated': 2,\n",
       " 'input/output': 2,\n",
       " 'proxy': 2,\n",
       " 'abnormal': 2,\n",
       " 'program': 2,\n",
       " 'information': 2,\n",
       " 'tabs': 2,\n",
       " 'menu': 2,\n",
       " 'expensive': 2,\n",
       " 'hosting': 2,\n",
       " 'parallelization': 2,\n",
       " 'unterminated': 2,\n",
       " 'premature': 2,\n",
       " 'merge': 2,\n",
       " 'non-starting': 2,\n",
       " 'workers': 2,\n",
       " 'checkout': 2,\n",
       " 'switch': 2,\n",
       " 'specified': 2,\n",
       " 'component': 2,\n",
       " 'asset': 2,\n",
       " 'symbol': 2,\n",
       " 'tasks': 2,\n",
       " 'designer': 2,\n",
       " 'errors': 2,\n",
       " 'refreshing': 2,\n",
       " 'statement': 2,\n",
       " 'resolution': 2,\n",
       " 'schedule': 2,\n",
       " 'delimiter': 2,\n",
       " 'operator': 2,\n",
       " 'peak': 1,\n",
       " 'batched': 1,\n",
       " 'regex': 1,\n",
       " 'updated': 1,\n",
       " 'description': 1,\n",
       " 'supported': 1,\n",
       " 'regions': 1,\n",
       " 'unconnectable': 1,\n",
       " 'linker': 1,\n",
       " 'highlight': 1,\n",
       " 'edited': 1,\n",
       " 'lifecycle': 1,\n",
       " 'compile': 1,\n",
       " 'vpc': 1,\n",
       " 'uninstantiated': 1,\n",
       " 'full': 1,\n",
       " 'backtest': 1,\n",
       " 'self-referencing': 1,\n",
       " 'rule': 1,\n",
       " 'partial': 1,\n",
       " 'credentials': 1,\n",
       " 'diagram': 1,\n",
       " 'spelling': 1,\n",
       " 'idempotent': 1,\n",
       " 'unclaimed': 1,\n",
       " 'frontend': 1,\n",
       " 'hanging': 1,\n",
       " 'idle': 1,\n",
       " 'intermittent': 1,\n",
       " 'benchmark': 1,\n",
       " 'distributed': 1,\n",
       " 'mpi': 1,\n",
       " 'fatal': 1,\n",
       " 'unpack': 1,\n",
       " 'mime': 1,\n",
       " 'persisted': 1,\n",
       " 'disruptive': 1,\n",
       " 'prompts': 1,\n",
       " 'completions': 1,\n",
       " 'frequent': 1,\n",
       " 'disconnection': 1,\n",
       " 'accounts': 1,\n",
       " 'renaming': 1,\n",
       " 'uninstallation': 1,\n",
       " 'activation': 1,\n",
       " 'blocking': 1,\n",
       " 'filtered': 1,\n",
       " 'grouping': 1,\n",
       " 'pagination': 1,\n",
       " 'flask': 1,\n",
       " 'spawn': 1,\n",
       " 'placeholder': 1,\n",
       " 'colliding': 1,\n",
       " 'migration': 1,\n",
       " 'runner': 1,\n",
       " 'links': 1,\n",
       " 'queuing': 1,\n",
       " 'avoidance': 1,\n",
       " 'preemption': 1,\n",
       " 'indentation': 1,\n",
       " 'non-existent': 1,\n",
       " 'typo': 1,\n",
       " 'guide': 1,\n",
       " 'modify': 1,\n",
       " 'dump': 1,\n",
       " 'methods': 1,\n",
       " 'non-ssh': 1,\n",
       " 'reliance': 1,\n",
       " 'non-additive': 1,\n",
       " 'conflict-prone': 1,\n",
       " 'builds': 1,\n",
       " 'updater': 1,\n",
       " 'branch': 1,\n",
       " 'jump': 1,\n",
       " 'unneeded': 1,\n",
       " 'prompt': 1,\n",
       " 'markdown': 1,\n",
       " 'refactor': 1,\n",
       " 'misnamed': 1,\n",
       " 'coverage': 1,\n",
       " 'adapted': 1,\n",
       " 'non-reproducible': 1,\n",
       " 'simplified': 1,\n",
       " 'minimized': 1,\n",
       " 'workload': 1,\n",
       " 'patch': 1,\n",
       " 'fragile': 1,\n",
       " 'telemetry': 1,\n",
       " 'airflow': 1,\n",
       " 'compatibility': 1,\n",
       " 'render': 1,\n",
       " 'fail': 1,\n",
       " 'silently': 1,\n",
       " 'linting': 1,\n",
       " 'release': 1,\n",
       " 'operand': 1,\n",
       " 'restriction': 1,\n",
       " 'fetching': 1,\n",
       " 'maintainer': 1,\n",
       " 'unprocessable': 1,\n",
       " 'relation': 1,\n",
       " 'boot': 1,\n",
       " 'context': 1,\n",
       " 'checkpoints': 1,\n",
       " 'arbitrary': 1,\n",
       " 'created': 1,\n",
       " 'containerization': 1,\n",
       " 'threshold': 1,\n",
       " 'checks': 1,\n",
       " 'unscoped': 1,\n",
       " 'genre': 1,\n",
       " 'added': 1,\n",
       " 'stdout': 1,\n",
       " 'credit-consuming': 1,\n",
       " 'unmarked': 1,\n",
       " 'sweeping': 1,\n",
       " 'overriden': 1,\n",
       " 'dropped': 1,\n",
       " 'manual': 1,\n",
       " 'settings': 1,\n",
       " 'remotely': 1,\n",
       " 'appended': 1,\n",
       " 'found': 1,\n",
       " 'directories': 1,\n",
       " 'improved': 1,\n",
       " 'ls': 1,\n",
       " 'undetermined': 1,\n",
       " 'corrupting': 1,\n",
       " 'stagnant': 1,\n",
       " 'confidential': 1,\n",
       " 'reachable': 1,\n",
       " 'violated': 1,\n",
       " 'cleaned': 1,\n",
       " 'anomaly': 1,\n",
       " 'aggregation': 1,\n",
       " 'location': 1,\n",
       " 'latency': 1,\n",
       " 'installed': 1,\n",
       " 'extensions': 1,\n",
       " 'parser': 1,\n",
       " 'tampered': 1,\n",
       " 'submit': 1,\n",
       " 'handling': 1,\n",
       " 'fault': 1,\n",
       " 'part': 1,\n",
       " 'picker': 1,\n",
       " 'retention': 1,\n",
       " 'sudo': 1,\n",
       " 'unvalidated': 1,\n",
       " 'mixing': 1,\n",
       " 'notorious': 1,\n",
       " 'expanded': 1,\n",
       " 'non-clickable': 1,\n",
       " 'already': 1,\n",
       " 'volume': 1,\n",
       " 'claim': 1,\n",
       " 'packaging': 1,\n",
       " 'unprivileged': 1,\n",
       " 'notification': 1,\n",
       " 'socket': 1,\n",
       " 'prep': 1,\n",
       " 'dead': 1,\n",
       " 'coercion': 1,\n",
       " 'timezone': 1,\n",
       " 'erroneous': 1,\n",
       " 'date': 1,\n",
       " 'deterministic': 1,\n",
       " 'properly': 1,\n",
       " 'built': 1,\n",
       " 'similar': 1,\n",
       " 'speed': 1,\n",
       " 'disable': 1,\n",
       " 'circular': 1,\n",
       " 'layers': 1,\n",
       " 'misbehaving': 1,\n",
       " 'lexer': 1,\n",
       " 'persistence': 1,\n",
       " 'non-sending': 1,\n",
       " 'emulator': 1,\n",
       " 'voila': 1,\n",
       " 'intolerable': 1,\n",
       " 'taint': 1,\n",
       " 'hard': 1,\n",
       " 'linking': 1,\n",
       " 'concurrent': 1,\n",
       " 'communication': 1,\n",
       " 'retrieving': 1,\n",
       " 'parallelism': 1,\n",
       " 'unfirable': 1,\n",
       " 'unworkable': 1,\n",
       " 'functions': 1,\n",
       " 'trace': 1,\n",
       " 'dimension': 1,\n",
       " 'time-consuming': 1,\n",
       " 'abrupt': 1,\n",
       " 'unauthenticated': 1,\n",
       " 'call': 1,\n",
       " 'unsupport': 1,\n",
       " 'replaceable': 1,\n",
       " 'refreshed': 1,\n",
       " 'mising': 1,\n",
       " 'death': 1,\n",
       " 'unbootable': 1,\n",
       " 'downloading': 1,\n",
       " 'negative': 1,\n",
       " 'flawed': 1,\n",
       " 'multiplication': 1,\n",
       " 'separation': 1,\n",
       " 'redirect': 1,\n",
       " 'disconnecting': 1,\n",
       " 'ids': 1,\n",
       " 'generation': 1,\n",
       " 'provisioned': 1,\n",
       " 'datatype': 1,\n",
       " 'interactive': 1,\n",
       " 'non': 1,\n",
       " 'integer': 1,\n",
       " 'unconverged': 1,\n",
       " 'objective': 1,\n",
       " 'hourly': 1,\n",
       " 'pods': 1,\n",
       " 'workaround': 1,\n",
       " 'looped': 1,\n",
       " 'forward': 1,\n",
       " 'launchpad': 1,\n",
       " 'nondescript': 1,\n",
       " 'flooded': 1,\n",
       " 'devices': 1,\n",
       " 'suppression': 1,\n",
       " 'unnamed': 1,\n",
       " 'transformer': 1,\n",
       " 'coerced': 1,\n",
       " 'device': 1,\n",
       " 'small': 1,\n",
       " 'ignoring': 1,\n",
       " 'constraint': 1,\n",
       " 'altered': 1,\n",
       " 'unmountable': 1,\n",
       " 'drive': 1,\n",
       " 'updating': 1,\n",
       " 'red': 1,\n",
       " 'color': 1,\n",
       " 'tenant': 1,\n",
       " 'troublesome': 1,\n",
       " 'inconvertible': 1,\n",
       " 'predict': 1,\n",
       " 'unconfigured': 1,\n",
       " ...}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "\n",
    "labels = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['Challenge_summary'] != 'na':\n",
    "        labels.extend(row['Challenge_summary'].split())\n",
    "\n",
    "label_freq = {}\n",
    "\n",
    "for elem in labels:\n",
    "    if elem in label_freq:\n",
    "        label_freq[elem] += 1\n",
    "    else:\n",
    "        label_freq[elem] = 1\n",
    "\n",
    "for key, value in dict(sorted(label_freq.items(), key=lambda item: item[1], reverse=True)).items():\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# df = pd.read_json(os.path.join(path_general_output, 'filtered.json'))\n",
    "\n",
    "# df['Challenge_type'] = np.nan\n",
    "# df['Challenge_summary'] = np.nan\n",
    "# df['Challenge_root_cause'] = np.nan\n",
    "# df['Solution'] = np.nan\n",
    "\n",
    "# df.to_json(os.path.join(path_special_output, 'labels+.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     if (row['Challenge_root_cause'] != 'na') and (row['Challenge_root_cause'] == row['Challenge_summary']):\n",
    "#         df.at[index, 'Challenge_root_cause'] = 'na'\n",
    "#     if (row['Challenge_root_cause'] != 'na') and (row['Challenge_root_cause'] == row['Solution']):\n",
    "#         print(row['Challenge_root_cause'])\n",
    "        \n",
    "# df.to_json(os.path.join(path_special_output, 'labels.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "\n",
    "# df['Challenge_summary'] = df['Challenge_summary'].str.lower()\n",
    "# df['Challenge_root_cause'] = df['Challenge_root_cause'].str.lower()\n",
    "# df['Solution'] = df['Solution'].str.lower()\n",
    "\n",
    "# df.to_json(os.path.join(path_special_output, 'labels.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "\n",
    "# regex_digit = r\"[0-9]\"\n",
    "\n",
    "# regex_error = r\"[a-zA-Z0-9]+[eE]rror[^a-zA-Z]\"\n",
    "# regex_exception = r\"[a-zA-Z0-9]+[eE]xception[^a-zA-Z]\"\n",
    "\n",
    "# regex_error_leading = r\"[a-zA-Z0-9]+[eE]rror[a-zA-Z]+\"\n",
    "# regex_exception_leading = r\"[a-zA-Z0-9]+[eE]xception[a-zA-Z]+\"\n",
    "\n",
    "# false_positive_list = []\n",
    "\n",
    "# def camel_case_split(str):\n",
    "#     words = [[str[0].lower()]]\n",
    " \n",
    "#     for c in str[1:]:\n",
    "#         if (words[-1][-1].islower() or words[-1][-1].isdigit()) and c.isupper():\n",
    "#             words.append(list(c.lower()))\n",
    "#         else:\n",
    "#             words[-1].append(c)\n",
    "#     return ' '.join([''.join(word) for word in words])\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     challenge = row['Challenge_title'] + ' ' + row['Challenge_body']\n",
    "#     challenge = challenge.replace('\\n', ' ')\n",
    "#     error_list = re.findall(regex_error, challenge)\n",
    "#     if len(error_list):\n",
    "#         if row['Challenge_type'] != 'anomaly':\n",
    "#             df.at[index, 'Challenge_type'] = 'anomaly'\n",
    "#             false_positive_list.append(row['Challenge_link'])\n",
    "#         error = max(error_list, key = len)\n",
    "#         if len(re.findall(regex_digit, error)):\n",
    "#             print(row['Challenge_title'])\n",
    "#         else:\n",
    "#             error = re.sub(r'error.+', 'error', camel_case_split(error))\n",
    "#             df.at[index, 'Challenge_summary'] = error\n",
    "#     else:\n",
    "#         exception_list = re.findall(regex_exception, challenge)\n",
    "#         if len(exception_list):\n",
    "#             if row['Challenge_type'] != 'anomaly':\n",
    "#                 df.at[index, 'Challenge_type'] = 'anomaly'\n",
    "#                 false_positive_list.append(row['Challenge_link'])\n",
    "#             exception = max(exception_list, key = len)\n",
    "#             if len(re.findall(regex_digit, exception)):\n",
    "#                 print(row['Challenge_title'])\n",
    "#             else:\n",
    "#                 exception = re.sub(r'exception.+', 'exception', camel_case_split(exception))\n",
    "#                 df.at[index, 'Challenge_summary'] = exception\n",
    "#         else:\n",
    "#             error_list_leading = re.findall(regex_error_leading, challenge)\n",
    "#             if len(error_list_leading):\n",
    "#                 print(row['Challenge_title'])\n",
    "#             else:\n",
    "#                 exception_list_leading = re.findall(regex_exception_leading, challenge)\n",
    "#                 if len(exception_list_leading):\n",
    "#                     print(row['Challenge_title'])\n",
    "                    \n",
    "# df.to_json(os.path.join(path_special_output, 'anomaly.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "\n",
    "# regex_digit = r\"[0-9]\"\n",
    "\n",
    "# regex_error = r\"[a-zA-Z0-9]+[eE]rror[^a-zA-Z]\"\n",
    "# regex_exception = r\"[a-zA-Z0-9]+[eE]xception[^a-zA-Z]\"\n",
    "\n",
    "# regex_error_leading = r\"[a-zA-Z0-9]+[eE]rror[a-zA-Z]+\"\n",
    "# regex_exception_leading = r\"[a-zA-Z0-9]+[eE]xception[a-zA-Z]+\"\n",
    "\n",
    "# def camel_case_split(str):\n",
    "#     words = [[str[0].lower()]]\n",
    " \n",
    "#     for c in str[1:]:\n",
    "#         if (words[-1][-1].islower() or words[-1][-1].isdigit()) and c.isupper():\n",
    "#             words.append(list(c.lower()))\n",
    "#         else:\n",
    "#             words[-1].append(c)\n",
    "#     return ' '.join([''.join(word) for word in words])\n",
    "\n",
    "# titles = []\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     if row['Challenge_title'] in titles:\n",
    "#         continue\n",
    "#     challenge = row['Challenge_title'] + ' ' + row['Challenge_body']\n",
    "#     challenge = challenge.replace('\\n', ' ').lower()\n",
    "#     if (' 403 ' in challenge) or ('[403]' in challenge) or ('(403)' in challenge) or (' 403,' in challenge) or ('forbidden' in challenge):\n",
    "#         pass\n",
    "#         # print(row['Challenge_title'])\n",
    "#         # df.at[index, 'Challenge_type'] = 'anomaly'\n",
    "#         # df.at[index, 'Challenge_summary'] = 'forbidden error'\n",
    "#     elif (' 404 ' in challenge) or ('[404]' in challenge) or ('(404)' in challenge) or (' 404,' in challenge) or ('not found' in challenge):\n",
    "#         print(row['Challenge_title'])\n",
    "        \n",
    "# # df.to_json(os.path.join(path_special_output, 'labels.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "\n",
    "# for i,r in df.iterrows():\n",
    "#     if r['Challenge_type'] == 'inquiry':\n",
    "#         df.at[i, 'Challenge_summary'] = 'na'\n",
    "#         df.at[i, 'Challenge_root_cause'] = 'na'\n",
    "\n",
    "# df.to_json(os.path.join(path_special_output, 'labels.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new = pd.read_json(os.path.join(path_special_output, 'labels+.json'))\n",
    "# df_old = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "\n",
    "# df = pd.concat([df_new, df_old], ignore_index=True)\n",
    "# df = df.drop_duplicates(['Challenge_link'], keep=False)\n",
    "\n",
    "# df = df[df['Challenge_type'].isna()]\n",
    "# df.to_json(os.path.join(path_special_output, 'extra.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new = pd.read_json(os.path.join(path_special_output, 'labels++.json'))\n",
    "# df_old = pd.read_json(os.path.join(path_special_output, 'extra.json'))\n",
    "\n",
    "# df = pd.concat([df_old, df_new], ignore_index=True)\n",
    "# df = df.drop_duplicates(['Challenge_link'])\n",
    "\n",
    "# df.to_json(os.path.join(path_special_output, 'extra+.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new = pd.read_json(os.path.join(path_special_output, 'labels+.json'))\n",
    "# df = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "\n",
    "# for index, row in df_new.iterrows():\n",
    "#     for i2,r2 in df.iterrows():\n",
    "#         if r2['Challenge_type'] == 'na':\n",
    "#             continue\n",
    "#         if r2['Challenge_link'] == row['Challenge_link']:\n",
    "#             df_new.at[index, 'Challenge_type'] = r2['Challenge_type']\n",
    "#             df_new.at[index, 'Challenge_summary'] = r2['Challenge_summary']\n",
    "#             df_new.at[index, 'Challenge_root_cause'] = r2['Challenge_root_cause']\n",
    "#             df_new.at[index, 'Solution'] = r2['Solution']\n",
    "#             break\n",
    "            \n",
    "# df_new.to_json(os.path.join(path_special_output, 'labels++.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: Import/Export Errors - Issues related to importing or exporting data or modules in a software application.\n",
      "Topic 1: Attribute Errors - Problems associated with the use or introduction of attributes in a program.\n",
      "Topic 2: Unremovable Projects - Challenges in deleting or removing projects from a system.\n",
      "Topic 3: Compilation Errors - Errors that occur during the process of compiling a program.\n",
      "Topic 4: Kernel Issues - Problems related to the kernel, such as disconnection or instability.\n",
      "Topic 5: Exception Handling - Issues related to handling exceptions in a program.\n",
      "Topic 6: Unsupported URI - Problems related to unsupported Uniform Resource Identifiers (URIs).\n",
      "Topic 7: Missing Files - Issues related to missing files in a software application.\n",
      "Topic 8: Value Errors - Problems related to unexpected or wrong values in a program.\n",
      "Topic 9: Slow Processing - Issues related to slow running or processing of a program.\n",
      "Topic 10: Forbidden Errors - Problems related to forbidden access or commands in a software application.\n",
      "Topic 11: Invalid Arguments - Issues related to incorrect or mismatched arguments in a function or method.\n",
      "Topic 12: Endpoint Issues - Problems related to deploying or accessing endpoints in a network.\n",
      "Topic 13: Missing Variables - Issues related to missing variables or environment entries in a program.\n",
      "Topic 14: Unresponsive Load - Problems related to unresponsive or slow loading of a software application.\n",
      "Topic 15: Missing Files - Issues related to missing files in a software application.\n",
      "Topic 16: Connection Timeout - Problems related to connection timeouts in a network.\n",
      "Topic 17: Unknown Errors - Unexplained or unexpected errors in a software application.\n",
      "Topic 18: Response Errors - Issues related to HTTP responses or server errors in a network.\n",
      "Topic 19: Failed Ping - Problems related to failed or unresponsive ping checks in a network.\n",
      "Topic 20: Pipeline Errors - Issues related to broken or problematic pipelines in a software application.\n",
      "Topic 21: Invalid Format - Problems related to incorrect or mismatched data formats in a program.\n",
      "Topic 22: Directory Issues - Issues related to invalid or missing directories in a system.\n",
      "Topic 23: Training Errors - Problems related to incomplete or unsuccessful training of a machine learning model.\n",
      "Topic 24: Missing Buckets - Issues related to missing buckets in a data storage system.\n",
      "Topic 25: Permission Denied - Problems related to denied access or permissions in a system.\n",
      "Topic 26: Model Errors - Issues related to errors in a machine learning model.\n",
      "Topic 27: Missing Output - Problems related to missing or unexpected output in a program.\n",
      "Topic 28: Input Shape - Issues related to incorrect or malformed input shapes in a machine learning model.\n",
      "Topic 29: Log Inconsistencies - Problems related to incomplete or malfunctioning logs in a system.\n",
      "Topic 30: Invalid Models - Issues related to incompatible or incorrect machine learning models.\n",
      "Topic 31: Denied Access - Problems related to denied access in a system.\n",
      "Topic 32: Restricted Access - Issues related to limited or restricted access in a system.\n",
      "Topic 33: Memory Overflow - Problems related to memory leaks or overflows in a system.\n",
      "Topic 34: Loading Errors - Issues related to failed or inefficient loading of a software application.\n",
      "Topic 35: Type Errors - Problems related to incorrect data types in a program.\n",
      "Topic 36: CuDNN Errors - Issues related to the CUDA Deep Neural Network library (CuDNN).\n",
      "Topic 37: Missing Metrics - Problems related to missing or incorrect metrics in a program.\n",
      "Topic 38: Incompatible Versions - Issues related to incompatible versions of a software or library.\n",
      "Topic 39: Package Issues - Problems related to unsupported or incompatible software packages.\n",
      "Topic 40: Configuration Errors - Issues related to incorrect or broken configurations in a system.\n",
      "Topic 41: Key Errors - Problems related to inaccessible or non-existent keys in a system.\n",
      "Topic 42: Unreproducible Behavior - Issues related to unpredictable or inconsistent behavior in a program.\n",
      "Topic 43: Invalid Parameters - Problems related to incorrect or inaccessible parameters in a function or method.\n",
      "Topic 44: Unclear Documentation - Issues related to incorrect or unclear documentation of a software application.\n",
      "Topic 45: Large Files - Problems related to handling large files in a system.\n",
      "Topic 46: Unsynchronized Plots - Issues related to unsynchronized or malfunctioning plots in a data visualization.\n",
      "Topic 47: Installation Errors - Problems related to failed or incorrect installation of a software application.\n",
      "Topic 48: Windows Errors - Issues related to errors in a Windows operating system.\n",
      "Topic 49: Web Service Issues - Problems related to inaccessible or inconsistent web services.\n",
      "Topic 50: Value Errors - Issues related to incorrect or unexpected values in a program.\n",
      "Topic 51: SSL Errors - Problems related to Secure Sockets Layer (SSL) encryption.\n",
      "Topic 52: Missing Credentials - Issues related to missing credentials in a system.\n",
      "Topic 53: Failed Deployment - Problems related to failed or inaccessible deployment of a software application.\n",
      "Topic 54: Environment Errors - Issues related to incorrect or incompatible software environments.\n",
      "Topic 55: Bad Requests - Problems related to incorrect or failed requests in a network.\n",
      "Topic 56: Import Errors - Issues related to importing data or modules in a software application.\n",
      "Topic 57: Unauthorized Roles - Problems related to unauthorized roles or permissions in a system.\n",
      "Topic 58: Exhausted Quota - Issues related to exceeded or insufficient quotas in a system.\n",
      "Topic 59: GPU Performance - Problems related to underutilization or slow performance of a Graphics Processing Unit (GPU).\n",
      "Topic 60: Inconsistent Results - Issues related to inconsistent or differing results in a program.\n",
      "Topic 61: Limit Exceeded - Problems related to exceeded limits or resources in a system.\n",
      "Topic 62: Serialization Errors - Issues related to serialization of data in a program.\n",
      "Topic 63: Unresponsive Jobs - Problems related to unresponsive or inaccessible jobs in a system.\n",
      "Topic 64: RPC Errors - Issues related to Remote Procedure Call (RPC) in a network.\n",
      "Topic 65: Missing Parameters - Problems related to missing parameters in a function or method.\n",
      "Topic 66: Prediction Errors - Issues related to incorrect or unexpected predictions in a machine learning model.\n",
      "Topic 67: Unbound Errors - Problems related to unbound local variables or functions in a program.\n",
      "Topic 68: Missing Columns - Issues related to missing or unexpected columns in a data frame.\n",
      "Topic 69: Outdated Packages - Problems related to outdated or unsupported software packages.\n",
      "Topic 70: Missing Datasets - Issues related to missing or inaccessible datasets in a system.\n",
      "Topic 71: Access Errors - Problems related to denied or incorrect access to data in a system.\n",
      "Topic 72: Missing Modules - Issues related to missing modules in a software application.\n",
      "Topic 73: Denied Access - Problems related to denied access or permissions in a system.\n",
      "Topic 74: Docker Build - Issues related to building or deploying Docker containers.\n",
      "Topic 75: Select Timeout - Problems related to timeouts in a network or server.\n",
      "Topic 76: Breaking Changes - Issues related to changes that break the functionality of a software application.\n",
      "Topic 77: Unsupported Features - Problems related to unsupported features or attributes in a software application.\n",
      "Topic 78: Typo Errors - Issues related to spelling mistakes or typos in a program.\n",
      "Topic 79: Inaccessible Images - Problems related to inaccessible or invalid images in a system.\n",
      "Topic 80: Download Errors - Issues related to failed or incorrect downloads in a system.\n",
      "Topic 81: Save Errors - Problems related to saving or persisting data in a system.\n",
      "Topic 82: Undefined Symbols - Issues related to undefined symbols or functions in a program.\n",
      "Topic 83: Login Errors - Problems related to incorrect or failed login attempts in a system.\n",
      "Topic 84: Authentication Errors - Issues related to incorrect or incomplete authentication in a system.\n",
      "Topic 85: Update Dependencies - Problems related to updating dependencies in a software application.\n",
      "Topic 86: Missing Commands - Issues related to missing or unrecognized commands in a system.\n",
      "Topic 87: Retrieval Errors - Problems related to retrieving data or resources in a system.\n",
      "Topic 88: Invalid Paths - Issues related to incorrect or mismatched file paths in a system.\n",
      "Topic 89: Missing Dependencies - Problems related to missing dependencies in a software application.\n",
      "Topic 90: Invalid Versions - Issues related to incorrect or mismatched versions of a software or library.\n",
      "Topic 91: Connection Reset - Problems related to reset or unstable connections in a network.\n",
      "Topic 92: Missing Logs - Issues related to missing or excessive logs in a system.\n",
      "Topic 93: Missing Artifacts - Problems related to missing or inaccessible artifacts in a system.\n",
      "Topic 94: Implementation Errors - Issues related to incorrect or failed implementation of a software application.\n",
      "Topic 95: Inaccessible URLs - Problems related to inaccessible or forbidden URLs in a network.\n",
      "Topic 96: Stuck Jobs - Issues related to jobs that are stuck or unresponsive in a system.\n",
      "Topic 97: Memory Errors - Problems related to memory allocation or leaks in a system.\n",
      "Topic 98: Unsaved Models - Issues related to unsaved or unavailable machine learning models.\n",
      "Topic 99: Failed Models - Problems related to failed or incorrect machine learning models.\n",
      "Topic 100: Bugs - Issues related to bugs or errors in a software application.\n",
      "Topic 101: Pending Authorization - Problems related to pending authorizations or permissions in a system.\n",
      "Topic 102: Failed Installation - Issues related to failed or incorrect installation of a software application.\n",
      "Topic 103: Expired Tokens - Problems related to expired tokens or sessions in a system.\n",
      "Topic 104: Missing Models - Issues related to missing or incorrect machine learning models.\n",
      "Topic 105: Missing Objects - Problems related to missing or unexpected objects in a program.\n",
      "Topic 106: Epoch Issues - Issues related to incorrect or misaligned epochs in a machine learning model.\n",
      "Topic 107: Invalid Values - Problems related to incorrect or unexpected values in a program.\n",
      "Topic 108: Indefinite Run - Issues related to indefinite or overridden runs in a program.\n",
      "Topic 109: Missing Data - Problems related to missing or inconsistent data in a system.\n",
      "Topic 110: Missing Runs - Issues related to missing or blocked runs in a program.\n",
      "Topic 111: Unresponsive Deployment - Problems related to unresponsive or slow deployment of a software application.\n",
      "Topic 112: Broken Links - Issues related to broken or malfunctioning links in a system.\n",
      "Topic 113: Initialization Errors - Problems related to incorrect or failed initialization of a program.\n",
      "Topic 114: Dataset Errors - Issues related to incorrect or inaccessible datasets in a system.\n",
      "Topic 115: Read-Only Files - Problems related to read-only or difficult to access files in a system.\n",
      "Topic 116: Unrecognized Commands - Issues related to unrecognized or incorrect commands in a system.\n"
     ]
    }
   ],
   "source": [
    "prompt_topic = '''You will be given lists of keywords with each refering to specific software engineering topic. Please summarize each with software engineering terms and attach a one-liner explanation. Also, you must guarantee that the summaries are exclusive to one another.###\\n'''\n",
    "\n",
    "with open(os.path.join(path_anomaly, 'Topic terms.pickle'), 'rb') as handle:\n",
    "    topic_terms = pickle.load(handle)\n",
    "\n",
    "    topic_term_list = []\n",
    "    for index, topic in enumerate(topic_terms):\n",
    "        terms = ', '.join([term[0] for term in topic])\n",
    "        topic_term = f'Topic {index}: {terms}'\n",
    "        topic_term_list.append(topic_term)\n",
    "\n",
    "    prompt = prompt_topic + '\\n'.join(topic_term_list) + '\\n###\\n'\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "        temperature=0,\n",
    "        max_tokens=3500,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        timeout=500,\n",
    "        stream=False)\n",
    "\n",
    "    topics = completion.choices[0].message.content\n",
    "    print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_clusters = {\n",
    "    \"Syntax Issues\": [1, 3, 8, 11, 21, 35, 43, 78, 82, 86, 88, 90, 107, 116],\n",
    "    \"System Issues\": [2, 4, 16, 22, 24, 31, 32, 33, 39, 41, 45, 48, 58, 61, 73, 75, 76, 80, 83, 85, 87, 92, 93, 97, 100, 102, 105, 113, 115],\n",
    "    \"Network Issues\": [6, 12, 18, 19, 49, 51, 55, 64, 75, 91, 95, 112],\n",
    "    \"Authentication Issues\": [10, 25, 31, 32, 52, 57, 73, 83, 84, 101, 103],\n",
    "    \"Performance Issues\": [9, 14, 33, 34, 59, 63, 96, 108, 111],\n",
    "    \"Data Issues\": [0, 7, 13, 15, 20, 21, 24, 26, 27, 28, 30, 37, 68, 70, 72, 81, 89, 92, 93, 98, 99, 104, 109, 114],\n",
    "    \"Algorithm Issues\": [5, 23, 26, 28, 30, 36, 37, 60, 62, 66, 98, 99, 104, 106, 110],\n",
    "    \"Compatibility Issues\": [4, 16, 38, 39, 54, 56, 74, 85, 89, 90, 102],\n",
    "    \"User Experience Issues\": [14, 34, 40, 42, 44, 47, 50, 76, 77, 79, 94, 100, 105, 108, 111, 112, 114, 116],\n",
    "    # etc. can be added here if more clusters are required\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_macro_topic_mapping_inverse = {\n",
    "    1: (\"Code-Level Issues\", [1, 3, 5, 8, 11, 13, 21, 35, 43, 62, 65, 67, 78, 82, 107]),\n",
    "    2: (\"System-Level Issues\", [0, 2, 4, 6, 7, 15, 16, 20, 22, 33, 40, 41, 45, 48, 58, 61, 72, 74, 75, 76, 80, 81, 83, 86, 88, 92, 97, 116]),\n",
    "    4: (\"Network-Level Issues\", [12, 18, 19, 55, 64, 91, 95]),\n",
    "    # These are generally issues related to the handling and processing of data and models, especially in data-driven or machine learning applications. Topics here include problems with datasets, models, training issues, etc.\n",
    "    3: (\"Authentication Issues\", [10, 25, 31, 32, 51, 52, 57, 71, 73, 84, 101, 103, 115]),\n",
    "    5: (\"Performance Issues\", [9, 14, 34, 59, 108]),\n",
    "    6: (\"Data Issues\", [24, 68, 70, 109, 114]),\n",
    "    7: (\"Machine Learning Issues\", [23, 26, 28, 30, 36, 37, 66, 98, 99, 104, 106]),\n",
    "    8: (\"Compatibility Issues\", [38, 39, 47, 56, 69, 85, 89, 90, 102]),\n",
    "    9: (\"User Experience Issues\", [44, 46]),\n",
    "    10: (\"Inconsistency Issues\", [42, 60]),\n",
    "    10: (\"Unknown Issues\", [17, 53, 54, 63, 77, 79, 87, 93, 94, 96, 100, 105, 110, 111, 112, 113]),\n",
    "}\n",
    "\n",
    "topic_clusters = {\n",
    "    # These are generally issues related to programming logic, syntax, data types, and anything that emerges during the coding process itself.\n",
    "    \"Syntax Issues\": [0, 1, 3, 5, 6, 13, 20, 35, 43, 45, 78, 82, 94, 113, 116],\n",
    "    # These are generally issues related to the software's interaction with its underlying system or platform, such as memory issues, installation problems, or errors related to specific system tools like Docker.\n",
    "    \"System Issues\": [2, 4, 22, 40, 48, 74, 76, 85, 106],\n",
    "    # These are generally issues related to network connections, web services, HTTP errors, and other online interaction problems.\n",
    "    \"Network Issues\": [12, 16, 18, 19, 51, 55, 64, 91, 95],\n",
    "    \"Authentication Issues\": [10, 25, 31, 32, 52, 57, 73, 83, 84, 101, 103],\n",
    "    \"Performance Issues\": [9, 14, 33, 59, 63, 96, 108, 111],\n",
    "    \"Data Issues\": [8, 11, 21, 29, 41, 50, 71, 62, 68, 87, 88, 109],\n",
    "    \"Algorithm Issues\": [23, 26, 28, 30, 66, 99],\n",
    "    \"Compatibility Issues\": [36, 38, 39, 69, 90],\n",
    "    # These are generally issues that affect the user's interaction with the software, such as problems with the user interface or errors that directly affect the user's experience.\n",
    "    \"User Experience Issues\": [42, 44, 46, 47, 54, 56, 58, 60, 61, 76, 77, 80, 81, 85, 102],\n",
    "    \"Data Handling Issues\": [7, 15, 24, 27, 37, 65, 70, 72, 79, 86, 89, 92, 93, 98, 104, 105, 110],\n",
    "    \"\": [17, 100],\n",
    "}\n",
    "\n",
    "\n",
    "anomaly_macro_topic_mapping = {}\n",
    "anomaly_macro_topic_index_mapping = {}\n",
    "for key, (macro_topic, topics) in anomaly_macro_topic_mapping_inverse.items():\n",
    "    anomaly_macro_topic_index_mapping[macro_topic] = key\n",
    "    for topic in topics:\n",
    "        anomaly_macro_topic_mapping[topic] = key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17,\n",
       " 42,\n",
       " 60,\n",
       " 72,\n",
       " 77,\n",
       " 79,\n",
       " 87,\n",
       " 93,\n",
       " 94,\n",
       " 96,\n",
       " 100,\n",
       " 105,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 51,\n",
       " 53,\n",
       " 54,\n",
       " 63]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '''Topic 17: Unknown Errors\n",
    "Topic 42: Unreproducible Behavior\n",
    "Topic 60: Inconsistent Results\n",
    "Topic 72: Missing Modules\n",
    "Topic 77: Unsupported Features\n",
    "Topic 79: Inaccessible Images\n",
    "Topic 87: Retrieval Errors\n",
    "Topic 93: Missing Artifacts\n",
    "Topic 94: Implementation Errors\n",
    "Topic 96: Stuck Jobs\n",
    "Topic 100: Bugs\n",
    "Topic 105: Missing Objects\n",
    "Topic 110: Missing Runs\n",
    "Topic 111: Unresponsive Deployment\n",
    "Topic 112: Broken Links\n",
    "Topic 113: Initialization Errors\n",
    "Topic 51: SSL Errors\n",
    "Topic 53: Failed Deployment\n",
    "Topic 54: Environment Errors\n",
    "Topic 63: Unresponsive Jobs'''\n",
    "\n",
    "topic_list = []\n",
    "for word in text.split('\\n'):\n",
    "    topic_list.append(int(word.split(':')[0].removeprefix('Topic ')))\n",
    "    \n",
    "topic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: Package Management - Handling and maintaining software packages including version checking and downgrading.\n",
      "Topic 1: Parameter Modification - Updating and modifying parameters in a software environment.\n",
      "Topic 2: Model Persistence - Saving and storing machine learning models and their metadata.\n",
      "Topic 3: Logging - Recording and managing logs related to models and metrics.\n",
      "Topic 4: Run Management - Controlling and monitoring the status of software runs.\n",
      "Topic 5: S3 Storage Usage - Utilizing S3 for online storage and directory management.\n",
      "Topic 6: Data Conversion - Changing the format and structure of data.\n",
      "Topic 7: Scripting - Creating and executing scripts in different modes.\n",
      "Topic 8: Data Analytics - Managing and developing data for stream analytics.\n",
      "Topic 9: Package Installation - Downloading and installing software packages.\n",
      "Topic 10: Package Upgrading - Updating and upgrading software packages.\n",
      "Topic 11: Compute Target Management - Creating and using compute targets in a software environment.\n",
      "Topic 12: Permission Management - Granting and managing access permissions.\n",
      "Topic 13: Quota Management - Increasing and checking quotas and capacities.\n",
      "Topic 14: File Downloading - Downloading and managing files.\n",
      "Topic 15: Package Installation - Installing software packages.\n",
      "Topic 16: Configuration Management - Updating and creating lifecycle configurations.\n",
      "Topic 17: Authentication - Configuring and managing interactive authentication.\n",
      "Topic 18: Experiment Management - Creating, sharing, and running experiments.\n",
      "Topic 19: Forum Engagement - Participating and asking questions on forums.\n",
      "Topic 20: Alternative Consideration - Evaluating and using alternative options and scenarios.\n",
      "Topic 21: Notebook Management - Starting, stopping, and restarting notebook instances.\n",
      "Topic 22: Package Upgrading - Upgrading and updating software packages.\n",
      "Topic 23: Error Handling - Managing error notifications and exceptions.\n",
      "Topic 24: Training Launch - Starting and managing training jobs.\n",
      "Topic 25: Bug Fixing - Releasing fixes for software bugs.\n",
      "Topic 26: Pipeline Management - Updating, modifying, and creating pipelines.\n",
      "Topic 27: Environment Management - Setting and configuring environment variables.\n",
      "Topic 28: Web Service Management - Using and deploying web services.\n",
      "Topic 29: Guidance Following - Referring to and following guidance and examples.\n",
      "Topic 30: Function Implementation - Using and implementing functions.\n",
      "Topic 31: Instruction Following - Following steps and instructions.\n",
      "Topic 32: Model Deployment - Deploying machine learning models.\n",
      "Topic 33: Environment Testing - Checking and testing software environments.\n",
      "Topic 34: Endpoint Management - Invoking and creating endpoints.\n",
      "Topic 35: Ongoing Fixes - Managing ongoing fixes and patches.\n",
      "Topic 36: Issue Management - Handling stale and expired issues.\n",
      "Topic 37: Connection Establishment - Opening and checking connections.\n",
      "Topic 38: File Copying - Copying and exporting files.\n",
      "Topic 39: Documentation - Reading and following software documentation.\n",
      "Topic 40: Tool Usage - Using different software tools.\n",
      "Topic 41: Docker Management - Creating and building Docker images.\n",
      "Topic 42: Feature Support - Handling supported and unsupported features.\n",
      "Topic 43: Work Completion - Completing work and logging in again.\n",
      "Topic 44: Container Management - Creating and customizing containers.\n"
     ]
    }
   ],
   "source": [
    "prompt_topic = '''You will be given a list of stemmed words refering to specific software engineering topics. Please summarize each topic in terms and attach a one-liner description based on the stemmed words. Also, you must guarantee that the summaries are exclusive to one another.###\\n'''\n",
    "\n",
    "with open(os.path.join(path_solution, 'Topic terms.pickle'), 'rb') as handle:\n",
    "    topic_terms = pickle.load(handle)\n",
    "\n",
    "    topic_term_list = []\n",
    "    for index, topic in enumerate(topic_terms):\n",
    "        terms = ', '.join([term[0] for term in topic])\n",
    "        topic_term = f'Topic {index}: {terms}'\n",
    "        topic_term_list.append(topic_term)\n",
    "\n",
    "    prompt = prompt_topic + '\\n'.join(topic_term_list) + '\\n###\\n'\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "        temperature=0,\n",
    "        max_tokens=3000,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        timeout=300,\n",
    "        stream=False)\n",
    "\n",
    "    topics = completion.choices[0].message.content\n",
    "    print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = '''Topic 0: Log Metrics - Analysis and modeling of log data for accuracy.\n",
    "Topic 1: Package Installation - Downloading, adding, specifying, and creating software packages.\n",
    "Topic 2: Permission Management - Granting, assigning, and applying access permissions.\n",
    "Topic 3: Package Upgrade - Updating and running software package upgrades.\n",
    "Topic 4: URI Configuration - Setting up and checking custom HTTP and URL configurations.\n",
    "Topic 5: Compute Management - Creating, using, and increasing compute targets and engines.\n",
    "Topic 6: Model Management - Saving, storing, and creating machine learning models.\n",
    "Topic 7: Documentation and Forum - Referring to, discussing, and reading software documentation and forums.\n",
    "Topic 8: Parameter Management - Adding, specifying, and removing parameters.\n",
    "Topic 9: Directory Management - Specifying and defining directory paths and locations.\n",
    "Topic 10: Package Installation - Installing software packages.\n",
    "Topic 11: Data Formatting - Updating, converting, and changing data formats.\n",
    "Topic 12: Storage Management - Increasing, using, and checking storage capacity.\n",
    "Topic 13: Line Management - Updating, removing, and replacing lines and parameters.\n",
    "Topic 14: Training Management - Launching, running, and creating training jobs.\n",
    "Topic 15: Dataset Management - Registering, creating, and using datasets.\n",
    "Topic 16: Run Management - Checking run status, history, and descriptions.\n",
    "Topic 17: Configuration Management - Updating, editing, and setting configurations.\n",
    "Topic 18: Bucket and Pipeline Management - Specifying and editing bucket names and pipelines.\n",
    "Topic 19: Kernel Management - Restarting, reinstalling, and updating kernels.\n",
    "Topic 20: Ticket Management - Opening, writing, and submitting tickets.\n",
    "Topic 21: Docker Management - Creating, building, and using Docker containers and images.\n",
    "Topic 22: Authentication Management - Configuring and logging into authentication systems.\n",
    "Topic 23: Dependency Management - Adding, updating, and removing dependencies.\n",
    "Topic 24: Package Upgrade - Updating and upgrading software packages.\n",
    "Topic 25: Environment Management - Adding, modifying, and setting environment variables.\n",
    "Topic 26: Issue Management - Marking and following up on stale issues.\n",
    "Topic 27: Error Management - Suppressing and communicating error messages and warnings.\n",
    "Topic 28: File Download - Downloading files and using download utilities.\n",
    "Topic 29: Model Deployment - Deploying and autoscaling models.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_macro_topic_mapping_inverse = {\n",
    "    # These topics are all related to the management of permissions and connectivity.\n",
    "    1: ('Access Management', [2]),\n",
    "    # These topics are all related to the management of source code.\n",
    "    8: ('Code Management', []),\n",
    "    # These topics are all related to the management of data and datasets.\n",
    "    2: ('Compute Management', []),\n",
    "    # These topics are all related to the management of services.\n",
    "    3: ('Data Management', []),\n",
    "    # These topics are all related to the management of packages and distributions.\n",
    "    4: ('Environment Management', [1, 3]),\n",
    "    # These topics are all related to the management of pipelines.\n",
    "    7: ('Lifecycle Management', []),\n",
    "    # These topics are all related to the management of machine learning models.\n",
    "    5: ('Model Management', []),\n",
    "    # These topics are all related to the management of logs and metrics.\n",
    "    6: ('Performance Management', [0]),\n",
    "}\n",
    "\n",
    "anomaly_macro_topic_mapping = {}\n",
    "anomaly_macro_topic_index_mapping = {}\n",
    "for key, (macro_topic, topics) in anomaly_macro_topic_mapping_inverse.items():\n",
    "    anomaly_macro_topic_index_mapping[macro_topic] = key\n",
    "    for topic in topics:\n",
    "        anomaly_macro_topic_mapping[topic] = key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "topic_ensemble = []\n",
    "for key, (macro_topic, topics) in macro_topic_mapping_inverse.items():\n",
    "    topic_ensemble.extend(topics)\n",
    "\n",
    "print(set(range(125)).difference(set(topic_ensemble)))\n",
    "print(set(set(topic_ensemble)).difference(range(125)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Number</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User Interface and Experience Issues</td>\n",
       "      <td>634</td>\n",
       "      <td>11.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data and Model Issues</td>\n",
       "      <td>701</td>\n",
       "      <td>12.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>System-Level Issues</td>\n",
       "      <td>2089</td>\n",
       "      <td>36.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Code-Level Issues</td>\n",
       "      <td>1605</td>\n",
       "      <td>28.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Networking and Web Service Issues</td>\n",
       "      <td>691</td>\n",
       "      <td>12.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Topic  Number  Percentage\n",
       "0  User Interface and Experience Issues     634       11.08\n",
       "1                 Data and Model Issues     701       12.26\n",
       "2                   System-Level Issues    2089       36.52\n",
       "3                     Code-Level Issues    1605       28.06\n",
       "4     Networking and Web Service Issues     691       12.08"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign human-readable & high-level topics to challenges & solutions\n",
    "\n",
    "df = pd.read_json(os.path.join(path_special_output, 'topics.json'))\n",
    "df['Challenge_summary_topic_macro'] = -1\n",
    "df['Challenge_root_cause_topic_macro'] = -1\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['Challenge_summary_topic'] in macro_topic_mapping:\n",
    "        df.at[index, 'Challenge_summary_topic_macro'] = macro_topic_mapping[row['Challenge_summary_topic']]\n",
    "        if row['Challenge_root_cause_topic'] in macro_topic_mapping:\n",
    "            df.at[index, 'Challenge_summary_topic_macro'] = macro_topic_mapping[row['Challenge_summary_topic']]\n",
    "    else:\n",
    "        df.drop(index, inplace=True)\n",
    "\n",
    "df.to_json(os.path.join(path_special_output, 'filtered.json'), indent=4, orient='records')\n",
    "\n",
    "df_number = pd.DataFrame()\n",
    "\n",
    "for key, (macro_topic, topics) in macro_topic_mapping_inverse.items():\n",
    "    entry = {\n",
    "        'Topic': macro_topic,\n",
    "        'Number': len(df[df[\"Challenge_summary_topic_macro\"] == key]),\n",
    "        'Percentage': round(len(df[df[\"Challenge_summary_topic_macro\"] == key]) / len(df) * 100, 2),\n",
    "    }\n",
    "    df_number = pd.concat([df_number, pd.DataFrame([entry])], ignore_index=True)\n",
    "\n",
    "minimize_weighted_sum(df_number, 'Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: Path Issues - Problems related to incorrect, mismatched, or missing file paths.\n",
      "Topic 1: Access Limitations - Issues concerning restricted, blocked, or insecure access to resources.\n",
      "Topic 2: Memory Problems - Concerns about exhausted, deleted, or high memory usage.\n",
      "Topic 3: Input/Output Errors - Problems with incorrect, invalid, or unexpected input and output formats.\n",
      "Topic 4: Unsupported Features - Issues with unsupported, unmaintained, or insufficient software features.\n",
      "Topic 5: Unreproducible Behavior - Problems related to unpredictable or false interactive behaviors.\n",
      "Topic 6: Missing Files - Issues concerning missing files, folders, or directories.\n",
      "Topic 7: Documentation Issues - Problems with unclear, confusing, or unspecified documentation.\n",
      "Topic 8: System Incompatibility - Issues with incompatible or unsupported operating systems or versions.\n",
      "Topic 9: Bug Issues - Problems related to known or unknown software bugs.\n",
      "Topic 10: Model Issues - Concerns about large, different, or wrong models.\n",
      "Topic 11: Outdated Packages - Issues with outdated or removed software packages.\n",
      "Topic 12: Version Incompatibility - Problems with incompatible, mismatched, or unsupported versions.\n",
      "Topic 13: Permission Restrictions - Issues concerning restricted, limited, or improper permissions.\n",
      "Topic 14: Missing Modules - Problems with missing, unreachable, or compressed modules.\n",
      "Topic 15: Dependency Issues - Issues with missing, incompatible, or conflicting dependencies.\n",
      "Topic 16: Breaking Changes - Problems related to changes that break the functionality of the software.\n",
      "Topic 17: Limitations - Issues concerning known or increased limitations.\n",
      "Topic 18: Docker Issues - Problems with conflicting, unsupported, or custom Docker environments.\n",
      "Topic 19: Parameter Issues - Issues with missing, wrong, or unsupported parameters.\n",
      "Topic 20: Data Type Issues - Problems with invalid, mismatched, or wrong data types.\n",
      "Topic 21: Endpoint Issues - Issues with misconfigured, wrong, or specific endpoints.\n",
      "Topic 22: Package Incompatibility - Problems with incompatible, conflicting, or invalid packages.\n",
      "Topic 23: Supplier Issues - Issues with unresponsive, malfunctioning, or custom suppliers.\n",
      "Topic 24: Argument Issues - Problems with missing, wrong, or unexpected arguments.\n",
      "Topic 25: Environment Issues - Issues with missing, unusable, or wrong environments.\n",
      "Topic 26: Deprecated Elements - Problems with deprecated features, methods, classes, or packages.\n",
      "Topic 27: Session Issues - Issues with inactive, missing, or expired sessions.\n",
      "Topic 28: Link Issues - Problems with broken, removed, or wrong links or URLs.\n"
     ]
    }
   ],
   "source": [
    "# prompt_topic = '''You will be given a list of stemmed words refering to specific software engineering topics. Please summarize each topic in terms and attach a one-liner description based on the stemmed words. Also, you must guarantee that the summaries are exclusive to one another.###\\n'''\n",
    "\n",
    "# with open(os.path.join(path_root_cause, 'Topic terms.pickle'), 'rb') as handle:\n",
    "#     topic_terms = pickle.load(handle)\n",
    "\n",
    "#     topic_term_list = []\n",
    "#     for index, topic in enumerate(topic_terms):\n",
    "#         terms = ', '.join([term[0] for term in topic])\n",
    "#         topic_term = f'Topic {index}: {terms}'\n",
    "#         topic_term_list.append(topic_term)\n",
    "\n",
    "#     prompt = prompt_topic + '\\n'.join(topic_term_list) + '\\n###\\n'\n",
    "#     completion = openai.ChatCompletion.create(\n",
    "#         model='gpt-4',\n",
    "#         messages=[{'role': 'user', 'content': prompt}],\n",
    "#         temperature=0,\n",
    "#         max_tokens=3000,\n",
    "#         top_p=1,\n",
    "#         frequency_penalty=0,\n",
    "#         presence_penalty=0,\n",
    "#         timeout=300,\n",
    "#         stream=False)\n",
    "\n",
    "#     topics = completion.choices[0].message.content\n",
    "#     print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw sankey diagram of tool and platform\n",
    "\n",
    "df = pd.read_json(os.path.join(path_special_output, 'topics.json'))\n",
    "df = df[df['Challenge_type'] != 'na']\n",
    "\n",
    "df['State'] = df['Challenge_closed_time'].apply(lambda x: 'closed' if not pd.isna(x) else 'open')\n",
    "\n",
    "categories = ['Platform', 'Tool', 'State']\n",
    "df_info = df.groupby(categories).size().reset_index(name='value')\n",
    "\n",
    "labels = {}\n",
    "newDf = pd.DataFrame()\n",
    "for i in range(len(categories)):\n",
    "    labels.update(df[categories[i]].value_counts().to_dict())\n",
    "    if i == len(categories)-1:\n",
    "        break\n",
    "    tempDf = df_info[[categories[i], categories[i+1], 'value']]\n",
    "    tempDf.columns = ['source', 'target', 'value']\n",
    "    newDf = pd.concat([newDf, tempDf])\n",
    "    \n",
    "newDf = newDf.groupby(['source', 'target']).agg({'value': 'sum'}).reset_index()\n",
    "source = newDf['source'].apply(lambda x: list(labels).index(x))\n",
    "target = newDf['target'].apply(lambda x: list(labels).index(x))\n",
    "value = newDf['value']\n",
    "\n",
    "labels = [f'{k} ({v})' for k, v in labels.items()]\n",
    "\n",
    "link = dict(source=source, target=target, value=value)\n",
    "node = dict(label=labels)\n",
    "data = go.Sankey(link=link, node=node)\n",
    "\n",
    "fig = go.Figure(data)\n",
    "fig.update_layout(width=1000, height=1000, font_size=20)\n",
    "fig.write_image(os.path.join(path_result_rq1, 'Tool platform state sankey.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add different metrics to each post\n",
    "\n",
    "df = pd.read_json(os.path.join(path_special_output, 'topics.json'))\n",
    "df = df[df['Challenge_type'] != 'na']\n",
    "\n",
    "df['Solution_word_count'] = np.nan\n",
    "df['Solution_sentence_count'] = np.nan\n",
    "df['Solution_readability'] = np.nan\n",
    "df['Solution_reading_time'] = np.nan\n",
    "df['Solution_link_count'] = np.nan\n",
    "\n",
    "df['Challenge_solved_time'] = np.nan\n",
    "df['Challenge_adjusted_solved_time'] = np.nan\n",
    "\n",
    "df['Solution_link_docs'] = np.nan\n",
    "df['Solution_link_issues'] = np.nan\n",
    "df['Solution_link_patches'] = np.nan\n",
    "df['Solution_link_tools'] = np.nan\n",
    "df['Solution_link_tutorials'] = np.nan\n",
    "df['Solution_link_examples'] = np.nan\n",
    "\n",
    "df['Challenge_created_time'] = pd.to_datetime(df['Challenge_created_time'])\n",
    "df['Challenge_closed_time'] = pd.to_datetime(df['Challenge_closed_time'])\n",
    "df['Challenge_last_edit_time'] = pd.to_datetime(df['Challenge_last_edit_time'])\n",
    "df['Solution_last_edit_time'] = pd.to_datetime(df['Solution_last_edit_time'])\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    challenge_content = row['Challenge_title'] + '.' + str(row['Challenge_body'])\n",
    "    df.at[index, 'Challenge_word_count'] = textstat.lexicon_count(challenge_content)\n",
    "    df.at[index, 'Challenge_sentence_count'] = textstat.sentence_count(challenge_content)\n",
    "    df.at[index, 'Challenge_readability'] = textstat.flesch_kincaid_grade(challenge_content)\n",
    "    df.at[index, 'Challenge_reading_time'] = textstat.reading_time(challenge_content)\n",
    "    \n",
    "    links = list(set(re.findall(link_pattern, challenge_content)))\n",
    "    df.at[index, 'Challenge_link_count'] = len(links)\n",
    "\n",
    "    solution_content = row['Solution_body']\n",
    "\n",
    "    if pd.notna(solution_content):\n",
    "        df.at[index, 'Solution_word_count'] = textstat.lexicon_count(solution_content)\n",
    "        df.at[index, 'Solution_sentence_count'] = textstat.sentence_count(solution_content)\n",
    "        df.at[index, 'Solution_readability'] = textstat.flesch_kincaid_grade(solution_content)\n",
    "        df.at[index, 'Solution_reading_time'] = textstat.reading_time(solution_content)\n",
    "        \n",
    "        links = list(set(re.findall(link_pattern, solution_content)))\n",
    "        df.at[index, 'Solution_link_count'] = len(links)\n",
    "        \n",
    "        link_docs = 0\n",
    "        link_tools = 0\n",
    "        link_issues = 0\n",
    "        link_patches = 0\n",
    "        link_tutorials = 0\n",
    "        link_examples = 0\n",
    "    \n",
    "        for link in links:\n",
    "            if any([patch in link for patch in keywords_patch]):\n",
    "                link_patches += 1\n",
    "            elif any([issue in link for issue in keywords_issue]):\n",
    "                link_issues += 1\n",
    "            elif any([tool in link for tool in keywords_tool]):\n",
    "                link_tools += 1\n",
    "            elif any([doc in link for doc in keywords_doc]):\n",
    "                link_docs += 1\n",
    "            elif any([tool in link for tool in keywords_tutorial]):\n",
    "                link_tutorials += 1\n",
    "            else:\n",
    "                link_examples += 1\n",
    "                \n",
    "        df.at[index, 'Solution_link_docs'] = link_docs\n",
    "        df.at[index, 'Solution_link_issues'] = link_issues\n",
    "        df.at[index, 'Solution_link_patches'] = link_patches\n",
    "        df.at[index, 'Solution_link_tools'] = link_tools\n",
    "        df.at[index, 'Solution_link_tutorials'] = link_tutorials\n",
    "        df.at[index, 'Solution_link_examples'] = link_examples\n",
    "        \n",
    "    creation_time = row['Challenge_created_time']\n",
    "    closed_time = row['Challenge_closed_time']\n",
    "    if pd.notna(creation_time) and pd.notna(closed_time) and (closed_time > creation_time):\n",
    "        df.at[index, 'Challenge_solved_time'] = (closed_time - creation_time) / pd.Timedelta(hours=1)\n",
    "\n",
    "    creation_time = row['Challenge_last_edit_time'] if pd.notna(row['Challenge_last_edit_time']) else creation_time\n",
    "    closed_time = row['Solution_last_edit_time'] if pd.notna(row['Solution_last_edit_time']) else closed_time\n",
    "    if pd.notna(creation_time) and pd.notna(closed_time) and (closed_time > creation_time):\n",
    "        df.at[index, 'Challenge_adjusted_solved_time'] = (closed_time - creation_time) / pd.Timedelta(hours=1)\n",
    "    else:\n",
    "        df.at[index, 'Challenge_adjusted_solved_time'] = df.at[index, 'Challenge_solved_time']\n",
    "\n",
    "df['Challenge_comment_count'] = df['Challenge_comment_count'].fillna(0)\n",
    "df['Challenge_answer_count'] = df['Challenge_answer_count'].fillna(0)\n",
    "df['Challenge_participation_count'] = df['Challenge_answer_count'] + df['Challenge_comment_count']\n",
    "\n",
    "df = df.reindex(sorted(df.columns), axis=1)\n",
    "df.to_json(os.path.join(path_result_rq1, 'metrics.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenge topic count distribution tree map\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_result_rq1, 'metrics.json'))\n",
    "df_topics['Challenge_topic_macro'] = df_topics['Challenge_topic_macro'].map(\n",
    "    macro_topic_index_mapping)\n",
    "df_topics['Solved'] = df_topics['Challenge_closed_time'].notna().map(\n",
    "    {True: 'Closed', False: 'Open'})\n",
    "df_topics['Count'] = 1\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Solved', 'Platform', 'Tool'],\n",
    "    values='Count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Platform', 'Solved', 'Tool'],\n",
    "    values='Count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Tool', 'Platform', 'Solved'],\n",
    "    values='Count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(\n",
    "    path_result_rq1, 'Challenge_topic_count_distribution.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenge view count distribution tree map\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_result_rq1, 'metrics.json'))\n",
    "df_topics['Challenge_topic_macro'] = df_topics['Challenge_topic_macro'].map(\n",
    "    macro_topic_index_mapping)\n",
    "df_topics['Solved'] = df_topics['Challenge_closed_time'].notna().map(\n",
    "    {True: 'Closed', False: 'Open'})\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Solved', 'Platform', 'Tool'],\n",
    "    values='Challenge_view_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Platform', 'Solved', 'Tool'],\n",
    "    values='Challenge_view_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Tool', 'Platform', 'Solved'],\n",
    "    values='Challenge_view_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(\n",
    "    path_result_rq1, 'Challenge_view_count_distribution.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenge score count distribution tree map\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_result_rq1, 'metrics.json'))\n",
    "df_topics['Challenge_topic_macro'] = df_topics['Challenge_topic_macro'].map(\n",
    "    macro_topic_index_mapping)\n",
    "df_topics['Solved'] = df_topics['Challenge_closed_time'].notna().map(\n",
    "    {True: 'Closed', False: 'Open'})\n",
    "df_topics['Challenge_score_count'] = df_topics['Challenge_score_count'].map(\n",
    "    lambda x: 1e-07 if x == 0 else x)\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Solved', 'Platform', 'Tool'],\n",
    "    values='Challenge_score_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Platform', 'Solved', 'Tool'],\n",
    "    values='Challenge_score_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Tool', 'Platform', 'Solved'],\n",
    "    values='Challenge_score_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(\n",
    "    path_result_rq1, 'Challenge_score_count_distribution.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenge favorite count distribution tree map\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_result_rq1, 'metrics.json'))\n",
    "df_topics['Challenge_topic_macro'] = df_topics['Challenge_topic_macro'].map(\n",
    "    macro_topic_index_mapping)\n",
    "df_topics['Solved'] = df_topics['Challenge_closed_time'].notna().map(\n",
    "    {True: 'Closed', False: 'Open'})\n",
    "df_topics['Challenge_favorite_count'] = df_topics['Challenge_favorite_count'].map(\n",
    "    lambda x: 1e-07 if x == 0 else x)\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Solved', 'Platform', 'Tool'],\n",
    "    values='Challenge_favorite_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Platform', 'Solved', 'Tool'],\n",
    "    values='Challenge_favorite_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Tool', 'Platform', 'Solved'],\n",
    "    values='Challenge_favorite_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(\n",
    "    path_result_rq1, 'Challenge_favorite_count_distribution.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenge answer count distribution tree map\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_result_rq1, 'metrics.json'))\n",
    "df_topics['Challenge_topic_macro'] = df_topics['Challenge_topic_macro'].map(\n",
    "    macro_topic_index_mapping)\n",
    "df_topics['Solved'] = df_topics['Challenge_closed_time'].notna().map(\n",
    "    {True: 'Closed', False: 'Open'})\n",
    "df_topics['Challenge_answer_count'] = df_topics['Challenge_answer_count'].map(\n",
    "    lambda x: 1e-07 if x == 0 else x)\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Solved', 'Platform', 'Tool'],\n",
    "    values='Challenge_answer_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Platform', 'Solved', 'Tool'],\n",
    "    values='Challenge_answer_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Tool', 'Platform', 'Solved'],\n",
    "    values='Challenge_answer_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(\n",
    "    path_result_rq1, 'Challenge_answer_count_distribution.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenge comment count distribution tree map\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_result_rq1, 'metrics.json'))\n",
    "df_topics['Challenge_topic_macro'] = df_topics['Challenge_topic_macro'].map(\n",
    "    macro_topic_index_mapping)\n",
    "df_topics['Solved'] = df_topics['Challenge_closed_time'].notna().map(\n",
    "    {True: 'Closed', False: 'Open'})\n",
    "df_topics['Challenge_comment_count'] = df_topics['Challenge_comment_count'].map(\n",
    "    lambda x: 1e-07 if x == 0 else x)\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Solved', 'Platform', 'Tool'],\n",
    "    values='Challenge_comment_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Platform', 'Solved', 'Tool'],\n",
    "    values='Challenge_comment_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Tool', 'Platform', 'Solved'],\n",
    "    values='Challenge_comment_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(\n",
    "    path_result_rq1, 'Challenge_comment_count_distribution.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenge topic participation distribution tree map\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_result_rq1, 'metrics.json'))\n",
    "df_topics['Challenge_topic_macro'] = df_topics['Challenge_topic_macro'].map(\n",
    "    macro_topic_index_mapping)\n",
    "df_topics['Solved'] = df_topics['Challenge_closed_time'].notna().map(\n",
    "    {True: 'Closed', False: 'Open'})\n",
    "df_topics['Challenge_participation_count'] = df_topics['Challenge_participation_count'].map(\n",
    "    lambda x: 1e-07 if x == 0 else x)\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Solved', 'Platform', 'Tool'],\n",
    "    values='Challenge_participation_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Platform', 'Solved', 'Tool'],\n",
    "    values='Challenge_participation_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Tool', 'Platform', 'Solved'],\n",
    "    values='Challenge_participation_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(\n",
    "    path_result_rq1, 'Challenge_participation_count_distribution.png'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
