{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import openai\n",
    "import textstat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The significance level indicates the probability of rejecting the null hypothesis when it is true.\n",
    "alpha = 0.05\n",
    "\n",
    "link_pattern = r'https?://[^\\s]+'\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None, 'display.max_colwidth', None)\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY', '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')\n",
    "\n",
    "keywords_patch = {\n",
    "    'pull',\n",
    "}\n",
    "\n",
    "keywords_issue = {\n",
    "    'answers',\n",
    "    'discussions',\n",
    "    'forums',\n",
    "    'issues',\n",
    "    'questions',\n",
    "    'stackoverflow',\n",
    "}\n",
    "\n",
    "keywords_tool = {\n",
    "    'github',\n",
    "    'gitlab',\n",
    "    'pypi',\n",
    "}\n",
    "\n",
    "keywords_doc = {\n",
    "    'developers',\n",
    "    'docs',\n",
    "    'documentation',\n",
    "    'features',\n",
    "    'library',\n",
    "    'org',\n",
    "    'wiki',\n",
    "}\n",
    "\n",
    "keywords_tutorial = {\n",
    "    'guide',\n",
    "    'learn',\n",
    "    'tutorial',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_result = '../../Result'\n",
    "\n",
    "path_result_rq1 = os.path.join(path_result, 'RQ1')\n",
    "path_code_rq1 = os.path.join('..', 'RQ1')\n",
    "\n",
    "path_general_output = os.path.join(path_result_rq1, 'General Topics')\n",
    "path_special_output = os.path.join(path_result_rq1, 'Special Topics')\n",
    "\n",
    "path_general_topic = os.path.join(path_code_rq1, 'General Topic Modeling')\n",
    "path_special_topic = os.path.join(path_code_rq1, 'Special Topic Modeling')\n",
    "\n",
    "path_anomaly = os.path.join(path_special_topic, 'Anomaly')\n",
    "path_root_cause = os.path.join(path_special_topic, 'Root Cause')\n",
    "path_solution = os.path.join(path_special_topic, 'Solution')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: Model Management - Handling and manipulation of models including training, saving, importing, and exporting.\n",
      "Topic 1: Data Pipelining - The process of managing and processing data through multiple pipelines.\n",
      "Topic 2: Package Installation - The process of installing, importing, and managing software packages using pip.\n",
      "Topic 3: Logging - The process of creating, tracking, and managing logs during model training.\n",
      "Topic 4: Docker Operations - Building, running, and managing Docker images and files.\n",
      "Topic 5: Access Management - Managing access permissions, roles, and tokens for secure operations.\n",
      "Topic 6: Data Labeling - The process of labeling data for training and object recognition.\n",
      "Topic 7: Git Operations - Managing data, files, and version control using Git.\n",
      "Topic 8: Bucket Operations - Managing files, data, and paths in storage buckets.\n",
      "Topic 9: Sweep Operations - Configuring, running, and managing multiple sweeps.\n",
      "Topic 10: Quota Management - Managing request quotas and handling limit exceptions.\n",
      "Topic 11: Remote Operations - Configuring, running, and connecting to remote files and executions.\n",
      "Topic 12: Batch Processing - Managing and processing data, files, and jobs in batches.\n",
      "Topic 13: Lambda Functions - Invoking and processing data using Lambda functions.\n",
      "Topic 14: Database Operations - Connecting, importing, and running operations on databases.\n",
      "Topic 15: Language Translation - Translating documents and languages using models.\n",
      "Topic 16: Panda Operations - Managing and converting files using Panda.\n",
      "Topic 17: Speech Processing - Handling audio files, generating speech, and transcribing services.\n",
      "Topic 18: Spark Operations - Configuring, implementing, and managing data using Spark.\n",
      "Topic 19: Instance Management - Creating, managing, and removing instances.\n",
      "Topic 20: Column Operations - Managing, cleaning, and visualizing data in columns.\n"
     ]
    }
   ],
   "source": [
    "prompt_topic = '''You will be given a list of stemmed words refering to specific software engineering topics. Please summarize each topic in terms and attach a one-liner description based on the stemmed words. Also, you must guarantee that the summaries are exclusive to one another.###\\n'''\n",
    "\n",
    "with open(os.path.join(path_general_topic, 'Topic terms.pickle'), 'rb') as handle:\n",
    "    topic_terms = pickle.load(handle)\n",
    "\n",
    "    topic_term_list = []\n",
    "    for index, topic in enumerate(topic_terms):\n",
    "        terms = ', '.join([term[0] for term in topic])\n",
    "        topic_term = f'Topic {index}: {terms}]'\n",
    "        topic_term_list.append(topic_term)\n",
    "\n",
    "    prompt = prompt_topic + '\\n'.join(topic_term_list) + '\\n###\\n'\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "        temperature=0,\n",
    "        max_tokens=3000,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        timeout=300,\n",
    "        stream=False)\n",
    "\n",
    "    topics = completion.choices[0].message.content\n",
    "    print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1: 'NA',\n",
       " 0: 'Model Management',\n",
       " 1: 'Pipeline Configuration',\n",
       " 2: 'Package Management',\n",
       " 3: 'Log Management',\n",
       " 4: 'Docker Configuration',\n",
       " 5: 'Access Control',\n",
       " 6: 'Label Management',\n",
       " 7: 'Git Configuration',\n",
       " 8: 'Bucket Management',\n",
       " 9: 'Sweep Management',\n",
       " 10: 'Quota Management',\n",
       " 11: 'Remote Configuration',\n",
       " 12: 'Batch Processing',\n",
       " 13: 'Lambda Configuration',\n",
       " 14: 'Database Management',\n",
       " 15: 'Language Translation',\n",
       " 16: 'Tabular Data Manipulation',\n",
       " 17: 'Speech Processing',\n",
       " 18: 'Spark Configuration',\n",
       " 19: 'Instance Management',\n",
       " 20: 'Columnar Data Manipulation'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = '''Topic 0: Model Management - Handling and manipulation of models including training, saving, importing, and exporting.\n",
    "Topic 1: Pipeline Configuration - The process of managing and processing data through multiple pipelines.\n",
    "Topic 2: Package Management - The process of installing, importing, and managing software packages using pip.\n",
    "Topic 3: Log Management - The process of creating, tracking, and managing logs during model training.\n",
    "Topic 4: Docker Configuration - Building, running, and managing Docker images and files.\n",
    "Topic 5: Access Control - Managing access permissions, roles, and tokens for secure operations.\n",
    "Topic 6: Label Management - The process of creating, adding, and modifying labels for raw data.\n",
    "Topic 7: Git Configuration - Managing data, files, and version control using Git.\n",
    "Topic 8: Bucket Management - Managing files, data, and paths in storage buckets.\n",
    "Topic 9: Sweep Management - Configuring, running, and managing multiple sweeps.\n",
    "Topic 10: Quota Management - Managing request quotas and handling limit exceptions.\n",
    "Topic 11: Remote Configuration - Configuring, running, and connecting to remote files and executions.\n",
    "Topic 12: Batch Processing - Managing and processing data, files, and jobs in batches.\n",
    "Topic 13: Lambda Configuration - Invoking and processing data using Lambda functions.\n",
    "Topic 14: Database Management - Connecting, importing, and running operations on databases.\n",
    "Topic 15: Language Translation - Translating documents and languages using models.\n",
    "Topic 16: Tabular Data Manipulation - Managing and converting files using Pandas.\n",
    "Topic 17: Speech Processing - Handling audio files, generating speech, and transcribing services.\n",
    "Topic 18: Spark Configuration - Configuring, implementing, and managing data using Spark.\n",
    "Topic 19: Instance Management - Creating, managing, and removing instances.\n",
    "Topic 20: Columnar Data Manipulation - Managing, cleaning, and visualizing data in columns.'''\n",
    "\n",
    "index = 0\n",
    "topic_dict = {-1: 'NA'}\n",
    "\n",
    "for topic in topics.split('\\n'):\n",
    "    topic_dict[index] = topic.split('-')[0].split(':')[-1].strip()\n",
    "    index += 1\n",
    "    \n",
    "topic_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pip instal, instal pip, instal packag, packag instal, pip environ, packag pip, import instal, pip packag, instal import, import packagdocker imag, build docker, docker build, docker file, imag docker, run docker, file docker, docker run, built docker, docker dockerinvok lambda, data lambda, lambda process, function lambda, lambda function, job lambda, lambda lambda, model lambda, infer lambda, lambdainstanc creat, creat instanc, type instanc, instanc instanc, instanc type, regular instanc, model instanc, instanc modul, stop instanc, instanc remov'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(path_general_topic, 'Topic terms.pickle'), 'rb') as handle:\n",
    "    topic_terms = pickle.load(handle)\n",
    "\n",
    "    terms = ''\n",
    "    for index, topic in enumerate(topic_terms):\n",
    "        if index in [2, 4, 19, 13]:\n",
    "            terms += ', '.join([term[0] for term in topic])\n",
    "terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Access Control': 1,\n",
       " 'Remote Configuration': 1,\n",
       " 'Git Configuration': 8,\n",
       " 'Batch Processing': 2,\n",
       " 'Spark Configuration': 2,\n",
       " 'Sweep Management': 2,\n",
       " 'Bucket Management': 3,\n",
       " 'Columnar Data Manipulation': 3,\n",
       " 'Database Management': 3,\n",
       " 'Label Management': 3,\n",
       " 'Tabular Data Manipulation': 3,\n",
       " 'Package Management': 4,\n",
       " 'Docker Configuration': 4,\n",
       " 'Instance Management': 4,\n",
       " 'Lambda Configuration': 4,\n",
       " 'Pipeline Configuration': 7,\n",
       " 'Model Management': 5,\n",
       " 'Log Management': 6,\n",
       " 'Quota Management': 6}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_topic_mapping_inverse = {\n",
    "    # These topics are all related to the management of permissions and connectivity.\n",
    "    1: ('Access Management', ['Access Control', 'Remote Configuration']),\n",
    "    # These topics are all related to the management of source code.\n",
    "    8: ('Code Management', ['Git Configuration']),\n",
    "    # These topics are all related to the management of data and datasets.\n",
    "    2: ('Compute Management', ['Batch Processing', 'Spark Configuration', 'Sweep Management']),\n",
    "    # These topics are all related to the management of services.\n",
    "    3: ('Data Management', ['Bucket Management', 'Columnar Data Manipulation', 'Database Management', 'Label Management', 'Tabular Data Manipulation']),\n",
    "    # These topics are all related to the management of packages and distributions.\n",
    "    4: ('Environment Management', ['Package Management', 'Docker Configuration', 'Instance Management', 'Lambda Configuration']),\n",
    "    # These topics are all related to the management of pipelines.\n",
    "    7: ('Lifecycle Management', ['Pipeline Configuration']),\n",
    "    # These topics are all related to the management of machine learning models.\n",
    "    5: ('Model Management', ['Model Management']),\n",
    "    # These topics are all related to the management of logs and metrics.\n",
    "    6: ('Performance Management', ['Log Management', 'Quota Management']),\n",
    "}\n",
    "\n",
    "macro_topic_mapping = {}\n",
    "macro_topic_index_mapping = {}\n",
    "for key, (macro_topic, topics) in macro_topic_mapping_inverse.items():\n",
    "    macro_topic_index_mapping[macro_topic] = key\n",
    "    for topic in topics:\n",
    "        macro_topic_mapping[topic] = key\n",
    "\n",
    "macro_topic_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Number</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Access Management</td>\n",
       "      <td>872</td>\n",
       "      <td>7.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Compute Management</td>\n",
       "      <td>1106</td>\n",
       "      <td>9.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Management</td>\n",
       "      <td>1460</td>\n",
       "      <td>13.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deployment Management</td>\n",
       "      <td>2730</td>\n",
       "      <td>24.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Model Management</td>\n",
       "      <td>2378</td>\n",
       "      <td>21.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Performance Management</td>\n",
       "      <td>1122</td>\n",
       "      <td>10.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lifecycle Management</td>\n",
       "      <td>1105</td>\n",
       "      <td>9.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Code Management</td>\n",
       "      <td>344</td>\n",
       "      <td>3.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Topic  Number  Percentage\n",
       "0       Access Management     872        7.84\n",
       "1      Compute Management    1106        9.95\n",
       "2         Data Management    1460       13.13\n",
       "3   Deployment Management    2730       24.56\n",
       "4        Model Management    2378       21.39\n",
       "5  Performance Management    1122       10.09\n",
       "6    Lifecycle Management    1105        9.94\n",
       "7         Code Management     344        3.09"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign human-readable & high-level topics to challenges & solutions\n",
    "\n",
    "df = pd.read_json(os.path.join(path_general_output, 'topics.json'))\n",
    "df['Challenge_topic_macro'] = -1\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if topic_dict[row['Challenge_topic']] in macro_topic_mapping:\n",
    "        df.at[index, 'Challenge_topic_macro'] = macro_topic_mapping[topic_dict[row['Challenge_topic']]]\n",
    "    else:\n",
    "        df.drop(index, inplace=True)\n",
    "\n",
    "df.to_json(os.path.join(path_general_output, 'filtered.json'), indent=4, orient='records')\n",
    "\n",
    "def minimize_weighted_sum(df):\n",
    "    df_new = df.sort_values('Number', ascending=False)\n",
    "    n = len(df)\n",
    "    center_idx = (n - 1) // 2\n",
    "    direction = -1\n",
    "    distance = 0\n",
    "\n",
    "    for _, row in df_new.iterrows():\n",
    "        # Calculate the new index\n",
    "        new_idx = center_idx + direction * distance\n",
    "        \n",
    "        # Place the element from the sorted list into the new list\n",
    "        df.iloc[new_idx] = row\n",
    "\n",
    "        # If we've just moved to the left, increase the distance\n",
    "        if direction == -1:\n",
    "            distance += 1\n",
    "\n",
    "        # Switch the direction\n",
    "        direction *= -1\n",
    "\n",
    "    return df\n",
    "\n",
    "df_number = pd.DataFrame()\n",
    "for key, (macro_topic, topics) in macro_topic_mapping_inverse.items():\n",
    "    entry = {\n",
    "        'Topic': macro_topic,\n",
    "        'Number': len(df[df[\"Challenge_topic_macro\"] == key]),\n",
    "        'Percentage': round(len(df[df[\"Challenge_topic_macro\"] == key]) / len(df) * 100, 2),\n",
    "    }\n",
    "    df_number = pd.concat([df_number, pd.DataFrame([entry])], ignore_index=True)\n",
    "\n",
    "minimize_weighted_sum(df_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "# df['Challenge_topic_macro'] = -1\n",
    "# for index, row in df.iterrows():\n",
    "#     if topic_dict[row['Challenge_topic']] in macro_topic_mapping:\n",
    "#         df.at[index, 'Challenge_topic_macro'] = macro_topic_mapping[topic_dict[row['Challenge_topic']]]\n",
    "#     else:\n",
    "#         df.drop(index, inplace=True)\n",
    "\n",
    "# df.to_json(os.path.join(path_special_output, 'labels.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(os.path.join(path_general_output, 'filtered.json'))\n",
    "\n",
    "df['Challenge_type'] = 'na'\n",
    "df['Challenge_summary'] = 'na'\n",
    "df['Challenge_root_cause'] = 'na'\n",
    "df['Challenge_solution'] = 'na'\n",
    "\n",
    "df.to_json(os.path.join(path_special_output, 'labels.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# df = pd.read_json(os.path.join(path_general_output, 'filtered.json'))\n",
    "\n",
    "# df['Challenge_type'] = np.nan\n",
    "# df['Challenge_summary'] = np.nan\n",
    "# df['Challenge_root_cause'] = np.nan\n",
    "# df['Challenge_solution'] = np.nan\n",
    "\n",
    "# df.to_json(os.path.join(path_special_output, 'labels+.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     if (row['Challenge_root_cause'] != 'na') and (row['Challenge_root_cause'] == row['Challenge_summary']):\n",
    "#         df.at[index, 'Challenge_root_cause'] = 'na'\n",
    "#     if (row['Challenge_root_cause'] != 'na') and (row['Challenge_root_cause'] == row['Challenge_solution']):\n",
    "#         print(row['Challenge_root_cause'])\n",
    "        \n",
    "# df.to_json(os.path.join(path_special_output, 'labels.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "\n",
    "# df['Challenge_summary'] = df['Challenge_summary'].str.lower()\n",
    "# df['Challenge_root_cause'] = df['Challenge_root_cause'].str.lower()\n",
    "# df['Challenge_solution'] = df['Challenge_solution'].str.lower()\n",
    "\n",
    "# df.to_json(os.path.join(path_special_output, 'labels.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "\n",
    "# regex_digit = r\"[0-9]\"\n",
    "\n",
    "# regex_error = r\"[a-zA-Z0-9]+[eE]rror[^a-zA-Z]\"\n",
    "# regex_exception = r\"[a-zA-Z0-9]+[eE]xception[^a-zA-Z]\"\n",
    "\n",
    "# regex_error_leading = r\"[a-zA-Z0-9]+[eE]rror[a-zA-Z]+\"\n",
    "# regex_exception_leading = r\"[a-zA-Z0-9]+[eE]xception[a-zA-Z]+\"\n",
    "\n",
    "# false_positive_list = []\n",
    "\n",
    "# def camel_case_split(str):\n",
    "#     words = [[str[0].lower()]]\n",
    " \n",
    "#     for c in str[1:]:\n",
    "#         if (words[-1][-1].islower() or words[-1][-1].isdigit()) and c.isupper():\n",
    "#             words.append(list(c.lower()))\n",
    "#         else:\n",
    "#             words[-1].append(c)\n",
    "#     return ' '.join([''.join(word) for word in words])\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     challenge = row['Challenge_title'] + ' ' + row['Challenge_body']\n",
    "#     challenge = challenge.replace('\\n', ' ')\n",
    "#     error_list = re.findall(regex_error, challenge)\n",
    "#     if len(error_list):\n",
    "#         if row['Challenge_type'] != 'anomaly':\n",
    "#             df.at[index, 'Challenge_type'] = 'anomaly'\n",
    "#             false_positive_list.append(row['Challenge_link'])\n",
    "#         error = max(error_list, key = len)\n",
    "#         if len(re.findall(regex_digit, error)):\n",
    "#             print(row['Challenge_title'])\n",
    "#         else:\n",
    "#             error = re.sub(r'error.+', 'error', camel_case_split(error))\n",
    "#             df.at[index, 'Challenge_summary'] = error\n",
    "#     else:\n",
    "#         exception_list = re.findall(regex_exception, challenge)\n",
    "#         if len(exception_list):\n",
    "#             if row['Challenge_type'] != 'anomaly':\n",
    "#                 df.at[index, 'Challenge_type'] = 'anomaly'\n",
    "#                 false_positive_list.append(row['Challenge_link'])\n",
    "#             exception = max(exception_list, key = len)\n",
    "#             if len(re.findall(regex_digit, exception)):\n",
    "#                 print(row['Challenge_title'])\n",
    "#             else:\n",
    "#                 exception = re.sub(r'exception.+', 'exception', camel_case_split(exception))\n",
    "#                 df.at[index, 'Challenge_summary'] = exception\n",
    "#         else:\n",
    "#             error_list_leading = re.findall(regex_error_leading, challenge)\n",
    "#             if len(error_list_leading):\n",
    "#                 print(row['Challenge_title'])\n",
    "#             else:\n",
    "#                 exception_list_leading = re.findall(regex_exception_leading, challenge)\n",
    "#                 if len(exception_list_leading):\n",
    "#                     print(row['Challenge_title'])\n",
    "                    \n",
    "# df.to_json(os.path.join(path_special_output, 'anomaly.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker TuningStep Fails to Download Source Code\n",
      "Sagemaker endpoint fails to respond then PipeModeDataset is used\n",
      "run-notebook command not found after install sagemaker-run-notebook\n",
      "[Error] Notebook: sentiment-analysis.ipynb in SageMaker Studio with kernel Python3 (Tensorflow2 GPU Optimized)\n",
      "Question : how/when is source_dir copied into the sagemaker training instance?\n",
      "Output 'SageMakerRoleArn' not found in stack\n",
      "How to verify pytorch model inference is running on Inf1 sagemaker endpoint properly\n",
      "Sagemaker Neo Compilation for ARM64\n",
      "Loading DLR models compiled with Sagemaker Neo\n",
      "Broken link for Azure ML on https://docs.fast.ai/\n",
      "[BUG] Broken link (run_notebook_on_azureml) in readme\n",
      "ImportError: No module named 'azureml.core'\n",
      "command 'vscodeai.azureml.toolbar.submit' not found\n",
      "Command 'Azure ML: Connect to Compute Instance' resulted in an error \n",
      "import `Workspace` in Azure ML\n",
      "MLOps with Azure Machine Learning Service and Azure DevOps workshop guide is not available\n",
      "clearml.storage - ERROR - Google cloud driver not found\n",
      "I am getting a lot of errors while running dvc repro especially for fake_news module not found\n",
      "kedro airflow plugins: ValueError Pipeline input(s) not found in the DataCatalog\n",
      "Kedro executable not found in docker image\n",
      "MLflow support for conda-pack environments\n",
      "Test failed on `pytest -s python/tests/spark/sql/codegen/test_mlflow_registry.py::test_mlflow_model_from_model_version`\n",
      "[DOC-FIX] `model_store` different between torchserve and mlflow-torchserve\n",
      "MLflow Server EKS Service API 500\n",
      "MLflow EKS Service API 500\n",
      "No default MLFlow run to serve\n",
      "Experiment entry not found in MLFlow\n",
      "mlflow.exceptions.MlflowException: Run 'LIFFireNet' not found\n",
      "Unable to `pip` install - mlflow_tools/make_exps_page doesn't exist\n",
      "mlflow sagemaker build-and-push-container gives executor failed running exit code 127\n",
      "wandb: ERROR Error while calling W&B API: project not found (<Response [404]>) \n",
      "wandb logging does not seem to work (on Colab at least)\n",
      "requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://api.wandb.ai/graphql\n",
      "Error with wandb\n",
      "wandb error\n",
      "get_wandb_logger fails to retrieve WandbLogger when debug=True\n",
      "Reading Mp3 files from S3 to Sagemaker for feature extraction using LIBROSA\n",
      "Invoice parser \"invents\" non-existing string for supplier_name normalized value\n",
      "Error 404: AciDeploymentFailed\n",
      "How to get root access in SageMaker Studio Lab\n",
      "When pretrained model is not found, sagemaker falls into an infinite silent loop\n",
      "Sagemaker notebooks raise error for `pandas.CSVDataSet`\n",
      "[Bug] study fail to mount in SWB 5.2.6 SageMaker Jupyter Notebook\n",
      "[BUG] Error in some of the AzureML tests\n",
      "error when installing AZURE ML training model piece\n",
      "Fix the definition of pipelines/sentence_embedding/dvc.yaml\n",
      "dvc servername and url not found by calling \"dvc-cc run\"\n",
      "Can not create model in MLflowCatalog\n",
      "dbx deploy fails due to mlflow experiment not found\n",
      "[BUG]: Unable to Start DFP Production MLFlow Server\n",
      "running mlflow>1.28 projects causes mlflow not found error\n",
      "[mlflow] Run chart-testing (lint) step returns Error validating maintainer 404 Not Found error\n",
      "MLFlow and Hydra causing crash when used together\n",
      "Programmatically enable installed extensions in Vertex AI Managed Notebook instance\n",
      "Install Python Packages in Azure ML?\n",
      "Broken DAG: urllib3 1.25.3 (/home/ubuntu/.local/lib/python3.7/site-packages), Requirement.parse('urllib3<1.25,>=1.21'), {'sagemaker'}\n",
      "Is it possible to check that the version of a file tracked by a DVC metadata file exists in remote storage without pulling the file?\n",
      "GCP AI Platform Vertex endpoint model undeploy : 404 The DeployedModel with ID `2367889687867` is missing\n",
      "Is there a way to pass arguments to our own docker container in sagemaker?\n",
      "Kedro can not find SQL Server table\n",
      "No such file or directory: 'docker': 'docker' when running sagemaker studio in local mode\n",
      "sudo: not found on AWS Sagemaker Studio\n",
      "Using Sacred Module with iPython\n",
      "Azure ML endpoint 404 error\n",
      "Google Cloud Vertex AI with Golang: rpc error: code = Unimplemented desc = unexpected HTTP status code received from server: 404 (Not Found)\n",
      "Error Tracking in Amazon SageMaker\n",
      "Error in connecting Azure SQL database from Azure Machine Learning Service using python\n",
      "In GCP Vertex AI, why is Delete Training Pipeline REST endpoint unimplemented?\n",
      "Trying to work on R using Azure ML Studio Notebook and facing challenges with ODBC package\n",
      "Problem trying to authenticate with bearer token on nginx + oauth2-proxy + docker\n",
      "Failed ping healthcheck after deploying TF2.1 model with TF-serving-container on AWS Sagemaker\n",
      "Pycaret MlFlow authentication\n",
      "AWS SageMaker Studio Lab - Permission denied\n",
      "mlflow static_prefix url in set_tracking_uri is not working\n",
      "azureml how to deploy docker image to webservice\n",
      "i am getting error when deploying machine learning model in aci\n",
      "Model.get_model_path(model_name=\"model\") throws an error: Model not found in cache or in root at\n",
      "How do you use pyodbc in Azure Machine Learning Workbench\n",
      "Mlflow download_artifacts giving Not Found error\n",
      "Sagemaker deploy model with inference code and requirements\n",
      "\"Entry Point Not Found\" Error LightGBM R package in Azure\n",
      "How to save parquet in S3 from AWS SageMaker?\n",
      "Why can't I access Output from Vertex pipeline kfp component?\n",
      "How to deploy a detectron2 model using file in azureML\n",
      "install python package in Azure ml\n",
      "Automatically Install OpenJDK into SageMaker Notebook\n",
      "jsonschema 4.4.0 does not provide the extra 'isoduration'\n",
      "Readding missing files to DVC\n",
      "Kubeflow vs Vertex AI Pipelines\n",
      "Sagemaker batch transform \"ValueError: could not convert string to float\"\n",
      "How to mock an S3AFileSystem locally for testing spark.read.csv with pytest?\n",
      "BERT model loading not working with pytorch 1.3.1-eia container\n",
      "Sagemaker directory opt/ml/models does not store models to load them for inference\n",
      "Google.Cloud.AIPlatform.V1 Received http2 header with status: 404\n",
      "SageMaker deploy error \"serve\" executable file not found in $PATH\n",
      "Ensure Java is installed and PATH is set for `java` in Amazon SageMaker Jupyter Notebook\n",
      "Wandb line plots only show bar charts after refresh\n",
      "pyodbc not working in web-service container, Azure Model Management\n",
      "mlflow / app engine error code 405 method not allowed, when using remote tracking server\n",
      "MLFlow - running \"mlflow ui\" throwing file not found error on windows 10\n",
      "Sagemaker: Specifying custom entry point gives not found error\n",
      "Job submittal fails with : CondaHTTPError: HTTP 000 CONNECTION FAILED\n",
      "Import azure.core not found issue in running Notebook through MachineLearningStudio\n",
      "Installing additional R package (ImputeTS R Package) in Azure ML\n",
      "How should Pubsub, acting a log sink, fire a function without sending the log?\n",
      "AWS Sagemaker : No response back from the endpoint \"HTTP 301 293\"\n",
      "How to specify a name for the output file of a SageMaker Batch Transform job?\n",
      "mlflow Exception: Run with UUID is already active\n",
      "How to serve daily precomputed predictions in aws sagemaker?\n",
      "Still on ML-Flow installation in R Studio\n",
      "Vertex Pipeline Metric values not being added to metrics artifact?\n",
      "Automatic hyperparameter tuning in Sagemaker aws failed to run\n",
      "Set up health check for Sagemaker endpoint in Postman\n",
      "Deploying Huggingface model for inference - pytorch-scatter issues\n",
      "Azure ML Internal Server Error and 404 Error\n",
      "How to connect AzureML (Machine Learning) with AzureVM (Virtual Machine)?\n",
      "Sagemaker AlgorithmError: ExecuteUserScriptError:\n",
      "SagemakerTraining job catboost-classification-model , ErrorMessage \"TypeError: Cannot convert 'xxx'' to float\n",
      "Unable to access to mlflow ui\n",
      "Trying to query Azure SQL Database with Azure ML / Docker Image\n",
      "IDtoken retrieval in Vertex AI pipeline fails randomly\n",
      "No such file or directory: '/opt/ml/input/data/test/revenue_train.csv' Sagemaker [SM_CHANNEL_TRAIN]\n",
      "Can't access mounted Dataset on Azure Machine Learning Service Notebook\n",
      "PartitionedDataSet not found when Kedro pipeline is run in Docker\n",
      "SageMaker Studio Image - pip not found and no python 3 in terminal for Python 3 notebook instance\n",
      "sagmaker deploy() model gives error exec: \"serve\": executable file not found in $PATH\n",
      "How to use AWS Sagemaker XGBoost framework?\n",
      "How to delete a run_id from MLflow\n",
      "How to Set Java Home for Notebook in SageMaker\n",
      "Using ipyleaflet within a Vertex AI Managed Notebook running on a Docker image\n",
      "ERROR:root:Line magic function `%azureml` not found?\n",
      "Store scaler with mlflow keras-model\n",
      "MLflow saves models to relative place instead of tracking_uri\n",
      "How to observe and control how sagemaker multimodel server loads models in memory\n",
      "Read MobileNetSSd model files from azure ML Registered Models\n",
      "xgboost model prediction error : Input numpy.ndarray must be 2 dimensional\n",
      "How to load data from your S3 bucket to Sagemaker jupyter notebook to train the model?\n",
      "\"list index out of range\" error in AzureML inference schema\n",
      "Cannot use tensorboard with Vertex AI Custom job\n",
      "502 bad gateway error with upstream prematurely closed connection?\n",
      "AWS SageMaker models popping in and out of the vacuum\n",
      "Azure ML model deployment fail: Module not found error\n",
      "Sagemaker Batch Transform Error \"Model container failed to respond to ping; Ensure /ping endpoint is implemented and responds with an HTTP 200 status\"\n",
      "AzureML Model.profile() timeout without ever running the model\n",
      "Kedro 0.16.3 and kedro[spark.SparkDataSet] pip libraries cannot be installed together on databricks cluster\n",
      "%run works only once in Jupyter Notebook\n",
      "Amazon sagemaker Lifecycle configuration not working\n",
      "Azure Machine Learning: Remove pre-installed R packages\n",
      "How best to install dependencies in a Sagemaker PySpark cluster\n",
      "TemplatedConfigLoader in register_config_loader not replacing patterns in catalog.yml (kedro)\n",
      "Wandb throws Permission denied error although I am logged in\n",
      "Vertex AI Pipelines (Kubeflow) skip step with dependent outputs on later step\n",
      "How to upload .r file into azure ml studio and run it?\n",
      "No GPU detected on AWS SageMaker pytorch-1.8-gpu-py36 instance\n",
      "Azure ML Studio cannot load a installed package in R\n",
      "Can't connect to Azure ML Web Service in Azure Data Factory\n",
      "Load/access/mount directory to aws sagemaker from S3\n",
      "Cannot use `gcloud auth print-identity-token` from within Vertex AI Custom Job\n",
      "Mlflow not running on machine\n",
      "sagemaker batch transform breaks with upstream prematurely closed connection while reading upstream\n",
      "How can I use GPUs on Azure ML with a NVIDIA CUDA custom docker base image?\n",
      "AWS Sagemaker InvokeEndpoint: operation: Endpoint of account not found\n",
      "Converting PDF and PPTX files drawn from S3 into a JPG format\n",
      "Model pkl not found by SageMaker inference\n",
      "Vertex AI - Deployment failed\n",
      "Missing delimiter error when importing html text\n",
      "Installing private python wheel from a storage account\n",
      "Error loading model from mlflow: java.io.StreamCorruptedException: invalid type code: 00\n",
      "How to submit local jobs with dsl.pipeline\n",
      "Cannot import librosa on SageMaker Jupyter notebook instance \"OSError: sndfile library not found\"\n",
      "SageMaker Batch Transform fails to access nginx\n",
      "Getting this weird error when trying to run DVC pull\n",
      "AWS Sagemaker Spark S3 access issue\n",
      "Error in running Azure Data Factory Pipeline. Linked Service Reference not found\n",
      "AWS Lambda send image file to Amazon Sagemaker\n",
      "How do I setup the _SERVER_MODEL_PATH variable?\n",
      "In Azure ML - After Web service deployment, getting column name not found error\n",
      "how to use kedro.versioning in latest version of kedro?\n",
      "Azure ML R Model Train & Score Web Service\n",
      "Sagemaker suddenly unable to install python packages, missing python-dev\n",
      "How to deploy multiple ml models with scoring file using azure ml cli\n",
      "MLflow 1.2.0 define MLproject file\n",
      "Unable to connect Mlflow server to my mlflow project image\n",
      "AzureML schema \"list index out of range\" error\n",
      "Can't find scoring.py when using PythonScriptStep() in Databricks\n",
      "Facing this error : container_linux.go:367: starting container process caused: exec: \"python\": executable file not found in $PATH: unknown\n",
      "Creating a dataframe in Azure ML Notebook with R kernel\n",
      "Azure: importing not already existing packages in 'src'\n",
      "Running mlflow as a systemd service - gunicorn not found\n",
      "AWS CreateDeviceFleet operation fail because \"the account id does not have ownership on bucket\"\n",
      "Blankspace and colon not found in firstline\n",
      "Uniquely identify instances of VMs (Azure ML - web services)\n",
      "sagemaker notebook instance Elastic Inference tensorflow model local deployment\n",
      "Run !docker build from Managed Notebook cell in GCP Vertex AI Workbench\n",
      "How to avoid error \"conda --version: conda not found\" in az ml run --submit-script command?\n",
      "Is it possible to \"apt install\" in SageMaker Studio Lab?\n",
      "AWS Sagemaker + AWS Lambda\n",
      "Where to perform the saving of an nodeoutput in Kedro?\n",
      "Installing additional R Package on Azure ML\n",
      "Unable to use GPU to train a NN model in azure machine learning service using P100-NC6s-V2 compute. Fails wth CUDA error\n",
      "Amazon SageMaker: ClientError: Data download failed:NoSuchKey (404): The specified key does not exist\n",
      "Vertex AI Custom Container Training Job python SDK - google.api_core.exceptions.FailedPrecondition: 400 '\n",
      "Jobs-Cloud Scheduler (Google Cloud) fails to run scheduled pipelines\n",
      "kedro context and catalog missing from ipython session\n",
      "How to install OpenJDK library?\n",
      "how to set path of bucket in amazonsagemaker jupyter notebook?\n",
      "Adding a {serve} metagraph to existing Tensorflow model\n",
      "mlflow serving r models failed if use LDA instead of linear regression\n",
      "Azure ML Online Endpoint deployment DriverFileNotFound Error\n",
      "Errors while using sagemaker api to invoke endpoints\n",
      "How combine results from multiple models in Google Vertex AI?\n",
      "How to explicitly set sagemaker autopilot's validation set?\n",
      "Gluonnlp installation not found on Sagemaker jupyter notebook\n",
      "Compare String with list of strings in bash\n",
      "AzureML Environment for Inference : can't add pip packages to dependencies\n",
      "SQLAlchemy Oracle - InvalidRequestError: could not retrieve isolation level\n",
      "how SageMaker to access s3 bucket data\n",
      "Failed to pull existing files from SSH DVC Remote\n",
      "'azureml.logging' module not found\n",
      "Vertex AI custom prediction vs Google Kubernetes Engine\n",
      "Reading File from Vertex AI and Google Cloud Storage\n",
      "cloud 9 and sagemaker - hyper parameter optimisation\n",
      "AWS SageMaker S3 os.listdir() Access denied\n",
      "Docker image not found during local deployment (\"no such image\")\n",
      "How do you write lifecycle configurations for SageMaker on windows?\n",
      "What is the name of the driver to connect to Azure SQL Database from pyodbc in Azure ML?\n",
      "Is there a way to un-register an environment in Azure ML studio\n",
      "Azure-ML Deployment does NOT see AzureML Environment (wrong version number)\n",
      "How can we get the pipeline to read columns with special characters?\n",
      "how create azure machine learning scoring image using local package\n",
      "Simple but frustrating error: Google.cloud module not found\n",
      "Custom container image not found by Vertex AI for model upload\n",
      "Sweep creation down? (Resolved)\n",
      "404 response executing GraphQL\n",
      "Agent bug? File not found error\n",
      "404 error running sweep from local jupyter nb\n",
      "I think that W&B is having some connection issues since yesterday night\n",
      "ModuleNotFoundError: No module named 'nvgpu' in sagemaker batch transform\n",
      "install java dependency when building my own processing container\n",
      "Java not found when running Sagemaker Studio python notebooks\n",
      "Batch transform step not working\n",
      "Sagemaker Neo compilation fails\n",
      "NVMLError_FunctionNotFound: I was trying to deploy a PyTorch model in a ml.g4dn.xlarge instance\n",
      "Unable to select a compute type in SageMaker Studio Lab\n",
      "Sagemaker Batch Transform - \"upstream prematurely closed connection\" - Unable to serve requests that take longer than 30 minutes\n",
      "Issues with exposing SKLearn model as endpoint on AWS Sagemaker\n",
      "Error Creating Endpoint\n",
      "SQL Server driver issue on notebook instance running on AWS SageMaker\n",
      "No such file or directory: '/opt/ml/input/data/test/revenue_train.csv' Sagemaker [SM_CHANNEL_TRAIN]\n",
      "Error for Training job catboost-classification-model , ErrorMessage \"TypeError: Cannot convert 'xxx'' to float\n",
      "Sagemaker Endpoint is not created when deploying HuggingFace Model using it.\n",
      "Export Autopilot model to GovCloud region\n",
      "passing a numpy array to predict_fn when making inference for xgboost model\n",
      "Failed ping healthcheck after deploying TF2.1 model with TF-serving-contain\n",
      "Custom packages in Sagemaker studio\n",
      "Trouble deploying SageMaker trained model in DeepLens\n",
      "ERROR: unexpected error - [Errno 2] No such file or directory:\n",
      "Dvc remote drive\n",
      "Cannot apply the first exp after new commit\n",
      "I have added my google drive as a remote storage\n",
      "DVC list shows libssl-so.1.1.1k not found\n",
      "Problem with top-level plot definitions\n",
      "SSH remote: unexpected error - Permission denied\n",
      "What to do if the file is not found in the repo?\n",
      "Track remote data on Azure\n",
      "Can't go to former version of dataset with `dvc checkout`\n",
      "Documentation: tutorial problem?\n",
      "How to save or log pytorch model using MLflow?\n",
      "Local run in azureml sdk2\n",
      "Missing ODBC drivers in Azure ML Compute Instances\n",
      "Bing Search API not working\n",
      "How to fix Apply Transformation error?\n",
      "how to modify the template script on azure auto ml?\n",
      "While running an Azure ML Experiement, I get \"File Not found\" error when attempting to find ODBC driver for python pyodbc.connect command\n",
      "ClusterIdentityNotFound when submitting experiment.\n",
      "Using Azure ML Studio Designer with R script: package not found but I installed it on the compute instance\n",
      "Azure ML Studio can't generate job when datastore is used as input; failed string validation? Also, code files not being loaded on job.\n",
      "How to  give Source Directory on the step pipeline in Azure Machine Learning\n",
      "Azure machine learning samples 404\n",
      "Error 404 for design pipelines\n",
      "Pickle Load- File Not Found when deploying using Azure ML Studio\n",
      "azure machine learning SubscriptionNotFound\n",
      "Swagger file not present -- Azure Machine Learning\n",
      "Azureml compute instance spark dependencies missing\n",
      "Local compute not found error when running a hyperparameter search\n",
      "Multiple new errors when deploying to ACI webservice\n",
      "After Web service deployment, getting column name not found error\n",
      "Module Not Found Error when launching parameter study\n",
      "How to import Microsoft.RelInfra.Common.Exception so that it could be properly handled?\n",
      "The azure cli command \"az ml attach folder\" is directly adding .azureml directory to .amlignore , so where to put config.json when using Azure devops pipeline to submit script to aml workspace?\n",
      "Failure when submitting pipe line\n",
      "Issues about Azure Machine Learning Studio\n",
      "How to use a working pipeline on live dataset?\n",
      "Getting 500 errors after model deployment\n",
      "Azure-cli-ml Version: '1.33.0', 'Error': WebserviceException. Can't deploy model into ACI\n",
      "Machine Learning CI Pipeline: Submitting an experiment failed\n",
      "How to use a registred model in a python script(in Azure) ?\n",
      "i am getting error when deploying machine learning model in aci\n",
      "i am getting error when deploying machine learning model in aci\n",
      "Endopint not consumable after successful model deployment to azure instance container (machine learning studio - designer)\n",
      "Cannot use GPU on Azure Notebooks in Azure Machine Learning Studio\n",
      "Deploying spark-nlp model using custom docker image fails in Azure Machine Learning\n",
      "Import Data Error - DocumentDb library exception: DocumentDB client threw an exception . ( Error 1000 ) Using Machine learning studio (classic)\n",
      "azureml when deployment fails from local source directory\n",
      "Module not found when custom python package installed via shell script\n",
      "Registered AzureML Model from a NotebookVM can not be found\n",
      "Isn't Interactive login, default for Workspace.from_config()?\n",
      "Investigating AML workspace images crashes due to already deleted model\n",
      "Rest api to create or update azure ML workspace doesn't create dependant resources\n",
      "Model file is not found for Registration of model in training Pipeline.\n",
      "Opening source file causes File not found exception\n",
      "Guild view not working in jupyterhub\n",
      "Local run vs remote run dependencies\n",
      "Tensorboard FileNot found error on Windows-10, guild-0.7.3.dev1\n",
      "Guild runs on remote not found\n",
      "sqlite3.OperationalError: disk I/O error when using the scratch drive on Linux cluster for storage of guild runs\n",
      "MLflow-Docker Artifacts Model Not Found\n",
      "Model Deployment Issues\n",
      "Deploy problems\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "\n",
    "# regex_digit = r\"[0-9]\"\n",
    "\n",
    "# regex_error = r\"[a-zA-Z0-9]+[eE]rror[^a-zA-Z]\"\n",
    "# regex_exception = r\"[a-zA-Z0-9]+[eE]xception[^a-zA-Z]\"\n",
    "\n",
    "# regex_error_leading = r\"[a-zA-Z0-9]+[eE]rror[a-zA-Z]+\"\n",
    "# regex_exception_leading = r\"[a-zA-Z0-9]+[eE]xception[a-zA-Z]+\"\n",
    "\n",
    "# def camel_case_split(str):\n",
    "#     words = [[str[0].lower()]]\n",
    " \n",
    "#     for c in str[1:]:\n",
    "#         if (words[-1][-1].islower() or words[-1][-1].isdigit()) and c.isupper():\n",
    "#             words.append(list(c.lower()))\n",
    "#         else:\n",
    "#             words[-1].append(c)\n",
    "#     return ' '.join([''.join(word) for word in words])\n",
    "\n",
    "# titles = []\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     if row['Challenge_title'] in titles:\n",
    "#         continue\n",
    "#     challenge = row['Challenge_title'] + ' ' + row['Challenge_body']\n",
    "#     challenge = challenge.replace('\\n', ' ').lower()\n",
    "#     if (' 403 ' in challenge) or ('[403]' in challenge) or ('(403)' in challenge) or (' 403,' in challenge) or ('forbidden' in challenge):\n",
    "#         pass\n",
    "#         # print(row['Challenge_title'])\n",
    "#         # df.at[index, 'Challenge_type'] = 'anomaly'\n",
    "#         # df.at[index, 'Challenge_summary'] = 'forbidden error'\n",
    "#     elif (' 404 ' in challenge) or ('[404]' in challenge) or ('(404)' in challenge) or (' 404,' in challenge) or ('not found' in challenge):\n",
    "#         print(row['Challenge_title'])\n",
    "        \n",
    "# # df.to_json(os.path.join(path_special_output, 'labels.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "\n",
    "# for i,r in df.iterrows():\n",
    "#     if r['Challenge_type'] == 'inquiry':\n",
    "#         df.at[i, 'Challenge_summary'] = 'na'\n",
    "#         df.at[i, 'Challenge_root_cause'] = 'na'\n",
    "\n",
    "# df.to_json(os.path.join(path_special_output, 'labels.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new = pd.read_json(os.path.join(path_special_output, 'labels+.json'))\n",
    "# df_old = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "\n",
    "# df = pd.concat([df_new, df_old], ignore_index=True)\n",
    "# df = df.drop_duplicates(['Challenge_link'], keep=False)\n",
    "\n",
    "# df = df[df['Challenge_type'].isna()]\n",
    "# df.to_json(os.path.join(path_special_output, 'extra.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new = pd.read_json(os.path.join(path_special_output, 'labels++.json'))\n",
    "# df_old = pd.read_json(os.path.join(path_special_output, 'extra.json'))\n",
    "\n",
    "# df = pd.concat([df_old, df_new], ignore_index=True)\n",
    "# df = df.drop_duplicates(['Challenge_link'])\n",
    "\n",
    "# df.to_json(os.path.join(path_special_output, 'extra+.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new = pd.read_json(os.path.join(path_special_output, 'labels+.json'))\n",
    "# df = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "\n",
    "# for index, row in df_new.iterrows():\n",
    "#     for i2,r2 in df.iterrows():\n",
    "#         if r2['Challenge_type'] == 'na':\n",
    "#             continue\n",
    "#         if r2['Challenge_link'] == row['Challenge_link']:\n",
    "#             df_new.at[index, 'Challenge_type'] = r2['Challenge_type']\n",
    "#             df_new.at[index, 'Challenge_summary'] = r2['Challenge_summary']\n",
    "#             df_new.at[index, 'Challenge_root_cause'] = r2['Challenge_root_cause']\n",
    "#             df_new.at[index, 'Challenge_solution'] = r2['Challenge_solution']\n",
    "#             break\n",
    "            \n",
    "# df_new.to_json(os.path.join(path_special_output, 'labels++.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: Import/Export Issues - Problems related to importing and exporting data or modules, including unauthorized and failed attempts.\n",
      "Topic 1: File Absence - Issues related to missing or unknown files, including deleted or non-existent files.\n",
      "Topic 2: Type Errors - Problems related to invalid or incorrect data types, including tensor type issues.\n",
      "Topic 3: Performance Issues - Issues related to slow processing, execution, and computation, resulting in low throughput.\n",
      "Topic 4: Value Errors - Problems related to incorrect or stagnant values, including calculation errors.\n",
      "Topic 5: Version Incompatibility - Issues related to incompatible, unsupported, or outdated software versions.\n",
      "Topic 6: Validation Exceptions - Problems related to validation and exceptions.\n",
      "Topic 7: Run Issues - Issues related to missing, mismatched, or incomplete runs.\n",
      "Topic 8: Unresponsiveness - Problems related to unresponsive loading, processes, or applications.\n",
      "Topic 9: Pipeline Failures - Issues related to broken, failed, or missing pipelines.\n",
      "Topic 10: Attribute Errors - Problems related to attributes and metadata.\n",
      "Topic 11: Import Errors - Issues related to missing, unexpected, or duplicated imports.\n",
      "Topic 12: Directory Errors - Problems related to invalid, unsupported, or missing directories and storage.\n",
      "Topic 13: Training Issues - Issues related to unresponsive, stuck, or unsuccessful training jobs.\n",
      "Topic 14: Unknown Errors - Problems related to unexpected, unexplained, or detected errors.\n",
      "Topic 15: HTTP Errors - Issues related to HTTP responses, requests, and browser interactions.\n",
      "Topic 16: Output Issues - Problems related to missing, empty, or incorrect output.\n",
      "Topic 17: Input Errors - Issues related to invalid, incorrect, or incompatible input.\n",
      "Topic 18: Interface Issues - Problems related to inactive or missing buttons and blank interfaces.\n",
      "Topic 19: Request Issues - Issues related to bad, conflicting, or refused requests.\n",
      "Topic 20: Endpoint Errors - Problems related to incorrect, inaccessible, or missing endpoints.\n",
      "Topic 21: Installation Errors - Issues related to failed, incompatible, or broken installations.\n",
      "Topic 22: Access Denial - Problems related to denied access to users, files, or directories.\n",
      "Topic 23: Attribute Errors - Issues related to attributes.\n",
      "Topic 24: Visibility Issues - Problems related to unviewable text, labels, or values.\n",
      "Topic 25: Kernel Instability - Issues related to unstable, defective, or unresponsive kernels.\n",
      "Topic 26: Value Errors - Problems related to invalid, unsupported, or incorrect values.\n",
      "Topic 27: Column Errors - Issues related to unexpected, unrecognized, or wrong columns in tables.\n",
      "Topic 28: Operational Errors - Problems related to execution, module, or invocation errors.\n",
      "Topic 29: Dataset Issues - Issues related to missing, unsupported, or invalid datasets.\n",
      "Topic 30: Memory Overflow - Problems related to memory leaks and overflows.\n",
      "Topic 31: Model Errors - Issues related to model shape, read, creation, or saving.\n",
      "Topic 32: Attribute Errors - Problems related to attributes.\n",
      "Topic 33: File Issues - Issues related to incomplete, wrong, or corrupted files.\n",
      "Topic 34: Environment Errors - Problems related to failed, invalid, or incompatible environments.\n",
      "Topic 35: Metric Issues - Issues related to missing, faulty, or undefined metrics.\n",
      "Topic 36: Load Errors - Problems related to failed or insufficient loads.\n",
      "Topic 37: Login Errors - Issues related to invalid, unknown, or missing logins.\n",
      "Topic 38: Experiment Issues - Problems related to missing, queued, or invalid experiments.\n",
      "Topic 39: Connection Resets - Issues related to reset or changed connections.\n",
      "Topic 40: Logging Inconsistencies - Problems related to inconsistent, overwriting, or incorrect logging.\n",
      "Topic 41: Pull Errors - Issues related to data or image pulls.\n",
      "Topic 42: Format Errors - Problems related to invalid, incompatible, or unexpected formats.\n",
      "Topic 43: Command Errors - Issues related to missing, invalid, or unrecognized commands.\n",
      "Topic 44: Key Errors - Problems related to keys.\n",
      "Topic 45: Quota Exhaustion - Issues related to exhausted or insufficient quotas.\n",
      "Topic 46: Token Errors - Problems related to invalid, wrong, or missing tokens.\n",
      "Topic 47: Dependency Issues - Issues related to missing, unresolved, or failed dependencies.\n",
      "Topic 48: Filesystem Issues - Problems related to missing or empty filesystems or blobs.\n",
      "Topic 49: Docker Errors - Issues related to Docker, including container errors and failed containerization.\n",
      "Topic 50: Initialization Errors - Problems related to incorrect, crashing, or timed out initialization.\n",
      "Topic 51: Encoding Errors - Issues related to encoding or decoding errors.\n",
      "Topic 52: Path Errors - Problems related to invalid, wrong, or missing paths.\n",
      "Topic 53: Parameter Issues - Issues related to missing, unknown, or empty parameters.\n",
      "Topic 54: Package Issues - Problems related to uninstallable or uninstalled packages or extensions.\n",
      "Topic 55: Permission Issues - Issues related to denied or insufficient permissions.\n",
      "Topic 56: Prediction Errors - Problems related to incorrect, missing, or unrecognized predictions.\n",
      "Topic 57: Graph Issues - Issues related to unrendered, unsynchronized, or cluttered graphs or plots.\n",
      "Topic 58: Role Issues - Problems related to unauthorized, invalid, or missing roles.\n",
      "Topic 59: Charge Issues - Issues related to unexplained or unexpected charges.\n",
      "Topic 60: Notebook Unresponsiveness - Problems related to unresponsive or unsuccessful notebooks.\n",
      "Topic 61: Deployment Issues - Issues related to unresponsive, unstable, or slow deployments.\n",
      "Topic 62: Size Exhaustion - Problems related to exhausted or uncomfortable sizes.\n",
      "Topic 63: Function Issues - Issues related to missing, incomplete, or unsupported functions.\n",
      "Topic 64: Model Issues - Problems related to invalid, wrong, or failed models.\n",
      "Topic 65: GPU Utilization - Issues related to unused, low performance, or slow GPUs.\n",
      "Topic 66: Configuration Errors - Problems related to invalid, incompatible, or wrong configurations.\n",
      "Topic 67: Pickling Errors - Issues related to pickling or unpickling errors.\n",
      "Topic 68: Object Issues - Problems related to missing objects, properties, or members.\n",
      "Topic 69: Forbidden Errors - Issues related to forbidden operations or access.\n",
      "Topic 70: Configuration Absence - Problems related to missing or unspecified configurations or setups.\n",
      "Topic 71: Artifact Issues - Issues related to missing, incomplete, or unexpected artifacts.\n",
      "Topic 72: Compute Issues - Problems related to invalid, missing, or insufficient compute targets.\n",
      "Topic 73: Argument Errors - Issues related to invalid, mismatched, or unrecognized arguments.\n",
      "Topic 74: Connection Timeouts - Problems related to connection or gateway timeouts.\n",
      "Topic 75: Service Timeouts - Issues related to request, service, or ignored timeouts.\n",
      "Topic 76: Log Issues - Problems related to missing, incomplete, or empty logs.\n",
      "Topic 77: URI/URL Issues - Issues related to unsupported, invalid, or missing URIs or URLs.\n",
      "Topic 78: Connection Timeouts - Problems related to timed out or unstable connections.\n",
      "Topic 79: Result Inconsistencies - Issues related to inconsistent, discrepant, or wrong results.\n",
      "Topic 80: Type Errors - Problems related to type errors or auto suggestions.\n",
      "Topic 81: Model Issues - Issues related to unsaved, detached, or unconsumable models.\n",
      "Topic 82: Data Absence - Problems related to missing, disappearing, or insufficient data.\n",
      "Topic 83: Parsing Errors - Issues related to parsing, parser errors, or improper parsing.\n",
      "Topic 84: Access Restrictions - Problems related to restricted, forbidden, or disabled access.\n",
      "Topic 85: Job Errors - Issues related to invalid, scheduled, or exited jobs.\n",
      "Topic 86: Gateway Issues - Problems related to bad gateways, network errors, or misconfigured connections.\n",
      "Topic 87: Model Absence - Issues related to missing, empty, or failing models.\n",
      "Topic 88: Parameter Errors - Problems related to invalid, unsuccessful, or unsupported parameters.\n",
      "Topic 89: Authentication Errors - Issues related to authentication problems, insufficient authentication, or misconfigured authentication.\n",
      "Topic 90: Sweep Issues - Problems related to repeating, slow, or missing sweeps.\n",
      "Topic 91: Tracking Errors - Issues related to tracking users, servers, or sockets.\n",
      "Topic 92: Credential Errors - Problems related to missing or invalid credentials.\n",
      "Topic 93: Validation Exceptions - Issues related to validation errors or exceptions.\n",
      "Topic 94: Executable Issues - Problems related to missing, unknown, or unsupported executables.\n",
      "Topic 95: Forbidden Operations - Issues related to forbidden methods, operators, or requirements.\n",
      "Topic 96: Limit Exceedance - Problems related to exceeded or exhausting limits.\n",
      "Topic 97: Cloning Errors - Issues related to failed or erroneous cloning or copying.\n",
      "Topic 98: Resource Shortages - Problems related to insufficient, empty, or exhausted resources.\n",
      "Topic 99: Message Failures - Issues related to failed, unrecognized, or repeated messages.\n",
      "Topic 100: Unsupported Content - Problems related to unsupported pandas, content, types, or media.\n",
      "Topic 101: File Size Issues - Issues related to large or big files, overwhelming data, or large uploads.\n",
      "Topic 102: Deployment Failures - Problems related to failed, unsuccessful, or broken deployments.\n",
      "Topic 103: Forbidden Errors - Issues related to forbidden operations or access.\n",
      "Topic 104: Data Set Errors - Problems related to data set errors or setup issues.\n",
      "Topic 105: Reproducibility Issues - Issues related to reproducing errors or handling simple errors.\n",
      "Topic 106: Memory Errors - Problems related to memory errors or allocation issues.\n",
      "Topic 107: Compilation Errors - Issues related to compilation, build, or unresolved errors.\n",
      "Topic 108: Link Issues - Problems related to broken, malfunctioning, or misdirected links.\n",
      "Topic 109: Server Errors - Issues related to internal server errors.\n",
      "Topic 110: Option Issues - Problems related to missing, disabled, or invisible options.\n",
      "Topic 111: Permission Denial - Issues related to denied permissions or ownership errors.\n",
      "Topic 112: Time Issues - Problems related to erroneous timezones, unexpected datetimes, or wrong timestamps.\n",
      "Topic 113: Access Denial - Issues related to denied access or changed access.\n",
      "Topic 114: Import/Export Issues - Problems related to importing and exporting data or modules, including unauthorized and failed attempts.\n",
      "Topic 115: File Absence - Issues related to missing or unknown files, including deleted or non-existent files.\n",
      "Topic 116: Type Errors - Problems related to invalid or incorrect data types, including tensor type issues.\n",
      "Topic 117: Performance Issues - Issues related to slow processing, execution, and computation, resulting in low throughput.\n",
      "Topic 118: Value Errors - Problems related to incorrect or stagnant values, including calculation errors.\n",
      "Topic 119: Version Incompatibility - Issues related to incompatible, unsupported, or outdated software versions.\n",
      "Topic 120: Validation Exceptions - Problems related to validation and exceptions.\n",
      "Topic 121: Run Issues - Issues related to missing, mismatched, or incomplete runs.\n",
      "Topic 122: Unresponsiveness - Problems related to unresponsive loading, processes, or applications.\n",
      "Topic 123: Pipeline Failures - Issues related to broken, failed, or missing pipelines.\n",
      "Topic 124: Attribute Errors - Problems related to attributes and metadata.\n",
      "Topic 125: Import Errors - Issues related to missing, unexpected, or duplicated imports.\n",
      "Topic 126: Directory Errors - Problems related to invalid, unsupported, or missing directories and storage.\n",
      "Topic 127: Training Issues - Issues related to unresponsive, stuck, or unsuccessful training jobs.\n",
      "Topic 128: Unknown Errors - Problems related to unexpected, unexplained, or detected errors.\n",
      "Topic 129: HTTP Errors - Issues related to HTTP responses, requests, and browser interactions.\n",
      "Topic 130: Output Issues - Problems related to missing, empty, or incorrect output.\n",
      "Topic 131: Input Errors - Issues related to invalid, incorrect, or incompatible input.\n",
      "Topic 132: Interface Issues - Problems related to inactive or missing buttons and blank interfaces.\n",
      "Topic 133: Request Issues - Issues related to bad, conflicting, or refused requests.\n",
      "Topic 134: Endpoint Errors - Problems related to incorrect, inaccessible, or missing endpoints.\n",
      "Topic 135: Installation Errors - Issues related to failed, incompatible, or broken installations.\n",
      "Topic 136: Access Denial - Problems related to denied access to users, files, or directories.\n",
      "Topic 137: Attribute Errors - Issues related to attributes.\n",
      "Topic 138: Visibility Issues - Problems related to unviewable text, labels, or values.\n",
      "Topic 139: Kernel Instability - Issues related to unstable, defective, or unresponsive kernels.\n",
      "Topic 140: Value Errors - Problems related to invalid, unsupported, or incorrect values.\n",
      "Topic 141: Column Errors - Issues related to unexpected, unrecognized, or wrong columns in tables.\n",
      "Topic 142: Operational Errors - Problems related to execution, module, or invocation errors.\n",
      "Topic 143: Dataset Issues - Issues related to missing, unsupported, or invalid datasets.\n",
      "Topic 144: Memory Overflow - Problems related to memory leaks and overflows.\n",
      "Topic 145: Model Errors - Issues related to model shape, read, creation, or saving.\n",
      "Topic 146: Attribute Errors - Problems related to attributes.\n",
      "Topic 147: File Issues - Issues related to incomplete, wrong, or corrupted files.\n",
      "Topic 148: Environment Errors - Problems related to failed, invalid, or incompatible environments.\n",
      "Topic 149: Metric Issues - Issues related to missing, faulty, or undefined metrics.\n",
      "Topic 150: Load Errors - Problems related to failed or insufficient loads.\n",
      "Topic 151: Login Errors - Issues related to invalid, unknown, or missing logins.\n",
      "Topic 152: Experiment Issues - Problems related to missing, queued, or invalid experiments.\n",
      "Topic 153: Connection Resets - Issues related to reset or changed connections.\n",
      "Topic 154: Logging Inconsistencies - Problems related to inconsistent, overwriting, or incorrect logging.\n",
      "Topic 155: Pull Errors - Issues related to data or image pulls.\n",
      "Topic 156: Format Errors - Problems related to invalid, incompatible, or unexpected formats.\n",
      "Topic 157: Command Errors - Issues related to missing, invalid, or unrecognized commands.\n",
      "Topic 158: Key Errors - Problems related to keys.\n",
      "Topic 159: Quota Exhaustion - Issues related to exhausted or insufficient quotas.\n",
      "Topic 160: Token Errors - Problems related to invalid, wrong, or missing tokens.\n",
      "Topic 161: Dependency Issues - Issues related to missing, unresolved, or failed dependencies.\n",
      "Topic 162: Filesystem Issues - Problems related to missing or empty filesystems or blobs.\n",
      "Topic 163: Docker Errors - Issues related to Docker, including container errors and failed containerization.\n",
      "Topic 164: Initialization Errors - Problems related to incorrect, crashing, or timed out initialization.\n",
      "Topic 165: Encoding Errors - Issues related to encoding or decoding errors.\n",
      "Topic 166: Path Errors - Problems related to invalid, wrong, or missing paths.\n",
      "Topic 167: Parameter Issues - Issues related to missing, unknown, or empty parameters.\n",
      "Topic 168: Package Issues - Problems related to uninstallable or uninstalled packages or extensions.\n",
      "Topic 169: Permission Issues - Issues related to denied or insufficient permissions.\n",
      "Topic 170: Prediction Errors - Problems related to incorrect, missing, or unrecognized predictions.\n",
      "Topic 171: Graph Issues - Issues related to unrendered, unsynchronized, or cluttered graphs or plots.\n",
      "Topic 172: Role Issues - Problems related to unauthorized, invalid, or missing roles.\n",
      "Topic 173: Charge Issues - Issues related to unexplained or unexpected charges.\n",
      "Topic 174: Notebook Unresponsiveness - Problems related to unresponsive or unsuccessful notebooks.\n",
      "Topic 175: Deployment Issues - Issues related to unresponsive, unstable, or slow deployments.\n",
      "Topic 176: Size Exhaustion - Problems related to exhausted or uncomfortable sizes.\n",
      "Topic 177: Function Issues - Issues related to missing, incomplete, or unsupported functions.\n",
      "Topic 178: Model Issues - Problems related to invalid, wrong, or failed models.\n",
      "Topic 179: GPU Utilization - Issues related to unused, low performance, or slow GPUs.\n",
      "Topic 180: Configuration Errors - Problems related to invalid, incompatible, or wrong configurations.\n",
      "Topic 181: Pickling Errors - Issues related to pickling or unpickling errors.\n",
      "Topic 182: Object Issues - Problems related to missing objects, properties, or members.\n",
      "Topic 183: Forbidden Errors - Issues related to forbidden operations or access.\n",
      "Topic 184: Configuration Absence - Problems related to missing or unspecified configurations or setups.\n",
      "Topic 185: Artifact Issues - Issues related to missing, incomplete, or unexpected artifacts.\n",
      "Topic 186: Compute Issues - Problems related to invalid, missing, or insufficient compute targets.\n",
      "Topic 187: Argument Errors - Issues related to invalid, mismatched, or unrecognized arguments.\n",
      "Topic 188: Connection Timeouts - Problems related to connection or gateway timeouts.\n",
      "Topic 189: Service Timeouts - Issues related to request, service, or ignored timeouts.\n",
      "Topic 190: Log Issues - Problems related to missing, incomplete, or empty logs.\n",
      "Topic 191: URI/URL Issues - Issues related to unsupported, invalid, or missing URIs or URLs.\n",
      "Topic 192: Connection Timeouts - Problems related to timed out or unstable connections.\n",
      "Topic 193: Result Inconsistencies - Issues related to inconsistent, discrepant, or wrong results.\n",
      "Topic 194: Type Errors - Problems related to type errors or auto suggestions.\n",
      "Topic 195: Model Issues - Issues related to unsaved, detached, or unconsumable models.\n",
      "Topic 196: Data Absence - Problems related to missing, disappearing, or insufficient data.\n",
      "Topic 197: Parsing Errors - Issues related to parsing, parser errors, or improper parsing.\n",
      "Topic 198: Access Restrictions - Problems related to restricted, forbidden, or disabled access.\n",
      "Topic 199: Job Errors - Issues related to invalid, scheduled, or exited jobs.\n",
      "Topic 200: Gateway Issues - Problems related to bad gateways, network errors, or misconfigured connections.\n",
      "Topic 201: Model Absence - Issues related to missing, empty, or failing models.\n",
      "Topic 202: Parameter Errors - Problems related to invalid, unsuccessful, or unsupported parameters.\n",
      "Topic 203: Authentication Errors - Issues related to authentication problems, insufficient authentication, or misconfigured authentication.\n",
      "Topic 204: Sweep Issues - Problems related to repeating, slow, or missing sweeps.\n",
      "Topic 205: Tracking Errors - Issues related to tracking users, servers, or sockets.\n",
      "Topic 206: Credential Errors - Problems related to missing or invalid credentials.\n",
      "Topic 207: Validation Exceptions - Issues related to validation errors or exceptions.\n",
      "Topic 208: Executable Issues - Problems related to missing, unknown, or unsupported executables.\n",
      "Topic 209: Forbidden Operations - Issues related to forbidden methods, operators, or requirements.\n",
      "Topic 210: Limit Exceedance - Problems related to exceeded or exhausting limits.\n",
      "Topic 211: Cloning Errors - Issues related to failed or erroneous cloning or copying.\n",
      "Topic 212: Resource Shortages - Problems related to insufficient, empty, or exhausted resources.\n",
      "Topic 213: Message Failures - Issues related to failed, unrecognized, or repeated messages.\n",
      "Topic 214: Unsupported Content - Problems related to unsupported pandas, content, types, or media.\n",
      "Topic 215: File Size Issues - Issues related to large or big files, overwhelming data, or large uploads.\n",
      "Topic 216: Deployment Failures - Problems related to failed, unsuccessful, or broken deployments.\n",
      "Topic 217: Forbidden Errors - Issues related to forbidden operations or access.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_topic = '''You will be given a list of stemmed words refering to specific software engineering topics. Please summarize each topic in terms and attach a one-liner description based on the stemmed words. Also, you must guarantee that the summaries are exclusive to one another.###\\n'''\n",
    "\n",
    "with open(os.path.join(path_anomaly, 'Topic terms.pickle'), 'rb') as handle:\n",
    "    topic_terms = pickle.load(handle)\n",
    "\n",
    "    topic_term_list = []\n",
    "    for index, topic in enumerate(topic_terms):\n",
    "        terms = ', '.join([term[0] for term in topic])\n",
    "        topic_term = f'Topic {index}: {terms}'\n",
    "        topic_term_list.append(topic_term)\n",
    "\n",
    "    prompt = prompt_topic + '\\n'.join(topic_term_list) + '\\n###\\n'\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "        temperature=0,\n",
    "        max_tokens=4000,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        timeout=500,\n",
    "        stream=False)\n",
    "\n",
    "    topics = completion.choices[0].message.content\n",
    "    print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Access Control': 1,\n",
       " 'Remote Configuration': 1,\n",
       " 'Git Configuration': 8,\n",
       " 'Batch Processing': 2,\n",
       " 'Spark Configuration': 2,\n",
       " 'Sweep Management': 2,\n",
       " 'Bucket Management': 3,\n",
       " 'Columnar Data Manipulation': 3,\n",
       " 'Database Management': 3,\n",
       " 'Label Management': 3,\n",
       " 'Tabular Data Manipulation': 3,\n",
       " 'Package Management': 4,\n",
       " 'Docker Configuration': 4,\n",
       " 'Instance Management': 4,\n",
       " 'Lambda Configuration': 4,\n",
       " 'Pipeline Configuration': 7,\n",
       " 'Model Management': 5,\n",
       " 'Log Management': 6,\n",
       " 'Quota Management': 6}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = '''Topic 0: Import/Export Issues - Problems related to importing and exporting data or files, including unauthorized and failed attempts.\n",
    "Topic 1: File Absence - Issues related to missing or unknown files, including deleted or non-existent files.\n",
    "Topic 2: Type Errors - Problems related to invalid or incorrect data types, including tensor type issues.\n",
    "Topic 3: Performance Issues - Issues related to slow processing, execution, and computation, resulting in low throughput.\n",
    "Topic 4: Value Errors - Problems related to incorrect or stagnant values, including calculation errors.\n",
    "Topic 5: Version Incompatibility - Issues related to incompatible, unsupported, or outdated software versions.\n",
    "Topic 6: Validation Exceptions - Problems related to validation and exceptions.\n",
    "Topic 7: Run Issues - Issues related to missing, mismatched, or incomplete runs.\n",
    "Topic 8: Unresponsiveness - Problems related to unresponsive loading, processes, or applications.\n",
    "Topic 9: Pipeline Failures - Issues related to broken, failed, or missing pipelines.\n",
    "Topic 10: Attribute Errors - Problems related to attributes and metadata.\n",
    "Topic 11: Import Errors - Issues related to missing, unexpected, or duplicated imports.\n",
    "Topic 12: Directory Issues - Problems related to incorrect or insufficient directories and storage.\n",
    "Topic 13: Training Issues - Issues related to unresponsive, stuck, or unsuccessful training.\n",
    "Topic 14: Unknown Errors - Problems related to unexpected, unexplained, or detected errors.\n",
    "Topic 15: HTTP Errors - Issues related to HTTP responses, requests, and browser interactions.\n",
    "Topic 16: Output Issues - Problems related to missing, empty, or incorrect output.\n",
    "Topic 17: Input Errors - Issues related to invalid, incorrect, or incompatible input.\n",
    "Topic 18: Interface Issues - Problems related to inactive buttons, missing elements, or blank pages.\n",
    "Topic 19: Request Issues - Issues related to bad, conflicting, or refused requests.\n",
    "Topic 20: Endpoint Issues - Problems related to incorrect, inaccessible, or missing endpoints.\n",
    "Topic 21: Installation Errors - Issues related to failed, incompatible, or broken installations.\n",
    "Topic 22: Access Denial - Problems related to denied access to files, directories, or users.\n",
    "Topic 23: Attribute Errors - Issues related to attributes.\n",
    "Topic 24: Visibility Issues - Problems related to unviewable text, labels, or values.\n",
    "Topic 25: Kernel Instability - Issues related to unstable, defective, or unresponsive kernels.\n",
    "Topic 26: Value Errors - Problems related to invalid, unsupported, or incorrect values.\n",
    "Topic 27: Column Issues - Issues related to unexpected, unrecognized, or wrong columns in tables.\n",
    "Topic 28: Operational Errors - Problems related to execution, module, or invocation errors.\n",
    "Topic 29: Dataset Issues - Issues related to missing, ignored, or incompatible datasets.\n",
    "Topic 30: Memory Overflow - Problems related to memory leaks or overflows.\n",
    "Topic 31: Model Errors - Issues related to model shapes, reading, creation, or saving.\n",
    "Topic 32: Attribute Errors - Problems related to attributes.\n",
    "Topic 33: File Issues - Issues related to incomplete, wrong, or corrupted files.\n",
    "Topic 34: Environment Issues - Problems related to failed, invalid, or incompatible environments.\n",
    "Topic 35: Metric Issues - Issues related to missing, incomplete, or faulty metrics.\n",
    "Topic 36: Load Errors - Problems related to failed or insufficient loads.\n",
    "Topic 37: Login Errors - Issues related to invalid, unknown, or missing logins.\n",
    "Topic 38: Experiment Issues - Problems related to missing, queued, or invalid experiments.\n",
    "Topic 39: Connection Reset - Issues related to reset or changed connections.\n",
    "Topic 40: Logging Inconsistencies - Problems related to inconsistent or incorrect logging.\n",
    "Topic 41: Pull Errors - Issues related to data or image pulling.\n",
    "Topic 42: Format Issues - Problems related to invalid, incompatible, or unexpected formats.\n",
    "Topic 43: Command Issues - Issues related to missing, invalid, or unrecognized commands.\n",
    "Topic 44: Key Errors - Problems related to keys.\n",
    "Topic 45: Quota Exhaustion - Issues related to exhausted or insufficient quotas.\n",
    "Topic 46: Token Issues - Problems related to invalid, wrong, or missing tokens.\n",
    "Topic 47: Dependency Issues - Issues related to missing, unresolved, or failed dependencies.\n",
    "Topic 48: Filesystem Issues - Problems related to missing or empty filesystems or blobs.\n",
    "Topic 49: Docker Errors - Issues related to Docker, including container errors and failed containerization.\n",
    "Topic 50: Initialization Errors - Problems related to incorrect, crashing, or timed-out initialization.\n",
    "Topic 51: Encoding Errors - Issues related to encoding or decoding errors.\n",
    "Topic 52: Path Issues - Problems related to invalid, wrong, or missing paths.\n",
    "Topic 53: Parameter Issues - Issues related to missing, unknown, or empty parameters.\n",
    "Topic 54: Uninstallable Packages - Problems related to uninstallable or uninstalled packages or extensions.\n",
    "Topic 55: Permission Issues - Issues related to denied or insufficient permissions.\n",
    "Topic 56: Prediction Errors - Problems related to incorrect, missing, or unrecognized predictions.\n",
    "Topic 57: Graphing Issues - Issues related to unrendered or unsynchronized plots or charts.\n",
    "Topic 58: Role Authorization - Problems related to unauthorized or invalid roles.\n",
    "Topic 59: Unexpected Charges - Issues related to unexplained or unexpected charges or values.\n",
    "Topic 60: Notebook Unresponsiveness - Problems related to unresponsive or unsuccessful notebooks.\n",
    "Topic 61: Deployment Issues - Issues related to unresponsive, unstable, or slow deployments.\n",
    "Topic 62: Size Exhaustion - Problems related to exhausted or uncomfortable sizes or designs.\n",
    "Topic 63: Function Issues - Issues related to missing, incomplete, or unsupported functions.\n",
    "Topic 64: Model Issues - Problems related to invalid, wrong, or failed models.\n",
    "Topic 65: GPU Utilization - Issues related to unused, low performance, or slow GPUs.\n",
    "Topic 66: Configuration Issues - Problems related to invalid, incompatible, or wrong configurations.\n",
    "Topic 67: Unpickling Errors - Issues related to unpickling or pickling errors.\n",
    "Topic 68: Object Absence - Problems related to missing objects, properties, members, or references.\n",
    "Topic 69: Forbidden Errors - Issues related to forbidden operations or access.\n",
    "Topic 70: Configuration Absence - Problems related to missing or unspecified configurations or setups.\n",
    "Topic 71: Artifact Issues - Issues related to missing, incomplete, or unexpected artifacts.\n",
    "Topic 72: Compute Issues - Problems related to invalid, missing, or insufficient compute targets.\n",
    "Topic 73: Argument Issues - Issues related to invalid, mismatched, or unrecognized arguments.\n",
    "Topic 74: Connection Timeout - Problems related to connection timeouts or unstable connections.\n",
    "Topic 75: Service Timeout - Issues related to request, service, or ignored timeouts.\n",
    "Topic 76: Log Absence - Problems related to missing, incomplete, or empty logs.\n",
    "Topic 77: URI/URL Issues - Issues related to unsupported, invalid, or missing URIs or URLs.\n",
    "Topic 78: Connection Timeout - Problems related to timed out or unstable connections.\n",
    "Topic 79: Result Inconsistencies - Issues related to inconsistent, discrepant, or wrong results.\n",
    "Topic 80: Type Errors - Problems related to type errors or auto suggestions.\n",
    "Topic 81: Model Issues - Issues related to unsaved, detached, or unconsumable models.\n",
    "Topic 82: Data Absence - Problems related to missing, disappearing, or insufficient data.\n",
    "Topic 83: Parsing Errors - Issues related to parsing, parser errors, or improper parsing.\n",
    "Topic 84: Access Restrictions - Problems related to restricted, forbidden, or disabled access.\n",
    "Topic 85: Job Issues - Issues related to invalid, scheduled, or exited jobs.\n",
    "Topic 86: Gateway Issues - Problems related to bad gateways, network errors, or misconfigured connections.\n",
    "Topic 87: Model Absence - Issues related to missing, empty, or failing models.\n",
    "Topic 88: Parameter Issues - Problems related to unsuccessful, unsupported, or malfunctioning parameters.\n",
    "Topic 89: Authentication Issues - Issues related to authentication problems, insufficient authentication, or misconfigured authentication.\n",
    "Topic 90: Sweep Issues - Problems related to repeating, slow, or missing sweeps.\n",
    "Topic 91: Tracking Errors - Issues related to tracking users, servers, or sockets.\n",
    "Topic 92: Credential Issues - Problems related to missing or invalid credentials.\n",
    "Topic 93: Validation Exceptions - Issues related to validation errors or exceptions.\n",
    "Topic 94: Executable Issues - Problems related to missing, unknown, or unsupported executables.\n",
    "Topic 95: Forbidden Operations - Issues related to forbidden methods, operators, or requirements.\n",
    "Topic 96: Limit Exceedance - Problems related to exceeded or exhausting limits.\n",
    "Topic 97: Cloning Issues - Issues related to copying, cloning, or failed cloning.\n",
    "Topic 98: Resource Shortages - Problems related to insufficient, empty, or exhausted resources.\n",
    "Topic 99: Messaging Issues - Issues related to failed, successful, or unrecognized messages.\n",
    "Topic 100: Pandas Issues - Problems related to unsupported pandas content or types.\n",
    "Topic 101: File Size Issues - Issues related to large or big files, including large uploads or data chunks.\n",
    "Topic 102: Deployment Failures - Problems related to failed, unsuccessful, or broken deployments.\n",
    "Topic 103: Forbidden Errors - Issues related to forbidden operations or access.\n",
    "Topic 104: Data Set Issues - Problems related to data set errors or setup.\n",
    "Topic 105: Reproducible Errors - Issues related to reproducible, simple, or conflicting errors.\n",
    "Topic 106: Memory Errors - Problems related to memory allocation or capacity.\n",
    "Topic 107: Compilation Errors - Issues related to compilation, build, or unresolved errors.\n",
    "Topic 108: Link Issues - Problems related to broken, malfunctioning, or misdirected links.\n",
    "Topic 109: Server Errors - Issues related to internal server errors.\n",
    "Topic 110: Option Issues - Problems related to missing, disabled, or invisible options.\n",
    "Topic 111: Permission Denial - Issues related to denied permissions or invalid ownership.\n",
    "Topic 112: Time Issues - Problems related to erroneous timezones, unexpected datetimes, or wrong timestamps.\n",
    "Topic 113: Access Denial - Issues related to denied or missing access.\n",
    "Topic 114: Permission Denial - Problems related to denied permissions or insufficient privileges.\n",
    "Topic 115: Prediction Errors - Issues related to incorrect, missing, or unrecognized predictions.\n",
    "Topic 116: Graphing Issues - Problems related to unrendered or unsynchronized plots or charts.\n",
    "Topic 117: Role Authorization - Issues related to unauthorized or invalid roles.\n",
    "Topic 118: Unexpected Charges - Problems related to unexplained or unexpected charges or values.\n",
    "Topic 119: Notebook Unresponsiveness - Issues related to unresponsive or unsuccessful notebooks.\n",
    "Topic 120: Deployment Issues - Problems related to unresponsive, unstable, or slow deployments.\n",
    "Topic 121: Size Exhaustion - Issues related to exhausted or uncomfortable sizes or designs.\n",
    "Topic 122: Function Issues - Problems related to missing, incomplete, or unsupported functions.\n",
    "Topic 123: Model Issues - Issues related to invalid, wrong, or failed models.\n",
    "Topic 124: GPU Utilization - Problems related to unused, low performance, or slow GPUs.\n",
    "Topic 125: Configuration Issues - Issues related to invalid, incompatible, or wrong configurations.\n",
    "Topic 126: Unpickling Errors - Problems related to unpickling or pickling errors.\n",
    "Topic 127: Object Absence - Issues related to missing objects, properties, members, or references.\n",
    "Topic 128: Forbidden Errors - Problems related to forbidden operations or access.\n",
    "Topic 129: Configuration Absence - Issues related to missing or unspecified configurations or setups.\n",
    "Topic 130: Artifact Issues - Problems related to missing, incomplete, or unexpected artifacts.\n",
    "Topic 131: Compute Issues - Issues related to invalid, missing, or insufficient compute targets.\n",
    "Topic 132: Argument Issues - Problems related to invalid, mismatched, or unrecognized arguments.\n",
    "Topic 133: Connection Timeout - Issues related to connection timeouts or unstable connections.\n",
    "Topic 134: Service Timeout - Problems related to request, service, or ignored timeouts.\n",
    "Topic 135: Log Absence - Issues related to missing, incomplete, or empty logs.\n",
    "Topic 136: URI/URL Issues - Problems related to unsupported, invalid, or missing URIs or URLs.\n",
    "Topic 137: Connection Timeout - Issues related to timed out or unstable connections.\n",
    "Topic 138: Result Inconsistencies - Problems related to inconsistent, discrepant, or wrong results.\n",
    "Topic 139: Type Errors - Issues related to type errors or auto suggestions.\n",
    "Topic 140: Model Issues - Problems related to unsaved, detached, or unconsumable models.\n",
    "Topic 141: Data Absence - Issues related to missing, disappearing, or insufficient data.\n",
    "Topic 142: Parsing Errors - Problems related to parsing, parser errors, or improper parsing.\n",
    "Topic 143: Access Restrictions - Issues related to restricted, forbidden, or disabled access.\n",
    "Topic 144: Job Issues - Problems related to invalid, scheduled, or exited jobs.\n",
    "Topic 145: Gateway Issues - Issues related to bad gateways, network errors, or misconfigured connections.\n",
    "Topic 146: Model Absence - Problems related to missing, empty, or failing models.\n",
    "Topic 147: Parameter Issues - Issues related to unsuccessful, unsupported, or malfunctioning parameters.\n",
    "Topic 148: Authentication Issues - Problems related to authentication problems, insufficient authentication, or misconfigured authentication.\n",
    "Topic 149: Sweep Issues - Problems related to repeating, slow, or missing sweeps.\n",
    "Topic 150: Tracking Errors - Issues related to tracking users, servers, or sockets.\n",
    "Topic 151: Credential Issues - Problems related to missing or invalid credentials.\n",
    "Topic 152: Validation Exceptions - Issues related to validation errors or exceptions.\n",
    "Topic 153: Executable Issues - Problems related to missing, unknown, or unsupported executables.\n",
    "Topic 154: Forbidden Operations - Issues related to forbidden methods, operators, or requirements.\n",
    "Topic 155: Limit Exceedance - Problems related to exceeded or exhausting limits.\n",
    "Topic 156: Cloning Issues - Issues related to copying, cloning, or failed cloning.\n",
    "Topic 157: Resource Shortages - Problems related to insufficient, empty, or exhausted resources.\n",
    "Topic 158: Messaging Issues - Issues related to failed, successful, or unrecognized messages.\n",
    "Topic 159: Pandas Issues - Problems related to unsupported pandas content or types.\n",
    "Topic 160: File Size Issues - Issues related to large or big files, including large uploads or data chunks.\n",
    "Topic 161: Deployment Failures - Problems related to failed, unsuccessful, or broken deployments.\n",
    "Topic 162: Forbidden Errors - Issues related to forbidden operations or access.\n",
    "Topic 163: Data Set Issues - Problems related'''\n",
    "\n",
    "index = 0\n",
    "topic_dict = {-1: 'NA'}\n",
    "\n",
    "for topic in topics.split('\\n'):\n",
    "    topic_dict[index] = topic.split('-')[0].split(':')[-1].strip()\n",
    "    index += 1\n",
    "\n",
    "topic_clusters = {\n",
    "    'File and Data Issues': [0, 1, 11, 12, 16, 17, 33, 41, 48, 82, 101, 141, 160],\n",
    "    'Error Type': [2, 4, 6, 14, 26, 28, 44, 50, 56, 80, 83, 88, 92, 93, 105, 106, 115, 126, 132, 139, 142, 152],\n",
    "    'Performance and Stability Issues': [3, 8, 13, 25, 30, 38, 39, 60, 61, 65, 74, 75, 78, 87, 90, 95, 100, 107, 120, 121, 124, 129, 131, 133, 137],\n",
    "    'Compatibility and Validation Issues': [5, 7, 9, 15, 18, 19, 21, 23, 24, 27, 31, 32, 35, 36, 42, 43, 45, 46, 47, 49, 53, 54, 57, 59, 62, 63, 64, 66, 68, 70, 72, 73, 76, 77, 79, 81, 84, 85, 86, 89, 91, 94, 96, 97, 98, 99, 102, 103, 104, 108, 109, 110, 111, 112, 114, 117, 118, 123, 125, 127, 128, 130, 134, 135, 136, 138, 140, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 161],\n",
    "    'Access and Permission Issues': [22, 55, 58, 69, 84, 113, 114, 122, 128, 144],\n",
    "    'Model, Prediction and Training Issues': [31, 56, 64, 81, 115, 123, 146],\n",
    "    'Environment and Configuration Issues': [34, 66, 70, 125, 129],\n",
    "    'Memory and Resource Issues': [30, 45, 98, 106, 121, 157],\n",
    "    'Execution and Operation Issues': [28, 36, 39, 67, 75, 94, 107, 133, 150],\n",
    "    'Authentication and User Issues': [22, 37, 58, 69, 84, 89, 111, 113, 114, 122, 128, 144, 148, 151],\n",
    "    'Interface and Interaction Issues': [18, 24, 57, 110, 112, 145],\n",
    "    'Network and Connection Issues': [15, 20, 39, 74, 78, 86, 133, 137, 145],\n",
    "    'System and Infrastructure Issues': [25, 49, 60, 61, 65, 90, 120, 124, 131, 146, 148],\n",
    "    'Tool and Package Specific Issues': [49, 54, 59, 99, 159]\n",
    "}\n",
    "\n",
    "macro_topic_mapping = {}\n",
    "macro_topic_index_mapping = {}\n",
    "for key, (macro_topic, topics) in macro_topic_mapping_inverse.items():\n",
    "    macro_topic_index_mapping[macro_topic] = key\n",
    "    for topic in topics:\n",
    "        macro_topic_mapping[topic] = key\n",
    "\n",
    "macro_topic_mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10, 29, 40, 51, 52, 71, 116, 119, 162}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = []\n",
    "for key, value in topic_clusters.items():\n",
    "    topics.extend(value)\n",
    "\n",
    "set(range(163)).difference(set(topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: Path Issues - Problems related to incorrect, mismatched, or missing file paths.\n",
      "Topic 1: Access Limitations - Issues concerning restricted, blocked, or insecure access to resources.\n",
      "Topic 2: Memory Problems - Concerns about exhausted, deleted, or high memory usage.\n",
      "Topic 3: Input/Output Errors - Problems with incorrect, invalid, or unexpected input and output formats.\n",
      "Topic 4: Unsupported Features - Issues with unsupported, unmaintained, or insufficient software features.\n",
      "Topic 5: Unreproducible Behavior - Problems related to unpredictable or false interactive behaviors.\n",
      "Topic 6: Missing Files - Issues concerning missing files, folders, or directories.\n",
      "Topic 7: Documentation Issues - Problems with unclear, confusing, or unspecified documentation.\n",
      "Topic 8: System Incompatibility - Issues with incompatible or unsupported operating systems or versions.\n",
      "Topic 9: Bug Issues - Problems related to known or unknown software bugs.\n",
      "Topic 10: Model Issues - Concerns about large, different, or wrong models.\n",
      "Topic 11: Outdated Packages - Issues with outdated or removed software packages.\n",
      "Topic 12: Version Incompatibility - Problems with incompatible, mismatched, or unsupported versions.\n",
      "Topic 13: Permission Restrictions - Issues concerning restricted, limited, or improper permissions.\n",
      "Topic 14: Missing Modules - Problems with missing, unreachable, or compressed modules.\n",
      "Topic 15: Dependency Issues - Issues with missing, incompatible, or conflicting dependencies.\n",
      "Topic 16: Breaking Changes - Problems related to changes that break the functionality of the software.\n",
      "Topic 17: Limitations - Issues concerning known or increased limitations.\n",
      "Topic 18: Docker Issues - Problems with conflicting, unsupported, or custom Docker environments.\n",
      "Topic 19: Parameter Issues - Issues with missing, wrong, or unsupported parameters.\n",
      "Topic 20: Data Type Issues - Problems with invalid, mismatched, or wrong data types.\n",
      "Topic 21: Endpoint Issues - Issues with misconfigured, wrong, or specific endpoints.\n",
      "Topic 22: Package Incompatibility - Problems with incompatible, conflicting, or invalid packages.\n",
      "Topic 23: Supplier Issues - Issues with unresponsive, malfunctioning, or custom suppliers.\n",
      "Topic 24: Argument Issues - Problems with missing, wrong, or unexpected arguments.\n",
      "Topic 25: Environment Issues - Issues with missing, unusable, or wrong environments.\n",
      "Topic 26: Deprecated Elements - Problems with deprecated features, methods, classes, or packages.\n",
      "Topic 27: Session Issues - Issues with inactive, missing, or expired sessions.\n",
      "Topic 28: Link Issues - Problems with broken, removed, or wrong links or URLs.\n"
     ]
    }
   ],
   "source": [
    "prompt_topic = '''You will be given a list of stemmed words refering to specific software engineering topics. Please summarize each topic in terms and attach a one-liner description based on the stemmed words. Also, you must guarantee that the summaries are exclusive to one another.###\\n'''\n",
    "\n",
    "with open(os.path.join(path_root_cause, 'Topic terms.pickle'), 'rb') as handle:\n",
    "    topic_terms = pickle.load(handle)\n",
    "\n",
    "    topic_term_list = []\n",
    "    for index, topic in enumerate(topic_terms):\n",
    "        terms = ', '.join([term[0] for term in topic])\n",
    "        topic_term = f'Topic {index}: {terms}'\n",
    "        topic_term_list.append(topic_term)\n",
    "\n",
    "    prompt = prompt_topic + '\\n'.join(topic_term_list) + '\\n###\\n'\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "        temperature=0,\n",
    "        max_tokens=3000,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        timeout=300,\n",
    "        stream=False)\n",
    "\n",
    "    topics = completion.choices[0].message.content\n",
    "    print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: Log Metrics and Models - Discusses the use and accuracy of log metrics and models in software engineering.\n",
      "Topic 1: Package Installation - Covers the process of installing, using, and creating software packages.\n",
      "Topic 2: Package Upgrade - Discusses the process of upgrading software packages and related commands.\n",
      "Topic 3: Model Saving - Discusses the process of saving, storing, and creating machine learning models.\n",
      "Topic 4: Training Jobs - Covers the process of launching, running, and describing training jobs in machine learning.\n",
      "Topic 5: Directory Specification - Discusses the process of specifying and defining directory paths in software engineering.\n",
      "Topic 6: Data Formatting - Covers the process of updating, converting, and changing data formats.\n",
      "Topic 7: Package Installation - Discusses the process of installing software packages.\n",
      "Topic 8: Documentation and Forums - Covers the use of documentation and forums for discussing software engineering topics.\n",
      "Topic 9: Dataset Registration - Discusses the process of registering, creating, and using datasets in data science.\n",
      "Topic 10: Argument Parsing - Covers the process of parsing, passing, and removing arguments and parameters in programming.\n",
      "Topic 11: URI Configuration - Discusses the process of configuring and testing Uniform Resource Identifiers (URIs).\n",
      "Topic 12: Configuration Updates - Covers the process of updating, changing, and editing software configurations.\n",
      "Topic 13: Bucket Specification - Discusses the process of specifying and editing buckets in cloud storage.\n",
      "Topic 14: Compute Targets - Covers the process of creating and using compute targets in cloud computing.\n",
      "Topic 15: Kernel Restart - Discusses the process of restarting, reinstalling, and updating kernels in operating systems.\n",
      "Topic 16: Permission Granting - Covers the process of granting and applying permissions in software systems.\n",
      "Topic 17: Ongoing Fixes - Discusses the process of fixing ongoing issues in software development.\n",
      "Topic 18: Package Downgrade - Covers the process of downgrading software packages and versions.\n",
      "Topic 19: Dependency Removal - Discusses the process of removing, adding, and updating software dependencies.\n",
      "Topic 20: Feature Requests - Covers the process of submitting, creating, and developing feature requests in software development.\n",
      "Topic 21: Environment Variables - Discusses the process of specifying, adding, and modifying environment variables in programming.\n",
      "Topic 22: Package Upgrade - Covers the process of upgrading and updating software packages.\n",
      "Topic 23: Ticket Management - Discusses the process of opening, reopening, and submitting tickets in software support.\n",
      "Topic 24: Authentication Configuration - Covers the process of configuring and adding authentication in software systems.\n",
      "Topic 25: Alternative Options - Discusses the consideration and use of alternative methods and options in software engineering.\n",
      "Topic 26: Script Usage - Covers the process of using, creating, and running scripts in programming.\n",
      "Topic 27: Data Export - Discusses the process of exporting data in data science.\n",
      "Topic 28: Tool Usage - Covers the use and integration of various tools in software engineering.\n",
      "Topic 29: Line Replacement - Discusses the process of updating, replacing, and removing lines and parameters in programming.\n",
      "Topic 30: Model Deployment - Covers the process of deploying models and automating deployments in machine learning.\n",
      "Topic 31: Endpoint Invocation - Discusses the process of invoking and automating endpoints in web services.\n",
      "Topic 32: Error Messaging - Covers the process of showing, suppressing, and communicating errors in software systems.\n",
      "Topic 33: Step Following - Discusses the process of following and reviewing steps in software development.\n",
      "Topic 34: File Download - Covers the process of downloading files and using download utilities in software systems.\n",
      "Topic 35: Run Status - Discusses the process of starting, stopping, and setting run statuses in software systems.\n",
      "Topic 36: Version Checking - Covers the process of checking and retrieving software package versions.\n",
      "Topic 37: Experiment Sharing - Discusses the process of creating, sharing, and applying experiments in data science.\n",
      "Topic 38: Service Updates - Covers the process of updating, enabling, and deploying web services.\n",
      "Topic 39: File Renaming - Discusses the process of renaming and modifying files in software systems.\n",
      "Topic 40: Fix Releases - Covers the process of releasing fixes in software development.\n",
      "Topic 41: Function Usage - Discusses the use and modification of functions in programming.\n",
      "Topic 42: File Upload - Covers the process of uploading files and data in software systems.\n",
      "Topic 43: Image Updates - Discusses the process of creating, changing, and using images in software systems.\n",
      "Topic 44: Feature Support - Covers the support and development of features in software systems.\n",
      "Topic 45: Docker Usage - Discusses the process of building and using Docker images and Dockerfiles.\n",
      "Topic 46: Detail Sharing - Covers the process of sharing details, examples, and stories in software development.\n",
      "Topic 47: Container Customization - Discusses the process of creating, building, and customizing containers in software systems.\n"
     ]
    }
   ],
   "source": [
    "prompt_topic = '''You will be given a list of stemmed words refering to specific software engineering topics. Please summarize each topic in terms and attach a one-liner description based on the stemmed words. Also, you must guarantee that the summaries are exclusive to one another.###\\n'''\n",
    "\n",
    "with open(os.path.join(path_solution, 'Topic terms.pickle'), 'rb') as handle:\n",
    "    topic_terms = pickle.load(handle)\n",
    "\n",
    "    topic_term_list = []\n",
    "    for index, topic in enumerate(topic_terms):\n",
    "        terms = ', '.join([term[0] for term in topic])\n",
    "        topic_term = f'Topic {index}: {terms}'\n",
    "        topic_term_list.append(topic_term)\n",
    "\n",
    "    prompt = prompt_topic + '\\n'.join(topic_term_list) + '\\n###\\n'\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "        temperature=0,\n",
    "        max_tokens=3000,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        timeout=300,\n",
    "        stream=False)\n",
    "\n",
    "    topics = completion.choices[0].message.content\n",
    "    print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw sankey diagram of tool and platform\n",
    "\n",
    "df = pd.read_json(os.path.join(path_special_output, 'topics.json'))\n",
    "df = df[df['Challenge_type'] != 'na']\n",
    "\n",
    "df['State'] = df['Challenge_closed_time'].apply(lambda x: 'closed' if not pd.isna(x) else 'open')\n",
    "\n",
    "categories = ['Platform', 'Tool', 'State']\n",
    "df_info = df.groupby(categories).size().reset_index(name='value')\n",
    "\n",
    "labels = {}\n",
    "newDf = pd.DataFrame()\n",
    "for i in range(len(categories)):\n",
    "    labels.update(df[categories[i]].value_counts().to_dict())\n",
    "    if i == len(categories)-1:\n",
    "        break\n",
    "    tempDf = df_info[[categories[i], categories[i+1], 'value']]\n",
    "    tempDf.columns = ['source', 'target', 'value']\n",
    "    newDf = pd.concat([newDf, tempDf])\n",
    "    \n",
    "newDf = newDf.groupby(['source', 'target']).agg({'value': 'sum'}).reset_index()\n",
    "source = newDf['source'].apply(lambda x: list(labels).index(x))\n",
    "target = newDf['target'].apply(lambda x: list(labels).index(x))\n",
    "value = newDf['value']\n",
    "\n",
    "labels = [f'{k} ({v})' for k, v in labels.items()]\n",
    "\n",
    "link = dict(source=source, target=target, value=value)\n",
    "node = dict(label=labels)\n",
    "data = go.Sankey(link=link, node=node)\n",
    "\n",
    "fig = go.Figure(data)\n",
    "fig.update_layout(width=1000, height=1000, font_size=20)\n",
    "fig.write_image(os.path.join(path_result_rq1, 'Tool platform state sankey.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add different metrics to each post\n",
    "\n",
    "df = pd.read_json(os.path.join(path_special_output, 'topics.json'))\n",
    "df = df[df['Challenge_type'] != 'na']\n",
    "\n",
    "df['Solution_word_count'] = np.nan\n",
    "df['Solution_sentence_count'] = np.nan\n",
    "df['Solution_readability'] = np.nan\n",
    "df['Solution_reading_time'] = np.nan\n",
    "df['Solution_link_count'] = np.nan\n",
    "\n",
    "df['Challenge_solved_time'] = np.nan\n",
    "df['Challenge_adjusted_solved_time'] = np.nan\n",
    "\n",
    "df['Solution_link_docs'] = np.nan\n",
    "df['Solution_link_issues'] = np.nan\n",
    "df['Solution_link_patches'] = np.nan\n",
    "df['Solution_link_tools'] = np.nan\n",
    "df['Solution_link_tutorials'] = np.nan\n",
    "df['Solution_link_examples'] = np.nan\n",
    "\n",
    "df['Challenge_created_time'] = pd.to_datetime(df['Challenge_created_time'])\n",
    "df['Challenge_closed_time'] = pd.to_datetime(df['Challenge_closed_time'])\n",
    "df['Challenge_last_edit_time'] = pd.to_datetime(df['Challenge_last_edit_time'])\n",
    "df['Solution_last_edit_time'] = pd.to_datetime(df['Solution_last_edit_time'])\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    challenge_content = row['Challenge_title'] + '.' + str(row['Challenge_body'])\n",
    "    df.at[index, 'Challenge_word_count'] = textstat.lexicon_count(challenge_content)\n",
    "    df.at[index, 'Challenge_sentence_count'] = textstat.sentence_count(challenge_content)\n",
    "    df.at[index, 'Challenge_readability'] = textstat.flesch_kincaid_grade(challenge_content)\n",
    "    df.at[index, 'Challenge_reading_time'] = textstat.reading_time(challenge_content)\n",
    "    \n",
    "    links = list(set(re.findall(link_pattern, challenge_content)))\n",
    "    df.at[index, 'Challenge_link_count'] = len(links)\n",
    "\n",
    "    solution_content = row['Solution_body']\n",
    "\n",
    "    if pd.notna(solution_content):\n",
    "        df.at[index, 'Solution_word_count'] = textstat.lexicon_count(solution_content)\n",
    "        df.at[index, 'Solution_sentence_count'] = textstat.sentence_count(solution_content)\n",
    "        df.at[index, 'Solution_readability'] = textstat.flesch_kincaid_grade(solution_content)\n",
    "        df.at[index, 'Solution_reading_time'] = textstat.reading_time(solution_content)\n",
    "        \n",
    "        links = list(set(re.findall(link_pattern, solution_content)))\n",
    "        df.at[index, 'Solution_link_count'] = len(links)\n",
    "        \n",
    "        link_docs = 0\n",
    "        link_tools = 0\n",
    "        link_issues = 0\n",
    "        link_patches = 0\n",
    "        link_tutorials = 0\n",
    "        link_examples = 0\n",
    "    \n",
    "        for link in links:\n",
    "            if any([patch in link for patch in keywords_patch]):\n",
    "                link_patches += 1\n",
    "            elif any([issue in link for issue in keywords_issue]):\n",
    "                link_issues += 1\n",
    "            elif any([tool in link for tool in keywords_tool]):\n",
    "                link_tools += 1\n",
    "            elif any([doc in link for doc in keywords_doc]):\n",
    "                link_docs += 1\n",
    "            elif any([tool in link for tool in keywords_tutorial]):\n",
    "                link_tutorials += 1\n",
    "            else:\n",
    "                link_examples += 1\n",
    "                \n",
    "        df.at[index, 'Solution_link_docs'] = link_docs\n",
    "        df.at[index, 'Solution_link_issues'] = link_issues\n",
    "        df.at[index, 'Solution_link_patches'] = link_patches\n",
    "        df.at[index, 'Solution_link_tools'] = link_tools\n",
    "        df.at[index, 'Solution_link_tutorials'] = link_tutorials\n",
    "        df.at[index, 'Solution_link_examples'] = link_examples\n",
    "        \n",
    "    creation_time = row['Challenge_created_time']\n",
    "    closed_time = row['Challenge_closed_time']\n",
    "    if pd.notna(creation_time) and pd.notna(closed_time) and (closed_time > creation_time):\n",
    "        df.at[index, 'Challenge_solved_time'] = (closed_time - creation_time) / pd.Timedelta(hours=1)\n",
    "\n",
    "    creation_time = row['Challenge_last_edit_time'] if pd.notna(row['Challenge_last_edit_time']) else creation_time\n",
    "    closed_time = row['Solution_last_edit_time'] if pd.notna(row['Solution_last_edit_time']) else closed_time\n",
    "    if pd.notna(creation_time) and pd.notna(closed_time) and (closed_time > creation_time):\n",
    "        df.at[index, 'Challenge_adjusted_solved_time'] = (closed_time - creation_time) / pd.Timedelta(hours=1)\n",
    "    else:\n",
    "        df.at[index, 'Challenge_adjusted_solved_time'] = df.at[index, 'Challenge_solved_time']\n",
    "\n",
    "df['Challenge_comment_count'] = df['Challenge_comment_count'].fillna(0)\n",
    "df['Challenge_answer_count'] = df['Challenge_answer_count'].fillna(0)\n",
    "df['Challenge_participation_count'] = df['Challenge_answer_count'] + df['Challenge_comment_count']\n",
    "\n",
    "df = df.reindex(sorted(df.columns), axis=1)\n",
    "df.to_json(os.path.join(path_result_rq1, 'metrics.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenge topic count distribution tree map\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_result_rq1, 'metrics.json'))\n",
    "df_topics['Challenge_topic_macro'] = df_topics['Challenge_topic_macro'].map(\n",
    "    macro_topic_index_mapping)\n",
    "df_topics['Solved'] = df_topics['Challenge_closed_time'].notna().map(\n",
    "    {True: 'Closed', False: 'Open'})\n",
    "df_topics['Count'] = 1\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Solved', 'Platform', 'Tool'],\n",
    "    values='Count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Platform', 'Solved', 'Tool'],\n",
    "    values='Count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Tool', 'Platform', 'Solved'],\n",
    "    values='Count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(\n",
    "    path_result_rq1, 'Challenge_topic_count_distribution.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenge view count distribution tree map\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_result_rq1, 'metrics.json'))\n",
    "df_topics['Challenge_topic_macro'] = df_topics['Challenge_topic_macro'].map(\n",
    "    macro_topic_index_mapping)\n",
    "df_topics['Solved'] = df_topics['Challenge_closed_time'].notna().map(\n",
    "    {True: 'Closed', False: 'Open'})\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Solved', 'Platform', 'Tool'],\n",
    "    values='Challenge_view_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Platform', 'Solved', 'Tool'],\n",
    "    values='Challenge_view_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Tool', 'Platform', 'Solved'],\n",
    "    values='Challenge_view_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(\n",
    "    path_result_rq1, 'Challenge_view_count_distribution.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenge score count distribution tree map\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_result_rq1, 'metrics.json'))\n",
    "df_topics['Challenge_topic_macro'] = df_topics['Challenge_topic_macro'].map(\n",
    "    macro_topic_index_mapping)\n",
    "df_topics['Solved'] = df_topics['Challenge_closed_time'].notna().map(\n",
    "    {True: 'Closed', False: 'Open'})\n",
    "df_topics['Challenge_score_count'] = df_topics['Challenge_score_count'].map(\n",
    "    lambda x: 1e-07 if x == 0 else x)\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Solved', 'Platform', 'Tool'],\n",
    "    values='Challenge_score_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Platform', 'Solved', 'Tool'],\n",
    "    values='Challenge_score_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Tool', 'Platform', 'Solved'],\n",
    "    values='Challenge_score_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(\n",
    "    path_result_rq1, 'Challenge_score_count_distribution.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenge favorite count distribution tree map\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_result_rq1, 'metrics.json'))\n",
    "df_topics['Challenge_topic_macro'] = df_topics['Challenge_topic_macro'].map(\n",
    "    macro_topic_index_mapping)\n",
    "df_topics['Solved'] = df_topics['Challenge_closed_time'].notna().map(\n",
    "    {True: 'Closed', False: 'Open'})\n",
    "df_topics['Challenge_favorite_count'] = df_topics['Challenge_favorite_count'].map(\n",
    "    lambda x: 1e-07 if x == 0 else x)\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Solved', 'Platform', 'Tool'],\n",
    "    values='Challenge_favorite_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Platform', 'Solved', 'Tool'],\n",
    "    values='Challenge_favorite_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Tool', 'Platform', 'Solved'],\n",
    "    values='Challenge_favorite_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(\n",
    "    path_result_rq1, 'Challenge_favorite_count_distribution.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenge answer count distribution tree map\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_result_rq1, 'metrics.json'))\n",
    "df_topics['Challenge_topic_macro'] = df_topics['Challenge_topic_macro'].map(\n",
    "    macro_topic_index_mapping)\n",
    "df_topics['Solved'] = df_topics['Challenge_closed_time'].notna().map(\n",
    "    {True: 'Closed', False: 'Open'})\n",
    "df_topics['Challenge_answer_count'] = df_topics['Challenge_answer_count'].map(\n",
    "    lambda x: 1e-07 if x == 0 else x)\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Solved', 'Platform', 'Tool'],\n",
    "    values='Challenge_answer_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Platform', 'Solved', 'Tool'],\n",
    "    values='Challenge_answer_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Tool', 'Platform', 'Solved'],\n",
    "    values='Challenge_answer_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(\n",
    "    path_result_rq1, 'Challenge_answer_count_distribution.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenge comment count distribution tree map\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_result_rq1, 'metrics.json'))\n",
    "df_topics['Challenge_topic_macro'] = df_topics['Challenge_topic_macro'].map(\n",
    "    macro_topic_index_mapping)\n",
    "df_topics['Solved'] = df_topics['Challenge_closed_time'].notna().map(\n",
    "    {True: 'Closed', False: 'Open'})\n",
    "df_topics['Challenge_comment_count'] = df_topics['Challenge_comment_count'].map(\n",
    "    lambda x: 1e-07 if x == 0 else x)\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Solved', 'Platform', 'Tool'],\n",
    "    values='Challenge_comment_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Platform', 'Solved', 'Tool'],\n",
    "    values='Challenge_comment_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Tool', 'Platform', 'Solved'],\n",
    "    values='Challenge_comment_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(\n",
    "    path_result_rq1, 'Challenge_comment_count_distribution.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenge topic participation distribution tree map\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_result_rq1, 'metrics.json'))\n",
    "df_topics['Challenge_topic_macro'] = df_topics['Challenge_topic_macro'].map(\n",
    "    macro_topic_index_mapping)\n",
    "df_topics['Solved'] = df_topics['Challenge_closed_time'].notna().map(\n",
    "    {True: 'Closed', False: 'Open'})\n",
    "df_topics['Challenge_participation_count'] = df_topics['Challenge_participation_count'].map(\n",
    "    lambda x: 1e-07 if x == 0 else x)\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Solved', 'Platform', 'Tool'],\n",
    "    values='Challenge_participation_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Platform', 'Solved', 'Tool'],\n",
    "    values='Challenge_participation_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Tool', 'Platform', 'Solved'],\n",
    "    values='Challenge_participation_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(\n",
    "    path_result_rq1, 'Challenge_participation_count_distribution.png'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
