{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import openai\n",
    "import textstat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The significance level indicates the probability of rejecting the null hypothesis when it is true.\n",
    "alpha = 0.05\n",
    "\n",
    "link_pattern = r'https?://[^\\s]+'\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None, 'display.max_colwidth', None)\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY', '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')\n",
    "\n",
    "keywords_patch = {\n",
    "    'pull',\n",
    "}\n",
    "\n",
    "keywords_issue = {\n",
    "    'answers',\n",
    "    'discussions',\n",
    "    'forums',\n",
    "    'issues',\n",
    "    'questions',\n",
    "    'stackoverflow',\n",
    "}\n",
    "\n",
    "keywords_tool = {\n",
    "    'github',\n",
    "    'gitlab',\n",
    "    'pypi',\n",
    "}\n",
    "\n",
    "keywords_doc = {\n",
    "    'developers',\n",
    "    'docs',\n",
    "    'documentation',\n",
    "    'features',\n",
    "    'library',\n",
    "    'org',\n",
    "    'wiki',\n",
    "}\n",
    "\n",
    "keywords_tutorial = {\n",
    "    'guide',\n",
    "    'learn',\n",
    "    'tutorial',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_result = '../../Result'\n",
    "\n",
    "path_result_rq1 = os.path.join(path_result, 'RQ1')\n",
    "path_code_rq1 = os.path.join('..', 'RQ1')\n",
    "\n",
    "path_general_output = os.path.join(path_result_rq1, 'General Topics')\n",
    "path_special_output = os.path.join(path_result_rq1, 'Special Topics')\n",
    "\n",
    "path_general_topic = os.path.join(path_code_rq1, 'General Topic Modeling')\n",
    "path_special_topic = os.path.join(path_code_rq1, 'Special Topic Modeling')\n",
    "\n",
    "path_anomaly = os.path.join(path_special_topic, 'Anomaly')\n",
    "path_root_cause = os.path.join(path_special_topic, 'Root Cause')\n",
    "path_solution = os.path.join(path_special_topic, 'Solution')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: Model Management - Handling and manipulation of models including training, saving, importing, and exporting.\n",
      "Topic 1: Data Pipelining - The process of managing and processing data through multiple pipelines.\n",
      "Topic 2: Package Installation - The process of installing, importing, and managing software packages using pip.\n",
      "Topic 3: Logging - The process of creating, tracking, and managing logs during model training.\n",
      "Topic 4: Docker Operations - Building, running, and managing Docker images and files.\n",
      "Topic 5: Access Management - Managing access permissions, roles, and tokens for secure operations.\n",
      "Topic 6: Data Labeling - The process of labeling data for training and object recognition.\n",
      "Topic 7: Git Operations - Managing data, files, and version control using Git.\n",
      "Topic 8: Bucket Operations - Managing files, data, and paths in storage buckets.\n",
      "Topic 9: Sweep Operations - Configuring, running, and managing multiple sweeps.\n",
      "Topic 10: Quota Management - Managing request quotas and handling limit exceptions.\n",
      "Topic 11: Remote Operations - Configuring, running, and connecting to remote files and executions.\n",
      "Topic 12: Batch Processing - Managing and processing data, files, and jobs in batches.\n",
      "Topic 13: Lambda Functions - Invoking and processing data using Lambda functions.\n",
      "Topic 14: Database Operations - Connecting, importing, and running operations on databases.\n",
      "Topic 15: Language Translation - Translating documents and languages using models.\n",
      "Topic 16: Panda Operations - Managing and converting files using Panda.\n",
      "Topic 17: Speech Processing - Handling audio files, generating speech, and transcribing services.\n",
      "Topic 18: Spark Operations - Configuring, implementing, and managing data using Spark.\n",
      "Topic 19: Instance Management - Creating, managing, and removing instances.\n",
      "Topic 20: Column Operations - Managing, cleaning, and visualizing data in columns.\n"
     ]
    }
   ],
   "source": [
    "prompt_topic = '''You will be given a list of stemmed words refering to specific software engineering topics. Please summarize each topic in terms and attach a one-liner description based on the stemmed words. Also, you must guarantee that the summaries are exclusive to one another.###\\n'''\n",
    "\n",
    "with open(os.path.join(path_general_topic, 'Topic terms.pickle'), 'rb') as handle:\n",
    "    topic_terms = pickle.load(handle)\n",
    "\n",
    "    topic_term_list = []\n",
    "    for index, topic in enumerate(topic_terms):\n",
    "        terms = ', '.join([term[0] for term in topic])\n",
    "        topic_term = f'Topic {index}: {terms}]'\n",
    "        topic_term_list.append(topic_term)\n",
    "\n",
    "    prompt = prompt_topic + '\\n'.join(topic_term_list) + '\\n###\\n'\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "        temperature=0,\n",
    "        max_tokens=3000,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        timeout=300,\n",
    "        stream=False)\n",
    "\n",
    "    topics = completion.choices[0].message.content\n",
    "    print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1: 'NA',\n",
       " 0: 'Model Management',\n",
       " 1: 'Pipeline Configuration',\n",
       " 2: 'Package Management',\n",
       " 3: 'Log Management',\n",
       " 4: 'Docker Configuration',\n",
       " 5: 'Access Control',\n",
       " 6: 'Label Management',\n",
       " 7: 'Git Configuration',\n",
       " 8: 'Bucket Management',\n",
       " 9: 'Sweep Management',\n",
       " 10: 'Quota Management',\n",
       " 11: 'Remote Configuration',\n",
       " 12: 'Batch Processing',\n",
       " 13: 'Lambda Configuration',\n",
       " 14: 'Database Management',\n",
       " 15: 'Language Translation',\n",
       " 16: 'Tabular Data Manipulation',\n",
       " 17: 'Speech Processing',\n",
       " 18: 'Spark Configuration',\n",
       " 19: 'Instance Management',\n",
       " 20: 'Columnar Data Manipulation'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = '''Topic 0: Model Management - Handling and manipulation of models including training, saving, importing, and exporting.\n",
    "Topic 1: Pipeline Configuration - The process of managing and processing data through multiple pipelines.\n",
    "Topic 2: Package Management - The process of installing, importing, and managing software packages using pip.\n",
    "Topic 3: Log Management - The process of creating, tracking, and managing logs during model training.\n",
    "Topic 4: Docker Configuration - Building, running, and managing Docker images and files.\n",
    "Topic 5: Access Control - Managing access permissions, roles, and tokens for secure operations.\n",
    "Topic 6: Label Management - The process of creating, adding, and modifying labels for raw data.\n",
    "Topic 7: Git Configuration - Managing data, files, and version control using Git.\n",
    "Topic 8: Bucket Management - Managing files, data, and paths in storage buckets.\n",
    "Topic 9: Sweep Management - Configuring, running, and managing multiple sweeps.\n",
    "Topic 10: Quota Management - Managing request quotas and handling limit exceptions.\n",
    "Topic 11: Remote Configuration - Configuring, running, and connecting to remote files and executions.\n",
    "Topic 12: Batch Processing - Managing and processing data, files, and jobs in batches.\n",
    "Topic 13: Lambda Configuration - Invoking and processing data using Lambda functions.\n",
    "Topic 14: Database Management - Connecting, importing, and running operations on databases.\n",
    "Topic 15: Language Translation - Translating documents and languages using models.\n",
    "Topic 16: Tabular Data Manipulation - Managing and converting files using Pandas.\n",
    "Topic 17: Speech Processing - Handling audio files, generating speech, and transcribing services.\n",
    "Topic 18: Spark Configuration - Configuring, implementing, and managing data using Spark.\n",
    "Topic 19: Instance Management - Creating, managing, and removing instances.\n",
    "Topic 20: Columnar Data Manipulation - Managing, cleaning, and visualizing data in columns.'''\n",
    "\n",
    "index = 0\n",
    "topic_dict = {-1: 'NA'}\n",
    "\n",
    "for topic in topics.split('\\n'):\n",
    "    topic_dict[index] = topic.split('-')[0].split(':')[-1].strip()\n",
    "    index += 1\n",
    "    \n",
    "topic_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Access Control': 1,\n",
       " 'Remote Configuration': 1,\n",
       " 'Git Configuration': 8,\n",
       " 'Batch Processing': 2,\n",
       " 'Spark Configuration': 2,\n",
       " 'Sweep Management': 2,\n",
       " 'Bucket Management': 3,\n",
       " 'Columnar Data Manipulation': 3,\n",
       " 'Database Management': 3,\n",
       " 'Label Management': 3,\n",
       " 'Tabular Data Manipulation': 3,\n",
       " 'Package Management': 4,\n",
       " 'Docker Configuration': 4,\n",
       " 'Instance Management': 4,\n",
       " 'Lambda Configuration': 4,\n",
       " 'Pipeline Configuration': 7,\n",
       " 'Model Management': 5,\n",
       " 'Log Management': 6,\n",
       " 'Quota Management': 6}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_topic_mapping_inverse = {\n",
    "    # These topics are all related to the management of permissions and connectivity.\n",
    "    1: ('Access Management', ['Access Control', 'Remote Configuration']),\n",
    "    # These topics are all related to the management of source code.\n",
    "    8: ('Code Management', ['Git Configuration']),\n",
    "    # These topics are all related to the management of data and datasets.\n",
    "    2: ('Compute Management', ['Batch Processing', 'Spark Configuration', 'Sweep Management']),\n",
    "    # These topics are all related to the management of services.\n",
    "    3: ('Data Management', ['Bucket Management', 'Columnar Data Manipulation', 'Database Management', 'Label Management', 'Tabular Data Manipulation']),\n",
    "    # These topics are all related to the management of packages and distributions.\n",
    "    4: ('Deployment Management', ['Package Management', 'Docker Configuration', 'Instance Management', 'Lambda Configuration']),\n",
    "    # These topics are all related to the management of pipelines.\n",
    "    7: ('Lifecycle Management', ['Pipeline Configuration']),\n",
    "    # These topics are all related to the management of machine learning models.\n",
    "    5: ('Model Management', ['Model Management']),\n",
    "    # These topics are all related to the management of logs and metrics.\n",
    "    6: ('Performance Management', ['Log Management', 'Quota Management']),\n",
    "}\n",
    "\n",
    "macro_topic_mapping = {}\n",
    "macro_topic_index_mapping = {}\n",
    "for key, (macro_topic, topics) in macro_topic_mapping_inverse.items():\n",
    "    macro_topic_index_mapping[macro_topic] = key\n",
    "    for topic in topics:\n",
    "        macro_topic_mapping[topic] = key\n",
    "\n",
    "macro_topic_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Number</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Access Management</td>\n",
       "      <td>872</td>\n",
       "      <td>7.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Compute Management</td>\n",
       "      <td>1106</td>\n",
       "      <td>9.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Management</td>\n",
       "      <td>1460</td>\n",
       "      <td>13.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deployment Management</td>\n",
       "      <td>2730</td>\n",
       "      <td>24.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Model Management</td>\n",
       "      <td>2378</td>\n",
       "      <td>21.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Performance Management</td>\n",
       "      <td>1122</td>\n",
       "      <td>10.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lifecycle Management</td>\n",
       "      <td>1105</td>\n",
       "      <td>9.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Code Management</td>\n",
       "      <td>344</td>\n",
       "      <td>3.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Topic  Number  Percentage\n",
       "0       Access Management     872        7.84\n",
       "1      Compute Management    1106        9.95\n",
       "2         Data Management    1460       13.13\n",
       "3   Deployment Management    2730       24.56\n",
       "4        Model Management    2378       21.39\n",
       "5  Performance Management    1122       10.09\n",
       "6    Lifecycle Management    1105        9.94\n",
       "7         Code Management     344        3.09"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign human-readable & high-level topics to challenges & solutions\n",
    "\n",
    "df = pd.read_json(os.path.join(path_general_output, 'topics.json'))\n",
    "df['Challenge_topic_macro'] = -1\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if topic_dict[row['Challenge_topic']] in macro_topic_mapping:\n",
    "        df.at[index, 'Challenge_topic_macro'] = macro_topic_mapping[topic_dict[row['Challenge_topic']]]\n",
    "    else:\n",
    "        df.drop(index, inplace=True)\n",
    "\n",
    "df.to_json(os.path.join(path_general_output, 'filtered.json'), indent=4, orient='records')\n",
    "\n",
    "def minimize_weighted_sum(df):\n",
    "    df_new = df.sort_values('Number', ascending=False)\n",
    "    n = len(df)\n",
    "    center_idx = (n - 1) // 2\n",
    "    direction = -1\n",
    "    distance = 0\n",
    "\n",
    "    for _, row in df_new.iterrows():\n",
    "        # Calculate the new index\n",
    "        new_idx = center_idx + direction * distance\n",
    "        \n",
    "        # Place the element from the sorted list into the new list\n",
    "        df.iloc[new_idx] = row\n",
    "\n",
    "        # If we've just moved to the left, increase the distance\n",
    "        if direction == -1:\n",
    "            distance += 1\n",
    "\n",
    "        # Switch the direction\n",
    "        direction *= -1\n",
    "\n",
    "    return df\n",
    "\n",
    "df_number = pd.DataFrame()\n",
    "for key, (macro_topic, topics) in macro_topic_mapping_inverse.items():\n",
    "    entry = {\n",
    "        'Topic': macro_topic,\n",
    "        'Number': len(df[df[\"Challenge_topic_macro\"] == key]),\n",
    "        'Percentage': round(len(df[df[\"Challenge_topic_macro\"] == key]) / len(df) * 100, 2),\n",
    "    }\n",
    "    df_number = pd.concat([df_number, pd.DataFrame([entry])], ignore_index=True)\n",
    "\n",
    "minimize_weighted_sum(df_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "# df['Challenge_topic_macro'] = -1\n",
    "# for index, row in df.iterrows():\n",
    "#     if topic_dict[row['Challenge_topic']] in macro_topic_mapping:\n",
    "#         df.at[index, 'Challenge_topic_macro'] = macro_topic_mapping[topic_dict[row['Challenge_topic']]]\n",
    "#     else:\n",
    "#         df.drop(index, inplace=True)\n",
    "\n",
    "# df.to_json(os.path.join(path_special_output, 'labels.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(os.path.join(path_general_output, 'filtered.json'))\n",
    "\n",
    "df['Challenge_type'] = 'na'\n",
    "df['Challenge_summary'] = 'na'\n",
    "df['Challenge_root_cause'] = 'na'\n",
    "df['Challenge_solution'] = 'na'\n",
    "\n",
    "df.to_json(os.path.join(path_special_output, 'labels.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# df = pd.read_json(os.path.join(path_general_output, 'filtered.json'))\n",
    "\n",
    "# df['Challenge_type'] = np.nan\n",
    "# df['Challenge_summary'] = np.nan\n",
    "# df['Challenge_root_cause'] = np.nan\n",
    "# df['Challenge_solution'] = np.nan\n",
    "\n",
    "# df.to_json(os.path.join(path_special_output, 'labels+.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     if (row['Challenge_root_cause'] != 'na') and (row['Challenge_root_cause'] == row['Challenge_summary']):\n",
    "#         df.at[index, 'Challenge_root_cause'] = 'na'\n",
    "#     if (row['Challenge_root_cause'] != 'na') and (row['Challenge_root_cause'] == row['Challenge_solution']):\n",
    "#         print(row['Challenge_root_cause'])\n",
    "        \n",
    "# df.to_json(os.path.join(path_special_output, 'labels.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "\n",
    "# df['Challenge_summary'] = df['Challenge_summary'].str.lower()\n",
    "# df['Challenge_root_cause'] = df['Challenge_root_cause'].str.lower()\n",
    "# df['Challenge_solution'] = df['Challenge_solution'].str.lower()\n",
    "\n",
    "# df.to_json(os.path.join(path_special_output, 'labels.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "\n",
    "# regex_digit = r\"[0-9]\"\n",
    "\n",
    "# regex_error = r\"[a-zA-Z0-9]+[eE]rror[^a-zA-Z]\"\n",
    "# regex_exception = r\"[a-zA-Z0-9]+[eE]xception[^a-zA-Z]\"\n",
    "\n",
    "# regex_error_leading = r\"[a-zA-Z0-9]+[eE]rror[a-zA-Z]+\"\n",
    "# regex_exception_leading = r\"[a-zA-Z0-9]+[eE]xception[a-zA-Z]+\"\n",
    "\n",
    "# false_positive_list = []\n",
    "\n",
    "# def camel_case_split(str):\n",
    "#     words = [[str[0].lower()]]\n",
    " \n",
    "#     for c in str[1:]:\n",
    "#         if (words[-1][-1].islower() or words[-1][-1].isdigit()) and c.isupper():\n",
    "#             words.append(list(c.lower()))\n",
    "#         else:\n",
    "#             words[-1].append(c)\n",
    "#     return ' '.join([''.join(word) for word in words])\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     challenge = row['Challenge_title'] + ' ' + row['Challenge_body']\n",
    "#     challenge = challenge.replace('\\n', ' ')\n",
    "#     error_list = re.findall(regex_error, challenge)\n",
    "#     if len(error_list):\n",
    "#         if row['Challenge_type'] != 'anomaly':\n",
    "#             df.at[index, 'Challenge_type'] = 'anomaly'\n",
    "#             false_positive_list.append(row['Challenge_link'])\n",
    "#         error = max(error_list, key = len)\n",
    "#         if len(re.findall(regex_digit, error)):\n",
    "#             print(row['Challenge_title'])\n",
    "#         else:\n",
    "#             error = re.sub(r'error.+', 'error', camel_case_split(error))\n",
    "#             df.at[index, 'Challenge_summary'] = error\n",
    "#     else:\n",
    "#         exception_list = re.findall(regex_exception, challenge)\n",
    "#         if len(exception_list):\n",
    "#             if row['Challenge_type'] != 'anomaly':\n",
    "#                 df.at[index, 'Challenge_type'] = 'anomaly'\n",
    "#                 false_positive_list.append(row['Challenge_link'])\n",
    "#             exception = max(exception_list, key = len)\n",
    "#             if len(re.findall(regex_digit, exception)):\n",
    "#                 print(row['Challenge_title'])\n",
    "#             else:\n",
    "#                 exception = re.sub(r'exception.+', 'exception', camel_case_split(exception))\n",
    "#                 df.at[index, 'Challenge_summary'] = exception\n",
    "#         else:\n",
    "#             error_list_leading = re.findall(regex_error_leading, challenge)\n",
    "#             if len(error_list_leading):\n",
    "#                 print(row['Challenge_title'])\n",
    "#             else:\n",
    "#                 exception_list_leading = re.findall(regex_exception_leading, challenge)\n",
    "#                 if len(exception_list_leading):\n",
    "#                     print(row['Challenge_title'])\n",
    "                    \n",
    "# df.to_json(os.path.join(path_special_output, 'anomaly.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker TuningStep Fails to Download Source Code\n",
      "Sagemaker endpoint fails to respond then PipeModeDataset is used\n",
      "run-notebook command not found after install sagemaker-run-notebook\n",
      "[Error] Notebook: sentiment-analysis.ipynb in SageMaker Studio with kernel Python3 (Tensorflow2 GPU Optimized)\n",
      "Question : how/when is source_dir copied into the sagemaker training instance?\n",
      "Output 'SageMakerRoleArn' not found in stack\n",
      "How to verify pytorch model inference is running on Inf1 sagemaker endpoint properly\n",
      "Sagemaker Neo Compilation for ARM64\n",
      "Loading DLR models compiled with Sagemaker Neo\n",
      "Broken link for Azure ML on https://docs.fast.ai/\n",
      "[BUG] Broken link (run_notebook_on_azureml) in readme\n",
      "ImportError: No module named 'azureml.core'\n",
      "command 'vscodeai.azureml.toolbar.submit' not found\n",
      "Command 'Azure ML: Connect to Compute Instance' resulted in an error \n",
      "import `Workspace` in Azure ML\n",
      "MLOps with Azure Machine Learning Service and Azure DevOps workshop guide is not available\n",
      "clearml.storage - ERROR - Google cloud driver not found\n",
      "I am getting a lot of errors while running dvc repro especially for fake_news module not found\n",
      "kedro airflow plugins: ValueError Pipeline input(s) not found in the DataCatalog\n",
      "Kedro executable not found in docker image\n",
      "MLflow support for conda-pack environments\n",
      "Test failed on `pytest -s python/tests/spark/sql/codegen/test_mlflow_registry.py::test_mlflow_model_from_model_version`\n",
      "[DOC-FIX] `model_store` different between torchserve and mlflow-torchserve\n",
      "MLflow Server EKS Service API 500\n",
      "MLflow EKS Service API 500\n",
      "No default MLFlow run to serve\n",
      "Experiment entry not found in MLFlow\n",
      "mlflow.exceptions.MlflowException: Run 'LIFFireNet' not found\n",
      "Unable to `pip` install - mlflow_tools/make_exps_page doesn't exist\n",
      "mlflow sagemaker build-and-push-container gives executor failed running exit code 127\n",
      "wandb: ERROR Error while calling W&B API: project not found (<Response [404]>) \n",
      "wandb logging does not seem to work (on Colab at least)\n",
      "requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://api.wandb.ai/graphql\n",
      "Error with wandb\n",
      "wandb error\n",
      "get_wandb_logger fails to retrieve WandbLogger when debug=True\n",
      "Reading Mp3 files from S3 to Sagemaker for feature extraction using LIBROSA\n",
      "Invoice parser \"invents\" non-existing string for supplier_name normalized value\n",
      "Error 404: AciDeploymentFailed\n",
      "How to get root access in SageMaker Studio Lab\n",
      "When pretrained model is not found, sagemaker falls into an infinite silent loop\n",
      "Sagemaker notebooks raise error for `pandas.CSVDataSet`\n",
      "[Bug] study fail to mount in SWB 5.2.6 SageMaker Jupyter Notebook\n",
      "[BUG] Error in some of the AzureML tests\n",
      "error when installing AZURE ML training model piece\n",
      "Fix the definition of pipelines/sentence_embedding/dvc.yaml\n",
      "dvc servername and url not found by calling \"dvc-cc run\"\n",
      "Can not create model in MLflowCatalog\n",
      "dbx deploy fails due to mlflow experiment not found\n",
      "[BUG]: Unable to Start DFP Production MLFlow Server\n",
      "running mlflow>1.28 projects causes mlflow not found error\n",
      "[mlflow] Run chart-testing (lint) step returns Error validating maintainer 404 Not Found error\n",
      "MLFlow and Hydra causing crash when used together\n",
      "Programmatically enable installed extensions in Vertex AI Managed Notebook instance\n",
      "Install Python Packages in Azure ML?\n",
      "Broken DAG: urllib3 1.25.3 (/home/ubuntu/.local/lib/python3.7/site-packages), Requirement.parse('urllib3<1.25,>=1.21'), {'sagemaker'}\n",
      "Is it possible to check that the version of a file tracked by a DVC metadata file exists in remote storage without pulling the file?\n",
      "GCP AI Platform Vertex endpoint model undeploy : 404 The DeployedModel with ID `2367889687867` is missing\n",
      "Is there a way to pass arguments to our own docker container in sagemaker?\n",
      "Kedro can not find SQL Server table\n",
      "No such file or directory: 'docker': 'docker' when running sagemaker studio in local mode\n",
      "sudo: not found on AWS Sagemaker Studio\n",
      "Using Sacred Module with iPython\n",
      "Azure ML endpoint 404 error\n",
      "Google Cloud Vertex AI with Golang: rpc error: code = Unimplemented desc = unexpected HTTP status code received from server: 404 (Not Found)\n",
      "Error Tracking in Amazon SageMaker\n",
      "Error in connecting Azure SQL database from Azure Machine Learning Service using python\n",
      "In GCP Vertex AI, why is Delete Training Pipeline REST endpoint unimplemented?\n",
      "Trying to work on R using Azure ML Studio Notebook and facing challenges with ODBC package\n",
      "Problem trying to authenticate with bearer token on nginx + oauth2-proxy + docker\n",
      "Failed ping healthcheck after deploying TF2.1 model with TF-serving-container on AWS Sagemaker\n",
      "Pycaret MlFlow authentication\n",
      "AWS SageMaker Studio Lab - Permission denied\n",
      "mlflow static_prefix url in set_tracking_uri is not working\n",
      "azureml how to deploy docker image to webservice\n",
      "i am getting error when deploying machine learning model in aci\n",
      "Model.get_model_path(model_name=\"model\") throws an error: Model not found in cache or in root at\n",
      "How do you use pyodbc in Azure Machine Learning Workbench\n",
      "Mlflow download_artifacts giving Not Found error\n",
      "Sagemaker deploy model with inference code and requirements\n",
      "\"Entry Point Not Found\" Error LightGBM R package in Azure\n",
      "How to save parquet in S3 from AWS SageMaker?\n",
      "Why can't I access Output from Vertex pipeline kfp component?\n",
      "How to deploy a detectron2 model using file in azureML\n",
      "install python package in Azure ml\n",
      "Automatically Install OpenJDK into SageMaker Notebook\n",
      "jsonschema 4.4.0 does not provide the extra 'isoduration'\n",
      "Readding missing files to DVC\n",
      "Kubeflow vs Vertex AI Pipelines\n",
      "Sagemaker batch transform \"ValueError: could not convert string to float\"\n",
      "How to mock an S3AFileSystem locally for testing spark.read.csv with pytest?\n",
      "BERT model loading not working with pytorch 1.3.1-eia container\n",
      "Sagemaker directory opt/ml/models does not store models to load them for inference\n",
      "Google.Cloud.AIPlatform.V1 Received http2 header with status: 404\n",
      "SageMaker deploy error \"serve\" executable file not found in $PATH\n",
      "Ensure Java is installed and PATH is set for `java` in Amazon SageMaker Jupyter Notebook\n",
      "Wandb line plots only show bar charts after refresh\n",
      "pyodbc not working in web-service container, Azure Model Management\n",
      "mlflow / app engine error code 405 method not allowed, when using remote tracking server\n",
      "MLFlow - running \"mlflow ui\" throwing file not found error on windows 10\n",
      "Sagemaker: Specifying custom entry point gives not found error\n",
      "Job submittal fails with : CondaHTTPError: HTTP 000 CONNECTION FAILED\n",
      "Import azure.core not found issue in running Notebook through MachineLearningStudio\n",
      "Installing additional R package (ImputeTS R Package) in Azure ML\n",
      "How should Pubsub, acting a log sink, fire a function without sending the log?\n",
      "AWS Sagemaker : No response back from the endpoint \"HTTP 301 293\"\n",
      "How to specify a name for the output file of a SageMaker Batch Transform job?\n",
      "mlflow Exception: Run with UUID is already active\n",
      "How to serve daily precomputed predictions in aws sagemaker?\n",
      "Still on ML-Flow installation in R Studio\n",
      "Vertex Pipeline Metric values not being added to metrics artifact?\n",
      "Automatic hyperparameter tuning in Sagemaker aws failed to run\n",
      "Set up health check for Sagemaker endpoint in Postman\n",
      "Deploying Huggingface model for inference - pytorch-scatter issues\n",
      "Azure ML Internal Server Error and 404 Error\n",
      "How to connect AzureML (Machine Learning) with AzureVM (Virtual Machine)?\n",
      "Sagemaker AlgorithmError: ExecuteUserScriptError:\n",
      "SagemakerTraining job catboost-classification-model , ErrorMessage \"TypeError: Cannot convert 'xxx'' to float\n",
      "Unable to access to mlflow ui\n",
      "Trying to query Azure SQL Database with Azure ML / Docker Image\n",
      "IDtoken retrieval in Vertex AI pipeline fails randomly\n",
      "No such file or directory: '/opt/ml/input/data/test/revenue_train.csv' Sagemaker [SM_CHANNEL_TRAIN]\n",
      "Can't access mounted Dataset on Azure Machine Learning Service Notebook\n",
      "PartitionedDataSet not found when Kedro pipeline is run in Docker\n",
      "SageMaker Studio Image - pip not found and no python 3 in terminal for Python 3 notebook instance\n",
      "sagmaker deploy() model gives error exec: \"serve\": executable file not found in $PATH\n",
      "How to use AWS Sagemaker XGBoost framework?\n",
      "How to delete a run_id from MLflow\n",
      "How to Set Java Home for Notebook in SageMaker\n",
      "Using ipyleaflet within a Vertex AI Managed Notebook running on a Docker image\n",
      "ERROR:root:Line magic function `%azureml` not found?\n",
      "Store scaler with mlflow keras-model\n",
      "MLflow saves models to relative place instead of tracking_uri\n",
      "How to observe and control how sagemaker multimodel server loads models in memory\n",
      "Read MobileNetSSd model files from azure ML Registered Models\n",
      "xgboost model prediction error : Input numpy.ndarray must be 2 dimensional\n",
      "How to load data from your S3 bucket to Sagemaker jupyter notebook to train the model?\n",
      "\"list index out of range\" error in AzureML inference schema\n",
      "Cannot use tensorboard with Vertex AI Custom job\n",
      "502 bad gateway error with upstream prematurely closed connection?\n",
      "AWS SageMaker models popping in and out of the vacuum\n",
      "Azure ML model deployment fail: Module not found error\n",
      "Sagemaker Batch Transform Error \"Model container failed to respond to ping; Ensure /ping endpoint is implemented and responds with an HTTP 200 status\"\n",
      "AzureML Model.profile() timeout without ever running the model\n",
      "Kedro 0.16.3 and kedro[spark.SparkDataSet] pip libraries cannot be installed together on databricks cluster\n",
      "%run works only once in Jupyter Notebook\n",
      "Amazon sagemaker Lifecycle configuration not working\n",
      "Azure Machine Learning: Remove pre-installed R packages\n",
      "How best to install dependencies in a Sagemaker PySpark cluster\n",
      "TemplatedConfigLoader in register_config_loader not replacing patterns in catalog.yml (kedro)\n",
      "Wandb throws Permission denied error although I am logged in\n",
      "Vertex AI Pipelines (Kubeflow) skip step with dependent outputs on later step\n",
      "How to upload .r file into azure ml studio and run it?\n",
      "No GPU detected on AWS SageMaker pytorch-1.8-gpu-py36 instance\n",
      "Azure ML Studio cannot load a installed package in R\n",
      "Can't connect to Azure ML Web Service in Azure Data Factory\n",
      "Load/access/mount directory to aws sagemaker from S3\n",
      "Cannot use `gcloud auth print-identity-token` from within Vertex AI Custom Job\n",
      "Mlflow not running on machine\n",
      "sagemaker batch transform breaks with upstream prematurely closed connection while reading upstream\n",
      "How can I use GPUs on Azure ML with a NVIDIA CUDA custom docker base image?\n",
      "AWS Sagemaker InvokeEndpoint: operation: Endpoint of account not found\n",
      "Converting PDF and PPTX files drawn from S3 into a JPG format\n",
      "Model pkl not found by SageMaker inference\n",
      "Vertex AI - Deployment failed\n",
      "Missing delimiter error when importing html text\n",
      "Installing private python wheel from a storage account\n",
      "Error loading model from mlflow: java.io.StreamCorruptedException: invalid type code: 00\n",
      "How to submit local jobs with dsl.pipeline\n",
      "Cannot import librosa on SageMaker Jupyter notebook instance \"OSError: sndfile library not found\"\n",
      "SageMaker Batch Transform fails to access nginx\n",
      "Getting this weird error when trying to run DVC pull\n",
      "AWS Sagemaker Spark S3 access issue\n",
      "Error in running Azure Data Factory Pipeline. Linked Service Reference not found\n",
      "AWS Lambda send image file to Amazon Sagemaker\n",
      "How do I setup the _SERVER_MODEL_PATH variable?\n",
      "In Azure ML - After Web service deployment, getting column name not found error\n",
      "how to use kedro.versioning in latest version of kedro?\n",
      "Azure ML R Model Train & Score Web Service\n",
      "Sagemaker suddenly unable to install python packages, missing python-dev\n",
      "How to deploy multiple ml models with scoring file using azure ml cli\n",
      "MLflow 1.2.0 define MLproject file\n",
      "Unable to connect Mlflow server to my mlflow project image\n",
      "AzureML schema \"list index out of range\" error\n",
      "Can't find scoring.py when using PythonScriptStep() in Databricks\n",
      "Facing this error : container_linux.go:367: starting container process caused: exec: \"python\": executable file not found in $PATH: unknown\n",
      "Creating a dataframe in Azure ML Notebook with R kernel\n",
      "Azure: importing not already existing packages in 'src'\n",
      "Running mlflow as a systemd service - gunicorn not found\n",
      "AWS CreateDeviceFleet operation fail because \"the account id does not have ownership on bucket\"\n",
      "Blankspace and colon not found in firstline\n",
      "Uniquely identify instances of VMs (Azure ML - web services)\n",
      "sagemaker notebook instance Elastic Inference tensorflow model local deployment\n",
      "Run !docker build from Managed Notebook cell in GCP Vertex AI Workbench\n",
      "How to avoid error \"conda --version: conda not found\" in az ml run --submit-script command?\n",
      "Is it possible to \"apt install\" in SageMaker Studio Lab?\n",
      "AWS Sagemaker + AWS Lambda\n",
      "Where to perform the saving of an nodeoutput in Kedro?\n",
      "Installing additional R Package on Azure ML\n",
      "Unable to use GPU to train a NN model in azure machine learning service using P100-NC6s-V2 compute. Fails wth CUDA error\n",
      "Amazon SageMaker: ClientError: Data download failed:NoSuchKey (404): The specified key does not exist\n",
      "Vertex AI Custom Container Training Job python SDK - google.api_core.exceptions.FailedPrecondition: 400 '\n",
      "Jobs-Cloud Scheduler (Google Cloud) fails to run scheduled pipelines\n",
      "kedro context and catalog missing from ipython session\n",
      "How to install OpenJDK library?\n",
      "how to set path of bucket in amazonsagemaker jupyter notebook?\n",
      "Adding a {serve} metagraph to existing Tensorflow model\n",
      "mlflow serving r models failed if use LDA instead of linear regression\n",
      "Azure ML Online Endpoint deployment DriverFileNotFound Error\n",
      "Errors while using sagemaker api to invoke endpoints\n",
      "How combine results from multiple models in Google Vertex AI?\n",
      "How to explicitly set sagemaker autopilot's validation set?\n",
      "Gluonnlp installation not found on Sagemaker jupyter notebook\n",
      "Compare String with list of strings in bash\n",
      "AzureML Environment for Inference : can't add pip packages to dependencies\n",
      "SQLAlchemy Oracle - InvalidRequestError: could not retrieve isolation level\n",
      "how SageMaker to access s3 bucket data\n",
      "Failed to pull existing files from SSH DVC Remote\n",
      "'azureml.logging' module not found\n",
      "Vertex AI custom prediction vs Google Kubernetes Engine\n",
      "Reading File from Vertex AI and Google Cloud Storage\n",
      "cloud 9 and sagemaker - hyper parameter optimisation\n",
      "AWS SageMaker S3 os.listdir() Access denied\n",
      "Docker image not found during local deployment (\"no such image\")\n",
      "How do you write lifecycle configurations for SageMaker on windows?\n",
      "What is the name of the driver to connect to Azure SQL Database from pyodbc in Azure ML?\n",
      "Is there a way to un-register an environment in Azure ML studio\n",
      "Azure-ML Deployment does NOT see AzureML Environment (wrong version number)\n",
      "How can we get the pipeline to read columns with special characters?\n",
      "how create azure machine learning scoring image using local package\n",
      "Simple but frustrating error: Google.cloud module not found\n",
      "Custom container image not found by Vertex AI for model upload\n",
      "Sweep creation down? (Resolved)\n",
      "404 response executing GraphQL\n",
      "Agent bug? File not found error\n",
      "404 error running sweep from local jupyter nb\n",
      "I think that W&B is having some connection issues since yesterday night\n",
      "ModuleNotFoundError: No module named 'nvgpu' in sagemaker batch transform\n",
      "install java dependency when building my own processing container\n",
      "Java not found when running Sagemaker Studio python notebooks\n",
      "Batch transform step not working\n",
      "Sagemaker Neo compilation fails\n",
      "NVMLError_FunctionNotFound: I was trying to deploy a PyTorch model in a ml.g4dn.xlarge instance\n",
      "Unable to select a compute type in SageMaker Studio Lab\n",
      "Sagemaker Batch Transform - \"upstream prematurely closed connection\" - Unable to serve requests that take longer than 30 minutes\n",
      "Issues with exposing SKLearn model as endpoint on AWS Sagemaker\n",
      "Error Creating Endpoint\n",
      "SQL Server driver issue on notebook instance running on AWS SageMaker\n",
      "No such file or directory: '/opt/ml/input/data/test/revenue_train.csv' Sagemaker [SM_CHANNEL_TRAIN]\n",
      "Error for Training job catboost-classification-model , ErrorMessage \"TypeError: Cannot convert 'xxx'' to float\n",
      "Sagemaker Endpoint is not created when deploying HuggingFace Model using it.\n",
      "Export Autopilot model to GovCloud region\n",
      "passing a numpy array to predict_fn when making inference for xgboost model\n",
      "Failed ping healthcheck after deploying TF2.1 model with TF-serving-contain\n",
      "Custom packages in Sagemaker studio\n",
      "Trouble deploying SageMaker trained model in DeepLens\n",
      "ERROR: unexpected error - [Errno 2] No such file or directory:\n",
      "Dvc remote drive\n",
      "Cannot apply the first exp after new commit\n",
      "I have added my google drive as a remote storage\n",
      "DVC list shows libssl-so.1.1.1k not found\n",
      "Problem with top-level plot definitions\n",
      "SSH remote: unexpected error - Permission denied\n",
      "What to do if the file is not found in the repo?\n",
      "Track remote data on Azure\n",
      "Can't go to former version of dataset with `dvc checkout`\n",
      "Documentation: tutorial problem?\n",
      "How to save or log pytorch model using MLflow?\n",
      "Local run in azureml sdk2\n",
      "Missing ODBC drivers in Azure ML Compute Instances\n",
      "Bing Search API not working\n",
      "How to fix Apply Transformation error?\n",
      "how to modify the template script on azure auto ml?\n",
      "While running an Azure ML Experiement, I get \"File Not found\" error when attempting to find ODBC driver for python pyodbc.connect command\n",
      "ClusterIdentityNotFound when submitting experiment.\n",
      "Using Azure ML Studio Designer with R script: package not found but I installed it on the compute instance\n",
      "Azure ML Studio can't generate job when datastore is used as input; failed string validation? Also, code files not being loaded on job.\n",
      "How to  give Source Directory on the step pipeline in Azure Machine Learning\n",
      "Azure machine learning samples 404\n",
      "Error 404 for design pipelines\n",
      "Pickle Load- File Not Found when deploying using Azure ML Studio\n",
      "azure machine learning SubscriptionNotFound\n",
      "Swagger file not present -- Azure Machine Learning\n",
      "Azureml compute instance spark dependencies missing\n",
      "Local compute not found error when running a hyperparameter search\n",
      "Multiple new errors when deploying to ACI webservice\n",
      "After Web service deployment, getting column name not found error\n",
      "Module Not Found Error when launching parameter study\n",
      "How to import Microsoft.RelInfra.Common.Exception so that it could be properly handled?\n",
      "The azure cli command \"az ml attach folder\" is directly adding .azureml directory to .amlignore , so where to put config.json when using Azure devops pipeline to submit script to aml workspace?\n",
      "Failure when submitting pipe line\n",
      "Issues about Azure Machine Learning Studio\n",
      "How to use a working pipeline on live dataset?\n",
      "Getting 500 errors after model deployment\n",
      "Azure-cli-ml Version: '1.33.0', 'Error': WebserviceException. Can't deploy model into ACI\n",
      "Machine Learning CI Pipeline: Submitting an experiment failed\n",
      "How to use a registred model in a python script(in Azure) ?\n",
      "i am getting error when deploying machine learning model in aci\n",
      "i am getting error when deploying machine learning model in aci\n",
      "Endopint not consumable after successful model deployment to azure instance container (machine learning studio - designer)\n",
      "Cannot use GPU on Azure Notebooks in Azure Machine Learning Studio\n",
      "Deploying spark-nlp model using custom docker image fails in Azure Machine Learning\n",
      "Import Data Error - DocumentDb library exception: DocumentDB client threw an exception . ( Error 1000 ) Using Machine learning studio (classic)\n",
      "azureml when deployment fails from local source directory\n",
      "Module not found when custom python package installed via shell script\n",
      "Registered AzureML Model from a NotebookVM can not be found\n",
      "Isn't Interactive login, default for Workspace.from_config()?\n",
      "Investigating AML workspace images crashes due to already deleted model\n",
      "Rest api to create or update azure ML workspace doesn't create dependant resources\n",
      "Model file is not found for Registration of model in training Pipeline.\n",
      "Opening source file causes File not found exception\n",
      "Guild view not working in jupyterhub\n",
      "Local run vs remote run dependencies\n",
      "Tensorboard FileNot found error on Windows-10, guild-0.7.3.dev1\n",
      "Guild runs on remote not found\n",
      "sqlite3.OperationalError: disk I/O error when using the scratch drive on Linux cluster for storage of guild runs\n",
      "MLflow-Docker Artifacts Model Not Found\n",
      "Model Deployment Issues\n",
      "Deploy problems\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "\n",
    "# regex_digit = r\"[0-9]\"\n",
    "\n",
    "# regex_error = r\"[a-zA-Z0-9]+[eE]rror[^a-zA-Z]\"\n",
    "# regex_exception = r\"[a-zA-Z0-9]+[eE]xception[^a-zA-Z]\"\n",
    "\n",
    "# regex_error_leading = r\"[a-zA-Z0-9]+[eE]rror[a-zA-Z]+\"\n",
    "# regex_exception_leading = r\"[a-zA-Z0-9]+[eE]xception[a-zA-Z]+\"\n",
    "\n",
    "# def camel_case_split(str):\n",
    "#     words = [[str[0].lower()]]\n",
    " \n",
    "#     for c in str[1:]:\n",
    "#         if (words[-1][-1].islower() or words[-1][-1].isdigit()) and c.isupper():\n",
    "#             words.append(list(c.lower()))\n",
    "#         else:\n",
    "#             words[-1].append(c)\n",
    "#     return ' '.join([''.join(word) for word in words])\n",
    "\n",
    "# titles = []\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     if row['Challenge_title'] in titles:\n",
    "#         continue\n",
    "#     challenge = row['Challenge_title'] + ' ' + row['Challenge_body']\n",
    "#     challenge = challenge.replace('\\n', ' ').lower()\n",
    "#     if (' 403 ' in challenge) or ('[403]' in challenge) or ('(403)' in challenge) or (' 403,' in challenge) or ('forbidden' in challenge):\n",
    "#         pass\n",
    "#         # print(row['Challenge_title'])\n",
    "#         # df.at[index, 'Challenge_type'] = 'anomaly'\n",
    "#         # df.at[index, 'Challenge_summary'] = 'forbidden error'\n",
    "#     elif (' 404 ' in challenge) or ('[404]' in challenge) or ('(404)' in challenge) or (' 404,' in challenge) or ('not found' in challenge):\n",
    "#         print(row['Challenge_title'])\n",
    "        \n",
    "# # df.to_json(os.path.join(path_special_output, 'labels.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "\n",
    "# for i,r in df.iterrows():\n",
    "#     if r['Challenge_type'] == 'inquiry':\n",
    "#         df.at[i, 'Challenge_summary'] = 'na'\n",
    "#         df.at[i, 'Challenge_root_cause'] = 'na'\n",
    "\n",
    "# df.to_json(os.path.join(path_special_output, 'labels.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new = pd.read_json(os.path.join(path_special_output, 'labels+.json'))\n",
    "# df_old = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "\n",
    "# df = pd.concat([df_new, df_old], ignore_index=True)\n",
    "# df = df.drop_duplicates(['Challenge_link'], keep=False)\n",
    "\n",
    "# df = df[df['Challenge_type'].isna()]\n",
    "# df.to_json(os.path.join(path_special_output, 'extra.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new = pd.read_json(os.path.join(path_special_output, 'labels++.json'))\n",
    "# df_old = pd.read_json(os.path.join(path_special_output, 'extra.json'))\n",
    "\n",
    "# df = pd.concat([df_old, df_new], ignore_index=True)\n",
    "# df = df.drop_duplicates(['Challenge_link'])\n",
    "\n",
    "# df.to_json(os.path.join(path_special_output, 'extra+.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new = pd.read_json(os.path.join(path_special_output, 'labels+.json'))\n",
    "# df = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "\n",
    "# for index, row in df_new.iterrows():\n",
    "#     for i2,r2 in df.iterrows():\n",
    "#         if r2['Challenge_type'] == 'na':\n",
    "#             continue\n",
    "#         if r2['Challenge_link'] == row['Challenge_link']:\n",
    "#             df_new.at[index, 'Challenge_type'] = r2['Challenge_type']\n",
    "#             df_new.at[index, 'Challenge_summary'] = r2['Challenge_summary']\n",
    "#             df_new.at[index, 'Challenge_root_cause'] = r2['Challenge_root_cause']\n",
    "#             df_new.at[index, 'Challenge_solution'] = r2['Challenge_solution']\n",
    "#             break\n",
    "            \n",
    "# df_new.to_json(os.path.join(path_special_output, 'labels++.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_topic = '''You will be given a list of stemmed words refering to specific software engineering topics. Please summarize each topic in terms and attach a one-liner description based on the stemmed words. Also, you must guarantee that the summaries are exclusive to one another.###\\n'''\n",
    "\n",
    "with open(os.path.join(path_anomaly, 'Topic terms.pickle'), 'rb') as handle:\n",
    "    topic_terms = pickle.load(handle)\n",
    "\n",
    "    topic_term_list = []\n",
    "    for index, topic in enumerate(topic_terms):\n",
    "        terms = ', '.join([term[0] for term in topic])\n",
    "        topic_term = f'Topic {index}: {terms}'\n",
    "        topic_term_list.append(topic_term)\n",
    "\n",
    "    prompt = prompt_topic + '\\n'.join(topic_term_list) + '\\n###\\n'\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "        temperature=0,\n",
    "        max_tokens=3000,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        timeout=500,\n",
    "        stream=False)\n",
    "\n",
    "    topics = completion.choices[0].message.content\n",
    "    print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_topic = '''You will be given a list of stemmed words refering to specific software engineering topics. Please summarize each topic in terms and attach a one-liner description based on the stemmed words. Also, you must guarantee that the summaries are exclusive to one another.###\\n'''\n",
    "\n",
    "with open(os.path.join(path_root_cause, 'Topic terms.pickle'), 'rb') as handle:\n",
    "    topic_terms = pickle.load(handle)\n",
    "\n",
    "    topic_term_list = []\n",
    "    for index, topic in enumerate(topic_terms):\n",
    "        terms = ', '.join([term[0] for term in topic])\n",
    "        topic_term = f'Topic {index}: {terms}'\n",
    "        topic_term_list.append(topic_term)\n",
    "\n",
    "    prompt = prompt_topic + '\\n'.join(topic_term_list) + '\\n###\\n'\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "        temperature=0,\n",
    "        max_tokens=3000,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        timeout=300,\n",
    "        stream=False)\n",
    "\n",
    "    topics = completion.choices[0].message.content\n",
    "    print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_topic = '''You will be given a list of stemmed words refering to specific software engineering topics. Please summarize each topic in terms and attach a one-liner description based on the stemmed words. Also, you must guarantee that the summaries are exclusive to one another.###\\n'''\n",
    "\n",
    "with open(os.path.join(path_solution, 'Topic terms.pickle'), 'rb') as handle:\n",
    "    topic_terms = pickle.load(handle)\n",
    "\n",
    "    topic_term_list = []\n",
    "    for index, topic in enumerate(topic_terms):\n",
    "        terms = ', '.join([term[0] for term in topic])\n",
    "        topic_term = f'Topic {index}: {terms}'\n",
    "        topic_term_list.append(topic_term)\n",
    "\n",
    "    prompt = prompt_topic + '\\n'.join(topic_term_list) + '\\n###\\n'\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "        temperature=0,\n",
    "        max_tokens=3000,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        timeout=300,\n",
    "        stream=False)\n",
    "\n",
    "    topics = completion.choices[0].message.content\n",
    "    print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw sankey diagram of tool and platform\n",
    "\n",
    "df = pd.read_json(os.path.join(path_special_output, 'topics.json'))\n",
    "df = df[df['Challenge_type'] != 'na']\n",
    "\n",
    "df['State'] = df['Challenge_closed_time'].apply(lambda x: 'closed' if not pd.isna(x) else 'open')\n",
    "\n",
    "categories = ['Platform', 'Tool', 'State']\n",
    "df_info = df.groupby(categories).size().reset_index(name='value')\n",
    "\n",
    "labels = {}\n",
    "newDf = pd.DataFrame()\n",
    "for i in range(len(categories)):\n",
    "    labels.update(df[categories[i]].value_counts().to_dict())\n",
    "    if i == len(categories)-1:\n",
    "        break\n",
    "    tempDf = df_info[[categories[i], categories[i+1], 'value']]\n",
    "    tempDf.columns = ['source', 'target', 'value']\n",
    "    newDf = pd.concat([newDf, tempDf])\n",
    "    \n",
    "newDf = newDf.groupby(['source', 'target']).agg({'value': 'sum'}).reset_index()\n",
    "source = newDf['source'].apply(lambda x: list(labels).index(x))\n",
    "target = newDf['target'].apply(lambda x: list(labels).index(x))\n",
    "value = newDf['value']\n",
    "\n",
    "labels = [f'{k} ({v})' for k, v in labels.items()]\n",
    "\n",
    "link = dict(source=source, target=target, value=value)\n",
    "node = dict(label=labels)\n",
    "data = go.Sankey(link=link, node=node)\n",
    "\n",
    "fig = go.Figure(data)\n",
    "fig.update_layout(width=1000, height=1000, font_size=20)\n",
    "fig.write_image(os.path.join(path_result_rq1, 'Tool platform state sankey.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add different metrics to each post\n",
    "\n",
    "df = pd.read_json(os.path.join(path_special_output, 'topics.json'))\n",
    "df = df[df['Challenge_type'] != 'na']\n",
    "\n",
    "df['Solution_word_count'] = np.nan\n",
    "df['Solution_sentence_count'] = np.nan\n",
    "df['Solution_readability'] = np.nan\n",
    "df['Solution_reading_time'] = np.nan\n",
    "df['Solution_link_count'] = np.nan\n",
    "\n",
    "df['Challenge_solved_time'] = np.nan\n",
    "df['Challenge_adjusted_solved_time'] = np.nan\n",
    "\n",
    "df['Solution_link_docs'] = np.nan\n",
    "df['Solution_link_issues'] = np.nan\n",
    "df['Solution_link_patches'] = np.nan\n",
    "df['Solution_link_tools'] = np.nan\n",
    "df['Solution_link_tutorials'] = np.nan\n",
    "df['Solution_link_examples'] = np.nan\n",
    "\n",
    "df['Challenge_created_time'] = pd.to_datetime(df['Challenge_created_time'])\n",
    "df['Challenge_closed_time'] = pd.to_datetime(df['Challenge_closed_time'])\n",
    "df['Challenge_last_edit_time'] = pd.to_datetime(df['Challenge_last_edit_time'])\n",
    "df['Solution_last_edit_time'] = pd.to_datetime(df['Solution_last_edit_time'])\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    challenge_content = row['Challenge_title'] + '.' + str(row['Challenge_body'])\n",
    "    df.at[index, 'Challenge_word_count'] = textstat.lexicon_count(challenge_content)\n",
    "    df.at[index, 'Challenge_sentence_count'] = textstat.sentence_count(challenge_content)\n",
    "    df.at[index, 'Challenge_readability'] = textstat.flesch_kincaid_grade(challenge_content)\n",
    "    df.at[index, 'Challenge_reading_time'] = textstat.reading_time(challenge_content)\n",
    "    \n",
    "    links = list(set(re.findall(link_pattern, challenge_content)))\n",
    "    df.at[index, 'Challenge_link_count'] = len(links)\n",
    "\n",
    "    solution_content = row['Solution_body']\n",
    "\n",
    "    if pd.notna(solution_content):\n",
    "        df.at[index, 'Solution_word_count'] = textstat.lexicon_count(solution_content)\n",
    "        df.at[index, 'Solution_sentence_count'] = textstat.sentence_count(solution_content)\n",
    "        df.at[index, 'Solution_readability'] = textstat.flesch_kincaid_grade(solution_content)\n",
    "        df.at[index, 'Solution_reading_time'] = textstat.reading_time(solution_content)\n",
    "        \n",
    "        links = list(set(re.findall(link_pattern, solution_content)))\n",
    "        df.at[index, 'Solution_link_count'] = len(links)\n",
    "        \n",
    "        link_docs = 0\n",
    "        link_tools = 0\n",
    "        link_issues = 0\n",
    "        link_patches = 0\n",
    "        link_tutorials = 0\n",
    "        link_examples = 0\n",
    "    \n",
    "        for link in links:\n",
    "            if any([patch in link for patch in keywords_patch]):\n",
    "                link_patches += 1\n",
    "            elif any([issue in link for issue in keywords_issue]):\n",
    "                link_issues += 1\n",
    "            elif any([tool in link for tool in keywords_tool]):\n",
    "                link_tools += 1\n",
    "            elif any([doc in link for doc in keywords_doc]):\n",
    "                link_docs += 1\n",
    "            elif any([tool in link for tool in keywords_tutorial]):\n",
    "                link_tutorials += 1\n",
    "            else:\n",
    "                link_examples += 1\n",
    "                \n",
    "        df.at[index, 'Solution_link_docs'] = link_docs\n",
    "        df.at[index, 'Solution_link_issues'] = link_issues\n",
    "        df.at[index, 'Solution_link_patches'] = link_patches\n",
    "        df.at[index, 'Solution_link_tools'] = link_tools\n",
    "        df.at[index, 'Solution_link_tutorials'] = link_tutorials\n",
    "        df.at[index, 'Solution_link_examples'] = link_examples\n",
    "        \n",
    "    creation_time = row['Challenge_created_time']\n",
    "    closed_time = row['Challenge_closed_time']\n",
    "    if pd.notna(creation_time) and pd.notna(closed_time) and (closed_time > creation_time):\n",
    "        df.at[index, 'Challenge_solved_time'] = (closed_time - creation_time) / pd.Timedelta(hours=1)\n",
    "\n",
    "    creation_time = row['Challenge_last_edit_time'] if pd.notna(row['Challenge_last_edit_time']) else creation_time\n",
    "    closed_time = row['Solution_last_edit_time'] if pd.notna(row['Solution_last_edit_time']) else closed_time\n",
    "    if pd.notna(creation_time) and pd.notna(closed_time) and (closed_time > creation_time):\n",
    "        df.at[index, 'Challenge_adjusted_solved_time'] = (closed_time - creation_time) / pd.Timedelta(hours=1)\n",
    "    else:\n",
    "        df.at[index, 'Challenge_adjusted_solved_time'] = df.at[index, 'Challenge_solved_time']\n",
    "\n",
    "df['Challenge_comment_count'] = df['Challenge_comment_count'].fillna(0)\n",
    "df['Challenge_answer_count'] = df['Challenge_answer_count'].fillna(0)\n",
    "df['Challenge_participation_count'] = df['Challenge_answer_count'] + df['Challenge_comment_count']\n",
    "\n",
    "df = df.reindex(sorted(df.columns), axis=1)\n",
    "df.to_json(os.path.join(path_result_rq1, 'metrics.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenge topic count distribution tree map\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_result_rq1, 'metrics.json'))\n",
    "df_topics['Challenge_topic_macro'] = df_topics['Challenge_topic_macro'].map(\n",
    "    macro_topic_index_mapping)\n",
    "df_topics['Solved'] = df_topics['Challenge_closed_time'].notna().map(\n",
    "    {True: 'Closed', False: 'Open'})\n",
    "df_topics['Count'] = 1\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Solved', 'Platform', 'Tool'],\n",
    "    values='Count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Platform', 'Solved', 'Tool'],\n",
    "    values='Count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Tool', 'Platform', 'Solved'],\n",
    "    values='Count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(\n",
    "    path_result_rq1, 'Challenge_topic_count_distribution.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenge view count distribution tree map\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_result_rq1, 'metrics.json'))\n",
    "df_topics['Challenge_topic_macro'] = df_topics['Challenge_topic_macro'].map(\n",
    "    macro_topic_index_mapping)\n",
    "df_topics['Solved'] = df_topics['Challenge_closed_time'].notna().map(\n",
    "    {True: 'Closed', False: 'Open'})\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Solved', 'Platform', 'Tool'],\n",
    "    values='Challenge_view_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Platform', 'Solved', 'Tool'],\n",
    "    values='Challenge_view_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Tool', 'Platform', 'Solved'],\n",
    "    values='Challenge_view_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(\n",
    "    path_result_rq1, 'Challenge_view_count_distribution.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenge score count distribution tree map\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_result_rq1, 'metrics.json'))\n",
    "df_topics['Challenge_topic_macro'] = df_topics['Challenge_topic_macro'].map(\n",
    "    macro_topic_index_mapping)\n",
    "df_topics['Solved'] = df_topics['Challenge_closed_time'].notna().map(\n",
    "    {True: 'Closed', False: 'Open'})\n",
    "df_topics['Challenge_score_count'] = df_topics['Challenge_score_count'].map(\n",
    "    lambda x: 1e-07 if x == 0 else x)\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Solved', 'Platform', 'Tool'],\n",
    "    values='Challenge_score_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Platform', 'Solved', 'Tool'],\n",
    "    values='Challenge_score_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Tool', 'Platform', 'Solved'],\n",
    "    values='Challenge_score_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(\n",
    "    path_result_rq1, 'Challenge_score_count_distribution.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenge favorite count distribution tree map\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_result_rq1, 'metrics.json'))\n",
    "df_topics['Challenge_topic_macro'] = df_topics['Challenge_topic_macro'].map(\n",
    "    macro_topic_index_mapping)\n",
    "df_topics['Solved'] = df_topics['Challenge_closed_time'].notna().map(\n",
    "    {True: 'Closed', False: 'Open'})\n",
    "df_topics['Challenge_favorite_count'] = df_topics['Challenge_favorite_count'].map(\n",
    "    lambda x: 1e-07 if x == 0 else x)\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Solved', 'Platform', 'Tool'],\n",
    "    values='Challenge_favorite_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Platform', 'Solved', 'Tool'],\n",
    "    values='Challenge_favorite_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Tool', 'Platform', 'Solved'],\n",
    "    values='Challenge_favorite_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(\n",
    "    path_result_rq1, 'Challenge_favorite_count_distribution.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenge answer count distribution tree map\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_result_rq1, 'metrics.json'))\n",
    "df_topics['Challenge_topic_macro'] = df_topics['Challenge_topic_macro'].map(\n",
    "    macro_topic_index_mapping)\n",
    "df_topics['Solved'] = df_topics['Challenge_closed_time'].notna().map(\n",
    "    {True: 'Closed', False: 'Open'})\n",
    "df_topics['Challenge_answer_count'] = df_topics['Challenge_answer_count'].map(\n",
    "    lambda x: 1e-07 if x == 0 else x)\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Solved', 'Platform', 'Tool'],\n",
    "    values='Challenge_answer_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Platform', 'Solved', 'Tool'],\n",
    "    values='Challenge_answer_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Tool', 'Platform', 'Solved'],\n",
    "    values='Challenge_answer_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(\n",
    "    path_result_rq1, 'Challenge_answer_count_distribution.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenge comment count distribution tree map\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_result_rq1, 'metrics.json'))\n",
    "df_topics['Challenge_topic_macro'] = df_topics['Challenge_topic_macro'].map(\n",
    "    macro_topic_index_mapping)\n",
    "df_topics['Solved'] = df_topics['Challenge_closed_time'].notna().map(\n",
    "    {True: 'Closed', False: 'Open'})\n",
    "df_topics['Challenge_comment_count'] = df_topics['Challenge_comment_count'].map(\n",
    "    lambda x: 1e-07 if x == 0 else x)\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Solved', 'Platform', 'Tool'],\n",
    "    values='Challenge_comment_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Platform', 'Solved', 'Tool'],\n",
    "    values='Challenge_comment_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Tool', 'Platform', 'Solved'],\n",
    "    values='Challenge_comment_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(\n",
    "    path_result_rq1, 'Challenge_comment_count_distribution.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenge topic participation distribution tree map\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_result_rq1, 'metrics.json'))\n",
    "df_topics['Challenge_topic_macro'] = df_topics['Challenge_topic_macro'].map(\n",
    "    macro_topic_index_mapping)\n",
    "df_topics['Solved'] = df_topics['Challenge_closed_time'].notna().map(\n",
    "    {True: 'Closed', False: 'Open'})\n",
    "df_topics['Challenge_participation_count'] = df_topics['Challenge_participation_count'].map(\n",
    "    lambda x: 1e-07 if x == 0 else x)\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Solved', 'Platform', 'Tool'],\n",
    "    values='Challenge_participation_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Platform', 'Solved', 'Tool'],\n",
    "    values='Challenge_participation_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Tool', 'Platform', 'Solved'],\n",
    "    values='Challenge_participation_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(\n",
    "    path_result_rq1, 'Challenge_participation_count_distribution.png'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
