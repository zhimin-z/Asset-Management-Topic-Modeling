{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import openai\n",
    "import textstat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from gensim.parsing.preprocessing import remove_stopwords, stem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The significance level indicates the probability of rejecting the null hypothesis when it is true.\n",
    "alpha = 0.05\n",
    "\n",
    "link_pattern = r'https?://[^\\s]+'\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None, 'display.max_colwidth', None)\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY', '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')\n",
    "\n",
    "keywords_patch = {\n",
    "    'pull',\n",
    "}\n",
    "\n",
    "keywords_issue = {\n",
    "    'answers',\n",
    "    'discussions',\n",
    "    'forums',\n",
    "    'issues',\n",
    "    'questions',\n",
    "    'stackoverflow',\n",
    "}\n",
    "\n",
    "keywords_tool = {\n",
    "    'github',\n",
    "    'gitlab',\n",
    "    'pypi',\n",
    "}\n",
    "\n",
    "keywords_doc = {\n",
    "    'developers',\n",
    "    'docs',\n",
    "    'documentation',\n",
    "    'features',\n",
    "    'library',\n",
    "    'org',\n",
    "    'wiki',\n",
    "}\n",
    "\n",
    "keywords_tutorial = {\n",
    "    'guide',\n",
    "    'learn',\n",
    "    'tutorial',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_result = '../../Result'\n",
    "\n",
    "path_result_rq1 = os.path.join(path_result, 'RQ1')\n",
    "path_code_rq1 = os.path.join('..', 'RQ1')\n",
    "\n",
    "path_general_output = os.path.join(path_result_rq1, 'General Topics')\n",
    "path_special_output = os.path.join(path_result_rq1, 'Special Topics')\n",
    "\n",
    "path_general_topic = os.path.join(path_code_rq1, 'General Topic Modeling')\n",
    "path_special_topic = os.path.join(path_code_rq1, 'Special Topic Modeling')\n",
    "\n",
    "path_anomaly = os.path.join(path_special_topic, 'Anomaly')\n",
    "path_root_cause = os.path.join(path_special_topic, 'Root Cause')\n",
    "path_solution = os.path.join(path_special_topic, 'Solution')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_weighted_sum(df, sort_column):\n",
    "    df_new = df.sort_values(sort_column, ascending=False)\n",
    "    n = len(df)\n",
    "    center_idx = (n - 1) // 2\n",
    "    direction = -1\n",
    "    distance = 0\n",
    "\n",
    "    for _, row in df_new.iterrows():\n",
    "        # Calculate the new index\n",
    "        new_idx = center_idx + direction * distance\n",
    "        \n",
    "        # Place the element from the sorted list into the new list\n",
    "        df.iloc[new_idx] = row\n",
    "\n",
    "        # If we've just moved to the left, increase the distance\n",
    "        if direction == -1:\n",
    "            distance += 1\n",
    "\n",
    "        # Switch the direction\n",
    "        direction *= -1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: Model Management - Handling and manipulation of models including training, saving, importing, and exporting.\n",
      "Topic 1: Data Pipelining - The process of managing and processing data through multiple pipelines.\n",
      "Topic 2: Package Installation - The process of installing, importing, and managing software packages using pip.\n",
      "Topic 3: Logging - The process of creating, tracking, and managing logs during model training.\n",
      "Topic 4: Docker Operations - Building, running, and managing Docker images and files.\n",
      "Topic 5: Access Management - Managing access permissions, roles, and tokens for secure operations.\n",
      "Topic 6: Data Labeling - The process of labeling data for training and object recognition.\n",
      "Topic 7: Git Operations - Managing data, files, and version control using Git.\n",
      "Topic 8: Bucket Operations - Managing files, data, and paths in storage buckets.\n",
      "Topic 9: Sweep Operations - Configuring, running, and managing multiple sweeps.\n",
      "Topic 10: Quota Management - Managing request quotas and handling limit exceptions.\n",
      "Topic 11: Remote Operations - Configuring, running, and connecting to remote files and executions.\n",
      "Topic 12: Batch Processing - Managing and processing data, files, and jobs in batches.\n",
      "Topic 13: Lambda Functions - Invoking and processing data using Lambda functions.\n",
      "Topic 14: Database Operations - Connecting, importing, and running operations on databases.\n",
      "Topic 15: Language Translation - Translating documents and languages using models.\n",
      "Topic 16: Panda Operations - Managing and converting files using Panda.\n",
      "Topic 17: Speech Processing - Handling audio files, generating speech, and transcribing services.\n",
      "Topic 18: Spark Operations - Configuring, implementing, and managing data using Spark.\n",
      "Topic 19: Instance Management - Creating, managing, and removing instances.\n",
      "Topic 20: Column Operations - Managing, cleaning, and visualizing data in columns.\n"
     ]
    }
   ],
   "source": [
    "prompt_topic = '''You will be given a list of stemmed words refering to specific software engineering topics. Please summarize each topic in terms and attach a one-liner description based on the stemmed words. Also, you must guarantee that the summaries are exclusive to one another.###\\n'''\n",
    "\n",
    "with open(os.path.join(path_general_topic, 'Topic terms.pickle'), 'rb') as handle:\n",
    "    topic_terms = pickle.load(handle)\n",
    "\n",
    "    topic_term_list = []\n",
    "    for index, topic in enumerate(topic_terms):\n",
    "        terms = ', '.join([term[0] for term in topic])\n",
    "        topic_term = f'Topic {index}: {terms}]'\n",
    "        topic_term_list.append(topic_term)\n",
    "\n",
    "    prompt = prompt_topic + '\\n'.join(topic_term_list) + '\\n###\\n'\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "        temperature=0,\n",
    "        max_tokens=3000,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        timeout=300,\n",
    "        stream=False)\n",
    "\n",
    "    topics = completion.choices[0].message.content\n",
    "    print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topics = '''Topic 0: Model Management - Handling and manipulation of models including training, saving, importing, and exporting.\n",
    "# Topic 1: Pipeline Configuration - The process of managing and processing data through multiple pipelines.\n",
    "# Topic 2: Package Management - The process of installing, importing, and managing software packages using pip.\n",
    "# Topic 3: Log Management - The process of creating, tracking, and managing logs during model training.\n",
    "# Topic 4: Docker Configuration - Building, running, and managing Docker images and files.\n",
    "# Topic 5: Access Control - Managing access permissions, roles, and tokens for secure operations.\n",
    "# Topic 6: Label Management - The process of creating, adding, and modifying labels for raw data.\n",
    "# Topic 7: Git Configuration - Managing data, files, and version control using Git.\n",
    "# Topic 8: Bucket Management - Managing files, data, and paths in storage buckets.\n",
    "# Topic 9: Sweep Management - Configuring, running, and managing multiple sweeps.\n",
    "# Topic 10: Quota Management - Managing request quotas and handling limit exceptions.\n",
    "# Topic 11: Remote Configuration - Configuring, running, and connecting to remote files and executions.\n",
    "# Topic 12: Batch Processing - Managing and processing data, files, and jobs in batches.\n",
    "# Topic 13: Lambda Configuration - Invoking and processing data using Lambda functions.\n",
    "# Topic 14: Database Management - Connecting, importing, and running operations on databases.\n",
    "# Topic 15: Language Translation - Translating documents and languages using models.\n",
    "# Topic 16: Tabular Data Manipulation - Managing and converting files using Pandas.\n",
    "# Topic 17: Speech Processing - Handling audio files, generating speech, and transcribing services.\n",
    "# Topic 18: Spark Configuration - Configuring, implementing, and managing data using Spark.\n",
    "# Topic 19: Instance Management - Creating, managing, and removing instances.\n",
    "# Topic 20: Columnar Data Manipulation - Managing, cleaning, and visualizing data in columns.'''\n",
    "\n",
    "# index = 0\n",
    "# topic_dict = {-1: 'NA'}\n",
    "\n",
    "# for topic in topics.split('\\n'):\n",
    "#     topic_dict[index] = topic.split('-')[0].split(':')[-1].strip()\n",
    "#     index += 1\n",
    "    \n",
    "# topic_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pip instal, instal pip, instal packag, packag instal, pip environ, packag pip, import instal, pip packag, instal import, import packagdocker imag, build docker, docker build, docker file, imag docker, run docker, file docker, docker run, built docker, docker dockerinvok lambda, data lambda, lambda process, function lambda, lambda function, job lambda, lambda lambda, model lambda, infer lambda, lambdainstanc creat, creat instanc, type instanc, instanc instanc, instanc type, regular instanc, model instanc, instanc modul, stop instanc, instanc remov'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with open(os.path.join(path_general_topic, 'Topic terms.pickle'), 'rb') as handle:\n",
    "#     topic_terms = pickle.load(handle)\n",
    "\n",
    "#     terms = ''\n",
    "#     for index, topic in enumerate(topic_terms):\n",
    "#         if index in [2, 4, 19, 13]:\n",
    "#             terms += ', '.join([term[0] for term in topic])\n",
    "# terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# macro_topic_mapping_inverse = {\n",
    "#     # These topics are all related to the management of permissions and connectivity.\n",
    "#     1: ('Access Management', ['Access Control', 'Remote Configuration']),\n",
    "#     # These topics are all related to the management of source code.\n",
    "#     8: ('Code Management', ['Git Configuration']),\n",
    "#     # These topics are all related to the management of data and datasets.\n",
    "#     2: ('Compute Management', ['Batch Processing', 'Spark Configuration', 'Sweep Management']),\n",
    "#     # These topics are all related to the management of services.\n",
    "#     3: ('Data Management', ['Bucket Management', 'Columnar Data Manipulation', 'Database Management', 'Label Management', 'Tabular Data Manipulation']),\n",
    "#     # These topics are all related to the management of packages and distributions.\n",
    "#     4: ('Environment Management', ['Package Management', 'Docker Configuration', 'Instance Management', 'Lambda Configuration']),\n",
    "#     # These topics are all related to the management of pipelines.\n",
    "#     7: ('Lifecycle Management', ['Pipeline Configuration']),\n",
    "#     # These topics are all related to the management of machine learning models.\n",
    "#     5: ('Model Management', ['Model Management']),\n",
    "#     # These topics are all related to the management of logs and metrics.\n",
    "#     6: ('Performance Management', ['Log Management', 'Quota Management']),\n",
    "# }\n",
    "\n",
    "macro_topic_mapping_inverse = {\n",
    "    # These topics are all related to the management of permissions and connectivity.\n",
    "    1: ('Access Management', [5, 11]),\n",
    "    # These topics are all related to the management of source code.\n",
    "    8: ('Code Management', [7]),\n",
    "    # These topics are all related to the management of data and datasets.\n",
    "    2: ('Compute Management', [9, 12, 18]),\n",
    "    # These topics are all related to the management of services.\n",
    "    3: ('Data Management', [6, 8, 14, 16, 20]),\n",
    "    # These topics are all related to the management of packages and distributions.\n",
    "    4: ('Environment Management', [2, 4, 13, 19]),\n",
    "    # These topics are all related to the management of pipelines.\n",
    "    7: ('Lifecycle Management', [1]),\n",
    "    # These topics are all related to the management of machine learning models.\n",
    "    5: ('Model Management', [0]),\n",
    "    # These topics are all related to the management of logs and metrics.\n",
    "    6: ('Performance Management', [3, 10]),\n",
    "}\n",
    "\n",
    "\n",
    "macro_topic_mapping = {}\n",
    "macro_topic_index_mapping = {}\n",
    "for key, (macro_topic, topics) in macro_topic_mapping_inverse.items():\n",
    "    macro_topic_index_mapping[macro_topic] = key\n",
    "    for topic in topics:\n",
    "        macro_topic_mapping[topic] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Number</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Access Management</td>\n",
       "      <td>872</td>\n",
       "      <td>7.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Compute Management</td>\n",
       "      <td>1106</td>\n",
       "      <td>9.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Management</td>\n",
       "      <td>1460</td>\n",
       "      <td>13.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Environment Management</td>\n",
       "      <td>2730</td>\n",
       "      <td>24.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Model Management</td>\n",
       "      <td>2378</td>\n",
       "      <td>21.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Performance Management</td>\n",
       "      <td>1122</td>\n",
       "      <td>10.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lifecycle Management</td>\n",
       "      <td>1105</td>\n",
       "      <td>9.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Code Management</td>\n",
       "      <td>344</td>\n",
       "      <td>3.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Topic  Number  Percentage\n",
       "0       Access Management     872        7.84\n",
       "1      Compute Management    1106        9.95\n",
       "2         Data Management    1460       13.13\n",
       "3  Environment Management    2730       24.56\n",
       "4        Model Management    2378       21.39\n",
       "5  Performance Management    1122       10.09\n",
       "6    Lifecycle Management    1105        9.94\n",
       "7         Code Management     344        3.09"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign human-readable & high-level topics to challenges & solutions\n",
    "\n",
    "df = pd.read_json(os.path.join(path_general_output, 'topics.json'))\n",
    "df['Challenge_topic_macro'] = -1\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['Challenge_topic'] in macro_topic_mapping:\n",
    "        df.at[index, 'Challenge_topic_macro'] = macro_topic_mapping[row['Challenge_topic']]\n",
    "    else:\n",
    "        df.drop(index, inplace=True)\n",
    "\n",
    "df.to_json(os.path.join(path_general_output, 'filtered.json'), indent=4, orient='records')\n",
    "\n",
    "df_number = pd.DataFrame()\n",
    "\n",
    "for key, (macro_topic, topics) in macro_topic_mapping_inverse.items():\n",
    "    entry = {\n",
    "        'Topic': macro_topic,\n",
    "        'Number': len(df[df[\"Challenge_topic_macro\"] == key]),\n",
    "        'Percentage': round(len(df[df[\"Challenge_topic_macro\"] == key]) / len(df) * 100, 2),\n",
    "    }\n",
    "    df_number = pd.concat([df_number, pd.DataFrame([entry])], ignore_index=True)\n",
    "\n",
    "minimize_weighted_sum(df_number, 'Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "# df['Challenge_topic_macro'] = -1\n",
    "# for index, row in df.iterrows():\n",
    "#     if topic_dict[row['Challenge_topic']] in macro_topic_mapping:\n",
    "#         df.at[index, 'Challenge_topic_macro'] = macro_topic_mapping[topic_dict[row['Challenge_topic']]]\n",
    "#     else:\n",
    "#         df.drop(index, inplace=True)\n",
    "\n",
    "# df.to_json(os.path.join(path_special_output, 'labels.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(os.path.join(path_general_output, 'filtered.json'))\n",
    "\n",
    "df['Challenge_type'] = 'na'\n",
    "df['Challenge_summary'] = 'na'\n",
    "df['Challenge_root_cause'] = 'na'\n",
    "df['Solution'] = 'na'\n",
    "\n",
    "df.to_json(os.path.join(path_special_output, 'labels.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['Challenge_summary'] != 'na':\n",
    "        for word in row['Challenge_summary'].split():\n",
    "            if len(word) == 2:\n",
    "                print(row['Challenge_title'])\n",
    "                break\n",
    "    if row['Challenge_root_cause'] != 'na':\n",
    "        for word in row['Challenge_root_cause'].split():\n",
    "            if len(word) == 2:\n",
    "                print(row['Challenge_title'])\n",
    "                break\n",
    "    if row['Solution'] != 'na':\n",
    "        for word in row['Solution'].split():\n",
    "            if len(word) == 2:\n",
    "                print(row['Challenge_title'])\n",
    "                break\n",
    "\n",
    "# df.to_json(os.path.join(path_special_output, 'preprocessed.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['Challenge_summary'] != 'na':\n",
    "        text = remove_stopwords(row['Challenge_summary'])\n",
    "        df.at[index, 'Challenge_summary'] = stem_text(text)\n",
    "    if row['Challenge_root_cause'] != 'na':\n",
    "        text = remove_stopwords(row['Challenge_root_cause'])\n",
    "        df.at[index, 'Challenge_root_cause'] = stem_text(text)\n",
    "    if row['Solution'] != 'na':\n",
    "        text = remove_stopwords(row['Solution'])\n",
    "        df.at[index, 'Solution'] = stem_text(text)\n",
    "\n",
    "df.to_json(os.path.join(path_special_output, 'preprocessed.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# df = pd.read_json(os.path.join(path_general_output, 'filtered.json'))\n",
    "\n",
    "# df['Challenge_type'] = np.nan\n",
    "# df['Challenge_summary'] = np.nan\n",
    "# df['Challenge_root_cause'] = np.nan\n",
    "# df['Solution'] = np.nan\n",
    "\n",
    "# df.to_json(os.path.join(path_special_output, 'labels+.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     if (row['Challenge_root_cause'] != 'na') and (row['Challenge_root_cause'] == row['Challenge_summary']):\n",
    "#         df.at[index, 'Challenge_root_cause'] = 'na'\n",
    "#     if (row['Challenge_root_cause'] != 'na') and (row['Challenge_root_cause'] == row['Solution']):\n",
    "#         print(row['Challenge_root_cause'])\n",
    "        \n",
    "# df.to_json(os.path.join(path_special_output, 'labels.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "\n",
    "# df['Challenge_summary'] = df['Challenge_summary'].str.lower()\n",
    "# df['Challenge_root_cause'] = df['Challenge_root_cause'].str.lower()\n",
    "# df['Solution'] = df['Solution'].str.lower()\n",
    "\n",
    "# df.to_json(os.path.join(path_special_output, 'labels.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "\n",
    "# regex_digit = r\"[0-9]\"\n",
    "\n",
    "# regex_error = r\"[a-zA-Z0-9]+[eE]rror[^a-zA-Z]\"\n",
    "# regex_exception = r\"[a-zA-Z0-9]+[eE]xception[^a-zA-Z]\"\n",
    "\n",
    "# regex_error_leading = r\"[a-zA-Z0-9]+[eE]rror[a-zA-Z]+\"\n",
    "# regex_exception_leading = r\"[a-zA-Z0-9]+[eE]xception[a-zA-Z]+\"\n",
    "\n",
    "# false_positive_list = []\n",
    "\n",
    "# def camel_case_split(str):\n",
    "#     words = [[str[0].lower()]]\n",
    " \n",
    "#     for c in str[1:]:\n",
    "#         if (words[-1][-1].islower() or words[-1][-1].isdigit()) and c.isupper():\n",
    "#             words.append(list(c.lower()))\n",
    "#         else:\n",
    "#             words[-1].append(c)\n",
    "#     return ' '.join([''.join(word) for word in words])\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     challenge = row['Challenge_title'] + ' ' + row['Challenge_body']\n",
    "#     challenge = challenge.replace('\\n', ' ')\n",
    "#     error_list = re.findall(regex_error, challenge)\n",
    "#     if len(error_list):\n",
    "#         if row['Challenge_type'] != 'anomaly':\n",
    "#             df.at[index, 'Challenge_type'] = 'anomaly'\n",
    "#             false_positive_list.append(row['Challenge_link'])\n",
    "#         error = max(error_list, key = len)\n",
    "#         if len(re.findall(regex_digit, error)):\n",
    "#             print(row['Challenge_title'])\n",
    "#         else:\n",
    "#             error = re.sub(r'error.+', 'error', camel_case_split(error))\n",
    "#             df.at[index, 'Challenge_summary'] = error\n",
    "#     else:\n",
    "#         exception_list = re.findall(regex_exception, challenge)\n",
    "#         if len(exception_list):\n",
    "#             if row['Challenge_type'] != 'anomaly':\n",
    "#                 df.at[index, 'Challenge_type'] = 'anomaly'\n",
    "#                 false_positive_list.append(row['Challenge_link'])\n",
    "#             exception = max(exception_list, key = len)\n",
    "#             if len(re.findall(regex_digit, exception)):\n",
    "#                 print(row['Challenge_title'])\n",
    "#             else:\n",
    "#                 exception = re.sub(r'exception.+', 'exception', camel_case_split(exception))\n",
    "#                 df.at[index, 'Challenge_summary'] = exception\n",
    "#         else:\n",
    "#             error_list_leading = re.findall(regex_error_leading, challenge)\n",
    "#             if len(error_list_leading):\n",
    "#                 print(row['Challenge_title'])\n",
    "#             else:\n",
    "#                 exception_list_leading = re.findall(regex_exception_leading, challenge)\n",
    "#                 if len(exception_list_leading):\n",
    "#                     print(row['Challenge_title'])\n",
    "                    \n",
    "# df.to_json(os.path.join(path_special_output, 'anomaly.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "\n",
    "# regex_digit = r\"[0-9]\"\n",
    "\n",
    "# regex_error = r\"[a-zA-Z0-9]+[eE]rror[^a-zA-Z]\"\n",
    "# regex_exception = r\"[a-zA-Z0-9]+[eE]xception[^a-zA-Z]\"\n",
    "\n",
    "# regex_error_leading = r\"[a-zA-Z0-9]+[eE]rror[a-zA-Z]+\"\n",
    "# regex_exception_leading = r\"[a-zA-Z0-9]+[eE]xception[a-zA-Z]+\"\n",
    "\n",
    "# def camel_case_split(str):\n",
    "#     words = [[str[0].lower()]]\n",
    " \n",
    "#     for c in str[1:]:\n",
    "#         if (words[-1][-1].islower() or words[-1][-1].isdigit()) and c.isupper():\n",
    "#             words.append(list(c.lower()))\n",
    "#         else:\n",
    "#             words[-1].append(c)\n",
    "#     return ' '.join([''.join(word) for word in words])\n",
    "\n",
    "# titles = []\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     if row['Challenge_title'] in titles:\n",
    "#         continue\n",
    "#     challenge = row['Challenge_title'] + ' ' + row['Challenge_body']\n",
    "#     challenge = challenge.replace('\\n', ' ').lower()\n",
    "#     if (' 403 ' in challenge) or ('[403]' in challenge) or ('(403)' in challenge) or (' 403,' in challenge) or ('forbidden' in challenge):\n",
    "#         pass\n",
    "#         # print(row['Challenge_title'])\n",
    "#         # df.at[index, 'Challenge_type'] = 'anomaly'\n",
    "#         # df.at[index, 'Challenge_summary'] = 'forbidden error'\n",
    "#     elif (' 404 ' in challenge) or ('[404]' in challenge) or ('(404)' in challenge) or (' 404,' in challenge) or ('not found' in challenge):\n",
    "#         print(row['Challenge_title'])\n",
    "        \n",
    "# # df.to_json(os.path.join(path_special_output, 'labels.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "\n",
    "# for i,r in df.iterrows():\n",
    "#     if r['Challenge_type'] == 'inquiry':\n",
    "#         df.at[i, 'Challenge_summary'] = 'na'\n",
    "#         df.at[i, 'Challenge_root_cause'] = 'na'\n",
    "\n",
    "# df.to_json(os.path.join(path_special_output, 'labels.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new = pd.read_json(os.path.join(path_special_output, 'labels+.json'))\n",
    "# df_old = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "\n",
    "# df = pd.concat([df_new, df_old], ignore_index=True)\n",
    "# df = df.drop_duplicates(['Challenge_link'], keep=False)\n",
    "\n",
    "# df = df[df['Challenge_type'].isna()]\n",
    "# df.to_json(os.path.join(path_special_output, 'extra.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new = pd.read_json(os.path.join(path_special_output, 'labels++.json'))\n",
    "# df_old = pd.read_json(os.path.join(path_special_output, 'extra.json'))\n",
    "\n",
    "# df = pd.concat([df_old, df_new], ignore_index=True)\n",
    "# df = df.drop_duplicates(['Challenge_link'])\n",
    "\n",
    "# df.to_json(os.path.join(path_special_output, 'extra+.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new = pd.read_json(os.path.join(path_special_output, 'labels+.json'))\n",
    "# df = pd.read_json(os.path.join(path_special_output, 'labels.json'))\n",
    "\n",
    "# for index, row in df_new.iterrows():\n",
    "#     for i2,r2 in df.iterrows():\n",
    "#         if r2['Challenge_type'] == 'na':\n",
    "#             continue\n",
    "#         if r2['Challenge_link'] == row['Challenge_link']:\n",
    "#             df_new.at[index, 'Challenge_type'] = r2['Challenge_type']\n",
    "#             df_new.at[index, 'Challenge_summary'] = r2['Challenge_summary']\n",
    "#             df_new.at[index, 'Challenge_root_cause'] = r2['Challenge_root_cause']\n",
    "#             df_new.at[index, 'Solution'] = r2['Solution']\n",
    "#             break\n",
    "            \n",
    "# df_new.to_json(os.path.join(path_special_output, 'labels++.json'), indent=4, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: Import Errors - Issues related to importing modules or packages in a software application.\n",
      "Topic 1: Type Errors - Problems associated with incorrect or incompatible data types in a program.\n",
      "Topic 2: Missing Files - Issues related to missing or non-existent files required for a software application.\n",
      "Topic 3: Value Errors - Problems associated with incorrect or unexpected values in a program.\n",
      "Topic 4: Argument Errors - Issues related to incorrect or unexpected arguments in a function or method.\n",
      "Topic 5: Access Issues - Problems related to unauthorized or denied access in a software application.\n",
      "Topic 6: Unresponsive Load - Issues related to unresponsive or halted loading processes in a software application.\n",
      "Topic 7: Import Issues - Problems related to importing modules or packages, including unrecognized or unresolved imports.\n",
      "Topic 8: Performance Issues - Problems related to the efficiency or speed of a software application.\n",
      "Topic 9: Attribute Errors - Issues related to incorrect or missing attributes in a program.\n",
      "Topic 10: HTTP Errors - Problems related to HTTP requests and responses, including failed or invalid requests.\n",
      "Topic 11: Execution Order - Issues related to the order in which commands or operations are executed in a program.\n",
      "Topic 12: Connection Issues - Problems related to establishing or maintaining a connection in a software application.\n",
      "Topic 13: Input Errors - Issues related to incorrect or incompatible input in a program.\n",
      "Topic 14: Model Errors - Problems related to incorrect or unsupported models in a software application.\n",
      "Topic 15: Package Compatibility - Issues related to incompatible or unsupported packages in a software application.\n",
      "Topic 16: Training Issues - Problems related to unresponsive or unsuccessful training processes in a machine learning application.\n",
      "Topic 17: Run Issues - Issues related to incorrect or missing run IDs in a software application.\n",
      "Topic 18: Unknown Errors - Problems that are unidentified or unexplained in a software application.\n",
      "Topic 19: Docker Errors - Issues related to Docker, including problems with building or pushing Docker images.\n",
      "Topic 20: Metadata Errors - Problems related to incorrect or missing metadata in a program.\n",
      "Topic 21: Endpoint Errors - Issues related to incorrect or inaccessible endpoints in a web service.\n",
      "Topic 22: File Issues - Problems related to missing or incomplete files in a software application.\n",
      "Topic 23: Forbidden Errors - Issues related to forbidden commands or parameters in a program.\n",
      "Topic 24: Syntax Errors - Problems related to incorrect syntax or parsing errors in a program.\n",
      "Topic 25: Access Restrictions - Issues related to restricted or limited access in a software application.\n",
      "Topic 26: Connection Timeout - Problems related to connection timeouts in a software application.\n",
      "Topic 27: File Validity - Issues related to invalid or corrupted files in a software application.\n",
      "Topic 28: Pipeline Issues - Problems related to incomplete or problematic pipelines in a software application.\n",
      "Topic 29: Validation Exceptions - Issues related to exceptions thrown during validation processes in a program.\n",
      "Topic 30: Dataset Issues - Problems related to incorrect or incompatible datasets in a machine learning application.\n",
      "Topic 31: Memory Overflow - Issues related to memory overflow or exhaustion in a software application.\n",
      "Topic 32: UI Issues - Problems related to user interface elements, such as inactive buttons or empty pages.\n",
      "Topic 33: Token Errors - Issues related to incorrect or missing tokens in a program.\n",
      "Topic 34: Metric Issues - Problems related to incorrect or undefined metrics in a software application.\n",
      "Topic 35: Permission Issues - Issues related to insufficient or improper permissions in a software application.\n",
      "Topic 36: Feature Support - Problems related to unsupported or unavailable features in a software application.\n",
      "Topic 37: Labeling Issues - Issues related to unviewable or inconsistent labels in a program.\n",
      "Topic 38: Quota Issues - Problems related to exhausted or insufficient quotas in a software application.\n",
      "Topic 39: CLI Issues - Issues related to inaccessible or unmanageable command line interfaces.\n",
      "Topic 40: Size Issues - Problems related to exhausted or insufficient size in a software application.\n",
      "Topic 41: Parameter Issues - Issues related to missing or unrecognized parameters in a program.\n",
      "Topic 42: Kernel Stability - Problems related to unstable or unresponsive kernels in a software application.\n",
      "Topic 43: Format Errors - Issues related to incorrect or unsupported formats in a program.\n",
      "Topic 44: Operational Errors - Problems related to failed operations or processes in a software application.\n",
      "Topic 45: Experiment Issues - Issues related to missing or queued experiments in a machine learning application.\n",
      "Topic 46: Directory Errors - Problems related to missing or invalid directories in a software application.\n",
      "Topic 47: History Issues - Issues related to missing or empty history in a software application.\n",
      "Topic 48: Load Errors - Problems related to failed or incorrect load processes in a software application.\n",
      "Topic 49: Invocation Timeout - Issues related to timeouts during invocation processes in a software application.\n",
      "Topic 50: Key Errors - Problems related to incorrect or appended keys in a program.\n",
      "Topic 51: Installation Errors - Issues related to failed or incompatible installations in a software application.\n",
      "Topic 52: Result Consistency - Problems related to inconsistent or discrepant results in a software application.\n",
      "Topic 53: Package Outdated - Issues related to outdated or deprecated packages in a software application.\n",
      "Topic 54: Environment Errors - Problems related to missing or unsupported environments in a software application.\n",
      "Topic 55: Validation Errors - Issues related to errors during validation processes in a program.\n",
      "Topic 56: Visualization Issues - Problems related to missing or malfunctioning charts and plots in a software application.\n",
      "Topic 57: Value Errors - Issues related to incorrect or unexpected values in a program.\n",
      "Topic 58: Artifact Issues - Problems related to missing or failed artifacts in a software application.\n",
      "Topic 59: Image Issues - Issues related to missing or unauthorized images in a software application.\n",
      "Topic 60: Login Errors - Problems related to incorrect or unrecoverable login processes in a software application.\n",
      "Topic 61: Logging Inconsistency - Issues related to inconsistent or incorrect logging in a software application.\n",
      "Topic 62: Deployment Failures - Problems related to failed or unsuccessful deployments in a software application.\n",
      "Topic 63: Job Errors - Issues related to incorrect or failed jobs in a software application.\n",
      "Topic 64: Git Errors - Problems related to Git, including issues with cloning or repository management.\n",
      "Topic 65: Name Errors - Issues related to incorrect or incomplete names in a program.\n",
      "Topic 66: Credential Errors - Problems related to incorrect or missing credentials in a software application.\n",
      "Topic 67: Command Issues - Issues related to missing or unrecognized commands in a program.\n",
      "Topic 68: Object Issues - Problems related to missing or unresolved objects in a software application.\n",
      "Topic 69: Prediction Errors - Issues related to incorrect or inconsistent predictions in a machine learning application.\n",
      "Topic 70: Download Errors - Problems related to failed or slow downloads in a software application.\n",
      "Topic 71: Gateway Issues - Issues related to bad or unsuccessful gateways in a network application.\n",
      "Topic 72: Unreproducible Behavior - Problems related to unreproducible or inconsistent behavior in a software application.\n",
      "Topic 73: GPU Utilization - Issues related to unused or underutilized GPUs in a software application.\n",
      "Topic 74: Workspace Issues - Problems related to missing or empty workspaces in a software application.\n",
      "Topic 75: Configuration Issues - Issues related to missing or broken configurations in a software application.\n",
      "Topic 76: Module Issues - Problems related to missing or unexpected modules in a software application.\n",
      "Topic 77: File System Read - Issues related to reading from the file system in a software application.\n",
      "Topic 78: Request Issues - Problems related to bad or blocked requests in a web service.\n",
      "Topic 79: Decoding Errors - Issues related to errors during decoding processes in a program.\n",
      "Topic 80: Compute Target - Problems related to invalid or missing compute targets in a software application.\n",
      "Topic 81: Notebook Unresponsiveness - Issues related to unresponsive notebooks in a software application.\n",
      "Topic 82: Model Saving - Problems related to unsaved or detached models in a machine learning application.\n",
      "Topic 83: Server Errors - Issues related to internal server errors in a web service.\n",
      "Topic 84: Resource Insufficiency - Problems related to insufficient or exhausted resources in a software application.\n",
      "Topic 85: Variable Issues - Issues related to missing or incomplete variables in a program.\n",
      "Topic 86: Log Issues - Problems related to missing or incomplete logs in a software application.\n",
      "Topic 87: Version Compatibility - Issues related to incompatible or conflicting versions in a software application.\n",
      "Topic 88: Documentation Clarity - Problems related to unclear or confusing documentation in a software application.\n",
      "Topic 89: Dependency Issues - Issues related to missing or unresolved dependencies in a software application.\n",
      "Topic 90: URI Support - Problems related to unsupported or invalid URIs in a web service.\n",
      "Topic 91: Authentication Errors - Issues related to incorrect or insufficient authentication in a software application.\n",
      "Topic 92: Connection Refusal - Problems related to refused or blocked connections in a network application.\n",
      "Topic 93: Validation Exceptions - Issues related to exceptions thrown during validation processes in a program.\n",
      "Topic 94: Model Issues - Problems related to missing or failing models in a machine learning application.\n",
      "Topic 95: Content Type - Issues related to unsupported or missing content types in a web service.\n",
      "Topic 96: Deployment Responsiveness - Problems related to unresponsive or slow deployments in a software application.\n",
      "Topic 97: Value Inconsistency - Issues related to incorrect or unexpected values in a program.\n",
      "Topic 98: Parameter Validity - Problems related to incorrect or failed parameters in a function or method.\n",
      "Topic 99: Bugs - Known or unknown bugs in a software application.\n",
      "Topic 100: Link Issues - Problems related to broken or malfunctioning links in a web service.\n",
      "Topic 101: Import Errors - Issues related to importing modules or packages in a software application.\n",
      "Topic 102: Path Issues - Problems related to incorrect or unclear paths in a software application.\n",
      "Topic 103: Character Validity - Issues related to incorrect or unsupported characters in a program.\n",
      "Topic 104: Dependency Conflicts - Problems related to conflicting or incompatible dependencies in a software application.\n",
      "Topic 105: Attribute Errors - Issues related to incorrect or missing attributes in a program.\n",
      "Topic 106: Warning Messages - Problems related to warning messages in a software application.\n",
      "Topic 107: Job Stuck - Issues related to stuck or infinite jobs in a software application.\n",
      "Topic 108: Configuration Validity - Problems related to incorrect or incompatible configurations in a software application.\n",
      "Topic 109: Data Support - Issues related to unsupported or invalid data in a software application.\n",
      "Topic 110: Installation Failures - Problems related to failed or difficult installations in a software application.\n",
      "Topic 111: Initialization Issues - Issues related to errors or failures during initialization processes in a program.\n",
      "Topic 112: Breaking Changes - Problems related to breaking changes in a software application.\n",
      "Topic 113: Limit Exceeded - Issues related to exceeded or increased limits in a software application.\n",
      "Topic 114: Model Errors - Problems related to failed or upgraded models in a machine learning application.\n",
      "Topic 115: Version Validity - Issues related to incorrect or malformed versions in a software application.\n",
      "Topic 116: Forbidden Errors - Problems related to forbidden actions or operations in a software application.\n",
      "Topic 117: Compilation Errors - Issues related to errors during compilation processes in a program.\n",
      "Topic 118: Pipe Errors - Problems related to broken or missing pipes in a software application.\n",
      "Topic 119: Path Validity - Issues related to incorrect or unexpected paths in a software application.\n",
      "Topic 120: Permission Issues - Problems related to denied or insufficient permissions in a software application.\n",
      "Topic 121: Timezone Errors - Issues related to incorrect or unidentified timezones in a software application.\n",
      "Topic 122: Request Issues - Problems related to bad or closed requests in a web service.\n",
      "Topic 123: Memory Errors - Issues related to memory allocation or consumption in a software application.\n",
      "Topic 124: Storage Insufficiency - Problems related to insufficient or conflicting storage in a software application.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_topic = '''You will be given a list of stemmed words refering to specific software engineering topics. Please summarize each topic in terms and attach a one-liner description based on the stemmed words. Also, you must guarantee that the summaries are exclusive to one another.###\\n'''\n",
    "\n",
    "with open(os.path.join(path_anomaly, 'Topic terms.pickle'), 'rb') as handle:\n",
    "    topic_terms = pickle.load(handle)\n",
    "\n",
    "    topic_term_list = []\n",
    "    for index, topic in enumerate(topic_terms):\n",
    "        terms = ', '.join([term[0] for term in topic])\n",
    "        topic_term = f'Topic {index}: {terms}'\n",
    "        topic_term_list.append(topic_term)\n",
    "\n",
    "    prompt = prompt_topic + '\\n'.join(topic_term_list) + '\\n###\\n'\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "        temperature=0,\n",
    "        max_tokens=3500,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        timeout=500,\n",
    "        stream=False)\n",
    "\n",
    "    topics = completion.choices[0].message.content\n",
    "    print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_macro_topic_mapping_inverse = {\n",
    "    # These are generally issues related to programming logic, syntax, data types, and anything that emerges during the coding process itself.\n",
    "    1: (\"Code-Level Issues\", [0, 1, 3, 4, 7, 9, 11, 13, 20, 24, 33, 37, 41, 43, 50, 55, 57, 65, 67, 85, 89, 93, 98, 101, 103, 105, 108, 111, 115, 117, 119]),\n",
    "    # These are generally issues related to the software's interaction with its underlying system or platform, such as memory issues, installation problems, or errors related to specific system tools like Docker.\n",
    "    2: (\"System-Level Issues\", [2, 6, 8, 12, 15, 17, 19, 22, 25, 26, 27, 31, 35, 38, 39, 40, 42, 44, 46, 48, 49, 51, 54, 62, 66, 70, 73, 75, 77, 80, 82, 84, 86, 88, 92, 94, 96, 99, 102, 104, 107, 110, 112, 113, 116, 120, 123, 124]),\n",
    "    # These are generally issues related to the handling and processing of data and models, especially in data-driven or machine learning applications. Topics here include problems with datasets, models, training issues, etc.\n",
    "    3: (\"Data and Model Issues\", [14, 16, 30, 34, 45, 58, 69, 72, 74, 76, 78, 81, 90, 95, 97, 100, 109, 114]),\n",
    "    # These are generally issues related to network connections, web services, HTTP errors, and other online interaction problems.\n",
    "    4: (\"Networking and Web Service Issues\", [10, 21, 28, 32, 36, 47, 52, 59, 60, 61, 71, 83, 87, 91, 106, 118, 122]),\n",
    "    # These are generally issues that affect the user's interaction with the software, such as problems with the user interface or errors that directly affect the user's experience.\n",
    "    5: (\"User Interface and Experience Issues\", [5, 18, 23, 29, 53, 56, 63, 64, 68, 79, 105, 121]),\n",
    "}\n",
    "\n",
    "anomaly_macro_topic_mapping = {}\n",
    "anomaly_macro_topic_index_mapping = {}\n",
    "for key, (macro_topic, topics) in anomaly_macro_topic_mapping_inverse.items():\n",
    "    anomaly_macro_topic_index_mapping[macro_topic] = key\n",
    "    for topic in topics:\n",
    "        anomaly_macro_topic_mapping[topic] = key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: Package Management - Handling and maintaining software packages including version checking and downgrading.\n",
      "Topic 1: Parameter Modification - Updating and modifying parameters in a software environment.\n",
      "Topic 2: Model Persistence - Saving and storing machine learning models and their metadata.\n",
      "Topic 3: Logging - Recording and managing logs related to models and metrics.\n",
      "Topic 4: Run Management - Controlling and monitoring the status of software runs.\n",
      "Topic 5: S3 Storage Usage - Utilizing S3 for online storage and directory management.\n",
      "Topic 6: Data Conversion - Changing the format and structure of data.\n",
      "Topic 7: Scripting - Creating and executing scripts in different modes.\n",
      "Topic 8: Data Analytics - Managing and developing data for stream analytics.\n",
      "Topic 9: Package Installation - Downloading and installing software packages.\n",
      "Topic 10: Package Upgrading - Updating and upgrading software packages.\n",
      "Topic 11: Compute Target Management - Creating and using compute targets in a software environment.\n",
      "Topic 12: Permission Management - Granting and managing access permissions.\n",
      "Topic 13: Quota Management - Increasing and checking quotas and capacities.\n",
      "Topic 14: File Downloading - Downloading and managing files.\n",
      "Topic 15: Package Installation - Installing software packages.\n",
      "Topic 16: Configuration Management - Updating and creating lifecycle configurations.\n",
      "Topic 17: Authentication - Configuring and managing interactive authentication.\n",
      "Topic 18: Experiment Management - Creating, sharing, and running experiments.\n",
      "Topic 19: Forum Engagement - Participating and asking questions on forums.\n",
      "Topic 20: Alternative Consideration - Evaluating and using alternative options and scenarios.\n",
      "Topic 21: Notebook Management - Starting, stopping, and restarting notebook instances.\n",
      "Topic 22: Package Upgrading - Upgrading and updating software packages.\n",
      "Topic 23: Error Handling - Managing error notifications and exceptions.\n",
      "Topic 24: Training Launch - Starting and managing training jobs.\n",
      "Topic 25: Bug Fixing - Releasing fixes for software bugs.\n",
      "Topic 26: Pipeline Management - Updating, modifying, and creating pipelines.\n",
      "Topic 27: Environment Management - Setting and configuring environment variables.\n",
      "Topic 28: Web Service Management - Using and deploying web services.\n",
      "Topic 29: Guidance Following - Referring to and following guidance and examples.\n",
      "Topic 30: Function Implementation - Using and implementing functions.\n",
      "Topic 31: Instruction Following - Following steps and instructions.\n",
      "Topic 32: Model Deployment - Deploying machine learning models.\n",
      "Topic 33: Environment Testing - Checking and testing software environments.\n",
      "Topic 34: Endpoint Management - Invoking and creating endpoints.\n",
      "Topic 35: Ongoing Fixes - Managing ongoing fixes and patches.\n",
      "Topic 36: Issue Management - Handling stale and expired issues.\n",
      "Topic 37: Connection Establishment - Opening and checking connections.\n",
      "Topic 38: File Copying - Copying and exporting files.\n",
      "Topic 39: Documentation - Reading and following software documentation.\n",
      "Topic 40: Tool Usage - Using different software tools.\n",
      "Topic 41: Docker Management - Creating and building Docker images.\n",
      "Topic 42: Feature Support - Handling supported and unsupported features.\n",
      "Topic 43: Work Completion - Completing work and logging in again.\n",
      "Topic 44: Container Management - Creating and customizing containers.\n"
     ]
    }
   ],
   "source": [
    "prompt_topic = '''You will be given a list of stemmed words refering to specific software engineering topics. Please summarize each topic in terms and attach a one-liner description based on the stemmed words. Also, you must guarantee that the summaries are exclusive to one another.###\\n'''\n",
    "\n",
    "with open(os.path.join(path_solution, 'Topic terms.pickle'), 'rb') as handle:\n",
    "    topic_terms = pickle.load(handle)\n",
    "\n",
    "    topic_term_list = []\n",
    "    for index, topic in enumerate(topic_terms):\n",
    "        terms = ', '.join([term[0] for term in topic])\n",
    "        topic_term = f'Topic {index}: {terms}'\n",
    "        topic_term_list.append(topic_term)\n",
    "\n",
    "    prompt = prompt_topic + '\\n'.join(topic_term_list) + '\\n###\\n'\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "        temperature=0,\n",
    "        max_tokens=3000,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        timeout=300,\n",
    "        stream=False)\n",
    "\n",
    "    topics = completion.choices[0].message.content\n",
    "    print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = '''Topic 0: Log Metrics - Analysis and modeling of log data for accuracy.\n",
    "Topic 1: Package Installation - Downloading, adding, specifying, and creating software packages.\n",
    "Topic 2: Permission Management - Granting, assigning, and applying access permissions.\n",
    "Topic 3: Package Upgrade - Updating and running software package upgrades.\n",
    "Topic 4: URI Configuration - Setting up and checking custom HTTP and URL configurations.\n",
    "Topic 5: Compute Management - Creating, using, and increasing compute targets and engines.\n",
    "Topic 6: Model Management - Saving, storing, and creating machine learning models.\n",
    "Topic 7: Documentation and Forum - Referring to, discussing, and reading software documentation and forums.\n",
    "Topic 8: Parameter Management - Adding, specifying, and removing parameters.\n",
    "Topic 9: Directory Management - Specifying and defining directory paths and locations.\n",
    "Topic 10: Package Installation - Installing software packages.\n",
    "Topic 11: Data Formatting - Updating, converting, and changing data formats.\n",
    "Topic 12: Storage Management - Increasing, using, and checking storage capacity.\n",
    "Topic 13: Line Management - Updating, removing, and replacing lines and parameters.\n",
    "Topic 14: Training Management - Launching, running, and creating training jobs.\n",
    "Topic 15: Dataset Management - Registering, creating, and using datasets.\n",
    "Topic 16: Run Management - Checking run status, history, and descriptions.\n",
    "Topic 17: Configuration Management - Updating, editing, and setting configurations.\n",
    "Topic 18: Bucket and Pipeline Management - Specifying and editing bucket names and pipelines.\n",
    "Topic 19: Kernel Management - Restarting, reinstalling, and updating kernels.\n",
    "Topic 20: Ticket Management - Opening, writing, and submitting tickets.\n",
    "Topic 21: Docker Management - Creating, building, and using Docker containers and images.\n",
    "Topic 22: Authentication Management - Configuring and logging into authentication systems.\n",
    "Topic 23: Dependency Management - Adding, updating, and removing dependencies.\n",
    "Topic 24: Package Upgrade - Updating and upgrading software packages.\n",
    "Topic 25: Environment Management - Adding, modifying, and setting environment variables.\n",
    "Topic 26: Issue Management - Marking and following up on stale issues.\n",
    "Topic 27: Error Management - Suppressing and communicating error messages and warnings.\n",
    "Topic 28: File Download - Downloading files and using download utilities.\n",
    "Topic 29: Model Deployment - Deploying and autoscaling models.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_macro_topic_mapping_inverse = {\n",
    "    # These topics are all related to the management of permissions and connectivity.\n",
    "    1: ('Access Management', [2]),\n",
    "    # These topics are all related to the management of source code.\n",
    "    8: ('Code Management', []),\n",
    "    # These topics are all related to the management of data and datasets.\n",
    "    2: ('Compute Management', []),\n",
    "    # These topics are all related to the management of services.\n",
    "    3: ('Data Management', []),\n",
    "    # These topics are all related to the management of packages and distributions.\n",
    "    4: ('Environment Management', [1, 3]),\n",
    "    # These topics are all related to the management of pipelines.\n",
    "    7: ('Lifecycle Management', []),\n",
    "    # These topics are all related to the management of machine learning models.\n",
    "    5: ('Model Management', []),\n",
    "    # These topics are all related to the management of logs and metrics.\n",
    "    6: ('Performance Management', [0]),\n",
    "}\n",
    "\n",
    "anomaly_macro_topic_mapping = {}\n",
    "anomaly_macro_topic_index_mapping = {}\n",
    "for key, (macro_topic, topics) in anomaly_macro_topic_mapping_inverse.items():\n",
    "    anomaly_macro_topic_index_mapping[macro_topic] = key\n",
    "    for topic in topics:\n",
    "        anomaly_macro_topic_mapping[topic] = key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "topic_ensemble = []\n",
    "for key, (macro_topic, topics) in macro_topic_mapping_inverse.items():\n",
    "    topic_ensemble.extend(topics)\n",
    "\n",
    "print(set(range(125)).difference(set(topic_ensemble)))\n",
    "print(set(set(topic_ensemble)).difference(range(125)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Number</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User Interface and Experience Issues</td>\n",
       "      <td>634</td>\n",
       "      <td>11.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data and Model Issues</td>\n",
       "      <td>701</td>\n",
       "      <td>12.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>System-Level Issues</td>\n",
       "      <td>2089</td>\n",
       "      <td>36.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Code-Level Issues</td>\n",
       "      <td>1605</td>\n",
       "      <td>28.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Networking and Web Service Issues</td>\n",
       "      <td>691</td>\n",
       "      <td>12.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Topic  Number  Percentage\n",
       "0  User Interface and Experience Issues     634       11.08\n",
       "1                 Data and Model Issues     701       12.26\n",
       "2                   System-Level Issues    2089       36.52\n",
       "3                     Code-Level Issues    1605       28.06\n",
       "4     Networking and Web Service Issues     691       12.08"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign human-readable & high-level topics to challenges & solutions\n",
    "\n",
    "df = pd.read_json(os.path.join(path_special_output, 'topics.json'))\n",
    "df['Challenge_summary_topic_macro'] = -1\n",
    "df['Challenge_root_cause_topic_macro'] = -1\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['Challenge_summary_topic'] in macro_topic_mapping:\n",
    "        df.at[index, 'Challenge_summary_topic_macro'] = macro_topic_mapping[row['Challenge_summary_topic']]\n",
    "        if row['Challenge_root_cause_topic'] in macro_topic_mapping:\n",
    "            df.at[index, 'Challenge_summary_topic_macro'] = macro_topic_mapping[row['Challenge_summary_topic']]\n",
    "    else:\n",
    "        df.drop(index, inplace=True)\n",
    "\n",
    "df.to_json(os.path.join(path_special_output, 'filtered.json'), indent=4, orient='records')\n",
    "\n",
    "df_number = pd.DataFrame()\n",
    "\n",
    "for key, (macro_topic, topics) in macro_topic_mapping_inverse.items():\n",
    "    entry = {\n",
    "        'Topic': macro_topic,\n",
    "        'Number': len(df[df[\"Challenge_summary_topic_macro\"] == key]),\n",
    "        'Percentage': round(len(df[df[\"Challenge_summary_topic_macro\"] == key]) / len(df) * 100, 2),\n",
    "    }\n",
    "    df_number = pd.concat([df_number, pd.DataFrame([entry])], ignore_index=True)\n",
    "\n",
    "minimize_weighted_sum(df_number, 'Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: Path Issues - Problems related to incorrect, mismatched, or missing file paths.\n",
      "Topic 1: Access Limitations - Issues concerning restricted, blocked, or insecure access to resources.\n",
      "Topic 2: Memory Problems - Concerns about exhausted, deleted, or high memory usage.\n",
      "Topic 3: Input/Output Errors - Problems with incorrect, invalid, or unexpected input and output formats.\n",
      "Topic 4: Unsupported Features - Issues with unsupported, unmaintained, or insufficient software features.\n",
      "Topic 5: Unreproducible Behavior - Problems related to unpredictable or false interactive behaviors.\n",
      "Topic 6: Missing Files - Issues concerning missing files, folders, or directories.\n",
      "Topic 7: Documentation Issues - Problems with unclear, confusing, or unspecified documentation.\n",
      "Topic 8: System Incompatibility - Issues with incompatible or unsupported operating systems or versions.\n",
      "Topic 9: Bug Issues - Problems related to known or unknown software bugs.\n",
      "Topic 10: Model Issues - Concerns about large, different, or wrong models.\n",
      "Topic 11: Outdated Packages - Issues with outdated or removed software packages.\n",
      "Topic 12: Version Incompatibility - Problems with incompatible, mismatched, or unsupported versions.\n",
      "Topic 13: Permission Restrictions - Issues concerning restricted, limited, or improper permissions.\n",
      "Topic 14: Missing Modules - Problems with missing, unreachable, or compressed modules.\n",
      "Topic 15: Dependency Issues - Issues with missing, incompatible, or conflicting dependencies.\n",
      "Topic 16: Breaking Changes - Problems related to changes that break the functionality of the software.\n",
      "Topic 17: Limitations - Issues concerning known or increased limitations.\n",
      "Topic 18: Docker Issues - Problems with conflicting, unsupported, or custom Docker environments.\n",
      "Topic 19: Parameter Issues - Issues with missing, wrong, or unsupported parameters.\n",
      "Topic 20: Data Type Issues - Problems with invalid, mismatched, or wrong data types.\n",
      "Topic 21: Endpoint Issues - Issues with misconfigured, wrong, or specific endpoints.\n",
      "Topic 22: Package Incompatibility - Problems with incompatible, conflicting, or invalid packages.\n",
      "Topic 23: Supplier Issues - Issues with unresponsive, malfunctioning, or custom suppliers.\n",
      "Topic 24: Argument Issues - Problems with missing, wrong, or unexpected arguments.\n",
      "Topic 25: Environment Issues - Issues with missing, unusable, or wrong environments.\n",
      "Topic 26: Deprecated Elements - Problems with deprecated features, methods, classes, or packages.\n",
      "Topic 27: Session Issues - Issues with inactive, missing, or expired sessions.\n",
      "Topic 28: Link Issues - Problems with broken, removed, or wrong links or URLs.\n"
     ]
    }
   ],
   "source": [
    "# prompt_topic = '''You will be given a list of stemmed words refering to specific software engineering topics. Please summarize each topic in terms and attach a one-liner description based on the stemmed words. Also, you must guarantee that the summaries are exclusive to one another.###\\n'''\n",
    "\n",
    "# with open(os.path.join(path_root_cause, 'Topic terms.pickle'), 'rb') as handle:\n",
    "#     topic_terms = pickle.load(handle)\n",
    "\n",
    "#     topic_term_list = []\n",
    "#     for index, topic in enumerate(topic_terms):\n",
    "#         terms = ', '.join([term[0] for term in topic])\n",
    "#         topic_term = f'Topic {index}: {terms}'\n",
    "#         topic_term_list.append(topic_term)\n",
    "\n",
    "#     prompt = prompt_topic + '\\n'.join(topic_term_list) + '\\n###\\n'\n",
    "#     completion = openai.ChatCompletion.create(\n",
    "#         model='gpt-4',\n",
    "#         messages=[{'role': 'user', 'content': prompt}],\n",
    "#         temperature=0,\n",
    "#         max_tokens=3000,\n",
    "#         top_p=1,\n",
    "#         frequency_penalty=0,\n",
    "#         presence_penalty=0,\n",
    "#         timeout=300,\n",
    "#         stream=False)\n",
    "\n",
    "#     topics = completion.choices[0].message.content\n",
    "#     print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw sankey diagram of tool and platform\n",
    "\n",
    "df = pd.read_json(os.path.join(path_special_output, 'topics.json'))\n",
    "df = df[df['Challenge_type'] != 'na']\n",
    "\n",
    "df['State'] = df['Challenge_closed_time'].apply(lambda x: 'closed' if not pd.isna(x) else 'open')\n",
    "\n",
    "categories = ['Platform', 'Tool', 'State']\n",
    "df_info = df.groupby(categories).size().reset_index(name='value')\n",
    "\n",
    "labels = {}\n",
    "newDf = pd.DataFrame()\n",
    "for i in range(len(categories)):\n",
    "    labels.update(df[categories[i]].value_counts().to_dict())\n",
    "    if i == len(categories)-1:\n",
    "        break\n",
    "    tempDf = df_info[[categories[i], categories[i+1], 'value']]\n",
    "    tempDf.columns = ['source', 'target', 'value']\n",
    "    newDf = pd.concat([newDf, tempDf])\n",
    "    \n",
    "newDf = newDf.groupby(['source', 'target']).agg({'value': 'sum'}).reset_index()\n",
    "source = newDf['source'].apply(lambda x: list(labels).index(x))\n",
    "target = newDf['target'].apply(lambda x: list(labels).index(x))\n",
    "value = newDf['value']\n",
    "\n",
    "labels = [f'{k} ({v})' for k, v in labels.items()]\n",
    "\n",
    "link = dict(source=source, target=target, value=value)\n",
    "node = dict(label=labels)\n",
    "data = go.Sankey(link=link, node=node)\n",
    "\n",
    "fig = go.Figure(data)\n",
    "fig.update_layout(width=1000, height=1000, font_size=20)\n",
    "fig.write_image(os.path.join(path_result_rq1, 'Tool platform state sankey.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add different metrics to each post\n",
    "\n",
    "df = pd.read_json(os.path.join(path_special_output, 'topics.json'))\n",
    "df = df[df['Challenge_type'] != 'na']\n",
    "\n",
    "df['Solution_word_count'] = np.nan\n",
    "df['Solution_sentence_count'] = np.nan\n",
    "df['Solution_readability'] = np.nan\n",
    "df['Solution_reading_time'] = np.nan\n",
    "df['Solution_link_count'] = np.nan\n",
    "\n",
    "df['Challenge_solved_time'] = np.nan\n",
    "df['Challenge_adjusted_solved_time'] = np.nan\n",
    "\n",
    "df['Solution_link_docs'] = np.nan\n",
    "df['Solution_link_issues'] = np.nan\n",
    "df['Solution_link_patches'] = np.nan\n",
    "df['Solution_link_tools'] = np.nan\n",
    "df['Solution_link_tutorials'] = np.nan\n",
    "df['Solution_link_examples'] = np.nan\n",
    "\n",
    "df['Challenge_created_time'] = pd.to_datetime(df['Challenge_created_time'])\n",
    "df['Challenge_closed_time'] = pd.to_datetime(df['Challenge_closed_time'])\n",
    "df['Challenge_last_edit_time'] = pd.to_datetime(df['Challenge_last_edit_time'])\n",
    "df['Solution_last_edit_time'] = pd.to_datetime(df['Solution_last_edit_time'])\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    challenge_content = row['Challenge_title'] + '.' + str(row['Challenge_body'])\n",
    "    df.at[index, 'Challenge_word_count'] = textstat.lexicon_count(challenge_content)\n",
    "    df.at[index, 'Challenge_sentence_count'] = textstat.sentence_count(challenge_content)\n",
    "    df.at[index, 'Challenge_readability'] = textstat.flesch_kincaid_grade(challenge_content)\n",
    "    df.at[index, 'Challenge_reading_time'] = textstat.reading_time(challenge_content)\n",
    "    \n",
    "    links = list(set(re.findall(link_pattern, challenge_content)))\n",
    "    df.at[index, 'Challenge_link_count'] = len(links)\n",
    "\n",
    "    solution_content = row['Solution_body']\n",
    "\n",
    "    if pd.notna(solution_content):\n",
    "        df.at[index, 'Solution_word_count'] = textstat.lexicon_count(solution_content)\n",
    "        df.at[index, 'Solution_sentence_count'] = textstat.sentence_count(solution_content)\n",
    "        df.at[index, 'Solution_readability'] = textstat.flesch_kincaid_grade(solution_content)\n",
    "        df.at[index, 'Solution_reading_time'] = textstat.reading_time(solution_content)\n",
    "        \n",
    "        links = list(set(re.findall(link_pattern, solution_content)))\n",
    "        df.at[index, 'Solution_link_count'] = len(links)\n",
    "        \n",
    "        link_docs = 0\n",
    "        link_tools = 0\n",
    "        link_issues = 0\n",
    "        link_patches = 0\n",
    "        link_tutorials = 0\n",
    "        link_examples = 0\n",
    "    \n",
    "        for link in links:\n",
    "            if any([patch in link for patch in keywords_patch]):\n",
    "                link_patches += 1\n",
    "            elif any([issue in link for issue in keywords_issue]):\n",
    "                link_issues += 1\n",
    "            elif any([tool in link for tool in keywords_tool]):\n",
    "                link_tools += 1\n",
    "            elif any([doc in link for doc in keywords_doc]):\n",
    "                link_docs += 1\n",
    "            elif any([tool in link for tool in keywords_tutorial]):\n",
    "                link_tutorials += 1\n",
    "            else:\n",
    "                link_examples += 1\n",
    "                \n",
    "        df.at[index, 'Solution_link_docs'] = link_docs\n",
    "        df.at[index, 'Solution_link_issues'] = link_issues\n",
    "        df.at[index, 'Solution_link_patches'] = link_patches\n",
    "        df.at[index, 'Solution_link_tools'] = link_tools\n",
    "        df.at[index, 'Solution_link_tutorials'] = link_tutorials\n",
    "        df.at[index, 'Solution_link_examples'] = link_examples\n",
    "        \n",
    "    creation_time = row['Challenge_created_time']\n",
    "    closed_time = row['Challenge_closed_time']\n",
    "    if pd.notna(creation_time) and pd.notna(closed_time) and (closed_time > creation_time):\n",
    "        df.at[index, 'Challenge_solved_time'] = (closed_time - creation_time) / pd.Timedelta(hours=1)\n",
    "\n",
    "    creation_time = row['Challenge_last_edit_time'] if pd.notna(row['Challenge_last_edit_time']) else creation_time\n",
    "    closed_time = row['Solution_last_edit_time'] if pd.notna(row['Solution_last_edit_time']) else closed_time\n",
    "    if pd.notna(creation_time) and pd.notna(closed_time) and (closed_time > creation_time):\n",
    "        df.at[index, 'Challenge_adjusted_solved_time'] = (closed_time - creation_time) / pd.Timedelta(hours=1)\n",
    "    else:\n",
    "        df.at[index, 'Challenge_adjusted_solved_time'] = df.at[index, 'Challenge_solved_time']\n",
    "\n",
    "df['Challenge_comment_count'] = df['Challenge_comment_count'].fillna(0)\n",
    "df['Challenge_answer_count'] = df['Challenge_answer_count'].fillna(0)\n",
    "df['Challenge_participation_count'] = df['Challenge_answer_count'] + df['Challenge_comment_count']\n",
    "\n",
    "df = df.reindex(sorted(df.columns), axis=1)\n",
    "df.to_json(os.path.join(path_result_rq1, 'metrics.json'), indent=4, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenge topic count distribution tree map\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_result_rq1, 'metrics.json'))\n",
    "df_topics['Challenge_topic_macro'] = df_topics['Challenge_topic_macro'].map(\n",
    "    macro_topic_index_mapping)\n",
    "df_topics['Solved'] = df_topics['Challenge_closed_time'].notna().map(\n",
    "    {True: 'Closed', False: 'Open'})\n",
    "df_topics['Count'] = 1\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Solved', 'Platform', 'Tool'],\n",
    "    values='Count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Platform', 'Solved', 'Tool'],\n",
    "    values='Count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Tool', 'Platform', 'Solved'],\n",
    "    values='Count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(\n",
    "    path_result_rq1, 'Challenge_topic_count_distribution.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenge view count distribution tree map\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_result_rq1, 'metrics.json'))\n",
    "df_topics['Challenge_topic_macro'] = df_topics['Challenge_topic_macro'].map(\n",
    "    macro_topic_index_mapping)\n",
    "df_topics['Solved'] = df_topics['Challenge_closed_time'].notna().map(\n",
    "    {True: 'Closed', False: 'Open'})\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Solved', 'Platform', 'Tool'],\n",
    "    values='Challenge_view_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Platform', 'Solved', 'Tool'],\n",
    "    values='Challenge_view_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Tool', 'Platform', 'Solved'],\n",
    "    values='Challenge_view_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(\n",
    "    path_result_rq1, 'Challenge_view_count_distribution.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenge score count distribution tree map\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_result_rq1, 'metrics.json'))\n",
    "df_topics['Challenge_topic_macro'] = df_topics['Challenge_topic_macro'].map(\n",
    "    macro_topic_index_mapping)\n",
    "df_topics['Solved'] = df_topics['Challenge_closed_time'].notna().map(\n",
    "    {True: 'Closed', False: 'Open'})\n",
    "df_topics['Challenge_score_count'] = df_topics['Challenge_score_count'].map(\n",
    "    lambda x: 1e-07 if x == 0 else x)\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Solved', 'Platform', 'Tool'],\n",
    "    values='Challenge_score_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Platform', 'Solved', 'Tool'],\n",
    "    values='Challenge_score_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Tool', 'Platform', 'Solved'],\n",
    "    values='Challenge_score_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(\n",
    "    path_result_rq1, 'Challenge_score_count_distribution.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenge favorite count distribution tree map\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_result_rq1, 'metrics.json'))\n",
    "df_topics['Challenge_topic_macro'] = df_topics['Challenge_topic_macro'].map(\n",
    "    macro_topic_index_mapping)\n",
    "df_topics['Solved'] = df_topics['Challenge_closed_time'].notna().map(\n",
    "    {True: 'Closed', False: 'Open'})\n",
    "df_topics['Challenge_favorite_count'] = df_topics['Challenge_favorite_count'].map(\n",
    "    lambda x: 1e-07 if x == 0 else x)\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Solved', 'Platform', 'Tool'],\n",
    "    values='Challenge_favorite_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Platform', 'Solved', 'Tool'],\n",
    "    values='Challenge_favorite_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Tool', 'Platform', 'Solved'],\n",
    "    values='Challenge_favorite_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(\n",
    "    path_result_rq1, 'Challenge_favorite_count_distribution.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenge answer count distribution tree map\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_result_rq1, 'metrics.json'))\n",
    "df_topics['Challenge_topic_macro'] = df_topics['Challenge_topic_macro'].map(\n",
    "    macro_topic_index_mapping)\n",
    "df_topics['Solved'] = df_topics['Challenge_closed_time'].notna().map(\n",
    "    {True: 'Closed', False: 'Open'})\n",
    "df_topics['Challenge_answer_count'] = df_topics['Challenge_answer_count'].map(\n",
    "    lambda x: 1e-07 if x == 0 else x)\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Solved', 'Platform', 'Tool'],\n",
    "    values='Challenge_answer_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Platform', 'Solved', 'Tool'],\n",
    "    values='Challenge_answer_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Tool', 'Platform', 'Solved'],\n",
    "    values='Challenge_answer_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(\n",
    "    path_result_rq1, 'Challenge_answer_count_distribution.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenge comment count distribution tree map\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_result_rq1, 'metrics.json'))\n",
    "df_topics['Challenge_topic_macro'] = df_topics['Challenge_topic_macro'].map(\n",
    "    macro_topic_index_mapping)\n",
    "df_topics['Solved'] = df_topics['Challenge_closed_time'].notna().map(\n",
    "    {True: 'Closed', False: 'Open'})\n",
    "df_topics['Challenge_comment_count'] = df_topics['Challenge_comment_count'].map(\n",
    "    lambda x: 1e-07 if x == 0 else x)\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Solved', 'Platform', 'Tool'],\n",
    "    values='Challenge_comment_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Platform', 'Solved', 'Tool'],\n",
    "    values='Challenge_comment_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Tool', 'Platform', 'Solved'],\n",
    "    values='Challenge_comment_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(\n",
    "    path_result_rq1, 'Challenge_comment_count_distribution.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenge topic participation distribution tree map\n",
    "\n",
    "df_topics = pd.read_json(os.path.join(path_result_rq1, 'metrics.json'))\n",
    "df_topics['Challenge_topic_macro'] = df_topics['Challenge_topic_macro'].map(\n",
    "    macro_topic_index_mapping)\n",
    "df_topics['Solved'] = df_topics['Challenge_closed_time'].notna().map(\n",
    "    {True: 'Closed', False: 'Open'})\n",
    "df_topics['Challenge_participation_count'] = df_topics['Challenge_participation_count'].map(\n",
    "    lambda x: 1e-07 if x == 0 else x)\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Solved', 'Platform', 'Tool'],\n",
    "    values='Challenge_participation_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Platform', 'Solved', 'Tool'],\n",
    "    values='Challenge_participation_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.treemap(\n",
    "    df_topics,\n",
    "    path=[px.Constant('All'), 'Tool', 'Platform', 'Solved'],\n",
    "    values='Challenge_participation_count',\n",
    "    color='Challenge_topic_macro',\n",
    "    color_continuous_scale='RdBu',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig = fig.update_layout(\n",
    "    width=1500,\n",
    "    height=750,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(\n",
    "    path_result_rq1, 'Challenge_participation_count_distribution.png'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
