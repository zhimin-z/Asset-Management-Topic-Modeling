{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shap\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.inspection import permutation_importance\n",
    "from scipy.stats import mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The significance level is the probability of rejecting the null hypothesis when it is true.\n",
    "alpha = 0.05\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_topic_ensemble_inverse = [\n",
    "    # Code versioning refers to the practice of tracking changes to software code over time.\n",
    "    {'Code Management': ['Code Versioning']},\n",
    "    # These words are all related to data management and analysis. They refer to various tasks and techniques used to organize, manipulate, store, transfer, and analyze data.\n",
    "    {'Data Management': ['Artifact Management', 'Columnar Manipulation', 'CSV Manipulation', 'Data Labeling', 'Data Storage',\n",
    "                         'Data Transfer', 'Data Visualization', 'Database Connectivity', 'Dataset Versioning', 'Pandas Dataframe', 'Batch Processing']},\n",
    "    # All of these words are related to the development and management of machine learning models.\n",
    "    {'Model Management': ['Hyperparameter Tuning',\n",
    "                          'Model Evaluation', 'Model Exporting', 'Model Registry']},\n",
    "    # These words are all related to the management and optimization of data pipelines in software development.\n",
    "    {'Lifecycle Management': ['Pipeline Configuration',\n",
    "                              'Pipeline Configuration (Data)', 'Pipeline Configuration (Model)', 'Run Management', 'Kubernetes Orchestration']},\n",
    "    # All of these words relate to the configuration and management of infrastructure aspects of computer systems and networks. Specifically, they involve setting up and optimizing different components such as processing power, memory, network connections, and software to ensure that they work together efficiently and effectively.\n",
    "    {'Infrastructure Management': ['Apache Spark Configuration', 'Cluster Configuration', 'Docker Configuration', 'GPU Configuration', 'VPC Networking', 'Memory Management',\n",
    "                                   'Remote Configuration', 'Resource Quota Control', 'TensorFlow Configuration', 'Jupyter Notebook', 'Package Management', 'SDK Management', 'YAML Configuration']},\n",
    "    # All of these words are related to the deployment and management of machine learning models or web services.\n",
    "    {'Deployment Management': ['Endpoint Serving', 'Endpoint Deployment', 'Model Serving', 'Model Inference',\n",
    "                               'REST Payload', 'Web Service', 'Serverless Serving', 'API Invocation']},\n",
    "    # All of these words are related to monitoring and logging data in various systems.\n",
    "    {'Report Management': ['CloudWatch Monitoring',\n",
    "                           'Metrics Logging', 'TensorBoard Logging', 'Metrics Logging']},\n",
    "    # All of these words are related to controlling access to information or resources in a system.\n",
    "    {'Identity Management': ['Account Management',\n",
    "                             'Bucket Access Control', 'Role-based Access Control']},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_challenge_azureml_sagemaker = 'SageMaker vs AzureML'\n",
    "path_general = os.path.join(os.getcwd(), '..', '..', 'General')\n",
    "path_solution = os.path.join(os.getcwd(), '..', '..', 'Solution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare metrics distribution of SageMaker vs AzureML challenges across different topics\n",
    "\n",
    "df = pd.read_json(os.path.join(path_general, 'logscale.json'))\n",
    "\n",
    "df_sagemaker = df[df['Tool'] == 'Amazon SageMaker']\n",
    "df_azureml = df[df['Tool'] == 'Azure Machine Learning']\n",
    "\n",
    "# Challenge topic count\n",
    "fig_challenge_count = go.Figure()\n",
    "fig_challenge_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=np.full(len(df_sagemaker), 'Challenge topic count (higher level)'),\n",
    "        y=df_sagemaker['Challenge_topic_macro'],\n",
    "        meanline_visible=True,\n",
    "        line_color='blue',\n",
    "        side='positive',\n",
    "        opacity=0.5,\n",
    "        name='SageMaker',\n",
    "    ))\n",
    "fig_challenge_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=np.full(len(df_azureml), 'Challenge topic count (higher level)'),\n",
    "        y=df_azureml['Challenge_topic_macro'],\n",
    "        meanline_visible=True,\n",
    "        line_color='orange',\n",
    "        side='negative',\n",
    "        opacity=0.5,\n",
    "        name='AzureML',\n",
    "    ))\n",
    "fig_challenge_count.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_count.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, 'Challenge count.png'))\n",
    "\n",
    "# Challenge score\n",
    "fig_challenge_score = go.Figure()\n",
    "fig_challenge_score.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_sagemaker['Challenge_topic_macro'],\n",
    "        y=df_sagemaker['Challenge_score'],\n",
    "        meanline_visible=True,\n",
    "        line_color='blue',\n",
    "        side='positive',\n",
    "        opacity=0.5,\n",
    "        legendgroup='SageMaker',\n",
    "        scalegroup='SageMaker',\n",
    "        name='SageMaker',\n",
    "    ))\n",
    "fig_challenge_score.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_azureml['Challenge_topic_macro'],\n",
    "        y=df_azureml['Challenge_score'],\n",
    "        meanline_visible=True,\n",
    "        line_color='orange',\n",
    "        side='negative',\n",
    "        opacity=0.5,\n",
    "        legendgroup='AzureML',\n",
    "        scalegroup='AzureML',\n",
    "        name='AzureML',\n",
    "    ))\n",
    "fig_challenge_score.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_score.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, 'Challenge score.png'))\n",
    "\n",
    "# Challenge favorite count\n",
    "fig_challenge_favorite_count = go.Figure()\n",
    "fig_challenge_favorite_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_sagemaker['Challenge_topic_macro'],\n",
    "        y=df_sagemaker['Challenge_favorite_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='blue',\n",
    "        side='positive',\n",
    "        opacity=0.5,\n",
    "        legendgroup='SageMaker',\n",
    "        scalegroup='SageMaker',\n",
    "        name='SageMaker',\n",
    "    ))\n",
    "fig_challenge_favorite_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_azureml['Challenge_topic_macro'],\n",
    "        y=df_azureml['Challenge_favorite_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='orange',\n",
    "        side='negative',\n",
    "        opacity=0.5,\n",
    "        legendgroup='AzureML',\n",
    "        scalegroup='AzureML',\n",
    "        name='AzureML',\n",
    "    ))\n",
    "fig_challenge_favorite_count.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_favorite_count.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, 'Challenge favorite count.png'))\n",
    "\n",
    "# Challenge view count\n",
    "fig_challenge_view_count = go.Figure()\n",
    "fig_challenge_view_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_sagemaker['Challenge_topic_macro'],\n",
    "        y=df_sagemaker['Challenge_view_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='blue',\n",
    "        side='positive',\n",
    "        opacity=0.5,\n",
    "        legendgroup='SageMaker',\n",
    "        scalegroup='SageMaker',\n",
    "        name='SageMaker',\n",
    "    ))\n",
    "fig_challenge_view_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_azureml['Challenge_topic_macro'],\n",
    "        y=df_azureml['Challenge_view_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='orange',\n",
    "        side='negative',\n",
    "        opacity=0.5,\n",
    "        legendgroup='AzureML',\n",
    "        scalegroup='AzureML',\n",
    "        name='AzureML',\n",
    "    ))\n",
    "fig_challenge_view_count.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_view_count.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, 'Challenge view count.png'))\n",
    "\n",
    "# Challenge link count\n",
    "fig_challenge_link_count = go.Figure()\n",
    "fig_challenge_link_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_sagemaker['Challenge_topic_macro'],\n",
    "        y=df_sagemaker['Challenge_link_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='blue',\n",
    "        side='positive',\n",
    "        opacity=0.5,\n",
    "        legendgroup='SageMaker',\n",
    "        scalegroup='SageMaker',\n",
    "        name='SageMaker',\n",
    "    ))\n",
    "fig_challenge_link_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_azureml['Challenge_topic_macro'],\n",
    "        y=df_azureml['Challenge_link_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='orange',\n",
    "        side='negative',\n",
    "        opacity=0.5,\n",
    "        legendgroup='AzureML',\n",
    "        scalegroup='AzureML',\n",
    "        name='AzureML',\n",
    "    ))\n",
    "fig_challenge_link_count.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_link_count.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, 'Challenge link count.png'))\n",
    "\n",
    "# Challenge sentence count\n",
    "fig_challenge_sentence_count = go.Figure()\n",
    "fig_challenge_sentence_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_sagemaker['Challenge_topic_macro'],\n",
    "        y=df_sagemaker['Challenge_sentence_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='blue',\n",
    "        side='positive',\n",
    "        opacity=0.5,\n",
    "        legendgroup='SageMaker',\n",
    "        scalegroup='SageMaker',\n",
    "        name='SageMaker',\n",
    "    ))\n",
    "fig_challenge_sentence_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_azureml['Challenge_topic_macro'],\n",
    "        y=df_azureml['Challenge_sentence_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='orange',\n",
    "        side='negative',\n",
    "        opacity=0.5,\n",
    "        legendgroup='AzureML',\n",
    "        scalegroup='AzureML',\n",
    "        name='AzureML',\n",
    "    ))\n",
    "fig_challenge_sentence_count.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_sentence_count.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, 'Challenge sentence count.png'))\n",
    "\n",
    "# Challenge word count\n",
    "fig_challenge_word_count = go.Figure()\n",
    "fig_challenge_word_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_sagemaker['Challenge_topic_macro'],\n",
    "        y=df_sagemaker['Challenge_word_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='blue',\n",
    "        side='positive',\n",
    "        opacity=0.5,\n",
    "        legendgroup='SageMaker',\n",
    "        scalegroup='SageMaker',\n",
    "        name='SageMaker',\n",
    "    ))\n",
    "fig_challenge_word_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_azureml['Challenge_topic_macro'],\n",
    "        y=df_azureml['Challenge_word_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='orange',\n",
    "        side='negative',\n",
    "        opacity=0.5,\n",
    "        legendgroup='AzureML',\n",
    "        scalegroup='AzureML',\n",
    "        name='AzureML',\n",
    "    ))\n",
    "fig_challenge_word_count.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_word_count.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, 'Challenge word count.png'))\n",
    "\n",
    "# Challenge unique word count\n",
    "fig_challenge_unique_word_count = go.Figure()\n",
    "fig_challenge_unique_word_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_sagemaker['Challenge_topic_macro'],\n",
    "        y=df_sagemaker['Challenge_unique_word_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='blue',\n",
    "        side='positive',\n",
    "        opacity=0.5,\n",
    "        legendgroup='SageMaker',\n",
    "        scalegroup='SageMaker',\n",
    "        name='SageMaker',\n",
    "    ))\n",
    "fig_challenge_unique_word_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_azureml['Challenge_topic_macro'],\n",
    "        y=df_azureml['Challenge_unique_word_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='orange',\n",
    "        side='negative',\n",
    "        opacity=0.5,\n",
    "        legendgroup='AzureML',\n",
    "        scalegroup='AzureML',\n",
    "        name='AzureML',\n",
    "    ))\n",
    "fig_challenge_unique_word_count.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_unique_word_count.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, 'Challenge unique word count.png'))\n",
    "\n",
    "# Challenge information entropy\n",
    "fig_challenge_information_entropy = go.Figure()\n",
    "fig_challenge_information_entropy.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_sagemaker['Challenge_topic_macro'],\n",
    "        y=df_sagemaker['Challenge_readability'],\n",
    "        meanline_visible=True,\n",
    "        line_color='blue',\n",
    "        side='positive',\n",
    "        opacity=0.5,\n",
    "        legendgroup='SageMaker',\n",
    "        scalegroup='SageMaker',\n",
    "        name='SageMaker',\n",
    "    ))\n",
    "fig_challenge_information_entropy.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_azureml['Challenge_topic_macro'],\n",
    "        y=df_azureml['Challenge_readability'],\n",
    "        meanline_visible=True,\n",
    "        line_color='orange',\n",
    "        side='negative',\n",
    "        opacity=0.5,\n",
    "        legendgroup='AzureML',\n",
    "        scalegroup='AzureML',\n",
    "        name='AzureML',\n",
    "    ))\n",
    "fig_challenge_information_entropy.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_information_entropy.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, 'Challenge information entropy.png'))\n",
    "\n",
    "# Challenge readability\n",
    "fig_challenge_readability = go.Figure()\n",
    "fig_challenge_readability.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_sagemaker['Challenge_topic_macro'],\n",
    "        y=df_sagemaker['Challenge_readability'],\n",
    "        meanline_visible=True,\n",
    "        line_color='blue',\n",
    "        side='positive',\n",
    "        opacity=0.5,\n",
    "        legendgroup='SageMaker',\n",
    "        scalegroup='SageMaker',\n",
    "        name='SageMaker',\n",
    "    ))\n",
    "fig_challenge_readability.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_azureml['Challenge_topic_macro'],\n",
    "        y=df_azureml['Challenge_readability'],\n",
    "        meanline_visible=True,\n",
    "        line_color='orange',\n",
    "        side='negative',\n",
    "        opacity=0.5,\n",
    "        legendgroup='AzureML',\n",
    "        scalegroup='AzureML',\n",
    "        name='AzureML',\n",
    "    ))\n",
    "fig_challenge_readability.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_readability.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, 'Challenge readability.png'))\n",
    "\n",
    "# Challenge answer count\n",
    "fig_challenge_answer_count = go.Figure()\n",
    "fig_challenge_answer_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_sagemaker['Challenge_topic_macro'],\n",
    "        y=df_sagemaker['Challenge_answer_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='blue',\n",
    "        side='positive',\n",
    "        opacity=0.5,\n",
    "        legendgroup='SageMaker',\n",
    "        scalegroup='SageMaker',\n",
    "        name='SageMaker',\n",
    "    ))\n",
    "fig_challenge_answer_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_azureml['Challenge_topic_macro'],\n",
    "        y=df_azureml['Challenge_answer_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='orange',\n",
    "        side='negative',\n",
    "        opacity=0.5,\n",
    "        legendgroup='AzureML',\n",
    "        scalegroup='AzureML',\n",
    "        name='AzureML',\n",
    "    ))\n",
    "fig_challenge_answer_count.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_answer_count.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, 'Challenge answer count.png'))\n",
    "\n",
    "# Challenge comment count\n",
    "fig_challenge_comment_count = go.Figure()\n",
    "fig_challenge_comment_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_sagemaker['Challenge_topic_macro'],\n",
    "        y=df_sagemaker['Challenge_comment_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='blue',\n",
    "        side='positive',\n",
    "        opacity=0.5,\n",
    "        legendgroup='SageMaker',\n",
    "        scalegroup='SageMaker',\n",
    "        name='SageMaker',\n",
    "    ))\n",
    "fig_challenge_comment_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_azureml['Challenge_topic_macro'],\n",
    "        y=df_azureml['Challenge_comment_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='orange',\n",
    "        side='negative',\n",
    "        opacity=0.5,\n",
    "        legendgroup='AzureML',\n",
    "        scalegroup='AzureML',\n",
    "        name='AzureML',\n",
    "    ))\n",
    "fig_challenge_comment_count.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_comment_count.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, 'Challenge comment count.png'))\n",
    "\n",
    "# Challenge participation count\n",
    "fig_challenge_participation_count = go.Figure()\n",
    "fig_challenge_participation_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_sagemaker['Challenge_topic_macro'],\n",
    "        y=df_sagemaker['Challenge_participation_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='blue',\n",
    "        side='positive',\n",
    "        opacity=0.5,\n",
    "        legendgroup='SageMaker',\n",
    "        scalegroup='SageMaker',\n",
    "        name='SageMaker',\n",
    "    ))\n",
    "fig_challenge_participation_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_azureml['Challenge_topic_macro'],\n",
    "        y=df_azureml['Challenge_participation_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='orange',\n",
    "        side='negative',\n",
    "        opacity=0.5,\n",
    "        legendgroup='AzureML',\n",
    "        scalegroup='AzureML',\n",
    "        name='AzureML',\n",
    "    ))\n",
    "fig_challenge_participation_count.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_participation_count.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, 'Challenge participation count.png'))\n",
    "\n",
    "# Challenge solved time\n",
    "fig_challenge_solved_time = go.Figure()\n",
    "fig_challenge_solved_time.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_sagemaker['Challenge_topic_macro'],\n",
    "        y=df_sagemaker['Challenge_solved_time'],\n",
    "        meanline_visible=True,\n",
    "        line_color='blue',\n",
    "        side='positive',\n",
    "        opacity=0.5,\n",
    "        legendgroup='SageMaker',\n",
    "        scalegroup='SageMaker',\n",
    "        name='SageMaker',\n",
    "    ))\n",
    "fig_challenge_solved_time.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_azureml['Challenge_topic_macro'],\n",
    "        y=df_azureml['Challenge_solved_time'],\n",
    "        meanline_visible=True,\n",
    "        line_color='orange',\n",
    "        side='negative',\n",
    "        opacity=0.5,\n",
    "        legendgroup='AzureML',\n",
    "        scalegroup='AzureML',\n",
    "        name='AzureML',\n",
    "    ))\n",
    "fig_challenge_solved_time.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_solved_time.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, 'Challenge solved time.png'))\n",
    "\n",
    "fig_challenge_mean_solved_time_evolution_sagemaker = go.Figure()\n",
    "fig_challenge_median_solved_time_evolution_sagemaker = go.Figure()\n",
    "\n",
    "fig_challenge_mean_solved_time_evolution_azureml = go.Figure()\n",
    "fig_challenge_median_solved_time_evolution_azureml = go.Figure()\n",
    "\n",
    "for name, group in df.groupby('Challenge_topic_macro'):\n",
    "    sagemaker = group[group['Tool'] == 'Amazon SageMaker']\n",
    "    azureml = group[group['Tool'] == 'Azure Machine Learning']\n",
    "\n",
    "    # Challenge score\n",
    "    challenge_score_azureml = azureml[azureml['Challenge_score'].notna(\n",
    "    )]['Challenge_score']\n",
    "    challenge_score_sagemaker = sagemaker[sagemaker['Challenge_score'].notna(\n",
    "    )]['Challenge_score']\n",
    "    if len(challenge_score_azureml) * len(challenge_score_sagemaker) > 0:\n",
    "        _, p = mannwhitneyu(challenge_score_azureml, challenge_score_sagemaker)\n",
    "        if p < alpha:\n",
    "            print(\n",
    "                f'p = {p:.2f}, indicating different distribution of SageMaker vs AzureML challenge regarding higher level topic {name} in challenge score')\n",
    "\n",
    "    # Challenge favorite count\n",
    "    challenge_favorite_count_azureml = azureml[azureml['Challenge_favorite_count'].notna(\n",
    "    )]['Challenge_favorite_count']\n",
    "    challenge_favorite_count_sagemaker = sagemaker[sagemaker['Challenge_favorite_count'].notna(\n",
    "    )]['Challenge_favorite_count']\n",
    "    if len(challenge_favorite_count_azureml) * len(challenge_favorite_count_sagemaker) > 0:\n",
    "        _, p = mannwhitneyu(challenge_favorite_count_azureml,\n",
    "                            challenge_favorite_count_sagemaker)\n",
    "        if p < alpha:\n",
    "            print(\n",
    "                f'p = {p:.2f}, indicating different distribution of SageMaker vs AzureML challenge regarding higher level topic {name} in challenge favorite count')\n",
    "\n",
    "    # Challenge link count\n",
    "    challenge_link_count_azureml = azureml[azureml['Challenge_link_count'].notna(\n",
    "    )]['Challenge_link_count']\n",
    "    challenge_link_count_sagemaker = sagemaker[sagemaker['Challenge_link_count'].notna(\n",
    "    )]['Challenge_link_count']\n",
    "    if len(challenge_link_count_azureml) * len(challenge_link_count_sagemaker) > 0:\n",
    "        _, p = mannwhitneyu(challenge_link_count_azureml,\n",
    "                            challenge_link_count_sagemaker)\n",
    "        if p < alpha:\n",
    "            print(\n",
    "                f'p = {p:.2f}, indicating different distribution of SageMaker vs AzureML challenge regarding higher level topic {name} in challenge link count')\n",
    "\n",
    "    # Challenge sentence count\n",
    "    challenge_sentence_count_azureml = azureml[azureml['Challenge_sentence_count'].notna(\n",
    "    )]['Challenge_sentence_count']\n",
    "    challenge_sentence_count_sagemaker = sagemaker[sagemaker['Challenge_sentence_count'].notna(\n",
    "    )]['Challenge_sentence_count']\n",
    "    if len(challenge_sentence_count_azureml) * len(challenge_sentence_count_sagemaker) > 0:\n",
    "        _, p = mannwhitneyu(challenge_sentence_count_azureml,\n",
    "                            challenge_sentence_count_sagemaker)\n",
    "        if p < alpha:\n",
    "            print(\n",
    "                f'p = {p:.2f}, indicating different distribution of SageMaker vs AzureML challenge regarding higher level topic {name} in challenge sentence count')\n",
    "\n",
    "    # Challenge word count\n",
    "    challenge_word_count_azureml = azureml[azureml['Challenge_word_count'].notna(\n",
    "    )]['Challenge_word_count']\n",
    "    challenge_word_count_sagemaker = sagemaker[sagemaker['Challenge_word_count'].notna(\n",
    "    )]['Challenge_word_count']\n",
    "    if len(challenge_word_count_azureml) * len(challenge_word_count_sagemaker) > 0:\n",
    "        _, p = mannwhitneyu(challenge_word_count_azureml,\n",
    "                            challenge_word_count_sagemaker)\n",
    "        if p < alpha:\n",
    "            print(\n",
    "                f'p = {p:.2f}, indicating different distribution of SageMaker vs AzureML challenge regarding higher level topic {name} in challenge word count')\n",
    "\n",
    "    # Challenge unique word count\n",
    "    challenge_unique_word_count_azureml = azureml[azureml['Challenge_unique_word_count'].notna(\n",
    "    )]['Challenge_unique_word_count']\n",
    "    challenge_unique_word_count_sagemaker = sagemaker[sagemaker['Challenge_unique_word_count'].notna(\n",
    "    )]['Challenge_unique_word_count']\n",
    "    if len(challenge_unique_word_count_azureml) * len(challenge_unique_word_count_sagemaker) > 0:\n",
    "        _, p = mannwhitneyu(challenge_unique_word_count_azureml,\n",
    "                            challenge_unique_word_count_sagemaker)\n",
    "        if p < alpha:\n",
    "            print(\n",
    "                f'p = {p:.2f}, indicating different distribution of SageMaker vs AzureML challenge regarding higher level topic {name} in challenge unique word count')\n",
    "\n",
    "    # Challenge information entropy\n",
    "    challenge_information_entropy_azureml = azureml[azureml['Challenge_information_entropy'].notna(\n",
    "    )]['Challenge_information_entropy']\n",
    "    challenge_information_entropy_sagemaker = sagemaker[sagemaker['Challenge_information_entropy'].notna(\n",
    "    )]['Challenge_information_entropy']\n",
    "    if len(challenge_information_entropy_azureml) * len(challenge_information_entropy_sagemaker) > 0:\n",
    "        _, p = mannwhitneyu(challenge_information_entropy_azureml,\n",
    "                            challenge_information_entropy_sagemaker)\n",
    "        if p < alpha:\n",
    "            print(\n",
    "                f'p = {p:.2f}, indicating different distribution of SageMaker vs AzureML challenge regarding higher level topic {name} in challenge information entropy')\n",
    "\n",
    "    # Challenge readability\n",
    "    challenge_readability_azureml = azureml[azureml['Challenge_readability'].notna(\n",
    "    )]['Challenge_readability']\n",
    "    challenge_readability_sagemaker = sagemaker[sagemaker['Challenge_readability'].notna(\n",
    "    )]['Challenge_readability']\n",
    "    if len(challenge_readability_azureml) * len(challenge_readability_sagemaker) > 0:\n",
    "        _, p = mannwhitneyu(challenge_readability_azureml,\n",
    "                            challenge_readability_sagemaker)\n",
    "        if p < alpha:\n",
    "            print(\n",
    "                f'p = {p:.2f}, indicating different distribution of SageMaker vs AzureML challenge regarding higher level topic {name} in challenge readability')\n",
    "\n",
    "    # Challenge view count\n",
    "    challenge_view_count_azureml = azureml[azureml['Challenge_view_count'].notna(\n",
    "    )]['Challenge_view_count']\n",
    "    challenge_view_count_sagemaker = sagemaker[sagemaker['Challenge_view_count'].notna(\n",
    "    )]['Challenge_view_count']\n",
    "    if len(challenge_view_count_azureml) * len(challenge_view_count_sagemaker) > 0:\n",
    "        _, p = mannwhitneyu(challenge_view_count_azureml,\n",
    "                            challenge_view_count_sagemaker)\n",
    "        if p < alpha:\n",
    "            print(\n",
    "                f'p = {p:.2f}, indicating different distribution of SageMaker vs AzureML challenge regarding higher level topic {name} in challenge answer count')\n",
    "\n",
    "    # Challenge answer count\n",
    "    challenge_answer_count_azureml = azureml['Challenge_answer_count']\n",
    "    challenge_answer_count_sagemaker = sagemaker['Challenge_answer_count']\n",
    "    if len(challenge_answer_count_azureml) * len(challenge_answer_count_sagemaker) > 0:\n",
    "        _, p = mannwhitneyu(challenge_answer_count_azureml,\n",
    "                            challenge_answer_count_sagemaker)\n",
    "        if p < alpha:\n",
    "            print(\n",
    "                f'p = {p:.2f}, indicating different distribution of SageMaker vs AzureML challenge regarding higher level topic {name} in challenge answer count')\n",
    "\n",
    "    # Challenge comment count\n",
    "    challenge_comment_count_azureml = azureml['Challenge_comment_count']\n",
    "    challenge_comment_count_sagemaker = sagemaker['Challenge_comment_count']\n",
    "    if len(challenge_comment_count_azureml) * len(challenge_comment_count_sagemaker) > 0:\n",
    "        _, p = mannwhitneyu(challenge_comment_count_azureml,\n",
    "                            challenge_comment_count_sagemaker)\n",
    "        if p < alpha:\n",
    "            print(\n",
    "                f'p = {p:.2f}, indicating different distribution of SageMaker vs AzureML challenge regarding higher level topic {name} in challenge comment count')\n",
    "\n",
    "    # Challenge participation count\n",
    "    challenge_participation_count_azureml = azureml['Challenge_participation_count']\n",
    "    challenge_participation_count_sagemaker = sagemaker['Challenge_participation_count']\n",
    "    if len(challenge_participation_count_azureml) * len(challenge_participation_count_sagemaker) > 0:\n",
    "        _, p = mannwhitneyu(challenge_participation_count_azureml,\n",
    "                            challenge_participation_count_sagemaker)\n",
    "        if p < alpha:\n",
    "            print(\n",
    "                f'p = {p:.2f}, indicating different distribution of SageMaker vs AzureML challenge regarding higher level topic {name} in challenge participation count')\n",
    "\n",
    "    # Challenge mean solved time evolution\n",
    "    group_sagemaker = sagemaker.groupby(pd.Grouper(key='Challenge_created_time', freq='Y'))[\n",
    "        'Challenge_solved_time'].mean().reset_index()\n",
    "    x_sagemaker = pd.to_datetime(\n",
    "        group_sagemaker['Challenge_created_time']).values\n",
    "    y_sagemaker = group_sagemaker['Challenge_solved_time'].values\n",
    "    fig_challenge_mean_solved_time_evolution_sagemaker.add_trace(\n",
    "        go.Scatter(x=x_sagemaker, y=y_sagemaker, mode='lines', name=name))\n",
    "\n",
    "    group_azureml = azureml.groupby(pd.Grouper(key='Challenge_created_time', freq='Y'))[\n",
    "        'Challenge_solved_time'].mean().reset_index()\n",
    "    x_azureml = pd.to_datetime(group_azureml['Challenge_created_time']).values\n",
    "    y_azureml = group_azureml['Challenge_solved_time'].values\n",
    "    fig_challenge_mean_solved_time_evolution_azureml.add_trace(\n",
    "        go.Scatter(x=x_azureml, y=y_azureml, mode='lines', name=name))\n",
    "\n",
    "    # Challenge median solved time evolution\n",
    "    group_sagemaker = sagemaker.groupby(pd.Grouper(key='Challenge_created_time', freq='Y'))[\n",
    "        'Challenge_solved_time'].median().reset_index()\n",
    "    x_sagemaker = pd.to_datetime(\n",
    "        group_sagemaker['Challenge_created_time']).values\n",
    "    y_sagemaker = group_sagemaker['Challenge_solved_time'].values\n",
    "    fig_challenge_median_solved_time_evolution_sagemaker.add_trace(\n",
    "        go.Scatter(x=x_sagemaker, y=y_sagemaker, mode='lines', name=name))\n",
    "\n",
    "    group_azureml = azureml.groupby(pd.Grouper(key='Challenge_created_time', freq='Y'))[\n",
    "        'Challenge_solved_time'].median().reset_index()\n",
    "    x_azureml = pd.to_datetime(group_azureml['Challenge_created_time']).values\n",
    "    y_azureml = group_azureml['Challenge_solved_time'].values\n",
    "    fig_challenge_median_solved_time_evolution_azureml.add_trace(\n",
    "        go.Scatter(x=x_azureml, y=y_azureml, mode='lines', name=name))\n",
    "\n",
    "# Challenge mean solved time\n",
    "challenge_mean_solved_time_azureml = df_azureml[['Challenge_topic_macro', 'Challenge_solved_time']].groupby(\n",
    "    'Challenge_topic_macro').mean()['Challenge_solved_time']\n",
    "challenge_mean_solved_time_sagemaker = df_sagemaker[['Challenge_topic_macro', 'Challenge_solved_time']].groupby(\n",
    "    'Challenge_topic_macro').mean()['Challenge_solved_time']\n",
    "_, p = mannwhitneyu(challenge_mean_solved_time_azureml,\n",
    "                    challenge_mean_solved_time_sagemaker)\n",
    "if p < alpha:\n",
    "    print(f'p = {p:.2f}, indicating different distribution of SageMaker vs AzureML in higher level mean challenge solved time')\n",
    "\n",
    "# Challenge median solved time\n",
    "challenge_median_solved_time_azureml = df_azureml[['Challenge_topic_macro', 'Challenge_solved_time']].groupby(\n",
    "    'Challenge_topic_macro').median()['Challenge_solved_time']\n",
    "challenge_median_solved_time_sagemaker = df_sagemaker[['Challenge_topic_macro', 'Challenge_solved_time']].groupby(\n",
    "    'Challenge_topic_macro').median()['Challenge_solved_time']\n",
    "_, p = mannwhitneyu(challenge_median_solved_time_azureml,\n",
    "                    challenge_median_solved_time_sagemaker)\n",
    "if p < alpha:\n",
    "    print(f'p = {p:.2f}, indicating different distribution of SageMaker vs AzureML in higher level median challenge solved time')\n",
    "\n",
    "fig_challenge_mean_solved_time_evolution_sagemaker.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_median_solved_time_evolution_sagemaker.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_mean_solved_time_evolution_sagemaker.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, 'Challenge mean solved time evolution (SageMaker).png'))\n",
    "fig_challenge_median_solved_time_evolution_sagemaker.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, 'Challenge median solved time evolution (SageMaker).png'))\n",
    "\n",
    "fig_challenge_mean_solved_time_evolution_azureml.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_median_solved_time_evolution_azureml.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_mean_solved_time_evolution_azureml.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, 'Challenge mean solved time evolution (AzureML).png'))\n",
    "fig_challenge_median_solved_time_evolution_azureml.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, 'Challenge median solved time evolution (AzureML).png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the explanability of the challenge solved rate classification model between SageMaker vs AzureML\n",
    "\n",
    "df = pd.read_json(os.path.join(path_general, 'filtered.json'))\n",
    "\n",
    "# SageMaker\n",
    "\n",
    "df_sagemaker = df[df['Tool'] == 'Amazon SageMaker']\n",
    "df_sagemaker = df_sagemaker[df_sagemaker.columns.drop(list(df_sagemaker.filter(\n",
    "    regex='Platform|Tool|Solution|topic|solved_time|edit_time')))]\n",
    "X = df_sagemaker.drop(\n",
    "    ['Challenge_link', 'Challenge_closed_time', 'Challenge_created_time'], axis=1)\n",
    "y = df_sagemaker['Challenge_closed_time'].isna()\n",
    "\n",
    "classifier = XGBClassifier(objective='binary:logistic', eval_metric='auc', tree_method='gpu_hist',\n",
    "                           random_state=random_state, max_depth=5, n_estimators=1000, eta=0.1483)\n",
    "classifier.fit(X, y)\n",
    "\n",
    "sorted_idx = classifier.feature_importances_.argsort()\n",
    "fig, _ = plt.subplots()\n",
    "plt.barh(X.columns[sorted_idx][:10],\n",
    "         classifier.feature_importances_[sorted_idx][:10])\n",
    "plt.xlabel(\"Xgboost Feature Importance\")\n",
    "fig.savefig(os.path.join(path_challenge_azureml_sagemaker,\n",
    "            f'Challenge_solved_rate xgboost_feature_importance (SageMaker).png'), bbox_inches='tight')\n",
    "\n",
    "explainer = shap.TreeExplainer(classifier)\n",
    "shap_values = explainer.shap_values(X)\n",
    "shap.summary_plot(shap_values, X, show=False)\n",
    "fig.savefig(os.path.join(path_challenge_azureml_sagemaker,\n",
    "            f'Challenge_solved_rate SHAP_based_feature_importance (SageMaker).png'), bbox_inches='tight')\n",
    "\n",
    "perm_importance = permutation_importance(\n",
    "    classifier, X, y, random_state=random_state)\n",
    "sorted_idx = perm_importance.importances_mean.argsort()\n",
    "fig, _ = plt.subplots()\n",
    "plt.barh(X.columns[sorted_idx],\n",
    "         perm_importance.importances_mean[sorted_idx])\n",
    "plt.xlabel(\"Permutation Importance\")\n",
    "fig.savefig(os.path.join(path_challenge_azureml_sagemaker,\n",
    "            f'Challenge_solved_rate permutation_based_feature_importance (SageMaker).png'), bbox_inches='tight')\n",
    "\n",
    "# AzureML\n",
    "\n",
    "df_azureml = df[df['Tool'] == 'Azure Machine Learning']\n",
    "df_azureml = df_azureml[df_azureml.columns.drop(list(df_azureml.filter(\n",
    "    regex='Platform|Tool|Solution|topic|solved_time|edit_time')))]\n",
    "X = df_azureml.drop(\n",
    "    ['Challenge_link', 'Challenge_closed_time', 'Challenge_created_time'], axis=1)\n",
    "y = df_azureml['Challenge_closed_time'].isna()\n",
    "\n",
    "classifier = XGBClassifier(objective='binary:logistic', eval_metric='auc', tree_method='gpu_hist',\n",
    "                           random_state=random_state, max_depth=5, n_estimators=1000, eta=0.1483)\n",
    "classifier.fit(X, y)\n",
    "\n",
    "sorted_idx = classifier.feature_importances_.argsort()\n",
    "fig, _ = plt.subplots()\n",
    "plt.barh(X.columns[sorted_idx][:10],\n",
    "         classifier.feature_importances_[sorted_idx][:10])\n",
    "plt.xlabel(\"Xgboost Feature Importance\")\n",
    "fig.savefig(os.path.join(path_challenge_azureml_sagemaker,\n",
    "            f'Challenge_solved_rate xgboost_feature_importance (AzureML).png'), bbox_inches='tight')\n",
    "\n",
    "explainer = shap.TreeExplainer(classifier)\n",
    "shap_values = explainer.shap_values(X)\n",
    "shap.summary_plot(shap_values, X, show=False)\n",
    "fig.savefig(os.path.join(path_challenge_azureml_sagemaker,\n",
    "            f'Challenge_solved_rate SHAP_based_feature_importance (AzureML).png'), bbox_inches='tight')\n",
    "\n",
    "perm_importance = permutation_importance(\n",
    "    classifier, X, y, random_state=random_state)\n",
    "sorted_idx = perm_importance.importances_mean.argsort()\n",
    "fig, _ = plt.subplots()\n",
    "plt.barh(X.columns[sorted_idx],\n",
    "         perm_importance.importances_mean[sorted_idx])\n",
    "plt.xlabel(\"Permutation Importance\")\n",
    "fig.savefig(os.path.join(path_challenge_azureml_sagemaker,\n",
    "            f'Challenge_solved_rate permutation_based_feature_importance (AzureML).png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the explanability of the challenge solved time regression model between SageMaker vs AzureML\n",
    "\n",
    "df = pd.read_json(os.path.join(path_solution, 'solved.json'))\n",
    "df = df[df['Challenge_solved_time'].notna()]\n",
    "df = df.drop(['Challenge_link', 'Challenge_closed_time',\n",
    "             'Challenge_created_time'], axis=1)\n",
    "\n",
    "# SageMaker\n",
    "\n",
    "df_sagemaker = df[df['Tool'] == 'Amazon SageMaker']\n",
    "X = df_sagemaker[df_sagemaker.columns.drop(list(df_sagemaker.filter(\n",
    "    regex='Platform|Tool|topic|solved_time|edit_time|favorite_count')))]\n",
    "y = df_sagemaker['Challenge_solved_time']\n",
    "\n",
    "regressor = XGBRegressor(objective='reg:squaredlogerror', tree_method='gpu_hist',\n",
    "                         random_state=random_state, max_depth=5, n_estimators=1000, eta=0.0206)\n",
    "regressor.fit(X, y)\n",
    "\n",
    "sorted_idx = regressor.feature_importances_.argsort()\n",
    "fig, _ = plt.subplots()\n",
    "plt.barh(X.columns[sorted_idx],\n",
    "         regressor.feature_importances_[sorted_idx])\n",
    "plt.xlabel(\"Xgboost Feature Importance\")\n",
    "fig.savefig(os.path.join(path_challenge_azureml_sagemaker,\n",
    "            f'Challenge_solved_time xgboost_feature_importance (SageMaker).png'), bbox_inches='tight')\n",
    "\n",
    "explainer = shap.TreeExplainer(regressor)\n",
    "shap_values = explainer.shap_values(X)\n",
    "shap.summary_plot(shap_values, X, show=False)\n",
    "fig.savefig(os.path.join(path_challenge_azureml_sagemaker,\n",
    "            f'Challenge_solved_time SHAP_based_feature_importance (SageMaker).png'), bbox_inches='tight')\n",
    "\n",
    "perm_importance = permutation_importance(\n",
    "    regressor, X, y, random_state=random_state)\n",
    "sorted_idx = perm_importance.importances_mean.argsort()\n",
    "fig, _ = plt.subplots()\n",
    "plt.barh(X.columns[sorted_idx],\n",
    "         perm_importance.importances_mean[sorted_idx])\n",
    "plt.xlabel(\"Permutation Importance\")\n",
    "fig.savefig(os.path.join(path_challenge_azureml_sagemaker,\n",
    "            f'Challenge_solved_time permutation_based_feature_importance (SageMaker).png'), bbox_inches='tight')\n",
    "\n",
    "# AzureML\n",
    "\n",
    "df_azureml = df[df['Tool'] == 'Azure Machine Learning']\n",
    "X = df_azureml[df_azureml.columns.drop(list(df_azureml.filter(\n",
    "    regex='Platform|Tool|topic|solved_time|edit_time|view_count')))]\n",
    "y = df_azureml['Challenge_solved_time']\n",
    "\n",
    "regressor = XGBRegressor(objective='reg:squaredlogerror', tree_method='gpu_hist',\n",
    "                         random_state=random_state, max_depth=5, n_estimators=1000, eta=0.0206)\n",
    "regressor.fit(X, y)\n",
    "\n",
    "sorted_idx = regressor.feature_importances_.argsort()\n",
    "fig, _ = plt.subplots()\n",
    "plt.barh(X.columns[sorted_idx],\n",
    "         regressor.feature_importances_[sorted_idx])\n",
    "plt.xlabel(\"Xgboost Feature Importance\")\n",
    "fig.savefig(os.path.join(path_challenge_azureml_sagemaker,\n",
    "            f'Challenge_solved_time xgboost_feature_importance (AzureML).png'), bbox_inches='tight')\n",
    "\n",
    "explainer = shap.TreeExplainer(regressor)\n",
    "shap_values = explainer.shap_values(X)\n",
    "shap.summary_plot(shap_values, X, show=False)\n",
    "fig.savefig(os.path.join(path_challenge_azureml_sagemaker,\n",
    "            f'Challenge_solved_time SHAP_based_feature_importance (AzureML).png'), bbox_inches='tight')\n",
    "\n",
    "perm_importance = permutation_importance(\n",
    "    regressor, X, y, random_state=random_state)\n",
    "sorted_idx = perm_importance.importances_mean.argsort()\n",
    "fig, _ = plt.subplots()\n",
    "plt.barh(X.columns[sorted_idx],\n",
    "         perm_importance.importances_mean[sorted_idx])\n",
    "plt.xlabel(\"Permutation Importance\")\n",
    "fig.savefig(os.path.join(path_challenge_azureml_sagemaker,\n",
    "            f'Challenge_solved_time permutation_based_feature_importance (AzureML).png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the explanability of the challenge adjusted solved time regression model between SageMaker vs AzureML\n",
    "\n",
    "df = pd.read_json(os.path.join(path_solution, 'solved.json'))\n",
    "df = df[df['Challenge_adjusted_solved_time'].notna()]\n",
    "df = df.drop(['Challenge_link', 'Challenge_closed_time',\n",
    "             'Challenge_created_time'], axis=1)\n",
    "\n",
    "# SageMaker\n",
    "\n",
    "df_sagemaker = df[df['Tool'] == 'Amazon SageMaker']\n",
    "X = df_sagemaker[df_sagemaker.columns.drop(list(df_sagemaker.filter(\n",
    "    regex='Platform|Tool|topic|solved_time|edit_time|favorite_count')))]\n",
    "y = df_sagemaker['Challenge_adjusted_solved_time']\n",
    "\n",
    "regressor = XGBRegressor(objective='reg:squaredlogerror', tree_method='gpu_hist',\n",
    "                         random_state=random_state, max_depth=5, n_estimators=1000, eta=0.03353)\n",
    "regressor.fit(X, y)\n",
    "\n",
    "sorted_idx = regressor.feature_importances_.argsort()\n",
    "fig, _ = plt.subplots()\n",
    "plt.barh(X.columns[sorted_idx],\n",
    "         regressor.feature_importances_[sorted_idx])\n",
    "plt.xlabel(\"Xgboost Feature Importance\")\n",
    "fig.savefig(os.path.join(path_challenge_azureml_sagemaker,\n",
    "            f'Challenge_adjusted_solved_time xgboost_feature_importance (SageMaker).png'), bbox_inches='tight')\n",
    "\n",
    "explainer = shap.TreeExplainer(regressor)\n",
    "shap_values = explainer.shap_values(X)\n",
    "shap.summary_plot(shap_values, X, show=False)\n",
    "fig.savefig(os.path.join(path_challenge_azureml_sagemaker,\n",
    "            f'Challenge_adjusted_solved_time SHAP_based_feature_importance (SageMaker).png'), bbox_inches='tight')\n",
    "\n",
    "perm_importance = permutation_importance(\n",
    "    regressor, X, y, random_state=random_state)\n",
    "sorted_idx = perm_importance.importances_mean.argsort()\n",
    "fig, _ = plt.subplots()\n",
    "plt.barh(X.columns[sorted_idx],\n",
    "         perm_importance.importances_mean[sorted_idx])\n",
    "plt.xlabel(\"Permutation Importance\")\n",
    "fig.savefig(os.path.join(path_challenge_azureml_sagemaker,\n",
    "            f'Challenge_adjusted_solved_time permutation_based_feature_importance (SageMaker).png'), bbox_inches='tight')\n",
    "\n",
    "# AzureML\n",
    "\n",
    "df_azureml = df[df['Tool'] == 'Azure Machine Learning']\n",
    "X = df_azureml[df_azureml.columns.drop(list(df_azureml.filter(\n",
    "    regex='Platform|Tool|topic|solved_time|edit_time|view_count')))]\n",
    "y = df_azureml['Challenge_adjusted_solved_time']\n",
    "\n",
    "regressor = XGBRegressor(objective='reg:squaredlogerror', tree_method='gpu_hist',\n",
    "                         random_state=random_state, max_depth=5, n_estimators=1000, eta=0.03353)\n",
    "regressor.fit(X, y)\n",
    "\n",
    "sorted_idx = regressor.feature_importances_.argsort()\n",
    "fig, _ = plt.subplots()\n",
    "plt.barh(X.columns[sorted_idx],\n",
    "         regressor.feature_importances_[sorted_idx])\n",
    "plt.xlabel(\"Xgboost Feature Importance\")\n",
    "fig.savefig(os.path.join(path_challenge_azureml_sagemaker,\n",
    "            f'Challenge_adjusted_solved_time xgboost_feature_importance (AzureML).png'), bbox_inches='tight')\n",
    "\n",
    "explainer = shap.TreeExplainer(regressor)\n",
    "shap_values = explainer.shap_values(X)\n",
    "shap.summary_plot(shap_values, X, show=False)\n",
    "fig.savefig(os.path.join(path_challenge_azureml_sagemaker,\n",
    "            f'Challenge_adjusted_solved_time SHAP_based_feature_importance (AzureML).png'), bbox_inches='tight')\n",
    "\n",
    "perm_importance = permutation_importance(\n",
    "    regressor, X, y, random_state=random_state)\n",
    "sorted_idx = perm_importance.importances_mean.argsort()\n",
    "fig, _ = plt.subplots()\n",
    "plt.barh(X.columns[sorted_idx],\n",
    "         perm_importance.importances_mean[sorted_idx])\n",
    "plt.xlabel(\"Permutation Importance\")\n",
    "fig.savefig(os.path.join(path_challenge_azureml_sagemaker,\n",
    "            f'Challenge_adjusted_solved_time permutation_based_feature_importance (AzureML).png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare metrics evolution of SageMaker vs AzureML challenges across different topics\n",
    "\n",
    "df_challenge = pd.read_json(os.path.join(path_general, 'filtered.json'))\n",
    "\n",
    "fig_challenge_topic_count_sagemaker = go.Figure()\n",
    "fig_challenge_view_count_sagemaker = go.Figure()\n",
    "fig_challenge_favorite_count_sagemaker = go.Figure()\n",
    "fig_challenge_answer_count_sagemaker = go.Figure()\n",
    "fig_challenge_comment_count_sagemaker = go.Figure()\n",
    "fig_challenge_participation_count_sagemaker = go.Figure()\n",
    "fig_challenge_score_sagemaker = go.Figure()\n",
    "fig_challenge_word_count_sagemaker = go.Figure()\n",
    "fig_challenge_unique_word_count_sagemaker = go.Figure()\n",
    "fig_challenge_sentence_count_sagemaker = go.Figure()\n",
    "fig_challenge_link_count_sagemaker = go.Figure()\n",
    "fig_challenge_information_entropy_sagemaker = go.Figure()\n",
    "fig_challenge_readability_sagemaker = go.Figure()\n",
    "fig_challenge_topic_closed_count_sagemaker = go.Figure()\n",
    "fig_challenge_solved_rate_sagemaker = go.Figure()\n",
    "\n",
    "fig_challenge_topic_count_azureml = go.Figure()\n",
    "fig_challenge_view_count_azureml = go.Figure()\n",
    "fig_challenge_favorite_count_azureml = go.Figure()\n",
    "fig_challenge_answer_count_azureml = go.Figure()\n",
    "fig_challenge_comment_count_azureml = go.Figure()\n",
    "fig_challenge_participation_count_azureml = go.Figure()\n",
    "fig_challenge_score_azureml = go.Figure()\n",
    "fig_challenge_word_count_azureml = go.Figure()\n",
    "fig_challenge_unique_word_count_azureml = go.Figure()\n",
    "fig_challenge_sentence_count_azureml = go.Figure()\n",
    "fig_challenge_link_count_azureml = go.Figure()\n",
    "fig_challenge_information_entropy_azureml = go.Figure()\n",
    "fig_challenge_readability_azureml = go.Figure()\n",
    "fig_challenge_topic_closed_count_azureml = go.Figure()\n",
    "fig_challenge_solved_rate_azureml = go.Figure()\n",
    "\n",
    "for name, group in df_challenge.groupby('Challenge_topic_macro'):\n",
    "    sagemaker = group[group['Tool'] == 'Amazon SageMaker']\n",
    "    azureml = group[group['Tool'] == 'Azure Machine Learning']\n",
    "\n",
    "    # plot challenge topic count over time\n",
    "    group_sagemaker = sagemaker.groupby(pd.Grouper(key='Challenge_created_time', freq='Y'))[\n",
    "        'Challenge_topic_macro'].count().reset_index()\n",
    "    x_sagemaker = pd.to_datetime(\n",
    "        group_sagemaker['Challenge_created_time']).values\n",
    "    y_sagemaker = group_sagemaker['Challenge_topic_macro'].values\n",
    "    diff_y = np.diff(y_sagemaker)\n",
    "    diff_y = np.insert(diff_y, 0, 0)\n",
    "    fig_challenge_topic_count_sagemaker.add_trace(\n",
    "        go.Scatter(x=x_sagemaker, y=diff_y, mode='lines', name=name))\n",
    "\n",
    "    group_azureml = azureml.groupby(pd.Grouper(key='Challenge_created_time', freq='Y'))[\n",
    "        'Challenge_topic_macro'].count().reset_index()\n",
    "    x_azureml = pd.to_datetime(group_azureml['Challenge_created_time']).values\n",
    "    y_azureml = group_azureml['Challenge_topic_macro'].values\n",
    "    diff_y = np.diff(y_azureml)\n",
    "    diff_y = np.insert(diff_y, 0, 0)\n",
    "    fig_challenge_topic_count_azureml.add_trace(\n",
    "        go.Scatter(x=x_azureml, y=diff_y, mode='lines', name=name))\n",
    "\n",
    "    # plot challenge participation count over time\n",
    "    group_sagemaker = sagemaker.groupby(pd.Grouper(key='Challenge_created_time', freq='Y'))[['Challenge_participation_count', 'Challenge_answer_count', 'Challenge_comment_count', 'Challenge_view_count', 'Challenge_favorite_count',\n",
    "                                                                                             'Challenge_link_count', 'Challenge_word_count', 'Challenge_score', 'Challenge_unique_word_count', 'Challenge_sentence_count', 'Challenge_information_entropy', 'Challenge_readability']].sum().reset_index()\n",
    "    y = group_sagemaker['Challenge_participation_count'].values\n",
    "    diff_y = np.diff(y)\n",
    "    diff_y = np.insert(diff_y, 0, 0)\n",
    "    fig_challenge_participation_count_sagemaker.add_trace(\n",
    "        go.Scatter(x=x_sagemaker, y=diff_y, mode='lines', name=name))\n",
    "\n",
    "    group_azureml = azureml.groupby(pd.Grouper(key='Challenge_created_time', freq='Y'))[['Challenge_participation_count', 'Challenge_answer_count', 'Challenge_comment_count', 'Challenge_view_count', 'Challenge_favorite_count',\n",
    "                                                                                         'Challenge_link_count', 'Challenge_word_count', 'Challenge_score', 'Challenge_unique_word_count', 'Challenge_sentence_count', 'Challenge_information_entropy', 'Challenge_readability']].sum().reset_index()\n",
    "    y = group_azureml['Challenge_participation_count'].values\n",
    "    diff_y = np.diff(y)\n",
    "    diff_y = np.insert(diff_y, 0, 0)\n",
    "    fig_challenge_participation_count_azureml.add_trace(\n",
    "        go.Scatter(x=x_azureml, y=diff_y, mode='lines', name=name))\n",
    "\n",
    "    # plot challenge answer count over time\n",
    "    y = group_sagemaker['Challenge_answer_count'].values\n",
    "    diff_y = np.diff(y)\n",
    "    diff_y = np.insert(diff_y, 0, 0)\n",
    "    fig_challenge_answer_count_sagemaker.add_trace(\n",
    "        go.Scatter(x=x_sagemaker, y=diff_y, mode='lines', name=name))\n",
    "    \n",
    "    y = group_azureml['Challenge_answer_count'].values\n",
    "    diff_y = np.diff(y)\n",
    "    diff_y = np.insert(diff_y, 0, 0)\n",
    "    fig_challenge_answer_count_azureml.add_trace(\n",
    "        go.Scatter(x=x_azureml, y=diff_y, mode='lines', name=name))\n",
    "\n",
    "    # plot challenge comment count over time\n",
    "    y = group_sagemaker['Challenge_comment_count'].values\n",
    "    diff_y = np.diff(y)\n",
    "    diff_y = np.insert(diff_y, 0, 0)\n",
    "    fig_challenge_comment_count_sagemaker.add_trace(\n",
    "        go.Scatter(x=x_sagemaker, y=diff_y, mode='lines', name=name))\n",
    "    \n",
    "    y = group_azureml['Challenge_comment_count'].values\n",
    "    diff_y = np.diff(y)\n",
    "    diff_y = np.insert(diff_y, 0, 0)\n",
    "    fig_challenge_comment_count_azureml.add_trace(\n",
    "        go.Scatter(x=x_azureml, y=diff_y, mode='lines', name=name))\n",
    "\n",
    "    # plot challenge view count over time\n",
    "    y = group_sagemaker['Challenge_view_count'].values\n",
    "    diff_y = np.diff(y)\n",
    "    diff_y = np.insert(diff_y, 0, 0)\n",
    "    fig_challenge_view_count_sagemaker.add_trace(\n",
    "        go.Scatter(x=x_sagemaker, y=diff_y, mode='lines', name=name))\n",
    "\n",
    "    y = group_azureml['Challenge_view_count'].values\n",
    "    diff_y = np.diff(y)\n",
    "    diff_y = np.insert(diff_y, 0, 0)\n",
    "    fig_challenge_view_count_azureml.add_trace(\n",
    "        go.Scatter(x=x_azureml, y=diff_y, mode='lines', name=name))\n",
    "\n",
    "    # plot challenge favorite count over time\n",
    "    y = group_sagemaker['Challenge_favorite_count'].values\n",
    "    diff_y = np.diff(y)\n",
    "    diff_y = np.insert(diff_y, 0, 0)\n",
    "    fig_challenge_favorite_count_sagemaker.add_trace(\n",
    "        go.Scatter(x=x_sagemaker, y=diff_y, mode='lines', name=name))\n",
    "\n",
    "    y = group_azureml['Challenge_favorite_count'].values\n",
    "    diff_y = np.diff(y)\n",
    "    diff_y = np.insert(diff_y, 0, 0)\n",
    "    fig_challenge_favorite_count_azureml.add_trace(\n",
    "        go.Scatter(x=x_azureml, y=diff_y, mode='lines', name=name))\n",
    "\n",
    "    # plot challenge score over time\n",
    "    y = group_sagemaker['Challenge_score'].values\n",
    "    diff_y = np.diff(y)\n",
    "    diff_y = np.insert(diff_y, 0, 0)\n",
    "    fig_challenge_score_sagemaker.add_trace(\n",
    "        go.Scatter(x=x_sagemaker, y=diff_y, mode='lines', name=name))\n",
    "\n",
    "    y = group_azureml['Challenge_score'].values\n",
    "    diff_y = np.diff(y)\n",
    "    diff_y = np.insert(diff_y, 0, 0)\n",
    "    fig_challenge_score_azureml.add_trace(\n",
    "        go.Scatter(x=x_azureml, y=diff_y, mode='lines', name=name))\n",
    "\n",
    "    # plot challenge closed topic count over time\n",
    "    group_closed_sagemaker = sagemaker.groupby(pd.Grouper(key='Challenge_closed_time', freq='Y'))[\n",
    "        'Challenge_topic_macro'].count().reset_index()\n",
    "    x = pd.to_datetime(group_closed_sagemaker['Challenge_closed_time']).values\n",
    "    y = group_closed_sagemaker['Challenge_topic_macro'].values\n",
    "    diff_Y = np.diff(y)\n",
    "    diff_Y = np.insert(diff_Y, 0, 0)\n",
    "    fig_challenge_topic_closed_count_sagemaker.add_trace(\n",
    "        go.Scatter(x=x, y=diff_Y, mode='lines', name=name))\n",
    "    \n",
    "    group_closed_azureml = azureml.groupby(pd.Grouper(key='Challenge_closed_time', freq='Y'))[\n",
    "        'Challenge_topic_macro'].count().reset_index()\n",
    "    x = pd.to_datetime(group_closed_azureml['Challenge_closed_time']).values\n",
    "    y = group_closed_azureml['Challenge_topic_macro'].values\n",
    "    diff_Y = np.diff(y)\n",
    "    diff_Y = np.insert(diff_Y, 0, 0)\n",
    "    fig_challenge_topic_closed_count_azureml.add_trace(\n",
    "        go.Scatter(x=x, y=diff_Y, mode='lines', name=name))\n",
    "\n",
    "    # plot challenge link count over time\n",
    "    y = group_sagemaker['Challenge_link_count'].values / y_sagemaker\n",
    "    fig_challenge_link_count_sagemaker.add_trace(\n",
    "        go.Scatter(x=x_sagemaker, y=y, mode='lines', name=name))\n",
    "\n",
    "    y = group_azureml['Challenge_link_count'].values / y_azureml\n",
    "    fig_challenge_link_count_azureml.add_trace(\n",
    "        go.Scatter(x=x_azureml, y=y, mode='lines', name=name))\n",
    "\n",
    "    # plot challenge word count over time\n",
    "    y = group_sagemaker['Challenge_word_count'].values / y_sagemaker\n",
    "    fig_challenge_word_count_sagemaker.add_trace(\n",
    "        go.Scatter(x=x_sagemaker, y=y, mode='lines', name=name))\n",
    "\n",
    "    y = group_azureml['Challenge_word_count'].values / y_azureml\n",
    "    fig_challenge_word_count_azureml.add_trace(\n",
    "        go.Scatter(x=x_azureml, y=y, mode='lines', name=name))\n",
    "\n",
    "    # plot challenge sentence count over time\n",
    "    y = group_sagemaker['Challenge_sentence_count'].values / y_sagemaker\n",
    "    fig_challenge_sentence_count_sagemaker.add_trace(\n",
    "        go.Scatter(x=x_sagemaker, y=y, mode='lines', name=name))\n",
    "\n",
    "    y = group_azureml['Challenge_sentence_count'].values / y_azureml\n",
    "    fig_challenge_sentence_count_azureml.add_trace(\n",
    "        go.Scatter(x=x_azureml, y=y, mode='lines', name=name))\n",
    "\n",
    "    # plot challenge unique word count over time\n",
    "    y = group_sagemaker['Challenge_unique_word_count'].values / y_sagemaker\n",
    "    fig_challenge_unique_word_count_sagemaker.add_trace(\n",
    "        go.Scatter(x=x_sagemaker, y=y, mode='lines', name=name))\n",
    "\n",
    "    y = group_azureml['Challenge_unique_word_count'].values / y_azureml\n",
    "    fig_challenge_unique_word_count_azureml.add_trace(\n",
    "        go.Scatter(x=x_azureml, y=y, mode='lines', name=name))\n",
    "\n",
    "    # plot challenge information entropy over time\n",
    "    y = group_sagemaker['Challenge_information_entropy'].values / y_sagemaker\n",
    "    fig_challenge_information_entropy_sagemaker.add_trace(\n",
    "        go.Scatter(x=x_sagemaker, y=y, mode='lines', name=name))\n",
    "\n",
    "    y = group_azureml['Challenge_information_entropy'].values / y_azureml\n",
    "    fig_challenge_information_entropy_azureml.add_trace(\n",
    "        go.Scatter(x=x_azureml, y=y, mode='lines', name=name))\n",
    "\n",
    "    # plot challenge readability over time\n",
    "    y = group_sagemaker['Challenge_readability'].values / y_sagemaker\n",
    "    fig_challenge_readability_sagemaker.add_trace(\n",
    "        go.Scatter(x=x_sagemaker, y=y, mode='lines', name=name))\n",
    "\n",
    "    y = group_azureml['Challenge_readability'].values / y_azureml\n",
    "    fig_challenge_readability_azureml.add_trace(\n",
    "        go.Scatter(x=x_azureml, y=y, mode='lines', name=name))\n",
    "\n",
    "    # plot challenge solved rate over time\n",
    "    group_closed_sagemaker = sagemaker.groupby(pd.Grouper(key='Challenge_closed_time', freq='Y'))['Challenge_topic_macro'].size(\n",
    "    ).cumsum().reset_index().rename(columns={'Challenge_closed_time': 'Date', 'Challenge_topic_macro': 'Solved'})\n",
    "    group_all_sagemaker = sagemaker.groupby(pd.Grouper(key='Challenge_created_time', freq='Y'))['Challenge_topic_macro'].size(\n",
    "    ).cumsum().reset_index().rename(columns={'Challenge_created_time': 'Date', 'Challenge_topic_macro': 'All'})\n",
    "    group_solved = pd.merge(group_closed_sagemaker, group_all_sagemaker, on='Date', how='outer').fillna(0).sort_values(by='Date')\n",
    "    x = pd.to_datetime(group_all_sagemaker['Date']).values\n",
    "    y = group_solved['Solved'] / group_solved['All'] * 100\n",
    "    fig_challenge_solved_rate_sagemaker.add_trace(\n",
    "        go.Scatter(x=x, y=y, mode='lines', name=name))\n",
    "    \n",
    "    group_closed_azureml = azureml.groupby(pd.Grouper(key='Challenge_closed_time', freq='Y'))['Challenge_topic_macro'].size(\n",
    "    ).cumsum().reset_index().rename(columns={'Challenge_closed_time': 'Date', 'Challenge_topic_macro': 'Solved'})\n",
    "    group_all_azureml = azureml.groupby(pd.Grouper(key='Challenge_created_time', freq='Y'))['Challenge_topic_macro'].size(\n",
    "    ).cumsum().reset_index().rename(columns={'Challenge_created_time': 'Date', 'Challenge_topic_macro': 'All'})\n",
    "    group_solved = pd.merge(group_closed_azureml, group_all_azureml, on='Date', how='outer').fillna(0).sort_values(by='Date')\n",
    "    x = pd.to_datetime(group_all_azureml['Date']).values\n",
    "    y = group_solved['Solved'] / group_solved['All'] * 100\n",
    "    fig_challenge_solved_rate_azureml.add_trace(\n",
    "        go.Scatter(x=x, y=y, mode='lines', name=name))\n",
    "\n",
    "fig_challenge_topic_count_sagemaker.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_view_count_sagemaker.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_favorite_count_sagemaker.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_participation_count_sagemaker.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_answer_count_sagemaker.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_comment_count_sagemaker.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_score_sagemaker.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_word_count_sagemaker.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_unique_word_count_sagemaker.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_sentence_count_sagemaker.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_link_count_sagemaker.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_information_entropy_sagemaker.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_readability_sagemaker.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_topic_closed_count_sagemaker.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_solved_rate_sagemaker.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "\n",
    "fig_challenge_topic_count_azureml.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_view_count_azureml.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_favorite_count_azureml.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_answer_count_azureml.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_comment_count_azureml.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_participation_count_azureml.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_score_azureml.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_word_count_azureml.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_unique_word_count_azureml.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_sentence_count_azureml.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_link_count_azureml.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_information_entropy_azureml.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_readability_azureml.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_topic_closed_count_azureml.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_solved_rate_azureml.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "\n",
    "fig_challenge_topic_count_sagemaker.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, f'Challenge_topic_count_increase_rate (SageMaker).png'))\n",
    "fig_challenge_view_count_sagemaker.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, f'Challenge_view_count_increase_rate (SageMaker).png'))\n",
    "fig_challenge_favorite_count_sagemaker.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, f'Challenge_favorite_count_increase_rate (SageMaker).png'))\n",
    "fig_challenge_answer_count_sagemaker.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, f'Challenge_answer_count_increase_rate (SageMaker).png'))\n",
    "fig_challenge_comment_count_sagemaker.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, f'Challenge_comment_count_increase_rate (SageMaker).png'))\n",
    "fig_challenge_participation_count_sagemaker.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, f'Challenge_participation_count_increase_rate (SageMaker).png'))\n",
    "fig_challenge_score_sagemaker.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, f'Challenge_score_increase_rate (SageMaker).png'))\n",
    "fig_challenge_link_count_sagemaker.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, f'Challenge_link_count (SageMaker).png'))\n",
    "fig_challenge_word_count_sagemaker.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, f'Challenge_word_count (SageMaker).png'))\n",
    "fig_challenge_unique_word_count_sagemaker.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, f'Challenge_unique_word_count (SageMaker).png'))\n",
    "fig_challenge_sentence_count_sagemaker.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, f'Challenge_sentence_count (SageMaker).png'))\n",
    "fig_challenge_information_entropy_sagemaker.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, f'Challenge_information_entropy (SageMaker).png'))\n",
    "fig_challenge_readability_sagemaker.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, f'Challenge_readability (SageMaker).png'))\n",
    "fig_challenge_topic_closed_count_sagemaker.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, f'Challenge_topic_closed_count_increase_rate (SageMaker).png'))\n",
    "fig_challenge_solved_rate_sagemaker.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, f'Challenge_solved_rate (SageMaker).png'))\n",
    "\n",
    "fig_challenge_topic_count_azureml.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, f'Challenge_topic_count_increase_rate (AzureML).png'))\n",
    "fig_challenge_view_count_azureml.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, f'Challenge_view_count_increase_rate (AzureML).png'))\n",
    "fig_challenge_favorite_count_azureml.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, f'Challenge_favorite_count_increase_rate (AzureML).png'))\n",
    "fig_challenge_answer_count_azureml.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, f'Challenge_answer_count_increase_rate (AzureML).png'))\n",
    "fig_challenge_comment_count_azureml.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, f'Challenge_comment_count_increase_rate (AzureML).png'))\n",
    "fig_challenge_participation_count_azureml.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, f'Challenge_participation_count_increase_rate (AzureML).png'))\n",
    "fig_challenge_score_azureml.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, f'Challenge_score_increase_rate (AzureML).png'))\n",
    "fig_challenge_link_count_azureml.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, f'Challenge_link_count (AzureML).png'))\n",
    "fig_challenge_word_count_azureml.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, f'Challenge_word_count (AzureML).png'))\n",
    "fig_challenge_unique_word_count_azureml.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, f'Challenge_unique_word_count (AzureML).png'))\n",
    "fig_challenge_sentence_count_azureml.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, f'Challenge_sentence_count (AzureML).png'))\n",
    "fig_challenge_information_entropy_azureml.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, f'Challenge_information_entropy (AzureML).png'))\n",
    "fig_challenge_readability_azureml.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, f'Challenge_readability (AzureML).png'))\n",
    "fig_challenge_topic_closed_count_azureml.write_image(os.path.join(  \n",
    "    path_challenge_azureml_sagemaker, f'Challenge_topic_closed_count_increase_rate (AzureML).png'))\n",
    "fig_challenge_solved_rate_azureml.write_image(os.path.join(\n",
    "    path_challenge_azureml_sagemaker, f'Challenge_solved_rate (AzureML).png'))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
