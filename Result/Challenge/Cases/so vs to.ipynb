{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shap\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.inspection import permutation_importance\n",
    "from scipy.stats import mannwhitneyu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The significance level is the probability of rejecting the null hypothesis when it is true.\n",
    "alpha = 0.05\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_topic_ensemble_inverse = [\n",
    "    # Code versioning refers to the practice of tracking changes to software code over time.\n",
    "    {'Code Management': ['Code Versioning']},\n",
    "    # These words are all related to data management and analysis. They refer to various tasks and techniques used to organize, manipulate, store, transfer, and analyze data.\n",
    "    {'Data Management': ['Artifact Management', 'Columnar Manipulation', 'CSV Manipulation', 'Data Labeling', 'Data Storage',\n",
    "                         'Data Transfer', 'Data Visualization', 'Database Connectivity', 'Dataset Versioning', 'Pandas Dataframe', 'Batch Processing']},\n",
    "    # All of these words are related to the development and management of machine learning models.\n",
    "    {'Model Management': ['Hyperparameter Tuning',\n",
    "                          'Model Evaluation', 'Model Exporting', 'Model Registry']},\n",
    "    # These words are all related to the management and optimization of data pipelines in software development.\n",
    "    {'Lifecycle Management': ['Pipeline Configuration',\n",
    "                              'Pipeline Configuration (Data)', 'Pipeline Configuration (Model)', 'Run Management', 'Kubernetes Orchestration']},\n",
    "    # All of these words relate to the configuration and management of infrastructure aspects of computer systems and networks. Specifically, they involve setting up and optimizing different components such as processing power, memory, network connections, and software to ensure that they work together efficiently and effectively.\n",
    "    {'Infrastructure Management': ['Apache Spark Configuration', 'Cluster Configuration', 'Docker Configuration', 'GPU Configuration', 'VPC Networking', 'Memory Management',\n",
    "                                   'Remote Configuration', 'Resource Quota Control', 'TensorFlow Configuration', 'Jupyter Notebook', 'Package Management', 'SDK Management', 'YAML Configuration']},\n",
    "    # All of these words are related to the deployment and management of machine learning models or web services.\n",
    "    {'Deployment Management': ['Endpoint Serving', 'Endpoint Deployment', 'Model Serving', 'Model Inference',\n",
    "                               'REST Payload', 'Web Service', 'Serverless Serving', 'API Invocation']},\n",
    "    # All of these words are related to monitoring and logging data in various systems.\n",
    "    {'Report Management': ['CloudWatch Monitoring',\n",
    "                           'Metrics Logging', 'TensorBoard Logging', 'Metrics Logging']},\n",
    "    # All of these words are related to controlling access to information or resources in a system.\n",
    "    {'Security Management': ['Account Management',\n",
    "                             'Bucket Access Control', 'Role-based Access Control']},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_challenge_so_to = 'Stack Overflow vs Tool-specific'\n",
    "path_general = os.path.join(os.getcwd(), '..', '..', 'General')\n",
    "path_solution = os.path.join(os.getcwd(), '..', '..', 'Solution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare metrics distribution of Stack Overflow vs tool-specific fora challenges across different topics\n",
    "\n",
    "df = pd.read_json(os.path.join(path_general, 'logscale.json'))\n",
    "\n",
    "df_so = df[df['Platform'] == 'Stack Overflow']\n",
    "df_to = df[df['Platform'] == 'Tool-specific']\n",
    "\n",
    "# Challenge topic count\n",
    "fig_challenge_count = go.Figure()\n",
    "fig_challenge_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=np.full(len(df_so), 'Challenge topic count (higher level)'),\n",
    "        y=df_so['Challenge_topic_macro'],\n",
    "        meanline_visible=True,\n",
    "        line_color='blue',\n",
    "        side='positive',\n",
    "        opacity=0.5,\n",
    "        name='Stack Overflow',\n",
    "    ))\n",
    "fig_challenge_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=np.full(len(df_to), 'Challenge topic count (higher level)'),\n",
    "        y=df_to['Challenge_topic_macro'],\n",
    "        meanline_visible=True,\n",
    "        line_color='orange',\n",
    "        side='negative',\n",
    "        opacity=0.5,\n",
    "        name='Tool-specific',\n",
    "    ))\n",
    "fig_challenge_count.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_count.write_image(os.path.join(\n",
    "    path_challenge_so_to, 'Challenge count.png'))\n",
    "\n",
    "# Challenge score\n",
    "fig_challenge_score = go.Figure()\n",
    "fig_challenge_score.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_so['Challenge_topic_macro'],\n",
    "        y=df_so['Challenge_score'],\n",
    "        meanline_visible=True,\n",
    "        line_color='blue',\n",
    "        side='positive',\n",
    "        opacity=0.5,\n",
    "        legendgroup='Stack Overflow',\n",
    "        scalegroup='Stack Overflow',\n",
    "        name='Stack Overflow',\n",
    "    ))\n",
    "fig_challenge_score.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_to['Challenge_topic_macro'],\n",
    "        y=df_to['Challenge_score'],\n",
    "        meanline_visible=True,\n",
    "        line_color='orange',\n",
    "        side='negative',\n",
    "        opacity=0.5,\n",
    "        legendgroup='Tool-specific',\n",
    "        scalegroup='Tool-specific',\n",
    "        name='Tool-specific',\n",
    "    ))\n",
    "fig_challenge_score.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_score.write_image(os.path.join(\n",
    "    path_challenge_so_to, 'Challenge score.png'))\n",
    "\n",
    "# Challenge favorite count\n",
    "fig_challenge_favorite_count = go.Figure()\n",
    "fig_challenge_favorite_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_so['Challenge_topic_macro'],\n",
    "        y=df_so['Challenge_favorite_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='blue',\n",
    "        side='positive',\n",
    "        opacity=0.5,\n",
    "        legendgroup='Stack Overflow',\n",
    "        scalegroup='Stack Overflow',\n",
    "        name='Stack Overflow',\n",
    "    ))\n",
    "fig_challenge_favorite_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_to['Challenge_topic_macro'],\n",
    "        y=df_to['Challenge_favorite_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='orange',\n",
    "        side='negative',\n",
    "        opacity=0.5,\n",
    "        legendgroup='Tool-specific',\n",
    "        scalegroup='Tool-specific',\n",
    "        name='Tool-specific',\n",
    "    ))\n",
    "fig_challenge_favorite_count.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_favorite_count.write_image(os.path.join(\n",
    "    path_challenge_so_to, 'Challenge favorite count.png'))\n",
    "\n",
    "# Challenge view count\n",
    "fig_challenge_view_count = go.Figure()\n",
    "fig_challenge_view_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_so['Challenge_topic_macro'],\n",
    "        y=df_so['Challenge_view_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='blue',\n",
    "        side='positive',\n",
    "        opacity=0.5,\n",
    "        legendgroup='Stack Overflow',\n",
    "        scalegroup='Stack Overflow',\n",
    "        name='Stack Overflow',\n",
    "    ))\n",
    "fig_challenge_view_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_to['Challenge_topic_macro'],\n",
    "        y=df_to['Challenge_view_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='orange',\n",
    "        side='negative',\n",
    "        opacity=0.5,\n",
    "        legendgroup='Tool-specific',\n",
    "        scalegroup='Tool-specific',\n",
    "        name='Tool-specific',\n",
    "    ))\n",
    "fig_challenge_view_count.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_view_count.write_image(os.path.join(\n",
    "    path_challenge_so_to, 'Challenge view count.png'))\n",
    "\n",
    "# Challenge link count\n",
    "fig_challenge_link_count = go.Figure()\n",
    "fig_challenge_link_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_so['Challenge_topic_macro'],\n",
    "        y=df_so['Challenge_link_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='blue',\n",
    "        side='positive',\n",
    "        opacity=0.5,\n",
    "        legendgroup='Stack Overflow',\n",
    "        scalegroup='Stack Overflow',\n",
    "        name='Stack Overflow',\n",
    "    ))\n",
    "fig_challenge_link_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_to['Challenge_topic_macro'],\n",
    "        y=df_to['Challenge_link_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='orange',\n",
    "        side='negative',\n",
    "        opacity=0.5,\n",
    "        legendgroup='Tool-specific',\n",
    "        scalegroup='Tool-specific',\n",
    "        name='Tool-specific',\n",
    "    ))\n",
    "fig_challenge_link_count.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_link_count.write_image(os.path.join(\n",
    "    path_challenge_so_to, 'Challenge link count.png'))\n",
    "\n",
    "# Challenge sentence count\n",
    "fig_challenge_sentence_count = go.Figure()\n",
    "fig_challenge_sentence_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_so['Challenge_topic_macro'],\n",
    "        y=df_so['Challenge_sentence_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='blue',\n",
    "        side='positive',\n",
    "        opacity=0.5,\n",
    "        legendgroup='Stack Overflow',\n",
    "        scalegroup='Stack Overflow',\n",
    "        name='Stack Overflow',\n",
    "    ))\n",
    "fig_challenge_sentence_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_to['Challenge_topic_macro'],\n",
    "        y=df_to['Challenge_sentence_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='orange',\n",
    "        side='negative',\n",
    "        opacity=0.5,\n",
    "        legendgroup='Tool-specific',\n",
    "        scalegroup='Tool-specific',\n",
    "        name='Tool-specific',\n",
    "    ))\n",
    "fig_challenge_sentence_count.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_sentence_count.write_image(os.path.join(\n",
    "    path_challenge_so_to, 'Challenge sentence count.png'))\n",
    "\n",
    "# Challenge word count\n",
    "fig_challenge_word_count = go.Figure()\n",
    "fig_challenge_word_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_so['Challenge_topic_macro'],\n",
    "        y=df_so['Challenge_word_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='blue',\n",
    "        side='positive',\n",
    "        opacity=0.5,\n",
    "        legendgroup='Stack Overflow',\n",
    "        scalegroup='Stack Overflow',\n",
    "        name='Stack Overflow',\n",
    "    ))\n",
    "fig_challenge_word_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_to['Challenge_topic_macro'],\n",
    "        y=df_to['Challenge_word_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='orange',\n",
    "        side='negative',\n",
    "        opacity=0.5,\n",
    "        legendgroup='Tool-specific',\n",
    "        scalegroup='Tool-specific',\n",
    "        name='Tool-specific',\n",
    "    ))\n",
    "fig_challenge_word_count.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_word_count.write_image(os.path.join(\n",
    "    path_challenge_so_to, 'Challenge word count.png'))\n",
    "\n",
    "# Challenge unique word count\n",
    "fig_challenge_unique_word_count = go.Figure()\n",
    "fig_challenge_unique_word_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_so['Challenge_topic_macro'],\n",
    "        y=df_so['Challenge_unique_word_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='blue',\n",
    "        side='positive',\n",
    "        opacity=0.5,\n",
    "        legendgroup='Stack Overflow',\n",
    "        scalegroup='Stack Overflow',\n",
    "        name='Stack Overflow',\n",
    "    ))\n",
    "fig_challenge_unique_word_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_to['Challenge_topic_macro'],\n",
    "        y=df_to['Challenge_unique_word_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='orange',\n",
    "        side='negative',\n",
    "        opacity=0.5,\n",
    "        legendgroup='Tool-specific',\n",
    "        scalegroup='Tool-specific',\n",
    "        name='Tool-specific',\n",
    "    ))\n",
    "fig_challenge_unique_word_count.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_unique_word_count.write_image(os.path.join(\n",
    "    path_challenge_so_to, 'Challenge unique word count.png'))\n",
    "\n",
    "# Challenge information entropy\n",
    "fig_challenge_information_entropy = go.Figure()\n",
    "fig_challenge_information_entropy.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_so['Challenge_topic_macro'],\n",
    "        y=df_so['Challenge_information_entropy'],\n",
    "        meanline_visible=True,\n",
    "        line_color='blue',\n",
    "        side='positive',\n",
    "        opacity=0.5,\n",
    "        legendgroup='Stack Overflow',\n",
    "        scalegroup='Stack Overflow',\n",
    "        name='Stack Overflow',\n",
    "    ))\n",
    "fig_challenge_information_entropy.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_to['Challenge_topic_macro'],\n",
    "        y=df_to['Challenge_information_entropy'],\n",
    "        meanline_visible=True,\n",
    "        line_color='orange',\n",
    "        side='negative',\n",
    "        opacity=0.5,\n",
    "        legendgroup='Tool-specific',\n",
    "        scalegroup='Tool-specific',\n",
    "        name='Tool-specific',\n",
    "    ))\n",
    "fig_challenge_information_entropy.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_information_entropy.write_image(os.path.join(\n",
    "    path_challenge_so_to, 'Challenge information entropy.png'))\n",
    "\n",
    "# Challenge readability\n",
    "fig_challenge_readability = go.Figure()\n",
    "fig_challenge_readability.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_so['Challenge_topic_macro'],\n",
    "        y=df_so['Challenge_readability'],\n",
    "        meanline_visible=True,\n",
    "        line_color='blue',\n",
    "        side='positive',\n",
    "        opacity=0.5,\n",
    "        legendgroup='Stack Overflow',\n",
    "        scalegroup='Stack Overflow',\n",
    "        name='Stack Overflow',\n",
    "    ))\n",
    "fig_challenge_readability.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_to['Challenge_topic_macro'],\n",
    "        y=df_to['Challenge_readability'],\n",
    "        meanline_visible=True,\n",
    "        line_color='orange',\n",
    "        side='negative',\n",
    "        opacity=0.5,\n",
    "        legendgroup='Tool-specific',\n",
    "        scalegroup='Tool-specific',\n",
    "        name='Tool-specific',\n",
    "    ))\n",
    "fig_challenge_readability.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_readability.write_image(os.path.join(\n",
    "    path_challenge_so_to, 'Challenge readability.png'))\n",
    "\n",
    "# Challenge answer count\n",
    "fig_challenge_answer_count = go.Figure()\n",
    "fig_challenge_answer_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_so['Challenge_topic_macro'],\n",
    "        y=df_so['Challenge_answer_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='blue',\n",
    "        side='positive',\n",
    "        opacity=0.5,\n",
    "        legendgroup='Stack Overflow',\n",
    "        scalegroup='Stack Overflow',\n",
    "        name='Stack Overflow',\n",
    "    ))\n",
    "fig_challenge_answer_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_to['Challenge_topic_macro'],\n",
    "        y=df_to['Challenge_answer_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='orange',\n",
    "        side='negative',\n",
    "        opacity=0.5,\n",
    "        legendgroup='Tool-specific',\n",
    "        scalegroup='Tool-specific',\n",
    "        name='Tool-specific',\n",
    "    ))\n",
    "fig_challenge_answer_count.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_answer_count.write_image(os.path.join(\n",
    "    path_challenge_so_to, 'Challenge answer count.png'))\n",
    "\n",
    "# Challenge comment count\n",
    "fig_challenge_comment_count = go.Figure()\n",
    "fig_challenge_comment_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_so['Challenge_topic_macro'],\n",
    "        y=df_so['Challenge_comment_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='blue',\n",
    "        side='positive',\n",
    "        opacity=0.5,\n",
    "        legendgroup='Stack Overflow',\n",
    "        scalegroup='Stack Overflow',\n",
    "        name='Stack Overflow',\n",
    "    ))\n",
    "fig_challenge_comment_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_to['Challenge_topic_macro'],\n",
    "        y=df_to['Challenge_comment_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='orange',\n",
    "        side='negative',\n",
    "        opacity=0.5,\n",
    "        legendgroup='Tool-specific',\n",
    "        scalegroup='Tool-specific',\n",
    "        name='Tool-specific',\n",
    "    ))\n",
    "fig_challenge_comment_count.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_comment_count.write_image(os.path.join(\n",
    "    path_challenge_so_to, 'Challenge comment count.png'))\n",
    "\n",
    "# Challenge participation count\n",
    "fig_challenge_participation_count = go.Figure()\n",
    "fig_challenge_participation_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_so['Challenge_topic_macro'],\n",
    "        y=df_so['Challenge_participation_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='blue',\n",
    "        side='positive',\n",
    "        opacity=0.5,\n",
    "        legendgroup='Stack Overflow',\n",
    "        scalegroup='Stack Overflow',\n",
    "        name='Stack Overflow',\n",
    "    ))\n",
    "fig_challenge_participation_count.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_to['Challenge_topic_macro'],\n",
    "        y=df_to['Challenge_participation_count'],\n",
    "        meanline_visible=True,\n",
    "        line_color='orange',\n",
    "        side='negative',\n",
    "        opacity=0.5,\n",
    "        legendgroup='Tool-specific',\n",
    "        scalegroup='Tool-specific',\n",
    "        name='Tool-specific',\n",
    "    ))\n",
    "fig_challenge_participation_count.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_participation_count.write_image(os.path.join(\n",
    "    path_challenge_so_to, 'Challenge participation count.png'))\n",
    "\n",
    "# Challenge solved time\n",
    "fig_challenge_solved_time = go.Figure()\n",
    "fig_challenge_solved_time.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_so['Challenge_topic_macro'],\n",
    "        y=df_so['Challenge_solved_time'],\n",
    "        meanline_visible=True,\n",
    "        line_color='blue',\n",
    "        side='positive',\n",
    "        opacity=0.5,\n",
    "        legendgroup='Stack Overflow',\n",
    "        scalegroup='Stack Overflow',\n",
    "        name='Stack Overflow',\n",
    "    ))\n",
    "fig_challenge_solved_time.add_trace(\n",
    "    go.Violin(\n",
    "        x=df_to['Challenge_topic_macro'],\n",
    "        y=df_to['Challenge_solved_time'],\n",
    "        meanline_visible=True,\n",
    "        line_color='orange',\n",
    "        side='negative',\n",
    "        opacity=0.5,\n",
    "        legendgroup='Tool-specific',\n",
    "        scalegroup='Tool-specific',\n",
    "        name='Tool-specific',\n",
    "    ))\n",
    "fig_challenge_solved_time.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_solved_time.write_image(os.path.join(\n",
    "    path_challenge_so_to, 'Challenge solved time.png'))\n",
    "\n",
    "fig_challenge_mean_solved_time_evolution_so = go.Figure()\n",
    "fig_challenge_median_solved_time_evolution_so = go.Figure()\n",
    "\n",
    "fig_challenge_mean_solved_time_evolution_to = go.Figure()\n",
    "fig_challenge_median_solved_time_evolution_to = go.Figure()\n",
    "\n",
    "for name, group in df.groupby('Challenge_topic_macro'):\n",
    "    so = group[group['Platform'] == 'Stack Overflow']\n",
    "    to = group[group['Platform'] == 'Tool-specific']\n",
    "\n",
    "    # Challenge score\n",
    "    challenge_score_so = so[so['Challenge_score'].notna(\n",
    "    )]['Challenge_score']\n",
    "    challenge_score_to = to[to['Challenge_score'].notna(\n",
    "    )]['Challenge_score']\n",
    "    if len(challenge_score_so) * len(challenge_score_to) > 0:\n",
    "        _, p = mannwhitneyu(challenge_score_so, challenge_score_to)\n",
    "        if p < alpha:\n",
    "            print(\n",
    "                f'p = {p:.2f}, indicating different distribution of Stack Overflow vs tool-specific fora challenge regarding higher level topic {name} in challenge score')\n",
    "\n",
    "    # Challenge favorite count\n",
    "    challenge_favorite_count_so = so[so['Challenge_favorite_count'].notna(\n",
    "    )]['Challenge_favorite_count']\n",
    "    challenge_favorite_count_to = to[to['Challenge_favorite_count'].notna(\n",
    "    )]['Challenge_favorite_count']\n",
    "    if len(challenge_favorite_count_so) * len(challenge_favorite_count_to) > 0:\n",
    "        _, p = mannwhitneyu(challenge_favorite_count_so,\n",
    "                            challenge_favorite_count_to)\n",
    "        if p < alpha:\n",
    "            print(\n",
    "                f'p = {p:.2f}, indicating different distribution of Stack Overflow vs tool-specific fora challenge regarding higher level topic {name} in challenge favorite count')\n",
    "\n",
    "    # Challenge link count\n",
    "    challenge_link_count_so = so[so['Challenge_link_count'].notna(\n",
    "    )]['Challenge_link_count']\n",
    "    challenge_link_count_to = to[to['Challenge_link_count'].notna(\n",
    "    )]['Challenge_link_count']\n",
    "    if len(challenge_link_count_so) * len(challenge_link_count_to) > 0:\n",
    "        _, p = mannwhitneyu(challenge_link_count_so, challenge_link_count_to)\n",
    "        if p < alpha:\n",
    "            print(\n",
    "                f'p = {p:.2f}, indicating different distribution of Stack Overflow vs tool-specific fora challenge regarding higher level topic {name} in challenge link count')\n",
    "\n",
    "    # Challenge sentence count\n",
    "    challenge_sentence_count_so = so[so['Challenge_sentence_count'].notna(\n",
    "    )]['Challenge_sentence_count']\n",
    "    challenge_sentence_count_to = to[to['Challenge_sentence_count'].notna(\n",
    "    )]['Challenge_sentence_count']\n",
    "    if len(challenge_sentence_count_so) * len(challenge_sentence_count_to) > 0:\n",
    "        _, p = mannwhitneyu(challenge_sentence_count_so,\n",
    "                            challenge_sentence_count_to)\n",
    "        if p < alpha:\n",
    "            print(\n",
    "                f'p = {p:.2f}, indicating different distribution of Stack Overflow vs tool-specific fora challenge regarding higher level topic {name} in challenge sentence count')\n",
    "\n",
    "    # Challenge word count\n",
    "    challenge_word_count_so = so[so['Challenge_word_count'].notna(\n",
    "    )]['Challenge_word_count']\n",
    "    challenge_word_count_to = to[to['Challenge_word_count'].notna(\n",
    "    )]['Challenge_word_count']\n",
    "    if len(challenge_word_count_so) * len(challenge_word_count_to) > 0:\n",
    "        _, p = mannwhitneyu(challenge_word_count_so, challenge_word_count_to)\n",
    "        if p < alpha:\n",
    "            print(\n",
    "                f'p = {p:.2f}, indicating different distribution of Stack Overflow vs tool-specific fora challenge regarding higher level topic {name} in challenge word count')\n",
    "\n",
    "    # Challenge unique word count\n",
    "    challenge_unique_word_count_so = so[so['Challenge_unique_word_count'].notna(\n",
    "    )]['Challenge_unique_word_count']\n",
    "    challenge_unique_word_count_to = to[to['Challenge_unique_word_count'].notna(\n",
    "    )]['Challenge_unique_word_count']\n",
    "    if len(challenge_unique_word_count_so) * len(challenge_unique_word_count_to) > 0:\n",
    "        _, p = mannwhitneyu(challenge_unique_word_count_so,\n",
    "                            challenge_unique_word_count_to)\n",
    "        if p < alpha:\n",
    "            print(\n",
    "                f'p = {p:.2f}, indicating different distribution of Stack Overflow vs tool-specific fora challenge regarding higher level topic {name} in challenge unique word count')\n",
    "\n",
    "    # Challenge information entropy\n",
    "    challenge_information_entropy_so = so[so['Challenge_information_entropy'].notna(\n",
    "    )]['Challenge_information_entropy']\n",
    "    challenge_information_entropy_to = to[to['Challenge_information_entropy'].notna(\n",
    "    )]['Challenge_information_entropy']\n",
    "    if len(challenge_information_entropy_so) * len(challenge_information_entropy_to) > 0:\n",
    "        _, p = mannwhitneyu(challenge_information_entropy_so,\n",
    "                            challenge_information_entropy_to)\n",
    "        if p < alpha:\n",
    "            print(\n",
    "                f'p = {p:.2f}, indicating different distribution of Stack Overflow vs tool-specific fora challenge regarding higher level topic {name} in challenge information entropy')\n",
    "\n",
    "    # Challenge readability\n",
    "    challenge_readability_so = so[so['Challenge_readability'].notna(\n",
    "    )]['Challenge_readability']\n",
    "    challenge_readability_to = to[to['Challenge_readability'].notna(\n",
    "    )]['Challenge_readability']\n",
    "    if len(challenge_readability_so) * len(challenge_readability_to) > 0:\n",
    "        _, p = mannwhitneyu(challenge_readability_so,\n",
    "                            challenge_readability_to)\n",
    "        if p < alpha:\n",
    "            print(\n",
    "                f'p = {p:.2f}, indicating different distribution of Stack Overflow vs tool-specific fora challenge regarding higher level topic {name} in challenge readability')\n",
    "\n",
    "    # Challenge view count\n",
    "    challenge_view_count_so = so[so['Challenge_view_count'].notna(\n",
    "    )]['Challenge_view_count']\n",
    "    challenge_view_count_to = to[to['Challenge_view_count'].notna(\n",
    "    )]['Challenge_view_count']\n",
    "    if len(challenge_view_count_so) * len(challenge_view_count_to) > 0:\n",
    "        _, p = mannwhitneyu(challenge_view_count_so,\n",
    "                            challenge_view_count_to)\n",
    "        if p < alpha:\n",
    "            print(\n",
    "                f'p = {p:.2f}, indicating different distribution of Stack Overflow vs tool-specific fora challenge regarding higher level topic {name} in challenge answer count')\n",
    "\n",
    "    # Challenge answer count\n",
    "    challenge_answer_count_so = so['Challenge_answer_count']\n",
    "    challenge_answer_count_to = to['Challenge_answer_count']\n",
    "    if len(challenge_answer_count_so) * len(challenge_answer_count_to) > 0:\n",
    "        _, p = mannwhitneyu(challenge_answer_count_so,\n",
    "                            challenge_answer_count_to)\n",
    "        if p < alpha:\n",
    "            print(\n",
    "                f'p = {p:.2f}, indicating different distribution of Stack Overflow vs tool-specific fora challenge regarding higher level topic {name} in challenge answer count')\n",
    "\n",
    "    # Challenge comment count\n",
    "    challenge_comment_count_so = so['Challenge_comment_count']\n",
    "    challenge_comment_count_to = to['Challenge_comment_count']\n",
    "    if len(challenge_comment_count_so) * len(challenge_comment_count_to) > 0:\n",
    "        _, p = mannwhitneyu(challenge_comment_count_so,\n",
    "                            challenge_comment_count_to)\n",
    "        if p < alpha:\n",
    "            print(\n",
    "                f'p = {p:.2f}, indicating different distribution of Stack Overflow vs tool-specific fora challenge regarding higher level topic {name} in challenge comment count')\n",
    "\n",
    "    # Challenge participation count\n",
    "    challenge_participation_count_so = so['Challenge_participation_count']\n",
    "    challenge_participation_count_to = to['Challenge_participation_count']\n",
    "    if len(challenge_comment_count_so) * len(challenge_comment_count_to) > 0:\n",
    "        _, p = mannwhitneyu(challenge_comment_count_so,\n",
    "                            challenge_comment_count_to)\n",
    "        if p < alpha:\n",
    "            print(\n",
    "                f'p = {p:.2f}, indicating different distribution of Stack Overflow vs tool-specific fora challenge regarding higher level topic {name} in challenge participation count')\n",
    "\n",
    "    # Challenge mean solved time evolution\n",
    "    group_so = so.groupby(pd.Grouper(key='Challenge_created_time', freq='Y'))[\n",
    "        'Challenge_solved_time'].mean().reset_index()\n",
    "    x_so = pd.to_datetime(group_so['Challenge_created_time']).values\n",
    "    y_so = group_so['Challenge_solved_time'].values\n",
    "    fig_challenge_mean_solved_time_evolution_so.add_trace(\n",
    "        go.Scatter(x=x_so, y=y_so, mode='lines', name=name))\n",
    "\n",
    "    group_to = to.groupby(pd.Grouper(key='Challenge_created_time', freq='Y'))[\n",
    "        'Challenge_solved_time'].mean().reset_index()\n",
    "    x_to = pd.to_datetime(group_to['Challenge_created_time']).values\n",
    "    y_to = group_to['Challenge_solved_time'].values\n",
    "    fig_challenge_mean_solved_time_evolution_to.add_trace(\n",
    "        go.Scatter(x=x_to, y=y_to, mode='lines', name=name))\n",
    "\n",
    "    # Challenge median solved time evolution\n",
    "    group_so = so.groupby(pd.Grouper(key='Challenge_created_time', freq='Y'))[\n",
    "        'Challenge_solved_time'].median().reset_index()\n",
    "    x_so = pd.to_datetime(group_so['Challenge_created_time']).values\n",
    "    y_so = group_so['Challenge_solved_time'].values\n",
    "    fig_challenge_median_solved_time_evolution_so.add_trace(\n",
    "        go.Scatter(x=x_so, y=y_so, mode='lines', name=name))\n",
    "\n",
    "    group_to = to.groupby(pd.Grouper(key='Challenge_created_time', freq='Y'))[\n",
    "        'Challenge_solved_time'].median().reset_index()\n",
    "    x_to = pd.to_datetime(group_to['Challenge_created_time']).values\n",
    "    y_to = group_to['Challenge_solved_time'].values\n",
    "    fig_challenge_median_solved_time_evolution_to.add_trace(\n",
    "        go.Scatter(x=x_to, y=y_to, mode='lines', name=name))\n",
    "\n",
    "fig_challenge_mean_solved_time_evolution_so.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_median_solved_time_evolution_so.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_mean_solved_time_evolution_so.write_image(os.path.join(\n",
    "    path_challenge_so_to, 'Challenge mean solved time evolution (Stack Overflow).png'))\n",
    "fig_challenge_median_solved_time_evolution_so.write_image(os.path.join(\n",
    "    path_challenge_so_to, 'Challenge median solved time evolution (Stack Overflow).png'))\n",
    "\n",
    "fig_challenge_mean_solved_time_evolution_to.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_median_solved_time_evolution_to.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    font=dict(size=20),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "fig_challenge_mean_solved_time_evolution_to.write_image(os.path.join(\n",
    "    path_challenge_so_to, 'Challenge mean solved time evolution (Tool-specific).png'))\n",
    "fig_challenge_median_solved_time_evolution_to.write_image(os.path.join(\n",
    "    path_challenge_so_to, 'Challenge median solved time evolution (Tool-specific).png'))\n",
    "\n",
    "# Challenge mean solved time\n",
    "challenge_mean_solved_time_so = df_so[['Challenge_topic_macro', 'Challenge_solved_time']].groupby(\n",
    "    'Challenge_topic_macro').mean()['Challenge_solved_time']\n",
    "challenge_mean_solved_time_to = df_to[['Challenge_topic_macro', 'Challenge_solved_time']].groupby(\n",
    "    'Challenge_topic_macro').mean()['Challenge_solved_time']\n",
    "_, p = mannwhitneyu(challenge_mean_solved_time_so,\n",
    "                    challenge_mean_solved_time_to)\n",
    "if p < alpha:\n",
    "    print(f'p = {p:.2f}, indicating different distribution of Stack Overflow vs tool-specific fora in higher level mean challenge solved time')\n",
    "\n",
    "# Challenge median solved time\n",
    "challenge_median_solved_time_so = df_so[['Challenge_topic_macro', 'Challenge_solved_time']].groupby(\n",
    "    'Challenge_topic_macro').median()['Challenge_solved_time']\n",
    "challenge_median_solved_time_to = df_to[['Challenge_topic_macro', 'Challenge_solved_time']].groupby(\n",
    "    'Challenge_topic_macro').median()['Challenge_solved_time']\n",
    "_, p = mannwhitneyu(challenge_median_solved_time_so,\n",
    "                    challenge_median_solved_time_to)\n",
    "if p < alpha:\n",
    "    print(f'p = {p:.2f}, indicating different distribution of Stack Overflow vs tool-specific fora in higher level median challenge solved time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the explanability of the challenge solved rate classification model between Stack Overflow vs tool-specific fora\n",
    "\n",
    "df = pd.read_json(os.path.join(path_general, 'filtered.json'))\n",
    "\n",
    "# Stack Overflow\n",
    "\n",
    "df_so = df[df['Platform'] == 'Stack Overflow']\n",
    "df_so = df_so[df_so.columns.drop(\n",
    "    list(df_so.filter(regex='Platform|Tool|Solution|topic|solved_time|edit_time')))]\n",
    "X = df_so.drop(['Challenge_link', 'Challenge_closed_time',\n",
    "               'Challenge_created_time'], axis=1)\n",
    "y = df_so['Challenge_closed_time'].isna()\n",
    "\n",
    "classifier = XGBClassifier(objective='binary:logistic', eval_metric='auc', tree_method='gpu_hist',\n",
    "                           random_state=random_state, max_depth=5, n_estimators=1000, eta=0.1483)\n",
    "classifier.fit(X, y)\n",
    "\n",
    "sorted_idx = classifier.feature_importances_.argsort()\n",
    "fig, _ = plt.subplots()\n",
    "plt.barh(X.columns[sorted_idx][:10],\n",
    "         classifier.feature_importances_[sorted_idx][:10])\n",
    "plt.xlabel(\"Xgboost Feature Importance\")\n",
    "fig.savefig(os.path.join(path_challenge_so_to,\n",
    "            f'Challenge_solved_rate xgboost_feature_importance (Stack Overflow).png'), bbox_inches='tight')\n",
    "\n",
    "explainer = shap.TreeExplainer(classifier)\n",
    "shap_values = explainer.shap_values(X)\n",
    "shap.summary_plot(shap_values, X, show=False)\n",
    "fig.savefig(os.path.join(path_challenge_so_to,\n",
    "            f'Challenge_solved_rate SHAP_based_feature_importance (Stack Overflow).png'), bbox_inches='tight')\n",
    "\n",
    "perm_importance = permutation_importance(\n",
    "    classifier, X, y, random_state=random_state)\n",
    "sorted_idx = perm_importance.importances_mean.argsort()\n",
    "fig, _ = plt.subplots()\n",
    "plt.barh(X.columns[sorted_idx],\n",
    "         perm_importance.importances_mean[sorted_idx])\n",
    "plt.xlabel(\"Permutation Importance\")\n",
    "fig.savefig(os.path.join(path_challenge_so_to,\n",
    "            f'Challenge_solved_rate permutation_based_feature_importance (Stack Overflow).png'), bbox_inches='tight')\n",
    "\n",
    "# Tool-specific fora\n",
    "\n",
    "df_to = df[df['Platform'] == 'Tool-specific']\n",
    "df_to = df_to[df_to.columns.drop(\n",
    "    list(df_to.filter(regex='Platform|Tool|Solution|topic|solved_time|edit_time')))]\n",
    "X = df_to.drop(['Challenge_link', 'Challenge_closed_time',\n",
    "               'Challenge_created_time'], axis=1)\n",
    "y = df_to['Challenge_closed_time'].isna()\n",
    "\n",
    "classifier = XGBClassifier(objective='binary:logistic', eval_metric='auc', tree_method='gpu_hist',\n",
    "                           random_state=random_state, max_depth=5, n_estimators=1000, eta=0.1483)\n",
    "classifier.fit(X, y)\n",
    "\n",
    "sorted_idx = classifier.feature_importances_.argsort()\n",
    "fig, _ = plt.subplots()\n",
    "plt.barh(X.columns[sorted_idx][:10],\n",
    "         classifier.feature_importances_[sorted_idx][:10])\n",
    "plt.xlabel(\"Xgboost Feature Importance\")\n",
    "fig.savefig(os.path.join(path_challenge_so_to,\n",
    "            f'Challenge_solved_rate xgboost_feature_importance (Tool-specific).png'), bbox_inches='tight')\n",
    "\n",
    "explainer = shap.TreeExplainer(classifier)\n",
    "shap_values = explainer.shap_values(X)\n",
    "shap.summary_plot(shap_values, X, show=False)\n",
    "fig.savefig(os.path.join(path_challenge_so_to,\n",
    "            f'Challenge_solved_rate SHAP_based_feature_importance (Tool-specific).png'), bbox_inches='tight')\n",
    "\n",
    "perm_importance = permutation_importance(\n",
    "    classifier, X, y, random_state=random_state)\n",
    "sorted_idx = perm_importance.importances_mean.argsort()\n",
    "fig, _ = plt.subplots()\n",
    "plt.barh(X.columns[sorted_idx],\n",
    "         perm_importance.importances_mean[sorted_idx])\n",
    "plt.xlabel(\"Permutation Importance\")\n",
    "fig.savefig(os.path.join(path_challenge_so_to,\n",
    "            f'Challenge_solved_rate permutation_based_feature_importance (Tool-specific).png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the explanability of the challenge solved time regression model between Stack Overflow vs tool-specific fora\n",
    "\n",
    "df = pd.read_json(os.path.join(path_solution, 'solved.json'))\n",
    "df = df[df['Challenge_solved_time'].notna()]\n",
    "df = df.drop(['Challenge_link', 'Challenge_closed_time',\n",
    "             'Challenge_created_time'], axis=1)\n",
    "\n",
    "# Stack Overflow\n",
    "\n",
    "df_so = df[df['Platform'] == 'Stack Overflow']\n",
    "X = df_so[df_so.columns.drop(\n",
    "    list(df_so.filter(regex='Platform|Tool|topic|solved_time|edit_time')))]\n",
    "y = df_so['Challenge_solved_time']\n",
    "\n",
    "regressor = XGBRegressor(objective='reg:squaredlogerror', tree_method='gpu_hist',\n",
    "                         random_state=random_state, max_depth=5, n_estimators=1000, eta=0.0206)\n",
    "regressor.fit(X, y)\n",
    "\n",
    "sorted_idx = regressor.feature_importances_.argsort()\n",
    "fig, _ = plt.subplots()\n",
    "plt.barh(X.columns[sorted_idx],\n",
    "         regressor.feature_importances_[sorted_idx])\n",
    "plt.xlabel(\"Xgboost Feature Importance\")\n",
    "fig.savefig(os.path.join(path_challenge_so_to,\n",
    "            f'Challenge_solved_time xgboost_feature_importance (Stack Overflow).png'), bbox_inches='tight')\n",
    "\n",
    "explainer = shap.TreeExplainer(regressor)\n",
    "shap_values = explainer.shap_values(X)\n",
    "shap.summary_plot(shap_values, X, show=False)\n",
    "fig.savefig(os.path.join(path_challenge_so_to,\n",
    "            f'Challenge_solved_time SHAP_based_feature_importance (Stack Overflow).png'), bbox_inches='tight')\n",
    "\n",
    "perm_importance = permutation_importance(\n",
    "    regressor, X, y, random_state=random_state)\n",
    "sorted_idx = perm_importance.importances_mean.argsort()\n",
    "fig, _ = plt.subplots()\n",
    "plt.barh(X.columns[sorted_idx],\n",
    "         perm_importance.importances_mean[sorted_idx])\n",
    "plt.xlabel(\"Permutation Importance\")\n",
    "fig.savefig(os.path.join(path_challenge_so_to,\n",
    "            f'Challenge_solved_time permutation_based_feature_importance (Stack Overflow).png'), bbox_inches='tight')\n",
    "\n",
    "# tool-specific fora\n",
    "\n",
    "df_to = df[df['Platform'] == 'Tool-specific']\n",
    "X = df_to[df_to.columns.drop(list(df_to.filter(\n",
    "    regex='Platform|Tool|topic|solved_time|edit_time|favorite_count|view_count')))]\n",
    "y = df_to['Challenge_solved_time']\n",
    "\n",
    "regressor = XGBRegressor(objective='reg:squaredlogerror', tree_method='gpu_hist',\n",
    "                         random_state=random_state, max_depth=5, n_estimators=1000, eta=0.0206)\n",
    "regressor.fit(X, y)\n",
    "\n",
    "sorted_idx = regressor.feature_importances_.argsort()\n",
    "fig, _ = plt.subplots()\n",
    "plt.barh(X.columns[sorted_idx],\n",
    "         regressor.feature_importances_[sorted_idx])\n",
    "plt.xlabel(\"Xgboost Feature Importance\")\n",
    "fig.savefig(os.path.join(path_challenge_so_to,\n",
    "            f'Challenge_solved_time xgboost_feature_importance (Tool-specific).png'), bbox_inches='tight')\n",
    "\n",
    "explainer = shap.TreeExplainer(regressor)\n",
    "shap_values = explainer.shap_values(X)\n",
    "shap.summary_plot(shap_values, X, show=False)\n",
    "fig.savefig(os.path.join(path_challenge_so_to,\n",
    "            f'Challenge_solved_time SHAP_based_feature_importance (Tool-specific).png'), bbox_inches='tight')\n",
    "\n",
    "perm_importance = permutation_importance(\n",
    "    regressor, X, y, random_state=random_state)\n",
    "sorted_idx = perm_importance.importances_mean.argsort()\n",
    "fig, _ = plt.subplots()\n",
    "plt.barh(X.columns[sorted_idx],\n",
    "         perm_importance.importances_mean[sorted_idx])\n",
    "plt.xlabel(\"Permutation Importance\")\n",
    "fig.savefig(os.path.join(path_challenge_so_to,\n",
    "            f'Challenge_solved_time permutation_based_feature_importance (Tool-specific).png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the explanability of the challenge adjusted solved time regression model between Stack Overflow vs tool-specific fora\n",
    "\n",
    "df = pd.read_json(os.path.join(path_solution, 'solved.json'))\n",
    "df = df[df['Challenge_adjusted_solved_time'].notna()]\n",
    "df = df.drop(['Challenge_link', 'Challenge_closed_time',\n",
    "             'Challenge_created_time'], axis=1)\n",
    "\n",
    "# Stack Overflow\n",
    "\n",
    "df_so = df[df['Platform'] == 'Stack Overflow']\n",
    "X = df_so[df_so.columns.drop(\n",
    "    list(df_so.filter(regex='Platform|Tool|topic|solved_time|edit_time')))]\n",
    "y = df_so['Challenge_adjusted_solved_time']\n",
    "\n",
    "regressor = XGBRegressor(objective='reg:squaredlogerror', tree_method='gpu_hist',\n",
    "                         random_state=random_state, max_depth=5, n_estimators=1000, eta=0.03353)\n",
    "regressor.fit(X, y)\n",
    "\n",
    "sorted_idx = regressor.feature_importances_.argsort()\n",
    "fig, _ = plt.subplots()\n",
    "plt.barh(X.columns[sorted_idx],\n",
    "         regressor.feature_importances_[sorted_idx])\n",
    "plt.xlabel(\"Xgboost Feature Importance\")\n",
    "fig.savefig(os.path.join(path_challenge_so_to,\n",
    "            f'Challenge_adjusted_solved_time xgboost_feature_importance (Stack Overflow).png'), bbox_inches='tight')\n",
    "\n",
    "explainer = shap.TreeExplainer(regressor)\n",
    "shap_values = explainer.shap_values(X)\n",
    "shap.summary_plot(shap_values, X, show=False)\n",
    "fig.savefig(os.path.join(path_challenge_so_to,\n",
    "            f'Challenge_adjusted_solved_time SHAP_based_feature_importance (Stack Overflow).png'), bbox_inches='tight')\n",
    "\n",
    "perm_importance = permutation_importance(\n",
    "    regressor, X, y, random_state=random_state)\n",
    "sorted_idx = perm_importance.importances_mean.argsort()\n",
    "fig, _ = plt.subplots()\n",
    "plt.barh(X.columns[sorted_idx],\n",
    "         perm_importance.importances_mean[sorted_idx])\n",
    "plt.xlabel(\"Permutation Importance\")\n",
    "fig.savefig(os.path.join(path_challenge_so_to,\n",
    "            f'Challenge_adjusted_solved_time permutation_based_feature_importance (Stack Overflow).png'), bbox_inches='tight')\n",
    "\n",
    "# tool-specific fora\n",
    "\n",
    "df_to = df[df['Platform'] == 'Tool-specific']\n",
    "X = df_to[df_to.columns.drop(list(df_to.filter(\n",
    "    regex='Platform|Tool|topic|solved_time|edit_time|favorite_count|view_count')))]\n",
    "y = df_to['Challenge_adjusted_solved_time']\n",
    "\n",
    "regressor = XGBRegressor(objective='reg:squaredlogerror', tree_method='gpu_hist',\n",
    "                         random_state=random_state, max_depth=5, n_estimators=1000, eta=0.03353)\n",
    "regressor.fit(X, y)\n",
    "\n",
    "sorted_idx = regressor.feature_importances_.argsort()\n",
    "fig, _ = plt.subplots()\n",
    "plt.barh(X.columns[sorted_idx],\n",
    "         regressor.feature_importances_[sorted_idx])\n",
    "plt.xlabel(\"Xgboost Feature Importance\")\n",
    "fig.savefig(os.path.join(path_challenge_so_to,\n",
    "            f'Challenge_adjusted_solved_time xgboost_feature_importance (Tool-specific).png'), bbox_inches='tight')\n",
    "\n",
    "explainer = shap.TreeExplainer(regressor)\n",
    "shap_values = explainer.shap_values(X)\n",
    "shap.summary_plot(shap_values, X, show=False)\n",
    "fig.savefig(os.path.join(path_challenge_so_to,\n",
    "            f'Challenge_adjusted_solved_time SHAP_based_feature_importance (Tool-specific).png'), bbox_inches='tight')\n",
    "\n",
    "perm_importance = permutation_importance(\n",
    "    regressor, X, y, random_state=random_state)\n",
    "sorted_idx = perm_importance.importances_mean.argsort()\n",
    "fig, _ = plt.subplots()\n",
    "plt.barh(X.columns[sorted_idx],\n",
    "         perm_importance.importances_mean[sorted_idx])\n",
    "plt.xlabel(\"Permutation Importance\")\n",
    "fig.savefig(os.path.join(path_challenge_so_to,\n",
    "            f'Challenge_adjusted_solved_time permutation_based_feature_importance (Tool-specific).png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare metrics evolution of Stack Overflow vs tool-specific fora challenges across different topics\n",
    "\n",
    "df_challenge = pd.read_json(os.path.join(path_general, 'filtered.json'))\n",
    "\n",
    "fig_challenge_topic_count_to = go.Figure()\n",
    "fig_challenge_view_count_to = go.Figure()\n",
    "fig_challenge_favorite_count_to = go.Figure()\n",
    "fig_challenge_answer_count_to = go.Figure()\n",
    "fig_challenge_comment_count_to = go.Figure()\n",
    "fig_challenge_participation_count_to = go.Figure()\n",
    "fig_challenge_topic_count_to = go.Figure()\n",
    "fig_challenge_answer_count_to = go.Figure()\n",
    "fig_challenge_score_to = go.Figure()\n",
    "fig_challenge_word_count_to = go.Figure()\n",
    "fig_challenge_unique_word_count_to = go.Figure()\n",
    "fig_challenge_sentence_count_to = go.Figure()\n",
    "fig_challenge_link_count_to = go.Figure()\n",
    "fig_challenge_information_entropy_to = go.Figure()\n",
    "fig_challenge_readability_to = go.Figure()\n",
    "fig_challenge_topic_closed_count_to = go.Figure()\n",
    "fig_challenge_solved_rate_to = go.Figure()\n",
    "\n",
    "fig_challenge_topic_count_so = go.Figure()\n",
    "fig_challenge_view_count_so = go.Figure()\n",
    "fig_challenge_favorite_count_so = go.Figure()\n",
    "fig_challenge_answer_count_so = go.Figure()\n",
    "fig_challenge_comment_count_so = go.Figure()\n",
    "fig_challenge_participation_count_so = go.Figure()\n",
    "fig_challenge_topic_count_so = go.Figure()\n",
    "fig_challenge_answer_count_so = go.Figure()\n",
    "fig_challenge_score_so = go.Figure()\n",
    "fig_challenge_word_count_so = go.Figure()\n",
    "fig_challenge_unique_word_count_so = go.Figure()\n",
    "fig_challenge_sentence_count_so = go.Figure()\n",
    "fig_challenge_link_count_so = go.Figure()\n",
    "fig_challenge_information_entropy_so = go.Figure()\n",
    "fig_challenge_readability_so = go.Figure()\n",
    "fig_challenge_topic_closed_count_so = go.Figure()\n",
    "fig_challenge_solved_rate_so = go.Figure()\n",
    "\n",
    "for name, group in df_challenge.groupby('Challenge_topic_macro'):\n",
    "    so = group[group['Platform'] == 'Stack Overflow']\n",
    "    to = group[group['Platform'] == 'Tool-specific']\n",
    "\n",
    "    # plot challenge topic count over time\n",
    "    group_to = to.groupby(pd.Grouper(key='Challenge_created_time', freq='Y'))[\n",
    "        'Challenge_topic_macro'].count().reset_index()\n",
    "    x_to = pd.to_datetime(group_to['Challenge_created_time']).values\n",
    "    y_to = group_to['Challenge_topic_macro'].values\n",
    "    diff_y = np.diff(y_to)\n",
    "    diff_y = np.insert(diff_y, 0, 0)\n",
    "    fig_challenge_topic_count_to.add_trace(\n",
    "        go.Scatter(x=x_to, y=diff_y, mode='lines', name=name))\n",
    "\n",
    "    group_so = so.groupby(pd.Grouper(key='Challenge_created_time', freq='Y'))[\n",
    "        'Challenge_topic_macro'].count().reset_index()\n",
    "    x_so = pd.to_datetime(group_so['Challenge_created_time']).values\n",
    "    y_so = group_so['Challenge_topic_macro'].values\n",
    "    diff_y = np.diff(y_so)\n",
    "    diff_y = np.insert(diff_y, 0, 0)\n",
    "    fig_challenge_topic_count_so.add_trace(\n",
    "        go.Scatter(x=x_so, y=diff_y, mode='lines', name=name))\n",
    "\n",
    "    # plot challenge participation count over time\n",
    "    group_to = to.groupby(pd.Grouper(key='Challenge_created_time', freq='Y'))[['Challenge_link_count', 'Challenge_word_count', 'Challenge_unique_word_count', 'Challenge_sentence_count', 'Challenge_information_entropy',\n",
    "                                                                               'Challenge_readability', 'Challenge_participation_count', 'Challenge_answer_count', 'Challenge_comment_count', 'Challenge_view_count', 'Challenge_favorite_count', 'Challenge_score']].sum().reset_index()\n",
    "    y = group_to['Challenge_participation_count'].values\n",
    "    diff_y = np.diff(y)\n",
    "    diff_y = np.insert(diff_y, 0, 0)\n",
    "    fig_challenge_participation_count_to.add_trace(\n",
    "        go.Scatter(x=x_to, y=diff_y, mode='lines', name=name))\n",
    "\n",
    "    group_so = so.groupby(pd.Grouper(key='Challenge_created_time', freq='Y'))[['Challenge_link_count', 'Challenge_word_count', 'Challenge_unique_word_count', 'Challenge_sentence_count', 'Challenge_information_entropy',\n",
    "                                                                               'Challenge_readability', 'Challenge_participation_count', 'Challenge_answer_count', 'Challenge_comment_count', 'Challenge_view_count', 'Challenge_favorite_count', 'Challenge_score']].sum().reset_index()\n",
    "    y = group_so['Challenge_participation_count'].values\n",
    "    diff_y = np.diff(y)\n",
    "    diff_y = np.insert(diff_y, 0, 0)\n",
    "    fig_challenge_participation_count_so.add_trace(\n",
    "        go.Scatter(x=x_so, y=diff_y, mode='lines', name=name))\n",
    "\n",
    "    # plot challenge closed topic count over time\n",
    "    group_closed_so = so.groupby(pd.Grouper(key='Challenge_closed_time', freq='Y'))[\n",
    "        'Challenge_topic_macro'].count().reset_index()\n",
    "    x = pd.to_datetime(group_closed_so['Challenge_closed_time']).values\n",
    "    y = group_closed_so['Challenge_topic_macro'].values\n",
    "    diff_Y = np.diff(y)\n",
    "    diff_Y = np.insert(diff_Y, 0, 0)\n",
    "    fig_challenge_topic_closed_count_so.add_trace(\n",
    "        go.Scatter(x=x, y=diff_Y, mode='lines', name=name))\n",
    "    \n",
    "    group_closed_to = to.groupby(pd.Grouper(key='Challenge_closed_time', freq='Y'))[\n",
    "        'Challenge_topic_macro'].count().reset_index()\n",
    "    x = pd.to_datetime(group_closed_to['Challenge_closed_time']).values\n",
    "    y = group_closed_to['Challenge_topic_macro'].values\n",
    "    diff_Y = np.diff(y)\n",
    "    diff_Y = np.insert(diff_Y, 0, 0)\n",
    "    fig_challenge_topic_closed_count_to.add_trace(\n",
    "        go.Scatter(x=x, y=diff_Y, mode='lines', name=name))\n",
    "\n",
    "    # plot challenge answer count over time\n",
    "    y = group_to['Challenge_answer_count'].values\n",
    "    diff_y = np.diff(y)\n",
    "    diff_y = np.insert(diff_y, 0, 0)\n",
    "    fig_challenge_answer_count_to.add_trace(\n",
    "        go.Scatter(x=x_to, y=diff_y, mode='lines', name=name))\n",
    "\n",
    "    y = group_so['Challenge_answer_count'].values\n",
    "    diff_y = np.diff(y)\n",
    "    diff_y = np.insert(diff_y, 0, 0)\n",
    "    fig_challenge_answer_count_so.add_trace(\n",
    "        go.Scatter(x=x_so, y=diff_y, mode='lines', name=name))\n",
    "\n",
    "    # plot challenge comment count over time\n",
    "    y = group_to['Challenge_comment_count'].values\n",
    "    diff_y = np.diff(y)\n",
    "    diff_y = np.insert(diff_y, 0, 0)\n",
    "    fig_challenge_comment_count_to.add_trace(\n",
    "        go.Scatter(x=x_to, y=diff_y, mode='lines', name=name))\n",
    "\n",
    "    y = group_so['Challenge_comment_count'].values\n",
    "    diff_y = np.diff(y)\n",
    "    diff_y = np.insert(diff_y, 0, 0)\n",
    "    fig_challenge_comment_count_so.add_trace(\n",
    "        go.Scatter(x=x_so, y=diff_y, mode='lines', name=name))\n",
    "\n",
    "    # plot challenge view count over time\n",
    "    y = group_to['Challenge_view_count'].values\n",
    "    diff_y = np.diff(y)\n",
    "    diff_y = np.insert(diff_y, 0, 0)\n",
    "    fig_challenge_view_count_to.add_trace(\n",
    "        go.Scatter(x=x_to, y=diff_y, mode='lines', name=name))\n",
    "\n",
    "    y = group_so['Challenge_view_count'].values\n",
    "    diff_y = np.diff(y)\n",
    "    diff_y = np.insert(diff_y, 0, 0)\n",
    "    fig_challenge_view_count_so.add_trace(\n",
    "        go.Scatter(x=x_so, y=diff_y, mode='lines', name=name))\n",
    "\n",
    "    # plot challenge favorite count over time\n",
    "    y = group_to['Challenge_favorite_count'].values\n",
    "    diff_y = np.diff(y)\n",
    "    diff_y = np.insert(diff_y, 0, 0)\n",
    "    fig_challenge_favorite_count_to.add_trace(\n",
    "        go.Scatter(x=x_to, y=diff_y, mode='lines', name=name))\n",
    "\n",
    "    y = group_so['Challenge_favorite_count'].values\n",
    "    diff_y = np.diff(y)\n",
    "    diff_y = np.insert(diff_y, 0, 0)\n",
    "    fig_challenge_favorite_count_so.add_trace(\n",
    "        go.Scatter(x=x_so, y=diff_y, mode='lines', name=name))\n",
    "\n",
    "    # plot challenge score over time\n",
    "    y = group_to['Challenge_score'].values\n",
    "    diff_y = np.diff(y)\n",
    "    diff_y = np.insert(diff_y, 0, 0)\n",
    "    fig_challenge_score_to.add_trace(\n",
    "        go.Scatter(x=x_to, y=diff_y, mode='lines', name=name))\n",
    "\n",
    "    y = group_so['Challenge_score'].values\n",
    "    diff_y = np.diff(y)\n",
    "    diff_y = np.insert(diff_y, 0, 0)\n",
    "    fig_challenge_score_so.add_trace(\n",
    "        go.Scatter(x=x_so, y=diff_y, mode='lines', name=name))\n",
    "\n",
    "    # plot challenge link count over time\n",
    "    y = group_to['Challenge_link_count'].values / y_to\n",
    "    fig_challenge_link_count_to.add_trace(\n",
    "        go.Scatter(x=x_to, y=y, mode='lines', name=name))\n",
    "\n",
    "    y = group_so['Challenge_link_count'].values / y_so\n",
    "    fig_challenge_link_count_so.add_trace(\n",
    "        go.Scatter(x=x_so, y=y, mode='lines', name=name))\n",
    "\n",
    "    # plot challenge word count over time\n",
    "    y = group_to['Challenge_word_count'].values / y_to\n",
    "    fig_challenge_word_count_to.add_trace(\n",
    "        go.Scatter(x=x_to, y=y, mode='lines', name=name))\n",
    "\n",
    "    y = group_so['Challenge_word_count'].values / y_so\n",
    "    fig_challenge_word_count_so.add_trace(\n",
    "        go.Scatter(x=x_so, y=y, mode='lines', name=name))\n",
    "\n",
    "    # plot challenge sentence count over time\n",
    "    y = group_to['Challenge_sentence_count'].values / y_to\n",
    "    fig_challenge_sentence_count_to.add_trace(\n",
    "        go.Scatter(x=x_to, y=y, mode='lines', name=name))\n",
    "\n",
    "    y = group_so['Challenge_sentence_count'].values / y_so\n",
    "    fig_challenge_sentence_count_so.add_trace(\n",
    "        go.Scatter(x=x_so, y=y, mode='lines', name=name))\n",
    "\n",
    "    # plot challenge unique word count over time\n",
    "    y = group_to['Challenge_unique_word_count'].values / y_to\n",
    "    fig_challenge_unique_word_count_to.add_trace(\n",
    "        go.Scatter(x=x_to, y=y, mode='lines', name=name))\n",
    "\n",
    "    y = group_so['Challenge_unique_word_count'].values / y_so\n",
    "    fig_challenge_unique_word_count_so.add_trace(\n",
    "        go.Scatter(x=x_so, y=y, mode='lines', name=name))\n",
    "\n",
    "    # plot challenge information entropy over time\n",
    "    y = group_to['Challenge_information_entropy'].values / y_to\n",
    "    fig_challenge_information_entropy_to.add_trace(\n",
    "        go.Scatter(x=x_to, y=y, mode='lines', name=name))\n",
    "\n",
    "    y = group_so['Challenge_information_entropy'].values / y_so\n",
    "    fig_challenge_information_entropy_so.add_trace(\n",
    "        go.Scatter(x=x_so, y=y, mode='lines', name=name))\n",
    "\n",
    "    # plot challenge readability over time\n",
    "    y = group_to['Challenge_readability'].values / y_to\n",
    "    fig_challenge_readability_to.add_trace(\n",
    "        go.Scatter(x=x_to, y=y, mode='lines', name=name))\n",
    "\n",
    "    y = group_so['Challenge_readability'].values / y_so\n",
    "    fig_challenge_readability_so.add_trace(\n",
    "        go.Scatter(x=x_so, y=y, mode='lines', name=name))\n",
    "\n",
    "    # plot challenge solved rate over time\n",
    "    group_closed_to = to.groupby(pd.Grouper(key='Challenge_closed_time', freq='Y'))['Challenge_topic_macro'].count(\n",
    "    ).cumsum().reset_index().rename(columns={'Challenge_closed_time': 'Date', 'Challenge_topic_macro': 'Solved'})\n",
    "    group_all_to = to.groupby(pd.Grouper(key='Challenge_created_time', freq='Y'))['Challenge_topic_macro'].count(\n",
    "    ).cumsum().reset_index().rename(columns={'Challenge_created_time': 'Date', 'Challenge_topic_macro': 'All'})\n",
    "    group_solved = pd.merge(group_closed_to, group_all_to, on='Date', how='outer').fillna(0).sort_values(by='Date')\n",
    "    x = pd.to_datetime(group_all_to['Date']).values\n",
    "    y = group_solved['Solved'] / group_solved['All'] * 100\n",
    "    fig_challenge_solved_rate_to.add_trace(\n",
    "        go.Scatter(x=x, y=y, mode='lines', name=name))\n",
    "    \n",
    "    group_closed_so = so.groupby(pd.Grouper(key='Challenge_closed_time', freq='Y'))['Challenge_topic_macro'].count(\n",
    "    ).cumsum().reset_index().rename(columns={'Challenge_closed_time': 'Date', 'Challenge_topic_macro': 'Solved'})\n",
    "    group_all_so = so.groupby(pd.Grouper(key='Challenge_created_time', freq='Y'))['Challenge_topic_macro'].count(\n",
    "    ).cumsum().reset_index().rename(columns={'Challenge_created_time': 'Date', 'Challenge_topic_macro': 'All'})\n",
    "    group_solved = pd.merge(group_closed_so, group_all_so, on='Date', how='outer').fillna(0).sort_values(by='Date')\n",
    "    x = pd.to_datetime(group_all_so['Date']).values\n",
    "    y = group_solved['Solved'] / group_solved['All'] * 100\n",
    "    fig_challenge_solved_rate_so.add_trace(\n",
    "        go.Scatter(x=x, y=y, mode='lines', name=name))\n",
    "\n",
    "fig_challenge_topic_count_to.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_view_count_to.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_favorite_count_to.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_answer_count_to.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_comment_count_to.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_participation_count_to.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_score_to.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_word_count_to.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_unique_word_count_to.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_sentence_count_to.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_link_count_to.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_information_entropy_to.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_readability_to.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_topic_closed_count_to.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_solved_rate_to.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "\n",
    "fig_challenge_topic_count_so.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_view_count_so.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_favorite_count_so.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_answer_count_so.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_comment_count_so.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_participation_count_so.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_score_so.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_word_count_so.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_unique_word_count_so.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_sentence_count_so.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_link_count_so.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_information_entropy_so.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_readability_so.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_topic_closed_count_so.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig_challenge_solved_rate_so.update_layout(\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0))\n",
    "\n",
    "fig_challenge_topic_count_to.write_image(os.path.join(\n",
    "    path_challenge_so_to, f'Challenge_topic_count_increase_rate (Tool-specific).png'))\n",
    "fig_challenge_view_count_to.write_image(os.path.join(\n",
    "    path_challenge_so_to, f'Challenge_view_count_increase_rate (Tool-specific).png'))\n",
    "fig_challenge_favorite_count_to.write_image(os.path.join(\n",
    "    path_challenge_so_to, f'Challenge_favorite_count_increase_rate (Tool-specific).png'))\n",
    "fig_challenge_answer_count_to.write_image(os.path.join(\n",
    "    path_challenge_so_to, f'Challenge_answer_count_increase_rate (Tool-specific).png'))\n",
    "fig_challenge_comment_count_to.write_image(os.path.join(\n",
    "    path_challenge_so_to, f'Challenge_comment_count_increase_rate (Tool-specific).png'))\n",
    "fig_challenge_participation_count_to.write_image(os.path.join(\n",
    "    path_challenge_so_to, f'Challenge_participation_count_increase_rate (Tool-specific).png'))\n",
    "fig_challenge_score_to.write_image(os.path.join(\n",
    "    path_challenge_so_to, f'Challenge_score_increase_rate (Tool-specific).png'))\n",
    "fig_challenge_link_count_to.write_image(os.path.join(\n",
    "    path_challenge_so_to, f'Challenge_link_count (Tool-specific).png'))\n",
    "fig_challenge_word_count_to.write_image(os.path.join(\n",
    "    path_challenge_so_to, f'Challenge_word_count (Tool-specific).png'))\n",
    "fig_challenge_unique_word_count_to.write_image(os.path.join(\n",
    "    path_challenge_so_to, f'Challenge_unique_word_count (Tool-specific).png'))\n",
    "fig_challenge_sentence_count_to.write_image(os.path.join(\n",
    "    path_challenge_so_to, f'Challenge_sentence_count (Tool-specific).png'))\n",
    "fig_challenge_information_entropy_to.write_image(os.path.join(\n",
    "    path_challenge_so_to, f'Challenge_information_entropy (Tool-specific).png'))\n",
    "fig_challenge_readability_to.write_image(os.path.join(\n",
    "    path_challenge_so_to, f'Challenge_readability (Tool-specific).png'))\n",
    "fig_challenge_topic_closed_count_to.write_image(os.path.join(\n",
    "    path_challenge_so_to, f'Challenge_topic_closed_count_increase_rate (Tool-specific).png'))\n",
    "fig_challenge_solved_rate_to.write_image(os.path.join(\n",
    "    path_challenge_so_to, f'Challenge_solved_rate (Tool-specific).png'))\n",
    "\n",
    "fig_challenge_topic_count_so.write_image(os.path.join(\n",
    "    path_challenge_so_to, f'Challenge_topic_count_increase_rate (Stack Overflow).png'))\n",
    "fig_challenge_view_count_so.write_image(os.path.join(\n",
    "    path_challenge_so_to, f'Challenge_view_count_increase_rate (Stack Overflow).png'))\n",
    "fig_challenge_favorite_count_so.write_image(os.path.join(\n",
    "    path_challenge_so_to, f'Challenge_favorite_count_increase_rate (Stack Overflow).png'))\n",
    "fig_challenge_answer_count_so.write_image(os.path.join(\n",
    "    path_challenge_so_to, f'Challenge_answer_count_increase_rate (Stack Overflow).png'))\n",
    "fig_challenge_comment_count_so.write_image(os.path.join(\n",
    "    path_challenge_so_to, f'Challenge_comment_count_increase_rate (Stack Overflow).png'))\n",
    "fig_challenge_participation_count_so.write_image(os.path.join(\n",
    "    path_challenge_so_to, f'Challenge_participation_count_increase_rate (Stack Overflow).png'))\n",
    "fig_challenge_score_so.write_image(os.path.join(\n",
    "    path_challenge_so_to, f'Challenge_score_increase_rate (Stack Overflow).png'))\n",
    "fig_challenge_link_count_so.write_image(os.path.join(\n",
    "    path_challenge_so_to, f'Challenge_link_count (Stack Overflow).png'))\n",
    "fig_challenge_word_count_so.write_image(os.path.join(\n",
    "    path_challenge_so_to, f'Challenge_word_count (Stack Overflow).png'))\n",
    "fig_challenge_unique_word_count_so.write_image(os.path.join(\n",
    "    path_challenge_so_to, f'Challenge_unique_word_count (Stack Overflow).png'))\n",
    "fig_challenge_sentence_count_so.write_image(os.path.join(\n",
    "    path_challenge_so_to, f'Challenge_sentence_count (Stack Overflow).png'))\n",
    "fig_challenge_information_entropy_so.write_image(os.path.join(\n",
    "    path_challenge_so_to, f'Challenge_information_entropy (Stack Overflow).png'))\n",
    "fig_challenge_readability_so.write_image(os.path.join(\n",
    "    path_challenge_so_to, f'Challenge_readability (Stack Overflow).png'))\n",
    "fig_challenge_topic_closed_count_so.write_image(os.path.join(\n",
    "    path_challenge_so_to, f'Challenge_topic_closed_count_increase_rate (Stack Overflow).png'))\n",
    "fig_challenge_solved_rate_so.write_image(os.path.join(\n",
    "    path_challenge_so_to, f'Challenge_solved_rate (Stack Overflow).png'))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
