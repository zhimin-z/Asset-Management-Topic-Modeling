[
    {
        "Answerer_created_time":1507661294190,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":98.0,
        "Answerer_view_count":16.0,
        "Challenge_adjusted_solved_time":28.2785163889,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>We would like to enforce specific security groups to be set on the SageMaker training jobs (XGBoost in script mode).\nHowever, distributed training, in this case, won\u2019t work out of the box, since the containers need to communicate with each other. What are the minimum inbound\/outbound rules (ports) that we need to specify for training jobs so that they can communicate?<\/p>",
        "Challenge_closed_time":1662835019252,
        "Challenge_comment_count":0,
        "Challenge_created_time":1662733216593,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/73663585",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":10.1,
        "Challenge_reading_time":5.55,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":28.2785163889,
        "Challenge_title":"Add Security groups in Amazon SageMaker for distributed training jobs",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":19.0,
        "Challenge_word_count":70,
        "Platform":"Stack Overflow",
        "Poster_created_time":1662621266503,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":48.0,
        "Poster_view_count":6.0,
        "Solution_body":"<p>setting up training in VPC including specifying security groups is documented here:\u00a0<a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/train-vpc.html#train-vpc-groups\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/train-vpc.html#train-vpc-groups<\/a><\/p>\n<p>Normally you would allow all communication between the training nodes. To do this you specify the security group source and destination to the name of the security group itself, and allow all IPv4 traffic. If you want to figure out what ports are used, you could: 1\/ define the permissive security group. 2\/ Turn on VPC flow logs 3\/ run training. 4\/ examine VPC Flow logs 5\/ update the security group only to the required ports.<\/p>\n<p>I must say restricting communication between the training nodes might be an extreme, so I would challenge the customer why it's really needed, as all nodes carry the same job, have the same IAM role, and are transiate by nature.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":12.1,
        "Solution_reading_time":12.21,
        "Solution_score_count":1.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":132.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":4.330165,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am using below code to connect to my workspace but it failed -<\/p>\n<p>Any idea what I missed?<\/p>\n<pre><code>from azure.ai.ml import MLClient\nfrom azure.identity import DefaultAzureCredential\n\n# authenticate\ncredential = DefaultAzureCredential()\n# # Get a handle to the workspace\nml_client = MLClient(\n    credential=credential,\n    subscription_id=&quot;&lt;SUBSCRIPTION_ID&gt;&quot;,\n    resource_group_name=&quot;&lt;RESOURCE_GROUP&gt;&quot;,\n    workspace_name=&quot;&lt;AML_WORKSPACE_NAME&gt;&quot;,\n)\n\n<\/code><\/pre>",
        "Challenge_closed_time":1684460862600,
        "Challenge_comment_count":0,
        "Challenge_created_time":1684445274006,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1287364\/creating-a-handle-not-connect-to-the-workspace",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":14.3,
        "Challenge_reading_time":7.35,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":4.330165,
        "Challenge_title":"Creating a handle not connect to the workspace",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":50,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=edebe9f5-ae1e-44d4-a89d-d7af3c288565\">@Ammar Huss  <\/a><\/p>\n<p>Thanks for reaching out to us. Have you tried to make a call? As the document describes -<\/p>\n<p>Creating MLClient will not connect to the workspace. The client initialization is lazy, it will wait for the first time it needs to make a call (this will happen in the next code cell).<\/p>\n<p>Please call it at least once to make the connection.<\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-explore-data?view=azureml-api-2#create-handle-to-workspace\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-explore-data?view=azureml-api-2#create-handle-to-workspace<\/a><\/p>\n<p>I hope this helps. Please let me know if that happened after you make a call but still not succeed. <\/p>\n<p>Thanks,<\/p>\n<p>Yutong<\/p>\n<p>-Please kindly accept the answer and vote 'Yes' if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":8.8,
        "Solution_reading_time":12.59,
        "Solution_score_count":1.0,
        "Solution_sentence_count":10.0,
        "Solution_word_count":111.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1508836189288,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Finland",
        "Answerer_reputation_count":36.0,
        "Answerer_view_count":2.0,
        "Challenge_adjusted_solved_time":5.5372291667,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I need to connect with Azure ML Workspace during deployment over container instance.<\/p>\n<pre><code>ws = Workspace(subscription_id=&quot;your-sub-id&quot;,\n              resource_group=&quot;your-resource-group-id&quot;,\n              workspace_name=&quot;your-workspace-name&quot;\n              )\n<\/code><\/pre>\n<p>Interactive Authentication to the ML Workspace prompts to login and then fails with below error message.<\/p>\n<pre><code>AttributeError: 'BasicTokenAuthentication' object has no attribute 'get_token'\n<\/code><\/pre>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-setup-authentication#interactive-authentication\" rel=\"nofollow noreferrer\">i have been following this Azure Authentication document.<\/a><\/p>\n<p>Any help is much appreciated.<\/p>",
        "Challenge_closed_time":1600775316867,
        "Challenge_comment_count":3,
        "Challenge_created_time":1600761544463,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/64005433",
        "Challenge_link_count":1,
        "Challenge_participation_count":5,
        "Challenge_readability":20.4,
        "Challenge_reading_time":10.71,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":3.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":3.8256677778,
        "Challenge_title":"Azure ML operations : workspace authentication error",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":706.0,
        "Challenge_word_count":63,
        "Platform":"Stack Overflow",
        "Poster_created_time":1530258066240,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":125.0,
        "Poster_view_count":33.0,
        "Solution_body":"<p>For me this was fixed by updating azureml-core from 1.13.0 to 1.14.0.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1600781478488,
        "Solution_link_count":0.0,
        "Solution_readability":2.1,
        "Solution_reading_time":0.95,
        "Solution_score_count":1.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":12.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1586263306992,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Krak\u00f3w, Poland",
        "Answerer_reputation_count":1622.0,
        "Answerer_view_count":654.0,
        "Challenge_adjusted_solved_time":9.5230127778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>How can I find IP for vertex AI managed notebook instance? The service is differing from user managed notebooks in certain sense. The creation of an instance doesn't create a compute instance, so it's all managed by itself.<\/p>\n<p>My purpose is to whitelist the set of IPs in Mongo atlas. Set of IPs being of all the notebooks in that region. I'm using google-managed networks in this case.<\/p>\n<p>I've a few doubts here:<\/p>\n<ul>\n<li>Since within managed nb, I can change CPU consumption, will this reinstantiate a new cluster, with entirely new IP, or it will be 1 from among a group of IPs?<\/li>\n<li>Is it possible to add a custom init script?<\/li>\n<\/ul>",
        "Challenge_closed_time":1635870534303,
        "Challenge_comment_count":0,
        "Challenge_created_time":1635836251457,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1636016613528,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/69806432",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":6.1,
        "Challenge_reading_time":8.58,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":9.5230127778,
        "Challenge_title":"Vertex AI Managed Notebook, get subnet\/IP",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":665.0,
        "Challenge_word_count":119,
        "Platform":"Stack Overflow",
        "Poster_created_time":1353151867408,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Bengaluru, Karnataka, India",
        "Poster_reputation_count":2513.0,
        "Poster_view_count":251.0,
        "Solution_body":"<p>If you want to connect to a database service on GCP, create a network (or use the default) and instantiate the notebook using this network (<code>Advanced options<\/code>) and create the white list for this entire network . It's required because the managed notebook creates a peering network on the network you will use, you can check you in <code>VPC Network<\/code> \u279e <code>VPC Network Peering<\/code>.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/Pd1ui.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Pd1ui.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>If you want an external IP, it will not work. Google managed notebooks <strong>does not use external ips<\/strong>, they basically access the internet via NAT gateways (does not matter if you use google or own managed networks) so you will not be able to do what you want. Move for user managed notebooks (where you can assign a fixed external ip) or white list any IP on your Mongo db service if you are not in a production environment.<\/p>\n<p>About yous doubts:<\/p>\n<blockquote>\n<p>Since within managed nb, I can change CPU consumption, will this instantiate a new cluster, with entirely new IP, or it will be 1 from among a group of IPs<\/p>\n<\/blockquote>\n<p>For the internal network it may change when you restart or recreate the notebook instance. For an external network, it does not exists and explained.<\/p>\n<blockquote>\n<p>Is it possible to add a custom init script?<\/p>\n<\/blockquote>\n<p>Basically not. But you can provide custom docker images for the notebook.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1635872119870,
        "Solution_link_count":2.0,
        "Solution_readability":9.7,
        "Solution_reading_time":19.36,
        "Solution_score_count":1.0,
        "Solution_sentence_count":12.0,
        "Solution_word_count":234.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_created_time":1515682479260,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":754.0,
        "Answerer_view_count":113.0,
        "Challenge_adjusted_solved_time":1.4016325,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I create one compute instance 'yhd-notebook' in Azure Machine Learning compute with user1. When I login with user2, and try to open the JupyterLab of this compute instance, it shows an error message like below.<\/p>\n\n<blockquote>\n  <p>User user2 does not have access to compute instance yhd-notebook.<\/p>\n  \n  <p>Only the creator can access a compute instance.<\/p>\n  \n  <p>Click here to sign out and sign in again with a different account.<\/p>\n<\/blockquote>\n\n<p>Is it possible to share compute instance with another user? BTW, both user1 and user2 have Owner role with the Azure subscription.<\/p>",
        "Challenge_closed_time":1583393458820,
        "Challenge_comment_count":0,
        "Challenge_created_time":1583388412943,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/60539094",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":6.9,
        "Challenge_reading_time":7.99,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":8.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":8,
        "Challenge_solved_time":1.4016325,
        "Challenge_title":"Is it possible to share compute instance with other user?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":3705.0,
        "Challenge_word_count":99,
        "Platform":"Stack Overflow",
        "Poster_created_time":1582361231692,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Guangzhou, China",
        "Poster_reputation_count":393.0,
        "Poster_view_count":58.0,
        "Solution_body":"<p>According to MS, all users in the workspace contributor and owner role can create, delete, start, stop, and restart compute instances across the workspace. However, only the creator of a specific compute instance is allowed to access Jupyter, JupyterLab, and RStudio on that compute instance. The creator of the compute instance has the compute instance dedicated to them, have root access, and can terminal in through Jupyter. Compute instance will have single-user login of creator user and all actions will use that user\u2019s identity for RBAC and attribution of experiment runs. SSH access is controlled through public\/private key mechanism.<\/p>",
        "Solution_comment_count":2.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":11.0,
        "Solution_reading_time":8.09,
        "Solution_score_count":7.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":99.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":0.2942933334,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Unit 4 of 7  <br \/>\nExercise - Back up an Azure virtual machine  <br \/>\nCreate a backup for Azure virtual machines  <\/p>\n<p>I am unable to run the following command in cloud shell to set up the environment:  <br \/>\nRGROUP=$(az group create --name vmbackups --location westus2 --output tsv --query name)  <\/p>\n<p>Following error pop up:  <br \/>\nERROR: (AuthorizationFailed) The client 'live.com#...... does not have authorization to perform action 'Microsoft.Resources\/subscriptions\/resourcegroups\/write' over scope '\/subscriptions\/.......\/resourcegroups\/vmbackups' or the scope is invalid. If access was recently granted, please refresh your credentials.  <br \/>\nCode: AuthorizationFailed  <br \/>\nMessage: The client 'live.com#l...... with object id '.......' does not have authorization to perform action 'Microsoft.Resources\/subscriptions\/resourcegroups\/write' over scope '\/subscriptions\/.....\/resourcegroups\/vmbackups' or the scope is invalid. If access was recently granted, please refresh your credentials.  <\/p>\n<p>When I do refresh, sign out or sign in do not helps. Anybody has any idea what to do?  <br \/>\nThank you  <\/p>",
        "Challenge_closed_time":1651918064643,
        "Challenge_comment_count":0,
        "Challenge_created_time":1651917005187,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/840311\/code-authorizationfailed",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":8.5,
        "Challenge_reading_time":14.6,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":14,
        "Challenge_solved_time":0.2942933334,
        "Challenge_title":"Code: AuthorizationFailed",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":146,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=854a8d3c-feda-48d5-ba7c-744d587335c9\">@Krisztian  <\/a>     <\/p>\n<p>Welcome to Microsoft Q&amp;A community.     <\/p>\n<p>Have you tried to do this first?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/199884-image.png?platform=QnA\" alt=\"199884-image.png\" \/>    <\/p>\n<p>Cheers,    <\/p>\n<p>Please &quot;Accept the answer&quot; if the information helped you. This will help us and others in the community as well.    <\/p>\n",
        "Solution_comment_count":2.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":9.8,
        "Solution_reading_time":6.08,
        "Solution_score_count":1.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":46.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1550779047856,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":363.0,
        "Answerer_view_count":9.0,
        "Challenge_adjusted_solved_time":4538.5667388889,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I am getting the below error.\nDoes anyone have any idea how to solve it?<\/p>\n<pre><code>Failed to create pipeline job. Error: Vertex AI Service Agent \n'XXXXX@gcp-sa-aiplatform-cc.iam.gserviceaccount.com' should be granted\n access to the image gcr.io\/gcp-project-id\/application:latest\n<\/code><\/pre>",
        "Challenge_closed_time":1659424830192,
        "Challenge_comment_count":3,
        "Challenge_created_time":1643025892210,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1643085989932,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/70833594",
        "Challenge_link_count":0,
        "Challenge_participation_count":5,
        "Challenge_readability":8.5,
        "Challenge_reading_time":4.54,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":3.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":4555.2605505556,
        "Challenge_title":"GCP Vertex AI Service Agent access to GCR image Error",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":707.0,
        "Challenge_word_count":44,
        "Platform":"Stack Overflow",
        "Poster_created_time":1501131989640,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":329.0,
        "Poster_view_count":88.0,
        "Solution_body":"<p><code>{PROJECT_NUMBER}@gcp-sa-aiplatform-cc.iam.gserviceaccount.com<\/code> is google's <a href=\"https:\/\/cloud.google.com\/iam\/docs\/service-agents\" rel=\"nofollow noreferrer\">AI Platform service agent<\/a>.\nThis Service agent requires access to read\/pull the docker image from your project's gcr to create container for pipeline run.<\/p>\n<p>If You have permission to edit <a href=\"https:\/\/cloud.google.com\/iam\/docs\/understanding-roles\" rel=\"nofollow noreferrer\">IAM roles<\/a>, You can try adding <a href=\"https:\/\/cloud.google.com\/artifact-registry\/docs\/access-control#roles\" rel=\"nofollow noreferrer\">Artifact Registry roles<\/a> to the above service agent.\nYou can start with adding <code>roles\/artifactregistry.reader<\/code>.<\/p>\n<p>Hope this helps :)<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":3.0,
        "Solution_readability":14.8,
        "Solution_reading_time":10.14,
        "Solution_score_count":1.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":66.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":0.2469486111,
        "Challenge_answer_count":2,
        "Challenge_body":"How can I extend the default time out period for SageMaker pre-signed URL ?",
        "Challenge_closed_time":1679527619211,
        "Challenge_comment_count":0,
        "Challenge_created_time":1679526730196,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1679874833968,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUKDk-YzA5SlK_zw3jb5Ox3g\/sagemaker-pre-signed-url-timeout-extension",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":9.0,
        "Challenge_reading_time":1.48,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":2,
        "Challenge_solved_time":0.2469486111,
        "Challenge_title":"SageMaker pre-signed URL timeout extension",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":24.0,
        "Challenge_word_count":17,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"The session timeout duration can specified using \n```\n`SessionExpirationDurationInSeconds`\n```\n in the API. Refer to https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/APIReference\/API_CreatePresignedDomainUrl.html#API_CreatePresignedDomainUrl_RequestParameters.\n This value defaults to 43200 which is the max allowed value.",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1679527619211,
        "Solution_link_count":1.0,
        "Solution_readability":21.9,
        "Solution_reading_time":4.25,
        "Solution_score_count":0.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":25.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1619163566860,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":1730.0,
        "Answerer_view_count":555.0,
        "Challenge_adjusted_solved_time":9614.8936591666,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I uploaded a model with<\/p>\n<pre><code>gcloud beta ai models upload --artifact-uri\n<\/code><\/pre>\n<p>And in the docker I access <code>AIP_STORAGE_URI<\/code>.\nI see that <code>AIP_STORAGE_URI<\/code> is another Google Storage location so I try to download the files using <code>storage.Client()<\/code> but then it says that I don't have access:<\/p>\n<pre><code>google.api_core.exceptions.Forbidden: 403 GET https:\/\/storage.googleapis.com\/storage\/v1\/b\/caip-tenant-***-***-*-*-***?projection=noAcl&amp;prettyPrint=false: custom-online-prediction@**.iam.gserviceaccount.com does not have storage.buckets.get access to the Google Cloud Storage bucket\n<\/code><\/pre>\n<p>I am running this endpoint with the default service account.<\/p>\n<p><a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/predictions\/custom-container-requirements#artifacts\" rel=\"nofollow noreferrer\">https:\/\/cloud.google.com\/vertex-ai\/docs\/predictions\/custom-container-requirements#artifacts<\/a><\/p>\n<p>According to the above link:\n<code>The service account that your container uses by default has permission to read from this URI. <\/code><\/p>\n<p>What am I doing wrong?<\/p>",
        "Challenge_closed_time":1627666181500,
        "Challenge_comment_count":0,
        "Challenge_created_time":1626854597743,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1626858370043,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/68465990",
        "Challenge_link_count":3,
        "Challenge_participation_count":1,
        "Challenge_readability":14.3,
        "Challenge_reading_time":15.69,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":3.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":11,
        "Challenge_solved_time":225.4399325,
        "Challenge_title":"How do I access AIP_STORAGE_URI in Vertex AI?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":742.0,
        "Challenge_word_count":111,
        "Platform":"Stack Overflow",
        "Poster_created_time":1466977784156,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":117.0,
        "Poster_view_count":17.0,
        "Solution_body":"<p>The reason behind the error being, the default service account that Vertex AI uses has the \u201c<a href=\"https:\/\/cloud.google.com\/storage\/docs\/access-control\/iam-roles#standard-roles\" rel=\"nofollow noreferrer\">Storage Object Viewer<\/a>\u201d role which excludes the <code>storage.buckets.get<\/code> permission. At the same time, the <code>storage.Client()<\/code> part of the code makes a <code>storage.buckets.get<\/code> request to the Vertex AI managed bucket for which the default service account does not have permission to.<\/p>\n<p>To resolve the issue, I would suggest you to follow the below steps -<\/p>\n<ol>\n<li><p>Make changes in the custom code to access the bucket with the model artifacts in your project instead of using the environment variable <code>AIP_STORAGE_URI<\/code> which points to the model location in the Vertex AI managed bucket.<\/p>\n<\/li>\n<li><p>Create your own service account and grant the service account with all the <a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/general\/custom-service-account\" rel=\"nofollow noreferrer\">permissions<\/a> needed by the custom code. For this specific error, a role with the <code>storage.buckets.get<\/code> permission, eg. <a href=\"https:\/\/cloud.google.com\/storage\/docs\/access-control\/iam-roles#standard-roles\" rel=\"nofollow noreferrer\">Storage Admin<\/a> (&quot;roles\/storage.admin&quot;) has to be granted to the service account.<\/p>\n<\/li>\n<li><p>Provide the newly created service account in the &quot;Service Account&quot; field when deploying the model.<\/p>\n<\/li>\n<\/ol>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1661471987216,
        "Solution_link_count":3.0,
        "Solution_readability":11.7,
        "Solution_reading_time":19.89,
        "Solution_score_count":2.0,
        "Solution_sentence_count":14.0,
        "Solution_word_count":176.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_created_time":1500629225150,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":5939.0,
        "Answerer_view_count":886.0,
        "Challenge_adjusted_solved_time":0.9110955556,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>This is the terraform shown in the docs:<\/p>\n<pre><code>resource &quot;aws_sagemaker_project&quot; &quot;example&quot; {\n  project_name = &quot;example&quot;\n\n  service_catalog_provisioning_details {\n    product_id = aws_servicecatalog_product.example.id\n  }\n}\n<\/code><\/pre>\n<p>I created a service catalog product with id: &quot;prod-xxxxxxxxxxxxx&quot;.\nWhen I substitute the service catalog product id into the above template,\nto get the following:<\/p>\n<pre><code>resource &quot;aws_sagemaker_project&quot; &quot;example&quot; {\n  project_name = &quot;example&quot;\n\n  service_catalog_provisioning_details {\n    product_id = aws_servicecatalog_product.prod-xxxxxxxxxxxxx\n  }\n}\n<\/code><\/pre>\n<p>I run terraform plan, but the following error occurs:<\/p>\n<pre><code>A managed resource &quot;aws_servicecatalog_product&quot; &quot;prod-xxxxxxxxxxxxx&quot; has not been declared in the root module.\n\n<\/code><\/pre>\n<p>What do I need to do to fix this error?<\/p>",
        "Challenge_closed_time":1654269294487,
        "Challenge_comment_count":2,
        "Challenge_created_time":1654264489180,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1654266014543,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/72490682",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":16.3,
        "Challenge_reading_time":13.07,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":1.3348075,
        "Challenge_title":"How to create an aws sagemaker project using terraform?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":298.0,
        "Challenge_word_count":92,
        "Platform":"Stack Overflow",
        "Poster_created_time":1653511725307,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":35.0,
        "Poster_view_count":26.0,
        "Solution_body":"<p>Since the documentation is lacking a bit of clarity, in order to have this work as in the example, you would first have to create the Service Catalog product in Terraform as well, e.g.:<\/p>\n<pre><code>resource &quot;aws_servicecatalog_product&quot; &quot;example&quot; {\n  name  = &quot;example&quot;\n  owner = [aws_security_group.example.id] # &lt;---- This would need to be created first\n  type  = aws_subnet.main.id # &lt;---- This would need to be created first\n\n  provisioning_artifact_parameters {\n    template_url = &quot;https:\/\/s3.amazonaws.com\/cf-templates-ozkq9d3hgiq2-us-east-1\/temp1.json&quot;\n  }\n\n  tags = {\n    foo = &quot;bar&quot;\n  }\n}\n<\/code><\/pre>\n<p>You can reference it then in the SageMaker project the same way as in the example:<\/p>\n<pre><code>resource &quot;aws_sagemaker_project&quot; &quot;example&quot; {\n  project_name = &quot;example&quot;\n\n  service_catalog_provisioning_details {\n    product_id = aws_servicecatalog_product.example.id\n  }\n}\n<\/code><\/pre>\n<p>Each of the resources that gets created has a set of attributes that can be accessed as needed by other resources, data sources or outputs. In order to understand how this works, I strongly suggest reading the documentation about referencing values [1]. Since you already created the Service Catalog product, the only thing you need to do is provide the string value for the product ID:<\/p>\n<pre><code>resource &quot;aws_sagemaker_project&quot; &quot;example&quot; {\n  project_name = &quot;example&quot;\n\n  service_catalog_provisioning_details {\n    product_id = &quot;prod-xxxxxxxxxxxxx&quot;\n  }\n}\n<\/code><\/pre>\n<p>When I can't understand what value is expected by an argument (e.g., <code>product_id<\/code> in this case), I usually read the docs and look for examples like in [2]. Note: That example is CloudFormation, but it can help you understand what type of a value is expected (e.g., string, number, bool).<\/p>\n<p>You could also import the created Service Catalog product into Terraform so you can manage it with IaC [3]. You should understand all the implications of <code>terraform import<\/code> though before trying it [4].<\/p>\n<hr \/>\n<p>[1] <a href=\"https:\/\/www.terraform.io\/language\/expressions\/references\" rel=\"nofollow noreferrer\">https:\/\/www.terraform.io\/language\/expressions\/references<\/a><\/p>\n<p>[2] <a href=\"https:\/\/docs.amazonaws.cn\/en_us\/AWSCloudFormation\/latest\/UserGuide\/aws-resource-sagemaker-project.html#aws-resource-sagemaker-project--examples--SageMaker_Project_Example\" rel=\"nofollow noreferrer\">https:\/\/docs.amazonaws.cn\/en_us\/AWSCloudFormation\/latest\/UserGuide\/aws-resource-sagemaker-project.html#aws-resource-sagemaker-project--examples--SageMaker_Project_Example<\/a><\/p>\n<p>[3] <a href=\"https:\/\/registry.terraform.io\/providers\/hashicorp\/aws\/latest\/docs\/resources\/servicecatalog_product#import\" rel=\"nofollow noreferrer\">https:\/\/registry.terraform.io\/providers\/hashicorp\/aws\/latest\/docs\/resources\/servicecatalog_product#import<\/a><\/p>\n<p>[4] <a href=\"https:\/\/www.terraform.io\/cli\/commands\/import\" rel=\"nofollow noreferrer\">https:\/\/www.terraform.io\/cli\/commands\/import<\/a><\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":9.0,
        "Solution_readability":17.8,
        "Solution_reading_time":40.53,
        "Solution_score_count":1.0,
        "Solution_sentence_count":21.0,
        "Solution_word_count":270.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1502379091636,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":1886.0,
        "Answerer_view_count":145.0,
        "Challenge_adjusted_solved_time":3.3631980556,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I'm currently trying to script our Azure Machine Learning infrastructure, using ARM templates and running through Terraform.  In order to ensure that the template works, I'm first running it from a file using the Az CLI.<\/p>\n\n<p>I'm running this on Ubuntu, with the below version of the Az CLI:-<\/p>\n\n<pre><code>azure-cli                         2.0.78\n\ncommand-modules-nspkg              2.0.3\ncore                              2.0.78\nnspkg                              3.0.4\ntelemetry                          1.0.4\n\nPython location '\/opt\/az\/bin\/python3'\nExtensions directory '\/home\/blah\/.azure\/cliextensions'\n\nPython (Linux) 3.6.5 (default, Dec 12 2019, 11:11:33) \n[GCC 8.3.0]\n<\/code><\/pre>\n\n<p>I have already created the Storage Account, App Insights and Key Vault using terraform.<\/p>\n\n<p>When trying to run the template using the Az CLI with the command:-<\/p>\n\n<pre><code>az group deployment create --name MachineLearning --resource-group data-science --template-file ML_ARM.json --parameters appInsightsName=machine-learning-dev storageAccountName=machinelearningdev keyVaultName=data-science-dev mlApiVersion=2018-11-19 mlWorkspaceName=machine-learning-dev location=uksouth\n<\/code><\/pre>\n\n<p>I receive the following error:-<\/p>\n\n<p><code>Make sure to create your workspace using a client which support MSI<\/code><\/p>\n\n<p>The ARM template is below:-<\/p>\n\n<pre><code>{\n    \"$schema\": \"https:\/\/schema.management.azure.com\/schemas\/2015-01-01\/deploymentTemplate.json#\",\n    \"contentVersion\": \"1.0.0.0\",\n    \"parameters\": {\n        \"storageAccountName\": {\n            \"type\": \"string\",\n            \"metadata\": {\n                \"description\": \"The name of the storage account\"\n            }\n        },\n        \"appInsightsName\" : {\n            \"type\": \"string\",\n            \"metadata\": {\n                \"description\": \"The name of the app insights account\"\n            }\n        },\n        \"keyVaultName\": {\n            \"type\": \"string\",\n            \"metadata\": {\n                \"description\": \"The name of the keyvault resource\"\n            }\n        },\n        \"mlApiVersion\": {\n            \"type\": \"string\",\n            \"metadata\": {\n                \"description\": \"The api version of the ML workspace\"\n            }\n        },\n        \"mlWorkspaceName\": {\n            \"type\": \"string\",\n            \"metadata\": {\n                \"description\": \"The name of the Machine Learning Workspace\"\n            }\n        },\n        \"location\": {\n            \"type\": \"string\",\n            \"metadata\": {\n                \"description\": \"Resource location\"\n            }\n        }\n    },\n  \"resources\": [\n        {\n            \"apiVersion\": \"[parameters('mlApiVersion')]\",\n            \"type\": \"Microsoft.MachineLearningServices\/workspaces\",\n            \"name\": \"[parameters('mlWorkspaceName')]\",\n            \"location\": \"[parameters('location')]\",\n            \"sku\": {\n              \"tier\": \"enterprise\",\n              \"name\": \"enterprise\"\n            },\n            \"properties\": {\n                \"storageAccount\": \"[resourceId('Microsoft.Storage\/storageAccounts',parameters('storageAccountName'))]\",\n                \"applicationInsights\": \"[resourceId('Microsoft.Insights\/components',parameters('appInsightsName'))]\",\n                \"keyVault\": \"[resourceId('Microsoft.KeyVault\/vaults',parameters('keyVaultName'))]\"\n            }\n        }\n    ]\n}\n<\/code><\/pre>\n\n<p>Some rudimentary googling hasn't really been enlightening into what the issue might be with this; the documentation and guide templates for the Machine Learning Service are linked below:-<\/p>\n\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-create-workspace-template\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-create-workspace-template<\/a>\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/templates\/microsoft.machinelearningservices\/2019-11-01\/workspaces\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/templates\/microsoft.machinelearningservices\/2019-11-01\/workspaces<\/a><\/p>\n\n<p>Any idea what the issue might be?  Thanks in advance for any pointers!<\/p>",
        "Challenge_closed_time":1576779595736,
        "Challenge_comment_count":0,
        "Challenge_created_time":1576767488223,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/59412213",
        "Challenge_link_count":5,
        "Challenge_participation_count":1,
        "Challenge_readability":15.2,
        "Challenge_reading_time":46.73,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":25,
        "Challenge_solved_time":3.3631980556,
        "Challenge_title":"Error: \"Make sure to create your workspace using a client which support MSI\" when deploying Azure ARM template for Machine Learning Services Workpsace",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":422.0,
        "Challenge_word_count":307,
        "Platform":"Stack Overflow",
        "Poster_created_time":1562705135403,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":327.0,
        "Poster_view_count":38.0,
        "Solution_body":"<p>I am not familar with Terraform or that robust on ML Services; however, the error you provided lends itself to needing to have MSI authentication configured which is configured in the link you provided.<\/p>\n\n<p>Try updating your ARM to include the identity section like this:<\/p>\n\n<pre><code>   ...  },\n\"identity\": {\n        \"type\": \"systemAssigned\"\n      },\n                \"properties\": {\n                    \"storageAccount\": \"[resourceId('Microsoft.Storage\/storageAccounts',parameters('storageAccountName'))]\",\n                    \"applicationInsights\": \"[resourceId('Microsoft.Insights\/components',parameters('appInsightsName'))]\",\n                    \"keyVault\": \"[resourceId('Microsoft.KeyVault\/vaults',parameters('keyVaultName'))]\"\n                }\n<\/code><\/pre>\n\n<p>This will create the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/active-directory\/managed-identities-azure-resources\/overview\" rel=\"nofollow noreferrer\">Managed Service Identity<\/a>.<\/p>",
        "Solution_comment_count":2.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":20.0,
        "Solution_reading_time":11.53,
        "Solution_score_count":1.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":67.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":0.1077063889,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>How to use safe and protected communication?<\/p>",
        "Challenge_closed_time":1656964172656,
        "Challenge_comment_count":0,
        "Challenge_created_time":1656963784913,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/913567\/problems-secure-connection",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":12.1,
        "Challenge_reading_time":1.03,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":2,
        "Challenge_solved_time":0.1077063889,
        "Challenge_title":"problems secure connection",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":9,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Your question is too vague for anyone to answer. Can you please elaborate?    <\/p>\n<p>If you are talking about securing Azure Machine Learning you will need to use Virtual Networks (VNet) to protect.    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-network-security-overview\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-network-security-overview<\/a><\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":13.9,
        "Solution_reading_time":5.44,
        "Solution_score_count":0.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":36.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":0.6205213889,
        "Challenge_answer_count":4,
        "Challenge_body":"<p>I don\u2019t have admin access to a team and want to remove myself from the said team. There are other admin users, but say I can\u2019t communicate with them, how to remove myself?<\/p>",
        "Challenge_closed_time":1649424480723,
        "Challenge_comment_count":0,
        "Challenge_created_time":1649422246846,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/how-to-remove-myself-from-a-team\/2201",
        "Challenge_link_count":0,
        "Challenge_participation_count":4,
        "Challenge_readability":4.8,
        "Challenge_reading_time":2.56,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":0.6205213889,
        "Challenge_title":"How to remove myself from a team?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":111.0,
        "Challenge_word_count":39,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p><a class=\"mention\" href=\"\/u\/sai_prasanna\">@sai_prasanna<\/a> no problem! You\u2019ve been removed from \u201cagara\u201d. Is there anything else I can help with?<\/p>\n<p>Thank you,<br>\nNate<\/p>",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":4.2,
        "Solution_reading_time":2.34,
        "Solution_score_count":null,
        "Solution_sentence_count":4.0,
        "Solution_word_count":21.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_created_time":1395431574432,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Islamabad Capital Territory, Pakistan",
        "Answerer_reputation_count":1520.0,
        "Answerer_view_count":214.0,
        "Challenge_adjusted_solved_time":2.3479152778,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I started to work with AWS SageMaker. I have an AWS Starter Account. I have been trying to deploy a built-in algorithm for 2 days but I always get <code>AccessDeniedException<\/code> despite the fact that I created IAM role according to <a href=\"https:\/\/aws.amazon.com\/tr\/getting-started\/tutorials\/build-train-deploy-machine-learning-model-sagemaker\/\" rel=\"nofollow noreferrer\">https:\/\/aws.amazon.com\/tr\/getting-started\/tutorials\/build-train-deploy-machine-learning-model-sagemaker\/<\/a><\/p>\n\n<blockquote>\n  <p>ClientError: An error occurred (AccessDeniedException) when calling the CreateTrainingJob operation: User: arn:aws:sts::161745376217:assumed-role\/AmazonSageMaker-ExecutionRole-20200203T194557\/SageMaker is not authorized to perform: sagemaker:CreateTrainingJob on resource: arn:aws:sagemaker:us-east-1:161745376217:training-job\/blazingtext-2020-02-03-18-12-14-017 with an explicit deny<\/p>\n<\/blockquote>\n\n<p>Could you help me to solve this problem ?\nThank you so much<\/p>",
        "Challenge_closed_time":1580764036812,
        "Challenge_comment_count":0,
        "Challenge_created_time":1580755584317,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1580790326547,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/60045326",
        "Challenge_link_count":2,
        "Challenge_participation_count":2,
        "Challenge_readability":19.9,
        "Challenge_reading_time":13.51,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":2.3479152778,
        "Challenge_title":"AWS SageMaker Access Denied",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":3755.0,
        "Challenge_word_count":86,
        "Platform":"Stack Overflow",
        "Poster_created_time":1481983208856,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":41.0,
        "Poster_view_count":8.0,
        "Solution_body":"<p>You have created a role for SageMaker to access S3 bucket, but it seems your IAM user doesn't have access to SageMaker service. Please make sure your IAM user has permission to SageMaker.<\/p>",
        "Solution_comment_count":2.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":8.5,
        "Solution_reading_time":2.38,
        "Solution_score_count":2.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":33.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":18.2166666667,
        "Challenge_answer_count":1,
        "Challenge_body":"Hi,\n\nI am carrying out the OAuth verification in Google Cloud Platform, I received an email that said:\n\"Thanks for your patience while we reviewed your project.\n\nYour project pc-api-XXXXXXXXXXXXXXX-XX has multiple unique domains in the redirect URI and origin URLs, many of which have\u00a0unrelated applications. This is in direct violation of the\u00a0Google API Services: User Data Policy, which requires that projects accurately represent their identity and intent to Google and to our users when they request access to Google user data.\n\nPlease follow the instructions on the\u00a0Google API Console\u00a0to:\n\nCreate new projects\nMigrate your redirect URIs with distinct brands to different projects, and\/or\nEnsure that these projects accurately represent their true identity to Google users\n\nYou can find more information in the\u00a0OAuth Application Verification FAQ. \u00a0To make sure we don't miss your messages, respond directly to this email to continue with the verification process.\"\n\n\n\nI have a web server, which checks the validity (domain-1.com) in-app purchases, and I also have a site with a different domain containing: privacy-policy and terms-of-service (domain-2.com).\n\nMy settings are as follows:\n\nOAuth consent screen:\n- Home page application:\u00a0https:\/\/www.domain-2.com\/\n- Privacy Policy:\u00a0https:\/\/www.domain-2.com\/privacy-policy\/\n- Terms of Service:\u00a0https:\/\/www.domain-2.com\/terms-of-service\/\n\nAuthorized domains:\n- domain-2.com\n- domain-1.com\n\nID client OAuth 2.0 -> Authorized Redirect URIs:\n-\u00a0https:\/\/game.domain-1.com:8443\n\nI have a working service account.\nI have successfully verified all 2 domains.\n\n\nWhere is the mistake?",
        "Challenge_closed_time":1649106480000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1649040900000,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Action-Needed-OAuth-Google-Cloud-platform-multiple-unique\/td-p\/410024\/jump-to\/first-unread-message",
        "Challenge_link_count":4,
        "Challenge_participation_count":1,
        "Challenge_readability":9.8,
        "Challenge_reading_time":21.11,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":17,
        "Challenge_solved_time":18.2166666667,
        "Challenge_title":"Action Needed | OAuth Google Cloud platform | multiple unique domains",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":118.0,
        "Challenge_word_count":233,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"I have found the solution:\n\nI had 2 Google Cloud Platform projects for the same application.\n\nI deleted a Google Cloud Platform.\nI implemented all the configurations of the deleted project in the other project, and it worked!\n\nView solution in original post",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":6.3,
        "Solution_reading_time":3.11,
        "Solution_score_count":3.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":43.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_created_time":1388584380832,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":396.0,
        "Answerer_view_count":34.0,
        "Challenge_adjusted_solved_time":42.3742536111,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I want to integrate mlflow ui to our website by using an iframe, but with the header hidden if possible. I found there is an environment variable setting in the source code \/mlflow\/server\/js\/components\/HomeView.js:\n<code>const headerHeight = process.env.HIDE_HEADER === 'true' ? 0 : 60;<\/code> But how can I specify this environment by running the server with <code>mlflow server<\/code>? I tried with <code>HIDE_HEADER=true mlflow server<\/code>, but this doesn't work. Or is there any other way to solve this?<\/p>",
        "Challenge_closed_time":1572468752163,
        "Challenge_comment_count":0,
        "Challenge_created_time":1572316204850,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/58600732",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":6.9,
        "Challenge_reading_time":7.46,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":42.3742536111,
        "Challenge_title":"Is there a way to hide mlflow ui header when start the server with mlflow server?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":296.0,
        "Challenge_word_count":87,
        "Platform":"Stack Overflow",
        "Poster_created_time":1441151447408,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":626.0,
        "Poster_view_count":79.0,
        "Solution_body":"<p>@Jason good question, those environment variables are read at build-time for the MLflow UI's Javascript assets. Since the PyPI MLflow wheel comes with pre-built Javascript assets, it's difficult to achieve your use case using a PyPI installation of <code>mlflow<\/code>.<\/p>\n\n<p>However, you can build a custom MLflow wheel from source with the UI header hidden by following the instructions <a href=\"https:\/\/github.com\/mlflow\/mlflow\/blob\/branch-1.3\/CONTRIBUTING.rst#building-a-distributable-artifact\" rel=\"nofollow noreferrer\">here<\/a>, replacing the <code>npm run build<\/code> step with <code>HIDE_HEADER=true npm run build<\/code> (basically, the idea is to set the desired environment variables prior to building Javascript assets via <code>npm run build<\/code>). You can then pip-install that wheel on the node hosting your MLflow server &amp; launch the server via <code>mlflow server<\/code>.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":12.0,
        "Solution_reading_time":11.62,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":112.0,
        "Tool":"MLflow"
    },
    {
        "Answerer_created_time":1276294622427,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":4334.0,
        "Answerer_view_count":496.0,
        "Challenge_adjusted_solved_time":135.0612036111,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have <a href=\"https:\/\/docs.aws.amazon.com\/code-samples\/latest\/catalog\/python-comprehend-TopicModeling.py.html\" rel=\"nofollow noreferrer\">Amazon sample code<\/a> for running <code>comprehend.start_topics_detection_job<\/code>. Here is the code with the variables filled in for my job:<\/p>\n\n<pre><code>import re\nimport csv\nimport pytz\nimport boto3\nimport json\n\n# https:\/\/docs.aws.amazon.com\/code-samples\/latest\/catalog\/python-comprehend-TopicModeling.py.html\n# https:\/\/docs.aws.amazon.com\/comprehend\/latest\/dg\/API_InputDataConfig.html\n\n# Set these values before running the program\ninput_s3_url = \"s3:\/\/comprehend-topic-modelling-bucket\/input_800_cleaned_articles\/\"\ninput_doc_format = \"ONE_DOC_PER_LINE\"\noutput_s3_url = \"s3:\/\/comprehend-topic-modelling-bucket\/output\"\ndata_access_role_arn = \"arn:aws:iam::372656143103:role\/access-aws-services-from-sagemaker\"\nnumber_of_topics = 30\n\n# Set up job configuration\ninput_data_config = {\"S3Uri\": input_s3_url, \"InputFormat\": input_doc_format}\noutput_data_config = {\"S3Uri\": output_s3_url}\n\n# Begin a job to detect the topics in the document collection\ncomprehend = boto3.client('comprehend')\nstart_result = comprehend.start_topics_detection_job(\n    NumberOfTopics=number_of_topics,\n    InputDataConfig=input_data_config,\n    OutputDataConfig=output_data_config,\n    DataAccessRoleArn=data_access_role_arn)\n\n# Output the results\nprint('Start Topic Detection Job: ' + json.dumps(start_result))\njob_id = start_result['JobId']\nprint(f'job_id: {job_id}')\n\n# Retrieve and output information about the job\ndescribe_result = comprehend.describe_topics_detection_job(JobId=job_id)\nprint('Describe Job: ' + json.dumps(describe_result)) . #&lt;===LINE 36\n\n# List and output information about current jobs\nlist_result = comprehend.list_topics_detection_jobs()\nprint('list_topics_detection_jobs_result: ' + json.dumps(list_result))\n<\/code><\/pre>\n\n<p>It's failing with the error:<\/p>\n\n<pre><code>---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n&lt;ipython-input-8-840a7ee043d4&gt; in &lt;module&gt;()\n     34 # Retrieve and output information about the job\n     35 describe_result = comprehend.describe_topics_detection_job(JobId=job_id)\n---&gt; 36 print('Describe Job: ' + json.dumps(describe_result))\n     37 \n     38 # List and output information about current jobs\n\n~\/anaconda3\/envs\/python3\/lib\/python3.6\/json\/__init__.py in dumps(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\n    229         cls is None and indent is None and separators is None and\n    230         default is None and not sort_keys and not kw):\n--&gt; 231         return _default_encoder.encode(obj)\n    232     if cls is None:\n    233         cls = JSONEncoder\n\n~\/anaconda3\/envs\/python3\/lib\/python3.6\/json\/encoder.py in encode(self, o)\n    197         # exceptions aren't as detailed.  The list call should be roughly\n    198         # equivalent to the PySequence_Fast that ''.join() would do.\n--&gt; 199         chunks = self.iterencode(o, _one_shot=True)\n    200         if not isinstance(chunks, (list, tuple)):\n    201             chunks = list(chunks)\n\n~\/anaconda3\/envs\/python3\/lib\/python3.6\/json\/encoder.py in iterencode(self, o, _one_shot)\n    255                 self.key_separator, self.item_separator, self.sort_keys,\n    256                 self.skipkeys, _one_shot)\n--&gt; 257         return _iterencode(o, 0)\n    258 \n    259 def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n\n~\/anaconda3\/envs\/python3\/lib\/python3.6\/json\/encoder.py in default(self, o)\n    178         \"\"\"\n    179         raise TypeError(\"Object of type '%s' is not JSON serializable\" %\n--&gt; 180                         o.__class__.__name__)\n    181 \n    182     def encode(self, o):\n\nTypeError: Object of type 'datetime' is not JSON serializable\n<\/code><\/pre>\n\n<p>It fails instantly, the second I pus \"run\". It seems to me that the call to <code>comprehend.start_topics_detection_job<\/code> may be failing, leading to an error line 36, <code>print('Describe Job: ' + json.dumps(describe_result))<\/code>.<\/p>\n\n<p>What am I missing?<\/p>\n\n<p><strong>UPDATE<\/strong><\/p>\n\n<p>The same IAM role is being used for the notebook, as well as in the above code. Here are the permissions currently assigned to that IAM role:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/6ihIr.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/6ihIr.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Challenge_closed_time":1556698045340,
        "Challenge_comment_count":3,
        "Challenge_created_time":1556211825007,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1586235824608,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/55854377",
        "Challenge_link_count":5,
        "Challenge_participation_count":4,
        "Challenge_readability":14.9,
        "Challenge_reading_time":57.0,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":33,
        "Challenge_solved_time":135.0612036111,
        "Challenge_title":"comprehend.start_topics_detection_job Fails with Silent Error?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":232.0,
        "Challenge_word_count":379,
        "Platform":"Stack Overflow",
        "Poster_created_time":1276294622427,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":4334.0,
        "Poster_view_count":496.0,
        "Solution_body":"<p>It turns out that there was nothing wrong with the call to <code>comprehend.describe_topics_detection_job<\/code> -- it was just returning, in <code>describe_result<\/code>, something that could not be json serialized, so <code>json.dumps(describe_result))<\/code> was throwing an error. <\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":11.1,
        "Solution_reading_time":3.8,
        "Solution_score_count":0.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":33.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":49.0639686111,
        "Challenge_answer_count":5,
        "Challenge_body":"<p>Hello,<\/p>\n<p>After several tries I am getting stuck when finishing a run about data uploading. It always throws the same error and it seems it \u2018kills\u2019 my network, consuming all resources as when I try to access other pages the internet is very slow.<\/p>\n<p>When I try to do the tests I always have a good connection (around 600Mb), and I tried on different days. I never have connection cuts, just when doing the run finish.<\/p>\n<p>The error I have is the following:<br>\n<img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/a\/a27d197a4c8825679f7e5c459ef89d5f87a2a192.png\" alt=\"Selection_001\" data-base62-sha1=\"nbrnemiqAtyylTXSAgkOD1SYaSS\" width=\"573\" height=\"182\"><\/p>",
        "Challenge_closed_time":1675199007678,
        "Challenge_comment_count":0,
        "Challenge_created_time":1675022377391,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/network-error-connecttimeout-entering-retry-loop\/3772",
        "Challenge_link_count":1,
        "Challenge_participation_count":5,
        "Challenge_readability":9.7,
        "Challenge_reading_time":9.65,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":49.0639686111,
        "Challenge_title":"Network error (ConnectTimeout), entering retry loop",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":203.0,
        "Challenge_word_count":94,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hey Mario!<\/p>\n<p>We have been having an influx of traffic lately. Please try again and if you still run into the ConnectTimeout Network error, please send us your debug.log so we can take a closer look.<\/p>",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":5.6,
        "Solution_reading_time":2.57,
        "Solution_score_count":null,
        "Solution_sentence_count":3.0,
        "Solution_word_count":36.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_created_time":1370505440848,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Calgary, AB",
        "Answerer_reputation_count":333.0,
        "Answerer_view_count":32.0,
        "Challenge_adjusted_solved_time":38.5735138889,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I'm trying to avoid to use the managed policies <code>AmazonSageMakerReadOnly<\/code> and <code>AmazonSageMakerFullAccess<\/code> because I only want the users to be able to start\/stop their own notebook instance and to open jupyter in their instance.<\/p>\n<p>So far the user role has the following permissions among others<\/p>\n<pre><code>...\n        {\n            &quot;Sid&quot;: &quot;&quot;,\n            &quot;Effect&quot;: &quot;Allow&quot;,\n            &quot;Action&quot;: [\n                &quot;sagemaker:StopNotebookInstance&quot;,\n                &quot;sagemaker:StartNotebookInstance&quot;,\n                &quot;sagemaker:CreatePresignedNotebookInstanceUrl&quot;\n            ],\n            &quot;Resource&quot;: &quot;*&quot;,\n            &quot;Condition&quot;: {\n                &quot;StringEquals&quot;: {\n                    &quot;aws:ResourceTag\/OwnerRole&quot;: &quot;${aws:userid}&quot;\n                }\n            }\n        },\n  \n<\/code><\/pre>\n<p>The policy does <strong>not<\/strong> have <code>sagemaker:CreatePresignedDomainUrl<\/code> but it has <code>sagemaker:CreatePresignedNotebookInstanceUrl<\/code>, when the user with this policy click on <code>Open Jupyter<\/code> in the AWS Sagemaker console , it opens an url <code>https:\/\/xxxxxx.notebook.eu-north-1.sagemaker.aws\/auth?authToken=xxxxx<\/code> but that url will return:<\/p>\n<p><code>403 Forbidden. Access to xxxxxx.notebook.eu-north-1.sagemaker.aws was denied. You don't have authorisation to view this page. HTTP ERROR 403<\/code><\/p>\n<p>As soon as I added <code>sagemaker:CreatePresignedDomainUrl<\/code> for resource <code>*<\/code> then the 403 error <strong>was gone<\/strong> and the user could open the jupyter notebook.<\/p>\n<p>My question is <strong>why is that needed<\/strong>, and <strong>what resource should I put<\/strong> instead of <code>*<\/code>, the documentation mentions <code>arn:aws:sagemaker:regionXXX:account-idXXX:app\/domain-id\/userProfileNameXXXX\/*<\/code> but I do not have any domain or user profile.<\/p>",
        "Challenge_closed_time":1652829020203,
        "Challenge_comment_count":0,
        "Challenge_created_time":1652690155553,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/72256288",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":17.2,
        "Challenge_reading_time":25.16,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":10,
        "Challenge_solved_time":38.5735138889,
        "Challenge_title":"Is sagemaker:CreatePresignedDomainUrl required to open jupyter in SageMaker notebook instance?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":173.0,
        "Challenge_word_count":176,
        "Platform":"Stack Overflow",
        "Poster_created_time":1237484106592,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Stockholm, Sweden",
        "Poster_reputation_count":19085.0,
        "Poster_view_count":906.0,
        "Solution_body":"<p><code>CreatePresignedDomainUrl<\/code> statement allows the role to launch a SageMaker Studio app (and hence the <code>domain-id\/user-profile<\/code> ARN). Opening SageMaker notebook instance does not need the presigned domain url permission.<\/p>\n<p>You'll need to make sure you're tagging the notebook with an OwnerRole key, with value = userid (not username). In addition, you'll need to use the <code>sagemaker:ResourceTag<\/code> (instead of <code>aws:ResourceTag<\/code>).<\/p>\n<p>See the <a href=\"https:\/\/docs.aws.amazon.com\/service-authorization\/latest\/reference\/list_amazonsagemaker.html\" rel=\"nofollow noreferrer\">service authorization page<\/a> for a complete list of actions and condition keys.<\/p>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":14.0,
        "Solution_reading_time":9.28,
        "Solution_score_count":1.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":74.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1491898605956,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Sydney NSW, Australia",
        "Answerer_reputation_count":161.0,
        "Answerer_view_count":7.0,
        "Challenge_adjusted_solved_time":545.9161877778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>We have applications for multiple tenants on our AWS account and would like to distinguish between them in different IAM roles. In most places this is already possible by limiting resource access based on naming patterns.<\/p>\n<p>For CloudWatch log groups of SageMaker training jobs however I have not seen a working solution yet. The tenants can choose the job name arbitrarily, and hence the only part of the LogGroup name that is available for pattern matching would be the prefix before the job name. This prefix however seems to be fixed to <code>\/aws\/sagemaker\/TrainingJobs<\/code>.<\/p>\n<p>Is there a way to change or extend this prefix in order to make such limiting possible? Say, for example <code>\/aws\/sagemaker\/TrainingJobs\/&lt;product&gt;-&lt;stage&gt;-&lt;component&gt;\/&lt;training-job-name&gt;-...<\/code> so that a resource limitation like <code>\/aws\/sagemaker\/TrainingJobs\/&lt;product&gt;-*<\/code> becomes possible?<\/p>",
        "Challenge_closed_time":1651281451296,
        "Challenge_comment_count":0,
        "Challenge_created_time":1649316153020,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/71777914",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":11.1,
        "Challenge_reading_time":12.46,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":545.9161877778,
        "Challenge_title":"Change AWS SageMaker LogGroup Prefix?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":48.0,
        "Challenge_word_count":127,
        "Platform":"Stack Overflow",
        "Poster_created_time":1257535237563,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Germany",
        "Poster_reputation_count":1904.0,
        "Poster_view_count":321.0,
        "Solution_body":"<p>I think it is not possible to change the log streams names for any of the SageMaker services.<\/p>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":6.8,
        "Solution_reading_time":1.22,
        "Solution_score_count":0.0,
        "Solution_sentence_count":1.0,
        "Solution_word_count":18.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":0.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":6.0041666667,
        "Challenge_answer_count":1,
        "Challenge_body":"Hi, I see in this page of documentation https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/notebook-interface-endpoint.html that:\n>\"*You can connect to your notebook instance from your VPC through an interface endpoint in your Virtual Private Cloud (VPC) instead of connecting over the internet. When you use a VPC interface endpoint, communication between your VPC and the notebook instance is conducted entirely and securely within the AWS network.*\"\n\nHow would customer interact on their laptop with the UI of a notebook instance sitting in a VPC?",
        "Challenge_closed_time":1541516577000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1541494962000,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1668438538512,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QU5z-7bQ9zQOi_NrVlHy_5oA\/which-connection-method-when-using-sagemaker-notebook-through-vpc-interface-endpoint",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":12.5,
        "Challenge_reading_time":8.01,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":6.0041666667,
        "Challenge_title":"Which connection method when using SageMaker Notebook through VPC Interface Endpoint?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":459.0,
        "Challenge_word_count":88,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":1.0,
        "Poster_isModerator":0.0,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"If you are trying to access from within VPC, you'll have a direct connection. Otherwise, you'll need a configuration in place, such as Amazon VPN or AWS Direct Connect, to connect to your notebooks. Here is the blog post where we tried to explain how to set up AWS PrivateLink for Amazon SageMaker notebooks: https:\/\/aws.amazon.com\/blogs\/machine-learning\/direct-access-to-amazon-sagemaker-notebooks-from-amazon-vpc-by-using-an-aws-privatelink-endpoint\/",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1667925550451,
        "Solution_link_count":1.0,
        "Solution_readability":14.0,
        "Solution_reading_time":5.85,
        "Solution_score_count":0.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":55.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":24.8431438889,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>hello.  <\/p>\n<p>I am currently using Machine Learning Studio (classic).  <\/p>\n<p>'From now through 31 August 2024, you can continue to use the existing Machine Learning Studio (classic) experiments and web services. Beginning 1 December 2021, new creation of Machine Learning Studio (classic) resources will not be available.  <\/p>\n<p>Is the following interpretation correct?  <\/p>\n<p>Things you can't do from 1 December 2021  <br \/>\n-Creating a workspace for Machine Learning Studio (classic)  <br \/>\n-Creating a web service plan for Machine Learning Studio (classic)  <\/p>\n<p>What you can do until 1 December 2021  <br \/>\n-Creating new Machine Learning Studio (classic) experiments  <br \/>\n-Creating new Machine Learning Studio (classic) trained models  <br \/>\n-Creating a new Machine Learning Studio (classic) web service<\/p>",
        "Challenge_closed_time":1636209342128,
        "Challenge_comment_count":0,
        "Challenge_created_time":1636119906810,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/616952\/about-the-end-of-machine-learning-studio-(classic)",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":12.7,
        "Challenge_reading_time":10.93,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":24.8431438889,
        "Challenge_title":"About the end of Machine Learning Studio (classic)#2",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":126,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hi, customers will not be able to create new ML Studio(classic) workspaces after Dec 1, 2021. However, customers can create or update experiments\/web services in existing workspaces until Aug 31, 2024.<\/p>\n<hr \/>\n<p>--- *Kindly <em><strong>Accept Answer<\/strong><\/em> if the information helps. Thanks.*<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":9.8,
        "Solution_reading_time":3.94,
        "Solution_score_count":0.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":41.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1263294862568,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":183045.0,
        "Answerer_view_count":13691.0,
        "Challenge_adjusted_solved_time":0.0226744444,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I'm trying to build a machine learning model locally using AWS SageMaker, but I got a validation error on IAM Role name. Although it's the exact role name that I created on the console.<\/p>\n<p>This is my code<\/p>\n<pre><code>    import boto3\n    import sagemaker\n    from sagemaker import get_execution_role\n    from sagemaker.amazon.amazon_estimator import image_uris\n    from sagemaker.amazon.amazon_estimator import RecordSet\n\n    sess = sagemaker.Session()\n\n\n    bucket = sagemaker.Session().default_bucket()\n    prefix = 'sagemaker\/ccard19'\n\n    role ='arn:aws:iam::94911111111542:role\/SageMaker-Full-Access '\n\n    container = image_uris.retrieve('linear-learner',boto3.Session().region_name)\n    \n    # Some other code\n\n   linear = sagemaker.LinearLearner(role=role,\n                                               instance_count=1,\n                                               instance_type='ml.m4.xlarge',\n                                               predictor_type='binary_classifier')\n  \n  # Some other code\n\n  ### Fit the classifier\n  linear.fit([train_records,val_records,test_records], wait=True, logs='All')\n\n<\/code><\/pre>\n<p>And this is the error message<\/p>\n<pre><code>ClientError: An error occurred (ValidationException) when calling the CreateTrainingJob operation: 1 validation error detected: Value 'arn:aws:iam::949010940542:role\/SageMaker-Full-Access ' at 'roleArn' failed to satisfy constraint: Member must satisfy regular expression pattern: ^arn:aws[a-z\\-]*:iam::\\d{12}:role\/?[a-zA-Z_0-9+=,.@\\-_\/]+$\n<\/code><\/pre>\n<p>Any Help please?<\/p>",
        "Challenge_closed_time":1617256809808,
        "Challenge_comment_count":0,
        "Challenge_created_time":1617256728180,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/66899120",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":16.7,
        "Challenge_reading_time":19.05,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":13,
        "Challenge_solved_time":0.0226744444,
        "Challenge_title":"Validation error on Role name when running AWS SageMaker linear-learner locally",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":560.0,
        "Challenge_word_count":132,
        "Platform":"Stack Overflow",
        "Poster_created_time":1378039539503,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":340.0,
        "Poster_view_count":17.0,
        "Solution_body":"<p>You have <strong>space<\/strong> in the name. It should be:<\/p>\n<pre><code>role ='arn:aws:iam::94911111111542:role\/SageMaker-Full-Access'\n<\/code><\/pre>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":12.7,
        "Solution_reading_time":2.09,
        "Solution_score_count":0.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":12.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1436696527987,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":724.0,
        "Answerer_view_count":87.0,
        "Challenge_adjusted_solved_time":17.01314,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>As mentioned in step-3 of <a href=\"https:\/\/aws.amazon.com\/blogs\/machine-learning\/creating-a-machine-learning-powered-rest-api-with-amazon-api-gateway-mapping-templates-and-amazon-sagemaker\/\" rel=\"nofollow noreferrer\">this blog by AWS<\/a>, I have created a role to invoke sagemaker endpoint. But, when I deploy the API to a stage, I get &quot;AWS ARN for integration contains invalid action&quot; and I can't deploy the stage.\n<a href=\"https:\/\/i.stack.imgur.com\/maMdl.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/maMdl.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>blog suggested to select API Gateway under services and to keep on next, but didn't mention which policy will be attached. and also that another inline policy to invoke a specific sagemaker endpoint to be created and attached.\n<a href=\"https:\/\/i.stack.imgur.com\/uQwx0.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/uQwx0.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>and as mentioned in <a href=\"https:\/\/docs.aws.amazon.com\/apigateway\/latest\/developerguide\/integration-request-basic-setup.html\" rel=\"nofollow noreferrer\">AWS Docs<\/a>:<\/p>\n<blockquote>\n<p>It must also have API Gateway declared (in the role's trust\nrelationship) as a trusted entity to assume the role.<\/p>\n<\/blockquote>\n<p>my role also have the trust-relationshp:\n<a href=\"https:\/\/i.stack.imgur.com\/VJ9aU.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/VJ9aU.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>What's missing in my role that led to the error?<\/p>",
        "Challenge_closed_time":1645781417427,
        "Challenge_comment_count":3,
        "Challenge_created_time":1645719715780,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1645720170123,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/71255132",
        "Challenge_link_count":8,
        "Challenge_participation_count":4,
        "Challenge_readability":14.4,
        "Challenge_reading_time":22.18,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":13,
        "Challenge_solved_time":17.1393463889,
        "Challenge_title":"API Gateway + AWS SageMaker - AWS ARN for integration contains invalid action for integration with sagemaker",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":177.0,
        "Challenge_word_count":174,
        "Platform":"Stack Overflow",
        "Poster_created_time":1559910246180,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Bengaluru, Karnataka, India",
        "Poster_reputation_count":2046.0,
        "Poster_view_count":369.0,
        "Solution_body":"<p>Check in all your API methods that you haven't specified &quot;Use Action Name&quot; for any integration request, and then left the &quot;Action&quot; field blank. If you do the &quot;AWS ARN for integration contains invalid action&quot; error message will be shown.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/EXEnQ.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/EXEnQ.png\" alt=\"action type choice\" \/><\/a><\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":9.5,
        "Solution_reading_time":5.63,
        "Solution_score_count":1.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":49.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1391261341596,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":76.0,
        "Answerer_view_count":4.0,
        "Challenge_adjusted_solved_time":5196.6227847222,
        "Challenge_answer_count":4,
        "Challenge_body":"<p>I wants to create azure machine learning workspace using terraform scripts.Is there any terraform provider to achieve this.<\/p>",
        "Challenge_closed_time":1600285333648,
        "Challenge_comment_count":1,
        "Challenge_created_time":1581577491623,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/60202189",
        "Challenge_link_count":0,
        "Challenge_participation_count":5,
        "Challenge_readability":5.7,
        "Challenge_reading_time":2.72,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":2.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":5196.6227847222,
        "Challenge_title":"How to create azure machine learning resource using terraform resource providers?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":1152.0,
        "Challenge_word_count":28,
        "Platform":"Stack Overflow",
        "Poster_created_time":1565633099383,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":110.0,
        "Poster_view_count":12.0,
        "Solution_body":"<p>In the meantime Microsoft has added a Terraform resource for ML Workspace in the Azure Provider. This should make any custom scripting obsolete.<\/p>\n<p><a href=\"https:\/\/www.terraform.io\/docs\/providers\/azurerm\/r\/machine_learning_workspace.html\" rel=\"nofollow noreferrer\">https:\/\/www.terraform.io\/docs\/providers\/azurerm\/r\/machine_learning_workspace.html<\/a><\/p>\n<pre><code>resource &quot;azurerm_machine_learning_workspace&quot; &quot;example&quot; {\n  name                    = &quot;example-workspace&quot;\n  location                = azurerm_resource_group.example.location\n  resource_group_name     = azurerm_resource_group.example.name\n  application_insights_id = azurerm_application_insights.example.id\n  key_vault_id            = azurerm_key_vault.example.id\n  storage_account_id      = azurerm_storage_account.example.id\n\n  identity {\n    type = &quot;SystemAssigned&quot;\n  }\n}\n<\/code><\/pre>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":25.1,
        "Solution_reading_time":11.31,
        "Solution_score_count":4.0,
        "Solution_sentence_count":10.0,
        "Solution_word_count":46.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":1.0,
        "Answerer_isModerator":0.0,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":4.5602777778,
        "Challenge_answer_count":1,
        "Challenge_body":"Is there a way to attach a custom image to just the user (not the domain) in SageMaker Studio. \n\nDocumentation states 'To make a custom SageMaker image available to all users within a domain, you attach the image to the domain. To make an image available to a single user, you attach the image to the user's profile.'\nhttps:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/studio-byoi.html \n\nWhen I 'edit user', I dont see a way to attach a custom image. Is there a way to do this?",
        "Challenge_closed_time":1607593010000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1607576593000,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1668514383580,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUhP1jmxpAQi6X0eDIUI2JKA\/attaching-custom-image-to-user-not-domain-in-sagemaker-studio",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":9.1,
        "Challenge_reading_time":6.55,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":4.5602777778,
        "Challenge_title":"Attaching custom image to user (not domain) in SageMaker Studio",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":328.0,
        "Challenge_word_count":89,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"You can attach custom images to user profiles via the APIs to create\/update user profiles.\n\nMore info:\n\nhttps:\/\/docs.aws.amazon.com\/sagemaker\/latest\/APIReference\/API_CreateUserProfile.html\nhttps:\/\/docs.aws.amazon.com\/sagemaker\/latest\/APIReference\/API_UpdateUserProfile.html",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1612932017912,
        "Solution_link_count":2.0,
        "Solution_readability":27.1,
        "Solution_reading_time":3.72,
        "Solution_score_count":1.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":19.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1324988509368,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Moscow, Russia",
        "Answerer_reputation_count":1593.0,
        "Answerer_view_count":93.0,
        "Challenge_adjusted_solved_time":0.0671325,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have deployed an Endpoint on Amazon SageMaker.\nNow I am trying to Invoke it.<\/p>\n\n<p>If I run this code in Sagemaker's Jupyter Notebook: <\/p>\n\n<pre><code>client = boto3.client('sagemaker-runtime')\nendpoint_name = 'DEMO-XGBoostEndpoint'\nbody = ','.join(['1.0'] * 6)\nresponse = client.invoke_endpoint(EndpointName=endpoint_name,\n                               ContentType='text\/csv',\n                               Body=body)\nresponse['Body'].read()\n<\/code><\/pre>\n\n<p>it works properly.<\/p>\n\n<p>But if I run the same code, with added credentials for boto3 client, from my machine:<\/p>\n\n<pre><code>client = boto3.client('sagemaker-runtime', \n                       aws_access_key_id=ACCESS_ID,\n                       aws_secret_access_key= ACCESS_KEY)\nendpoint_name = 'DEMO-XGBoostEndpoint'\nbody = ','.join(['1.0'] * 6)\nresponse = client.invoke_endpoint(EndpointName=endpoint_name,\n                               ContentType='text\/csv',\n                               Body=body)\nresponse['Body'].read()\n<\/code><\/pre>\n\n<p>I get this error:<\/p>\n\n<blockquote>\n  <p>ClientError: An error occurred (AccessDeniedException) when calling the InvokeEndpoint operation: User: arn:aws:iam::249707424405:user\/yury.logachev is not authorized to perform: sagemaker:InvokeEndpoint on resource: arn:aws:sagemaker:us-east-1:249707424405:endpoint\/demo-xgboostendpoint-2018-12-12-22-07-28 with an explicit deny<\/p>\n<\/blockquote>\n\n<p>If I run the latter piece of code (with added credentials as a parameters of client) on Sagemaker's Jupyter Notebook, I also get the same error.<\/p>\n\n<p>I understand that the solution should be linked with roles, policies etc, but could not find out it.<\/p>",
        "Challenge_closed_time":1547664263500,
        "Challenge_comment_count":0,
        "Challenge_created_time":1547411152043,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1547664021823,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/54172907",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":12.0,
        "Challenge_reading_time":20.7,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":15,
        "Challenge_solved_time":70.3087380556,
        "Challenge_title":"Amazon Sagemaker. AccessDeniedException when calling the InvokeEndpoint operation",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":2435.0,
        "Challenge_word_count":155,
        "Platform":"Stack Overflow",
        "Poster_created_time":1324988509368,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Moscow, Russia",
        "Poster_reputation_count":1593.0,
        "Poster_view_count":93.0,
        "Solution_body":"<p>The problem was with the MFA autharization. \nWhen I invoked the model from inside the model, the MFA was passed. \nBut when I tried to invoke the model from my machine, the MFA was not passed, so the access was denied.<\/p>\n\n<p>I created special user without MFA to debug the model, and that solved my problem.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":6.4,
        "Solution_reading_time":3.78,
        "Solution_score_count":1.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":56.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":0.4124352778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am using Azure ML for real-time machine learning. I have installed the Kafka server, but I am having a connection issue when trying to create a topic using the below line of code. I received the following warning: WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost\/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient). I appreciate your help.<\/p>\n<pre><code>!.\/kafka_2.13-3.3.2\/bin\/kafka-topics.sh --create --topic amids-train --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1\n<\/code><\/pre>",
        "Challenge_closed_time":1680844061480,
        "Challenge_comment_count":0,
        "Challenge_created_time":1680842576713,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1202024\/azure-ml-and-kafka-server-connection-issue",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":9.5,
        "Challenge_reading_time":8.31,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":8,
        "Challenge_solved_time":0.4124352778,
        "Challenge_title":"Azure ML and Kafka Server Connection Issue",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":78,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hi Ghada,\nThe warning message you received suggests that the Kafka broker may not be available or is not running on the specified address and port.\nHere are some steps you can follow to troubleshoot the issue:<\/p>\n<ol>\n<li> Verify that the Kafka broker is running: You can check if the Kafka broker is running by using the following command in a new terminal window:\n    .\/kafka_2.13-3.3.2\/bin\/kafka-server-start.sh .\/kafka_2.13-3.3.2\/config\/server.properties<\/li>\n<li> Verify that the address and port are correct: Make sure that the address and port specified in the <strong><code>bootstrap-server<\/code><\/strong> parameter are correct and that there are no firewall or network configuration issues preventing you from connecting to the broker.<\/li>\n<li> Check the Kafka logs for errors: Check the Kafka logs to see if there are any error messages that could help identify the issue. You can find the Kafka logs in the <strong><code>logs<\/code><\/strong> directory of your Kafka installation.<\/li>\n<li> Try using a different topic name: It's possible that the topic name you're using is already in use or is invalid. Try using a different topic name to see if that resolves the issue.<\/li>\n<\/ol>\n<p>I hope these steps help you resolve the issue. Let me know if you have any further questions!<\/p>\n",
        "Solution_comment_count":5.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":10.8,
        "Solution_reading_time":16.11,
        "Solution_score_count":1.0,
        "Solution_sentence_count":9.0,
        "Solution_word_count":200.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":0.3468794445,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I want to connect my MSA with my certification profile.    <\/p>\n<p>My MSA is julia.loef<a href=\"\/users\/na\/?userid=ff0fe430-0000-0006-0000-000000000000\">@Karima ben  <\/a>.com and my work account is julia.loef-bleiksch@nl.abnamro.com    <\/p>\n<p>Can you please help me with this?<\/p>",
        "Challenge_closed_time":1661435443443,
        "Challenge_comment_count":0,
        "Challenge_created_time":1661434194677,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/981835\/a-request-to-change-the-personal-account-(msa)-ass",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":8.5,
        "Challenge_reading_time":4.72,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":0.3468794445,
        "Challenge_title":"a request to change the personal account (MSA) associated with my Certification profile",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":44,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hi <a href=\"\/users\/na\/?userid=75eb21e6-d923-4b38-8134-7fa8e68a193a\">@Julia Loef-Bleiksch  <\/a>     <\/p>\n<p>Please post this on Microsoft Certifications forum found at <a href=\"https:\/\/trainingsupport.microsoft.com\/en-us\/mcp\">https:\/\/trainingsupport.microsoft.com\/en-us\/mcp<\/a> and someone will gladly assist.    <\/p>\n<p>Unfortunately MS Certifications is not supported on this forum.    <\/p>\n<p>If this was helpful please accept answer.<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":13.5,
        "Solution_reading_time":5.77,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":40.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1631803441500,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"mexico",
        "Answerer_reputation_count":1258.0,
        "Answerer_view_count":685.0,
        "Challenge_adjusted_solved_time":28.3038852778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have been using <a href=\"https:\/\/github.com\/GoogleCloudPlatform\/mlops-with-vertex-ai\/blob\/main\/08-model-monitoring.ipynb\" rel=\"nofollow noreferrer\">this<\/a> example of creating a Vertex AI monitoring job. It sends an email.<\/p>\n<pre><code>alerting_config = vertex_ai_beta.ModelMonitoringAlertConfig(\nemail_alert_config=vertex_ai_beta.ModelMonitoringAlertConfig.EmailAlertConfig(\n    user_emails=NOTIFY_EMAILS\n)\n<\/code><\/pre>\n<p>Is there any way to instead send a Pubsub message?<\/p>",
        "Challenge_closed_time":1660246628340,
        "Challenge_comment_count":1,
        "Challenge_created_time":1660144734353,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/73308825",
        "Challenge_link_count":1,
        "Challenge_participation_count":2,
        "Challenge_readability":18.1,
        "Challenge_reading_time":7.49,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":28.3038852778,
        "Challenge_title":"Can Vertex AI model monitoring job send a pubsub message instead of email?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":86.0,
        "Challenge_word_count":47,
        "Platform":"Stack Overflow",
        "Poster_created_time":1351154914716,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":2564.0,
        "Poster_view_count":451.0,
        "Solution_body":"<p>You can configure the <a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/model-monitoring\/using-model-monitoring#set-up-alerts\" rel=\"nofollow noreferrer\">alert to be sent to Cloud Logging<\/a>. To enable Cloud Logging alerts you have to set the <code>enableLogging<\/code> field on your <code>ModelMonitoringAlertConfig<\/code> configuration to <code>TRUE<\/code>. Then you can forward the logs to any service that Cloud Logging supports, Pub\/Sub is one of these.<\/p>\n<p>For this you\u2019ll need one of the following permissions:<\/p>\n<ul>\n<li>Owner (roles\/owner)<\/li>\n<li>Logging Admin (roles\/logging.admin)<\/li>\n<li>Logs Configuration Writer (roles\/logging.configWriter)<\/li>\n<\/ul>\n<p>Then you need to <a href=\"https:\/\/cloud.google.com\/logging\/docs\/export\/configure_export_v2#creating_sink\" rel=\"nofollow noreferrer\">create a sink<\/a>.<\/p>\n<p>After that you have created the sink you\u2019ll need to set the <a href=\"https:\/\/cloud.google.com\/logging\/docs\/export\/configure_export_v2#dest-auth\" rel=\"nofollow noreferrer\">destination permissions<\/a>.<\/p>\n<p>While Cloud Logging provides you with the ability to exclude logs from being ingested, you might want to consider keeping logs that help with supportability. Using these logs can help you quickly troubleshoot and identify issues with your applications.<\/p>\n<p>Logs routed to Pub\/Sub are generally available within seconds, with 99% of logs available in less than 60 seconds.<\/p>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":3.0,
        "Solution_readability":12.7,
        "Solution_reading_time":18.63,
        "Solution_score_count":2.0,
        "Solution_sentence_count":13.0,
        "Solution_word_count":155.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":29.6355555556,
        "Challenge_answer_count":1,
        "Challenge_body":"**Describe the bug**\r\nThere are several areas in the code where we have an explicit check for the `neptune.amazonaws.com` DNS suffix; this is used to determine if we need to use Neptune-specific configuration options and request URI elements. \r\n\r\nHowever, these checks misidentify endpoints of Neptune clusters in AWS CN regions, which use the `neptune.<region>.amazonaws.com.cn` DNS suffix instead, as non-AWS endpoints. As a result, required config options such as `auth_mode` and `region` are not set correctly.\r\n\r\nAll of the following checks need to be changed to \"amazonaws.com\":\r\nhttps:\/\/github.com\/aws\/graph-notebook\/blob\/a5818452d152ba51b7f7e26b6cf8e188dca54693\/src\/graph_notebook\/magics\/graph_magic.py#L160\r\nhttps:\/\/github.com\/aws\/graph-notebook\/blob\/a5818452d152ba51b7f7e26b6cf8e188dca54693\/src\/graph_notebook\/neptune\/client.py#L129\r\nhttps:\/\/github.com\/aws\/graph-notebook\/blob\/a5818452d152ba51b7f7e26b6cf8e188dca54693\/src\/graph_notebook\/configuration\/generate_config.py#L54\r\nhttps:\/\/github.com\/aws\/graph-notebook\/blob\/68e888def530be70e08b5250c8146292fb49cfa1\/src\/graph_notebook\/configuration\/get_config.py#L14",
        "Challenge_closed_time":1635986654000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1635879966000,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/github.com\/aws\/graph-notebook\/issues\/222",
        "Challenge_link_count":4,
        "Challenge_participation_count":1,
        "Challenge_readability":18.5,
        "Challenge_reading_time":16.11,
        "Challenge_repo_contributor_count":22.0,
        "Challenge_repo_fork_count":115.0,
        "Challenge_repo_issue_count":411.0,
        "Challenge_repo_star_count":500.0,
        "Challenge_repo_watch_count":33.0,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":29.6355555556,
        "Challenge_title":"Configuration options not being set correctly when using CN region Neptune endpoint as host",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":103,
        "Platform":"Github",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"Resolved as of release 3.0.8",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":2.9,
        "Solution_reading_time":0.35,
        "Solution_score_count":0.0,
        "Solution_sentence_count":1.0,
        "Solution_word_count":5.0,
        "Tool":"Neptune"
    },
    {
        "Answerer_created_time":1440323757107,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":424.0,
        "Answerer_view_count":28.0,
        "Challenge_adjusted_solved_time":1.0847583334,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Does anybody install DVC on MinIO storage?<\/p>\n<p>I have read <a href=\"https:\/\/dvc.org\/doc\/command-reference\/remote\/modify#available-parameters-per-storage-type\" rel=\"nofollow noreferrer\">docs<\/a> but not all clear for me.<\/p>\n<p>Which command should I use for setup MinIO storage with this entrance parameters:<\/p>\n<p>storage url: <a href=\"https:\/\/minio.mysite.com\/minio\/bucket-name\/\" rel=\"nofollow noreferrer\">https:\/\/minio.mysite.com\/minio\/bucket-name\/<\/a>\nlogin: my_login\npassword: my_password<\/p>",
        "Challenge_closed_time":1621599285543,
        "Challenge_comment_count":0,
        "Challenge_created_time":1621595380413,
        "Challenge_favorite_count":1.0,
        "Challenge_last_edit_time":1621622008696,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/67635688",
        "Challenge_link_count":3,
        "Challenge_participation_count":1,
        "Challenge_readability":14.2,
        "Challenge_reading_time":7.23,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":5.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":1.0847583334,
        "Challenge_title":"Installation DVC on MinIO storage",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":1547.0,
        "Challenge_word_count":47,
        "Platform":"Stack Overflow",
        "Poster_created_time":1526481416047,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":85.0,
        "Poster_view_count":5.0,
        "Solution_body":"<p><strong>Install<\/strong><\/p>\n<p>I usually use it as a Python package, int this case you need to install:<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>pip install &quot;dvc[s3]&quot;\n<\/code><\/pre>\n<p><strong>Setup remote<\/strong><\/p>\n<p>By default DVC supports AWS S3 storages and they work fine.<br \/>\nAlso they support &quot;S3-compatible storage&quot;, but setup for this type of remotes is nod described properly. In particular case of MinIO you have <strong>bucket<\/strong> - directory on MinIO server where actual data stores (it is similar to AWS bucket), but DVC uses AWS CLI to authenticate. In case of MinIO you need to pass them explicitly.<\/p>\n<p>Then follow commands to setup your DVC remote:<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code># setup default remote (change &quot;bucket-name&quot; to your minio backet name)\ndvc remote add -d minio s3:\/\/bucket-name -f\n\n# add information about storage url (where &quot;https:\/\/minio.mysite.com&quot; your url)\ndvc remote modify minio endpointurl https:\/\/minio.mysite.com\n\n#  add info about login and password\ndvc remote modify minio access_key_id my_login\ndvc remote modify minio secret_access_key my_password\n<\/code><\/pre>\n<p><strong>If you move from old remote<\/strong>, use follow command to move your data:<\/p>\n<p>Before setup (download all old remote cache to local machine):<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>dvc pull -r &lt;old_remote_name&gt; --all-commits --all-tags --all-branches\n<\/code><\/pre>\n<p>After setup (upload all cache to a new remote):<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>dvc push -r &lt;new_remote_name&gt; --all-commits --all-tags --all-branches\n<\/code><\/pre>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":17.0,
        "Solution_reading_time":21.73,
        "Solution_score_count":6.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":204.0,
        "Tool":"DVC"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":3.9460580556,
        "Challenge_answer_count":5,
        "Challenge_body":"<p>I am trying to connect to my Azure ML workspace using SDK for python, using Virtual Studio Code to do so. After pip installing the needed SDK packages:    <br \/>\n    pip install azureml-sdk  <br \/>\n    pip install azureml-sdk[notebooks,automl,explain]  <\/p>\n<p>I downloaded the .json configuration file for my workspace, made sure it was in the correct location for the file path and tried the following code (with my subscription id, resource group and workspace name in place of the fillers in this chunk of code):    <\/p>\n<pre><code>{  \n    &quot;subscription_id&quot;: &quot;1234567-abcde-890-fgh...&quot;,  \n    &quot;resource_group&quot;: &quot;aml-resources&quot;,  \n    &quot;workspace_name&quot;: &quot;aml-workspace&quot;  \n}  \n<\/code><\/pre>\n<p>Upon executing this in my ipy kernel in Virutal Studio Code I got a UserErrorException (see image below, I have blocked out subscription id's and other sensitive information):    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/41683-subscriptionerror.png?platform=QnA\" alt=\"41683-subscriptionerror.png\" \/>    <\/p>\n<p>I then tried this alternative way to connect to my workspace using the following code (again with my info filled in instead of the fillers in the code):    <br \/>\n    from azureml.core import Workspace  <\/p>\n<pre><code>from azureml.core import Workspace  \n  \nws = Workspace.get(name='aml-workspace',  \n                   subscription_id='1234567-abcde-890-fgh...',  \n                   resource_group='aml-resources')  \n  \nws = Workspace.from_config()  \n<\/code><\/pre>\n<p>This produced the same error upon execution. I have tried using different subscriptions with different workspace names and resource groups and it gives me the same error every time. It appears to be telling me I do not have access to the subscription that I am logged in to? I am unsure how to fix this. I am trying to do this as part of the lessons in the Microsoft Azure Data Scientist certification if anyone is familiar with that or has run into the same problem while trying to complete the modules for that certification provided through Microsoft.     <\/p>",
        "Challenge_closed_time":1606097262372,
        "Challenge_comment_count":0,
        "Challenge_created_time":1606083056563,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/171465\/problems-connecting-to-workspace-using-azure-machi",
        "Challenge_link_count":1,
        "Challenge_participation_count":5,
        "Challenge_readability":11.1,
        "Challenge_reading_time":26.68,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":14,
        "Challenge_solved_time":3.9460580556,
        "Challenge_title":"Problems connecting to workspace using Azure Machine Learning SDK for Python",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":279,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>can you try using InteractiveLoginAuthentication?  <\/p>\n<p>below code might help you  <\/p>\n<pre><code>from azureml.core.authentication import InteractiveLoginAuthentication\nia = InteractiveLoginAuthentication(tenant_id='YourTenant id')\n# You can find tenant id under azure active directory-&gt;properties\nws = Workspace.get(name='aml-workspace',\n                    subscription_id='1234567-abcde-890-fgh...',\n                    resource_group='aml-resources',auth=ia)\n<\/code><\/pre>\n",
        "Solution_comment_count":2.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":21.7,
        "Solution_reading_time":6.01,
        "Solution_score_count":3.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":33.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":13.2357005556,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have created a machine learning workspace in West Europe region. But the storage account, key vault and application insights got created in East US region. All these got created by default with creation on ML workspace.  <br \/>\nSo I want to know the reason for different region and also want to move the storage account to West Europe region.<\/p>",
        "Challenge_closed_time":1613167744632,
        "Challenge_comment_count":0,
        "Challenge_created_time":1613120096110,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/270693\/why-the-storage-account-assosiated-to-azure-machin",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":7.9,
        "Challenge_reading_time":5.63,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":13.2357005556,
        "Challenge_title":"Why the storage account assosiated to azure machine learning has differenent region compared ML workspace?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":74,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hi, this is unusual. There's no way to move your default AML storage account to a different region. I recommend creating a new workspace or contacting <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/azure-portal\/supportability\/how-to-create-azure-support-request\">Azure Support<\/a> to investigate further.    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":13.6,
        "Solution_reading_time":4.14,
        "Solution_score_count":0.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":33.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1459546601027,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"United Kingdom",
        "Answerer_reputation_count":2300.0,
        "Answerer_view_count":217.0,
        "Challenge_adjusted_solved_time":72.7501658334,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have developed different Athena Workgroups for different teams so that I can separate their queries and their query results. The users would like to query the tables available to them from their notebook instances (JupyterLab). I am having difficulty finding code which successfully covers the requirement of querying a table from the user's specific workgroup. I have only found code that will query the table from the primary workgroup. <\/p>\n\n<p>The code I have currently used is added below. <\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from pyathena import connect\nimport pandas as pd\nconn = connect(s3_staging_dir='&lt;ATHENA QUERY RESULTS LOCATION&gt;',\nregion_name='&lt;YOUR REGION, for example, us-west-2&gt;')\n\n\ndf = pd.read_sql(\"SELECT * FROM &lt;DATABASE-NAME&gt;.&lt;YOUR TABLE NAME&gt; limit 8;\", conn)\ndf\n<\/code><\/pre>\n\n<p>This code does not work as the users only have access to perform queries from their specific workgroups hence get errors when this code is run. It also does not cover the requirement of separating the user's queries in user specific workgroups. <\/p>\n\n<p>Any suggestions on how I can add alter the code so that I can run the queries within a specific workgroup from the notebook instance?<\/p>",
        "Challenge_closed_time":1565963773252,
        "Challenge_comment_count":2,
        "Challenge_created_time":1565704743610,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/57479389",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":10.0,
        "Challenge_reading_time":16.22,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":11,
        "Challenge_solved_time":71.9526783333,
        "Challenge_title":"Query a table\/database in Athena from a Notebook instance",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":5367.0,
        "Challenge_word_count":188,
        "Platform":"Stack Overflow",
        "Poster_created_time":1411838896900,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":105.0,
        "Poster_view_count":40.0,
        "Solution_body":"<p>Documentation of <code>pyathena<\/code> is not super extensive, but after looking into source code we can see that <code>connect<\/code> simply creates instance of <code>Connection<\/code> class.<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>def connect(*args, **kwargs):\n    from pyathena.connection import Connection\n    return Connection(*args, **kwargs)\n<\/code><\/pre>\n\n<p>Now, after looking into signature of <code>Connection.__init__<\/code> on <a href=\"https:\/\/github.com\/laughingman7743\/PyAthena\/blob\/master\/pyathena\/connection.py\" rel=\"nofollow noreferrer\">GitHub<\/a> we can see parameter <code>work_group=None<\/code> which name in the same way as one of the parameters for <code>start_query_execution<\/code> from the <a href=\"https:\/\/boto3.amazonaws.com\/v1\/documentation\/api\/latest\/reference\/services\/athena.html#Athena.Client.start_query_execution\" rel=\"nofollow noreferrer\">official<\/a> AWS Python API <code>boto3<\/code>. Here is what their documentation say about it:<\/p>\n\n<blockquote>\n  <p>WorkGroup (string) -- The name of the workgroup in which the query is being started.<\/p>\n<\/blockquote>\n\n<p>After following through usages and imports in <code>Connection<\/code> we endup with <a href=\"https:\/\/github.com\/laughingman7743\/PyAthena\/blob\/master\/pyathena\/common.py\" rel=\"nofollow noreferrer\">BaseCursor<\/a> class that under the hood makes a call to <code>start_query_execution<\/code> while unpacking a dictionary with parameters assembled by <code>BaseCursor._build_start_query_execution_request<\/code> method. That is excatly where we can see familar syntax for submitting queries to AWS Athena, in particular the following part:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>if self._work_group or work_group:\n    request.update({\n        'WorkGroup': work_group if work_group else self._work_group\n    })\n<\/code><\/pre>\n\n<p>So this should do a trick for your case:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import pandas as pd\nfrom pyathena import connect\n\n\nconn = connect(\n    s3_staging_dir='&lt;ATHENA QUERY RESULTS LOCATION&gt;',\n    region_name='&lt;YOUR REGION, for example, us-west-2&gt;',\n    work_group='&lt;USER SPECIFIC WORKGROUP&gt;'\n)\n\ndf = pd.read_sql(\"SELECT * FROM &lt;DATABASE-NAME&gt;.&lt;YOUR TABLE NAME&gt; limit 8;\", conn)\n<\/code><\/pre>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1565966644207,
        "Solution_link_count":3.0,
        "Solution_readability":15.9,
        "Solution_reading_time":29.82,
        "Solution_score_count":3.0,
        "Solution_sentence_count":15.0,
        "Solution_word_count":213.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1270568377790,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Philadelphia",
        "Answerer_reputation_count":13056.0,
        "Answerer_view_count":354.0,
        "Challenge_adjusted_solved_time":1.5477955556,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am using AWS sagemaker, I have some secret keys and access keys to access some APIs that I don't want to expose directly in code.<\/p>\n<p>What are the ways like environment variables etc., that can be used to hide these keys and I can use them securely, and how to set them.<\/p>",
        "Challenge_closed_time":1625064328872,
        "Challenge_comment_count":0,
        "Challenge_created_time":1625052591003,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1625058756808,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/68193944",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":5.4,
        "Challenge_reading_time":3.89,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":3.2605191667,
        "Challenge_title":"Set custom environment variables in AWS",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":277.0,
        "Challenge_word_count":58,
        "Platform":"Stack Overflow",
        "Poster_created_time":1567880532003,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Lahore, Pakistan",
        "Poster_reputation_count":137.0,
        "Poster_view_count":100.0,
        "Solution_body":"<p>AWS System Manager (SSM) is designed to store keys and tokens securely.<\/p>\n<p>Depending on how your notebook is defined, you could <a href=\"https:\/\/sagemaker.readthedocs.io\/en\/stable\/api\/training\/processing.html\" rel=\"nofollow noreferrer\">use the 'env' property<\/a> directly or in <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/your-algorithms-training-algo-running-container.html#your-algorithms-training-algo-running-container-environment-variables\" rel=\"nofollow noreferrer\">training data<\/a>, or you could access SSM directly from sagemaker. For example this Snowflake KB article explains how to fetch auth info from ssm: <a href=\"https:\/\/community.snowflake.com\/s\/article\/Connecting-a-Jupyter-Notebook-Part-3\" rel=\"nofollow noreferrer\">https:\/\/community.snowflake.com\/s\/article\/Connecting-a-Jupyter-Notebook-Part-3<\/a><\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":4.0,
        "Solution_readability":23.8,
        "Solution_reading_time":11.46,
        "Solution_score_count":1.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":62.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":21.5217911111,
        "Challenge_answer_count":4,
        "Challenge_body":"<p>I have a project \u201cfoo\u201d on my personal wandb account (entity \u201cuser\u201d). However, I am also a member of a team (\u201cteam\u201d). When I try to sync an offline run using <code>wandb sync path\/to\/foo\/run<\/code>, I want it to be saved in project \u201cfoo\u201d on my personal account. However, wandb creates a new project \u201cfoo\u201d that is owned by \u201cteam\u201d.<\/p>\n<p>Is there any way I can fix this? Do I need to change the way I\u2019m logged in to my wandb account? wandb says that I am logged in as <code>user (team)<\/code>, but I\u2019m not sure how to change that.<\/p>",
        "Challenge_closed_time":1683034536819,
        "Challenge_comment_count":0,
        "Challenge_created_time":1682957058371,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/wandb-sync-confusing-personal-project-for-team-project\/4315",
        "Challenge_link_count":0,
        "Challenge_participation_count":4,
        "Challenge_readability":4.9,
        "Challenge_reading_time":7.12,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":8,
        "Challenge_solved_time":21.5217911111,
        "Challenge_title":"Wandb sync confusing personal project for team project",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":75.0,
        "Challenge_word_count":106,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hi <a class=\"mention\" href=\"\/u\/adamoyoung\">@adamoyoung<\/a> thanks for reporting this issue. Could you please provide the <code>--entity<\/code> and <code>--project<\/code> arguments as follows:<br>\n<code>wandb sync -e personal -p foo path\/to\/foo\/run<\/code><\/p>\n<p>Would this work for you? There\u2019s a <code>Project Defaults<\/code> section in your <a href=\"https:\/\/wandb.ai\/settings\">personal settings page<\/a> where this in your case seems to be configured for your team entity. You may change that if you wanted the default to be your personal account.<\/p>",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":9.9,
        "Solution_reading_time":7.15,
        "Solution_score_count":null,
        "Solution_sentence_count":5.0,
        "Solution_word_count":70.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":1.0,
        "Answerer_isModerator":0.0,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":9.3446652778,
        "Challenge_answer_count":1,
        "Challenge_body":"Hi Friends,\n\nI have deleted everything in Sagemaker - but support is asking me to delete the experiments that are still in my account : they sent me a link to follow\n\nhttps:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/experiments-cleanup.html\n\nbut I have no idea how to complete this task -- does anyone know in terms that someone who has no idea what this means - can follow and achieve this task\n\nyou have no idea how much it would mean to me for any assistance",
        "Challenge_closed_time":1668070837516,
        "Challenge_comment_count":0,
        "Challenge_created_time":1668037196721,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1668612841943,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUFMzl26gfQna8sAZcCDJw_Q\/sagemaker-experiments-deletion-help-needed",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":12.4,
        "Challenge_reading_time":6.13,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":9.3446652778,
        "Challenge_title":"SageMaker Experiments Deletion Help Needed",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":89.0,
        "Challenge_word_count":79,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"You need to use a computer with Python, the SageMaker SDK installed, and AWS credentials with enough permissions for that account configured. If you are already using SageMaker Studio, that should work.\n\nUse the [second method](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/experiments-cleanup.html#experiments-cleanup-boto3). Create a file (Menu File -> New -> Python File). Rename it as  `cleanup_experiments.py`(right click on the file on top and select Rename Python File), then paste the code in the documentation (those three sections, one after another). Save the file and open a terminal (Menu File -> New -> Terminal). Navigate to the directory where you saved the file and execute the command `python cleanup_experiments.py`",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":1668129579400,
        "Solution_link_count":1.0,
        "Solution_readability":9.3,
        "Solution_reading_time":9.3,
        "Solution_score_count":1.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":98.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1572449042430,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Germany",
        "Answerer_reputation_count":2082.0,
        "Answerer_view_count":238.0,
        "Challenge_adjusted_solved_time":2.8597922222,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>The entire error message after executing <code>terraform apply<\/code> within the terraform-folder of <a href=\"https:\/\/github.com\/AndreasLuckert\/aws-sm-notebook-instance\" rel=\"nofollow noreferrer\">this source code in my GitHub-repo<\/a> (inspired by <a href=\"https:\/\/www.linkedin.com\/pulse\/terraform-sagemaker-part-2a-creating-custom-notebook-instance-david\" rel=\"nofollow noreferrer\">this tutorial<\/a> and <a href=\"https:\/\/github.com\/dkhundley\/terraform-sagemaker-tutorial\" rel=\"nofollow noreferrer\">its related GitHub-repo<\/a>):<\/p>\n<pre><code>aws_sagemaker_notebook_instance.notebook_instance: Creating...\naws_sagemaker_notebook_instance.notebook_instance: Still creating... [10s elapsed]\naws_sagemaker_notebook_instance.notebook_instance: Still creating... [20s elapsed]\n...\naws_sagemaker_notebook_instance.notebook_instance: Still creating... [15m21s elapsed]\naws_sagemaker_notebook_instance.notebook_instance: Still creating... [15m31s elapsed]\n\u2577\n\u2502 Error: error waiting for sagemaker notebook instance (aws-sm-notebook-instance) to create: unexpected state 'Failed', wanted target 'InService'. last error: %!s(&lt;nil&gt;)\n\u2502\n\u2502   with aws_sagemaker_notebook_instance.notebook_instance,\n\u2502   on notebook_instance.tf line 2, in resource &quot;aws_sagemaker_notebook_instance&quot; &quot;notebook_instance&quot;:\n\u2502    2: resource &quot;aws_sagemaker_notebook_instance&quot; &quot;notebook_instance&quot; {\n\u2502\n<\/code><\/pre>\n<p>Internet research seemed to provide the solution in <a href=\"https:\/\/yuyasugano.medium.com\/machine-learning-infrastructure-terraforming-sagemaker-part-2-f2460a9a4663\" rel=\"nofollow noreferrer\">this article<\/a>, which inspired be to increase the allowed <code>IDLE_TIME<\/code> in the <code>on-start.sh<\/code> - script to <code>IDLE_TIME=1800<\/code> (in seconds, which equals 30 minutes). This should've been sufficient for the deployment time of around 15 minutes; yet, it threw the same error again.<\/p>\n<p>Next, I found <a href=\"https:\/\/stackoverflow.com\/questions\/65884743\/resolving-broken-deleted-state-in-terraform\">this post on StackOverFlow<\/a> suggesting to<\/p>\n<blockquote>\n<p>run <code>terraform refresh<\/code>, which will cause Terraform to refresh its state\nfile against what actually exists with the cloud provider.<\/p>\n<\/blockquote>\n<p>Unfortunately, running <code>terraform apply<\/code> right after refreshing didn't resolve the issue either.\nI'm wondering why the aforementioned <code>IDLE_TIME=1800<\/code> - setting does not have any effect. This should be more than sufficient for a 15-minute apply-time.<\/p>\n<hr \/>\n<p><strong>EDIT: adding code specifics for enhanced understanding<\/strong><\/p>\n<p><strong>1. Creating the SageMaker notebook instance<\/strong><\/p>\n<pre><code>resource &quot;aws_sagemaker_notebook_instance&quot; &quot;notebook_instance&quot; {\n  name                    = &quot;aws-sm-notebook-instance&quot;\n  role_arn                = aws_iam_role.notebook_iam_role.arn\n  instance_type           = &quot;ml.t2.medium&quot;\n  lifecycle_config_name   = aws_sagemaker_notebook_instance_lifecycle_configuration.notebook_config.name\n  default_code_repository = aws_sagemaker_code_repository.git_repo.code_repository_name\n}\n<\/code><\/pre>\n<p><strong>2. Defining the SageMaker notebook lifecycle configuration<\/strong><\/p>\n<pre><code>resource &quot;aws_sagemaker_notebook_instance_lifecycle_configuration&quot; &quot;notebook_config&quot; {\n  name      = &quot;dev-platform-al-sm-lifecycle-config&quot;\n  on_create = filebase64(&quot;..\/scripts\/on-create.sh&quot;)\n  on_start  = filebase64(&quot;..\/scripts\/on-start.sh&quot;)\n}\n<\/code><\/pre>\n<p><strong>3. Defining the Git repo to instantiate on the SageMaker notebook instance<\/strong><\/p>\n<pre><code>resource &quot;aws_sagemaker_code_repository&quot; &quot;git_repo&quot; {\n  code_repository_name = &quot;aws-sm-notebook-instance-repo&quot;\n\n  git_config {\n    repository_url = &quot;https:\/\/github.com\/AndreasLuckert\/aws-sm-notebook-instance.git&quot;\n  }\n}\n<\/code><\/pre>\n<p><strong>Contents of <code>on-start.sh<\/code> (including IDLE_TIME - parameter)<\/strong>\nNote that this script will be invoked by the <code>scripts\/autostop.py<\/code> - script, which you can find <a href=\"https:\/\/github.com\/AndreasLuckert\/aws-sm-notebook-instance\/blob\/main\/scripts\/autostop.py\" rel=\"nofollow noreferrer\">here<\/a> in the associated <a href=\"https:\/\/github.com\/AndreasLuckert\/aws-sm-notebook-instance\" rel=\"nofollow noreferrer\">public repo containing the source code<\/a>.<\/p>\n<pre><code>#!\/bin\/bash\n\nset -e\n\n## IDLE AUTOSTOP STEPS\n## ----------------------------------------------------------------\n\n## Setting the timeout (in seconds) for how long the SageMaker notebook can run idly before being auto-stopped\n# -&gt; e.g. 1800 s = 30 min since first deployment can take between 15 and 20 minutes which could then fail like so:\n# &quot;Error: error waiting for sagemaker notebook instance (aws-sm-notebook-instance) to create: unexpected state 'Failed', wanted target 'InService'. last error: %!s(&lt;nil&gt;)&quot;\n# Hint for solution under following link: https:\/\/yuyasugano.medium.com\/machine-learning-infrastructure-terraforming-sagemaker-part-2-f2460a9a4663\nIDLE_TIME=1800\n\n# Getting the autostop.py script from GitHub\necho &quot;Fetching the autostop script...&quot;\nwget https:\/\/raw.githubusercontent.com\/andreasluckert\/aws-sm-notebook-instance\/main\/scripts\/autostop.py\n\n# Using crontab to autostop the notebook when idle time is breached\necho &quot;Starting the SageMaker autostop script in cron.&quot;\n(crontab -l 2&gt;\/dev\/null; echo &quot;*\/5 * * * * \/usr\/bin\/python $PWD\/autostop.py --time $IDLE_TIME --ignore-connections&quot;) | crontab -\n\n\n\n## CUSTOM CONDA KERNEL USAGE STEPS\n## ----------------------------------------------------------------\n\n# Setting the proper user credentials\nsudo -u ec2-user -i &lt;&lt;'EOF'\nunset SUDO_UID\n\n# Setting the source for the custom conda kernel\nWORKING_DIR=\/home\/ec2-user\/SageMaker\/custom-miniconda\nsource &quot;$WORKING_DIR\/miniconda\/bin\/activate&quot;\n\n# Loading all the custom kernels\nfor env in $WORKING_DIR\/miniconda\/envs\/*; do\n    BASENAME=$(basename &quot;$env&quot;)\n    source activate &quot;$BASENAME&quot;\n    python -m ipykernel install --user --name &quot;$BASENAME&quot; --display-name &quot;Custom ($BASENAME)&quot;\ndone\n<\/code><\/pre>",
        "Challenge_closed_time":1631187921612,
        "Challenge_comment_count":6,
        "Challenge_created_time":1631108848430,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1631177626360,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/69104302",
        "Challenge_link_count":10,
        "Challenge_participation_count":7,
        "Challenge_readability":16.9,
        "Challenge_reading_time":85.0,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":47,
        "Challenge_solved_time":21.9647727778,
        "Challenge_title":"Terraform Error: error waiting for sagemaker notebook instance to create: unexpected state 'Failed', wanted target 'InService'. last error: %!s(<nil>)",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":768.0,
        "Challenge_word_count":500,
        "Platform":"Stack Overflow",
        "Poster_created_time":1572449042430,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Germany",
        "Poster_reputation_count":2082.0,
        "Poster_view_count":238.0,
        "Solution_body":"<p>The solution to the problem was to check the CloudWatch Log events under <code>CloudWatch -&gt; Log groups -&gt; \/aws\/sagemaker\/NotebookInstances -&gt; aws-sm-notebook-instance\/LifecycleConfigOnCreate<\/code> to find the following error-message:<\/p>\n<pre><code>\/bin\/bash: \/tmp\/OnCreate_2021-09-08-12-24rw5al34g: \/bin\/bash^M: bad interpreter: No such file or directory\n<\/code><\/pre>\n<p>A bit of internet research brought me to <a href=\"https:\/\/askubuntu.com\/questions\/304999\/not-able-to-execute-a-sh-file-bin-bashm-bad-interpreter\/305001#305001\">this solution related to newline characters in shell-scripts<\/a>, which depend on whether you are on <code>Windows<\/code> or a <code>UNIX<\/code>-system.\nAs I'm working on Windows, the shell-scripts created in VS-Code comprised dos-specific <code>CRLF<\/code> newline-handling, which could be resolved via the button on the bottom-right in <code>VS-Code<\/code> to switch the <em>carriage return<\/em> (CRLF) character to the <em>line feed<\/em> (LF) character used by UNIX.<\/p>\n<p>As the compute instance employed by AWS Sagemaker is a Linux-system, it cannot handle the dos-style CRLF newline-characters in the shell-scripts and this &quot;adds&quot; a <code>^M<\/code> after <code>\/bin\/bash<\/code> which obviously leads to an error as such an interpreter does not exist.<\/p>\n<p>So, finally <code>terraform apply<\/code> worked out well:<\/p>\n<pre><code>$ terraform apply\n...\n...\naws_sagemaker_notebook_instance.notebook_instance: Still creating... [7m30s elapsed]\naws_sagemaker_notebook_instance.notebook_instance: Still creating... [7m40s elapsed]\naws_sagemaker_notebook_instance.notebook_instance: Creation complete after 7m43s [id=aws-sm-notebook-instance]\n\nApply complete! Resources: 1 added, 1 changed, 1 destroyed.\n<\/code><\/pre>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":13.3,
        "Solution_reading_time":23.36,
        "Solution_score_count":0.0,
        "Solution_sentence_count":11.0,
        "Solution_word_count":184.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1559607319220,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":66.0,
        "Answerer_view_count":12.0,
        "Challenge_adjusted_solved_time":510.8353358333,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am trying to create Sagemaker notebook instance using cloudformation template. Just wanted to see if there is any way i can associate codecommit repo to that note book instance.<\/p>\n\n<p>I know simple way to create repo and associate it using sagemaker via GUI easily.. However, is there any way we can associate via template. <\/p>\n\n<p>I found similar info on <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/nbi-git-repo.html\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/nbi-git-repo.html<\/a> But it doesn't show with cloudformation<\/p>",
        "Challenge_closed_time":1559608178472,
        "Challenge_comment_count":0,
        "Challenge_created_time":1557513388300,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1557769171263,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/56083148",
        "Challenge_link_count":2,
        "Challenge_participation_count":1,
        "Challenge_readability":13.0,
        "Challenge_reading_time":8.36,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":8,
        "Challenge_solved_time":581.8861588889,
        "Challenge_title":"Associate CodeCommit repo While creating Sagemaker notebook Instance",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":1194.0,
        "Challenge_word_count":78,
        "Platform":"Stack Overflow",
        "Poster_created_time":1553287213987,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":17.0,
        "Poster_view_count":8.0,
        "Solution_body":"<p>SageMaker now supports associating code repository including CodeCommit and any other Git repository with Notebook Instances via CloudFormation. <\/p>\n\n<p>Here's the link for more information: <a href=\"https:\/\/docs.aws.amazon.com\/AWSCloudFormation\/latest\/UserGuide\/aws-resource-sagemaker-coderepository.html\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/AWSCloudFormation\/latest\/UserGuide\/aws-resource-sagemaker-coderepository.html<\/a><\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":30.7,
        "Solution_reading_time":6.18,
        "Solution_score_count":2.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":29.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":145.6833333333,
        "Challenge_answer_count":2,
        "Challenge_body":"While working on simulator of Google Agent assist, the checkbox to enable FAQ or Article Suggestion or smart reply option is DISABLED.\n\nThe chat on simulator is working with virtual agent I have configured via Dialog flow with intents that I have built, but can't use agent assist feature since I am not able to enable it.\n\nPlease note I have configured smart reply, article suggestion and Knowledge Base option in the agent assist in my google project.\n\nLooking for help to fix the issue.",
        "Challenge_closed_time":1675226640000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1674702180000,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Agent-Assist-Simulator-view-feature-FAQ-article\/td-p\/514223\/jump-to\/first-unread-message",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":9.5,
        "Challenge_reading_time":7.04,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":145.6833333333,
        "Challenge_title":"Google Agent Assist - Simulator view - feature FAQ, article suggestion CHECKBOX disabled",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":93.0,
        "Challenge_word_count":95,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"Smart reply, FAQ and Articlet Suggestion of google agent assist became visible after I disabled the \"Choose to use Dialogflow\" option in my selected \"Conversation Profile\".\n\nHowever there is another issue. The \"smart reply\"\/\"FAQ\"\/\"Article Suggestion\" though enabled and visible in UI but they are not working. I am not getting any suggestion or smart reply for the customer chat. Any idea what could be wrong ?\n\nView solution in original post",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":7.9,
        "Solution_reading_time":5.44,
        "Solution_score_count":0.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":70.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":67.5666666667,
        "Challenge_answer_count":1,
        "Challenge_body":"Based on this excerpt:\n\nNote:\u00a0Cloud TPU v4 capacity is located in us-central2 region. Currently, v4 is only available in zone\u00a0us-central2-b. See\u00a0Types and Topologies\u00a0for information about supported v4 TPU types and topologies.\n\nfrom https:\/\/cloud.google.com\/tpu\/docs\/regions-zones\n\n\u00a0\n\nI'm expecting to find the region however it's not present in the dropdown. CLI is also saying it's either forbidden or mistyped.",
        "Challenge_closed_time":1683617100000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1683373860000,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Missing-us-central2-b-when-creating-TPU-VM\/td-p\/550953\/jump-to\/first-unread-message",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":8.6,
        "Challenge_reading_time":5.71,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":67.5666666667,
        "Challenge_title":"Missing `us-central2-b` when creating TPU VM",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":60.0,
        "Challenge_word_count":64,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"Good day\u00a0@lukas0,\n\nWelcome to Google Cloud Community!\n\nAs of now, you need to reach out to Google Cloud Support in order to enable this feature in your Project. You can check the key note in this documentation:\u00a0https:\/\/cloud.google.com\/tpu\/docs\/system-architecture-tpu-vm#tpu-v4-config\n\nYou can use this link to reach out to Google Cloud Support:\u00a0https:\/\/cloud.google.com\/support\n\nHope this will help!\n\nView solution in original post",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":7.3,
        "Solution_reading_time":5.41,
        "Solution_score_count":1.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":61.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":1.1574388889,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>We have an active subscription. For few of the users we activated owner role for the machine learning resource group.    <br \/>\nBut when they login to the portal\/ML environment and try to switch directory and subscription, they don't see our production subscription and hence the workspace, although directory is correct. User had created a trial subscription on its own before and he only has visibility to that.    <\/p>\n<p>I checked with a test account and after login to ML studio I see this, which I believe is the same reason user does not see the subscription.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/255195-screenshot-2022-10-28-085206.png?platform=QnA\" alt=\"255195-screenshot-2022-10-28-085206.png\" \/>    <\/p>\n<p>How can I safely give user subscription access only for ML resource group    <\/p>",
        "Challenge_closed_time":1666977116507,
        "Challenge_comment_count":0,
        "Challenge_created_time":1666972949727,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1067157\/access-to-azure-subscription-for-users",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":10.3,
        "Challenge_reading_time":10.93,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":8,
        "Challenge_solved_time":1.1574388889,
        "Challenge_title":"Access to Azure subscription for users",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":120,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hi <a href=\"\/users\/na\/?userid=8cb8b6e9-f7ac-47d9-bcd3-6c4b5af3201d\">@RT-7199  <\/a>     <\/p>\n<p>Thank you for asking this question on the **Microsoft Q&amp;A Platform. **    <\/p>\n<p>The role will depend on the activity that the user performs, for example, to create a new workspace you will require the role owner or contributor at the Resource group-level. (If you receive a failure when trying to create a workspace for the first time, make sure that your role allows Microsoft.MachineLearningServices\/register\/action. This action allows you to register the Azure Machine Learning resource provider with your Azure subscription.)    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/255119-image.png?platform=QnA\" alt=\"255119-image.png\" \/>    <\/p>\n<p>You can get more information about RBAC for Azure Machine Learning workspace <strong><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-assign-roles?tabs=labeler#common-scenarios\">here<\/a><\/strong>    <\/p>\n<p>Hope this helps!    <\/p>\n<p>----------    <\/p>\n<p><strong><a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/support\/accepted-answers\">Accept Answer<\/a><\/strong> and Upvote, if any of the above helped, this thread can help others in the community looking for remediation for similar issues.    <br \/>\n<em>NOTE: To answer you as quickly as possible, please mention me in your reply.<\/em>    <\/p>\n",
        "Solution_comment_count":3.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":3.0,
        "Solution_readability":12.2,
        "Solution_reading_time":17.92,
        "Solution_score_count":0.0,
        "Solution_sentence_count":11.0,
        "Solution_word_count":152.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":2.8202777778,
        "Challenge_answer_count":0,
        "Challenge_body":"**Describe the bug**\r\nCurrently the example DAG for sagemaker just uses access key and secret key. We need to use a temporary  access token\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Desktop (please complete the following information):**\r\n - OS: [e.g. iOS]\r\n - Browser [e.g. chrome, safari]\r\n - Version [e.g. 22]\r\n\r\n**Smartphone (please complete the following information):**\r\n - Device: [e.g. iPhone6]\r\n - OS: [e.g. iOS8.1]\r\n - Browser [e.g. stock browser, safari]\r\n - Version [e.g. 22]\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "Challenge_closed_time":1666960895000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1666950742000,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/github.com\/astronomer\/astronomer-providers\/issues\/738",
        "Challenge_link_count":0,
        "Challenge_participation_count":0,
        "Challenge_readability":6.6,
        "Challenge_reading_time":10.27,
        "Challenge_repo_contributor_count":18.0,
        "Challenge_repo_fork_count":22.0,
        "Challenge_repo_issue_count":807.0,
        "Challenge_repo_star_count":97.0,
        "Challenge_repo_watch_count":33.0,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":14,
        "Challenge_solved_time":2.8202777778,
        "Challenge_title":"Sagemaker example DAG to use aws session token",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":120,
        "Platform":"Github",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":-15.7,
        "Solution_reading_time":0.0,
        "Solution_score_count":0.0,
        "Solution_sentence_count":1.0,
        "Solution_word_count":0.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":3.6038047222,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have enrolled myself in Azure Machine Learning course and the first step there is to create an azure ML workspace with subscription, resource group, region, storage account etc. I am a new joiner and I am doing this for my learning. Not sure which option to select. Is there any guidance or doc to follow? I have checked with my team and they are suggesting to use my personal account to get a demo account and free azure subscription to do the course and not my microsoft credentials. Require assistance in this regard.<\/p>",
        "Challenge_closed_time":1655384032827,
        "Challenge_comment_count":0,
        "Challenge_created_time":1655371059130,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/891716\/request-help-with-azure-machine-learning-workspace",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":6.5,
        "Challenge_reading_time":7.07,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":3.6038047222,
        "Challenge_title":"Request help with Azure machine learning workspace",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":100,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=149f8035-b796-4252-b4c0-40b562c68c91\">@Sanjana Das  <\/a>  Thanks for the question. Here is the document to Create workspace resources you need to get started with Azure Machine Learning. You can use your personal account to get free azure subscription.    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/quickstart-create-resources\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/quickstart-create-resources<\/a>    <\/p>\n<p>------------------------------    <\/p>\n<ul>\n<li> Please don't forget to click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/25904\/accepted-answers.html\">how<\/a>    <\/li>\n<li> Want a reminder to come back and check responses? Here is how to subscribe to a <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/67444\/email-notifications.html\">notification<\/a>    <\/li>\n<li> If you are interested in joining the VM program and help shape the future of Q&amp;A: Here is how you can be part of <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/543261\/index.html\">Q&amp;A Volunteer Moderators<\/a>    <\/li>\n<\/ul>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":6.0,
        "Solution_readability":14.4,
        "Solution_reading_time":20.24,
        "Solution_score_count":0.0,
        "Solution_sentence_count":13.0,
        "Solution_word_count":134.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":0.0197222222,
        "Challenge_answer_count":0,
        "Challenge_body":"Archived from slack discussion!\n\nI\u2019m receiving the following error recently, but it only occurs when I use a VPN, if I\u2019m in the office I don\u2019t get this issue.\nHas anyone received similar or have any clues on what might be the problem?\n\n File \"\/usr\/local\/opt\/python@3.8\/Frameworks\/Python.framework\/Versions\/3.8\/lib\/python3.8\/ssl.py\", line 1019, in _create\n    self.getpeername()\nurllib3.exceptions.ProtocolError: ('Connection aborted.', OSError(22, 'Invalid argument'))",
        "Challenge_closed_time":1667914455000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1667914384000,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1519",
        "Challenge_link_count":0,
        "Challenge_participation_count":0,
        "Challenge_readability":11.5,
        "Challenge_reading_time":7.08,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":0.0197222222,
        "Challenge_title":"Issue installing polyaxon python client urllib3.exceptions.ProtocolError: OSError",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":62,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"Sometimes the CA bundle is not up-to date and needs to be installed manually, especially if it's a new Python version. Please run the following commands:\n\ncd \/Applications\/Python\\ 3.8\/\n\nthen\n\n.\/Install\\ Certificates.command",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":10.7,
        "Solution_reading_time":2.78,
        "Solution_score_count":1.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":32.0,
        "Tool":"Polyaxon"
    },
    {
        "Answerer_created_time":1597855076910,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Delft, Netherlands",
        "Answerer_reputation_count":60.0,
        "Answerer_view_count":6.0,
        "Challenge_adjusted_solved_time":0.3015636111,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am unable to perform the simple action:<\/p>\n<pre><code>import sagemaker\nsess = sagemaker.Session()\nrole = sagemaker.get_execution_role()\n<\/code><\/pre>\n<p>because my notebook instance is not connected to the internet. I have an STS endpoint interface in the same subnet as my notebook instance but I thought the sagemaker API is using the global endpoint. I actually get the following error message after a while:<\/p>\n<pre><code>ConnectTimeoutError: Connect timeout on endpoint URL: &quot;https:\/\/sts.us-east-1.amazonaws.com\/&quot;\n<\/code><\/pre>\n<p>How do I fix this? Or does one need to update the sagemaker module?<\/p>",
        "Challenge_closed_time":1608634938236,
        "Challenge_comment_count":0,
        "Challenge_created_time":1608633852607,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/65407274",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":10.1,
        "Challenge_reading_time":8.76,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":8,
        "Challenge_solved_time":0.3015636111,
        "Challenge_title":"AWS SageMaker (with internet disabled) unable to connect to STS",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":510.0,
        "Challenge_word_count":91,
        "Platform":"Stack Overflow",
        "Poster_created_time":1597855076910,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Delft, Netherlands",
        "Poster_reputation_count":60.0,
        "Poster_view_count":6.0,
        "Solution_body":"<p>So the solution is to include a VPC endpoint for the sagemaker API (api.sagemaker...) as well as STS.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":5.6,
        "Solution_reading_time":1.34,
        "Solution_score_count":0.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":18.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1516367794196,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":56.0,
        "Answerer_view_count":2.0,
        "Challenge_adjusted_solved_time":1055.1677944445,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>System information\nOS Platform and Distribution: Windows 10\nMLflow installed: using pip\nMLflow version: version 1.24.0\n**Python version: Python 3.9.7 **<\/p>\n<p>Describe the problem\nI have created a docker-compose system with a backend\/artifact storages, mlflow server and nginx to add an authentication layer.<\/p>\n<pre><code>...\nmlflow:\n        restart: always\n        build: .\n        environment:\n            - AWS_ACCESS_KEY_ID=${MINIO_USR}\n            - AWS_SECRET_ACCESS_KEY=${MINIO_PASS}       \n        expose:\n            - '5000'\n        networks:\n            - frontend\n            - backend\n        depends_on:\n            - storage                       \n        image: 'mlflow:Dockerfile'\n        container_name: mlflow_server_nginx\n\n    nginx:\n        restart: always\n        build: .\/nginx\n        container_name: mlflow_nginx\n        ports:\n            - 5043:443\n        links:\n            - mlflow:mlflow\n        volumes:\n            - 'path\/to\/nginx\/auth:\/etc\/nginx\/conf.d'\n            - 'path\/to\/nginx\/nginx.conf:\/etc\/nginx\/nginx.conf:ro'\n        networks:\n            - frontend\n        depends_on:\n            - mlflow\n<\/code><\/pre>\n<p>I have created an user\/password via htpasswd and a custom SSL CA (.pem\/.key) using openssl and my-mlflow.com server-name.<\/p>\n<p>When the docker-compose system is built i can access to mlflow UI via my browser. But when i try to create a new experiment using python trying diferent approaches, i get next errors:\nExecuted code 1:<\/p>\n<pre><code># Setting the requried environment variables\nos.environ['MLFLOW_S3_ENDPOINT_URL'] = 'https:\/\/localhost:9000'\nos.environ['AWS_ACCESS_KEY_ID'] = 'user'\nos.environ['AWS_SECRET_ACCESS_KEY'] = 'password'\n# Set username and password for added authentication\n#os.environ['MLFLOW_TRACKING_URI '] = 'https:\/\/localhost:5043\/'\n#os.environ['MLFLOW_TRACKING_USERNAME '] = 'user'\n#os.environ['MLFLOW_TRACKING_PASSWORD '] = 'password'\n#os.environ['MLFLOW_TRACKING_SERVER_CERT_PATH'] = 'path\/to\/nginx\/auth\/domain.pem'\n#os.environ['MLFLOW_TRACKING_CLIENT_CERT_PATH'] = 'path\/to\/nginx\/auth\/domain.pem'\n# MLflow enviroment\nremote_server_uri = &quot;https:\/\/user:password@localhost:5043\/&quot; # set to your server URI\nmlflow.set_tracking_uri(remote_server_uri)\n\nmlflow.set_experiment(&quot;MLflow_demo&quot;)\n<\/code><\/pre>\n<p>Error:<\/p>\n<pre><code>MlflowException: API request to https:\/\/user:password@localhost:5043\/api\/2.0\/mlflow\/experiments\/list failed with exception HTTPSConnectionPool(host='localhost', port=5043): Max retries exceeded with url: \/api\/2.0\/mlflow\/experiments\/list?view_type=ALL (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:1108)')))\n<\/code><\/pre>\n<p>After read some notes in the documentation and realated issues I tryed next<\/p>\n<pre><code># Setting the requried environment variables\nos.environ['MLFLOW_S3_ENDPOINT_URL'] = 'https:\/\/localhost:9000'\nos.environ['AWS_ACCESS_KEY_ID'] = 'user'\nos.environ['AWS_SECRET_ACCESS_KEY'] = 'password'\n# Set username and password for added authentication\n#os.environ['MLFLOW_TRACKING_URI '] = 'https:\/\/localhost:5043\/'\n#os.environ['MLFLOW_TRACKING_USERNAME '] = 'user'\n#os.environ['MLFLOW_TRACKING_PASSWORD '] = 'password'\n#os.environ['MLFLOW_TRACKING_SERVER_CERT_PATH'] = 'path\/to\/nginx\/auth\/domain.pem'\nos.environ['MLFLOW_TRACKING_CLIENT_CERT_PATH'] = 'path\/to\/nginx\/auth\/domain.pem'\n# MLflow enviroment\nremote_server_uri = &quot;https:\/\/user:password@localhost:5043\/&quot; # set to your server URI\nmlflow.set_tracking_uri(remote_server_uri)\n\nmlflow.set_experiment(&quot;MLflow_demo&quot;)\n<\/code><\/pre>\n<p>Error:<\/p>\n<pre><code>MlflowException: API request to https:\/\/user:password@localhost:5043\/api\/2.0\/mlflow\/experiments\/list failed with exception HTTPSConnectionPool(host='localhost', port=5043): Max retries exceeded with url: \/api\/2.0\/mlflow\/experiments\/list?view_type=ALL (Caused by SSLError(SSLError(9, '[SSL] PEM lib (_ssl.c:4012)')))\n<\/code><\/pre>\n<p>Finally<\/p>\n<pre><code># Setting the requried environment variables\nos.environ['MLFLOW_S3_ENDPOINT_URL'] = 'https:\/\/localhost:9000'\nos.environ['AWS_ACCESS_KEY_ID'] = 'user'\nos.environ['AWS_SECRET_ACCESS_KEY'] = 'password'\n# Set username and password for added authentication\n#os.environ['MLFLOW_TRACKING_URI '] = 'https:\/\/localhost:5043\/'\n#os.environ['MLFLOW_TRACKING_USERNAME '] = 'user'\n#os.environ['MLFLOW_TRACKING_PASSWORD '] = 'password'\nos.environ['MLFLOW_TRACKING_SERVER_CERT_PATH'] = 'path\/to\/nginx\/auth\/domain.pem'\n#os.environ['MLFLOW_TRACKING_CLIENT_CERT_PATH'] = 'path\/to\/nginx\/auth\/domain.pem'\n# MLflow enviroment\nremote_server_uri = &quot;https:\/\/user:password@localhost:5043\/&quot; # set to your server URI\nmlflow.set_tracking_uri(remote_server_uri)\n\nmlflow.set_experiment(&quot;MLflow_demo&quot;)\n<\/code><\/pre>\n<p>Error:<\/p>\n<pre><code>MlflowException: API request to https:\/\/user:password@localhost:5043\/api\/2.0\/mlflow\/experiments\/list failed with exception HTTPSConnectionPool(host='localhost', port=5043): Max retries exceeded with url: \/api\/2.0\/mlflow\/experiments\/list?view_type=ALL (Caused by SSLError(SSLCertVerificationError(&quot;hostname 'localhost' doesn't match '*.my-mlflow.com'&quot;)))\n<\/code><\/pre>\n<p>Can you give me some hints about how to solve it?<\/p>\n<p>Thank you very much!\nFernando....<\/p>",
        "Challenge_closed_time":1652276299263,
        "Challenge_comment_count":0,
        "Challenge_created_time":1648650339347,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/71679081",
        "Challenge_link_count":12,
        "Challenge_participation_count":1,
        "Challenge_readability":18.4,
        "Challenge_reading_time":68.29,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":45,
        "Challenge_solved_time":1007.2110877778,
        "Challenge_title":"How can I connect mlflow server via nginx ssl authentication?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":625.0,
        "Challenge_word_count":377,
        "Platform":"Stack Overflow",
        "Poster_created_time":1580841805372,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Seville, Spain",
        "Poster_reputation_count":33.0,
        "Poster_view_count":4.0,
        "Solution_body":"<p>You can set:<\/p>\n<pre><code>os.environ['MLFLOW_TRACKING_INSECURE_TLS'] = 'true'\n<\/code><\/pre>\n<p>And then try to get your cert-chain straight from there for production use.<\/p>\n<p>Also see Documentation: <a href=\"https:\/\/mlflow.org\/docs\/latest\/tracking.html#id19\" rel=\"nofollow noreferrer\">https:\/\/mlflow.org\/docs\/latest\/tracking.html#id19<\/a><\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1652448943407,
        "Solution_link_count":2.0,
        "Solution_readability":14.1,
        "Solution_reading_time":4.76,
        "Solution_score_count":0.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":26.0,
        "Tool":"MLflow"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":18.7064261111,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I'm trying to understand how DEP works in ML.<\/p>\n<p>The Microsoft recommended architecture states that I must use a service endpoint along with a service endpoint policy to prevent ML compute subnets from gaining access to non-white listed storage accounts (<a href=\"\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-network-isolation-planning#recommended-architecture-with-data-exfiltration-prevention<\/a>)<\/p>\n<p>Some other examples I found on the web don't use service endpoints and instead prefer private endpoints for storage accounts. Does using PEs alone prevent data exfiltration? I'm not sure, because from what I've seen so far, it's possible to add any storage account as a datastore through the ML workspace as long as you have the appropriate access rights for the storage account.<\/p>\n<p>So I'm a bit confused and would appreciate if someone could shed some light on this.<\/p>",
        "Challenge_closed_time":1677483032160,
        "Challenge_comment_count":0,
        "Challenge_created_time":1677415689026,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1184373\/azure-ml-and-data-exfiltration-prevention",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":11.5,
        "Challenge_reading_time":12.13,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":18.7064261111,
        "Challenge_title":"Azure ML and Data exfiltration prevention",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":127,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=c7bbbc2c-bba8-4500-a3a8-df7a87f8e72a\">Plodie<\/a> Thanks, using private endpoints alone may not prevent data exfiltration, but it can reduce the attack surface and the chances of data exfiltration. It is recommended to use a combination of Azure Virtual Network, Azure Private Link, and <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/governance\/policy\/overview\">Azure Policy<\/a> to secure your Azure Machine Learning resources.<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":15.7,
        "Solution_reading_time":6.55,
        "Solution_score_count":0.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":50.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1267440784443,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Somewhere",
        "Answerer_reputation_count":15705.0,
        "Answerer_view_count":2150.0,
        "Challenge_adjusted_solved_time":0.2702147222,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I have created a workspace in our azure environment and try to run this code:<\/p>\n<pre><code>library(azuremlsdk)\n\nws &lt;- get_workspace(\n    name = &quot;someworkspace&quot;, \n    subscription_id = &quot;si1&quot;, \n    resource_group =&quot;rg1&quot;\n)\n<\/code><\/pre>\n<p>Some interactive authenticator opens in my browser, which I think is intended behaviour as I have no tenantdid. However, I get this:<\/p>\n<pre><code>Performing interactive authentication. Please follow the instructions on the terminal.\nNote, we have launched a browser for you to login. For old experience with device code, use &quot;az login --use-device-code&quot;\nYou have logged in. Now let us find all the subscriptions to which you have access...\nInteractive authentication successfully completed.\nPerforming interactive authentication. Please follow the instructions on the terminal.\nNote, we have launched a browser for you to login. For old experience with device code, use &quot;az login --use-device-code&quot;\nYou have logged in. Now let us find all the subscriptions to which you have access...\nInteractive authentication successfully completed.\nAuthenticationException: AuthenticationException:\n        Message: Could not retrieve user token. Please run 'az login'\n        InnerException It is required that you pass in a value for the &quot;algorithms&quot; argument when calling decode().\n        ErrorResponse\n{\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;inner_error&quot;: {\n            &quot;code&quot;: &quot;Authentication&quot;\n        },\n        &quot;message&quot;: &quot;Could not retrieve user token. Please run 'az login'&quot;\n    }\n}\n<\/code><\/pre>\n<p>I also tried:<\/p>\n<pre><code>az login\n<\/code><\/pre>\n<p>This works fine. So for me all this is very confusing!<\/p>",
        "Challenge_closed_time":1620752159740,
        "Challenge_comment_count":0,
        "Challenge_created_time":1620740709577,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1620751186967,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/67488064",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":11.3,
        "Challenge_reading_time":22.83,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":19,
        "Challenge_solved_time":3.1806008333,
        "Challenge_title":"get workspace failed azuremlsdk - AuthenticationException",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":530.0,
        "Challenge_word_count":216,
        "Platform":"Stack Overflow",
        "Poster_created_time":1267440784443,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Somewhere",
        "Poster_reputation_count":15705.0,
        "Poster_view_count":2150.0,
        "Solution_body":"<p>So I tried the same in Python and had a similar error and came across this:<\/p>\n<p><a href=\"https:\/\/github.com\/Azure\/azure-sdk-for-python\/issues\/16035\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/azure-sdk-for-python\/issues\/16035<\/a><\/p>\n<p>Downgrading:<\/p>\n<pre><code> PyJWT \n<\/code><\/pre>\n<p>helped. The bizarre world of open source and its web of interdependencies!<\/p>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":10.3,
        "Solution_reading_time":5.08,
        "Solution_score_count":2.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":36.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1221810788500,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Paderborn, North-Rhine-Westphalia, Germany",
        "Answerer_reputation_count":68522.0,
        "Answerer_view_count":7896.0,
        "Challenge_adjusted_solved_time":3.4510725,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I would like to know if I can change the port of my MLflow server.<\/p>\n<p>By default it is running on port 5000, but my company's VPN only allows HTTP (port 80) and HTTPS (port 443) traffic.<\/p>\n<p>This might be a very beginner's question, but is it possible, and if yes, is there any problem on running the MLflow server on port 83 (HTTP) ?<\/p>\n<p>Thank you<\/p>",
        "Challenge_closed_time":1635152056288,
        "Challenge_comment_count":0,
        "Challenge_created_time":1635139632427,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/69703225",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":4.5,
        "Challenge_reading_time":5.02,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":3.4510725,
        "Challenge_title":"Can I change the port of my MLflow tracking server?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":540.0,
        "Challenge_word_count":76,
        "Platform":"Stack Overflow",
        "Poster_created_time":1561106497312,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":133.0,
        "Poster_view_count":17.0,
        "Solution_body":"<p>Yes, you can do that by passing the <code>-p port_number<\/code> command-line switch when starting MLflow server (see <a href=\"https:\/\/mlflow.org\/docs\/latest\/cli.html#cmdoption-mlflow-server-p\" rel=\"nofollow noreferrer\">docs<\/a>). Please note, that to be able to use ports below 1024, the server needs to be run as root.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":8.5,
        "Solution_reading_time":4.22,
        "Solution_score_count":1.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":40.0,
        "Tool":"MLflow"
    },
    {
        "Answerer_created_time":1589293508567,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":833.0,
        "Answerer_view_count":55.0,
        "Challenge_adjusted_solved_time":0.0,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>On Azure ML Workspace Notebook, I'm trying to get my workspace instance, as seen at<\/p>\n<p><a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/manage-azureml-service\/authentication-in-azureml\/authentication-in-azureml.ipynb\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-auto-train-models#configure-workspace.<\/a><\/p>\n<p>I have a config file and I am running the notebook in an Azure compute instance.<\/p>\n<p>I tried to execute Workspace.from_config().<\/p>\n<p>As a result, I'm getting the 'MSIAuthentication' object has no attribute 'get_token' error.<\/p>\n<p>I tried to submit both <code>MsiAuthentication<\/code> and <code>InteractiveLoginAuthentication<\/code>, as suggested in<\/p>\n<p><a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/manage-azureml-service\/authentication-in-azureml\/authentication-in-azureml.ipynb\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/manage-azureml-service\/authentication-in-azureml\/authentication-in-azureml.ipynb.<\/a><\/p>",
        "Challenge_closed_time":1625753450150,
        "Challenge_comment_count":0,
        "Challenge_created_time":1625753450150,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/68303285",
        "Challenge_link_count":4,
        "Challenge_participation_count":1,
        "Challenge_readability":28.1,
        "Challenge_reading_time":16.5,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":2.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":8,
        "Challenge_solved_time":0.0,
        "Challenge_title":"'MSIAuthentication' object has no attribute 'get_token'",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":1670.0,
        "Challenge_word_count":73,
        "Platform":"Stack Overflow",
        "Poster_created_time":1589293508567,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":833.0,
        "Poster_view_count":55.0,
        "Solution_body":"<p><strong>There are 2 solutions I've found:<\/strong><\/p>\n<p>1.- Use the kernel &quot;Python 3.6 - AzureML&quot;<\/p>\n<p>2.- <code>pip install azureml-core --upgrade<\/code><\/p>\n<p>This will <strong>upgrade<\/strong><\/p>\n<blockquote>\n<p>azureml-core to 1.32.0<\/p>\n<\/blockquote>\n<p>But will <strong>downgrade<\/strong>:<\/p>\n<blockquote>\n<p>azure-mgmt-resource to 13.0.0 (was 18.0.0)<\/p>\n<\/blockquote>\n<blockquote>\n<p>azure-mgmt-storage down to 11.2.0 (was 18.0.0)<\/p>\n<\/blockquote>\n<blockquote>\n<p>urllib3 to 1.26.5 (was 1.26.6)<\/p>\n<\/blockquote>\n<p>This upgrade \/ downgrade allows the same package versions as in the python 3.6 anaconda install<\/p>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":5.4,
        "Solution_reading_time":8.48,
        "Solution_score_count":2.0,
        "Solution_sentence_count":12.0,
        "Solution_word_count":66.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":0.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":46.8695180555,
        "Challenge_answer_count":2,
        "Challenge_body":"I want to allowlist the Sagemaker studio IP so people can access certain allowlisted services from Sagemaker. I created a sagemaker domain in my private subnet of my VPC, so theoretically it should use the IP of the associated NAT gateway, right? But I see a different IP \ud83e\udd14",
        "Challenge_closed_time":1675200089343,
        "Challenge_comment_count":0,
        "Challenge_created_time":1674683552396,
        "Challenge_favorite_count":1.0,
        "Challenge_last_edit_time":1675031393875,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUX7n9V0osTAmdmLYM21vmKQ\/how-to-allowlist-sagemaker-ip",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":9.5,
        "Challenge_reading_time":3.7,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":143.4824852778,
        "Challenge_title":"How to allowlist sagemaker IP?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":112.0,
        "Challenge_word_count":52,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"I should've read through my terraform code that created Sagemaker more carefully, I specified a VPC so I thought it would be *in* the VPC but it turns out I needed to specify the AppNetworkAccessType too.\n\nbad:\n```hcl\nresource \"aws_sagemaker_domain\" \"my_domain\" {\n  domain_name = var.domain_name\n  auth_mode   = \"IAM\"\n  vpc_id      = var.vpc_id\n  subnet_ids  = var.subnet_ids\n```\n\ngood:\n```hcl\nresource \"aws_sagemaker_domain\" \"my_domain\" {\n  domain_name = var.domain_name\n  auth_mode   = \"IAM\"\n  vpc_id      = var.vpc_id\n  subnet_ids  = var.subnet_ids\n  app_network_access_type = \"VpcOnly\"\n```",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1675200124140,
        "Solution_link_count":0.0,
        "Solution_readability":10.0,
        "Solution_reading_time":7.07,
        "Solution_score_count":0.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":64.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1619177157943,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":835.0,
        "Answerer_view_count":516.0,
        "Challenge_adjusted_solved_time":139.5224691667,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>In a Vertex AI pipeline component,I try:<\/p>\n<pre><code>def my_comp(project_id: str, location: str, endpoint_id: str, endpoint: Output[Artifact]):\n    import google.cloud.aiplatform as aip\n    endpoints = aip.Endpoint.list()\n...\n<\/code><\/pre>\n<p>which gives:<\/p>\n<pre><code>'aiplatform.endpoints.list' denied on resource '\/\/aiplatform.googleapis.com\/projects\/...\n<\/code><\/pre>\n<p>My service account has owner permissions, and it works outside of the component. What do I need to do?<\/p>",
        "Challenge_closed_time":1663223342092,
        "Challenge_comment_count":6,
        "Challenge_created_time":1662721061203,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/73661090",
        "Challenge_link_count":0,
        "Challenge_participation_count":7,
        "Challenge_readability":10.1,
        "Challenge_reading_time":7.02,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":139.5224691667,
        "Challenge_title":"How do I give Vertex AI pipeline component permissions?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":62.0,
        "Challenge_word_count":58,
        "Platform":"Stack Overflow",
        "Poster_created_time":1351154914716,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":2564.0,
        "Poster_view_count":451.0,
        "Solution_body":"<p>This permission denied on resource issue can be resolved by using import statement:<\/p>\n<pre><code>from google.cloud import aiplatform_v1 as aiplatform\n<\/code><\/pre>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":10.7,
        "Solution_reading_time":2.19,
        "Solution_score_count":0.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":20.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_created_time":1406731060412,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Washington, USA",
        "Answerer_reputation_count":139.0,
        "Answerer_view_count":6.0,
        "Challenge_adjusted_solved_time":268.3228897222,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am setting up SageMaker for a group outside my organization, and wondering how I provide access to SageMaker Studio (and any dependent AWS resources SageMaker would use) to these users.\nThe idea is to have then use SageMaker studio to do train and test models.<\/p>\n<p>Ideally, it would be great if I simply send them a link where they sign in, and are then granted access to SageMaker hosted from my AWS account.<\/p>\n<p>I believe to grant temporary access I need to attach a <strong>role<\/strong> to a group of <strong>users<\/strong>, and also attach a <strong>policy<\/strong> to this group, them finally associate this role with SageMaker. But how do I then create a <strong>link<\/strong> to SageMaker so these users can sign in?<\/p>\n<p>The other option would be to set this up using cross-account access, since those I want to give access to also have their own AWS account. But again, how does one generate a link to direct these users to the SageMaker on my AWS account?<\/p>\n<p>There appears to be 2 options, as per <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/gs-studio-onboard.html\" rel=\"nofollow noreferrer\">SageMaker Onboarding<\/a>:<\/p>\n<ol>\n<li><strong>AWS SSO authentication<\/strong><\/li>\n<\/ol>\n<ul>\n<li>access to Studio via unique sign-in URL that directly opens Studio<\/li>\n<li>sign in with their SSO credentials<\/li>\n<li>organizations manages members in AWS SSO instead of Studio<\/li>\n<li>can assign multiple members access to Studio at the same time<\/li>\n<\/ul>\n<ol start=\"2\">\n<li><strong>IAM authentication<\/strong><\/li>\n<\/ol>\n<ul>\n<li>sign in through the SageMaker console<\/li>\n<li>must add and manage members manually one at time using the Studio Control Panel<\/li>\n<\/ul>\n<p>I don't understand the 2nd approach, since wouldn't this mean users would have to sign-in as root to the console anyway and then have full access. I could edit the policy attached to IAM users, but this begs another question:<\/p>\n<p>...does SageMaker come pre-baked with policies that include its dependent AWS services? For example, SageMaker will use S3 for storage and EC2 for processing; do I need to set these individually in the policy, or can I simply use a SageMaker policy, which will include all those dependencies by default?<\/p>",
        "Challenge_closed_time":1626467994683,
        "Challenge_comment_count":0,
        "Challenge_created_time":1625496004123,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1625502032280,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/68258003",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":13.9,
        "Challenge_reading_time":29.04,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":13,
        "Challenge_solved_time":269.9973777778,
        "Challenge_title":"How does one make AWS SageMaker available to people outside their organization?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":1359.0,
        "Challenge_word_count":352,
        "Platform":"Stack Overflow",
        "Poster_created_time":1346443720088,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":11650.0,
        "Poster_view_count":977.0,
        "Solution_body":"<p>First of all, you can generate &quot;disposable&quot; (called pre-signed) URLs which can be used for accessing SageMaker Studio User Profiles without any AWS credentials. These URls can be valid for max 5 minutes and can be generated with a single AWS API call.<\/p>\n<p>One approach to provide Studio access to your users is to set up a service which can authenticate your Studio users and then calls the <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/APIReference\/API_CreatePresignedDomainUrl.html\" rel=\"nofollow noreferrer\">CreatePresignedDomainUrl SageMaker API<\/a> method to sends back the generated pre-signed URL to the user.<\/p>\n<p>Alternatively, you can use AWS SSO as well, which can do most of the heavy lifting for you, especially if you'd like to integrate with a single sign-on service. AWS SSO integrates with SageMaker Studio and you can assign Studio user profiles to your onboarded users. Your users then can go through your single sign-on service and can launch the Studio without logging into the AWS Console.<\/p>\n<p>An another approach is to use IAM Federation where you basically provide access to the AWS API and\/or to the Console to your users which authenticated by an (external) identity provider. Federated users can assume specific roles to operate with the AWS API or the Management Console. For accessing SageMaker Studio, users just need to have the CreatePresignedDomainUrl access policy which allows them to create the pre-signed URL by themselves. If you want to isolate your SageMaker user profiles and ensure each federated user can access just those user profiles which are assigned to them, please see the following <a href=\"https:\/\/aws.amazon.com\/blogs\/machine-learning\/configuring-amazon-sagemaker-studio-for-teams-and-groups-with-complete-resource-isolation\/\" rel=\"nofollow noreferrer\">blog post<\/a> for more information.<\/p>\n<p>And finally, please note that, once the user has logged in to Studio, the Execution Role configured for the specific user profile will determine what the Studio user can access and is able to do (e.g. spinning up SageMaker training jobs, deploying models, accessing S3, etc). Thus, you don't need to set up these policies for your IAM users or roles used by the federated users.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":12.9,
        "Solution_reading_time":28.44,
        "Solution_score_count":3.0,
        "Solution_sentence_count":15.0,
        "Solution_word_count":325.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1574678086832,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Amstelveen, Netherlands",
        "Answerer_reputation_count":3917.0,
        "Answerer_view_count":640.0,
        "Challenge_adjusted_solved_time":6.4474319444,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have installed mlflow on GCP VM instance, \nnow I want to access mlflow UI with external IP.\nI tried setting up a firewall rule and opening the default port for mlflow, but not able to access it.\nCan someone give step by step process for just running mlflow on VM instance?<\/p>",
        "Challenge_closed_time":1583767598368,
        "Challenge_comment_count":3,
        "Challenge_created_time":1583744387613,
        "Challenge_favorite_count":1.0,
        "Challenge_last_edit_time":1583832420660,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/60597319",
        "Challenge_link_count":0,
        "Challenge_participation_count":4,
        "Challenge_readability":5.2,
        "Challenge_reading_time":3.67,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":4.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":6.4474319444,
        "Challenge_title":"Running MLFlow on GCP VM",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":1537.0,
        "Challenge_word_count":56,
        "Platform":"Stack Overflow",
        "Poster_created_time":1451124057623,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"India",
        "Poster_reputation_count":736.0,
        "Poster_view_count":234.0,
        "Solution_body":"<p>I've decided to check on my test VM and run mlflow server on GCE VM. Have a look at my steps below:<\/p>\n\n<ol>\n<li>create VM instance based on Ubuntu Linux 18.04 LTS<\/li>\n<li><p><a href=\"https:\/\/www.mlflow.org\/docs\/latest\/quickstart.html\" rel=\"noreferrer\">install MLflow<\/a>:<\/p>\n\n<pre><code>$ sudo apt update\n$ sudo apt upgrade\n$ cd ~\n$ git clone https:\/\/github.com\/mlflow\/mlflow\n$ cd mlflow\n$ sudo apt install python3-pip\n$ pip3 install mlflow\n$ python3 setup.py build\n$ sudo python3 setup.py install\n$ mlflow --version\nmlflow, version 1.7.1.dev0\n<\/code><\/pre><\/li>\n<li><p>run mlflow server on internal IP of VM instance (default 127.0.0.1):<\/p>\n\n<pre><code>$ ifconfig \nens4: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1460\ninet 10.XXX.15.XXX  netmask 255.255.255.255  broadcast 0.0.0.0\n...\n\n$ mlflow server --host 10.XXX.15.XXX\n[2020-03-09 15:05:50 +0000] [8631] [INFO] Starting gunicorn 20.0.4\n[2020-03-09 15:05:50 +0000] [8631] [INFO] Listening at: http:\/\/10.128.15.211:5000 (8631)\n[2020-03-09 15:05:50 +0000] [8631] [INFO] Using worker: sync\n[2020-03-09 15:05:50 +0000] [8634] [INFO] Booting worker with pid: 8634\n[2020-03-09 15:05:51 +0000] [8635] [INFO] Booting worker with pid: 8635\n[2020-03-09 15:05:51 +0000] [8636] [INFO] Booting worker with pid: 8636\n[2020-03-09 15:05:51 +0000] [8638] [INFO] Booting worker with pid: 8638\n<\/code><\/pre><\/li>\n<li><p>check from VM instance (from second connection):<\/p>\n\n<pre><code>$ curl -I http:\/\/10.XXX.15.XXX:5000\nHTTP\/1.1 200 OK\nServer: gunicorn\/20.0.4\nDate: Mon, 09 Mar 2020 15:06:08 GMT\nConnection: close\nContent-Length: 853\nContent-Type: text\/html; charset=utf-8\nLast-Modified: Mon, 09 Mar 2020 14:57:11 GMT\nCache-Control: public, max-age=43200\nExpires: Tue, 10 Mar 2020 03:06:08 GMT\nETag: \"1583765831.3202355-853-3764264575\"\n<\/code><\/pre><\/li>\n<li><p><a href=\"https:\/\/cloud.google.com\/vpc\/docs\/add-remove-network-tags\" rel=\"noreferrer\">set network tag<\/a> <code>mlflow-server<\/code> <\/p><\/li>\n<li><p><a href=\"https:\/\/cloud.google.com\/vpc\/docs\/using-firewalls#creating_firewall_rules\" rel=\"noreferrer\">create firewall rule<\/a> to allow access on port 5000<\/p>\n\n<pre><code>$ gcloud compute --project=test-prj firewall-rules create mlflow-server --direction=INGRESS --priority=999 --network=default --action=ALLOW --rules=tcp:5000 --source-ranges=0.0.0.0\/0 --target-tags=mlflow-server\n<\/code><\/pre><\/li>\n<li><p>check from on-premises Linux machine <code>nmap -Pn 35.225.XXX.XXX<\/code><\/p>\n\n<pre><code>Starting Nmap 7.80 ( https:\/\/nmap.org ) at 2020-03-09 16:20 CET\nNmap scan report for 74.123.225.35.bc.googleusercontent.com (35.225.XXX.XXX)\nHost is up (0.20s latency).\nNot shown: 993 filtered ports\nPORT     STATE  SERVICE\n...\n5000\/tcp open   upnp\n...\n<\/code><\/pre><\/li>\n<li><p>go to web browser <a href=\"http:\/\/35.225.XXX.XXX:5000\/\" rel=\"noreferrer\">http:\/\/35.225.XXX.XXX:5000\/<\/a><\/p><\/li>\n<\/ol>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/u2aFt.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/u2aFt.png\" alt=\"mlflow\"><\/a><\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":11.0,
        "Solution_readability":8.4,
        "Solution_reading_time":39.18,
        "Solution_score_count":5.0,
        "Solution_sentence_count":29.0,
        "Solution_word_count":297.0,
        "Tool":"MLflow"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":20.56922,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>Bunch of secrets being automatically created in key vault that is integrated into Azure ML workspace(s). These secrets seem to be generated by the ML resource\/service itself and continues to generate new secrets.<\/p>\n<p>\u00a0Can you please help with the document for these secrets?<\/p>",
        "Challenge_closed_time":1682931416008,
        "Challenge_comment_count":1,
        "Challenge_created_time":1682857366816,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1270782\/secrets-automatically-created-in-key-vault",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":10.4,
        "Challenge_reading_time":4.1,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":20.56922,
        "Challenge_title":"Secrets automatically created in key vault",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":49,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>@<a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=dfa9d536-725c-462d-87c8-47fbafb1a2bc\">D-0887<\/a> Thanks, When you perform operations in Azure ML that require secret values to be stored like creating connections, datastores, or workspace management operations, the key vault instance associated to the workspace is used to store those secrets.<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":22.0,
        "Solution_reading_time":4.76,
        "Solution_score_count":0.0,
        "Solution_sentence_count":1.0,
        "Solution_word_count":39.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1582301202872,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":41.0,
        "Answerer_view_count":3.0,
        "Challenge_adjusted_solved_time":44.77405,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>When deploying a real-time inferencing pipeline in Azure ML (as per <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-deploy#deploy-the-real-time-endpoint\" rel=\"nofollow noreferrer\">this<\/a> tutorial), I receive the below error. I've tried forcibly logging out using OAuth. Tried creating a new Azure workspace but continue to receive the same error.<\/p>\n\n<p>It looks like the tenant id causing the problem is example.onmicrosoft.com (72f988bf-86f1-41af-91ab-2d7cd011db47)<\/p>\n\n<hr>\n\n<p><em>Deploy: Failed on step CreateServiceFromModels. Details: AzureML service API error. Error calling ServiceCreate: {\"code\":\"Unauthorized\",\"statusCode\":401,\"message\":\"Unauthorized\",\"details\":[{\"code\":\"EmptyOrInvalidToken\",\"message\":\"Error: Service invocation failed!\\r\\nRequest: GET <a href=\"https:\/\/management.azure.com\/subscriptions\/subscription_id\/resourceGroups\/dev-rg\/providers\/Microsoft.MachineLearningServices\/workspaces\/dev-ws\/providers\/Microsoft.Authorization\/permissions?api-version=2015-07-01\" rel=\"nofollow noreferrer\">https:\/\/management.azure.com\/subscriptions\/subscription_id\/resourceGroups\/dev-rg\/providers\/Microsoft.MachineLearningServices\/workspaces\/dev-ws\/providers\/Microsoft.Authorization\/permissions?api-version=2015-07-01<\/a>\\r\\nStatus Code: 401 Unauthorized\\r\\nReason Phrase: Unauthorized\\r\\nResponse Body: {\\\"error\\\":{\\\"code\\\":\\\"InvalidAuthenticationTokenTenant\\\",\\\"message\\\":\\\"The access token is from the wrong issuer '<a href=\"https:\/\/sts.windows.net\/72f988bf-86f1-41af-91ab-2d7cd011db47\/\" rel=\"nofollow noreferrer\">https:\/\/sts.windows.net\/72f988bf-86f1-41af-91ab-2d7cd011db47\/<\/a>'. It must match the tenant '<a href=\"https:\/\/sts.windows.net\/correct_tenant_id\/\" rel=\"nofollow noreferrer\">https:\/\/sts.windows.net\/correct_tenant_id\/<\/a>' associated with this subscription. Please use the authority (URL) '<a href=\"https:\/\/login.windows.net\/correct_tenant_id\" rel=\"nofollow noreferrer\">https:\/\/login.windows.net\/correct_tenant_id<\/a>' to get the token. Note, if the subscription is transferred to another tenant there i<\/em><\/p>",
        "Challenge_closed_time":1582556597823,
        "Challenge_comment_count":2,
        "Challenge_created_time":1582302156893,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1582395411243,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/60342645",
        "Challenge_link_count":9,
        "Challenge_participation_count":3,
        "Challenge_readability":23.7,
        "Challenge_reading_time":29.64,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":2.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":20,
        "Challenge_solved_time":70.6780361111,
        "Challenge_title":"Azure ML inference pipeline deployment authorization token error",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":481.0,
        "Challenge_word_count":138,
        "Platform":"Stack Overflow",
        "Poster_created_time":1582301202872,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":41.0,
        "Poster_view_count":3.0,
        "Solution_body":"<p>I appear to have had User Access Administrator role only (in addition to Classic Service Administrator). As soon as I added myself to the Owner role in the Access Control (IAM) section of the Azure Portal, the deployment succeeded.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":12.1,
        "Solution_reading_time":2.94,
        "Solution_score_count":2.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":39.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1491898605956,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Sydney NSW, Australia",
        "Answerer_reputation_count":161.0,
        "Answerer_view_count":7.0,
        "Challenge_adjusted_solved_time":482.1258816667,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am currently creating a GroundTruth Labeling job, and am following the tutorial\n<a href=\"https:\/\/www.youtube.com\/watch?v=_FPI6KjDlCI&amp;t=210s\" rel=\"nofollow noreferrer\">https:\/\/www.youtube.com\/watch?v=_FPI6KjDlCI&amp;t=210s<\/a>\nI have created the same bucket <code>ground-truth-example-labeling-job<\/code> and uploaded jpg files within the bucket. Within this tutorial, under Select S3 bucket or resource, they were able to go within the S3 Bucket and access the jpg files inside.<\/p>\n<p>However, I am able to go inside the <code>ground-truth-example-labeling-job<\/code> bucket, but no jpg files are visible for me to select. The entire bucket is empty with nothing to select.<\/p>\n<p>Is this a permissions settings problem?<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/sdXZw.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/sdXZw.png\" alt=\"enter image description here\" \/><\/a>\n<a href=\"https:\/\/i.stack.imgur.com\/s10qk.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/s10qk.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Challenge_closed_time":1651560562667,
        "Challenge_comment_count":0,
        "Challenge_created_time":1649824909493,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/71851981",
        "Challenge_link_count":6,
        "Challenge_participation_count":1,
        "Challenge_readability":12.8,
        "Challenge_reading_time":14.85,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":13,
        "Challenge_solved_time":482.1258816667,
        "Challenge_title":"Objects Not Visible Within S3 Bucket for GroundTruth Labeling Job",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":66.0,
        "Challenge_word_count":119,
        "Platform":"Stack Overflow",
        "Poster_created_time":1595831555067,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":37.0,
        "Poster_view_count":27.0,
        "Solution_body":"<p>You cannot select the files.<\/p>\n<p>But if you have a folder within a bucket then you can select that folder which consists of the input data.<\/p>\n<p>In the video they selected the bucket but not the files.<\/p>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":5.7,
        "Solution_reading_time":2.6,
        "Solution_score_count":1.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":37.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":31.5278255556,
        "Challenge_answer_count":1,
        "Challenge_body":"When having made a labeling job on Ground Truth, an outgoing mail should be sent to team member, but in my case, mail not be sent with no error message.\n\n1. in case no private team created (the first job creation) : mail can be sent. (set up a team during job creation)\n2. in case a private team already set up: mail cannot be sent. (select a existing team during job creation)\n\nI think policies of the job role might not be enough, for example, cognito policy. How can I make sure the cause of the error?",
        "Challenge_closed_time":1662130403760,
        "Challenge_comment_count":0,
        "Challenge_created_time":1662016903588,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1667926589664,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUqbxtiU_kSe-GoPcj6g0pzg\/outgoing-mail-for-sagemaker-labeling-job",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":6.6,
        "Challenge_reading_time":6.49,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":31.5278255556,
        "Challenge_title":"Outgoing mail for sagemaker labeling job",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":68.0,
        "Challenge_word_count":102,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"To Successfully create a SageMaker Labeling Job you will need the following Permission Policies applied within your account:\n\n1. The IAM entity you have used to create the job will need permissions outlined in the \"Permissions Required to Use the Amazon SageMaker Ground Truth Console\" [1]\n2. Your Labelling Job Role will need SageMakerFullAccess [2]\n\nWith these permissions in place your job should create successfully.\n\nLinks to documentation provided by AWS:\n\n[1] https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/security_iam_id-based-policy-examples.html#console-permissions\n\n[2] https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/security-iam-awsmanpol.html#security-iam-awsmanpol-AmazonSageMakerFullAccess",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":1662130403760,
        "Solution_link_count":2.0,
        "Solution_readability":17.4,
        "Solution_reading_time":9.23,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":75.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1475181309096,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Brazil",
        "Answerer_reputation_count":4242.0,
        "Answerer_view_count":421.0,
        "Challenge_adjusted_solved_time":19.7379844444,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am creating my own Docker image so that I can use my own models in AWS SageMaker. I sucessfully created a Docker image using command line inside the Jupyter Notebook in SageMaker ml.t2.medium instance using a customized Dockerfile:<\/p>\n\n<pre><code>REPOSITORY            TAG                 IMAGE ID            CREATED             SIZE\nsklearn               latest              01234212345        6 minutes ago       1.23GB\n<\/code><\/pre>\n\n<p>But when I run in Jupyter:<\/p>\n\n<pre><code>! aws ecr create-repository --repository-name sklearn\n<\/code><\/pre>\n\n<p>I get the following error:<\/p>\n\n<pre><code>An error occurred (AccessDeniedException) when calling the CreateRepository operation: User: arn:aws:sts::1234567:assumed-role\/AmazonSageMaker-ExecutionRole-12345\/SageMaker is not authorized to perform: ecr:CreateRepository on resource: *\n<\/code><\/pre>\n\n<p>I already set up SageMaker, EC2, EC2ContainerService permissions and the following policy for EC2Container but I still get the same error.<\/p>\n\n<pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"sagemaker:*\",\n        \"ec2:*\"\n      ],\n      \"Resource\": \"*\"\n    }\n  ]\n}\n<\/code><\/pre>\n\n<p>Any idea on how I can solve this issue?<\/p>\n\n<p>Thanks in advance.<\/p>",
        "Challenge_closed_time":1528126261856,
        "Challenge_comment_count":3,
        "Challenge_created_time":1528052776997,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1528055205112,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/50669991",
        "Challenge_link_count":0,
        "Challenge_participation_count":4,
        "Challenge_readability":13.9,
        "Challenge_reading_time":15.5,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":8,
        "Challenge_solved_time":20.4124608333,
        "Challenge_title":"AWS SageMaker is not authorized to perform: ecr:CreateRepository on resource: *",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":4509.0,
        "Challenge_word_count":145,
        "Platform":"Stack Overflow",
        "Poster_created_time":1475181309096,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Brazil",
        "Poster_reputation_count":4242.0,
        "Poster_view_count":421.0,
        "Solution_body":"<p>I solved the problem. We must set a permission at SageMaker Execution Role as following:<\/p>\n\n<pre><code>{\n\"Version\": \"2012-10-17\",\n\"Statement\": [\n    {\n        \"Effect\": \"Allow\",\n        \"Action\": [\n            \"ecr:*\"            ],\n        \"Resource\": \"*\"\n    }\n]}\n<\/code><\/pre>",
        "Solution_comment_count":2.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":9.3,
        "Solution_reading_time":2.88,
        "Solution_score_count":5.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":25.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1522634496792,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Rio de Janeiro, RJ, Brasil",
        "Answerer_reputation_count":264.0,
        "Answerer_view_count":23.0,
        "Challenge_adjusted_solved_time":26.5148555556,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I have many experiment, like:<\/p>\n<p><img src=\"https:\/\/user-images.githubusercontent.com\/40580910\/95883598-82a07d00-0d51-11eb-847d-872452f6caa4.png\" alt=\"image\" \/><\/p>\n<p>and now, i want load an experiment<\/p>\n<pre><code>#%% sumonando os pacotes e verificando azureml.core\nimport azureml.core\nimport pandas as pd\nimport numpy as np\nimport logging\n\nprint(&quot;AzureML SDK Version: &quot;, azureml.core.VERSION)\n\n#%% Conectando ao azure e crinado o exparimento\n\nfrom azureml.core import Workspace, Experiment\n\nws = Workspace.from_config() \nprint(Experiment.list(ws))\n#%%\nExperiment = Experiment.from_directory('teste2-Monitor-Runs') `\n<\/code><\/pre>\n<p>but<\/p>\n<pre><code>&quot;error&quot;: {\n    &quot;message&quot;: &quot;No cache found for current project, try providing resource group and workspace \narguments&quot;\n}`\n<\/code><\/pre>\n<hr \/>\n<p>Content: <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.experiment(class)?view=azure-ml-py\" rel=\"nofollow noreferrer\">azureml.core.Experiment class - Azure Machine Learning Python<\/a><\/p>",
        "Challenge_closed_time":1602700300720,
        "Challenge_comment_count":0,
        "Challenge_created_time":1602604847240,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/64338898",
        "Challenge_link_count":2,
        "Challenge_participation_count":2,
        "Challenge_readability":14.8,
        "Challenge_reading_time":14.62,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":11,
        "Challenge_solved_time":26.5148555556,
        "Challenge_title":"How to load an experiment in azureml?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":254.0,
        "Challenge_word_count":92,
        "Platform":"Stack Overflow",
        "Poster_created_time":1522634496792,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Rio de Janeiro, RJ, Brasil",
        "Poster_reputation_count":264.0,
        "Poster_view_count":23.0,
        "Solution_body":"<p>I believe it is that way.<\/p>\n<pre><code>from azureml.core import Experiment, Workspace\nExperiment = ws.experiments[&quot;teste2-Monitor-Runs&quot;]\n<\/code><\/pre>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":15.7,
        "Solution_reading_time":2.22,
        "Solution_score_count":0.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":14.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":0.9340691667,
        "Challenge_answer_count":1,
        "Challenge_body":"Is there any overlap of permissions between a space execution role and a user profile execution role, if those two are given different permissions? Does it behave the same as with service control policies (SCPs) and policies on IAM roles, where the overlap is what takes effect? For example, if the space execution role has an explicit deny (or even an implicit deny for that matter!) for `CreateApp`, but the user profile execution role has an explicit allow for `CreateApp`, then that user profile won't be able to CreateApp?",
        "Challenge_closed_time":1671479342572,
        "Challenge_comment_count":0,
        "Challenge_created_time":1671475979923,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1671823545396,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUUTo01GFWQlyRYDXAKQInyA\/venn-diagram-of-permissions-in-sagemaker-studio",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":10.7,
        "Challenge_reading_time":7.08,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":0.9340691667,
        "Challenge_title":"Venn diagram of permissions in SageMaker Studio?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":156.0,
        "Challenge_word_count":95,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"Hi Yann, the user profile's execution role is what will be used within the context of the private app of the user profile. So, once a user hits Launch -> Studio or is redirected to Studio UI through SSO, the user's execution role will allow them to launch apps such as data science app, data wrangler app, etc.\n\nThe default space execution role is what is assumed by the user once they are in a shared space. So, once the user is in the UI by clicking Launch -> Spaces, the user cannot create apps to run notebooks in, within that space.\n\nTL;DR - they are two distinct roles, each giving the user permissions on a private space or a shared space, and do not work like SCPs. Any user in the shared space within a domain, will share the same execution role as of today. However, for the private space, each user profile can have their own role if needed.",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1671492806348,
        "Solution_link_count":0.0,
        "Solution_readability":9.7,
        "Solution_reading_time":10.14,
        "Solution_score_count":1.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":158.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":14.4512016667,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>Hello Microsoft Q&amp;A Team,    <\/p>\n<p>I get the error     <\/p>\n<blockquote>\n<p>AssetException: Error with code: Can't connect to HTTPS URL because the SSL module is not available    <\/p>\n<\/blockquote>\n<p> when executing the following command:    <\/p>\n<blockquote>\n<p>pipeline_job = ml_client.jobs.create_or_update(    <br \/>\n    pipeline_job, experiment_name=&quot;data_preparation&quot;    <br \/>\n)    <br \/>\npipeline_job    <\/p>\n<\/blockquote>\n<p>Yesterday the command worked without an error. I did not make any changes. So I have no idea, what the problem is.    <\/p>\n<p>Thanks for helping me out.    <\/p>\n<p>Cheers    <\/p>\n<p>Lukas    <\/p>",
        "Challenge_closed_time":1667605270036,
        "Challenge_comment_count":0,
        "Challenge_created_time":1667553245710,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1075753\/aml-assetexception-error-with-code-cant-connect-to",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":8.6,
        "Challenge_reading_time":9.02,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":14.4512016667,
        "Challenge_title":"AML - AssetException: Error with code: Can't connect to HTTPS URL because the SSL module is not available.",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":96,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=733bec54-8d30-4052-8297-64b100f6e3d4\">@Lukas  <\/a> Thanks for your question. Can you please add more details about the document\/sample that you are trying.<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":6.0,
        "Solution_reading_time":2.48,
        "Solution_score_count":0.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":20.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1600124498003,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":46.0,
        "Answerer_view_count":2.0,
        "Challenge_adjusted_solved_time":110.7464591667,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I've set up a ClearML server in GCP using the sub-domain approach. I can access all three domains (<code>https:\/\/app.clearml.mydomain.com<\/code>, <code>https:\/\/api.clearml.mydomain.com<\/code> and <code>https:\/\/files.clearml.mydomain.com<\/code>) in a browser and see what I think is the correct response, but when connecting with the python SDK via <code>clearml-init<\/code> I get the following error:<\/p>\n<pre><code>clearml.backend_api.session.session.LoginError: Failed getting token (error 400 from https:\/\/api.clearml.mydomain.com): Bad Request\n<\/code><\/pre>\n<p>Are there any likely causes of this error?<\/p>",
        "Challenge_closed_time":1640162037740,
        "Challenge_comment_count":0,
        "Challenge_created_time":1639763350487,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/70397010",
        "Challenge_link_count":4,
        "Challenge_participation_count":1,
        "Challenge_readability":11.1,
        "Challenge_reading_time":8.87,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":110.7464591667,
        "Challenge_title":"What would stop credentials from validation on a ClearML server?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":194.0,
        "Challenge_word_count":76,
        "Platform":"Stack Overflow",
        "Poster_created_time":1600124498003,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":46.0,
        "Poster_view_count":2.0,
        "Solution_body":"<p>Following the discussion <a href=\"https:\/\/github.com\/allegroai\/clearml\/issues\/517\" rel=\"nofollow noreferrer\">here<\/a>, it seemed that the load balancer being used was blocking <code>GET<\/code> requests with a payload which are used by ClearML. A <a href=\"https:\/\/github.com\/allegroai\/clearml\/pull\/521\" rel=\"nofollow noreferrer\">fix<\/a> is being worked on to allow the method to be changed to a <code>POST<\/code> request via an environment variable.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":11.8,
        "Solution_reading_time":5.95,
        "Solution_score_count":0.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":51.0,
        "Tool":"ClearML"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":1.4038472222,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hallo, i would like make an appointment for Exam AI-900: Microsoft Azure AI Fundamentals.     <br \/>\nHowever this exam is currently not available at Pearson vue or Certiport. When can i expect this again? Is there an alternative ?<\/p>",
        "Challenge_closed_time":1662210933980,
        "Challenge_comment_count":0,
        "Challenge_created_time":1662205880130,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/992629\/certification-test-for-ai-900-microsoft-azure-ai-f",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":8.1,
        "Challenge_reading_time":3.86,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":1.4038472222,
        "Challenge_title":"certification test for AI-900: Microsoft Azure AI Fundamentals not available",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":47,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hi Jurian,    <\/p>\n<p>This is available in PearsonVue check this.  <a href=\"https:\/\/learn.microsoft.com\/en-us\/certifications\/exams\/ai-900\">ai-900<\/a>    <\/p>\n<p>Any specific region you are trying from?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/237503-image.png?platform=QnA\" alt=\"237503-image.png\" \/>    <\/p>\n<p>==    <br \/>\nPlease &quot;Accept the answer&quot; if the information helped you. This will help us and others in the community as well.    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":11.8,
        "Solution_reading_time":6.23,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":48.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":371.2785480556,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>What can I do when I forget my password in the local wandb?<br>\nIt seems that deleting or uninstalling  doesn\u2019t work.<\/p>",
        "Challenge_closed_time":1646784628352,
        "Challenge_comment_count":0,
        "Challenge_created_time":1645448025579,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/forgot-password-in-local\/1959",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":5.2,
        "Challenge_reading_time":1.84,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":371.2785480556,
        "Challenge_title":"Forgot password in local",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":273.0,
        "Challenge_word_count":24,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hi <a class=\"mention\" href=\"\/u\/nightmare4214\">@nightmare4214<\/a> ,<\/p>\n<p>Could you try the following steps?<\/p>\n<ul>\n<li>Log into the docker container using <code>docker exec -it wandb-local bash<\/code>\n<\/li>\n<li>Type <code>\/usr\/local\/bin\/local password EMAIL@ADDRESS.com<\/code> (where <code>EMAIL@ADDRESS.com<\/code> is your email)<\/li>\n<\/ul>\n<p>This should let you manually reset your password for the local instance and you should be able to log in through this. Please let me know if this does not work for you.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":7.8,
        "Solution_reading_time":7.04,
        "Solution_score_count":null,
        "Solution_sentence_count":6.0,
        "Solution_word_count":69.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_created_time":1584379010350,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":36.0,
        "Answerer_view_count":0.0,
        "Challenge_adjusted_solved_time":18.4716680556,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I'm having an issue with AWS when I try to create a device fleet with sagemaker :<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import boto3\n\nsagemaker_client = boto3.client('sagemaker', region_name=AWS_REGION)\nsagemaker_client.create_device_fleet(\n    DeviceFleetName=device_fleet_name,\n    RoleArn=iot_role_arn,\n    OutputConfig={\n        'S3OutputLocation': s3_device_fleet_output\n    }\n)\n\n<\/code><\/pre>\n<p>It raises the following exception:<\/p>\n<blockquote>\n<p>ClientError: An error occurred (ValidationException) when calling the CreateDeviceFleet operation: The account id &lt;my-account-id&gt; does not have ownership on bucket: &lt;bucket-name&gt;<\/p>\n<\/blockquote>\n<p>I dont get it because I created the bucket so I should be the owner. I have not found how to check or change bucket ownership.<\/p>\n<p>I tried changing the bucket policy as follows but it didn't help.<\/p>\n<pre class=\"lang-json prettyprint-override\"><code>{\n    &quot;Version&quot;: &quot;2012-10-17&quot;,\n    &quot;Statement&quot;: [\n        {\n            &quot;Sid&quot;: &quot;Statement1&quot;,\n            &quot;Principal&quot;: {\n                &quot;AWS&quot;: &quot;arn:aws:iam::&lt;id&gt;:user\/&lt;user&gt;&quot;\n            },\n            &quot;Effect&quot;: &quot;Allow&quot;,\n            &quot;Action&quot;: &quot;*&quot;,\n            &quot;Resource&quot;: [\n                &quot;arn:aws:s3:::&lt;bucket-name&gt;&quot;,\n                &quot;arn:aws:s3:::&lt;bucket-name&gt;\/*&quot;\n            ]\n        }\n    ]\n}\n\n<\/code><\/pre>\n<p>I also tried with sagemaker's GUI, it fails for the same reason (ValidationException, the account id &lt;my-account-id&gt; does not have ownership on bucket : &lt;bucket-name&gt;).<\/p>",
        "Challenge_closed_time":1641479927648,
        "Challenge_comment_count":2,
        "Challenge_created_time":1641413429643,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/70599052",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":17.7,
        "Challenge_reading_time":21.43,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":18.4716680556,
        "Challenge_title":"AWS CreateDeviceFleet operation fail because \"the account id does not have ownership on bucket\"",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":48.0,
        "Challenge_word_count":153,
        "Platform":"Stack Overflow",
        "Poster_created_time":1584379010350,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":36.0,
        "Poster_view_count":0.0,
        "Solution_body":"<p>This bucket policy made it work :<\/p>\n<pre class=\"lang-json prettyprint-override\"><code>{\n    &quot;Version&quot;: &quot;2012-10-17&quot;,\n    &quot;Statement&quot;: [\n        {\n            &quot;Sid&quot;: &quot;Statement1&quot;,\n            &quot;Effect&quot;: &quot;Allow&quot;,\n            &quot;Principal&quot;: {\n                &quot;AWS&quot;: &quot;arn:aws:iam::&lt;account-id&gt;:role\/&lt;iot-role&gt;&quot;\n            },\n            &quot;Action&quot;: &quot;*&quot;,\n            &quot;Resource&quot;: [\n                &quot;arn:aws:s3:::&lt;bucket-name&gt;&quot;,\n                &quot;arn:aws:s3:::&lt;bucket-name&gt;\/*&quot;\n            ]\n        }\n    ]\n}\n<\/code><\/pre>\n<p>I still don't fully get it, because the role had full access on s3 buckets so i don't know why editing the bucket's policy changed something, but it works.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":29.5,
        "Solution_reading_time":9.24,
        "Solution_score_count":0.0,
        "Solution_sentence_count":1.0,
        "Solution_word_count":55.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":12.3472294445,
        "Challenge_answer_count":1,
        "Challenge_body":"![Studio encountered an error when creating your project](https:\/\/repost.aws\/media\/postImages\/original\/IMWYkHCNADT7ihgQuoRgh7nQ)\nI trying tutorial on \"MLOps template for model building, training, and deployment with third-party Git repositories using CodePipeline\". But I am getting  error as shown in image",
        "Challenge_closed_time":1658994240283,
        "Challenge_comment_count":0,
        "Challenge_created_time":1658949790257,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1668585903416,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUOCKdskABQumCC7OnzBZR4g\/sagemaker-studio-encountered-an-error-when-creating-your-project-github-and-codepipeline-template",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":14.9,
        "Challenge_reading_time":5.29,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":12.3472294445,
        "Challenge_title":"Sagemaker Studio encountered an error when creating your project(github and codepipeline template)",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":165.0,
        "Challenge_word_count":46,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"Hello. It seems like you are having permission problems according to the snapshot you provided. \nIf you head to the Cloudformation service, you will probably get a better understanding of where the tamplate is failing. \nMake sure to have followed the prerequisites and check out this [section](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/sagemaker-projects-templates-sm.html#sagemaker-projects-templates-update).",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":1658994240283,
        "Solution_link_count":1.0,
        "Solution_readability":15.3,
        "Solution_reading_time":5.41,
        "Solution_score_count":1.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":47.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":3.1427777778,
        "Challenge_answer_count":1,
        "Challenge_body":"A customer is trying to setup Sagemaker studio. He is following our published instructions to set up using IAM: https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/onboard-iam.html\n\nBut is getting an error: User:  arn:aws:iam:xxxx:user\/user1 is not authorized to perform: sagemaker:CreateDomain on resource: arn:aws:sagemaker: us-east-2:xxxx:domain\/yyyy\n\nHe has admin priviledges on the account and AmazonSageMakerFullAccess. We noticed that the AmazonSageMakerFullAccess policy actually has a limitation. You can perform all sagemaker actions, but not on a resource with arn \u201carn:aws:sagemaker:*:*:domain\/*\u201d. \nWe confirmed there are no other domains in that region with the CLI as you are only allowed one \u2013 so that isn\u2019t blocking.\nAnd aws sagemaker list-user-profiles returns no user profiles. \n\nHas anyone seen that error before or know the workaround? Should he create a custom policy to enable creating domains or would there be any implications of that? Are there specific permissions he should have so as to onboard using IAM?",
        "Challenge_closed_time":1586807470000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1586796156000,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1668609159168,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUyWQfPusnSHG6Ujfzx27o1w\/sagemaker-studio-create-domain-error",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":12.0,
        "Challenge_reading_time":13.44,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":11,
        "Challenge_solved_time":3.1427777778,
        "Challenge_title":"Sagemaker Studio - create domain error",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":1584.0,
        "Challenge_word_count":146,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"A user with admin privileges would have access to `\"iam:CreateServiceLinkedRole\"` and `\"sagemaker:CreateDomain\"` actions, unless SCPs or permissions boundaries are involved. However, for the purpose of onboarding Amazon SageMaker Studio with limited permissions, I would grant the user [least privilege](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/security_iam_id-based-policy-examples.html#security_iam_service-with-iam-policy-best-practices) by reviewing [Control Access to the Amazon SageMaker API by Using Identity-based Policies](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/security_iam_id-based-policy-examples.html#api-access-policy) and [Actions, Resources, and Condition Keys for Amazon SageMaker](https:\/\/docs.aws.amazon.com\/IAM\/latest\/UserGuide\/list_amazonsagemaker.html) documentation:\n\n    {\n        \"Effect\": \"Allow\",\n        \"Action\": \"sagemaker:CreateDomain\",\n        \"Resource\": \"arn:aws:sagemaker:<REGION>:<ACCOUNT-ID>:domain\/*\"\n    }\n\nNOTE: An AWS account is limited to one Domain, per region, see [CreateDomain](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/APIReference\/API_CreateDomain.html).\n\n    {\n        \"Effect\": \"Allow\",\n        \"Action\": \"iam:CreateServiceLinkedRole\",\n        \"Resource\": \"*\",\n        \"Condition\": {\n            \"StringEquals\": {\n                \"iam:AWSServiceName\": \"sagemaker.amazonaws.com\"\n            }\n        }\n    }\n\nCheers!",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1667925577936,
        "Solution_link_count":4.0,
        "Solution_readability":28.1,
        "Solution_reading_time":17.07,
        "Solution_score_count":1.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":91.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1253986272627,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":11930.0,
        "Answerer_view_count":2649.0,
        "Challenge_adjusted_solved_time":51.1702544445,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have created a model with VPC, Private subnet, and appropriate security group. The endpoint URL can, however, be reached through the internet though failing due to the lack of security token<\/p>\n\n<p>Things I need clarification on now are<\/p>\n\n<ol>\n<li>Is there a way to avoid the URL being accessible from the internet<\/li>\n<li>Are we not charged for requests failed on AUTH(like for API Gateway)<\/li>\n<li>Does that make our deployment vulnerable to any attacks<\/li>\n<\/ol>",
        "Challenge_closed_time":1550250221603,
        "Challenge_comment_count":0,
        "Challenge_created_time":1550066008687,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/54671841",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":13.8,
        "Challenge_reading_time":6.65,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":51.1702544445,
        "Challenge_title":"Sagemaker endpoint(with VPC) url accessible from internet",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":679.0,
        "Challenge_word_count":81,
        "Platform":"Stack Overflow",
        "Poster_created_time":1320419229500,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":4924.0,
        "Poster_view_count":358.0,
        "Solution_body":"<p>You are not hitting your endpoint, but the endpoint of AWS SageMaker runtime. This endpoint is checking all the permissions to access your hosted model, and only if the credentials and requirements are met, the request is forwarded to your instances and models. <\/p>\n\n<p>Therefore, you can't prevent this URL from being accessible from the Internet, but at the same time, you don't need to protect it or pay for it. AWS has a high level of security on these endpoints, and I don't think that you have a more secure way to protect these endpoints. <\/p>",
        "Solution_comment_count":4.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":10.4,
        "Solution_reading_time":6.71,
        "Solution_score_count":3.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":97.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1365101584443,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Munich, Germany",
        "Answerer_reputation_count":7203.0,
        "Answerer_view_count":445.0,
        "Challenge_adjusted_solved_time":0.7841066667,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have a step function statemachine which creates SageMaker batch transform job, the definition is written in Terraform, I wanted to add the stepfunction execution id to the batch transform job names:<\/p>\n<p>in stepfunction terraform file:<\/p>\n<pre><code>  definition = templatefile(&quot;stepfuntion.json&quot;,\n    {\n      xxxx\n)\n<\/code><\/pre>\n<p>in the &quot;stepfuntion.json&quot;:<\/p>\n<pre><code>{...\n          &quot;TransformJobName&quot;: &quot;jobname-$$.Execution.Id&quot;,\n  \n          }\n      },\n        &quot;End&quot;: true\n      }\n    }\n  }\n<\/code><\/pre>\n<p>But after terraform apply, it didn't generate the actual id, it gave me <code>jobname-$$.Execution.Id<\/code>, can anyone help with this please?<\/p>\n<p>Resources: <a href=\"https:\/\/docs.aws.amazon.com\/step-functions\/latest\/dg\/input-output-contextobject.html\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/step-functions\/latest\/dg\/input-output-contextobject.html<\/a>\n&quot;To access the context object, first specify the parameter name by appending .$ to the end, as you do when selecting state input with a path. Then, to access context object data instead of the input, prepend the path with $$.. This tells AWS Step Functions to use the path to select a node in the context object.&quot;<\/p>\n<p>Can someone tell me what I'm missing please?<\/p>",
        "Challenge_closed_time":1610017101707,
        "Challenge_comment_count":0,
        "Challenge_created_time":1610012100150,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1610014278923,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/65609804",
        "Challenge_link_count":2,
        "Challenge_participation_count":1,
        "Challenge_readability":14.0,
        "Challenge_reading_time":17.23,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":12,
        "Challenge_solved_time":1.3893213889,
        "Challenge_title":"How to append stepfunction execution id to SageMaker job names?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":488.0,
        "Challenge_word_count":148,
        "Platform":"Stack Overflow",
        "Poster_created_time":1540920956270,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"United Kingdom",
        "Poster_reputation_count":2385.0,
        "Poster_view_count":585.0,
        "Solution_body":"<p>The var you are trying to use terraform doesn't know about it<\/p>\n<blockquote>\n<p>jobname-$$.Execution.Id.<\/p>\n<\/blockquote>\n<p>That's something specific to the Step function and available within state machine not available for terraform.<\/p>",
        "Solution_comment_count":17.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":9.3,
        "Solution_reading_time":3.16,
        "Solution_score_count":1.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":31.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1546969667040,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"New York, NY, USA",
        "Answerer_reputation_count":1689.0,
        "Answerer_view_count":170.0,
        "Challenge_adjusted_solved_time":1.9175436111,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I know there is a good tutorial on how to create jupyter notebooks on AWS sagemaker \"the easy way\".<\/p>\n\n<p>Do you know if it is possible to allow 10 students to create jupyter-notebooks who do not have an AWS accounts, and also allow them to edit jupyter-notebooks?<\/p>",
        "Challenge_closed_time":1554143903380,
        "Challenge_comment_count":0,
        "Challenge_created_time":1554137000223,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1554180914787,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/55459903",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":9.0,
        "Challenge_reading_time":3.98,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":2.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":1.9175436111,
        "Challenge_title":"multiuser public jupyter notebook on AWS sagemaker",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":1259.0,
        "Challenge_word_count":53,
        "Platform":"Stack Overflow",
        "Poster_created_time":1394050586807,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":568.0,
        "Poster_view_count":67.0,
        "Solution_body":"<p>Enabling multiple users to leverage the same notebook (in this case, without authentication) will involve managing your Security Groups to enable open access. You can filter, allowing access for a known IP address range, if your students are accessing it from a classroom or campus, for example.<\/p>\n\n<p>Tips for this are available in <a href=\"https:\/\/stackoverflow.com\/questions\/42617692\/is-it-possible-to-grant-multiple-users-to-jupyter-notebook\">this answer<\/a> and this page from the documentation, diving into <a href=\"https:\/\/aws.amazon.com\/blogs\/machine-learning\/understanding-amazon-sagemaker-notebook-instance-networking-configurations-and-advanced-routing-options\/\" rel=\"nofollow noreferrer\">network configurations for SageMaker hosted notebook instances<\/a>.<\/p>\n\n<p>As for enabling students to spin up their own notebooks, I'm not sure if it's possible to enable completely unauthenticated AWS-level resource provisioning -- however once you've spun up a single managed notebook instance yourself, students can create their own notebooks directly from the browser in Jupyter, once they've navigated to the publicly available IP. You may need to attach a new SageMaker IAM role that enables notebook creation (amongst other things, depending on the workload requirements). Depending on the computational needs (number, duration, and types of concurrent workloads), there will be different optimal setups of number of managed instances and instance type to prevent computational bottlenecking.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1554169700776,
        "Solution_link_count":2.0,
        "Solution_readability":16.8,
        "Solution_reading_time":19.51,
        "Solution_score_count":1.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":180.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1653511725307,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":35.0,
        "Answerer_view_count":26.0,
        "Challenge_adjusted_solved_time":165.2682675,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I created a sagemaker project with a terraform template which successfully created with a stack successfully created and associated with it. However, there is no repository associated or pipeline associated with the sagemaker project despite there being both in the cloudformation template I used. Can someone help with this?<\/p>\n<p>Is there a way to manually link a sagemaker project with a code commit repository? I see that succesfully linked repositories have the tag: <code>sagemaker:project-name<\/code> with the correct project name.<\/p>",
        "Challenge_closed_time":1657906025030,
        "Challenge_comment_count":2,
        "Challenge_created_time":1657295938437,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1657311059267,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/72914046",
        "Challenge_link_count":0,
        "Challenge_participation_count":4,
        "Challenge_readability":11.5,
        "Challenge_reading_time":8.02,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":169.4684980556,
        "Challenge_title":"Sagemaker Project successfully creates but there are no linked pipelines or repositories",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":124.0,
        "Challenge_word_count":90,
        "Platform":"Stack Overflow",
        "Poster_created_time":1653511725307,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":35.0,
        "Poster_view_count":26.0,
        "Solution_body":"<p>Using a different cloudformation template fixed the issue. Not sure why.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":6.6,
        "Solution_reading_time":1.01,
        "Solution_score_count":0.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":11.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1526004205792,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"China",
        "Answerer_reputation_count":28087.0,
        "Answerer_view_count":3298.0,
        "Challenge_adjusted_solved_time":16.0070080556,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I'm having the following error while trying to submit an Azure ML Studio pipeline<\/p>\n<p><code>Get credentials or pull docker image failed with err: error response from daemon: get https:\/\/lgcrmldev.azurecr.io\/v2\/azureml\/azureml_977f5bda2f6f4f634482661c121c8959\/manifests\/latest: unauthorized: authentication required, visit https:\/\/aka.ms\/acr\/authorization for more information.<\/code><\/p>\n<p>The notebook python code I'm doing is something on these lines:<\/p>\n<pre><code># create a Python script to do the actual work and save it in the pipeline folder:\n\n%%writefile $experiment_folder\/batch_online_retail.py\nimport os\nimport numpy as np\nfrom azureml.core import Model\nimport joblib\n\n\n# Called when the service is loaded\ndef init():\n    global model\n    \n    # Load the model\n    model_path = Model.get_model_path('Random_Forest_model')\n    model = joblib.load(model_path)\n\ndef run(batch):\n    try:\n        result = []\n        \n    # Process each line\n    for in range (len(batch)):\n        # Read the comma-delimited data into an array\n        data = np.genfromtxt(f, delimiter=',')        \n        # Reshape into a 2-dimensional array for prediction (model expects multiple items)\n        prediction = model.predict(data.reshape(1, -1))        \n        # Append prediction to results\n        resultList.append(&quot;{}: {}&quot;.format(os.path.basename(f), prediction[0]))\n    return resultList      \n<\/code><\/pre>\n<pre><code># Creating the run context\nfrom azureml.core import Environment\nfrom azureml.core.runconfig import DEFAULT_CPU_IMAGE\nfrom azureml.core.runconfig import CondaDependencies\n\n# Add dependencies required by the model\n# For scikit-learn models, you need scikit-learn\n# For parallel pipeline steps, you need azureml-core and azureml-dataprep[fuse]\ncd = CondaDependencies.create(conda_packages=['scikit-learn','pip'],\n                              pip_packages=['azureml-defaults','azureml-core','azureml-dataprep[fuse,pandas]'])\n\nbatch_env = Environment(name='batch_environment')\nbatch_env.python.conda_dependencies = cd\nbatch_env.docker.enabled = True\nbatch_env.docker.base_image = DEFAULT_CPU_IMAGE\nprint('Configuration ready.')\n\n<\/code><\/pre>\n<pre><code># Creating the ParallelRunStep\nfrom azureml.pipeline.steps import ParallelRunConfig, ParallelRunStep\nfrom azureml.pipeline.core import PipelineData\n\ndefault_ds = ws.get_default_datastore()\n\noutput_dir = PipelineData(name='inferences', \n                          datastore=default_ds, \n                          output_path_on_compute='online-retail\/results')\n\nparallel_run_config = ParallelRunConfig(\n    source_directory=experiment_folder,\n    entry_script=&quot;batch_online_retail.py&quot;,\n    mini_batch_size=&quot;5&quot;,\n    error_threshold=10,\n    output_action=&quot;append_row&quot;,\n    environment=batch_env,\n    compute_target=inference_cluster,\n    node_count=2)\n\nparallelrun_step = ParallelRunStep(\n    name='batch-score-retail',\n    parallel_run_config=parallel_run_config,\n    inputs=[batch_data_set.as_named_input('online_retail_batch')],\n    output=output_dir,\n    arguments=[],\n    allow_reuse=True\n)\n\nprint('Steps defined')\n<\/code><\/pre>\n<p>and finally,<\/p>\n<pre><code># Create an Azure ML experiment in your workspace, put the step into a pipeline and run it\nfrom azureml.core import Experiment\nfrom azureml.pipeline.core import Pipeline\n\npipeline = Pipeline(workspace=ws, steps=[parallelrun_step])\npipeline_run = Experiment(ws, 'online-retail-deployment-cf').submit(pipeline)\npipeline_run.wait_for_completion(show_output=True)\n<\/code><\/pre>\n<p>It's in this final step that I keep getting the error above.<\/p>\n<p>My Container Registry has my user and Azure ML resource as a Contributor in the access control panel, so I don't think it's lack of permissions.<\/p>\n<p>I've found this Microsoft page that seems to have a fix for the error I'm having:\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/container-registry\/container-registry-faq#docker-push-succeeds-but-docker-pull-fails-with-error-unauthorized-authentication-required\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/container-registry\/container-registry-faq#docker-push-succeeds-but-docker-pull-fails-with-error-unauthorized-authentication-required<\/a><\/p>\n<p>But I don't understand how can I implement the suggested fix. This is because the Docker image the notebook uses is inside the Compute Instance created in Azure ML which we have limited access.<\/p>\n<p>Any ideas on what is the problem and how to fix it?<\/p>\n<p>Thank you in advance,\nCarla<\/p>",
        "Challenge_closed_time":1613725945092,
        "Challenge_comment_count":0,
        "Challenge_created_time":1613668319863,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/66264795",
        "Challenge_link_count":4,
        "Challenge_participation_count":1,
        "Challenge_readability":17.1,
        "Challenge_reading_time":57.57,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":35,
        "Challenge_solved_time":16.0070080556,
        "Challenge_title":"Azure ML studio - Container Registry Error while trying to submit a pipeline",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":869.0,
        "Challenge_word_count":389,
        "Platform":"Stack Overflow",
        "Poster_created_time":1613665696487,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":3.0,
        "Poster_view_count":1.0,
        "Solution_body":"<p>According to the example <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-with-custom-image#define-your-environment\" rel=\"nofollow noreferrer\">here<\/a>, I think you need to configure the environment variables for the docker images stored in the Azure Container Registry:<\/p>\n<pre><code>batch_env = Environment(name='batch_environment')\nbatch_env.python.conda_dependencies = cd\nbatch_env.docker.enabled = True\n# Set the container registry information.\nbatch_env.docker.base_image_registry.address = &quot;myregistry.azurecr.io&quot;\nbatch_env.docker.base_image_registry.username = &quot;username&quot;\nbatch_env.docker.base_image_registry.password = &quot;password&quot;\nbatch_env.docker.base_image = &quot;myregistry.azurecr.io\/DEFAULT_CPU_IMAGE&quot;\n<\/code><\/pre>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":24.0,
        "Solution_reading_time":10.91,
        "Solution_score_count":0.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":47.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":227.5307463889,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>Is it possible to migrate models created in Azure ML studio (classic) to Azure ML studio v2?  <\/p>\n<p>Can I move my models from v1 to v2 in an easy way?  <\/p>\n<p>Thanks in advance!<\/p>",
        "Challenge_closed_time":1602438917847,
        "Challenge_comment_count":1,
        "Challenge_created_time":1601619807160,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/114944\/migrate-models-from-azure-machine-learning-studio",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":5.7,
        "Challenge_reading_time":3.47,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":227.5307463889,
        "Challenge_title":"Migrate models from Azure Machine Learning Studio (classic) v1 to Azure Machine Learning Studio v2",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":49,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hello Helena,  <\/p>\n<p>Thanks for your waiting. There is not a tool for auto-migration from V1 to V2 for now and future since the architecture of studio(classic) and machine learning studio is totally different. So I don't think it's easy to migrate. But we will have plan for migration in next few month, there should be a way to migrate from studio(classic) to machine learning studio with effort.   <\/p>\n<p>Regards,  <br \/>\nYutong<\/p>\n",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":7.7,
        "Solution_reading_time":5.35,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":72.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":0.3294444444,
        "Challenge_answer_count":1,
        "Challenge_body":"I'm trying to figure out a minimally permissive yet operational network configuration for Amazon SageMaker training to train on data from Amazon FSx for Lustre. My understanding is that both the file system and the SageMaker instance can have their own security groups and that FSx uses TCP on ports 988 and 1021-1023. Therefore, I think a good network configuration for using SageMaker with FSx is the following:\n* SageMaker EC2 equipped with the security group SM-SG that allows Inbound only with TCP on 988 and 1021-1023 from FSX-SG only.\n* Amazon FSx equipped with the security group FSX-SG that allows outbound only with TCP on 988 and 1021-1023 towards SM-SG only.\nIs this configuration enough for the training to work? Do FSx and SageMaker need other ports and sources to be opened to operate normally?",
        "Challenge_closed_time":1605281179000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1605279993000,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1668217529291,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUrTkxH_kIT-a_LJSGYS5SXA\/how-do-i-achieve-the-least-access-secure-networking-for-sagemaker-training-on-amazon-fsx-for-lustre",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":11.6,
        "Challenge_reading_time":11.16,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":0.3294444444,
        "Challenge_title":"How do I achieve the least-access secure networking for SageMaker Training on Amazon FSx for Lustre?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":191.0,
        "Challenge_word_count":149,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":1.0,
        "Poster_isModerator":0.0,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"For the security group for Amazon FSx (Example: FSx-SG), you need to add the following additional rules:\n\n1. FSx-SG needs inbound access from the security group for SageMaker (Example: SM-SG). The SageMaker instance needs to initiate a connection to the Amazon FSx file system, which is an inbound TCP packet to FSx.\n2. FSx-SG needs inbound and outbound access to itself. This is because, Amazon FSx for Lustre is a clustered file system, where each file system is typically powered by multiple file servers, and the file servers need to  communicate with one another.\n\nFor more information on the minimum set of rules required for FSx-SG, see [File system access control with Amazon VPC][1].\n[1]: https:\/\/docs.aws.amazon.com\/fsx\/latest\/LustreGuide\/limit-access-security-groups.html",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1667925559451,
        "Solution_link_count":1.0,
        "Solution_readability":12.0,
        "Solution_reading_time":9.75,
        "Solution_score_count":0.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":116.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1430233500800,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":212.0,
        "Answerer_view_count":25.0,
        "Challenge_adjusted_solved_time":21511.1452602778,
        "Challenge_answer_count":3,
        "Challenge_body":"<p>I suspect this has to more to do with IAM roles than Sagemaker.<\/p>\n\n<p>I'm following the example <a href=\"https:\/\/github.com\/aws\/sagemaker-python-sdk\/blob\/master\/src\/sagemaker\/tensorflow\/README.rst\" rel=\"noreferrer\">here<\/a><\/p>\n\n<p>Specifically, when it makes this call<\/p>\n\n<pre><code>tf_estimator.fit('s3:\/\/bucket\/path\/to\/training\/data')\n<\/code><\/pre>\n\n<p>I get this error<\/p>\n\n<pre><code>ClientError: An error occurred (AccessDenied) when calling the GetRole operation: User: arn:aws:sts::013772784144:assumed-role\/AmazonSageMaker-ExecutionRole-20181022T195630\/SageMaker is not authorized to perform: iam:GetRole on resource: role SageMakerRole\n<\/code><\/pre>\n\n<p>My notebook instance has an IAM role attached to it.\nThat role has the <code>AmazonSageMakerFullAccess<\/code> policy. It also has a custom policy that looks like this<\/p>\n\n<pre><code>{\n\"Version\": \"2012-10-17\",\n\"Statement\": [\n    {\n        \"Effect\": \"Allow\",\n        \"Action\": [\n            \"s3:GetObject\",\n            \"s3:PutObject\",\n            \"s3:DeleteObject\",\n            \"s3:ListBucket\"\n        ],\n        \"Resource\": [\n            \"arn:aws:s3:::*\"\n        ]\n    }\n]\n<\/code><\/pre>\n\n<p>}<\/p>\n\n<p>My input files and .py script is in an s3 bucket with the phrase <code>sagemaker<\/code> in it.<\/p>\n\n<p>What else am I missing?<\/p>",
        "Challenge_closed_time":1543010904776,
        "Challenge_comment_count":0,
        "Challenge_created_time":1542853625410,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/53423061",
        "Challenge_link_count":1,
        "Challenge_participation_count":3,
        "Challenge_readability":13.6,
        "Challenge_reading_time":16.26,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":6.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":43.6887127778,
        "Challenge_title":"How do I make this IAM role error in aws sagemaker go away?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":8160.0,
        "Challenge_word_count":130,
        "Platform":"Stack Overflow",
        "Poster_created_time":1319234288808,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":4966.0,
        "Poster_view_count":304.0,
        "Solution_body":"<p>If you're running the example code on a SageMaker notebook instance, you can use the execution_role which has the <code>AmazonSageMakerFullAccess<\/code> attached.<\/p>\n<pre><code>from sagemaker import get_execution_role\nsagemaker_session = sagemaker.Session()\nrole = get_execution_role()\n<\/code><\/pre>\n<p>And you can pass this role when initializing <code>tf_estimator<\/code>.\nYou can check out the example <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/automatic-model-tuning-ex-role.html\" rel=\"nofollow noreferrer\">here<\/a> for using <code>execution_role<\/code> with S3 on notebook instance.<\/p>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":1620293748347,
        "Solution_link_count":1.0,
        "Solution_readability":18.4,
        "Solution_reading_time":8.09,
        "Solution_score_count":8.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":57.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1534058291092,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":116.0,
        "Answerer_view_count":33.0,
        "Challenge_adjusted_solved_time":55.4162013889,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I am trying to create sagemaker studio project using aws cdk following below steps:<\/p>\n<p>create domain (<a href=\"https:\/\/github.com\/aws-samples\/aws-cdk-sagemaker-studio.git\" rel=\"nofollow noreferrer\">using this example<\/a>)\ncreate user (<a href=\"https:\/\/github.com\/aws-samples\/aws-cdk-sagemaker-studio.git\" rel=\"nofollow noreferrer\">using this example<\/a>)\ncreate jupyter app\ncreate project<\/p>\n<p>Code for creating jupyter app:<\/p>\n<pre><code>\ndef __init__(self, scope: Construct,\n             construct_id: str, *,\n             app_name: str,\n             app_type: str,\n             domain_id: str,\n             user_profile_name: str,\n             depends_on=None, **kwargs) -&gt; None:\n    super().__init__(scope, construct_id)\n\n    sagemaker_jupyter_app = sg.CfnApp(self, construct_id,\n                                      app_name=app_name,\n                                      app_type=app_type,\n                                      domain_id=domain_id,\n                                      user_profile_name=user_profile_name\n                                      )\n    sagemaker_jupyter_app.add_depends_on(depends_on_user_creation)\n<\/code><\/pre>\n<p>Code for creating project:<\/p>\n<pre><code>\ndef __init__(self, scope: Construct,\n             construct_id: str, *,\n             project_name: str,\n             project_description: str,\n             product_id: str,\n             depends_on=None,\n             **kwargs) -&gt; None:\n    super().__init__(scope, construct_id)\n\n    sagemaker_studio_project = sg.CfnProject(self, construct_id,\n                                             project_name=project_name,\n                                             service_catalog_provisioning_details={\n                                                 &quot;ProductId&quot;: &quot;prod-7tjedn5dz4jrw&quot;\n                                             },\n                                             project_description=project_description\n                                             )\n<\/code><\/pre>\n<p>Domain, user, jupyter app all gets created successfully. The problem comes in with project.\nBelow is the error :<\/p>\n<blockquote>\n<p>Resource handler returned message: &quot;Product prod-7tjedn5dz4jrw does\nnot exist or access was denied (Service: SageMaker, Status Code: 400,\nRequest ID: 768116aa-e77b-4691-a972-38b83093fdc4)&quot; (RequestToken:\n45ca2a0c-3f03-e3e0-f29d-d9443ff4dfc1, HandlerErrorCode:\nGeneralServiceException)<\/p>\n<\/blockquote>\n<p>I am running this code from an ec2 instance that has SagemakerFullAccess\nI also tried attaching SagemakerFullAccess execution role with project...but got the same error.\nI have also attached below policy to my domain:<\/p>\n<ul>\n<li>AmazonSageMakerAdmin-ServiceCatalogProductsServiceRolePolicy<\/li>\n<\/ul>",
        "Challenge_closed_time":1650740870208,
        "Challenge_comment_count":1,
        "Challenge_created_time":1650541371883,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/71953876",
        "Challenge_link_count":2,
        "Challenge_participation_count":3,
        "Challenge_readability":18.5,
        "Challenge_reading_time":29.03,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":13,
        "Challenge_solved_time":55.4162013889,
        "Challenge_title":"How to create Sagemaker studio project using aws cdk",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":491.0,
        "Challenge_word_count":193,
        "Platform":"Stack Overflow",
        "Poster_created_time":1534058291092,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":116.0,
        "Poster_view_count":33.0,
        "Solution_body":"<p>Basically this was an issue related to IAM.\nRunning cdk program requires bootstrapping it using the command <code>cdk bootstrap<\/code>\nAfter running this command cdk was creating a bunch of roles out of which one role will be related to cloudformation's execution role. Something like<\/p>\n<blockquote>\n<p>cdk-serialnumber-cfn-exec-role-Id-region<\/p>\n<\/blockquote>\n<p>Now this role was used by cloudformation to run the stack.<\/p>\n<p>Using sagemaker from console automatically adds the role associated with domain\/user at<\/p>\n<blockquote>\n<p>ServiceCatalog -&gt; Portfolios -&gt; Imported -&gt; Amazon SageMaker Solutions and ML Ops products -&gt; Groups, roles, and users<\/p>\n<\/blockquote>\n<p>Thats was the reason why product id was accessible from console.<\/p>\n<p>After adding the role created by cdk bootsrap to the above path I was able to run my stack.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":13.8,
        "Solution_reading_time":10.93,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":120.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1508862010472,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"PNW",
        "Answerer_reputation_count":3080.0,
        "Answerer_view_count":193.0,
        "Challenge_adjusted_solved_time":173.7865944444,
        "Challenge_answer_count":3,
        "Challenge_body":"<p>Just learning how to use <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/bot-service\/?view=azure-bot-service-3.0\" rel=\"nofollow noreferrer\">Azure Bot Service<\/a> and <code>Azure Bot Framework<\/code>. I created a Bot in Azure portal following <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/bot-service\/bot-service-quickstart?view=azure-bot-service-3.0\" rel=\"nofollow noreferrer\">this<\/a> Official Azure tutorial. Does this bot need to be published somewhere? I read somewhere that you <code>Build--&gt;Test--&gt;Publish--&gt;Evaluate<\/code>. I've tested it in Azure portal itself as explained <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/bot-service\/bot-service-quickstart?view=azure-bot-service-3.0\" rel=\"nofollow noreferrer\">here<\/a>. Not sure about the Publish part of it.<\/p>",
        "Challenge_closed_time":1526659876240,
        "Challenge_comment_count":0,
        "Challenge_created_time":1526657122620,
        "Challenge_favorite_count":1.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/50414639",
        "Challenge_link_count":3,
        "Challenge_participation_count":3,
        "Challenge_readability":14.3,
        "Challenge_reading_time":10.93,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":3.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":10,
        "Challenge_solved_time":0.7648944444,
        "Challenge_title":"How to Publish an Azure Bot",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":844.0,
        "Challenge_word_count":70,
        "Platform":"Stack Overflow",
        "Poster_created_time":1330144099340,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":19815.0,
        "Poster_view_count":2272.0,
        "Solution_body":"<p>How do you intend to use your bot? Azure Bots work by connecting them to existing channels like Skype, Facebook Messenger, SMS, etc or making REST calls from a custom application.<\/p>\n\n<p>However you can also reach your bot directly from: <code>https:\/\/webchat.botframework.com\/embed\/YOUR_BOT_ID?t=YOUR_TOKEN_HERE<\/code><\/p>\n\n<p>You can embed it on any web page with this HTML tag:<\/p>\n\n<pre><code>&lt;iframe src=\"https:\/\/webchat.botframework.com\/embed\/YOUR_BOT_ID?t=YOUR_TOKEN_HERE\"&gt;&lt;\/iframe&gt;\n<\/code><\/pre>\n\n<p>Please note that both of these methods expose your token and would allow other developers to add your bot to their pages as well.<\/p>\n\n<p>Bot ID is the name of your bot and you can get the token from the portal by going to your bot and choosing \"Channel\" blade and then clicking the \"Get bot embed codes\" link.<\/p>\n\n<p>Edit: I went ahead and wrote a blog post on this topic <a href=\"https:\/\/medium.com\/@joelatwar\/how-to-embed-your-azure-web-app-bot-in-any-web-page-120dfda91fdc\" rel=\"nofollow noreferrer\">https:\/\/medium.com\/@joelatwar\/how-to-embed-your-azure-web-app-bot-in-any-web-page-120dfda91fdc<\/a><\/p>",
        "Solution_comment_count":2.0,
        "Solution_last_edit_time":1527282754360,
        "Solution_link_count":4.0,
        "Solution_readability":10.9,
        "Solution_reading_time":14.62,
        "Solution_score_count":5.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":131.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1432829415467,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":501.0,
        "Answerer_view_count":76.0,
        "Challenge_adjusted_solved_time":674.1436052778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have an experiment in AzureML which has a R module at its core. Additionally, I have some .RData files stored in Azure blob storage. The blob container is set as private (no anonymous access).<\/p>\n\n<p>Now, I am trying to make a https call from inside the R script to the azure blob storage container in order to download some files. I am using the <code>httr<\/code> package's <code>GET()<\/code> function and properly set up the url, authentication etc...The code works in R on my local machine but the same code gives me the following error when called from inside the R module in the experiment<\/p>\n\n<pre><code>error:1411809D:SSL routines:SSL_CHECK_SERVERHELLO_TLSEXT:tls invalid ecpointformat list\n<\/code><\/pre>\n\n<p>Apparently this is an error from the underlying OpenSSL library (which got fixed a while ago). Some suggested workarounds I found <a href=\"https:\/\/stackoverflow.com\/questions\/20046176\/rcurl-errors-when-fetching-ssl-endpoint\">here<\/a> were to set <code>sslversion = 3<\/code> and <code>ssl_verifypeer = 1<\/code>, or turn off verification <code>ssl_verifypeer = 0<\/code>. Both of these approaches returned the same error.<\/p>\n\n<p>I am guessing that this has something to do with the internal Azure certificate \/ validation...? Or maybe I am missing or overseeing something?<\/p>\n\n<p>Any help or ideas would be greatly appreciated. Thanks in advance.<\/p>\n\n<p>Regards<\/p>",
        "Challenge_closed_time":1450358402136,
        "Challenge_comment_count":1,
        "Challenge_created_time":1447931485157,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1495540337367,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/33802274",
        "Challenge_link_count":1,
        "Challenge_participation_count":2,
        "Challenge_readability":8.6,
        "Challenge_reading_time":18.63,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":15,
        "Challenge_solved_time":674.1436052778,
        "Challenge_title":"Error:1411809D:SSL routines - When trying to make https call from inside R module in AzureML",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":358.0,
        "Challenge_word_count":203,
        "Platform":"Stack Overflow",
        "Poster_created_time":1432829415467,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":501.0,
        "Poster_view_count":76.0,
        "Solution_body":"<p>After a while, an answer came back from the support team, so I am going to post the relevant part as an answer here for anyone who lands here with the same problem. <\/p>\n\n<p>\"This is a known issue. The container (a sandbox technology known as \"drawbridge\" running on top of Azure PaaS VM) executing the Execute R module doesn't support outbound HTTPS traffic. Please try to switch to HTTP and that should work.\"<\/p>\n\n<p>As well as that a solution is on the way :<\/p>\n\n<p>\"We are actively looking at how to fix this bug. \"<\/p>\n\n<p>Here is the original <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/azure\/en-US\/5866e16c-a145-481e-8764-f7c7823742b0\/https-call-from-inside-r-module-possible-?forum=MachineLearning\" rel=\"nofollow\">link<\/a> as a reference.\nhth<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":9.3,
        "Solution_reading_time":9.62,
        "Solution_score_count":0.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":107.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":24.0520611111,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>Can we connect Azure ML Notebooks directly to Snowflake using Private end-points, my ML Workspace is inside a VNet.<\/p>",
        "Challenge_closed_time":1653034845860,
        "Challenge_comment_count":0,
        "Challenge_created_time":1652948258440,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/855820\/connect-azure-ml-with-snowflake-using-private-endp",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":7.2,
        "Challenge_reading_time":2.25,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":2,
        "Challenge_solved_time":24.0520611111,
        "Challenge_title":"Connect Azure ML with Snowflake using Private endpoint?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":26,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=03343194-9922-4c28-abc7-1d7c46b6d2d6\">@Varun  <\/a>     <\/p>\n<p>Thanks for reaching out to us, currently there is no internal way in Azure Machine Learning Studio to connect to Snowflake. I am sorry for all inconveniences.     <\/p>\n<p>But you can run a  Python 3 code to use the Snowflake python connector - <a href=\"https:\/\/docs.snowflake.com\/en\/user-guide\/python-connector.html\">https:\/\/docs.snowflake.com\/en\/user-guide\/python-connector.html<\/a>    <\/p>\n<p>With Azure ML Studio, there's no built-in support for SnowFlake, I will forward your feedback to product group to see if there any plan in the future.     <\/p>\n<p>Hope this helps!    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p><em>-Please kindly accept the answer if you feel helpful, thanks a lot for supporting the community.<\/em>     <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":9.0,
        "Solution_reading_time":10.31,
        "Solution_score_count":0.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":103.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1361156607787,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Bergen, Norway",
        "Answerer_reputation_count":6168.0,
        "Answerer_view_count":334.0,
        "Challenge_adjusted_solved_time":0.3461716667,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have an AWS SageMaker domain in my account created via Terraform. The resource was modified outside of Terraform. The modification was the equivalent of the following:<\/p>\n<pre class=\"lang-bash prettyprint-override\"><code>aws sagemaker update-domain --domain-id d-domainid123 --default-user-settings '{&quot;KernelGatewayAppSettings&quot;: { &quot;CustomImages&quot;: [ { ... } ] } }'\n<\/code><\/pre>\n<p>Ever since, all <code>terraform plan<\/code> operations want to replace the AWS SageMaker domain:<\/p>\n<pre><code>  # module.main.aws_sagemaker_domain.default must be replaced\n-\/+ resource &quot;aws_sagemaker_domain&quot; &quot;default&quot; {\n      ~ arn                                            = &quot;arn:aws:sagemaker:eu-central-1:000111222333:domain\/d-domainid123&quot; -&gt; (known after apply)\n      ...\n        # (6 unchanged attributes hidden)\n      ~ default_user_settings {\n            # (2 unchanged attributes hidden)\n          - kernel_gateway_app_settings { # forces replacement\n               - custom_images = [ ... ]\n            }\n        }\n    }\n<\/code><\/pre>\n<p>My goal is to reconcile the situation without Terraform or me needing to create a new domain. I can't modify the Terraform sources to match the state of the SageMaker domain because that would force the recreation of domains in other accounts provisioned from the same Terraform source code.<\/p>\n<p><strong>I want to issue an <code>aws<\/code> CLI command that updates the domain and removes the <code>&quot;KernelGatewayAppSettings&quot;: { ... }<\/code> key completely from the <code>&quot;DefaultUserSettings&quot;<\/code> of the SageMaker domain. Is there a way to do this?<\/strong><\/p>\n<p>I tried the following, but the empty object is still there, so they did not work.<\/p>\n<pre class=\"lang-bash prettyprint-override\"><code>aws sagemaker update-domain --domain-id d-domainid123 --default-user-settings '{&quot;KernelGatewayAppSettings&quot;: {} }'\naws sagemaker update-domain --domain-id d-domainid123 --default-user-settings '{&quot;KernelGatewayAppSettings&quot;: null }'\n\n# Still:\naws sagemaker describe-domain --domain-id d-domainid123\n{\n    &quot;DomainArn&quot;: ...,\n    &quot;DomainId&quot;: ...,\n    ...\n    &quot;DefaultUserSettings&quot;: {\n        &quot;ExecutionRole&quot;: &quot;arn:aws:iam::0001112233444:role\/SageMakerStudioExecutionRole&quot;,\n        &quot;SecurityGroups&quot;: [\n            &quot;...&quot;\n        ],\n        &quot;KernelGatewayAppSettings&quot;: {\n            &quot;CustomImages&quot;: []\n        }\n    },\n    ...\n}\n<\/code><\/pre>",
        "Challenge_closed_time":1662394449848,
        "Challenge_comment_count":0,
        "Challenge_created_time":1662393203630,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1662455073636,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/73611956",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":15.8,
        "Challenge_reading_time":31.72,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":16,
        "Challenge_solved_time":0.3461716667,
        "Challenge_title":"Remove JSON object via AWS Update* API to prevent Terraform from recreating the resource",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":32.0,
        "Challenge_word_count":223,
        "Platform":"Stack Overflow",
        "Poster_created_time":1219760368600,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Miskolc, Hungary",
        "Poster_reputation_count":3743.0,
        "Poster_view_count":178.0,
        "Solution_body":"<p>One option you have is to use the <a href=\"https:\/\/www.terraform.io\/language\/meta-arguments\/lifecycle\" rel=\"nofollow noreferrer\">lifecycle meta argument<\/a> to ignore out-of-band changes to the resource.<\/p>\n<pre><code>  lifecycle {\n    ignore_changes = [\n      default_user_settings\n    ]\n  }\n<\/code><\/pre>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":13.8,
        "Solution_reading_time":3.86,
        "Solution_score_count":1.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":26.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1638293279416,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":26.0,
        "Answerer_view_count":13.0,
        "Challenge_adjusted_solved_time":0.5860544444,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am following the example <a href=\"https:\/\/github.com\/GoogleCloudPlatform\/vertex-ai-samples\/blob\/master\/notebooks\/community\/matching_engine\/matching_engine_for_indexing.ipynb\" rel=\"nofollow noreferrer\">notebook<\/a> as per GCP <a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/matching-engine\/using-matching-engine#example_notebook\" rel=\"nofollow noreferrer\">docs<\/a> to test Vertex Matching Engine. I have deployed an index but while trying to query the index I am getting <code>_InactiveRpcError<\/code>. The VPC network is in <code>us-west2<\/code> with private service access enabled and the Index is deployed in <code>us-central1<\/code>. My VPC network contains the <a href=\"https:\/\/cloud.google.com\/vpc\/docs\/firewalls#more_rules_default_vpc\" rel=\"nofollow noreferrer\">pre-populated firewall rules<\/a>.<\/p>\n<p>Index<\/p>\n<pre><code>createTime: '2021-11-23T15:25:53.928606Z'\ndeployedIndexes:\n- deployedIndexId: brute_force_glove_deployed_v3\n  indexEndpoint: projects\/XXXXXXXXXXXX\/locations\/us-central1\/indexEndpoints\/XXXXXXXXXXXX\ndescription: testing python script for creating index\ndisplayName: glove_100_brute_force_20211123152551\netag: AMEw9yOVPWBOTpbAvJLllqxWMi2YurEV_sad2n13QvbIlqjOdMyiq_j20gG1ldhdZNTL\nmetadata:\n  config:\n    algorithmConfig:\n      bruteForceConfig: {}\n    dimensions: 100\n    distanceMeasureType: DOT_PRODUCT_DISTANCE\nmetadataSchemaUri: gs:\/\/google-cloud-aiplatform\/schema\/matchingengine\/metadata\/nearest_neighbor_search_1.0.0.yaml\nname: projects\/XXXXXXXXXXXX\/locations\/us-central1\/indexes\/XXXXXXXXXXXX\nupdateTime: '2021-11-23T16:04:17.993730Z'\n<\/code><\/pre>\n<p>Index-Endpoint<\/p>\n<pre><code>createTime: '2021-11-24T10:59:51.975949Z'\ndeployedIndexes:\n- automaticResources:\n    maxReplicaCount: 1\n    minReplicaCount: 1\n  createTime: '2021-11-30T15:16:12.323028Z'\n  deploymentGroup: default\n  displayName: brute_force_glove_deployed_v3\n  enableAccessLogging: true\n  id: brute_force_glove_deployed_v3\n  index: projects\/XXXXXXXXXXXX\/locations\/us-central1\/indexes\/XXXXXXXXXXXX\n  indexSyncTime: '2021-11-30T16:37:35.597200Z'\n  privateEndpoints:\n    matchGrpcAddress: 10.242.4.5\ndisplayName: index_endpoint_for_demo\netag: AMEw9yO6cuDfgpBhGVw7-NKnlS1vdFI5nnOtqVgW1ddMP-CMXM7NfGWVpqRpMRPsNCwc\nname: projects\/XXXXXXXXXXXX\/locations\/us-central1\/indexEndpoints\/XXXXXXXXXXXX\nnetwork: projects\/XXXXXXXXXXXX\/global\/networks\/XXXXXXXXXXXX\nupdateTime: '2021-11-24T10:59:53.271100Z'\n<\/code><\/pre>\n<p>Code<\/p>\n<pre><code>\nimport grpc\n\n# import the generated classes\nimport match_service_pb2\nimport match_service_pb2_grpc\n\nDEPLOYED_INDEX_SERVER_IP = '10.242.0.5'\nDEPLOYED_INDEX_ID = 'brute_force_glove_deployed_v3'\n\nquery = [-0.11333, 0.48402, 0.090771, -0.22439, 0.034206, -0.55831, 0.041849, -0.53573, 0.18809, -0.58722, 0.015313, -0.014555, 0.80842, -0.038519, 0.75348, 0.70502, -0.17863, 0.3222, 0.67575, 0.67198, 0.26044, 0.4187, -0.34122, 0.2286, -0.53529, 1.2582, -0.091543, 0.19716, -0.037454, -0.3336, 0.31399, 0.36488, 0.71263, 0.1307, -0.24654, -0.52445, -0.036091, 0.55068, 0.10017, 0.48095, 0.71104, -0.053462, 0.22325, 0.30917, -0.39926, 0.036634, -0.35431, -0.42795, 0.46444, 0.25586, 0.68257, -0.20821, 0.38433, 0.055773, -0.2539, -0.20804, 0.52522, -0.11399, -0.3253, -0.44104, 0.17528, 0.62255, 0.50237, -0.7607, -0.071786, 0.0080131, -0.13286, 0.50097, 0.18824, -0.54722, -0.42664, 0.4292, 0.14877, -0.0072514, -0.16484, -0.059798, 0.9895, -0.61738, 0.054169, 0.48424, -0.35084, -0.27053, 0.37829, 0.11503, -0.39613, 0.24266, 0.39147, -0.075256, 0.65093, -0.20822, -0.17456, 0.53571, -0.16537, 0.13582, -0.56016, 0.016964, 0.1277, 0.94071, -0.22608, -0.021106]\n\nchannel = grpc.insecure_channel(&quot;{}:10000&quot;.format(DEPLOYED_INDEX_SERVER_IP))\nstub = match_service_pb2_grpc.MatchServiceStub(channel)\n\nrequest = match_service_pb2.MatchRequest()\nrequest.deployed_index_id = DEPLOYED_INDEX_ID\nfor val in query:\n    request.float_val.append(val)\n\nresponse = stub.Match(request)\nresponse\n<\/code><\/pre>\n<p>Error<\/p>\n<pre><code>_InactiveRpcError                         Traceback (most recent call last)\n\/tmp\/ipykernel_3451\/467153318.py in &lt;module&gt;\n    108     request.float_val.append(val)\n    109 \n--&gt; 110 response = stub.Match(request)\n    111 response\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/grpc\/_channel.py in __call__(self, request, timeout, metadata, credentials, wait_for_ready, compression)\n    944         state, call, = self._blocking(request, timeout, metadata, credentials,\n    945                                       wait_for_ready, compression)\n--&gt; 946         return _end_unary_response_blocking(state, call, False, None)\n    947 \n    948     def with_call(self,\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/grpc\/_channel.py in _end_unary_response_blocking(state, call, with_call, deadline)\n    847             return state.response\n    848     else:\n--&gt; 849         raise _InactiveRpcError(state)\n    850 \n    851 \n\n_InactiveRpcError: &lt;_InactiveRpcError of RPC that terminated with:\n    status = StatusCode.UNAVAILABLE\n    details = &quot;failed to connect to all addresses&quot;\n    debug_error_string = &quot;{&quot;created&quot;:&quot;@1638277076.941429628&quot;,&quot;description&quot;:&quot;Failed to pick subchannel&quot;,&quot;file&quot;:&quot;src\/core\/ext\/filters\/client_channel\/client_channel.cc&quot;,&quot;file_line&quot;:3093,&quot;referenced_errors&quot;:[{&quot;created&quot;:&quot;@1638277076.941428202&quot;,&quot;description&quot;:&quot;failed to connect to all addresses&quot;,&quot;file&quot;:&quot;src\/core\/lib\/transport\/error_utils.cc&quot;,&quot;file_line&quot;:163,&quot;grpc_status&quot;:14}]}&quot;\n&gt;\n<\/code><\/pre>",
        "Challenge_closed_time":1638293279416,
        "Challenge_comment_count":0,
        "Challenge_created_time":1638291169620,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1639486727367,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/70173096",
        "Challenge_link_count":3,
        "Challenge_participation_count":1,
        "Challenge_readability":16.9,
        "Challenge_reading_time":74.1,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":2.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":35,
        "Challenge_solved_time":0.5860544444,
        "Challenge_title":"_InactiveRpcError while querying Vertex AI Matching Engine Index",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":350.0,
        "Challenge_word_count":372,
        "Platform":"Stack Overflow",
        "Poster_created_time":1463607987528,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Lahore, Pakistan",
        "Poster_reputation_count":143.0,
        "Poster_view_count":23.0,
        "Solution_body":"<p>Currently, Matching Engine only supports Query from the same region. Can you try running the code from VM in <code>us-central1<\/code>.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":6.0,
        "Solution_reading_time":1.79,
        "Solution_score_count":1.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":20.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_created_time":1554298968016,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"wondeland",
        "Answerer_reputation_count":1540.0,
        "Answerer_view_count":118.0,
        "Challenge_adjusted_solved_time":554.3479247222,
        "Challenge_answer_count":4,
        "Challenge_body":"<p>As I am logging my entire models and params into mlflow I thought it will be a good idea to have  it protected under a user name and password.<\/p>\n\n<p>I use the following code to run the mlflow server<\/p>\n\n<p><code>mlflow server --host 0.0.0.0 --port 11111<\/code>\nworks perfect,in mybrowser i type <code>myip:11111<\/code> and i see everything (which eventually is the problem)<\/p>\n\n<p>If I understood the documentation and the following <a href=\"https:\/\/groups.google.com\/forum\/#!topic\/mlflow-users\/E9QW4HdS8a8\" rel=\"noreferrer\">https:\/\/groups.google.com\/forum\/#!topic\/mlflow-users\/E9QW4HdS8a8<\/a> link here correct, I should use nginx to create the authentication.<\/p>\n\n<p>I installed <code>nginx open sourcre<\/code>  and <code>apache2-utils<\/code><\/p>\n\n<p>created <code>sudo htpasswd -c \/etc\/apache2\/.htpasswd user1<\/code> user and passwords.<\/p>\n\n<p>I edited my <code>\/etc\/nginx\/nginx.conf<\/code> to the following:<\/p>\n\n<pre><code>server {\n        listen 80;\n        listen 443 ssl;\n\n        server_name my_ip;\n        root NOT_SURE_WHICH_PATH_TO_PUT_HERE, THE VENV?;\n        location \/ {\n            proxy_pass                      my_ip:11111\/;\n            auth_basic                      \"Restricted Content\";\n            auth_basic_user_file \/home\/path to the password file\/.htpasswd;\n        }\n    }\n<\/code><\/pre>\n\n<p><strong>but no authentication appears.<\/strong><\/p>\n\n<p>if I change the conf to listen to  <code>listen 11111<\/code>\nI get an error that the port is already in use ( of course, by the mlflow server....)<\/p>\n\n<p>my wish is to have a authentication window before anyone can enter by the mlflow with a browser.<\/p>\n\n<p>would be happy to hear any suggestions.<\/p>",
        "Challenge_closed_time":1576255052616,
        "Challenge_comment_count":1,
        "Challenge_created_time":1574259400087,
        "Challenge_favorite_count":3.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/58956459",
        "Challenge_link_count":2,
        "Challenge_participation_count":5,
        "Challenge_readability":9.9,
        "Challenge_reading_time":20.43,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":11.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":14,
        "Challenge_solved_time":554.3479247222,
        "Challenge_title":"How to run authentication on a mlFlow server?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":13870.0,
        "Challenge_word_count":193,
        "Platform":"Stack Overflow",
        "Poster_created_time":1554298968016,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"wondeland",
        "Poster_reputation_count":1540.0,
        "Poster_view_count":118.0,
        "Solution_body":"<p>the problem here is that both <code>mlflow<\/code> and <code>nginx<\/code> are trying to run on the <strong>same port<\/strong>... <\/p>\n\n<ol>\n<li><p>first lets deal with nginx:<\/p>\n\n<p>1.1 in \/etc\/nginx\/sites-enable make a new file <code>sudo nano mlflow<\/code> and delete the exist default.<\/p>\n\n<p>1.2 in mlflow file:<\/p><\/li>\n<\/ol>\n\n<pre><code>server {\n    listen YOUR_PORT;\n    server_name YOUR_IP_OR_DOMAIN;\n    auth_basic           \u201cAdministrator\u2019s Area\u201d;\n    auth_basic_user_file \/etc\/apache2\/.htpasswd; #read the link below how to set username and pwd in nginx\n\n    location \/ {\n        proxy_pass http:\/\/localhost:8000;\n        include \/etc\/nginx\/proxy_params;\n        proxy_redirect off;\n    }\n}\n<\/code><\/pre>\n\n<p>1.3.  restart nginx <code>sudo systemctl restart nginx<\/code><\/p>\n\n<ol start=\"2\">\n<li>on your server run mlflow  <code>mlflow server --host localhost --port 8000<\/code><\/li>\n<\/ol>\n\n<p>Now if you try access the YOUR_IP_OR_DOMAIN:YOUR_PORT within your browser an auth popup should appear, enter your host and pass and now you in mlflow<\/p>\n\n<ol start=\"3\">\n<li><p>now there are 2 options to tell the mlflow server about it:<\/p>\n\n<p>3.1 set username and pwd as environment variable \n<code>export MLFLOW_TRACKING_USERNAME=user export MLFLOW_TRACKING_PASSWORD=pwd<\/code><\/p>\n\n<p>3.2 edit in your <code>\/venv\/lib\/python3.6\/site-packages\/mlflowpackages\/mlflow\/tracking\/_tracking_service\/utils.py<\/code> the function <\/p><\/li>\n<\/ol>\n\n<pre><code>def _get_rest_store(store_uri, **_):\n    def get_default_host_creds():\n        return rest_utils.MlflowHostCreds(\n            host=store_uri,\n            username=replace with nginx user\n            password=replace with nginx pwd\n            token=os.environ.get(_TRACKING_TOKEN_ENV_VAR),\n            ignore_tls_verification=os.environ.get(_TRACKING_INSECURE_TLS_ENV_VAR) == 'true',\n        )\n<\/code><\/pre>\n\n<p>in your .py file where you work with mlflow:<\/p>\n\n<pre><code>import mlflow\nremote_server_uri = \"YOUR_IP_OR_DOMAIN:YOUR_PORT\" # set to your server URI\nmlflow.set_tracking_uri(remote_server_uri)\nmlflow.set_experiment(\"\/my-experiment\")\nwith mlflow.start_run():\n    mlflow.log_param(\"a\", 1)\n    mlflow.log_metric(\"b\", 2)\n<\/code><\/pre>\n\n<p>A link to nginx authentication doc <a href=\"https:\/\/docs.nginx.com\/nginx\/admin-guide\/security-controls\/configuring-http-basic-authentication\/\" rel=\"noreferrer\">https:\/\/docs.nginx.com\/nginx\/admin-guide\/security-controls\/configuring-http-basic-authentication\/<\/a><\/p>",
        "Solution_comment_count":3.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":3.0,
        "Solution_readability":14.7,
        "Solution_reading_time":30.69,
        "Solution_score_count":8.0,
        "Solution_sentence_count":15.0,
        "Solution_word_count":211.0,
        "Tool":"MLflow"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":41.9026855556,
        "Challenge_answer_count":7,
        "Challenge_body":"<p>Some of our teams projects were erroneously deleted by a colleague since he wanted to clean up his account and probably thought it were his own projects. Is there any chance to get the data back (I assume not, but worth a try\u2026)?<\/p>",
        "Challenge_closed_time":1642591492148,
        "Challenge_comment_count":0,
        "Challenge_created_time":1642440642480,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/a-colleague-accidentally-deleted-some-projects-any-chance-to-get-them-back\/1774",
        "Challenge_link_count":0,
        "Challenge_participation_count":7,
        "Challenge_readability":6.8,
        "Challenge_reading_time":3.8,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":41.9026855556,
        "Challenge_title":"A colleague accidentally deleted some projects, any chance to get them back?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":149.0,
        "Challenge_word_count":54,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Please check the names of the project. By username I meant the entity name where the projects were logged. If these were team projects then I need the team name.<\/p>",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":1.3,
        "Solution_reading_time":2.04,
        "Solution_score_count":null,
        "Solution_sentence_count":3.0,
        "Solution_word_count":30.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":64.0951252778,
        "Challenge_answer_count":1,
        "Challenge_body":"I'm using SageMaker Studio, and I have my data files as well as a requirements.txt organized under my home directory. All works fine when I run notebook kernels interactively: they can access my files just fine. However, when I create a \"notebook job\", it doesn't seem to have access to any of my files. Is there a way to give my notebook job access to the same file system as my interactive notebooks?\n\nAfter I run a job, I see that a folder for the job was created within the input S3 bucket, and within that folder there's a \"input\/\" subfolder. But I don't know how to predict the name of the temp folder created for the job, so it doesn't seem like I could myself drop additional inputs in there, even if I wanted to. And if I could, how would I find them, at run-time?\n\nCould sure use guidance on how my notebook jobs can access input files.\n\nThanks,\n\nChris",
        "Challenge_closed_time":1671466765571,
        "Challenge_comment_count":1,
        "Challenge_created_time":1671236023120,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1671582880756,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUqh6oq1d6QbKzNSszEwPm0g\/can-sagemaker-notebook-jobs-access-studio-storage",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":7.5,
        "Challenge_reading_time":10.9,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":10,
        "Challenge_solved_time":64.0951252778,
        "Challenge_title":"Can SageMaker notebook jobs access studio storage?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":63.0,
        "Challenge_word_count":168,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"Hi Chris, the option to use input files is to directly use the S3 URIs in the notebook itself, i.e., instead of reading from an `inputs` folder in your local EFS storage (which doesn't get copied over to `inputs` folder for the training job), read the inputs directly from the S3 URI. If the inputs will be dynamic for your notebook jobs, use parameterized executions (reference - https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/notebook-auto-run-troubleshoot-override.html)",
        "Solution_comment_count":3.0,
        "Solution_last_edit_time":1671466784964,
        "Solution_link_count":1.0,
        "Solution_readability":13.2,
        "Solution_reading_time":5.98,
        "Solution_score_count":0.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":67.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":69.30036,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>User is not authorized to query provided resources due to s2s call not providing any active baggage to verify role-based access.  <\/p>",
        "Challenge_closed_time":1614577233696,
        "Challenge_comment_count":2,
        "Challenge_created_time":1614327752400,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/290347\/automate-machine-learning-model-on-azure-portal-fa",
        "Challenge_link_count":0,
        "Challenge_participation_count":4,
        "Challenge_readability":10.1,
        "Challenge_reading_time":2.39,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":2,
        "Challenge_solved_time":69.30036,
        "Challenge_title":"Automate machine learning model on Azure portal failed",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":29,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>No update yet.  <\/p>\n<p>I have been receiving emails from Microsoft that they will disable my account for going against their policy.   <\/p>\n<p>Reason was because I am frequently using the Azure platform.  <\/p>\n<p>I decided to take a break from the platform to avoid them deleting my account.  <\/p>\n<p>Don't know what to do \ud83d\ude2d next<\/p>\n",
        "Solution_comment_count":2.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":5.3,
        "Solution_reading_time":4.05,
        "Solution_score_count":1.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":56.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":0.2003183333,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hello,  <\/p>\n<p>no practice exam for the Azure certification DP-100 seems to be available in the official channels. It would, however, be very helpful for preparing.  <br \/>\nBy any chance, do you plan to introduce such a resource any time soon?  <\/p>\n<p>Thanks and best regards  <br \/>\nTim<\/p>",
        "Challenge_closed_time":1593083339536,
        "Challenge_comment_count":0,
        "Challenge_created_time":1593082618390,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/39948\/practice-exam-for-dp-100",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":4.9,
        "Challenge_reading_time":3.89,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":0.2003183333,
        "Challenge_title":"Practice Exam for DP-100",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":51,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hi,    <\/p>\n<p>Microsoft Certification \/ Exams are currently not supported in the Q&amp;A forums, the supported products are listed over here <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/products\">https:\/\/learn.microsoft.com\/en-us\/answers\/products<\/a> (more to be added later on).      <\/p>\n<p>You can ask the experts in the dedicated <strong>Microsoft Certification - Preparation Resources<\/strong> forum over here:        <br \/>\n<a href=\"https:\/\/trainingsupport.microsoft.com\/en-us\/mcp\/forum\/mcp_exams-mcp_prep\">https:\/\/trainingsupport.microsoft.com\/en-us\/mcp\/forum\/mcp_exams-mcp_prep<\/a>    <\/p>\n<p>(Please don't forget to accept helpful replies as answer)      <\/p>\n<p>Best regards,      <br \/>\nLeon    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":17.7,
        "Solution_reading_time":9.15,
        "Solution_score_count":2.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":63.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":1.0,
        "Answerer_isModerator":0.0,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":0.9927311111,
        "Challenge_answer_count":1,
        "Challenge_body":"does cloudformation support sagemaker batch transform? if yes, can the jobs be triggered\/run automatically once the stack is created?",
        "Challenge_closed_time":1649089461868,
        "Challenge_comment_count":0,
        "Challenge_created_time":1649085888036,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1668627644320,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUyENAstk3Q_--wYwScAIq-A\/how-to-automate-sagemaker-batch-transform",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":11.1,
        "Challenge_reading_time":2.25,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":0.9927311111,
        "Challenge_title":"How to automate sagemaker batch transform?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":1138.0,
        "Challenge_word_count":24,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"While CloudFormation doesn't currently offer a resource for a SageMaker Batch Transform ([resource list here in the docs](https:\/\/docs.aws.amazon.com\/AWSCloudFormation\/latest\/UserGuide\/AWS_SageMaker.html)), there are plenty of other integration points to automate running these jobs.\n\n### CloudFormation\n\nI'd actually argue that CloudFormation is probably not a great fit for this anyway because CloudFormation defines **resources** which can be created, updated, and deleted. I could maybe see a correspondence between \"Create\" = \"Run a job\", maybe \"Delete\" = \"Delete job outputs\", and possibly \"Update\" = \"Re-run the job\"? But these are opinionated choices that might not make sense in every case.\n\nIf you really wanted, you could create a [Custom CloudFormation resource](https:\/\/docs.aws.amazon.com\/AWSCloudFormation\/latest\/UserGuide\/template-custom-resources.html) backed by an AWS Lambda function using the [CreateTransformJob API](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/APIReference\/API_CreateTransformJob.html) (via whatever language you prefer e.g. [boto3 in Python](https:\/\/boto3.amazonaws.com\/v1\/documentation\/api\/latest\/reference\/services\/sagemaker.html#SageMaker.Client.create_transform_job)).\n\nNote that:\n- If you wanted to use the [SageMaker Python SDK](https:\/\/sagemaker.readthedocs.io\/en\/stable\/) (`import sagemaker`, `Transformer`, etc) instead of the low-level boto3 interface in Python - you'd need to install this extra library in your Lambda function. Tools like AWS SAM and CDK can help with this.\n- The maximum Lambda timeout is 15 minutes, you may not want to keep your Lambda function running (billable) just waiting for the transform to complete anyway, and even the overall Custom Resource will have a longer max timeout within which it must stabilize after a create\/update\/delete request... So additional orchestration may be required beyond a single synchronous Lambda function call.\n\n### Other (better?) options\n\nAs mentioned above, you can create, describe and stop SageMaker Batch Transform jobs from any environment where you're able to call AWS APIs \/ use AWS SDKs... And you can even use the high-level open-source `sagemaker` SDK from anywhere you install it. Interesting options might include:\n\n- [Amazon SageMaker Pipelines](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/pipelines.html): SageMaker Pipelines have native \"steps\" for a range of SageMaker processes, including transform jobs but also training, pre-processing and more. You can define a multi-step pipeline from the SageMaker Python SDK (in your notebook or elsewhere) and then start it running on-demand (with parameters) by calling the [StartPipelineExecution API](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/APIReference\/API_StartPipelineExecution.html).\n- [AWS Step Functions](https:\/\/docs.aws.amazon.com\/step-functions\/latest\/dg\/welcome.html): Step Functions provides general-purpose serverless orchestration so while the orchestration for SageMaker jobs in particular might be a little more complex (one step to start the job, then a polling check to check wait for completion) - the visual workflow editor and range of integrations to other services may be useful.\n- [Amazon S3 Lambda integrations](https:\/\/docs.aws.amazon.com\/lambda\/latest\/dg\/with-s3.html) can trigger an event automatically (to start your transform job) when new data is uploaded to Amazon S3.\n- [Scheduled EventBridge Rules](https:\/\/docs.aws.amazon.com\/eventbridge\/latest\/userguide\/eb-create-rule-schedule.html) can run actions on a regular schedule (such as calling Lambda functions, kicking off these pipelines, etc) - in case you need a schedule-based execution rather than in response to some event.\n\nThe choice will depend on what the initial trigger for your workflow would be (schedule? Data upload? Some other AWS event? An API call from outside AWS?) and what other steps need to be orchestrated as well as your transform job in the overall flow.",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":1649089461868,
        "Solution_link_count":10.0,
        "Solution_readability":13.3,
        "Solution_reading_time":50.56,
        "Solution_score_count":1.0,
        "Solution_sentence_count":29.0,
        "Solution_word_count":479.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1442422586352,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Atlanta, United States",
        "Answerer_reputation_count":20328.0,
        "Answerer_view_count":2380.0,
        "Challenge_adjusted_solved_time":2.0320580556,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I'm trying to use terraform to create a model on SageMaker by following <a href=\"https:\/\/registry.terraform.io\/providers\/hashicorp\/aws\/latest\/docs\/resources\/sagemaker_model\" rel=\"nofollow noreferrer\">this page<\/a>\nI can't assign a full access policy to the sagemaker role due to permission constrains, so I created a role and attached a policy with part of the permissions<\/p>\n<p>When I tested <code>Terraform plan<\/code>, it gave me this:<\/p>\n<pre><code>Error: Invalid template interpolation value\n...\n<\/code><\/pre>\n<pre><code>..........................\n 141:                 &quot;ecr:GetRepositoryPolicy&quot;\n 142:             ],\n 143:             &quot;Resource&quot;: [\n 144:                 &quot;arn:aws:s3:::${aws_s3_bucket.xx_xxxxxxxxxx_xxx_bucket}&quot;,\n 145:                 &quot;arn:aws:s3:::${local.binaries_bucket_name}&quot;,\n 146:                 &quot;arn:aws:s3:::${aws_s3_bucket.xx_xxxxxxxxxx_xxx_bucket}\/*&quot;,\n 147:                 &quot;arn:aws:s3:::${local.binaries_bucket_name}\/*&quot;,\n 148:                 &quot;arn:aws:ecr:us-east-1:*:repository\/*&quot;,\n 149.....................\n 157:         }\n 158:     ]\n 159: }\n 160: POLICY\n    |----------------\n    | aws_s3_bucket.xx_xxxxxxxxxx_xxx_bucket is object with 25 attributes\n\nCannot include the given value in a string template: string required.\n<\/code><\/pre>\n<p>I'm new to this, just wondering if this is complaining the bucket name is too long or something else? What should I do to fix this, I'm a bit confused. Many thanks.<\/p>\n<p>(PS: Terraform version <code>v0.13.4<\/code> + provider registry.terraform.io\/hashicorp\/aws <code>v3.20.0<\/code>)<\/p>",
        "Challenge_closed_time":1607629351412,
        "Challenge_comment_count":3,
        "Challenge_created_time":1607622036003,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1607700252620,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/65239565",
        "Challenge_link_count":1,
        "Challenge_participation_count":5,
        "Challenge_readability":12.3,
        "Challenge_reading_time":20.62,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":2.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":14,
        "Challenge_solved_time":2.0320580556,
        "Challenge_title":"Terraform - Cannot include the given value in a string template: string required",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":8882.0,
        "Challenge_word_count":152,
        "Platform":"Stack Overflow",
        "Poster_created_time":1540920956270,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"United Kingdom",
        "Poster_reputation_count":2385.0,
        "Poster_view_count":585.0,
        "Solution_body":"<p>It appears what you want here is the ARN of the S3 bucket, which is provided by <a href=\"https:\/\/www.terraform.io\/docs\/configuration\/blocks\/resources\/behavior.html#accessing-resource-attributes\" rel=\"noreferrer\">exported resource attributes<\/a>. Specifically, you probably want the <code>arn<\/code> resource attribute.<\/p>\n<p>Updating your policy like:<\/p>\n<pre><code> 144:             &quot;${aws_s3_bucket.xx_xxxxxxxxxx_xxx_bucket.arn}&quot;,\n 146:             &quot;${aws_s3_bucket.xx_xxxxxxxxxx_xxx_bucket.arn}\/*&quot;,\n<\/code><\/pre>\n<p>will provide you with the String that you need by accessing the <code>arn<\/code> attribute. The currently written policy is accessing <code>aws_s3_bucket.xx_xxxxxxxxxx_xxx_bucket<\/code>, which is a Map (possibly Object) of every argument and attribute for that resource, and will not interpolate within the string of your policy.<\/p>",
        "Solution_comment_count":4.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":12.1,
        "Solution_reading_time":11.28,
        "Solution_score_count":5.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":85.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1416648155470,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":14749.0,
        "Answerer_view_count":968.0,
        "Challenge_adjusted_solved_time":76.2321219444,
        "Challenge_answer_count":1,
        "Challenge_body":"<h1>Question<\/h1>\n<p>Please advise how to trouble shoot the problem.<\/p>\n<h1>Problem<\/h1>\n<p>Cannot access the RedShift cluster endpoint from the SageMaker studio instance.<\/p>\n<pre><code>import socket\nsock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\nresult = sock.connect_ex(('dsoaws.cw7xniw3gvef.us-east-2.redshift.amazonaws.com',5439))\nif result == 0:\n   print(&quot;Port is open&quot;)\nelse:\n   print(&quot;Port is not open&quot;)\nsock.close()\n---\n\nPort is not open\n<\/code><\/pre>\n<h1>RedShift Cluster<\/h1>\n<p>Endpoint is <code>dsoaws.cw7xniw3gvef.us-east-2.redshift.amazonaws.com:5439\/dsoaws<\/code>.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/t4w92.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/t4w92.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>The network setting shows the VPC is vpc-5b123432 allowing access from sg-56cb133e.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/nu5kM.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/nu5kM.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<hr \/>\n<h1>SageMaker Studio<\/h1>\n<p>The SageMaker Studio instance is in the save VPC vpc-5b123432. However, not sure if sg-56cb133e is actually attached to the SageMaker studio instance. Please advise how to confirm if the sg-56cb133e is attached to the instance.<\/p>\n<pre><code>import json\nimport boto3\nfrom botocore.exceptions import ClientError\nfrom botocore.config import Config\n\nconfig = Config(\n   retries = {\n      'max_attempts': 10,\n      'mode': 'adaptive'\n   }\n)\n\n\niam = boto3.client('iam', config=config)\nsts = boto3.client('sts')\nredshift = boto3.client('redshift')\nsm = boto3.client('sagemaker')\nec2 = boto3.client('ec2')\n\ntry:\n    domain_id = sm.list_domains()['Domains'][0]['DomainId'] #['NotebookInstances'][0]['NotebookInstanceName']\n    describe_domain_response = sm.describe_domain(DomainId=domain_id)\n    vpc_id = describe_domain_response['VpcId']\n    print(vpc_id)\n    security_groups = ec2.describe_security_groups()['SecurityGroups']\n    for security_group in security_groups:\n        if vpc_id == security_group['VpcId']:\n            security_group_id = security_group['GroupId']\n    print(security_group_id)\nexcept:\n    pass\n-----\nvpc-5b123432\nsg-56cb133e\n<\/code><\/pre>\n<hr \/>\n<h1>Security Group<\/h1>\n<p><a href=\"https:\/\/i.stack.imgur.com\/JgCgi.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/JgCgi.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/gjmLh.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/gjmLh.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<h1>IAM<\/h1>\n<p>The IAM role <code>SageMaker<\/code> is attached to the SageMaker Studio.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/oY9ix.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/oY9ix.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Challenge_closed_time":1628118669360,
        "Challenge_comment_count":0,
        "Challenge_created_time":1627882823273,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/68616817",
        "Challenge_link_count":10,
        "Challenge_participation_count":1,
        "Challenge_readability":15.4,
        "Challenge_reading_time":38.15,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":33,
        "Challenge_solved_time":65.5128019444,
        "Challenge_title":"AWS - Cannot access RedShift endpoint from the SageMaker Studio",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":434.0,
        "Challenge_word_count":229,
        "Platform":"Stack Overflow",
        "Poster_created_time":1416648155470,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":14749.0,
        "Poster_view_count":968.0,
        "Solution_body":"<h1>Cause<\/h1>\n<p>Did not use VPC Only sagemaker deployment as having used the Quick Start onboard.<\/p>\n<h1>Fix<\/h1>\n<ol>\n<li>Deleted the SageMaker Studio. R<\/li>\n<li>Recreated by using the Standard Setup + VPC only\n<a href=\"https:\/\/i.stack.imgur.com\/zZ7be.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/zZ7be.png\" alt=\"enter image description here\" \/><\/a><\/li>\n<li>Added the NAT and configured the routing tables.<\/li>\n<\/ol>\n<h1>References<\/h1>\n<ul>\n<li><a href=\"https:\/\/aws.amazon.com\/blogs\/machine-learning\/securing-amazon-sagemaker-studio-connectivity-using-a-private-vpc\/\" rel=\"nofollow noreferrer\">Securing Amazon SageMaker Studio connectivity using a private VPC<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/aws-samples\/amazon-sagemaker-studio-vpc-networkfirewall\" rel=\"nofollow noreferrer\">Amazon SageMaker Studio in a private VPC with NAT Gateway and Network Firewall<\/a><\/li>\n<\/ul>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":1628157258912,
        "Solution_link_count":4.0,
        "Solution_readability":17.8,
        "Solution_reading_time":12.15,
        "Solution_score_count":0.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":80.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":506.6507333334,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I need to move my Machine Learning Studio workspace to a new region. I am aware that the move function <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-move-workspace#limitations\">doesn't allow automatically moving to a new region<\/a>, so I'll have to create a new workspace. That's not a big problem, but I still want to keep my job\/experiment history (in my new workspace). How can I do that?    <\/p>",
        "Challenge_closed_time":1664291528087,
        "Challenge_comment_count":1,
        "Challenge_created_time":1662467585447,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/995833\/moving-azure-machine-learning-studio-jobs-to-a-new",
        "Challenge_link_count":1,
        "Challenge_participation_count":2,
        "Challenge_readability":7.9,
        "Challenge_reading_time":6.1,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":506.6507333334,
        "Challenge_title":"Moving Azure Machine Learning Studio jobs to a new region",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":70,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=a645d9b8-7c24-4419-8686-bc144a45c4f1\">@David-3633  <\/a>     <\/p>\n<p>Sorry, I just got confimation from product team, this is currently impossible. I am sorry for the inconvenience.     <\/p>\n<p>A near future workaround which could let users at least share some experiment outputs\/inputs like environments, models, datasets cross region, but not the jobs\/metrics\/logs themselves. This feature is in private preview now and will be in public preview soon.    <\/p>\n<p>I hope this information helps.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Solution_comment_count":2.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":8.3,
        "Solution_reading_time":8.29,
        "Solution_score_count":0.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":90.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":14.6736786111,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hello,    <\/p>\n<p>In my MLStudio my notebook files window has disappeared so I can not access any of my data (as seen on the image) and I do not know what to do.    <\/p>\n<p>Please your help to solve this as soon as poosible.    <\/p>\n<p>Thank you.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/203167-image.png?platform=QnA\" alt=\"203167-image.png\" \/>    <\/p>",
        "Challenge_closed_time":1652928385600,
        "Challenge_comment_count":1,
        "Challenge_created_time":1652875560357,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/854288\/notebook-files-have-disaperred",
        "Challenge_link_count":1,
        "Challenge_participation_count":2,
        "Challenge_readability":7.6,
        "Challenge_reading_time":5.16,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":14.6736786111,
        "Challenge_title":"Notebook files have disaperred",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":55,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hello,    <\/p>\n<p>Thanks for reaching out to us. Could you please check the access of Storage?  <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/storage\/blobs\/assign-azure-role-data-access?tabs=portal#assign-an-azure-role\">https:\/\/learn.microsoft.com\/en-us\/azure\/storage\/blobs\/assign-azure-role-data-access?tabs=portal#assign-an-azure-role<\/a>    <\/p>\n<p>To access these storage services, you must have at least Storage Blob Data Reader access to the storage account. Only storage account owners can change your access level via the Azure portal.    <\/p>\n<p>Or, your admin put the data storage behind V-Net and you can not get access to it- <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-identity-based-data-access#work-with-virtual-networks\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-identity-based-data-access#work-with-virtual-networks<\/a>    <br \/>\nIn this situation, you need to ask permission from your admin.    <\/p>\n<p>Could you please share which situation you are in?     <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n",
        "Solution_comment_count":2.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":14.0,
        "Solution_reading_time":13.94,
        "Solution_score_count":0.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":98.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":11799.0105555556,
        "Challenge_answer_count":1,
        "Challenge_body":"For uploading data to AWS Neptune we use `NeptuneCSVPublisher`, which internally uses `NeptuneBulkLoaderApi`. The current configuration uses config key `NeptuneCSVPublisher.AWS_IAM_ROLE_NAME`, which provides name of IAM role for the loader to be able to use S3 and Neptune. The issue is that `NeptuneBulkLoaderApi` constructs IAM role ARN from name as follows: \r\n\r\n```python\r\naccount_id = self.session.client('sts').get_caller_identity()['Account']\r\nself.iam_role_arn = f'arn:aws:iam::{account_id}:role\/{iam_role_name}'\r\n```\r\n\r\nwhereas, [second element of ARN aka partition](https:\/\/docs.aws.amazon.com\/general\/latest\/gr\/aws-arns-and-namespaces.html) can be currently:\r\n* `aws` -AWS Regions\r\n* `aws-cn` - China Regions\r\n* `aws-us-gov` - AWS GovCloud (US) Regions\r\n\r\nSince we use Amundsen also in AWS China, the above ARN is not valid. \r\n\r\n## Expected Behavior\r\n\r\nIAM role ARN either takes into account AWS partition or there is a possibility of passing IAM role ARN instead of name directly.\r\n\r\n## Current Behavior\r\n\r\nIAM role ARN is constructed incorrectly outside of AWS Global.\r\n\r\n## Possible Solutions\r\n\r\nIAM role ARN should take partition into account. There are two solutions:\r\n1. Add partition into current code\r\n2. Add option of passing IAM role ARN directly which supersedes IAM role name \r\n\r\n### Solution 1\r\n\r\nSince I didn't know or found any good way to get the AWS partition, we can use caller identity and ARN there to get the partition, e.g.:\r\n\r\n```python\r\nidentity = self.session.client('sts').get_caller_identity()\r\naccount_id = identity['Account']\r\npartition = identity['Arn'].split(':')[1]\r\nself.iam_role_arn = f'arn:{partition}:iam::{account_id}:role\/{iam_role_name}'\r\n```\r\n\r\nThis is smaller fix but it is a bit hacky and I'm not sure it'll work in all situation, but it should I guess.\r\n\r\n### Solution 2\r\n\r\nAdd config key `NeptuneCSVPublisher.AWS_IAM_ROLE_ARN` which either supersedes `NeptuneCSVPublisher.AWS_IAM_ROLE_NAME` in a way that in constructor we would have something like:\r\n\r\n```python\r\nif iam_role_arn:\r\n    self.iam_role_arn = iam_role_arn\r\nelse:\r\n   ...\r\n   self.iam_role_arn = f'arn:{partition}:iam::{account_id}:role\/{iam_role_name}'\r\n```\r\n\r\nOr even replace `NeptuneCSVPublisher.AWS_IAM_ROLE_NAME` with `NeptuneCSVPublisher.AWS_IAM_ROLE_ARN`, which is IMO cleaner, but would be not backward compatible. \r\n\r\n## Steps to Reproduce\r\nDeploy Amundsen in AWS China with Neptune and try to use Databuilder to upload CSV data from S3. \r\n\r\n## Screenshots (if appropriate)\r\n\r\n## Context\r\nCurrently we are unable to load data into Neptune as the IAM role ARN setting is hidden and we get an error:\r\n\r\n```\r\n[ERROR] Exception: Failed to load csv. Response: {'detailedMessage': \"Failed to start new load from the source s3:\/\/amundsenBucket\/amundsen\/2021_08_10_01_01_28. Couldn't find the aws credential for iam_role_arn: arn:aws:iam::111111111:role\/RoleForNeptune111111-2222\", 'code': 'InvalidParameterException', 'requestId': 'xxx'}\r\nTraceback (most recent call last):\r\n\u00a0\u00a0File \"\/var\/task\/ctw\/jobs\/synchronize_redshift_metadata.py\", line 49, in lambda_handler\r\n\u00a0\u00a0\u00a0\u00a0redshift_to_neptune_job.launch()\r\n\u00a0\u00a0File \"\/var\/task\/databuilder\/job\/job.py\", line 76, in launch\r\n\u00a0\u00a0\u00a0\u00a0raise e\r\n\u00a0\u00a0File \"\/var\/task\/databuilder\/job\/job.py\", line 72, in launch\r\n\u00a0\u00a0\u00a0\u00a0self.publisher.publish()\r\n\u00a0\u00a0File \"\/var\/task\/databuilder\/publisher\/base_publisher.py\", line 40, in publish\r\n\u00a0\u00a0\u00a0\u00a0raise e\r\n\u00a0\u00a0File \"\/var\/task\/databuilder\/publisher\/base_publisher.py\", line 37, in publish\r\n\u00a0\u00a0\u00a0\u00a0self.publish_impl()\r\n\u00a0\u00a0File \"\/var\/task\/databuilder\/publisher\/neptune_csv_publisher.py\", line 109, in publish_impl\r\n\u00a0\u00a0\u00a0\u00a0raise Exception(\"Failed to load csv. Response: {0}\".format(str(bulk_upload_response)))\r\n```\r\n\r\n## Your Environment\r\n* Amunsen version used: `amundsen-databuilder==4.3.1`\r\n* Data warehouse stores: AWS Neptune\r\n* Deployment (k8s or native): AWS Step Functions (k8s for backend but unrelated for now)\r\n* Link to your fork or repository:",
        "Challenge_closed_time":1671067447000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1628591009000,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/github.com\/amundsen-io\/amundsen\/issues\/1430",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":10.2,
        "Challenge_reading_time":49.7,
        "Challenge_repo_contributor_count":207.0,
        "Challenge_repo_fork_count":890.0,
        "Challenge_repo_issue_count":2023.0,
        "Challenge_repo_star_count":3674.0,
        "Challenge_repo_watch_count":245.0,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":38,
        "Challenge_solved_time":11799.0105555556,
        "Challenge_title":"Databuilder `NeptuneBulkLoaderApi` constructs wrong IAM role ARN for AWS other than global",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":441,
        "Platform":"Github",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs.\n",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":9.2,
        "Solution_reading_time":1.69,
        "Solution_score_count":0.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":24.0,
        "Tool":"Neptune"
    },
    {
        "Answerer_created_time":1261400320736,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Antwerp, Belgium",
        "Answerer_reputation_count":7876.0,
        "Answerer_view_count":924.0,
        "Challenge_adjusted_solved_time":0.6120011111,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I've installed <a href=\"https:\/\/mlflow.org\/\" rel=\"nofollow noreferrer\">MLflow<\/a> on Ubuntu Server 18.04 LTS, in a virtual environment (Python 3), using its <a href=\"https:\/\/mlflow.org\/docs\/latest\/quickstart.html\" rel=\"nofollow noreferrer\">Quickstart documentation<\/a>:<\/p>\n\n<pre><code>$ python3 -m venv mlflow\n$ source \/home\/emre\/mlflow\/bin\/activate\n$ pip install mlflow\n<\/code><\/pre>\n\n<p>that gave the following output during install:<\/p>\n\n<pre><code>Collecting mlflow\n  Downloading https:\/\/files.pythonhosted.org\/packages\/e8\/b3\/cf358e182be34a62fcd6843e5df793f278bd9d24f78f565509cb927c6a22\/mlflow-0.1.0.tar.gz (4.3MB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4.3MB 323kB\/s\nCollecting Flask (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/7f\/e7\/08578774ed4536d3242b14dacb4696386634607af824ea997202cd0edb4b\/Flask-1.0.2-py2.py3-none-any.whl (91kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 92kB 9.4MB\/s\nCollecting awscli (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/ba\/32\/d6d254f6ccc2ed21f02d81f38709ff06feca9cbdb2e68ea90635fa483a73\/awscli-1.15.46-py2.py3-none-any.whl (1.3MB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.3MB 1.0MB\/s\nCollecting boto3 (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/24\/e0\/a98898b94d8093bbd8fd4576fb2e89620adac1e24a2bfc28d11c4ce29a5b\/boto3-1.7.46-py2.py3-none-any.whl (128kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 133kB 8.8MB\/s\nCollecting click&gt;=6.7 (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/34\/c1\/8806f99713ddb993c5366c362b2f908f18269f8d792aff1abfd700775a77\/click-6.7-py2.py3-none-any.whl (71kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 71kB 9.3MB\/s\nCollecting databricks-cli (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/58\/78\/4bda6f29a091ab7b0ad29efdba2491e5d0b56bd09d608857e6f0b799be48\/databricks-cli-0.7.2.tar.gz\nCollecting gitpython (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/ac\/c9\/96d7c86c623cb065976e58c0f4898170507724d6b4be872891d763d686f4\/GitPython-2.1.10-py2.py3-none-any.whl (449kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 450kB 2.9MB\/s\nCollecting numpy (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/68\/1e\/116ad560de97694e2d0c1843a7a0075cc9f49e922454d32f49a80eb6f1f2\/numpy-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (12.2MB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 12.2MB 110kB\/s\nCollecting pandas (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/57\/eb\/6ab533ea8e35e7dd159af6922ac1123d4565d89f3926ad9a6aa46530978f\/pandas-0.23.1-cp36-cp36m-manylinux1_x86_64.whl (11.8MB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 11.8MB 116kB\/s\nCollecting protobuf (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/fc\/f0\/db040681187496d10ac50ad167a8fd5f953d115b16a7085e19193a6abfd2\/protobuf-3.6.0-cp36-cp36m-manylinux1_x86_64.whl (7.1MB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7.1MB 177kB\/s\nCollecting pygal (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/5f\/b7\/201c9254ac0d2b8ffa3bb2d528d23a4130876d9ba90bc28e99633f323f17\/pygal-2.4.0-py2.py3-none-any.whl (127kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 133kB 9.7MB\/s\nCollecting python-dateutil (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/cf\/f5\/af2b09c957ace60dcfac112b669c45c8c97e32f94aa8b56da4c6d1682825\/python_dateutil-2.7.3-py2.py3-none-any.whl (211kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 215kB 6.0MB\/s\nCollecting pyyaml (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/10\/7d\/6efe0bd69580fecd40adf47ebaf8d807238308ccb851f0549881fa7605aa\/PyYAML-4.1.tar.gz (153kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 153kB 7.8MB\/s\nCollecting querystring_parser (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/57\/64\/3086a9a991ff3aca7b769f5b0b51ff8445a06337ae2c58f215bcee48f527\/querystring_parser-1.2.3.tar.gz\nCollecting requests&gt;=2.17.3 (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/65\/47\/7e02164a2a3db50ed6d8a6ab1d6d60b69c4c3fdf57a284257925dfc12bda\/requests-2.19.1-py2.py3-none-any.whl (91kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 92kB 8.2MB\/s\nCollecting scikit-learn (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/3d\/2d\/9fbc7baa5f44bc9e88ffb7ed32721b879bfa416573e85031e16f52569bc9\/scikit_learn-0.19.1-cp36-cp36m-manylinux1_x86_64.whl (12.4MB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 12.4MB 108kB\/s\nCollecting scipy (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/a8\/0b\/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730\/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 31.2MB 42kB\/s\nCollecting six&gt;=1.10.0 (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/67\/4b\/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a\/six-1.11.0-py2.py3-none-any.whl\nCollecting uuid (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/ce\/63\/f42f5aa951ebf2c8dac81f77a8edcc1c218640a2a35a03b9ff2d4aa64c3d\/uuid-1.30.tar.gz\nCollecting zipstream (from mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/1a\/a4\/58f0709cef999db1539960aa2ae77100dc800ebb8abb7afc97a1398dfb2f\/zipstream-1.1.4.tar.gz\nCollecting itsdangerous&gt;=0.24 (from Flask-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/dc\/b4\/a60bcdba945c00f6d608d8975131ab3f25b22f2bcfe1dab221165194b2d4\/itsdangerous-0.24.tar.gz (46kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51kB 10.4MB\/s\nCollecting Werkzeug&gt;=0.14 (from Flask-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/20\/c4\/12e3e56473e52375aa29c4764e70d1b8f3efa6682bef8d0aae04fe335243\/Werkzeug-0.14.1-py2.py3-none-any.whl (322kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 327kB 4.0MB\/s\nCollecting Jinja2&gt;=2.10 (from Flask-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/7f\/ff\/ae64bacdfc95f27a016a7bed8e8686763ba4d277a78ca76f32659220a731\/Jinja2-2.10-py2.py3-none-any.whl (126kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 133kB 8.2MB\/s\nCollecting rsa&lt;=3.5.0,&gt;=3.1.2 (from awscli-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/e1\/ae\/baedc9cb175552e95f3395c43055a6a5e125ae4d48a1d7a924baca83e92e\/rsa-3.4.2-py2.py3-none-any.whl (46kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51kB 10.5MB\/s\nCollecting botocore==1.10.46 (from awscli-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/b4\/04\/ddaad5574f70a539d106e8d53b4685e3de4387de7a16884a95459f8c7691\/botocore-1.10.46-py2.py3-none-any.whl (4.4MB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4.4MB 314kB\/s\nCollecting s3transfer&lt;0.2.0,&gt;=0.1.12 (from awscli-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/d7\/14\/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d\/s3transfer-0.1.13-py2.py3-none-any.whl (59kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 61kB 10.6MB\/s\nCollecting colorama&lt;=0.3.9,&gt;=0.2.5 (from awscli-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/db\/c8\/7dcf9dbcb22429512708fe3a547f8b6101c0d02137acbd892505aee57adf\/colorama-0.3.9-py2.py3-none-any.whl\nCollecting docutils&gt;=0.10 (from awscli-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/36\/fa\/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d\/docutils-0.14-py3-none-any.whl (543kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 552kB 2.5MB\/s\nCollecting jmespath&lt;1.0.0,&gt;=0.7.1 (from boto3-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/b7\/31\/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365\/jmespath-0.9.3-py2.py3-none-any.whl\nCollecting configparser&gt;=0.3.5 (from databricks-cli-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/7c\/69\/c2ce7e91c89dc073eb1aa74c0621c3eefbffe8216b3f9af9d3885265c01c\/configparser-3.5.0.tar.gz\nCollecting tabulate&gt;=0.7.7 (from databricks-cli-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/12\/c2\/11d6845db5edf1295bc08b2f488cf5937806586afe42936c3f34c097ebdc\/tabulate-0.8.2.tar.gz (45kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51kB 7.9MB\/s\nCollecting gitdb2&gt;=2.0.0 (from gitpython-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/e0\/95\/c772c13b7c5740ec1a0924250e6defbf5dfdaee76a50d1c47f9c51f1cabb\/gitdb2-2.0.3-py2.py3-none-any.whl (63kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 71kB 11.2MB\/s\nCollecting pytz&gt;=2011k (from pandas-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/dc\/83\/15f7833b70d3e067ca91467ca245bae0f6fe56ddc7451aa0dc5606b120f2\/pytz-2018.4-py2.py3-none-any.whl (510kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 512kB 421kB\/s\nRequirement already satisfied: setuptools in .\/mlflow\/lib\/python3.6\/site-packages (from protobuf-&gt;mlflow)\nCollecting chardet&lt;3.1.0,&gt;=3.0.2 (from requests&gt;=2.17.3-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/bc\/a9\/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8\/chardet-3.0.4-py2.py3-none-any.whl (133kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 143kB 8.7MB\/s\nCollecting idna&lt;2.8,&gt;=2.5 (from requests&gt;=2.17.3-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/4b\/2a\/0276479a4b3caeb8a8c1af2f8e4355746a97fab05a372e4a2c6a6b876165\/idna-2.7-py2.py3-none-any.whl (58kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 61kB 10.3MB\/s\nCollecting urllib3&lt;1.24,&gt;=1.21.1 (from requests&gt;=2.17.3-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/bd\/c9\/6fdd990019071a4a32a5e7cb78a1d92c53851ef4f56f62a3486e6a7d8ffb\/urllib3-1.23-py2.py3-none-any.whl (133kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 143kB 8.3MB\/s\nCollecting certifi&gt;=2017.4.17 (from requests&gt;=2.17.3-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/7c\/e6\/92ad559b7192d846975fc916b65f667c7b8c3a32bea7372340bfe9a15fa5\/certifi-2018.4.16-py2.py3-none-any.whl (150kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 153kB 8.0MB\/s\nCollecting MarkupSafe&gt;=0.23 (from Jinja2&gt;=2.10-&gt;Flask-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/4d\/de\/32d741db316d8fdb7680822dd37001ef7a448255de9699ab4bfcbdf4172b\/MarkupSafe-1.0.tar.gz\nCollecting pyasn1&gt;=0.1.3 (from rsa&lt;=3.5.0,&gt;=3.1.2-&gt;awscli-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/a0\/70\/2c27740f08e477499ce19eefe05dbcae6f19fdc49e9e82ce4768be0643b9\/pyasn1-0.4.3-py2.py3-none-any.whl (72kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 81kB 10.9MB\/s\nCollecting smmap2&gt;=2.0.0 (from gitdb2&gt;=2.0.0-&gt;gitpython-&gt;mlflow)\n  Downloading https:\/\/files.pythonhosted.org\/packages\/e3\/59\/4e22f692e65f5f9271252a8e63f04ce4ad561d4e06192478ee48dfac9611\/smmap2-2.0.3-py2.py3-none-any.whl\nBuilding wheels for collected packages: mlflow, databricks-cli, pyyaml, querystring-parser, uuid, zipstream, itsdangerous, configparser, tabulate, MarkupSafe\n  Running setup.py bdist_wheel for mlflow ... error\n  Complete output from command \/home\/emre\/mlflow\/bin\/python3 -u -c \"import setuptools, tokenize;__file__='\/tmp\/pip-build-s7vrp5z7\/mlflow\/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d \/tmp\/tmp10fdrz2ypip-wheel- --python-tag cp36:\n  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n     or: -c --help [cmd1 cmd2 ...]\n     or: -c --help-commands\n     or: -c cmd --help\n\n  error: invalid command 'bdist_wheel'\n\n  ----------------------------------------\n  Failed building wheel for mlflow\n  Running setup.py clean for mlflow\n  Running setup.py bdist_wheel for databricks-cli ... error\n  Complete output from command \/home\/emre\/mlflow\/bin\/python3 -u -c \"import setuptools, tokenize;__file__='\/tmp\/pip-build-s7vrp5z7\/databricks-cli\/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d \/tmp\/tmpy_2acqi3pip-wheel- --python-tag cp36:\n  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n     or: -c --help [cmd1 cmd2 ...]\n     or: -c --help-commands\n     or: -c cmd --help\n\n  error: invalid command 'bdist_wheel'\n\n  ----------------------------------------\n  Failed building wheel for databricks-cli\n  Running setup.py clean for databricks-cli\n  Running setup.py bdist_wheel for pyyaml ... error\n  Complete output from command \/home\/emre\/mlflow\/bin\/python3 -u -c \"import setuptools, tokenize;__file__='\/tmp\/pip-build-s7vrp5z7\/pyyaml\/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d \/tmp\/tmp4bs2fwrtpip-wheel- --python-tag cp36:\n  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n     or: -c --help [cmd1 cmd2 ...]\n     or: -c --help-commands\n     or: -c cmd --help\n\n  error: invalid command 'bdist_wheel'\n\n  ----------------------------------------\n  Failed building wheel for pyyaml\n  Running setup.py clean for pyyaml\n  Running setup.py bdist_wheel for querystring-parser ... error\n  Complete output from command \/home\/emre\/mlflow\/bin\/python3 -u -c \"import setuptools, tokenize;__file__='\/tmp\/pip-build-s7vrp5z7\/querystring-parser\/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d \/tmp\/tmp_cnm9w_tpip-wheel- --python-tag cp36:\n  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n     or: -c --help [cmd1 cmd2 ...]\n     or: -c --help-commands\n     or: -c cmd --help\n\n  error: invalid command 'bdist_wheel'\n\n  ----------------------------------------\n  Failed building wheel for querystring-parser\n  Running setup.py clean for querystring-parser\n  Running setup.py bdist_wheel for uuid ... error\n  Complete output from command \/home\/emre\/mlflow\/bin\/python3 -u -c \"import setuptools, tokenize;__file__='\/tmp\/pip-build-s7vrp5z7\/uuid\/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d \/tmp\/tmpenr2igaxpip-wheel- --python-tag cp36:\n  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n     or: -c --help [cmd1 cmd2 ...]\n     or: -c --help-commands\n     or: -c cmd --help\n\n  error: invalid command 'bdist_wheel'\n\n  ----------------------------------------\n  Failed building wheel for uuid\n  Running setup.py clean for uuid\n  Running setup.py bdist_wheel for zipstream ... error\n  Complete output from command \/home\/emre\/mlflow\/bin\/python3 -u -c \"import setuptools, tokenize;__file__='\/tmp\/pip-build-s7vrp5z7\/zipstream\/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d \/tmp\/tmpnzsjh5e2pip-wheel- --python-tag cp36:\n  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n     or: -c --help [cmd1 cmd2 ...]\n     or: -c --help-commands\n     or: -c cmd --help\n\n  error: invalid command 'bdist_wheel'\n\n  ----------------------------------------\n  Failed building wheel for zipstream\n  Running setup.py clean for zipstream\n  Running setup.py bdist_wheel for itsdangerous ... error\n  Complete output from command \/home\/emre\/mlflow\/bin\/python3 -u -c \"import setuptools, tokenize;__file__='\/tmp\/pip-build-s7vrp5z7\/itsdangerous\/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d \/tmp\/tmp7imi3zv2pip-wheel- --python-tag cp36:\n  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n     or: -c --help [cmd1 cmd2 ...]\n     or: -c --help-commands\n     or: -c cmd --help\n\n  error: invalid command 'bdist_wheel'\n\n  ----------------------------------------\n  Failed building wheel for itsdangerous\n  Running setup.py clean for itsdangerous\n  Running setup.py bdist_wheel for configparser ... error\n  Complete output from command \/home\/emre\/mlflow\/bin\/python3 -u -c \"import setuptools, tokenize;__file__='\/tmp\/pip-build-s7vrp5z7\/configparser\/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d \/tmp\/tmpyk9qtmi1pip-wheel- --python-tag cp36:\n  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n     or: -c --help [cmd1 cmd2 ...]\n     or: -c --help-commands\n     or: -c cmd --help\n\n  error: invalid command 'bdist_wheel'\n\n  ----------------------------------------\n  Failed building wheel for configparser\n  Running setup.py clean for configparser\n  Running setup.py bdist_wheel for tabulate ... error\n  Complete output from command \/home\/emre\/mlflow\/bin\/python3 -u -c \"import setuptools, tokenize;__file__='\/tmp\/pip-build-s7vrp5z7\/tabulate\/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d \/tmp\/tmpjim2qr00pip-wheel- --python-tag cp36:\n  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n     or: -c --help [cmd1 cmd2 ...]\n     or: -c --help-commands\n     or: -c cmd --help\n\n  error: invalid command 'bdist_wheel'\n\n  ----------------------------------------\n  Failed building wheel for tabulate\n  Running setup.py clean for tabulate\n  Running setup.py bdist_wheel for MarkupSafe ... error\n  Complete output from command \/home\/emre\/mlflow\/bin\/python3 -u -c \"import setuptools, tokenize;__file__='\/tmp\/pip-build-s7vrp5z7\/MarkupSafe\/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d \/tmp\/tmpsdpdd8ulpip-wheel- --python-tag cp36:\n  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n     or: -c --help [cmd1 cmd2 ...]\n     or: -c --help-commands\n     or: -c cmd --help\n\n  error: invalid command 'bdist_wheel'\n\n  ----------------------------------------\n  Failed building wheel for MarkupSafe\n  Running setup.py clean for MarkupSafe\nFailed to build mlflow databricks-cli pyyaml querystring-parser uuid zipstream itsdangerous configparser tabulate MarkupSafe\nInstalling collected packages: click, itsdangerous, Werkzeug, MarkupSafe, Jinja2, Flask, pyasn1, rsa, jmespath, six, python-dateutil, docutils, botocore, s3transfer, colorama, pyyaml, awscli, boto3, configparser, chardet, idna, urllib3, certifi, requests, tabulate, databricks-cli, smmap2, gitdb2, gitpython, numpy, pytz, pandas, protobuf, pygal, querystring-parser, scikit-learn, scipy, uuid, zipstream, mlflow\n  Running setup.py install for itsdangerous ... done\n  Running setup.py install for MarkupSafe ... done\n  Running setup.py install for pyyaml ... done\n  Running setup.py install for configparser ... done\n  Running setup.py install for tabulate ... done\n  Running setup.py install for databricks-cli ... done\n  Running setup.py install for querystring-parser ... done\n  Running setup.py install for uuid ... done\n  Running setup.py install for zipstream ... done\n  Running setup.py install for mlflow ... done\nSuccessfully installed Flask-1.0.2 Jinja2-2.10 MarkupSafe-1.0 Werkzeug-0.14.1 awscli-1.15.46 boto3-1.7.46 botocore-1.10.46 certifi-2018.4.16 chardet-3.0.4 click-6.7 colorama-0.3.9 configparser-3.5.0 databricks-cli-0.7.2 docutils-0.14 gitdb2-2.0.3 gitpython-2.1.10 idna-2.7 itsdangerous-0.24 jmespath-0.9.3 mlflow-0.1.0 numpy-1.14.5 pandas-0.23.1 protobuf-3.6.0 pyasn1-0.4.3 pygal-2.4.0 python-dateutil-2.7.3 pytz-2018.4 pyyaml-4.1 querystring-parser-1.2.3 requests-2.19.1 rsa-3.4.2 s3transfer-0.1.13 scikit-learn-0.19.1 scipy-1.1.0 six-1.11.0 smmap2-2.0.3 tabulate-0.8.2 urllib3-1.23 uuid-1.30 zipstream-1.1.4\n<\/code><\/pre>\n\n<p>After that I checked the following didn't give any errors:<\/p>\n\n<pre><code>import os\nfrom mlflow import log_metric, log_param, log_artifact\n<\/code><\/pre>\n\n<p>But when I try to run the web-based user interface, I get the following errors:<\/p>\n\n<pre><code>$ mlflow ui\nTraceback (most recent call last):\n  File \"\/home\/emre\/mlflow\/lib\/python3.6\/site-packages\/pkg_resources\/__init__.py\", line 574, in _build_master\n    ws.require(__requires__)\n  File \"\/home\/emre\/mlflow\/lib\/python3.6\/site-packages\/pkg_resources\/__init__.py\", line 892, in require\n    needed = self.resolve(parse_requirements(requirements))\n  File \"\/home\/emre\/mlflow\/lib\/python3.6\/site-packages\/pkg_resources\/__init__.py\", line 783, in resolve\n    raise VersionConflict(dist, req).with_context(dependent_req)\npkg_resources.ContextualVersionConflict: (PyYAML 4.1 (\/home\/emre\/mlflow\/lib\/python3.6\/site-packages), Requirement.parse('PyYAML&lt;=3.12,&gt;=3.10'), {'awscli'})\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"\/home\/emre\/mlflow\/bin\/mlflow\", line 6, in &lt;module&gt;\n    from pkg_resources import load_entry_point\n  File \"\/home\/emre\/mlflow\/lib\/python3.6\/site-packages\/pkg_resources\/__init__.py\", line 3088, in &lt;module&gt;\n    @_call_aside\n  File \"\/home\/emre\/mlflow\/lib\/python3.6\/site-packages\/pkg_resources\/__init__.py\", line 3072, in _call_aside\n    f(*args, **kwargs)\n  File \"\/home\/emre\/mlflow\/lib\/python3.6\/site-packages\/pkg_resources\/__init__.py\", line 3101, in _initialize_master_working_set\n    working_set = WorkingSet._build_master()\n  File \"\/home\/emre\/mlflow\/lib\/python3.6\/site-packages\/pkg_resources\/__init__.py\", line 576, in _build_master\n    return cls._build_from_requirements(__requires__)\n  File \"\/home\/emre\/mlflow\/lib\/python3.6\/site-packages\/pkg_resources\/__init__.py\", line 589, in _build_from_requirements\n    dists = ws.resolve(reqs, Environment())\n  File \"\/home\/emre\/mlflow\/lib\/python3.6\/site-packages\/pkg_resources\/__init__.py\", line 783, in resolve\n    raise VersionConflict(dist, req).with_context(dependent_req)\npkg_resources.ContextualVersionConflict: (PyYAML 4.1 (\/home\/emre\/mlflow\/lib\/python3.6\/site-packages), Requirement.parse('PyYAML&lt;=3.12,&gt;=3.10'), {'awscli'})\n<\/code><\/pre>\n\n<p>Any ideas how I can fix this?<\/p>",
        "Challenge_closed_time":1530109158067,
        "Challenge_comment_count":0,
        "Challenge_created_time":1530106954863,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1530112131487,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/51064366",
        "Challenge_link_count":42,
        "Challenge_participation_count":1,
        "Challenge_readability":15.2,
        "Challenge_reading_time":293.26,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":213,
        "Challenge_solved_time":0.6120011111,
        "Challenge_title":"Can't run MLflow web-based user interface",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":791.0,
        "Challenge_word_count":1336,
        "Platform":"Stack Overflow",
        "Poster_created_time":1261400320736,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Antwerp, Belgium",
        "Poster_reputation_count":7876.0,
        "Poster_view_count":924.0,
        "Solution_body":"<p>Apparently I had to install the <code>wheel<\/code> module inside my virtual environment. I deleted the virtual environment, re-created it, and then installed the <code>wheel<\/code> module:<\/p>\n\n<pre><code>pip install wheel\n<\/code><\/pre>\n\n<p>after that <code>pip install mlflow<\/code>, as well as <code>mlflow ui<\/code> worked successfully.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":14.8,
        "Solution_reading_time":4.47,
        "Solution_score_count":1.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":41.0,
        "Tool":"MLflow"
    },
    {
        "Answerer_created_time":1446889503236,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":335.0,
        "Answerer_view_count":74.0,
        "Challenge_adjusted_solved_time":14.9678333333,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Today the following error appeared in my study when I try to optimize it after loading <strong>on Colab<\/strong> on Optuna 2.8.0. I save a study with joblib each time a trial begins or ends in a separate file for each trial. Never have I had this problem before and not sure what actually causes it.<\/p>\n<p>Colab shows the following trace:<\/p>\n<pre><code>\/usr\/local\/lib\/python3.7\/dist-packages\/optuna\/study.py in optimize(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\n    408             callbacks=callbacks,\n    409             gc_after_trial=gc_after_trial,\n--&gt; 410             show_progress_bar=show_progress_bar,\n    411         )\n    412 \n\n\/usr\/local\/lib\/python3.7\/dist-packages\/optuna\/_optimize.py in _optimize(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\n     73                 reseed_sampler_rng=False,\n     74                 time_start=None,\n---&gt; 75                 progress_bar=progress_bar,\n     76             )\n     77         else:\n\n\/usr\/local\/lib\/python3.7\/dist-packages\/optuna\/_optimize.py in _optimize_sequential(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\n    160 \n    161         try:\n--&gt; 162             trial = _run_trial(study, func, catch)\n    163         except Exception:\n    164             raise\n\n\/usr\/local\/lib\/python3.7\/dist-packages\/optuna\/_optimize.py in _run_trial(study, func, catch)\n    195                 failed_trial_callback(study, failed_trial)\n    196 \n--&gt; 197     trial = study.ask()\n    198 \n    199     state: Optional[TrialState] = None\n\n\/usr\/local\/lib\/python3.7\/dist-packages\/optuna\/study.py in ask(self, fixed_distributions)\n    485         if trial_id is None:\n    486             trial_id = self._storage.create_new_trial(self._study_id)\n--&gt; 487         trial = trial_module.Trial(self, trial_id)\n    488 \n    489         for name, param in fixed_distributions.items():\n\n\/usr\/local\/lib\/python3.7\/dist-packages\/optuna\/trial\/_trial.py in __init__(self, study, trial_id)\n     55         self.storage = self.study._storage\n     56 \n---&gt; 57         self._init_relative_params()\n     58 \n     59     def _init_relative_params(self) -&gt; None:\n\n\/usr\/local\/lib\/python3.7\/dist-packages\/optuna\/trial\/_trial.py in _init_relative_params(self)\n     65         self.relative_search_space = self.study.sampler.infer_relative_search_space(study, trial)\n     66         self.relative_params = self.study.sampler.sample_relative(\n---&gt; 67             study, trial, self.relative_search_space\n     68         )\n     69 \n\n\/usr\/local\/lib\/python3.7\/dist-packages\/optuna\/samplers\/_tpe\/sampler.py in sample_relative(self, study, trial, search_space)\n    327         self._raise_error_if_multi_objective(study)\n    328 \n--&gt; 329         if self._group:\n    330             assert self._search_space_group is not None\n    331             params = {}\n\nAttributeError: 'TPESampler' object has no attribute '_group'\n<\/code><\/pre>\n<p>PS. Interestingly, the problem with the study doesn't seem to exist on my local machine. I use version 2.5.0.<\/p>",
        "Challenge_closed_time":1623056322107,
        "Challenge_comment_count":0,
        "Challenge_created_time":1623053333190,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1623053642967,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/67868051",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":14.2,
        "Challenge_reading_time":36.24,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":26,
        "Challenge_solved_time":0.8302547222,
        "Challenge_title":"'TPESampler' object has no attribute '_group'",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":101.0,
        "Challenge_word_count":257,
        "Platform":"Stack Overflow",
        "Poster_created_time":1446889503236,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":335.0,
        "Poster_view_count":74.0,
        "Solution_body":"<p>Just got the answer from Optuna developers:<\/p>\n<blockquote>\n<p>A (private) attribute was introduced to the TPESampler in v2.8 and if\nyou've pickled or serialized the sampler before this introduction,\nyou'll encounter this AttributeError when unpickling it with v2.8.<\/p>\n<\/blockquote>\n<p>The solution to this problem is re-instantiating the sampler object and substitute it to the study.sampler:<\/p>\n<pre><code>study = optuna.load_study(...) \nsampler = optuna.samplers.TPESampler() \nstudy.sampler = sampler\nstudy.optimize(...)\n<\/code><\/pre>\n<p>PS. The same kind of problem may appear with a pruner. If so, re-instantiate also the pruner!<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1623107527167,
        "Solution_link_count":0.0,
        "Solution_readability":11.3,
        "Solution_reading_time":8.24,
        "Solution_score_count":0.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":80.0,
        "Tool":"Optuna"
    },
    {
        "Answerer_created_time":1512520584492,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Bloomington, IN, USA",
        "Answerer_reputation_count":868.0,
        "Answerer_view_count":51.0,
        "Challenge_adjusted_solved_time":7347.4097222222,
        "Challenge_answer_count":3,
        "Challenge_body":"<p>I am trying to run a machine learning experiment in azureml.<\/p>\n<p>I can't figure out how to get the workspace context from the control script.  Examples like <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-bring-data#control-script\" rel=\"nofollow noreferrer\">this one<\/a> in the microsoft docs use Workspace.from_config().  When I use this in the control script I get the following error:<\/p>\n<blockquote>\n<p>&quot;message&quot;: &quot;We could not find config.json in: [path] or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.&quot;<\/p>\n<\/blockquote>\n<p>I've also tried including my subscription id and the resource specs like so:<\/p>\n<pre><code>subscription_id = 'id'\nresource_group = 'name'\nworkspace_name = 'name'\n\nworkspace = Workspace(subscription_id, resource_group, workspace_name)\n<\/code><\/pre>\n<p>In this case I have to monitor the log and authenticate on each run as I would locally.<\/p>\n<p>How do you get the local workspace from a control script for azureml?<\/p>",
        "Challenge_closed_time":1641958092267,
        "Challenge_comment_count":0,
        "Challenge_created_time":1615507417267,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/66592313",
        "Challenge_link_count":1,
        "Challenge_participation_count":3,
        "Challenge_readability":9.5,
        "Challenge_reading_time":14.56,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":11,
        "Challenge_solved_time":7347.4097222222,
        "Challenge_title":"Get local workspace in azureml",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":333.0,
        "Challenge_word_count":143,
        "Platform":"Stack Overflow",
        "Poster_created_time":1512520584492,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Bloomington, IN, USA",
        "Poster_reputation_count":868.0,
        "Poster_view_count":51.0,
        "Solution_body":"<p>This had no answers for 10 months, and now they are coming in :).  I figuerd this out quite a while ago but haven't gotten around to posting the answer.  Here it is.<\/p>\n<p>From the training script, you can get the workspace from the run context as follows:<\/p>\n<pre><code>from azureml.core import Run\nRun.get_context()\nws = run.experiment.workspace\n<\/code><\/pre>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":4.5,
        "Solution_reading_time":4.52,
        "Solution_score_count":0.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":55.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":23.5220988889,
        "Challenge_answer_count":4,
        "Challenge_body":"<p>I get the following error inside the child runs in ML studio while doing an Automated ML experiment.  <\/p>\n<p>&quot;Identity does not have permissions for Microsoft.MachineLearningServices\/workspaces\/metadata\/artifacts\/write actions.&quot;  <\/p>\n<p>I am the owner of the resource group so I am not sure what the issue is.  <\/p>\n<p>Thanks  <\/p>",
        "Challenge_closed_time":1621971310163,
        "Challenge_comment_count":0,
        "Challenge_created_time":1621886630607,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/407580\/permission-error-while-finishing-auto-ml-run",
        "Challenge_link_count":0,
        "Challenge_participation_count":4,
        "Challenge_readability":8.7,
        "Challenge_reading_time":4.91,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":23.5220988889,
        "Challenge_title":"Permission error while finishing auto ml run",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":54,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hello everyone, <a href=\"\/users\/na\/?userid=1321ce4c-8332-49c7-b902-2bcd4256debc\">@Shubham Miglani  <\/a> <a href=\"\/users\/na\/?userid=8886df29-ba7f-42f0-a932-a7883bbe54ea\">@Nick Schafer  <\/a>     <\/p>\n<p>We have identified the issue and a hot fix is rolling out.  It will be fixed in all regions by end of today. Sorry for the experience.     <\/p>\n<p>Regards,    <br \/>\nYutong<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":6.0,
        "Solution_reading_time":4.76,
        "Solution_score_count":0.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":42.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1334762714136,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Boston, MA",
        "Answerer_reputation_count":6557.0,
        "Answerer_view_count":2005.0,
        "Challenge_adjusted_solved_time":7270.5901094445,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Is there no way to connect to a URL from azure ml and get it's content <\/p>\n\n<p><strong>my code:<\/strong><\/p>\n\n<pre><code>import requests\ndef azureml_main(dataframe1 = None, dataframe2 = None):    \n    b= requests.get(\"http:\/\/www.google.com\",timeout=30)\n    dataframe1 = b.content\n    return dataframe1\n<\/code><\/pre>\n\n<p>Is there any change need to be made to connect to URL <\/p>\n\n<p><strong>ERROR:<\/strong><\/p>\n\n<pre><code>Error 0085: The following error occurred during script evaluation, please view the output log for more information:\n ---------- Start of error message from Python interpreter ----------\ndata:text\/plain,Caught exception while executing function: Traceback (most recent call last):\nFile \"C:\\server\\invokepy.py\", line 167, in batch\nodfs = mod.azureml_main(*idfs)\nFile \"C:\\temp\\azuremod.py\", line 24, in azureml_main\nb= requests.get(\"http:\/\/www.google.com\",timeout=30)\nFile \"C:\\pyhome\\lib\\site-packages\\requests\\api.py\", line 55, in get\nreturn request('get', url, **kwargs)\nFile \"C:\\pyhome\\lib\\site-packages\\requests\\api.py\", line 44, in request\nreturn session.request(method=method, url=url, **kwargs)\nFile \"C:\\pyhome\\lib\\site-packages\\requests\\sessions.py\", line 456, in request\nresp = self.send(prep, **send_kwargs)\nFile \"C:\\pyhome\\lib\\site-packages\\requests\\sessions.py\", line 559, in send\nr = adapter.send(request, **kwargs)\nFile \"C:\\pyhome\\lib\\site-packages\\requests\\adapters.py\", line 375, in send\nraise ConnectionError(e, request=request)\nConnectionError: HTTPConnectionPool(host='www.google.com', port=80): Max retries exceeded with url: \/ (Caused by &lt;class 'socket.gaierror'&gt;: [Errno 11001] getaddrinfo failed)\n\n---------- End of error message from Python  interpreter  ---------\n<\/code><\/pre>\n\n<p>Or is there any change needed to be made on the azure ml settings<\/p>",
        "Challenge_closed_time":1427711885336,
        "Challenge_comment_count":0,
        "Challenge_created_time":1427449480153,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1427810420956,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/29297579",
        "Challenge_link_count":2,
        "Challenge_participation_count":1,
        "Challenge_readability":9.7,
        "Challenge_reading_time":24.02,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":18,
        "Challenge_solved_time":72.8903286111,
        "Challenge_title":"Azure ML Execute Python Module: Network I\/O Disabled?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":525.0,
        "Challenge_word_count":189,
        "Platform":"Stack Overflow",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p><em>UPDATE<\/em> 1\/28\/2016<\/p>\n\n<p>Network I\/O for <code>Execute Python Script<\/code> is now supported.<\/p>\n\n<p><em>Out of date<\/em><\/p>\n\n<p>Network I\/O is not support from Execute Python Modules. In order to execute such a program, you should instead launch a virtual machine(Windows or Linux your choice). <\/p>\n\n<p>Windows:<\/p>\n\n<ol>\n<li>RDP into Virtual Machine<\/li>\n<li>Install your choice of Python<\/li>\n<li>You can drag and drop your Python program from your Local Windows machine onto your RDP screen to transfer your code<\/li>\n<li>Then run your program <\/li>\n<\/ol>\n\n<p>Ubuntu:<\/p>\n\n<ol>\n<li>SSH into your virtual machine using Cygwin or Putty(Windows) or Terminal SSH (mac) <code>ssh yourUserName@yourAzureVM.cloudapps.net<\/code><\/li>\n<li>install Python <code>sudo apt-get install python<\/code><\/li>\n<li>open your preferred Linux text editor <code>vi myProgram.py<\/code><\/li>\n<li>Copy and Paste your code into the editor (leave vi with esc <code>:wq<\/code> )<\/li>\n<li>Run your code <code>python myProgram.py<\/code><\/li>\n<\/ol>\n\n<p>To move data from your VM to AzureML please check out the <a href=\"https:\/\/github.com\/Azure\/Azure-MachineLearning-ClientLibrary-Python\" rel=\"nofollow\">Azure-MachineLearning-ClientLibrary-Python<\/a> on Github<\/p>",
        "Solution_comment_count":4.0,
        "Solution_last_edit_time":1453984545350,
        "Solution_link_count":1.0,
        "Solution_readability":11.7,
        "Solution_reading_time":16.1,
        "Solution_score_count":1.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":148.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":11.9707011111,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am a network admin and know very little about Machine Learning<\/p>\n<p>We setup a private ML studio workspace for our user who is assigned the Owner role to the resource group the workspace uses.<\/p>\n<p>First we had issue with creating compute and user had to be assigned some network join permissions at the Vnet, as he could not even get a list of subnets. I could not find any ML role at the Vnet level that needs to be assigned.<\/p>\n<p>After assigning those permissions, user can create compute but not able to click terminal as all the applications are greyed out. That may be because compute is not assigned to me.<\/p>\n<p>I created a test compute myself. and even added a dns entry pointing to compute instance as we have custom dns, terminal still does not open.<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/c03305a2-59dc-4c88-9454-fe171d86a1c5?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>What all permissions that we need to assign user and at what resource so they can use ML studio without our intervention.<\/p>\n<p>Thanks<\/p>",
        "Challenge_closed_time":1677816721020,
        "Challenge_comment_count":0,
        "Challenge_created_time":1677773626496,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1185943\/ml-studio-roles-permissions-issue",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":8.7,
        "Challenge_reading_time":13.68,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":10,
        "Challenge_solved_time":11.9707011111,
        "Challenge_title":"ML studio Roles\/Permissions issue",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":169,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=b845915b-4001-0003-0000-000000000000\">@R.T  <\/a><\/p>\n<p>Thanks for reaching out to us, I understand you are building your compute within your VNET for your team. There are two roles related to VNET you may want to add, could you please take a look and have a try? Please let me know if below roles are still not working and we can discuss the next step.<\/p>\n<p>To deploy your compute resources inside a VNet, you need to explicitly have permissions for the following actions:<\/p>\n<ul>\n<li> <code>Microsoft.Network\/virtualNetworks\/*\/read<\/code> on the VNet resources.<\/li>\n<li> <code>Microsoft.Network\/virtualNetworks\/subnets\/join\/action<\/code> on the subnet resource.   For more information on Azure RBAC with networking, see the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/role-based-access-control\/built-in-roles#networking\">Networking built-in roles<\/a>.<\/li>\n<\/ul>\n<p>Since you ask all relative permissions, I want to share some common Common scenarios for roles\/permissions management like below screenshot-<\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-assign-roles?tabs=labeler#common-scenarios\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-assign-roles?tabs=labeler#common-scenarios<\/a><\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/dbf3883e-5d1b-4294-88b1-f31f79efd7a5?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>And also some examples of custom role for different scenarios like below screenshot- <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-assign-roles?tabs=labeler#example-custom-roles\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-assign-roles?tabs=labeler#example-custom-roles<\/a><\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/fd4691a6-36f5-4eb8-ba40-f58460a1efd4?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>Please let me know if you need further help.<\/p>\n<p>Regards,<\/p>\n<p>Yutong<\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":5.0,
        "Solution_readability":14.9,
        "Solution_reading_time":28.12,
        "Solution_score_count":0.0,
        "Solution_sentence_count":16.0,
        "Solution_word_count":184.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":1.0525094444,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>As a college student with a .edu email address, I have access to Azure services for free. However, I am unaware of how to utilize this platform. For instance, if I want to learn and practice SQL, can I do it? Any guidance on this is appreciated. Thanks!<\/p>",
        "Challenge_closed_time":1681206677624,
        "Challenge_comment_count":0,
        "Challenge_created_time":1681202888590,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1218671\/how-to-utilize-azure",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":4.2,
        "Challenge_reading_time":3.39,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":1.0525094444,
        "Challenge_title":"How to utilize Azure",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":51,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hi <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=293bf6a7-206e-45a1-bbbd-b32bc920f2ea\">Puranjay Wadhera <\/a>\u2022,\nWelcome to Microsoft Q&amp;A forum.\nAs I understand, you want to begin using Azure services related to SQL.\nWe have detailed documention on our official Microsoft Site for Azure SQL database where you could create your first Database and explore different functionalities of it.\nLink: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/azure-sql\/database\/sql-database-paas-overview?view=azuresql\">What is Azure SQL Database?<\/a>\nOn the left panel, you could find Quickstarts, Tutorials, Concepts which covers the service very well.\nAdditionally, we have Azure SQL YouTube channel <a href=\"https:\/\/www.youtube.com\/@AzureSQL\/about\">https:\/\/www.youtube.com\/@AzureSQL\/about<\/a>\nPlease try these and let us know if you need any specific concept details, we would assist you.<\/p>\n<p>If this answers your query, do click <code>Accept Answer<\/code> and <code>Mark Helpful<\/code> for the same. And, if you have any further query do let us know.\nThank you.<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":3.0,
        "Solution_readability":9.0,
        "Solution_reading_time":13.96,
        "Solution_score_count":0.0,
        "Solution_sentence_count":11.0,
        "Solution_word_count":127.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":243.3152777778,
        "Challenge_answer_count":0,
        "Challenge_body":"Only allow access to project members for the given MLflow.",
        "Challenge_closed_time":1620648494000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1619772559000,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/github.com\/konstellation-io\/kdl-server\/issues\/404",
        "Challenge_link_count":0,
        "Challenge_participation_count":0,
        "Challenge_readability":5.2,
        "Challenge_reading_time":1.2,
        "Challenge_repo_contributor_count":16.0,
        "Challenge_repo_fork_count":0.0,
        "Challenge_repo_issue_count":909.0,
        "Challenge_repo_star_count":5.0,
        "Challenge_repo_watch_count":7.0,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":2,
        "Challenge_solved_time":243.3152777778,
        "Challenge_title":"Users can access to any MLflow project",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":16,
        "Platform":"Github",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":-15.7,
        "Solution_reading_time":0.0,
        "Solution_score_count":0.0,
        "Solution_sentence_count":1.0,
        "Solution_word_count":0.0,
        "Tool":"MLflow"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":154.0425902778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I'm trying to create a workspace in azure machine learning and receiving this error after 2 browser Windows open and I click log in.<\/p>\n<blockquote>\n<p>library(azuremlsdk)  <br \/>\nnew_ws &lt;- create_workspace(name = 'muffin',<\/p>\n<\/blockquote>\n<ul>\n<li>   subscription_id = 'XXXXXXXXXXXX',<\/li>\n<li>   resource_group = 'white',<\/li>\n<li>   location = 'eastus2',<\/li>\n<li>   create_resource_group = T)  <br \/>\n    Note, we have launched a browser for you to login. For old experience with device code, use &quot;az login --use-device-code&quot;  <br \/>\n    You have logged in. Now let us find all the subscriptions to which you have access...  <br \/>\n    Note, we have launched a browser for you to login. For old experience with device code, use &quot;az login --use-device-code&quot;  <br \/>\n    You have logged in. Now let us find all the subscriptions to which you have access...  <br \/>\n    Error in py_call_impl(callable, dots$args, dots$keywords) :  <br \/>\n    AuthenticationException: AuthenticationException:  <br \/>\n    Message: Could not retrieve user token. Please run 'az login'  <br \/>\n    InnerException It is required that you pass in a value for the &quot;algorithms&quot; argument when calling decode().  <br \/>\n    ErrorResponse  <br \/>\n    {  <br \/>\n    &quot;error&quot;: {  <br \/>\n    &quot;code&quot;: &quot;UserError&quot;,  <br \/>\n    &quot;inner_error&quot;: {  <br \/>\n    &quot;code&quot;: &quot;Authentication&quot;  <br \/>\n    },  <br \/>\n    &quot;message&quot;: &quot;Could not retrieve user token. Please run 'az login'&quot;  <br \/>\n    }  <br \/>\n    }<\/li>\n<\/ul>\n<p>how do I get passed this error?<\/p>",
        "Challenge_closed_time":1621844855832,
        "Challenge_comment_count":3,
        "Challenge_created_time":1621290302507,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/398420\/azuremlsdk-for-r-error-could-not-retrieve-user-tok",
        "Challenge_link_count":0,
        "Challenge_participation_count":4,
        "Challenge_readability":9.5,
        "Challenge_reading_time":20.26,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":13,
        "Challenge_solved_time":154.0425902778,
        "Challenge_title":"azuremlsdk for R error Could not retrieve user token. Please run 'az login'",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":207,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>You have to use this command to make it install the correct version of miniconda reticulate::py_install(&quot;PyJWT==1.7.1&quot;). If you don't do that it seems to install the wrong version. I also had to manually delete the r-miniconda folder in \\appdata\\local\\r-miniconda which got installed previously to get it to install the correct version. It's pretty outrageous they leave that out of the tutorial when it ain't going to work otherwise.<\/p>\n<p>If you try to do the accident.R tutorial for azuremlsdk-r next make sure you add the line<\/p>\n<p>interactive_auth &lt;- interactive_login_authentication(tenant_id=&quot;&lt;tenant id&gt;&quot;)<\/p>\n<p>to your code otherwise you'll get a permissions error and it won't work.<\/p>\n<p>Then to the create_workspace or get_workspace function you have to add auth = interactive_auth after a comma.<\/p>\n<p>It should look like this<\/p>\n<p>new_ws &lt;- get_workspace(name = &quot;&lt;workspace name&gt;&quot;,  <br \/>\nsubscription_id = &quot;&lt;subscription id&gt;&quot;,  <br \/>\nresource_group = &quot;&lt;resource name&gt;&quot;,  <br \/>\nauth = interactive_auth)<\/p>\n<p>To find the tenant ID I had to download the azure CLI and run the command az login. Not sure if there is another way to find a tenant ID or not.<\/p>\n<p>To leave out critical steps from a tutorial is gross incompetence on the part of Azure. How anyone who isn't a comp sci phd uses this service is a mystery to me.<\/p>\n",
        "Solution_comment_count":2.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":10.5,
        "Solution_reading_time":17.95,
        "Solution_score_count":0.0,
        "Solution_sentence_count":11.0,
        "Solution_word_count":203.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1614711784088,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":26.0,
        "Answerer_view_count":0.0,
        "Challenge_adjusted_solved_time":1978.3835261111,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am following this <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/edge-device-fleet-create.html#edge-device-fleet-create-console\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/edge-device-fleet-create.html#edge-device-fleet-create-console<\/a> docs to create device fleet. In this console, Role ARN is optional but it throws <code>RoleARN is required<\/code>. If I provide proper RoleArn it throws <code>Failed to create\/modify RoleAlias. Check your IAM role permission<\/code>.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/84UEW.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/84UEW.jpg\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/wKuTV.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/wKuTV.jpg\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>I have no idea what is going wrong. Any hint would be appreciable.<\/p>",
        "Challenge_closed_time":1614723172687,
        "Challenge_comment_count":0,
        "Challenge_created_time":1607600991993,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/65233943",
        "Challenge_link_count":6,
        "Challenge_participation_count":1,
        "Challenge_readability":13.9,
        "Challenge_reading_time":12.97,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":13,
        "Challenge_solved_time":1978.3835261111,
        "Challenge_title":"Unable to create Device Fleet",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":48.0,
        "Challenge_word_count":79,
        "Platform":"Stack Overflow",
        "Poster_created_time":1426675778223,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Coimbatore, Tamil Nadu, India",
        "Poster_reputation_count":10189.0,
        "Poster_view_count":1471.0,
        "Solution_body":"<p>Mohamed, this means that Sagemaker Edge Manager was unable to use the RoleAlias you provided to take the necessary actions when creating a DeviceFleet. It needs to have the AmazonSageMakerEdgeDeviceFleetPolicy attached (or have similar permissions granted) and it needs to trust both SageMaker and IoT Core.<\/p>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":13.4,
        "Solution_reading_time":3.95,
        "Solution_score_count":1.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":46.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1499171495843,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Bhubaneswar, Odisha, India",
        "Answerer_reputation_count":521.0,
        "Answerer_view_count":77.0,
        "Challenge_adjusted_solved_time":0.7756461111,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>For example, I have A, B acounts.<\/p>\n<p>First, I log in Google Colab with A account.\nand I want to log in wandb with B acounts. ( using !wandb login )\nis it possible??<\/p>",
        "Challenge_closed_time":1644559750243,
        "Challenge_comment_count":0,
        "Challenge_created_time":1644556957917,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/71075704",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":4.1,
        "Challenge_reading_time":2.73,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":0.7756461111,
        "Challenge_title":"how to login wandb with another acount using colab?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":316.0,
        "Challenge_word_count":40,
        "Platform":"Stack Overflow",
        "Poster_created_time":1644556763936,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":3.0,
        "Poster_view_count":0.0,
        "Solution_body":"<p>You can you the following commands to force a relogin:<\/p>\n<ul>\n<li>from terminal<\/li>\n<\/ul>\n<pre><code>wandb login --relogin\n<\/code><\/pre>\n<ul>\n<li>Using the API:<\/li>\n<\/ul>\n<pre><code>import wandb\nwandb.login(relogin=True)\n<\/code><\/pre>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":16.2,
        "Solution_reading_time":3.16,
        "Solution_score_count":2.0,
        "Solution_sentence_count":1.0,
        "Solution_word_count":27.0,
        "Tool":"Weights & Biases"
    }
]