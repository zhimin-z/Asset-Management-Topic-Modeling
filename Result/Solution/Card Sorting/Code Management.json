[
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":null,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am looking for sample of notebook\/SDK, but this link is not working at all. Any new repo for reference? <a href=\"https:\/\/learn.microsoft.com\/en-us\/samples\/azure\/azureml-examples\/azure-machine-learning-examples\/\">https:\/\/learn.microsoft.com\/en-us\/samples\/azure\/azureml-examples\/azure-machine-learning-examples\/<\/a><\/p>",
        "Challenge_closed_time":1.0,
        "Challenge_comment_count":0,
        "Challenge_created_time":1669742901290,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1109020\/azure-machine-learning-samples-404",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":18.5,
        "Challenge_reading_time":4.88,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":null,
        "Challenge_title":"Azure machine learning samples 404",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":null,
        "Challenge_word_count":26,
        "Issue_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=79877fab-184b-4267-bfdd-49ea0b34bfe1\">@Yadama Kenzan  <\/a>     <\/p>\n<p>Thanks for reporting this issue, is there any place you got the link or it's from the web search? This link has been deprecated.    <\/p>\n<p>Please see this repo for SDK V2 samples\/ CLI V2 samples - <a href=\"https:\/\/github.com\/Azure\/azureml-examples\">https:\/\/github.com\/Azure\/azureml-examples<\/a>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/265362-image.png?platform=QnA\" alt=\"265362-image.png\" \/>    <\/p>\n<p>Please let me know where this link is from so that I can fix the resource as well.     <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.    <\/p>\n",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":9.4,
        "Solution_reading_time":9.71,
        "Solution_score_count":0.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":89.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1427953176670,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":145.0,
        "Answerer_view_count":13.0,
        "Challenge_adjusted_solved_time":null,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I'm having problems pushing files with DVC to DAGsHub.<\/p>\n<p>Workflow:<\/p>\n<ul>\n<li>I used my email to signup to DAGsHub.<\/li>\n<li>I created a repo and clone it to my computer.<\/li>\n<li>I added files to the repo and track them using DVC and Git to track the pointer files.<\/li>\n<li>Running DVC push -r origin, it asks me for my password. When I enter the password and hit enter - nothing happens.<\/li>\n<\/ul>\n<p>It sits and waits, barring me from even canceling the operation with Ctrl+C.\nI'm forced to manually close the terminal, open a new one, ending the &quot;Python&quot; process in task manager and delete the lock file in .dvc\/tmp\/lock.<\/p>",
        "Challenge_closed_time":1.0,
        "Challenge_comment_count":2,
        "Challenge_created_time":1620537862843,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1620625906412,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/67454531",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":6.0,
        "Challenge_reading_time":8.8,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":5.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":null,
        "Challenge_title":"Git bash command prompt hanging when running dvc push to DAGsHub",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":254.0,
        "Challenge_word_count":117,
        "Issue_self_closed":null,
        "Platform":"Stack Overflow",
        "Poster_created_time":1620537484800,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":53.0,
        "Poster_view_count":2.0,
        "Solution_body":"<p><strong>Short answer<\/strong><\/p>\n<p>Do not use <code>ask_password<\/code>.\nInstead, save your token in the local config by running once:<\/p>\n<pre><code>dvc remote modify origin --local --unset ask_password\ndvc remote modify origin --local password &lt;--access token--&gt;\n<\/code><\/pre>\n<p><code>dvc push -r origin<\/code> should work then.<\/p>\n<p><strong>Long answer<\/strong><\/p>\n<p><a href=\"https:\/\/www.atlassian.com\/git\/tutorials\/git-bash#:%7E:text=What%20is%20Git%20Bash%3F,operating%20system%20through%20written%20commands.\" rel=\"nofollow noreferrer\">Git Bash<\/a> is not running the regular Windows command prompt but an emulated Unix-style bash prompt. From the information in your question, I cannot know for sure, but this is probably causing the <code>msvcrt<\/code> package used by DVC to prompt the password on windows machines to fail\/hang.<\/p>\n<p>There are potentially 3 ways to deal with the issue:<\/p>\n<ol>\n<li>Run <code>dvc pull<\/code> from the regular Windows cmd prompt.<\/li>\n<li>Find a way to make Git Bash wrap Python calls with <code>winpty<\/code> - I am not 100% positive about how to do this, but not using <code>winpty<\/code> seems to be the reason <code>msvcrt<\/code> fails at prompting for your password.<\/li>\n<li>The simplest solution - Do not use <code>ask_password<\/code>.\nInstead, save your token in the local config by running once:\n<pre><code>dvc remote modify origin --local --unset ask_password\ndvc remote modify origin --local password &lt;--access token--&gt;\n<\/code><\/pre>\nYou can get your access token by clicking on the question mark beside the DVC\nremote of your DAGsHub repository, then click on &quot;Reveal my token&quot;.<\/li>\n<\/ol>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":13.6,
        "Solution_reading_time":21.52,
        "Solution_score_count":4.0,
        "Solution_sentence_count":9.0,
        "Solution_word_count":211.0,
        "Tool":"DVC"
    },
    {
        "Answerer_created_time":1250347954880,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"San Francisco, CA, USA",
        "Answerer_reputation_count":5575.0,
        "Answerer_view_count":358.0,
        "Challenge_adjusted_solved_time":null,
        "Challenge_answer_count":1,
        "Challenge_body":"<p><strong>Background<\/strong>: In my projects I'm using GIT and <a href=\"https:\/\/dvc.org\/\" rel=\"nofollow noreferrer\">DVC<\/a> to keep track of versions:<\/p>\n<ul>\n<li>GIT - only for source codes<\/li>\n<li>DVC - for dataset, model objects and outputs<\/li>\n<\/ul>\n<p>I'm testing different approaches in separate branches, i.e:<\/p>\n<ul>\n<li>random_forest<\/li>\n<li>neural_network_1<\/li>\n<li>...<\/li>\n<\/ul>\n<p>Typically as an output I'm keeping predictions in csv file with standarised name (i.e.: pred_test.csv). As a consequence in different branches I've different pred_test.csv files. The structure of the file is very simple, it contains two columns:<\/p>\n<ul>\n<li>ID<\/li>\n<li>Prediction<\/li>\n<\/ul>\n<p><strong>Question<\/strong>: What is the best way to merge those prediction files into single big file?<\/p>\n<p>I would like to obtain a file with structure:<\/p>\n<ul>\n<li>ID<\/li>\n<li>Prediction_random_forest<\/li>\n<li>Prediction_neural_network_1<\/li>\n<li>Prediction_...<\/li>\n<\/ul>\n<p>My main issue is how to access files with predictions which are in different branches?<\/p>",
        "Challenge_closed_time":1.0,
        "Challenge_comment_count":5,
        "Challenge_created_time":1645092064283,
        "Challenge_favorite_count":1.0,
        "Challenge_last_edit_time":1645132430276,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/71155959",
        "Challenge_link_count":1,
        "Challenge_participation_count":6,
        "Challenge_readability":9.4,
        "Challenge_reading_time":14.6,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":null,
        "Challenge_title":"How to merge data (CSV) files from multiple branches (Git and DVC)?",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":274.0,
        "Challenge_word_count":141,
        "Issue_self_closed":null,
        "Platform":"Stack Overflow",
        "Poster_created_time":1265742671200,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":2735.0,
        "Poster_view_count":552.0,
        "Solution_body":"<p>I would try to use <a href=\"https:\/\/dvc.org\/doc\/command-reference\/get\" rel=\"nofollow noreferrer\"><code>dvc get<\/code><\/a> in this case:<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>dvc get -o random_forest_pred.csv --rev random_forest . pred_test.csv\n<\/code><\/pre>\n<p>It should bring the <code>pred_test.csv<\/code> from the <code>random_forest<\/code> branch.<\/p>\n<blockquote>\n<p>Mind the <code>.<\/code> before the <code>pred_test.csv<\/code> please, it's needed and it means that &quot;use the current repo&quot;, since <code>dvc get<\/code> could also be used on other repos (e.g. GitHub URL)<\/p>\n<\/blockquote>\n<p>Then I think you could use some CLI or write a script to join the files:<\/p>\n<p><a href=\"https:\/\/unix.stackexchange.com\/questions\/293775\/merging-contents-of-multiple-csv-files-into-single-csv-file\">https:\/\/unix.stackexchange.com\/questions\/293775\/merging-contents-of-multiple-csv-files-into-single-csv-file<\/a><\/p>",
        "Solution_comment_count":2.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":12.7,
        "Solution_reading_time":12.55,
        "Solution_score_count":2.0,
        "Solution_sentence_count":9.0,
        "Solution_word_count":82.0,
        "Tool":"DVC"
    },
    {
        "Answerer_created_time":1614873430827,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":169.0,
        "Answerer_view_count":7.0,
        "Challenge_adjusted_solved_time":null,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I'm in a team using dvc with git to version-control data files. We are using dvc 1.3.1, with the an S3 bucket remote. I'm getting this error when executing <code>dvc fetch<\/code> or <code>dvc pull<\/code> on a colleague's branch:<\/p>\n<pre><code>ERROR: failed to fetch data from the cloud - DVC-file 'C:\\Users\\blah\\Documents\\repo\\data\\processed_data.dvc' format error: extra keys not allowed @ data['outs'][0]['size']\n<\/code><\/pre>\n<p>When I check the dvc file for a cached file with which I have no problem I see this:<\/p>\n<pre><code>md5: ded591aacbe363f0518ceb9c3bc1836b\nouts:\n- md5: efdab20e8b59903b9523cc188ff727e5\n  path: completion_header.p\n  cache: true\n  metric: false\n  persist: false\n<\/code><\/pre>\n<p>but a problematic file only has this:<\/p>\n<pre><code>outs:\n- md5: f4e15187d9a0bbb328e629eabd8d1784.dir\n  size: 112007\n  nfiles: 3\n  path: processed_data\n<\/code><\/pre>\n<p>In all cases, files are added to dvc with the command <code>dvc add %dirname%<\/code>. This is the second time I've seen this on a colleague's branch (2 different people).<\/p>\n<p>Since posting, I have realized that my colleague dvc'd a directory. I have attempted creating the directory first, then calling <code>dvc fetch<\/code>, but get the same error.<\/p>",
        "Challenge_closed_time":1.0,
        "Challenge_comment_count":0,
        "Challenge_created_time":1618565400113,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1618826341416,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/67122683",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":9.1,
        "Challenge_reading_time":15.85,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":2.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":11,
        "Challenge_solved_time":null,
        "Challenge_title":"DVC Files Incomplete",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":548.0,
        "Challenge_word_count":164,
        "Issue_self_closed":null,
        "Platform":"Stack Overflow",
        "Poster_created_time":1348150034832,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Glasgow, UK",
        "Poster_reputation_count":2400.0,
        "Poster_view_count":263.0,
        "Solution_body":"<blockquote>\n<p>In all cases, files are added to dvc with the command dvc add %filename%.<\/p>\n<\/blockquote>\n<p>It seems like there is a high chance that one of the dvc files created in newer versions of dvc and you are trying to operate with an older version. Are all of your colleagues use the same dvc version when adding new files?<\/p>",
        "Solution_comment_count":4.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":7.6,
        "Solution_reading_time":4.1,
        "Solution_score_count":2.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":60.0,
        "Tool":"DVC"
    },
    {
        "Answerer_created_time":1541523185320,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Ottawa, ON, Canada",
        "Answerer_reputation_count":1003.0,
        "Answerer_view_count":56.0,
        "Challenge_adjusted_solved_time":null,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>What is the difference between these two? We used git-lfs in my previous job and we are starting to use dvc alongside git in my current one. They both place some kind of index instead of file and can be downloaded on demand. Has dvc some improvements over the former one?<\/p>",
        "Challenge_closed_time":1.0,
        "Challenge_comment_count":0,
        "Challenge_created_time":1571919586097,
        "Challenge_favorite_count":5.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/58541260",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":5.2,
        "Challenge_reading_time":3.8,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":27.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":null,
        "Challenge_title":"Difference between git-lfs and dvc",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":6255.0,
        "Challenge_word_count":55,
        "Issue_self_closed":null,
        "Platform":"Stack Overflow",
        "Poster_created_time":1373630643248,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":382.0,
        "Poster_view_count":11.0,
        "Solution_body":"<p>DVC is a better replacement for <code>git-lfs<\/code>. <\/p>\n\n<p>Unlike git-lfs, DVC doesn't require installing a dedicated server; It can be used on-premises (NAS, SSH, for example) or with any major cloud provider (S3, Google Cloud, Azure).<\/p>\n\n<p>For more information: <a href=\"https:\/\/dvc.org\/doc\/use-cases\/data-and-model-files-versioning\" rel=\"noreferrer\">https:\/\/dvc.org\/doc\/use-cases\/data-and-model-files-versioning<\/a><\/p>",
        "Solution_comment_count":5.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":14.7,
        "Solution_reading_time":5.71,
        "Solution_score_count":10.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":42.0,
        "Tool":"DVC"
    },
    {
        "Answerer_created_time":1305851487736,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":5993.0,
        "Answerer_view_count":457.0,
        "Challenge_adjusted_solved_time":68.3225869444,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>My team has a set up wherein we track datasets and models in DVC, and have a GitLab repository for tracking our code and DVC metadata files. We have a job in our dev GitLab pipeline (run on each push to a merge request) that has the goal of checking to be sure that the developer remembered to run <code>dvc push<\/code> to keep DVC remote storage up-to-date. Right now, the way we do this is by running <code>dvc pull<\/code> on the GitLab runner, which will fail with errors telling you which files (new files or latest versions of existing files) were not found.<\/p>\n<p>The downside to this approach is that we are loading the entirety of our data stored in DVC onto a GitLab runner, and we've run into out-of-memory issues, not to mention lengthy run time to download all that data. Since the path and md5 hash of the objects are stored in the DVC metadata files, I would think that's all the information that DVC would need to be able to answer the question &quot;is the remote storage system up-to-date&quot;.<\/p>\n<p>It seems like <code>dvc status<\/code> is similar to what I'm asking for, but compares the cache or workspace and remote storage. In other words, it requires the files to actually be present on whatever filesystem is making the call.<\/p>\n<p>Is there some way to achieve the goal I laid out above (&quot;inform the developer that they need to run <code>dvc push<\/code>&quot;) without pulling everything from DVC?<\/p>",
        "Challenge_closed_time":1.0,
        "Challenge_comment_count":0,
        "Challenge_created_time":1622232629793,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1622257491983,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/67744934",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":12.7,
        "Challenge_reading_time":19.1,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":5.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":null,
        "Challenge_title":"Is it possible to check that the version of a file tracked by a DVC metadata file exists in remote storage without pulling the file?",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":488.0,
        "Challenge_word_count":272,
        "Issue_self_closed":null,
        "Platform":"Stack Overflow",
        "Poster_created_time":1618255062696,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":75.0,
        "Poster_view_count":2.0,
        "Solution_body":"<blockquote>\n<p>It seems like dvc status is similar to what I'm asking for<\/p>\n<\/blockquote>\n<p><code>dvc status --cloud<\/code> will give you a list of &quot;new&quot; files if they that haven't been pushed to the (default) remote. It won't error out though, so your CI script should fail depending on the stdout message.<\/p>\n<p>More info: <a href=\"https:\/\/dvc.org\/doc\/command-reference\/status#options\" rel=\"nofollow noreferrer\">https:\/\/dvc.org\/doc\/command-reference\/status#options<\/a><\/p>\n<p>I'd also ask everyone to run <code>dvc install<\/code>, which will setup some Git hooks, including automatic <code>dvc push<\/code> with <code>git push<\/code>.<\/p>\n<p>See <a href=\"https:\/\/dvc.org\/doc\/command-reference\/install\" rel=\"nofollow noreferrer\">https:\/\/dvc.org\/doc\/command-reference\/install<\/a><\/p>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":1622503453296,
        "Solution_link_count":4.0,
        "Solution_readability":13.8,
        "Solution_reading_time":10.5,
        "Solution_score_count":3.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":83.0,
        "Tool":"DVC"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":null,
        "Challenge_answer_count":0,
        "Challenge_body":"From slack\n\nMy job is stack with a warning status, I configured a private bitbucket connection and the cloning fails.",
        "Challenge_closed_time":1.0,
        "Challenge_comment_count":0,
        "Challenge_created_time":1649328334000,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1472",
        "Challenge_link_count":0,
        "Challenge_participation_count":0,
        "Challenge_readability":7.2,
        "Challenge_reading_time":1.85,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":2,
        "Challenge_solved_time":null,
        "Challenge_title":"How to debug my init git container",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":null,
        "Challenge_word_count":26,
        "Issue_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"Before updating the connections or changing anything about your current deployment, please perform the following debugging steps:\n\nEnable logs from all containers:\n\n\n\nYou can also inspect the operations from the statuses page to get more information (for distributed runs you can select the correct pod)\n\n\nYou can suspend the init container using :\n\n  - connection: my-connection\n    git: {...}\n    container:\n      command: [\"\/bin\/bash\", \"-c\"]\n      args: [\"sleep 3600\"]\nUse shell to get inside the container (for distributed runs you can select the correct pod and container):",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":20.1,
        "Solution_reading_time":6.86,
        "Solution_score_count":1.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":80.0,
        "Tool":"Polyaxon"
    },
    {
        "Answerer_created_time":1250347954880,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"San Francisco, CA, USA",
        "Answerer_reputation_count":5575.0,
        "Answerer_view_count":358.0,
        "Challenge_adjusted_solved_time":6.6123980556,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I work on a project with DVC (Data version control). Let's say I make a lot of local commits. Something like this:<\/p>\n\n<pre><code># make changes for experiment 1\ndvc add my_data_file\ngit add my_data_file.dvc\ngit commit -m \"Experiment 1\"\n\n# make changes for experiment 2\n# which change both code and data\ndvc add my_data_file\ngit add my_data_file.dvc\ngit commit -m \"Experiment 2\"\n\n# make changes for experiment 3\n# which change both code and data\ndvc add my_data_file\ngit add my_data_file.dvc\ngit commit -m \"Experiment 3\"\n\n# Finally I'm done\n# push changes:\ndvc push\ngit push\n<\/code><\/pre>\n\n<p>However there is one problem: <code>dvc push<\/code> will only push data from experiment 3. Is there any way to push data from all local commits (i.e. starting from the first commit diverged from remote branch)?<\/p>\n\n<p>Currently I see two options:<\/p>\n\n<ol>\n<li>Tag each commit and push it with <code>dvc push -T<\/code><\/li>\n<li>After \"expermient 3\" commit execute <code>git checkout commit-hash &amp;&amp; dvc push<\/code> for all local commits not yet pushed to remote.<\/li>\n<\/ol>\n\n<p>Both these options seem cumbersome and error-prone. Is there any better way to do it?<\/p>",
        "Challenge_closed_time":1.0,
        "Challenge_comment_count":0,
        "Challenge_created_time":1561823734517,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/56818930",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":8.1,
        "Challenge_reading_time":14.88,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":2.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":12,
        "Challenge_solved_time":null,
        "Challenge_title":"\"dvc push\" after several local commits",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":916.0,
        "Challenge_word_count":185,
        "Issue_self_closed":null,
        "Platform":"Stack Overflow",
        "Poster_created_time":1522254698710,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Russia",
        "Poster_reputation_count":784.0,
        "Poster_view_count":77.0,
        "Solution_body":"<p>@NShiny, there is a related ticket:<\/p>\n\n<p><a href=\"https:\/\/github.com\/iterative\/dvc\/issues\/1691\" rel=\"nofollow noreferrer\">support push\/pull\/metrics\/gc, etc across different commits<\/a>.<\/p>\n\n<p>Please, give it a vote so that we know how to prioritize it.<\/p>\n\n<p>As a workaround, I would recommend to run <a href=\"https:\/\/dvc.org\/doc\/commands-reference\/install\" rel=\"nofollow noreferrer\"><code>dvc install<\/code><\/a>. It installs a <code>pre-push<\/code> GIt hook and runs <code>dvc push<\/code> automatically:<\/p>\n\n<pre><code>Git pre-push hook executes dvc push before git push to upload files and directories under DVC control to remote.\n<\/code><\/pre>\n\n<p>It means, though you need to run <code>git push<\/code> after every <code>git commit<\/code> :(<\/p>",
        "Solution_comment_count":2.0,
        "Solution_last_edit_time":1561847539150,
        "Solution_link_count":2.0,
        "Solution_readability":12.8,
        "Solution_reading_time":9.83,
        "Solution_score_count":2.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":86.0,
        "Tool":"DVC"
    },
    {
        "Answerer_created_time":1221810788500,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Paderborn, North-Rhine-Westphalia, Germany",
        "Answerer_reputation_count":68522.0,
        "Answerer_view_count":7896.0,
        "Challenge_adjusted_solved_time":22.2570675,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am using mlflow run with a GitHub uri.<\/p>\n<p>When I run using the below command<\/p>\n<pre><code>mlflow run &lt;git-uri&gt;\n<\/code><\/pre>\n<p>The command sets up a conda environment and then <em>clones the Git repo into a <strong>temp<\/strong> directory, But I need it setup in a <strong>specific<\/strong> directory<\/em><\/p>\n<p>I checked the entire document, but I can't find it. Is there no such option to do so in one shot?<\/p>",
        "Challenge_closed_time":1.0,
        "Challenge_comment_count":0,
        "Challenge_created_time":1623534343453,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/67953241",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":9.2,
        "Challenge_reading_time":5.98,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":null,
        "Challenge_title":"mlflow run git-uri clone to specific directory",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":239.0,
        "Challenge_word_count":73,
        "Issue_self_closed":null,
        "Platform":"Stack Overflow",
        "Poster_created_time":1575348765723,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Chennai, Tamil Nadu, India",
        "Poster_reputation_count":1049.0,
        "Poster_view_count":192.0,
        "Solution_body":"<p>For non-local URIs, MLflow uses the Python's <code>tempfile.mkdtemp<\/code> function (<a href=\"https:\/\/github.com\/mlflow\/mlflow\/blob\/1c43176cefb5531fbb243975b9c8c5bfb9775e66\/mlflow\/projects\/utils.py#L140\" rel=\"nofollow noreferrer\">source code<\/a>), that creates the temporary directory.  You may have some control over it by setting the <code>TMPDIR<\/code> environment variable as described in <a href=\"https:\/\/docs.python.org\/3\/library\/tempfile.html#tempfile.mkstemp\" rel=\"nofollow noreferrer\">Python docs<\/a> (it lists <code>TMP<\/code> &amp; <code>TEMP<\/code> as well, but they didn't work for me on MacOS) - but it will set only &quot;base path&quot; for temporary directories and files, the directory\/file names are still will be random.<\/p>",
        "Solution_comment_count":3.0,
        "Solution_last_edit_time":1623614468896,
        "Solution_link_count":2.0,
        "Solution_readability":13.9,
        "Solution_reading_time":9.86,
        "Solution_score_count":1.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":75.0,
        "Tool":"MLflow"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":null,
        "Challenge_answer_count":0,
        "Challenge_body":"In every run you can see:\r\n```\r\n               2020-07-03 23:24:19,549 DEBUG: Trying to spawn '['\/home\/efiop\/git\/dvc-bench\/envs\/76391772e92136ec87b9940d70226329\/bin\/python', '\r\n\/home\/efiop\/.pyenv\/versions\/3.8.3\/envs\/dvc-3.8.3\/lib\/python3.8\/site-packages\/asv\/benchmark.py', 'daemon', '-q', 'updater']'\r\n               2020-07-03 23:24:19,550 DEBUG: Spawned '['\/home\/efiop\/git\/dvc-bench\/envs\/76391772e92136ec87b9940d70226329\/bin\/python', '\/home\/ef\r\niop\/.pyenv\/versions\/3.8.3\/envs\/dvc-3.8.3\/lib\/python3.8\/site-packages\/asv\/benchmark.py', 'daemon', '-q', 'updater']'\r\n               Unknown mode daemon\r\n```\r\nwe clearly need to take more care on dvc-side, but a good enough workaround is to set CI or DVC_TEST env var to make dvc skip launching the updater.",
        "Challenge_closed_time":1594041.0,
        "Challenge_comment_count":0,
        "Challenge_created_time":1593808834000,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/github.com\/iterative\/dvc-bench\/issues\/149",
        "Challenge_link_count":0,
        "Challenge_participation_count":0,
        "Challenge_readability":10.9,
        "Challenge_reading_time":9.95,
        "Challenge_repo_contributor_count":10.0,
        "Challenge_repo_fork_count":9.0,
        "Challenge_repo_issue_count":400.0,
        "Challenge_repo_star_count":19.0,
        "Challenge_repo_watch_count":17.0,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":null,
        "Challenge_title":"dvc tries to launch updater using asv script",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":null,
        "Challenge_word_count":66,
        "Issue_self_closed":0.0,
        "Platform":"Github",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":-15.7,
        "Solution_reading_time":0.0,
        "Solution_score_count":null,
        "Solution_sentence_count":1.0,
        "Solution_word_count":0.0,
        "Tool":"DVC"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":null,
        "Challenge_answer_count":0,
        "Challenge_body":"**Describe the bug**\r\n\r\nAt model train completion, the test set loss is written as iteration 0 to the TensorBoard \/ W&B chart `validation\/lm_loss`, and the test set perplexity is written as iteration 0 to the chart `validation\/lm_loss_ppl`. As the validation loss and perplexity has already been written to this chart, this results in TensorBoard deleting all the validation metrics, overwriting them with the test loss and perplexity values. W&B refuses to add the test metrics to the charts at all, throwing a warning that looks like `wandb: WARNING Step must only increase in log calls.  Step 0 < 32000; dropping {'validation\/lm_loss': 1.715476632118225}.`\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Pip install and setup TensorBoard and W&B\r\n2. Begin training a model with a train, validation, and test set\r\n3. Observe in both TensorBoard and W&B that validation metrics are being logged\r\n4. Allow the model to train to completion\r\n5. Observe that the TensorBoard validation metrics are now gone, overwritten by the test set metrics\r\n6. Observe the W&B error in the text logs \/ program output\r\n\r\n**Expected behavior**\r\nTest metrics should be written to their own charts.\r\n\r\n**Proposed solution**\r\nTest loss and perplexity should be written to their own charts `test\/lm_loss` and `test\/lm_loss_ppl` respectively.\r\n\r\n**Screenshots**\r\n![image](https:\/\/user-images.githubusercontent.com\/6119143\/189752970-3b26dd14-475f-48cb-be84-fae23a99ba10.png)\r\n\r\n**Environment (please complete the following information):**\r\n - GPUs: 4x A100 80 GB\r\n- Configs: (configs that I used to reproduce the bug and test bug fixes are included below)\r\n\r\n```\r\n# GPT-2 pretraining setup\r\n{\r\n   # parallelism settings ( you will want to change these based on your cluster setup, ideally scheduling pipeline stages\r\n   # across the node boundaries )\r\n   \"pipe-parallel-size\": 1,\r\n   \"model-parallel-size\": 1,\r\n\r\n   # model settings\r\n   \"num-layers\": 24,\r\n   \"hidden-size\": 1024,\r\n   \"num-attention-heads\": 16,\r\n   \"seq-length\": 4096,\r\n   \"max-position-embeddings\": 4096,\r\n   \"norm\": \"layernorm\",\r\n   \"pos-emb\": \"rotary\",\r\n   \"no-weight-tying\": true,\r\n\r\n   # these should provide some speedup but takes a while to build, set to true if desired\r\n   \"scaled-upper-triang-masked-softmax-fusion\": false,\r\n   \"bias-gelu-fusion\": false,\r\n\r\n\r\n\r\n   # optimizer settings\r\n   \"optimizer\": {\r\n     \"type\": \"Adam\",\r\n     \"params\": {\r\n       \"lr\": 0.00003,\r\n       \"betas\": [0.9, 0.999],\r\n       \"eps\": 1.0e-8,\r\n     }\r\n   },\r\n   \"zero_optimization\": {\r\n    \"stage\": 1,\r\n    \"allgather_partitions\": True,\r\n    \"allgather_bucket_size\": 500000000,\r\n    \"overlap_comm\": True,\r\n    \"reduce_scatter\": True,\r\n    \"reduce_bucket_size\": 500000000,\r\n    \"contiguous_gradients\": True,\r\n    \"cpu_offload\": False\r\n  },\r\n   # batch \/ data settings\r\n   \"train_micro_batch_size_per_gpu\": 16,\r\n   \"data-impl\": \"mmap\",\r\n   \"split\": \"949,50,1\",\r\n\r\n   # activation checkpointing\r\n   \"checkpoint-activations\": true,\r\n   \"checkpoint-num-layers\": 1,\r\n   \"partition-activations\": true,\r\n   \"synchronize-each-layer\": true,\r\n\r\n   # regularization\r\n   \"gradient_clipping\": 1.0,\r\n   \"weight-decay\": 0.01,\r\n   \"hidden-dropout\": 0,\r\n   \"attention-dropout\": 0,\r\n\r\n   # precision settings\r\n   \"fp16\": {\r\n     \"fp16\": true,\r\n     \"enabled\": true,\r\n     \"loss_scale\": 0,\r\n     \"loss_scale_window\": 1000,\r\n     \"hysteresis\": 2,\r\n     \"min_loss_scale\": 1\r\n   },\r\n\r\n   # misc. training settings\r\n   \"train-iters\": 100,\r\n   \"lr-decay-iters\": 100,\r\n   \"distributed-backend\": \"nccl\",\r\n   \"lr-decay-style\": \"constant\",\r\n   \"warmup\": 0.1,\r\n   \"save-interval\": 25,\r\n   \"eval-interval\": 25,\r\n   \"eval-iters\": 10,\r\n\r\n   # Checkpoint\r\n   \"finetune\": true,\r\n\r\n   # logging\r\n   \"log-interval\": 10,\r\n   \"steps_per_print\": 10,\r\n   \"keep-last-n-checkpoints\": 4,\r\n   \"wall_clock_breakdown\": true,\r\n}\r\n```\r\n\r\n```\r\n# Suggested data paths when using GPT-NeoX locally\r\n{\r\n  \"train-data-paths\": [\"\/mnt\/4TBNVME\/gpt-neox\/data\/preprocessed\/train_text_document\"],\r\n  \"test-data-paths\": [\"\/mnt\/4TBNVME\/gpt-neox\/data\/preprocessed\/test_text_document\"],\r\n  \"valid-data-paths\": [\"\/mnt\/4TBNVME\/gpt-neox\/data\/preprocessed\/val_text_document\"],\r\n\r\n  \"vocab-file\": \"\/mnt\/4TBNVME\/gpt-neox\/data\/gpt2-vocab.json\",\r\n  \"merge-file\": \"\/mnt\/4TBNVME\/gpt-neox\/data\/gpt2-merges.txt\",\r\n\r\n  \"save\": \"\/mnt\/4TBNVME\/checkpoints_test\",\r\n  \"load\": \"\/mnt\/4TBNVME\/checkpoints_test\",\r\n\r\n  \"checkpoint_validation_with_forward_pass\": False,\r\n  \r\n  \"tensorboard-dir\": \"\/mnt\/4TBNVME\/logs\/tensorboard\/bug_fix_test\",\r\n  \"log-dir\": \"\/mnt\/4TBNVME\/logs\/gptneox\/bug_fix_test\",\r\n\r\n  \"use_wandb\": True,\r\n  \"wandb_host\": \"https:\/\/api.wandb.ai\",\r\n  \"wandb_project\": \"neox_test\"\r\n}\r\n```\r\n\r\n```\r\n# Add this to your config for sparse attention every other layer\r\n{\r\n  \"attention_config\": [[[\"local\", \"global\"], \"all\"]],\r\n\r\n  # sparsity config:\r\n  # (these are the defaults for local sliding window sparsity, training will work without this here, but it's left in for\r\n  # illustrative purposes)\r\n  # see https:\/\/www.deepspeed.ai\/tutorials\/sparse-attention\/#how-to-config-sparsity-structures for\r\n  # more detailed config instructions and available parameters\r\n\r\n  \"sparsity_config\": {\r\n    \"block\": 16, # block size\r\n    \"num_local_blocks\": 32,\r\n  }\r\n}\r\n```\r\n\r\n**Additional context**\r\n\r\nI have a bug fix ready, will follow up with it.",
        "Challenge_closed_time":1663248.0,
        "Challenge_comment_count":0,
        "Challenge_created_time":1663015846000,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/github.com\/EleutherAI\/gpt-neox\/issues\/669",
        "Challenge_link_count":3,
        "Challenge_participation_count":0,
        "Challenge_readability":16.2,
        "Challenge_reading_time":63.87,
        "Challenge_repo_contributor_count":44.0,
        "Challenge_repo_fork_count":385.0,
        "Challenge_repo_issue_count":712.0,
        "Challenge_repo_star_count":2929.0,
        "Challenge_repo_watch_count":75.0,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":25,
        "Challenge_solved_time":null,
        "Challenge_title":"Test set metrics overwrite validation set metrics in TensorBoard and are rejected for logging by Weights and Biases (W&B)",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":null,
        "Challenge_word_count":522,
        "Issue_self_closed":0.0,
        "Platform":"Github",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":-15.7,
        "Solution_reading_time":0.0,
        "Solution_score_count":null,
        "Solution_sentence_count":1.0,
        "Solution_word_count":0.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_created_time":1646219230528,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":1.0,
        "Answerer_view_count":1.0,
        "Challenge_adjusted_solved_time":null,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I want to build an Azure ML environment with two python packages that I have in Azure Devops.\nFor this I need a workspace connection to Azure Devops. One package is published to an artifact feed and I can access it using the python SDK using a personal access token:<\/p>\n<pre><code>ws.set_connection(name=&quot;ConnectionName&quot;, \n                  category= &quot;PythonFeed&quot;, \n                  target = &quot;https:\/\/pkgs.dev.azure.com\/&quot;, \n                  authType = &quot;PAT&quot;, \n                  value = PAT_TOKEN)\n<\/code><\/pre>\n<p>However, for the other I need to get the package from the git repository in Azure Devops. The documentation of the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.workspace.workspace?view=azure-ml-py#azureml-core-workspace-workspace-set-connection\" rel=\"nofollow noreferrer\">Python SDK<\/a> and the underlying <a href=\"https:\/\/docs.microsoft.com\/en-us\/rest\/api\/azureml\/workspace-connections\/create\" rel=\"nofollow noreferrer\">REST API<\/a> don't give the options for the arguments, only that they need to be strings (see links).<\/p>\n<p>My question: what are the options for the following arguments:<\/p>\n<ul>\n<li>authType<\/li>\n<li>category<\/li>\n<li>valueFormat<\/li>\n<\/ul>\n<p>And what do I need to set for target argument, so that I can connect to the Azure DevOps repository with potentially different authentication?<\/p>",
        "Challenge_closed_time":1.0,
        "Challenge_comment_count":0,
        "Challenge_created_time":1646219844250,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/71321757",
        "Challenge_link_count":3,
        "Challenge_participation_count":1,
        "Challenge_readability":13.0,
        "Challenge_reading_time":18.16,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":10,
        "Challenge_solved_time":null,
        "Challenge_title":"What are valid Azure ML Workspace connection argument options?",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":93.0,
        "Challenge_word_count":157,
        "Issue_self_closed":null,
        "Platform":"Stack Overflow",
        "Poster_created_time":1646219230528,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":1.0,
        "Poster_view_count":1.0,
        "Solution_body":"<p>To get the package from a Azure DevOps git repository you can change the target to the repository URL:<\/p>\n<pre><code>ws.set_connection(\n    name=&quot;ConnectionName&quot;, \n    category = &quot;PythonFeed&quot;,\n    target = &quot;https:\/\/dev.azure.com\/&lt;MY-ORG&gt;\/&lt;MY-PROJECT&gt;\/_git\/&lt;MY-REPO&gt;&quot;, \n    authType = &quot;PAT&quot;, \n    value = &lt;PAT-TOKEN&gt;)\n<\/code><\/pre>\n<p>Note here that there is no user specified in the URL (the standard &quot;clone&quot; URL in Azure DevOps also contains &quot;DevOps-Vx@&quot;).<\/p>\n<p>As for any other options for &quot;authType&quot;, &quot;category&quot; and &quot;valueFormat&quot;, I don't know.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":14.3,
        "Solution_reading_time":8.53,
        "Solution_score_count":0.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":64.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":null,
        "Challenge_answer_count":2,
        "Challenge_body":"Hi!\r\n\r\nI have installed all required packages by `pip install -r requrements.txt` and tried to run hyperparametric search using the [file](https:\/\/github.com\/ashleve\/lightning-hydra-template\/blob\/main\/configs\/hparams_search\/mnist_optuna.yaml):\r\n```\r\ntrain.py -m hparams_search=mnist_optuna experiment=example\r\n``` \r\nI faced 2 problems:\r\n\r\n# 1. hydra-optuna-sweeper problem\r\n\r\nI got the following error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\hydra\\_internal\\utils.py\", line 213, in run_and_report\r\n    return func()\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\hydra\\_internal\\utils.py\", line 461, in <lambda>\r\n    lambda: hydra.multirun(\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\hydra\\_internal\\hydra.py\", line 162, in multirun\r\n    ret = sweeper.sweep(arguments=task_overrides)\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\hydra_plugins\\hydra_optuna_sweeper\\optuna_sweeper.py\", line 52, in sweep\r\n    return self.sweeper.sweep(arguments)\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\hydra_plugins\\hydra_optuna_sweeper\\_impl.py\", line 289, in sweep\r\n    assert self.search_space is None\r\nAssertionError\r\n```\r\nThe same error was reported in [this issue](https:\/\/github.com\/facebookresearch\/hydra\/issues\/2253).\r\n\r\nFile [requrements.txt](https:\/\/github.com\/ashleve\/lightning-hydra-template\/blob\/main\/requirements.txt) contains the following versions for hydra-optuna-sweeper:\r\n```\r\n# --------- hydra --------- #\r\nhydra-core>=1.1.0\r\nhydra-colorlog>=1.1.0\r\nhydra-optuna-sweeper>=1.1.0\r\n```\r\nBut the latest versions of the packages are installing:\r\n```\r\nhydra-colorlog==1.2.0\r\nhydra-core==1.2.0\r\nhydra-optuna-sweeper==1.2.0\r\n```\r\n\r\nIf I understand correctly, optuna sweeper's syntax has changed in hydra since version 1.2.0. When I change the syntax to the new version (as it was in mentioned above [issue](https:\/\/github.com\/facebookresearch\/hydra\/issues\/2253)):\r\n```yaml\r\nhydra:\r\n  sweeper:\r\n    ...\r\n    params:\r\n      datamodule.batch_size: choice(32,64,128)\r\n      model.lr: interval(0.0001, 0.2)\r\n      model.net.lin1_size: choice(32, 64, 128, 256, 512)\r\n      model.net.lin2_size: choice(32, 64, 128, 256, 512)\r\n      model.net.lin3_size: choice(32, 64, 128, 256, 512)\r\n```\r\neverything works without errors.\r\n\r\n# 2. wandb problem\r\nAfter the command `pip install -r requrements.txt` wandb==0.12.20 was installed.\r\nWhen running the training process with this logger:\r\n```\r\ntrain.py -m hparams_search=mnist_optuna experiment=example logger=wandb\r\n```\r\nThe first run with the certian parameters combination finished successfully, the second run had the error:\r\n\r\n```\r\nException in thread StreamThr:\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\threading.py\", line 973, in _bootstrap_inner\r\n    self.run()\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\wandb\\sdk\\service\\streams.py\", line 40, in run\r\n    self._target(**self._kwargs)\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\wandb\\sdk\\internal\\internal.py\", line 85, in wandb_internal\r\n    configure_logging(_settings.log_internal, _settings._log_level)\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\wandb\\sdk\\internal\\internal.py\", line 189, in configure_logging\r\n    log_handler = logging.FileHandler(log_fname)\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\logging\\__init__.py\", line 1146, in __init__\r\n    StreamHandler.__init__(self, self._open())\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\logging\\__init__.py\", line 1175, in _open\r\n    return open(self.baseFilename, self.mode, encoding=self.encoding,\r\nFileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\yusip\\\\Desktop\\\\lightning-hydra-template-main\\\\logs\\\\experiments\\\\multiruns\\\\simple_dense_net\\\\2022-06-30_14-36-03\\\\0\\\\wandb\\\\run-2022\r\n0630_143648-2vxuij78\\\\logs\\\\debug-internal.log'\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\runpy.py\", line 197, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\runpy.py\", line 87, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\wandb\\__main__.py\", line 3, in <module>\r\n    cli.cli(prog_name=\"python -m wandb\")\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\click\\core.py\", line 1130, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\click\\core.py\", line 1055, in main\r\n    rv = self.invoke(ctx)\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\click\\core.py\", line 1657, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\click\\core.py\", line 1404, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\click\\core.py\", line 760, in invoke\r\n    return __callback(*args, **kwargs)\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\wandb\\cli\\cli.py\", line 96, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\wandb\\cli\\cli.py\", line 285, in service\r\n    server.serve()\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\wandb\\sdk\\service\\server.py\", line 140, in serve\r\n    mux.loop()\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\wandb\\sdk\\service\\streams.py\", line 332, in loop\r\n    raise e\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\wandb\\sdk\\service\\streams.py\", line 330, in loop\r\n    self._loop()\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\wandb\\sdk\\service\\streams.py\", line 323, in _loop\r\n    self._process_action(action)\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\wandb\\sdk\\service\\streams.py\", line 288, in _process_action\r\n    self._process_add(action)\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\wandb\\sdk\\service\\streams.py\", line 208, in _process_add\r\n    stream.start_thread(thread)\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\wandb\\sdk\\service\\streams.py\", line 68, in start_thread\r\n    self._wait_thread_active()\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\wandb\\sdk\\service\\streams.py\", line 73, in _wait_thread_active\r\n    assert result\r\nAssertionError\r\nProblem at: C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py 357 experiment\r\nwandb: ERROR Error communicating with wandb process\r\nwandb: ERROR try: wandb.init(settings=wandb.Settings(start_method='fork'))\r\nwandb: ERROR or:  wandb.init(settings=wandb.Settings(start_method='thread'))\r\nwandb: ERROR For more info see: https:\/\/docs.wandb.ai\/library\/init#init-start-error\r\nError executing job with overrides: ['datamodule.batch_size=32', 'model.lr=0.09357304154313738', 'model.net.lin1_size=256', 'model.net.lin2_size=512', 'model.net.lin3_size=256', 'hparams_search=mnist_op\r\ntuna', 'experiment=example', 'logger=wandb']\r\nError in call to target 'pytorch_lightning.loggers.wandb.WandbLogger':\r\nUsageError(\"Error communicating with wandb process\\ntry: wandb.init(settings=wandb.Settings(start_method='fork'))\\nor:  wandb.init(settings=wandb.Settings(start_method='thread'))\\nFor more info see: htt\r\nps:\/\/docs.wandb.ai\/library\/init#init-start-error\")\r\nfull_key: logger.wandb\r\n```\r\nIt is not clear, which parameters should be passed to pytorch lighting wrapper when initializinig this logger, to avoid this error.\r\n\r\n\r\n",
        "Challenge_closed_time":1657912.0,
        "Challenge_comment_count":0,
        "Challenge_created_time":1656590728000,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/github.com\/ashleve\/lightning-hydra-template\/issues\/362",
        "Challenge_link_count":5,
        "Challenge_participation_count":2,
        "Challenge_readability":17.7,
        "Challenge_reading_time":99.61,
        "Challenge_repo_contributor_count":24.0,
        "Challenge_repo_fork_count":341.0,
        "Challenge_repo_issue_count":412.0,
        "Challenge_repo_star_count":2043.0,
        "Challenge_repo_watch_count":19.0,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":79,
        "Challenge_solved_time":null,
        "Challenge_title":"hydra-optuna-sweeper and wandb versions conflict",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":null,
        "Challenge_word_count":523,
        "Issue_self_closed":0.0,
        "Platform":"Github",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"Hi @GillianGrayson \r\n\r\nFor **1. hydra-optuna-sweeper problem**, it has been modified in release_1.4. You can find [here](https:\/\/github.com\/ashleve\/lightning-hydra-template\/blob\/7e67c4692590550e7b703655845e59508eb071bb\/configs\/hparams_search\/mnist_optuna.yaml#L49)\r\n\r\n @GillianGrayson ty for reporting, the problems have been fixed on the current `main` branch.",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":12.1,
        "Solution_reading_time":4.76,
        "Solution_score_count":null,
        "Solution_sentence_count":4.0,
        "Solution_word_count":30.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_created_time":1640731722280,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":76.0,
        "Answerer_view_count":1.0,
        "Challenge_adjusted_solved_time":null,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I Can not run <code>apt to install git-lfs<\/code> on sagemaker notebook instance. I want to run git commands in my notebook.<\/p>",
        "Challenge_closed_time":1.0,
        "Challenge_comment_count":0,
        "Challenge_created_time":1640732204667,
        "Challenge_favorite_count":1.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/70513398",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":6.0,
        "Challenge_reading_time":2.42,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":2.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":null,
        "Challenge_title":"I can not install \"git-lfs\" on aws sagemaker notebook instance",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":489.0,
        "Challenge_word_count":30,
        "Issue_self_closed":null,
        "Platform":"Stack Overflow",
        "Poster_created_time":1596727881047,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":65.0,
        "Poster_view_count":4.0,
        "Solution_body":"<p>use the following commands to install git-lfs<\/p>\n<pre><code>!curl -s https:\/\/packagecloud.io\/install\/repositories\/github\/git-lfs\/script.rpm.sh | sudo bash\n\n!sudo yum install git-lfs -y\n\n!git lfs install\n<\/code><\/pre>\n<p>that should make it work<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":8.9,
        "Solution_reading_time":3.29,
        "Solution_score_count":6.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":26.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1294388296987,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Italy",
        "Answerer_reputation_count":32174.0,
        "Answerer_view_count":3457.0,
        "Challenge_adjusted_solved_time":null,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I use Azure Machine Learning Workspace Notebooks, connected to a DevOps Repository - using terminal git commands to manage my code. I work on different branches, often has to switch back and forth between them.<\/p>\n<p>I reviewed this thread before: <a href=\"https:\/\/stackoverflow.com\/questions\/18615428\/switching-branches-keeps-new-files-from-other-branch\">switching branches keeps new files from other branch<\/a><\/p>\n<p>In my case it does not only keep the files that should be ignored with the use of the gitignore file, but others too.<\/p>\n<p>I tested it with a totally empty branch, that should not have any files in it, checked it out, and it still has files from the branch that I worked with previously. When I check it manually on DevOps, in the repo, the empty branch is actually empty there.<\/p>\n<p>Has anyone seen similar issues?<\/p>",
        "Challenge_closed_time":1.0,
        "Challenge_comment_count":2,
        "Challenge_created_time":1622716713767,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/67819912",
        "Challenge_link_count":1,
        "Challenge_participation_count":3,
        "Challenge_readability":8.8,
        "Challenge_reading_time":11.63,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":8,
        "Challenge_solved_time":null,
        "Challenge_title":"Azure ML, DevOps: Switching between branches keeps some files from another branch",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":189.0,
        "Challenge_word_count":137,
        "Issue_self_closed":null,
        "Platform":"Stack Overflow",
        "Poster_created_time":1438890950452,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Nordhavnen, Copenhagen, Denmark",
        "Poster_reputation_count":570.0,
        "Poster_view_count":187.0,
        "Solution_body":"<p>Some files that are tracked in a branch could be not tracked in another. So when you switch back to the &quot;non tracking&quot; branch, that files remain in the file system. Git does not clean stuff that does not track directly. Do not exchange the term not tracked by ignored. Files are not tracked until we &quot;add&quot; them in stage and commit.\nYou could cleanup the working git by running <code>git clean -f -d<\/code><\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":3.4,
        "Solution_reading_time":5.27,
        "Solution_score_count":1.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":74.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1510527902860,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Zurich, Switzerland",
        "Answerer_reputation_count":1078.0,
        "Answerer_view_count":40.0,
        "Challenge_adjusted_solved_time":null,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have to test if my kedro project works from github so I create a new environment, then :<\/p>\n<pre><code>git clone &lt;my_project&gt;\npip install kedro kedro[pandas] kedro-viz jupyter\nkedro build-reqs\nkedro install\n<\/code><\/pre>\n<p>and the install fails, then I retry a few time (sometimes 2 or 3) then the next attempt it is successful<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/4KTui.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/4KTui.png\" alt=\"see image\" \/><\/a><\/p>\n<p>EDIT:\npython -V : Python 3.7.10\nkedro --version : kedro, version 0.17.3<\/p>\n<p>i cant post my requirement.txt (post is mostly code) so here is my requirement.in<\/p>\n<pre><code>black==v19.10b0\nflake8&gt;=3.7.9, &lt;4.0\nipython==7.10\nisort&gt;=4.3.21, &lt;5.0\njupyter~=1.0\njupyter_client&gt;=5.1, &lt;7.0\njupyterlab==0.31.1\nkedro==0.17.3\nnbstripout==0.3.3\npytest-cov~=2.5\npytest-mock&gt;=1.7.1, &lt;2.0\npytest~=6.1.2\nwheel==0.32.2\nspacy&gt;=3.0.0,&lt;4.0.0\nscikit-learn == 0.24.2\nkedro-viz==3.11.0\nwordcloud== 1.8.1\nhttps:\/\/github.com\/explosion\/spacy-models\/releases\/download\/fr_core_news_sm-3.0.0\/fr_core_news_sm-3.0.0.tar.gz#egg=fr_core_news_sm\n<\/code><\/pre>",
        "Challenge_closed_time":1.0,
        "Challenge_comment_count":3,
        "Challenge_created_time":1623434458303,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1623788215208,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/67941614",
        "Challenge_link_count":3,
        "Challenge_participation_count":4,
        "Challenge_readability":11.0,
        "Challenge_reading_time":16.17,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":2.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":null,
        "Challenge_title":"Kedro install fail to install, but few attempt later it is successful",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":594.0,
        "Challenge_word_count":122,
        "Issue_self_closed":null,
        "Platform":"Stack Overflow",
        "Poster_created_time":1596486679830,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":23.0,
        "Poster_view_count":4.0,
        "Solution_body":"<p>As indicated in the comment, I think there are two issues at play.<\/p>\n<h4>1. Decoding error<\/h4>\n<p>This is the main exception you're getting, i.e.:<\/p>\n<pre><code>UnicodeDecodeError: \u2018utf-8\u2019 codec can\u2019t decode byte 0xe8 in position 69: invalid continuation byte\n<\/code><\/pre>\n<p>This is unexpectedly raised while Kedro itself is handling the errors from <code>pip install<\/code> (see <a href=\"https:\/\/github.com\/quantumblacklabs\/kedro\/blob\/master\/kedro\/framework\/cli\/project.py#L172\" rel=\"nofollow noreferrer\">this line of Kedro's source code<\/a>). I believe the cause might be that you have accented characters in your working directory, which can't be interpreted by Python's standard <code>decode()<\/code> (see <a href=\"https:\/\/stackoverflow.com\/questions\/49898909\/reading-a-file-with-french-characters-in-python\">this<\/a>). Example:<\/p>\n<pre><code>b'acc\u00e9l\u00e9ration'.decode()\n&gt;&gt; SyntaxError: bytes can only contain ASCII literal characters.\n<\/code><\/pre>\n<p>The decoding error is obscuring the actual <code>pip install<\/code> error.<\/p>\n<h4>2. <code>pip install<\/code> error<\/h4>\n<p>As you correctly pointed out, <code>kedro install<\/code> uses <code>pip install<\/code> under the hood. It's a bit difficult to pinpoint the exact cause without seeing the actual error. I could however reproduce a similar issue, in my case getting the following error:<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'c:\\\\users\\\\&lt;mu-user&gt;\\\\anaconda3\\\\&lt;my-env&gt;\\\\kedro_project_tests\\\\lib\\\\site-packages\\\\~ydantic\\\\annotated_types.cp37-win_amd64.pyd'\nConsider using the `--user` option or check the permissions.\n<\/code><\/pre>\n<p>I believe this is caused by interactions caused by between different versions Kedro and Kedro-Viz. Simply not <code>pip install<\/code>ing <code>kedro-viz<\/code> <em>before<\/em> doing <code>kedro install<\/code> fixed it for me.<\/p>\n<hr \/>\n<p><em>Note: Related to this, there will surely be an error if the version of Kedro installed through <code>pip<\/code> <em>before<\/em> doing <code>kedro install<\/code> is not the same as the version of Kedro specified in <code>requirements.in<\/code> or <code>requirements.txt<\/code>. This is obvious, as the package currently handling execution will be uninstalled. The error in this case will be something like this:<\/em><\/p>\n<pre><code>ERROR: Could not install packages due to an OSError: [WinError 32] The process cannot access the file because it is being used by another process: 'c:\\\\users\\\\&lt;my-user&gt;\\\\anaconda3\\\\envs\\\\&lt;my-env&gt;\\\\scripts\\\\kedro.exe\n<\/code><\/pre>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":13.6,
        "Solution_reading_time":34.39,
        "Solution_score_count":1.0,
        "Solution_sentence_count":17.0,
        "Solution_word_count":296.0,
        "Tool":"Kedro"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":null,
        "Challenge_answer_count":7,
        "Challenge_body":"> From https:\/\/github.com\/iterative\/dvc.org\/issues\/1743#issuecomment-730726776\r\n\r\n```console\r\n$ git@github.com:iterative\/example-get-started.git\r\n...\r\n$ cd example-get-started\r\n$ dvc fetch\r\nERROR: failed to fetch data from the cloud - Lockfile 'dvc.lock' is corrupted.\r\n```",
        "Challenge_closed_time":1606074.0,
        "Challenge_comment_count":0,
        "Challenge_created_time":1606072868000,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/github.com\/iterative\/example-repos-dev\/issues\/17",
        "Challenge_link_count":1,
        "Challenge_participation_count":7,
        "Challenge_readability":16.4,
        "Challenge_reading_time":4.1,
        "Challenge_repo_contributor_count":17.0,
        "Challenge_repo_fork_count":11.0,
        "Challenge_repo_issue_count":154.0,
        "Challenge_repo_star_count":15.0,
        "Challenge_repo_watch_count":14.0,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":null,
        "Challenge_title":"example-get-started is broken with latest DVC",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":null,
        "Challenge_word_count":26,
        "Issue_self_closed":1.0,
        "Platform":"Github",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"What DVC version do you use? It should be be fixed in the most recent one. 1.9.1 on Windows (latest) the latest version is 1.10 something. if it's not updated on Windows then we have a problem with Win releases cc @efiop  Ah I was wrong, you're right. Works with 1.10.1 which I got from https:\/\/github.com\/iterative\/dvc\/releases\/\r\n\r\nThe problem is that the dvc.org home page download button is stuck at 1.9.1 for all platforms, it seems. Opened iterative\/dvc.org\/issues\/1964, resolving here. I use the latest dvc version [DVC version: 1.11.16 (pip)] and have got the same issue while following the [installation](https:\/\/github.com\/iterative\/example-get-started) steps:\r\nOS: Mac OS Mojave 10.14.6\r\n```\r\n$ dvc pull\r\nEverything is up to date.                                             \r\nERROR: failed to pull data from the cloud - Lockfile 'dvc.lock' is corrupted.\r\n``` @yakushechkin example-get-started is migrating to dvc 2.0, so it is no longer compatible with older dvc versions. We plan on releasing 2.0 on Wednesday. You could try `pip install --pre dvc` to install dvc pre-release. Sorry for the inconvenience.",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":5.0,
        "Solution_reading_time":13.16,
        "Solution_score_count":null,
        "Solution_sentence_count":22.0,
        "Solution_word_count":163.0,
        "Tool":"DVC"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":null,
        "Challenge_answer_count":9,
        "Challenge_body":"Hi. I just upgraded to pycaret 2.1. When I ran the compare_models function with the Titanic dataset, I got the following error:\r\n\r\nMlflowException: Unable to map 'np.object' type to MLflow DataType. np.object canbe mapped iff all values have identical data type which is one of (string, (bytes or byterray),  int, float)\r\n\r\nThe same code worked fine in pycaret 2.0.",
        "Challenge_closed_time":1598806.0,
        "Challenge_comment_count":0,
        "Challenge_created_time":1598718264000,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/github.com\/pycaret\/pycaret\/issues\/566",
        "Challenge_link_count":0,
        "Challenge_participation_count":9,
        "Challenge_readability":6.9,
        "Challenge_reading_time":4.83,
        "Challenge_repo_contributor_count":93.0,
        "Challenge_repo_fork_count":1518.0,
        "Challenge_repo_issue_count":2643.0,
        "Challenge_repo_star_count":6633.0,
        "Challenge_repo_watch_count":124.0,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":null,
        "Challenge_title":"Compare models MLFlowException",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":null,
        "Challenge_word_count":61,
        "Issue_self_closed":0.0,
        "Platform":"Github",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"@sagarnildass Hi, Thanks for reporting. This seems like an error from `MLFlow`. I tried to reproduce this out of `pycaret` and I was successful. See below code that throws an error:\r\n\r\n```\r\nimport pandas as pd\r\ndata = pd.read_csv('titanic.csv') #train data from Kaggle\r\nfrom mlflow.models.signature import infer_signature\r\ninfer_signature(data)\r\n```\r\nThis gives the following error:\r\nMlflowException: Unable to map 'np.object' type to MLflow DataType. np.object canbe mapped iff all values have identical data type which is one of (string, (bytes or byterray),  int, float).\r\n\r\nI will log an issue on MLFlow GitHub.\r\n\r\nHere is the issue I logged on MLFlow: https:\/\/github.com\/mlflow\/mlflow\/issues\/3362 Hey\r\n\r\nThanks for the quick reply. \r\n\r\nI found out that presence of null values are a problem. If the dataset contains null values, this error was raised. When I imputed the null values, this problem was solved. Can you also mention this when you log this issue?\r\n\r\nThanks! @sagarnildass Thanks. I have added that in my issue but I don't think so it's 100% True. I have worked with few missing datasets and it worked okay. For example, the `hepatitis` dataset on our repo works fine. Example code:\r\n\r\n```\r\nfrom pycaret.datasets import get_data\r\ndata = get_data('hepatitis')\r\nfrom pycaret.classification import *\r\ns = setup(data, target = 'Class', log_experiment=True, experiment_name = 'hepatitis1')\r\n```\r\n\r\nThis dataset has missing values but it just worked fine. \r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/58118658\/91642055-41991700-e9f6-11ea-9b6f-0f42a86401d9.png)\r\n\r\nCan you investigate more and add your comments on the original issue here: https:\/\/github.com\/mlflow\/mlflow\/issues\/3362\r\n\r\nThanks a lot for helping. @Yard1 I don't know how soon `MLFLow` will be able to fix this but in `2.2` we will have to create some kind of exceptions under `logging_param` chunks to not fail the process even when `infer_signature` fails, as it's not mandatory and has no impact other than the signature file that gets generated under `model` directory when `log_experiment` is set to `True`. @pycaret : I believe object datatypes are a problem. It clearly states: \"np.object canbe mapped iff all values have identical data type which is one of (string, (bytes or byterray), int, float)\". So do you think null values in a object datatype column might be the root  problem here? Because in hepatitis data, all the columns are numeric. @pycaret If we get MLFlow logging into a function then it will be easy to wrap it into a try except block.  @sagarnildass Thanks again for reporting. I am planning to do a bug fix release tomorrow `2.1.1`. For now, I have wrapped this inside `try` and `except` clause to avoid the error. I have tested it on the titanic dataset.\r\n\r\nCan you please sync the `master` and try to see if you can reproduce the error now?\r\n\r\nThanks Done...it's working as expected. @sagarnildass Thanks. I will publish the `2.1.1.` release today. @Yard1 FYI.\r\n\r\nThanks for your help @sagarnildass ",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":3.0,
        "Solution_readability":6.6,
        "Solution_reading_time":36.65,
        "Solution_score_count":null,
        "Solution_sentence_count":39.0,
        "Solution_word_count":449.0,
        "Tool":"MLflow"
    },
    {
        "Answerer_created_time":1631019482980,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":234.0,
        "Answerer_view_count":155.0,
        "Challenge_adjusted_solved_time":null,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>Goal: <code>add<\/code> <code>commit<\/code> <code>push<\/code> all contents of <code>project_model\/data\/<\/code> to <strong>dvcstore<\/strong>.<\/p>\n<p>I don't have any <code>.dvc<\/code> files in my project.<\/p>\n<pre><code>$ dvc add .\/project_model\/data\/\nERROR: Cannot add '\/home\/me\/PycharmProjects\/project\/project_model\/data\/images', because it is overlapping with other DVC tracked output: '\/home\/me\/PycharmProjects\/project\/project_model\/data'.\nTo include '\/home\/me\/PycharmProjects\/project\/project_model\/data\/images' in '\/home\/me\/PycharmProjects\/project\/project_model\/data', run 'dvc commit project_model\/data.dvc'\n\n$ dvc commit project_model\/data.dvc\nERROR: failed to commit project_model\/data.dvc - 'project_model\/data.dvc' does not exist\n<\/code><\/pre>\n<p>I've deleted contents from <code>.dvc\/cache\/<\/code> and <strong>S3<\/strong> <code>s3:\/\/foo\/bar\/dvcstore\/<\/code>, with no luck.<\/p>\n<hr \/>\n<pre><code>$ dvc -V\n2.10.2\n<\/code><\/pre>\n<pre><code>$ dvc doctor\nDVC version: 2.10.2 (pip)\n---------------------------------\nPlatform: Python 3.9.12 on Linux-5.15.0-47-generic-x86_64-with-glibc2.35\nSupports:\n        webhdfs (fsspec = 2022.5.0),\n        http (aiohttp = 3.8.1, aiohttp-retry = 2.5.2),\n        https (aiohttp = 3.8.1, aiohttp-retry = 2.5.2),\n        s3 (s3fs = 2022.5.0, boto3 = 1.21.21)\nCache types: hardlink, symlink\nCache directory: ext4 on \/dev\/nvme0n1p5\nCaches: local\nRemotes: s3\nWorkspace directory: ext4 on \/dev\/nvme0n1p5\nRepo: dvc, git\n<\/code><\/pre>\n<p>Please let me know if there's anything else I can add to post.<\/p>",
        "Challenge_closed_time":1.0,
        "Challenge_comment_count":0,
        "Challenge_created_time":1663059618623,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/73700203",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":11.8,
        "Challenge_reading_time":21.01,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":23,
        "Challenge_solved_time":null,
        "Challenge_title":"ERROR: Cannot add 'folder-path', because it is overlapping with other DVC tracked output:",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":31.0,
        "Challenge_word_count":154,
        "Issue_self_closed":null,
        "Platform":"Stack Overflow",
        "Poster_created_time":1631019482980,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":234.0,
        "Poster_view_count":155.0,
        "Solution_body":"<p>In my case, the problem was in <code>dvc.yaml<\/code>.<\/p>\n<p>For a few <code>stages<\/code>, I had cyclical dependencies, where a file-path was mentioned in both the <code>deps<\/code> and <code>outs<\/code>.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":7.4,
        "Solution_reading_time":2.73,
        "Solution_score_count":0.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":27.0,
        "Tool":"DVC"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":null,
        "Challenge_answer_count":3,
        "Challenge_body":"Wandb sweep on our [primary notebook don't](https:\/\/colab.research.google.com\/drive\/1vl6tgH78bNb9A5JP6NcfFHB189TIjy5c#scrollTo=sTDGweZ0d0QP) advance instead they just stall after the first part of the sweep completes. This is causing problems.",
        "Challenge_closed_time":1600665.0,
        "Challenge_comment_count":0,
        "Challenge_created_time":1600217910000,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/github.com\/AIStream-Peelout\/flow-forecast\/issues\/154",
        "Challenge_link_count":1,
        "Challenge_participation_count":3,
        "Challenge_readability":10.5,
        "Challenge_reading_time":3.48,
        "Challenge_repo_contributor_count":13.0,
        "Challenge_repo_fork_count":209.0,
        "Challenge_repo_issue_count":605.0,
        "Challenge_repo_star_count":1230.0,
        "Challenge_repo_watch_count":20.0,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":null,
        "Challenge_title":"Wandb Run stalling",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":null,
        "Challenge_word_count":26,
        "Issue_self_closed":1.0,
        "Platform":"Github",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"So this appears to be a problem on the Weights and Biases end of things. https:\/\/github.com\/wandb\/client\/issues\/1243 This is fixed see original issue.",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":7.6,
        "Solution_reading_time":1.9,
        "Solution_score_count":null,
        "Solution_sentence_count":2.0,
        "Solution_word_count":22.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_created_time":1314097464768,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Warsaw, Poland",
        "Answerer_reputation_count":11056.0,
        "Answerer_view_count":544.0,
        "Challenge_adjusted_solved_time":null,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>In <a href=\"https:\/\/neptune.ml\/\" rel=\"nofollow noreferrer\">Neptune<\/a> (this machine learning experiment tracker) is it possible to make it git-aware? I mean - using <code>.gitignore<\/code> for excluded files and saving commit hashes for each run?<\/p>\n\n<p>In particular, when I review an already finished job, can I go directly to GitHub commit?<\/p>",
        "Challenge_closed_time":1.0,
        "Challenge_comment_count":0,
        "Challenge_created_time":1495124614783,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1503919276067,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/44053141",
        "Challenge_link_count":1,
        "Challenge_participation_count":2,
        "Challenge_readability":7.9,
        "Challenge_reading_time":4.85,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":null,
        "Challenge_title":"Can I make Neptune talk to git?",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":140.0,
        "Challenge_word_count":53,
        "Issue_self_closed":null,
        "Platform":"Stack Overflow",
        "Poster_created_time":1314097464768,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Warsaw, Poland",
        "Poster_reputation_count":11056.0,
        "Poster_view_count":544.0,
        "Solution_body":"<p>Starting form version 2.0 Neptune provides integration with git, see: <a href=\"https:\/\/docs.neptune.ml\/advanced-topics\/git-integration\/\" rel=\"nofollow noreferrer\">https:\/\/docs.neptune.ml\/advanced-topics\/git-integration\/<\/a>.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":28.7,
        "Solution_reading_time":3.2,
        "Solution_score_count":0.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":14.0,
        "Tool":"Neptune"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":0.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":null,
        "Challenge_answer_count":2,
        "Challenge_body":"We have a gitlab repo within a private VPN and would like to setup Studio to clone that repo and to push and pull updates. Is that possible yet from within Studio?",
        "Challenge_closed_time":1.0,
        "Challenge_comment_count":1,
        "Challenge_created_time":1643132865842,
        "Challenge_favorite_count":1.0,
        "Challenge_last_edit_time":1668578369590,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QURGs7VOVlTzKCG7H2AFLWww\/how-can-we-connect-a-sagemaker-studio-user-to-a-gitlab-repo-within-a-private-vpn",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":8.2,
        "Challenge_reading_time":2.92,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":null,
        "Challenge_title":"How can we connect a Sagemaker Studio user to a gitlab repo within a private VPN?",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":376.0,
        "Challenge_word_count":47,
        "Issue_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"Thank you for your response. For those looking to do the same thing, according to AWS Support AWS SageMakers does NOT support GitLab yet and there is no ETA for that feature.",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1650994900956,
        "Solution_link_count":0.0,
        "Solution_readability":6.0,
        "Solution_reading_time":2.1,
        "Solution_score_count":0.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":32.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1620132280447,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":146.0,
        "Answerer_view_count":9.0,
        "Challenge_adjusted_solved_time":null,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I'm using DAGsHub storage as a remote and running into the following error message (when trying to DVC pull):<\/p>\n<blockquote>\n<p>ERROR: Lockfile 'bias_tagging_model\/dvc.lock' is corrupted.<\/p>\n<\/blockquote>\n<p>I thought I might have messed something up, but when cloning the git repo again and DVC pulling I am still running into this.\nThe data looks ok when viewed in the browser.\nIf you have any ideas, I would appreciate your help!<\/p>",
        "Challenge_closed_time":1.0,
        "Challenge_comment_count":1,
        "Challenge_created_time":1620243318287,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/67407702",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":7.6,
        "Challenge_reading_time":5.76,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":3.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":null,
        "Challenge_title":"Corrupted dvc.lock",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":362.0,
        "Challenge_word_count":70,
        "Issue_self_closed":null,
        "Platform":"Stack Overflow",
        "Poster_created_time":1620132740443,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"New York, NY, USA",
        "Poster_reputation_count":75.0,
        "Poster_view_count":2.0,
        "Solution_body":"<p>Usually, the reason for this error is the DVC version.<\/p>\n<p>If the dvc.lock file has a DVC 2.* schema and you are using a lower version, it will throw this error.<\/p>\n<p>Upgrade your DVC version, and it should work.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":2.8,
        "Solution_reading_time":2.73,
        "Solution_score_count":4.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":39.0,
        "Tool":"DVC"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":null,
        "Challenge_answer_count":4,
        "Challenge_body":"<p>I was wondering if it would be possible to have a simple W&amp;B\/wandb badge to display on GitHub repositories, meaning: \u201cThis repository supports experiment tracking with wandb\u201d.<\/p>\n<p>By badge, I mean like below. The official wandb client repository for example uses pypi, codecov and circleci badges.<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/2a8eb240dfb428a627280e4311324e7c0ec92188.png\" data-download-href=\"\/uploads\/short-url\/64tMj9Dw36m9P2OBKPlPRcyIuBq.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/2a8eb240dfb428a627280e4311324e7c0ec92188_2_690x151.png\" alt=\"image\" data-base62-sha1=\"64tMj9Dw36m9P2OBKPlPRcyIuBq\" width=\"690\" height=\"151\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/2a8eb240dfb428a627280e4311324e7c0ec92188_2_690x151.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/2a8eb240dfb428a627280e4311324e7c0ec92188.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/2a8eb240dfb428a627280e4311324e7c0ec92188.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/2a8eb240dfb428a627280e4311324e7c0ec92188_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">775\u00d7170 36 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Challenge_closed_time":1.0,
        "Challenge_comment_count":0,
        "Challenge_created_time":1648914623994,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/feature-request-w-b-badge-or-shield-for-github-repositories\/2181",
        "Challenge_link_count":6,
        "Challenge_participation_count":4,
        "Challenge_readability":26.2,
        "Challenge_reading_time":24.27,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":4.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":null,
        "Challenge_title":"[Feature Request] W&B badge or shield for GitHub repositories",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":291.0,
        "Challenge_word_count":93,
        "Issue_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hi <a class=\"mention\" href=\"\/u\/dealer56\">@dealer56<\/a>,<\/p>\n<p>I discussed this with some folks, and looks like we already have a <a href=\"https:\/\/img.shields.io\/badge\/Weights_&amp;_Biases-FFCC33?style=for-the-badge&amp;logo=WeightsAndBiases&amp;logoColor=black\" rel=\"noopener nofollow ugc\">badge<\/a> for something like this. You should also be able to generate such badges through <a href=\"http:\/\/shields.io\" rel=\"noopener nofollow ugc\">shields.io<\/a>, and we plan to have a tutorial in the future on how to use badges to present a metric on your repo.<\/p>\n<p>I\u2019ll link the tutorial once it is out.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":9.7,
        "Solution_reading_time":8.21,
        "Solution_score_count":null,
        "Solution_sentence_count":7.0,
        "Solution_word_count":73.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_created_time":1308292969430,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":651.0,
        "Answerer_view_count":99.0,
        "Challenge_adjusted_solved_time":null,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>We're currently working with 3 employees in the same notebook-instance, however, since this is a shared workspace this makes version management extra difficult. Is it possible to link aws credentials to your git account from within SageMaker? Or are there any other ways recommended for version management? <\/p>\n\n<p>Right now we're using a single git account for committing the code from within jupyter terminal. <\/p>",
        "Challenge_closed_time":1.0,
        "Challenge_comment_count":0,
        "Challenge_created_time":1534776705277,
        "Challenge_favorite_count":1.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/51933366",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":9.8,
        "Challenge_reading_time":5.64,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":3.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":null,
        "Challenge_title":"Version management in SageMaker",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":836.0,
        "Challenge_word_count":68,
        "Issue_self_closed":null,
        "Platform":"Stack Overflow",
        "Poster_created_time":1534775846323,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":33.0,
        "Poster_view_count":2.0,
        "Solution_body":"<p>The situation has changed : Git is now <a href=\"https:\/\/aws.amazon.com\/blogs\/machine-learning\/amazon-sagemaker-notebooks-now-support-git-integration-for-increased-persistence-collaboration-and-reproducibility\/\" rel=\"nofollow noreferrer\">available<\/a> in SageMaker<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":40.0,
        "Solution_reading_time":3.78,
        "Solution_score_count":1.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":13.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1530020182168,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"McLean, VA, USA",
        "Answerer_reputation_count":936.0,
        "Answerer_view_count":153.0,
        "Challenge_adjusted_solved_time":null,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I have a Sagemaker notebook that I would like to move to a GitHub repository. I thought perhaps I should download the files locally, then I can easily push to git. But I cannot figure out how to download the folder to my local computer. Then I though, perhaps there is a way using the AWS CLI to move directly from Sagemaker to git? I've made many google searches that are unable to answer my question.<\/p>",
        "Challenge_closed_time":1.0,
        "Challenge_comment_count":0,
        "Challenge_created_time":1591031437107,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/62137347",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":6.3,
        "Challenge_reading_time":5.46,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":4.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":null,
        "Challenge_title":"How to get a Sagemaker notebook onto GitHub?",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":2743.0,
        "Challenge_word_count":83,
        "Issue_self_closed":null,
        "Platform":"Stack Overflow",
        "Poster_created_time":1530020182168,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"McLean, VA, USA",
        "Poster_reputation_count":936.0,
        "Poster_view_count":153.0,
        "Solution_body":"<p>Building off the answer given by @mokugo-devops, I was able to link my existing notebook to my GitHub account.<\/p>\n\n<p>First, I followed the directions posted in the link provided in his answer to set up my GitHub repo with my AWS account on the CLI, then I used the following command to edit my existing notebook:<\/p>\n\n<pre><code>aws sagemaker  update-notebook-instance \\\n--notebook-instance-name &lt;value&gt; \\\n--default-code-repository &lt;saved-github-repo-name-in-AWS&gt;\n<\/code><\/pre>\n\n<p>my notebook instance is now linked my GitHub repo.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":18.7,
        "Solution_reading_time":6.98,
        "Solution_score_count":1.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":73.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1305851487736,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":5993.0,
        "Answerer_view_count":457.0,
        "Challenge_adjusted_solved_time":32.1755194445,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Suppose I run the following commands:<\/p>\n<pre><code># set up DVC\n\nmkdir foo\ncd foo &amp;&amp; git init\ndvc init\ngit add * &amp;&amp; git commit -m &quot;dvc init&quot;\n\n\n# make a data file\n\nmkdir -p bar\/biz\ntouch bar\/biz\/boz\n\n\n# add the data file\n\ndvc add bar\/biz\/boz\n<\/code><\/pre>\n<p>And DVC outputs the following:<\/p>\n<pre><code>To track the changes with git, run:\n\n  git add bar\/biz\/.gitignore bar\/biz\/boz.dvc\n<\/code><\/pre>\n<hr \/>\n<p>This last part is what I would like to avoid.  Preferably, DVC would only change the top level <code>.gitignore<\/code> (located at the project root, where <code>git init<\/code> was executed), and will change only DVC files at the top level.<\/p>\n<p><strong>And here's why:<\/strong><\/p>\n<p>I have a rather large dataset developed in an original work more or less ad-hoc. This data is not systematically organized, nor do I want to organize it as-is.<\/p>\n<p>Instead, I want to incrementally add this old, bespoke data to the DVC directory tree.  And each time I add some of the data to the tree, I want to check it in with DVC as I would if I were modifying code or mixing one project's code into another.<\/p>\n<p>However, DVC wants to create a local file and gitignore at every location I add.  This creates a mess and I have no reasonable faith that it will be easy to maintain all of these atomic and distributed datastores.<\/p>\n<hr \/>\n<p><strong>The question:<\/strong><\/p>\n<p>What is the preferred way to incrementally add data in DVC so that DVC uses the root gitignore and root DVC files\/items?<\/p>",
        "Challenge_closed_time":1.0,
        "Challenge_comment_count":0,
        "Challenge_created_time":1655234204993,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/72622280",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":10.4,
        "Challenge_reading_time":19.3,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":2.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":12,
        "Challenge_solved_time":null,
        "Challenge_title":"How does one add individual files with DVC?",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":112.0,
        "Challenge_word_count":254,
        "Issue_self_closed":null,
        "Platform":"Stack Overflow",
        "Poster_created_time":1405262190020,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Atlanta, GA",
        "Poster_reputation_count":26244.0,
        "Poster_view_count":1383.0,
        "Solution_body":"<p>Assuming bar\/ is the dataset directory you're incrementally adding to, you can instead<\/p>\n<pre><code>dvc add bar\n<\/code><\/pre>\n<p>This creates a bar.dvc file and writes to .gitignore at the top level.<\/p>\n<p>When you update content in bar\/, <code>dvc add<\/code> it again or use <code>dvc commit<\/code> to register the new dataset version. The new files get added to the project cache and the .dvc file gets an updated <code>md5<\/code> hash that identifies to the latest directory structure.<\/p>\n<p>Some docs:<br \/>\n<a href=\"https:\/\/dvc.org\/doc\/start\/data-management#making-changes\" rel=\"nofollow noreferrer\">https:\/\/dvc.org\/doc\/start\/data-management#making-changes<\/a><br \/>\n<a href=\"https:\/\/dvc.org\/doc\/command-reference\/add\" rel=\"nofollow noreferrer\">https:\/\/dvc.org\/doc\/command-reference\/add<\/a><br \/>\n<a href=\"https:\/\/dvc.org\/doc\/user-guide\/project-structure\/internal-files#structure-of-the-cache-directory\" rel=\"nofollow noreferrer\">https:\/\/dvc.org\/doc\/user-guide\/project-structure\/internal-files#structure-of-the-cache-directory<\/a><\/p>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":1655350036863,
        "Solution_link_count":6.0,
        "Solution_readability":16.8,
        "Solution_reading_time":14.03,
        "Solution_score_count":0.0,
        "Solution_sentence_count":12.0,
        "Solution_word_count":89.0,
        "Tool":"DVC"
    },
    {
        "Answerer_created_time":1662022756172,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":46.0,
        "Answerer_view_count":1.0,
        "Challenge_adjusted_solved_time":0.5066644444,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I'm using DVC extension in VScode inside a python project. The problem is that dvc shows files not tracked by dvc in the source control panel! As in the following picture.\nDVC track only data folder and not the src folder. How can I fix it? Have you also encountered these problems?<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/sn8YY.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/sn8YY.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Challenge_closed_time":1.0,
        "Challenge_comment_count":1,
        "Challenge_created_time":1662017466370,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1662021092696,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/73565648",
        "Challenge_link_count":2,
        "Challenge_participation_count":2,
        "Challenge_readability":6.1,
        "Challenge_reading_time":6.65,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":10,
        "Challenge_solved_time":null,
        "Challenge_title":"DVC shows files not tracked in source control in visual studio code",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":39.0,
        "Challenge_word_count":73,
        "Issue_self_closed":null,
        "Platform":"Stack Overflow",
        "Poster_created_time":1580668804396,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":498.0,
        "Poster_view_count":66.0,
        "Solution_body":"<p>The files shown are completely untracked. They are shown in both SCM trees so you can add them to either Git or DVC using inline actions.\nOnce the files are tracked by one of the tools they should only show up under the appropriate tree.<\/p>",
        "Solution_comment_count":2.0,
        "Solution_last_edit_time":1662022916688,
        "Solution_link_count":0.0,
        "Solution_readability":5.6,
        "Solution_reading_time":2.94,
        "Solution_score_count":3.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":45.0,
        "Tool":"DVC"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":null,
        "Challenge_answer_count":0,
        "Challenge_body":"From slack\n\nI am currently defining some machines configuration using machine-env1.yaml, machine-env2.yaml which basically contains node selectors and CPU, GPU, and TPU requests configuration, and then running:\n\npolyaxon run -f polyaxonfile.yaml -f machine-env1.yaml\n\nI have two problems with this approach:\n\nI need to copy the env files to all our git repos, which means if I make a change I need to perform several pull requests\nI need to tell the data-scientits to pull the last commit, sometimes that's not possible because they can not merge\/rebase the changes.\n\nBased on those two issues, in the end we tell data-scientists to just use:\n\nenvironment:\n  nodeSelector:\n    nodes: large-pool\n...\nrun:\n  ...\n  container:\n      resources:\n        limits:\n          cpu: 3000m\n          memory: 6000Mi\n        requests:\n          cpu: 2000m\n          memory: 4000Mi\n\nWhich is error prone and confusing for them, and make the files bigger and difficult to change.\n\nAny elegant way to abstract this type of configuration from the data-scientists?",
        "Challenge_closed_time":1.0,
        "Challenge_comment_count":0,
        "Challenge_created_time":1649336966000,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1484",
        "Challenge_link_count":0,
        "Challenge_participation_count":0,
        "Challenge_readability":11.6,
        "Challenge_reading_time":13.74,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":8,
        "Challenge_solved_time":null,
        "Challenge_title":"I would like to configure Polyaxon in a way to avoid asking data-scientists to configure pre-emptible node-pools or request TPUs on their own",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":null,
        "Challenge_word_count":170,
        "Issue_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"We have already shared a resource on how to configure the environments in this guide\n\nif you are using multiple git repos and you do not want to replicate the yaml files in all repos you can register those files as presets:\n\nUsers will be able to use --presets machine1 or --presets=env1\n\nNote that in the example in that link, it shows that it defines a queue but you do not have to define a queue, a preset is just any YAML file that can be used with the override operator -f main.yaml -f override1.yaml -f override2.yaml in this case override1.yaml and override2.yaml it can be saved as organization presets using the UI.\n\nMore info from the intro section about presets and the UI section\n\nAlso, when you define presets you can use them directly on the operation or component\n\npresets: [preset1, preset2]\n\nThis is similar to the CLI command\n\npolyaxon run -f polyaxon.yaml --presets preset1,preset2",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":8.5,
        "Solution_reading_time":10.83,
        "Solution_score_count":1.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":156.0,
        "Tool":"Polyaxon"
    }
]