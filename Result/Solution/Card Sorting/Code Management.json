[
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":64.6766666667,
        "Challenge_answer_count":0,
        "Challenge_body":"In every run you can see:\r\n```\r\n               2020-07-03 23:24:19,549 DEBUG: Trying to spawn '['\/home\/efiop\/git\/dvc-bench\/envs\/76391772e92136ec87b9940d70226329\/bin\/python', '\r\n\/home\/efiop\/.pyenv\/versions\/3.8.3\/envs\/dvc-3.8.3\/lib\/python3.8\/site-packages\/asv\/benchmark.py', 'daemon', '-q', 'updater']'\r\n               2020-07-03 23:24:19,550 DEBUG: Spawned '['\/home\/efiop\/git\/dvc-bench\/envs\/76391772e92136ec87b9940d70226329\/bin\/python', '\/home\/ef\r\niop\/.pyenv\/versions\/3.8.3\/envs\/dvc-3.8.3\/lib\/python3.8\/site-packages\/asv\/benchmark.py', 'daemon', '-q', 'updater']'\r\n               Unknown mode daemon\r\n```\r\nwe clearly need to take more care on dvc-side, but a good enough workaround is to set CI or DVC_TEST env var to make dvc skip launching the updater.",
        "Challenge_closed_time":1594041670000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1593808834000,
        "Challenge_favorite_count":null,
        "Challenge_gpt_summary_original":"The user needs to rebuild the \"get-started\" feature with the latest DVC version because every DVC command changes the `.gitignore` file, causing inconvenience when switching between branches.",
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/github.com\/iterative\/dvc-bench\/issues\/149",
        "Challenge_link_count":0,
        "Challenge_participation_count":0,
        "Challenge_readability":10.9,
        "Challenge_reading_time":9.95,
        "Challenge_repo_contributor_count":10.0,
        "Challenge_repo_fork_count":9.0,
        "Challenge_repo_issue_count":400.0,
        "Challenge_repo_star_count":19.0,
        "Challenge_repo_watch_count":17.0,
        "Challenge_score_count":0.0,
        "Challenge_self_closed":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":64.6766666667,
        "Challenge_title":"dvc tries to launch updater using asv script",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":null,
        "Challenge_word_count":66,
        "Platform":"Github",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":-15.7,
        "Solution_reading_time":0.0,
        "Solution_score_count":null,
        "Solution_sentence_count":1.0,
        "Solution_word_count":0.0,
        "Tool":"DVC"
    },
    {
        "Answerer_created_time":1631019482980,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":234.0,
        "Answerer_view_count":155.0,
        "Challenge_adjusted_solved_time":25.0813055556,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>Goal: <code>add<\/code> <code>commit<\/code> <code>push<\/code> all contents of <code>project_model\/data\/<\/code> to <strong>dvcstore<\/strong>.<\/p>\n<p>I don't have any <code>.dvc<\/code> files in my project.<\/p>\n<pre><code>$ dvc add .\/project_model\/data\/\nERROR: Cannot add '\/home\/me\/PycharmProjects\/project\/project_model\/data\/images', because it is overlapping with other DVC tracked output: '\/home\/me\/PycharmProjects\/project\/project_model\/data'.\nTo include '\/home\/me\/PycharmProjects\/project\/project_model\/data\/images' in '\/home\/me\/PycharmProjects\/project\/project_model\/data', run 'dvc commit project_model\/data.dvc'\n\n$ dvc commit project_model\/data.dvc\nERROR: failed to commit project_model\/data.dvc - 'project_model\/data.dvc' does not exist\n<\/code><\/pre>\n<p>I've deleted contents from <code>.dvc\/cache\/<\/code> and <strong>S3<\/strong> <code>s3:\/\/foo\/bar\/dvcstore\/<\/code>, with no luck.<\/p>\n<hr \/>\n<pre><code>$ dvc -V\n2.10.2\n<\/code><\/pre>\n<pre><code>$ dvc doctor\nDVC version: 2.10.2 (pip)\n---------------------------------\nPlatform: Python 3.9.12 on Linux-5.15.0-47-generic-x86_64-with-glibc2.35\nSupports:\n        webhdfs (fsspec = 2022.5.0),\n        http (aiohttp = 3.8.1, aiohttp-retry = 2.5.2),\n        https (aiohttp = 3.8.1, aiohttp-retry = 2.5.2),\n        s3 (s3fs = 2022.5.0, boto3 = 1.21.21)\nCache types: hardlink, symlink\nCache directory: ext4 on \/dev\/nvme0n1p5\nCaches: local\nRemotes: s3\nWorkspace directory: ext4 on \/dev\/nvme0n1p5\nRepo: dvc, git\n<\/code><\/pre>\n<p>Please let me know if there's anything else I can add to post.<\/p>",
        "Challenge_closed_time":1663149911323,
        "Challenge_comment_count":0,
        "Challenge_created_time":1663059618623,
        "Challenge_favorite_count":0.0,
        "Challenge_gpt_summary_original":"The user is encountering an error while trying to add, commit, and push the contents of a folder to dvcstore. The error message indicates that the folder is overlapping with other DVC tracked output. The user has tried deleting contents from .dvc\/cache and S3 but the issue persists. The post includes the DVC version and doctor output for reference.",
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/73700203",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":11.8,
        "Challenge_reading_time":21.01,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_closed":1.0,
        "Challenge_sentence_count":23,
        "Challenge_solved_time":25.0813055556,
        "Challenge_title":"ERROR: Cannot add 'folder-path', because it is overlapping with other DVC tracked output:",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":31.0,
        "Challenge_word_count":154,
        "Platform":"Stack Overflow",
        "Poster_created_time":1631019482980,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":234.0,
        "Poster_view_count":155.0,
        "Solution_body":"<p>In my case, the problem was in <code>dvc.yaml<\/code>.<\/p>\n<p>For a few <code>stages<\/code>, I had cyclical dependencies, where a file-path was mentioned in both the <code>deps<\/code> and <code>outs<\/code>.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":7.4,
        "Solution_reading_time":2.73,
        "Solution_score_count":0.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":27.0,
        "Tool":"DVC"
    },
    {
        "Answerer_created_time":1308292969430,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":651.0,
        "Answerer_view_count":99.0,
        "Challenge_adjusted_solved_time":2443.6834486111,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>We're currently working with 3 employees in the same notebook-instance, however, since this is a shared workspace this makes version management extra difficult. Is it possible to link aws credentials to your git account from within SageMaker? Or are there any other ways recommended for version management? <\/p>\n\n<p>Right now we're using a single git account for committing the code from within jupyter terminal. <\/p>",
        "Challenge_closed_time":1543573965692,
        "Challenge_comment_count":0,
        "Challenge_created_time":1534776705277,
        "Challenge_favorite_count":1.0,
        "Challenge_gpt_summary_original":"The user is facing challenges with version management in SageMaker while working with three employees in the same notebook-instance. They are looking for ways to link AWS credentials to their git account or any other recommended methods for version management. Currently, they are using a single git account for committing the code from within the Jupyter terminal.",
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/51933366",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":9.8,
        "Challenge_reading_time":5.64,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":3.0,
        "Challenge_self_closed":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":2443.6834486111,
        "Challenge_title":"Version management in SageMaker",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":836.0,
        "Challenge_word_count":68,
        "Platform":"Stack Overflow",
        "Poster_created_time":1534775846323,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":33.0,
        "Poster_view_count":2.0,
        "Solution_body":"<p>The situation has changed : Git is now <a href=\"https:\/\/aws.amazon.com\/blogs\/machine-learning\/amazon-sagemaker-notebooks-now-support-git-integration-for-increased-persistence-collaboration-and-reproducibility\/\" rel=\"nofollow noreferrer\">available<\/a> in SageMaker<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":40.0,
        "Solution_reading_time":3.78,
        "Solution_score_count":1.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":13.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":0.4736111111,
        "Challenge_answer_count":0,
        "Challenge_body":"> From https:\/\/github.com\/iterative\/dvc.org\/issues\/1743#issuecomment-730726776\r\n\r\n```console\r\n$ git@github.com:iterative\/example-get-started.git\r\n...\r\n$ cd example-get-started\r\n$ dvc fetch\r\nERROR: failed to fetch data from the cloud - Lockfile 'dvc.lock' is corrupted.\r\n```",
        "Challenge_closed_time":1606074573000,
        "Challenge_comment_count":7,
        "Challenge_created_time":1606072868000,
        "Challenge_favorite_count":null,
        "Challenge_gpt_summary_original":"The user is facing an issue where DVC and Git services are not detecting the root directory of the repository correctly. They assume that the current working directory is where they can find the `.git` and `.dvc` directories, which affects their logic to automatically initialize DVC on behalf of the user. The user suggests detecting the correct paths to resolve the issue. Relevant resources have been provided for further information.",
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/github.com\/iterative\/example-repos-dev\/issues\/17",
        "Challenge_link_count":1,
        "Challenge_participation_count":7,
        "Challenge_readability":16.4,
        "Challenge_reading_time":4.1,
        "Challenge_repo_contributor_count":17.0,
        "Challenge_repo_fork_count":11.0,
        "Challenge_repo_issue_count":154.0,
        "Challenge_repo_star_count":15.0,
        "Challenge_repo_watch_count":14.0,
        "Challenge_score_count":0.0,
        "Challenge_self_closed":1.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":0.4736111111,
        "Challenge_title":"example-get-started is broken with latest DVC",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":null,
        "Challenge_word_count":26,
        "Platform":"Github",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"What DVC version do you use? It should be be fixed in the most recent one. 1.9.1 on Windows (latest) the latest version is 1.10 something. if it's not updated on Windows then we have a problem with Win releases cc @efiop  Ah I was wrong, you're right. Works with 1.10.1 which I got from https:\/\/github.com\/iterative\/dvc\/releases\/\r\n\r\nThe problem is that the dvc.org home page download button is stuck at 1.9.1 for all platforms, it seems. Opened iterative\/dvc.org\/issues\/1964, resolving here. I use the latest dvc version [DVC version: 1.11.16 (pip)] and have got the same issue while following the [installation](https:\/\/github.com\/iterative\/example-get-started) steps:\r\nOS: Mac OS Mojave 10.14.6\r\n```\r\n$ dvc pull\r\nEverything is up to date.                                             \r\nERROR: failed to pull data from the cloud - Lockfile 'dvc.lock' is corrupted.\r\n``` @yakushechkin example-get-started is migrating to dvc 2.0, so it is no longer compatible with older dvc versions. We plan on releasing 2.0 on Wednesday. You could try `pip install --pre dvc` to install dvc pre-release. Sorry for the inconvenience.",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":5.0,
        "Solution_reading_time":13.16,
        "Solution_score_count":null,
        "Solution_sentence_count":22.0,
        "Solution_word_count":163.0,
        "Tool":"DVC"
    },
    {
        "Answerer_created_time":1294388296987,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Italy",
        "Answerer_reputation_count":32174.0,
        "Answerer_view_count":3457.0,
        "Challenge_adjusted_solved_time":1.2159166667,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I use Azure Machine Learning Workspace Notebooks, connected to a DevOps Repository - using terminal git commands to manage my code. I work on different branches, often has to switch back and forth between them.<\/p>\n<p>I reviewed this thread before: <a href=\"https:\/\/stackoverflow.com\/questions\/18615428\/switching-branches-keeps-new-files-from-other-branch\">switching branches keeps new files from other branch<\/a><\/p>\n<p>In my case it does not only keep the files that should be ignored with the use of the gitignore file, but others too.<\/p>\n<p>I tested it with a totally empty branch, that should not have any files in it, checked it out, and it still has files from the branch that I worked with previously. When I check it manually on DevOps, in the repo, the empty branch is actually empty there.<\/p>\n<p>Has anyone seen similar issues?<\/p>",
        "Challenge_closed_time":1622721091067,
        "Challenge_comment_count":2,
        "Challenge_created_time":1622716713767,
        "Challenge_favorite_count":0.0,
        "Challenge_gpt_summary_original":"The user is encountering an issue while using Azure Machine Learning Workspace Notebooks connected to a DevOps Repository. They are switching between different branches but are facing a problem where some files from another branch are being kept even though they should be ignored with the use of the gitignore file. The user has tested it with an empty branch, but it still has files from the previous branch. They are seeking help to resolve this issue.",
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/67819912",
        "Challenge_link_count":1,
        "Challenge_participation_count":3,
        "Challenge_readability":8.8,
        "Challenge_reading_time":11.63,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_closed":0.0,
        "Challenge_sentence_count":8,
        "Challenge_solved_time":1.2159166667,
        "Challenge_title":"Azure ML, DevOps: Switching between branches keeps some files from another branch",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":189.0,
        "Challenge_word_count":137,
        "Platform":"Stack Overflow",
        "Poster_created_time":1438890950452,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Nordhavnen, Copenhagen, Denmark",
        "Poster_reputation_count":570.0,
        "Poster_view_count":187.0,
        "Solution_body":"<p>Some files that are tracked in a branch could be not tracked in another. So when you switch back to the &quot;non tracking&quot; branch, that files remain in the file system. Git does not clean stuff that does not track directly. Do not exchange the term not tracked by ignored. Files are not tracked until we &quot;add&quot; them in stage and commit.\nYou could cleanup the working git by running <code>git clean -f -d<\/code><\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":3.4,
        "Solution_reading_time":5.27,
        "Solution_score_count":1.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":74.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":64.4975,
        "Challenge_answer_count":0,
        "Challenge_body":"**Describe the bug**\r\n\r\nAt model train completion, the test set loss is written as iteration 0 to the TensorBoard \/ W&B chart `validation\/lm_loss`, and the test set perplexity is written as iteration 0 to the chart `validation\/lm_loss_ppl`. As the validation loss and perplexity has already been written to this chart, this results in TensorBoard deleting all the validation metrics, overwriting them with the test loss and perplexity values. W&B refuses to add the test metrics to the charts at all, throwing a warning that looks like `wandb: WARNING Step must only increase in log calls.  Step 0 < 32000; dropping {'validation\/lm_loss': 1.715476632118225}.`\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Pip install and setup TensorBoard and W&B\r\n2. Begin training a model with a train, validation, and test set\r\n3. Observe in both TensorBoard and W&B that validation metrics are being logged\r\n4. Allow the model to train to completion\r\n5. Observe that the TensorBoard validation metrics are now gone, overwritten by the test set metrics\r\n6. Observe the W&B error in the text logs \/ program output\r\n\r\n**Expected behavior**\r\nTest metrics should be written to their own charts.\r\n\r\n**Proposed solution**\r\nTest loss and perplexity should be written to their own charts `test\/lm_loss` and `test\/lm_loss_ppl` respectively.\r\n\r\n**Screenshots**\r\n![image](https:\/\/user-images.githubusercontent.com\/6119143\/189752970-3b26dd14-475f-48cb-be84-fae23a99ba10.png)\r\n\r\n**Environment (please complete the following information):**\r\n - GPUs: 4x A100 80 GB\r\n- Configs: (configs that I used to reproduce the bug and test bug fixes are included below)\r\n\r\n```\r\n# GPT-2 pretraining setup\r\n{\r\n   # parallelism settings ( you will want to change these based on your cluster setup, ideally scheduling pipeline stages\r\n   # across the node boundaries )\r\n   \"pipe-parallel-size\": 1,\r\n   \"model-parallel-size\": 1,\r\n\r\n   # model settings\r\n   \"num-layers\": 24,\r\n   \"hidden-size\": 1024,\r\n   \"num-attention-heads\": 16,\r\n   \"seq-length\": 4096,\r\n   \"max-position-embeddings\": 4096,\r\n   \"norm\": \"layernorm\",\r\n   \"pos-emb\": \"rotary\",\r\n   \"no-weight-tying\": true,\r\n\r\n   # these should provide some speedup but takes a while to build, set to true if desired\r\n   \"scaled-upper-triang-masked-softmax-fusion\": false,\r\n   \"bias-gelu-fusion\": false,\r\n\r\n\r\n\r\n   # optimizer settings\r\n   \"optimizer\": {\r\n     \"type\": \"Adam\",\r\n     \"params\": {\r\n       \"lr\": 0.00003,\r\n       \"betas\": [0.9, 0.999],\r\n       \"eps\": 1.0e-8,\r\n     }\r\n   },\r\n   \"zero_optimization\": {\r\n    \"stage\": 1,\r\n    \"allgather_partitions\": True,\r\n    \"allgather_bucket_size\": 500000000,\r\n    \"overlap_comm\": True,\r\n    \"reduce_scatter\": True,\r\n    \"reduce_bucket_size\": 500000000,\r\n    \"contiguous_gradients\": True,\r\n    \"cpu_offload\": False\r\n  },\r\n   # batch \/ data settings\r\n   \"train_micro_batch_size_per_gpu\": 16,\r\n   \"data-impl\": \"mmap\",\r\n   \"split\": \"949,50,1\",\r\n\r\n   # activation checkpointing\r\n   \"checkpoint-activations\": true,\r\n   \"checkpoint-num-layers\": 1,\r\n   \"partition-activations\": true,\r\n   \"synchronize-each-layer\": true,\r\n\r\n   # regularization\r\n   \"gradient_clipping\": 1.0,\r\n   \"weight-decay\": 0.01,\r\n   \"hidden-dropout\": 0,\r\n   \"attention-dropout\": 0,\r\n\r\n   # precision settings\r\n   \"fp16\": {\r\n     \"fp16\": true,\r\n     \"enabled\": true,\r\n     \"loss_scale\": 0,\r\n     \"loss_scale_window\": 1000,\r\n     \"hysteresis\": 2,\r\n     \"min_loss_scale\": 1\r\n   },\r\n\r\n   # misc. training settings\r\n   \"train-iters\": 100,\r\n   \"lr-decay-iters\": 100,\r\n   \"distributed-backend\": \"nccl\",\r\n   \"lr-decay-style\": \"constant\",\r\n   \"warmup\": 0.1,\r\n   \"save-interval\": 25,\r\n   \"eval-interval\": 25,\r\n   \"eval-iters\": 10,\r\n\r\n   # Checkpoint\r\n   \"finetune\": true,\r\n\r\n   # logging\r\n   \"log-interval\": 10,\r\n   \"steps_per_print\": 10,\r\n   \"keep-last-n-checkpoints\": 4,\r\n   \"wall_clock_breakdown\": true,\r\n}\r\n```\r\n\r\n```\r\n# Suggested data paths when using GPT-NeoX locally\r\n{\r\n  \"train-data-paths\": [\"\/mnt\/4TBNVME\/gpt-neox\/data\/preprocessed\/train_text_document\"],\r\n  \"test-data-paths\": [\"\/mnt\/4TBNVME\/gpt-neox\/data\/preprocessed\/test_text_document\"],\r\n  \"valid-data-paths\": [\"\/mnt\/4TBNVME\/gpt-neox\/data\/preprocessed\/val_text_document\"],\r\n\r\n  \"vocab-file\": \"\/mnt\/4TBNVME\/gpt-neox\/data\/gpt2-vocab.json\",\r\n  \"merge-file\": \"\/mnt\/4TBNVME\/gpt-neox\/data\/gpt2-merges.txt\",\r\n\r\n  \"save\": \"\/mnt\/4TBNVME\/checkpoints_test\",\r\n  \"load\": \"\/mnt\/4TBNVME\/checkpoints_test\",\r\n\r\n  \"checkpoint_validation_with_forward_pass\": False,\r\n  \r\n  \"tensorboard-dir\": \"\/mnt\/4TBNVME\/logs\/tensorboard\/bug_fix_test\",\r\n  \"log-dir\": \"\/mnt\/4TBNVME\/logs\/gptneox\/bug_fix_test\",\r\n\r\n  \"use_wandb\": True,\r\n  \"wandb_host\": \"https:\/\/api.wandb.ai\",\r\n  \"wandb_project\": \"neox_test\"\r\n}\r\n```\r\n\r\n```\r\n# Add this to your config for sparse attention every other layer\r\n{\r\n  \"attention_config\": [[[\"local\", \"global\"], \"all\"]],\r\n\r\n  # sparsity config:\r\n  # (these are the defaults for local sliding window sparsity, training will work without this here, but it's left in for\r\n  # illustrative purposes)\r\n  # see https:\/\/www.deepspeed.ai\/tutorials\/sparse-attention\/#how-to-config-sparsity-structures for\r\n  # more detailed config instructions and available parameters\r\n\r\n  \"sparsity_config\": {\r\n    \"block\": 16, # block size\r\n    \"num_local_blocks\": 32,\r\n  }\r\n}\r\n```\r\n\r\n**Additional context**\r\n\r\nI have a bug fix ready, will follow up with it.",
        "Challenge_closed_time":1663248037000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1663015846000,
        "Challenge_favorite_count":null,
        "Challenge_gpt_summary_original":"The user is facing an issue where the wandb API key is not configured for GitHub CI.",
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/github.com\/EleutherAI\/gpt-neox\/issues\/669",
        "Challenge_link_count":3,
        "Challenge_participation_count":0,
        "Challenge_readability":16.2,
        "Challenge_reading_time":63.87,
        "Challenge_repo_contributor_count":44.0,
        "Challenge_repo_fork_count":385.0,
        "Challenge_repo_issue_count":712.0,
        "Challenge_repo_star_count":2929.0,
        "Challenge_repo_watch_count":75.0,
        "Challenge_score_count":0.0,
        "Challenge_self_closed":0.0,
        "Challenge_sentence_count":25,
        "Challenge_solved_time":64.4975,
        "Challenge_title":"Test set metrics overwrite validation set metrics in TensorBoard and are rejected for logging by Weights and Biases (W&B)",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":null,
        "Challenge_word_count":522,
        "Platform":"Github",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":-15.7,
        "Solution_reading_time":0.0,
        "Solution_score_count":null,
        "Solution_sentence_count":1.0,
        "Solution_word_count":0.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_created_time":1427953176670,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":145.0,
        "Answerer_view_count":13.0,
        "Challenge_adjusted_solved_time":14.9208969444,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I'm having problems pushing files with DVC to DAGsHub.<\/p>\n<p>Workflow:<\/p>\n<ul>\n<li>I used my email to signup to DAGsHub.<\/li>\n<li>I created a repo and clone it to my computer.<\/li>\n<li>I added files to the repo and track them using DVC and Git to track the pointer files.<\/li>\n<li>Running DVC push -r origin, it asks me for my password. When I enter the password and hit enter - nothing happens.<\/li>\n<\/ul>\n<p>It sits and waits, barring me from even canceling the operation with Ctrl+C.\nI'm forced to manually close the terminal, open a new one, ending the &quot;Python&quot; process in task manager and delete the lock file in .dvc\/tmp\/lock.<\/p>",
        "Challenge_closed_time":1620591578072,
        "Challenge_comment_count":2,
        "Challenge_created_time":1620537862843,
        "Challenge_favorite_count":0.0,
        "Challenge_gpt_summary_original":"The user is facing issues while pushing files with DVC to DAGsHub. The Git bash command prompt hangs when the user runs DVC push -r origin, and it asks for a password. However, when the user enters the password and hits enter, nothing happens, and the operation cannot be canceled with Ctrl+C. The user is forced to manually close the terminal, end the \"Python\" process in task manager, and delete the lock file in .dvc\/tmp\/lock.",
        "Challenge_last_edit_time":1620625906412,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/67454531",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":6.0,
        "Challenge_reading_time":8.8,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":5.0,
        "Challenge_self_closed":0.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":14.9208969444,
        "Challenge_title":"Git bash command prompt hanging when running dvc push to DAGsHub",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":254.0,
        "Challenge_word_count":117,
        "Platform":"Stack Overflow",
        "Poster_created_time":1620537484800,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":53.0,
        "Poster_view_count":2.0,
        "Solution_body":"<p><strong>Short answer<\/strong><\/p>\n<p>Do not use <code>ask_password<\/code>.\nInstead, save your token in the local config by running once:<\/p>\n<pre><code>dvc remote modify origin --local --unset ask_password\ndvc remote modify origin --local password &lt;--access token--&gt;\n<\/code><\/pre>\n<p><code>dvc push -r origin<\/code> should work then.<\/p>\n<p><strong>Long answer<\/strong><\/p>\n<p><a href=\"https:\/\/www.atlassian.com\/git\/tutorials\/git-bash#:%7E:text=What%20is%20Git%20Bash%3F,operating%20system%20through%20written%20commands.\" rel=\"nofollow noreferrer\">Git Bash<\/a> is not running the regular Windows command prompt but an emulated Unix-style bash prompt. From the information in your question, I cannot know for sure, but this is probably causing the <code>msvcrt<\/code> package used by DVC to prompt the password on windows machines to fail\/hang.<\/p>\n<p>There are potentially 3 ways to deal with the issue:<\/p>\n<ol>\n<li>Run <code>dvc pull<\/code> from the regular Windows cmd prompt.<\/li>\n<li>Find a way to make Git Bash wrap Python calls with <code>winpty<\/code> - I am not 100% positive about how to do this, but not using <code>winpty<\/code> seems to be the reason <code>msvcrt<\/code> fails at prompting for your password.<\/li>\n<li>The simplest solution - Do not use <code>ask_password<\/code>.\nInstead, save your token in the local config by running once:\n<pre><code>dvc remote modify origin --local --unset ask_password\ndvc remote modify origin --local password &lt;--access token--&gt;\n<\/code><\/pre>\nYou can get your access token by clicking on the question mark beside the DVC\nremote of your DAGsHub repository, then click on &quot;Reveal my token&quot;.<\/li>\n<\/ol>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":13.6,
        "Solution_reading_time":21.52,
        "Solution_score_count":4.0,
        "Solution_sentence_count":9.0,
        "Solution_word_count":211.0,
        "Tool":"DVC"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":24.5525,
        "Challenge_answer_count":0,
        "Challenge_body":"Hi. I just upgraded to pycaret 2.1. When I ran the compare_models function with the Titanic dataset, I got the following error:\r\n\r\nMlflowException: Unable to map 'np.object' type to MLflow DataType. np.object canbe mapped iff all values have identical data type which is one of (string, (bytes or byterray),  int, float)\r\n\r\nThe same code worked fine in pycaret 2.0.",
        "Challenge_closed_time":1598806653000,
        "Challenge_comment_count":9,
        "Challenge_created_time":1598718264000,
        "Challenge_favorite_count":null,
        "Challenge_gpt_summary_original":"The user is experiencing deployment issues with MLflow 1.13 and suspects that it may have caused a problem with their AzureML example. They have shared a link to their GitHub repository and a related pull request.",
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/github.com\/pycaret\/pycaret\/issues\/566",
        "Challenge_link_count":0,
        "Challenge_participation_count":9,
        "Challenge_readability":6.9,
        "Challenge_reading_time":4.83,
        "Challenge_repo_contributor_count":93.0,
        "Challenge_repo_fork_count":1518.0,
        "Challenge_repo_issue_count":2643.0,
        "Challenge_repo_star_count":6633.0,
        "Challenge_repo_watch_count":124.0,
        "Challenge_score_count":0.0,
        "Challenge_self_closed":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":24.5525,
        "Challenge_title":"Compare models MLFlowException",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":null,
        "Challenge_word_count":61,
        "Platform":"Github",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"@sagarnildass Hi, Thanks for reporting. This seems like an error from `MLFlow`. I tried to reproduce this out of `pycaret` and I was successful. See below code that throws an error:\r\n\r\n```\r\nimport pandas as pd\r\ndata = pd.read_csv('titanic.csv') #train data from Kaggle\r\nfrom mlflow.models.signature import infer_signature\r\ninfer_signature(data)\r\n```\r\nThis gives the following error:\r\nMlflowException: Unable to map 'np.object' type to MLflow DataType. np.object canbe mapped iff all values have identical data type which is one of (string, (bytes or byterray),  int, float).\r\n\r\nI will log an issue on MLFlow GitHub.\r\n\r\nHere is the issue I logged on MLFlow: https:\/\/github.com\/mlflow\/mlflow\/issues\/3362 Hey\r\n\r\nThanks for the quick reply. \r\n\r\nI found out that presence of null values are a problem. If the dataset contains null values, this error was raised. When I imputed the null values, this problem was solved. Can you also mention this when you log this issue?\r\n\r\nThanks! @sagarnildass Thanks. I have added that in my issue but I don't think so it's 100% True. I have worked with few missing datasets and it worked okay. For example, the `hepatitis` dataset on our repo works fine. Example code:\r\n\r\n```\r\nfrom pycaret.datasets import get_data\r\ndata = get_data('hepatitis')\r\nfrom pycaret.classification import *\r\ns = setup(data, target = 'Class', log_experiment=True, experiment_name = 'hepatitis1')\r\n```\r\n\r\nThis dataset has missing values but it just worked fine. \r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/58118658\/91642055-41991700-e9f6-11ea-9b6f-0f42a86401d9.png)\r\n\r\nCan you investigate more and add your comments on the original issue here: https:\/\/github.com\/mlflow\/mlflow\/issues\/3362\r\n\r\nThanks a lot for helping. @Yard1 I don't know how soon `MLFLow` will be able to fix this but in `2.2` we will have to create some kind of exceptions under `logging_param` chunks to not fail the process even when `infer_signature` fails, as it's not mandatory and has no impact other than the signature file that gets generated under `model` directory when `log_experiment` is set to `True`. @pycaret : I believe object datatypes are a problem. It clearly states: \"np.object canbe mapped iff all values have identical data type which is one of (string, (bytes or byterray), int, float)\". So do you think null values in a object datatype column might be the root  problem here? Because in hepatitis data, all the columns are numeric. @pycaret If we get MLFlow logging into a function then it will be easy to wrap it into a try except block.  @sagarnildass Thanks again for reporting. I am planning to do a bug fix release tomorrow `2.1.1`. For now, I have wrapped this inside `try` and `except` clause to avoid the error. I have tested it on the titanic dataset.\r\n\r\nCan you please sync the `master` and try to see if you can reproduce the error now?\r\n\r\nThanks Done...it's working as expected. @sagarnildass Thanks. I will publish the `2.1.1.` release today. @Yard1 FYI.\r\n\r\nThanks for your help @sagarnildass ",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":3.0,
        "Solution_readability":6.6,
        "Solution_reading_time":36.65,
        "Solution_score_count":null,
        "Solution_sentence_count":39.0,
        "Solution_word_count":449.0,
        "Tool":"MLflow"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":0.0855555556,
        "Challenge_answer_count":0,
        "Challenge_body":"From slack\n\nI am currently defining some machines configuration using machine-env1.yaml, machine-env2.yaml which basically contains node selectors and CPU, GPU, and TPU requests configuration, and then running:\n\npolyaxon run -f polyaxonfile.yaml -f machine-env1.yaml\n\nI have two problems with this approach:\n\nI need to copy the env files to all our git repos, which means if I make a change I need to perform several pull requests\nI need to tell the data-scientits to pull the last commit, sometimes that's not possible because they can not merge\/rebase the changes.\n\nBased on those two issues, in the end we tell data-scientists to just use:\n\nenvironment:\n  nodeSelector:\n    nodes: large-pool\n...\nrun:\n  ...\n  container:\n      resources:\n        limits:\n          cpu: 3000m\n          memory: 6000Mi\n        requests:\n          cpu: 2000m\n          memory: 4000Mi\n\nWhich is error prone and confusing for them, and make the files bigger and difficult to change.\n\nAny elegant way to abstract this type of configuration from the data-scientists?",
        "Challenge_closed_time":1649337274000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1649336966000,
        "Challenge_favorite_count":null,
        "Challenge_gpt_summary_original":"The user is facing challenges in configuring Polyaxon for their data scientists. They are currently using machine-env files to define node selectors and CPU, GPU, and TPU requests configuration, but this approach requires copying the files to all git repos and telling data scientists to pull the last commit. As a result, they are looking for a more elegant way to abstract this type of configuration from the data scientists.",
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1484",
        "Challenge_link_count":0,
        "Challenge_participation_count":0,
        "Challenge_readability":11.6,
        "Challenge_reading_time":13.74,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_closed":1.0,
        "Challenge_sentence_count":8,
        "Challenge_solved_time":0.0855555556,
        "Challenge_title":"I would like to configure Polyaxon in a way to avoid asking data-scientists to configure pre-emptible node-pools or request TPUs on their own",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":null,
        "Challenge_word_count":170,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"We have already shared a resource on how to configure the environments in this guide\n\nif you are using multiple git repos and you do not want to replicate the yaml files in all repos you can register those files as presets:\n\nUsers will be able to use --presets machine1 or --presets=env1\n\nNote that in the example in that link, it shows that it defines a queue but you do not have to define a queue, a preset is just any YAML file that can be used with the override operator -f main.yaml -f override1.yaml -f override2.yaml in this case override1.yaml and override2.yaml it can be saved as organization presets using the UI.\n\nMore info from the intro section about presets and the UI section\n\nAlso, when you define presets you can use them directly on the operation or component\n\npresets: [preset1, preset2]\n\nThis is similar to the CLI command\n\npolyaxon run -f polyaxon.yaml --presets preset1,preset2",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":8.5,
        "Solution_reading_time":10.83,
        "Solution_score_count":1.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":156.0,
        "Tool":"Polyaxon"
    },
    {
        "Answerer_created_time":1314097464768,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Warsaw, Poland",
        "Answerer_reputation_count":11056.0,
        "Answerer_view_count":544.0,
        "Challenge_adjusted_solved_time":0.0373211111,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>In <a href=\"https:\/\/neptune.ml\/\" rel=\"nofollow noreferrer\">Neptune<\/a> (this machine learning experiment tracker) is it possible to make it git-aware? I mean - using <code>.gitignore<\/code> for excluded files and saving commit hashes for each run?<\/p>\n\n<p>In particular, when I review an already finished job, can I go directly to GitHub commit?<\/p>",
        "Challenge_closed_time":1503919410423,
        "Challenge_comment_count":0,
        "Challenge_created_time":1495124614783,
        "Challenge_favorite_count":0.0,
        "Challenge_gpt_summary_original":"The user is inquiring about the possibility of making Neptune, a machine learning experiment tracker, git-aware. They want to know if they can use .gitignore for excluded files and save commit hashes for each run. Additionally, they want to know if they can go directly to the GitHub commit when reviewing a finished job.",
        "Challenge_last_edit_time":1503919276067,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/44053141",
        "Challenge_link_count":1,
        "Challenge_participation_count":2,
        "Challenge_readability":7.9,
        "Challenge_reading_time":4.85,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_closed":1.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":2442.9987888889,
        "Challenge_title":"Can I make Neptune talk to git?",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":140.0,
        "Challenge_word_count":53,
        "Platform":"Stack Overflow",
        "Poster_created_time":1314097464768,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Warsaw, Poland",
        "Poster_reputation_count":11056.0,
        "Poster_view_count":544.0,
        "Solution_body":"<p>Starting form version 2.0 Neptune provides integration with git, see: <a href=\"https:\/\/docs.neptune.ml\/advanced-topics\/git-integration\/\" rel=\"nofollow noreferrer\">https:\/\/docs.neptune.ml\/advanced-topics\/git-integration\/<\/a>.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":28.7,
        "Solution_reading_time":3.2,
        "Solution_score_count":0.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":14.0,
        "Tool":"Neptune"
    },
    {
        "Answerer_created_time":1614873430827,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":169.0,
        "Answerer_view_count":7.0,
        "Challenge_adjusted_solved_time":0.3104436111,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I'm in a team using dvc with git to version-control data files. We are using dvc 1.3.1, with the an S3 bucket remote. I'm getting this error when executing <code>dvc fetch<\/code> or <code>dvc pull<\/code> on a colleague's branch:<\/p>\n<pre><code>ERROR: failed to fetch data from the cloud - DVC-file 'C:\\Users\\blah\\Documents\\repo\\data\\processed_data.dvc' format error: extra keys not allowed @ data['outs'][0]['size']\n<\/code><\/pre>\n<p>When I check the dvc file for a cached file with which I have no problem I see this:<\/p>\n<pre><code>md5: ded591aacbe363f0518ceb9c3bc1836b\nouts:\n- md5: efdab20e8b59903b9523cc188ff727e5\n  path: completion_header.p\n  cache: true\n  metric: false\n  persist: false\n<\/code><\/pre>\n<p>but a problematic file only has this:<\/p>\n<pre><code>outs:\n- md5: f4e15187d9a0bbb328e629eabd8d1784.dir\n  size: 112007\n  nfiles: 3\n  path: processed_data\n<\/code><\/pre>\n<p>In all cases, files are added to dvc with the command <code>dvc add %dirname%<\/code>. This is the second time I've seen this on a colleague's branch (2 different people).<\/p>\n<p>Since posting, I have realized that my colleague dvc'd a directory. I have attempted creating the directory first, then calling <code>dvc fetch<\/code>, but get the same error.<\/p>",
        "Challenge_closed_time":1618566517710,
        "Challenge_comment_count":0,
        "Challenge_created_time":1618565400113,
        "Challenge_favorite_count":0.0,
        "Challenge_gpt_summary_original":"The user is encountering an error while using DVC with Git to version-control data files. The error occurs when executing \"dvc fetch\" or \"dvc pull\" on a colleague's branch, and the error message indicates a DVC-file format error. The problematic file has incomplete information in comparison to a cached file that is working fine. The files are added to DVC with the command \"dvc add %dirname%\". The user has attempted creating the directory first, but the error persists.",
        "Challenge_last_edit_time":1618826341416,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/67122683",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":9.1,
        "Challenge_reading_time":15.85,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":2.0,
        "Challenge_self_closed":0.0,
        "Challenge_sentence_count":11,
        "Challenge_solved_time":0.3104436111,
        "Challenge_title":"DVC Files Incomplete",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":548.0,
        "Challenge_word_count":164,
        "Platform":"Stack Overflow",
        "Poster_created_time":1348150034832,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Glasgow, UK",
        "Poster_reputation_count":2400.0,
        "Poster_view_count":263.0,
        "Solution_body":"<blockquote>\n<p>In all cases, files are added to dvc with the command dvc add %filename%.<\/p>\n<\/blockquote>\n<p>It seems like there is a high chance that one of the dvc files created in newer versions of dvc and you are trying to operate with an older version. Are all of your colleagues use the same dvc version when adding new files?<\/p>",
        "Solution_comment_count":4.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":7.6,
        "Solution_reading_time":4.1,
        "Solution_score_count":2.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":60.0,
        "Tool":"DVC"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":94.8744444444,
        "Challenge_answer_count":0,
        "Challenge_body":"load_dataset function from hugging face can't access the dvc tracked data directory \r\n--> OSError: [Errno 30] Read-only file system: '\/data'",
        "Challenge_closed_time":1642070875000,
        "Challenge_comment_count":1,
        "Challenge_created_time":1641729327000,
        "Challenge_favorite_count":null,
        "Challenge_gpt_summary_original":"The user is facing an issue with the \"dvc-cc init\" command as it only takes the first three letters of the repository name for the DVC folder name. The user is also prompted to enter the remote DVC folder and username for accessing the DVC storage server.",
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/github.com\/johannespischinger\/senti_anal\/issues\/11",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":10.1,
        "Challenge_reading_time":2.07,
        "Challenge_repo_contributor_count":2.0,
        "Challenge_repo_fork_count":0.0,
        "Challenge_repo_issue_count":95.0,
        "Challenge_repo_star_count":2.0,
        "Challenge_repo_watch_count":1.0,
        "Challenge_score_count":0.0,
        "Challenge_self_closed":1.0,
        "Challenge_sentence_count":2,
        "Challenge_solved_time":94.8744444444,
        "Challenge_title":"data loading bug with dvc",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":null,
        "Challenge_word_count":23,
        "Platform":"Github",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"What command are you using? Note `\/data` is not same as `.\/data`",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":2.1,
        "Solution_reading_time":0.78,
        "Solution_score_count":null,
        "Solution_sentence_count":2.0,
        "Solution_word_count":12.0,
        "Tool":"DVC"
    },
    {
        "Answerer_created_time":1221810788500,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Paderborn, North-Rhine-Westphalia, Germany",
        "Answerer_reputation_count":68522.0,
        "Answerer_view_count":7896.0,
        "Challenge_adjusted_solved_time":22.2570675,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am using mlflow run with a GitHub uri.<\/p>\n<p>When I run using the below command<\/p>\n<pre><code>mlflow run &lt;git-uri&gt;\n<\/code><\/pre>\n<p>The command sets up a conda environment and then <em>clones the Git repo into a <strong>temp<\/strong> directory, But I need it setup in a <strong>specific<\/strong> directory<\/em><\/p>\n<p>I checked the entire document, but I can't find it. Is there no such option to do so in one shot?<\/p>",
        "Challenge_closed_time":1623570743820,
        "Challenge_comment_count":0,
        "Challenge_created_time":1623534343453,
        "Challenge_favorite_count":0.0,
        "Challenge_gpt_summary_original":"The user is facing a challenge while using mlflow run with a GitHub uri. The command clones the Git repo into a temp directory, but the user needs it to be set up in a specific directory. The user is unable to find an option to do so in one shot.",
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/67953241",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":9.2,
        "Challenge_reading_time":5.98,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_closed":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":10.1112130556,
        "Challenge_title":"mlflow run git-uri clone to specific directory",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":239.0,
        "Challenge_word_count":73,
        "Platform":"Stack Overflow",
        "Poster_created_time":1575348765723,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Chennai, Tamil Nadu, India",
        "Poster_reputation_count":1049.0,
        "Poster_view_count":192.0,
        "Solution_body":"<p>For non-local URIs, MLflow uses the Python's <code>tempfile.mkdtemp<\/code> function (<a href=\"https:\/\/github.com\/mlflow\/mlflow\/blob\/1c43176cefb5531fbb243975b9c8c5bfb9775e66\/mlflow\/projects\/utils.py#L140\" rel=\"nofollow noreferrer\">source code<\/a>), that creates the temporary directory.  You may have some control over it by setting the <code>TMPDIR<\/code> environment variable as described in <a href=\"https:\/\/docs.python.org\/3\/library\/tempfile.html#tempfile.mkstemp\" rel=\"nofollow noreferrer\">Python docs<\/a> (it lists <code>TMP<\/code> &amp; <code>TEMP<\/code> as well, but they didn't work for me on MacOS) - but it will set only &quot;base path&quot; for temporary directories and files, the directory\/file names are still will be random.<\/p>",
        "Solution_comment_count":3.0,
        "Solution_last_edit_time":1623614468896,
        "Solution_link_count":2.0,
        "Solution_readability":13.9,
        "Solution_reading_time":9.86,
        "Solution_score_count":1.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":75.0,
        "Tool":"MLflow"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":0.1038888889,
        "Challenge_answer_count":0,
        "Challenge_body":"From slack\n\nMy job is stack with a warning status, I configured a private bitbucket connection and the cloning fails.",
        "Challenge_closed_time":1649328708000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1649328334000,
        "Challenge_favorite_count":null,
        "Challenge_gpt_summary_original":"The user is facing issues with their job status due to a failed cloning process while configuring a private bitbucket connection in their init git container. They are seeking guidance on how to debug the issue.",
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1472",
        "Challenge_link_count":0,
        "Challenge_participation_count":0,
        "Challenge_readability":7.2,
        "Challenge_reading_time":1.85,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_closed":1.0,
        "Challenge_sentence_count":2,
        "Challenge_solved_time":0.1038888889,
        "Challenge_title":"How to debug my init git container",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":null,
        "Challenge_word_count":26,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"Before updating the connections or changing anything about your current deployment, please perform the following debugging steps:\n\nEnable logs from all containers:\n\n\n\nYou can also inspect the operations from the statuses page to get more information (for distributed runs you can select the correct pod)\n\n\nYou can suspend the init container using :\n\n  - connection: my-connection\n    git: {...}\n    container:\n      command: [\"\/bin\/bash\", \"-c\"]\n      args: [\"sleep 3600\"]\nUse shell to get inside the container (for distributed runs you can select the correct pod and container):",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":20.1,
        "Solution_reading_time":6.86,
        "Solution_score_count":1.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":80.0,
        "Tool":"Polyaxon"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":124.4336111111,
        "Challenge_answer_count":0,
        "Challenge_body":"Wandb sweep on our [primary notebook don't](https:\/\/colab.research.google.com\/drive\/1vl6tgH78bNb9A5JP6NcfFHB189TIjy5c#scrollTo=sTDGweZ0d0QP) advance instead they just stall after the first part of the sweep completes. This is causing problems.",
        "Challenge_closed_time":1600665871000,
        "Challenge_comment_count":3,
        "Challenge_created_time":1600217910000,
        "Challenge_favorite_count":null,
        "Challenge_gpt_summary_original":"The user needs to remove the `data\/MNIST` subdirectory from their repo's history as it slipped through `.gitignore`. They plan to use an open-source tool called `bfg` for this purpose and will delete their local clones and clone a fresh, cleaned version from upstream after committing all local changes.",
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/github.com\/AIStream-Peelout\/flow-forecast\/issues\/154",
        "Challenge_link_count":1,
        "Challenge_participation_count":3,
        "Challenge_readability":10.5,
        "Challenge_reading_time":3.48,
        "Challenge_repo_contributor_count":13.0,
        "Challenge_repo_fork_count":209.0,
        "Challenge_repo_issue_count":605.0,
        "Challenge_repo_star_count":1230.0,
        "Challenge_repo_watch_count":20.0,
        "Challenge_score_count":0.0,
        "Challenge_self_closed":1.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":124.4336111111,
        "Challenge_title":"Wandb Run stalling",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":null,
        "Challenge_word_count":26,
        "Platform":"Github",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"So this appears to be a problem on the Weights and Biases end of things. https:\/\/github.com\/wandb\/client\/issues\/1243 This is fixed see original issue.",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":7.6,
        "Solution_reading_time":1.9,
        "Solution_score_count":null,
        "Solution_sentence_count":2.0,
        "Solution_word_count":22.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_created_time":1646219230528,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":1.0,
        "Answerer_view_count":1.0,
        "Challenge_adjusted_solved_time":3670.8803794444,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I want to build an Azure ML environment with two python packages that I have in Azure Devops.\nFor this I need a workspace connection to Azure Devops. One package is published to an artifact feed and I can access it using the python SDK using a personal access token:<\/p>\n<pre><code>ws.set_connection(name=&quot;ConnectionName&quot;, \n                  category= &quot;PythonFeed&quot;, \n                  target = &quot;https:\/\/pkgs.dev.azure.com\/&quot;, \n                  authType = &quot;PAT&quot;, \n                  value = PAT_TOKEN)\n<\/code><\/pre>\n<p>However, for the other I need to get the package from the git repository in Azure Devops. The documentation of the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.workspace.workspace?view=azure-ml-py#azureml-core-workspace-workspace-set-connection\" rel=\"nofollow noreferrer\">Python SDK<\/a> and the underlying <a href=\"https:\/\/docs.microsoft.com\/en-us\/rest\/api\/azureml\/workspace-connections\/create\" rel=\"nofollow noreferrer\">REST API<\/a> don't give the options for the arguments, only that they need to be strings (see links).<\/p>\n<p>My question: what are the options for the following arguments:<\/p>\n<ul>\n<li>authType<\/li>\n<li>category<\/li>\n<li>valueFormat<\/li>\n<\/ul>\n<p>And what do I need to set for target argument, so that I can connect to the Azure DevOps repository with potentially different authentication?<\/p>",
        "Challenge_closed_time":1659435013616,
        "Challenge_comment_count":0,
        "Challenge_created_time":1646219844250,
        "Challenge_favorite_count":0.0,
        "Challenge_gpt_summary_original":"The user wants to build an Azure ML environment with two python packages from Azure DevOps, but is having trouble connecting to the git repository for one of the packages. They are seeking information on the valid options for the authType, category, and valueFormat arguments, as well as guidance on how to set the target argument to connect to the Azure DevOps repository with potentially different authentication.",
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/71321757",
        "Challenge_link_count":3,
        "Challenge_participation_count":1,
        "Challenge_readability":13.0,
        "Challenge_reading_time":18.16,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_closed":1.0,
        "Challenge_sentence_count":10,
        "Challenge_solved_time":3670.8803794444,
        "Challenge_title":"What are valid Azure ML Workspace connection argument options?",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":93.0,
        "Challenge_word_count":157,
        "Platform":"Stack Overflow",
        "Poster_created_time":1646219230528,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":1.0,
        "Poster_view_count":1.0,
        "Solution_body":"<p>To get the package from a Azure DevOps git repository you can change the target to the repository URL:<\/p>\n<pre><code>ws.set_connection(\n    name=&quot;ConnectionName&quot;, \n    category = &quot;PythonFeed&quot;,\n    target = &quot;https:\/\/dev.azure.com\/&lt;MY-ORG&gt;\/&lt;MY-PROJECT&gt;\/_git\/&lt;MY-REPO&gt;&quot;, \n    authType = &quot;PAT&quot;, \n    value = &lt;PAT-TOKEN&gt;)\n<\/code><\/pre>\n<p>Note here that there is no user specified in the URL (the standard &quot;clone&quot; URL in Azure DevOps also contains &quot;DevOps-Vx@&quot;).<\/p>\n<p>As for any other options for &quot;authType&quot;, &quot;category&quot; and &quot;valueFormat&quot;, I don't know.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":14.3,
        "Solution_reading_time":8.53,
        "Solution_score_count":0.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":64.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1305851487736,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":5993.0,
        "Answerer_view_count":457.0,
        "Challenge_adjusted_solved_time":68.3225869444,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>My team has a set up wherein we track datasets and models in DVC, and have a GitLab repository for tracking our code and DVC metadata files. We have a job in our dev GitLab pipeline (run on each push to a merge request) that has the goal of checking to be sure that the developer remembered to run <code>dvc push<\/code> to keep DVC remote storage up-to-date. Right now, the way we do this is by running <code>dvc pull<\/code> on the GitLab runner, which will fail with errors telling you which files (new files or latest versions of existing files) were not found.<\/p>\n<p>The downside to this approach is that we are loading the entirety of our data stored in DVC onto a GitLab runner, and we've run into out-of-memory issues, not to mention lengthy run time to download all that data. Since the path and md5 hash of the objects are stored in the DVC metadata files, I would think that's all the information that DVC would need to be able to answer the question &quot;is the remote storage system up-to-date&quot;.<\/p>\n<p>It seems like <code>dvc status<\/code> is similar to what I'm asking for, but compares the cache or workspace and remote storage. In other words, it requires the files to actually be present on whatever filesystem is making the call.<\/p>\n<p>Is there some way to achieve the goal I laid out above (&quot;inform the developer that they need to run <code>dvc push<\/code>&quot;) without pulling everything from DVC?<\/p>",
        "Challenge_closed_time":1622257759208,
        "Challenge_comment_count":0,
        "Challenge_created_time":1622232629793,
        "Challenge_favorite_count":0.0,
        "Challenge_gpt_summary_original":"The user's team tracks datasets and models in DVC and has a GitLab repository for tracking code and DVC metadata files. They have a job in their dev GitLab pipeline that checks if the developer has run \"dvc push\" to keep DVC remote storage up-to-date. Currently, they run \"dvc pull\" on the GitLab runner, which loads the entirety of their data stored in DVC onto the runner, causing out-of-memory issues and lengthy run time. The user is looking for a way to check if the version of a file tracked by a DVC metadata file exists in remote storage without pulling the file.",
        "Challenge_last_edit_time":1622257491983,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/67744934",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":12.7,
        "Challenge_reading_time":19.1,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":5.0,
        "Challenge_self_closed":0.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":6.9803930556,
        "Challenge_title":"Is it possible to check that the version of a file tracked by a DVC metadata file exists in remote storage without pulling the file?",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":488.0,
        "Challenge_word_count":272,
        "Platform":"Stack Overflow",
        "Poster_created_time":1618255062696,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":75.0,
        "Poster_view_count":2.0,
        "Solution_body":"<blockquote>\n<p>It seems like dvc status is similar to what I'm asking for<\/p>\n<\/blockquote>\n<p><code>dvc status --cloud<\/code> will give you a list of &quot;new&quot; files if they that haven't been pushed to the (default) remote. It won't error out though, so your CI script should fail depending on the stdout message.<\/p>\n<p>More info: <a href=\"https:\/\/dvc.org\/doc\/command-reference\/status#options\" rel=\"nofollow noreferrer\">https:\/\/dvc.org\/doc\/command-reference\/status#options<\/a><\/p>\n<p>I'd also ask everyone to run <code>dvc install<\/code>, which will setup some Git hooks, including automatic <code>dvc push<\/code> with <code>git push<\/code>.<\/p>\n<p>See <a href=\"https:\/\/dvc.org\/doc\/command-reference\/install\" rel=\"nofollow noreferrer\">https:\/\/dvc.org\/doc\/command-reference\/install<\/a><\/p>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":1622503453296,
        "Solution_link_count":4.0,
        "Solution_readability":13.8,
        "Solution_reading_time":10.5,
        "Solution_score_count":3.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":83.0,
        "Tool":"DVC"
    },
    {
        "Answerer_created_time":1662022756172,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":46.0,
        "Answerer_view_count":1.0,
        "Challenge_adjusted_solved_time":0.5066644444,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I'm using DVC extension in VScode inside a python project. The problem is that dvc shows files not tracked by dvc in the source control panel! As in the following picture.\nDVC track only data folder and not the src folder. How can I fix it? Have you also encountered these problems?<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/sn8YY.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/sn8YY.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Challenge_closed_time":1662022756172,
        "Challenge_comment_count":1,
        "Challenge_created_time":1662017466370,
        "Challenge_favorite_count":0.0,
        "Challenge_gpt_summary_original":"The user is facing an issue with the DVC extension in VScode where it shows files not tracked by DVC in the source control panel. The user is specifically concerned about the src folder not being tracked and is seeking a solution to fix the problem.",
        "Challenge_last_edit_time":1662021092696,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/73565648",
        "Challenge_link_count":2,
        "Challenge_participation_count":2,
        "Challenge_readability":6.1,
        "Challenge_reading_time":6.65,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_closed":0.0,
        "Challenge_sentence_count":10,
        "Challenge_solved_time":1.4693894444,
        "Challenge_title":"DVC shows files not tracked in source control in visual studio code",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":39.0,
        "Challenge_word_count":73,
        "Platform":"Stack Overflow",
        "Poster_created_time":1580668804396,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":498.0,
        "Poster_view_count":66.0,
        "Solution_body":"<p>The files shown are completely untracked. They are shown in both SCM trees so you can add them to either Git or DVC using inline actions.\nOnce the files are tracked by one of the tools they should only show up under the appropriate tree.<\/p>",
        "Solution_comment_count":2.0,
        "Solution_last_edit_time":1662022916688,
        "Solution_link_count":0.0,
        "Solution_readability":5.6,
        "Solution_reading_time":2.94,
        "Solution_score_count":3.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":45.0,
        "Tool":"DVC"
    },
    {
        "Answerer_created_time":1405882600928,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"London, United Kingdom",
        "Answerer_reputation_count":552.0,
        "Answerer_view_count":115.0,
        "Challenge_adjusted_solved_time":0.4960861111,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>i have added \"versioned: true\" in the \"catalog.yml\" file of the \"hello_world\" tutorial.<\/p>\n\n<pre><code>example_iris_data:\n  type: pandas.CSVDataSet\n  filepath: data\/01_raw\/iris.csv\n  versioned: true\n<\/code><\/pre>\n\n<p>Then when I used \n\"kedro run\" to run the tutorial, it has error as below:\n\"VersionNotFoundError: Did not find any versions for CSVDataSet\".<\/p>\n\n<p>May i know what is the right way for me to do versioning for the \"iris.csv\" file? thanks!<\/p>",
        "Challenge_closed_time":1592218684390,
        "Challenge_comment_count":0,
        "Challenge_created_time":1592216898480,
        "Challenge_favorite_count":0.0,
        "Challenge_gpt_summary_original":"The user added \"versioned: true\" in the \"catalog.yml\" file of the \"hello_world\" tutorial to do data versioning for the \"iris.csv\" file. However, when running the tutorial using \"kedro run\", an error occurred stating \"VersionNotFoundError: Did not find any versions for CSVDataSet\". The user is seeking guidance on the correct way to do versioning for the \"iris.csv\" file.",
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/62386291",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":7.0,
        "Challenge_reading_time":6.3,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_closed":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":0.4960861111,
        "Challenge_title":"Data versioning of \"Hello_World\" tutorial",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":338.0,
        "Challenge_word_count":66,
        "Platform":"Stack Overflow",
        "Poster_created_time":1517455831447,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":53.0,
        "Poster_view_count":1.0,
        "Solution_body":"<p>Try versioning one of the downstream outputs. For example, add this entry in your <code>catalog.yml<\/code>, and run <code>kedro run<\/code><\/p>\n\n<pre><code>example_train_x:\n  type: pandas.CSVDataSet\n  filepath: data\/02_intermediate\/example_iris_data.csv\n  versioned: true\n<\/code><\/pre>\n\n<p>And you will see <code>example_iris.data.csv<\/code> directory (not a file) under <code>data\/02_intermediate<\/code>. The reason <code>example_iris_data<\/code> gives you an error is that it's the starting data and there's already <code>iris.csv<\/code> in <code>data\/01_raw<\/code> so, Kedro cannot create <code>data\/01_raw\/iris.csv\/<\/code> directory because of the name conflict with the existing <code>iris.csv<\/code> file. <\/p>\n\n<p>Hope this helps :) <\/p>",
        "Solution_comment_count":2.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":11.1,
        "Solution_reading_time":9.68,
        "Solution_score_count":1.0,
        "Solution_sentence_count":10.0,
        "Solution_word_count":78.0,
        "Tool":"Kedro"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":1102.8986563889,
        "Challenge_answer_count":0,
        "Challenge_body":"<!-- Issues are public, they should not contain confidential information -->\n\n### What is the current _bug_ behavior? how can we reproduce it?\nThe requirements.txt file does not have the entire dependency tree defined\n\n### Possible fixes\nModify the requirements.txt file so that it has the complete tree of dependencies and their respective versions\n### Steps\n\n- [x] Make sure that the\n      [code contributions checklist](https:\/\/docs.fluidattacks.com\/development\/contributing#checklist)\n      has been followed.",
        "Challenge_closed_time":1675452134148,
        "Challenge_comment_count":13,
        "Challenge_created_time":1671481698985,
        "Challenge_favorite_count":null,
        "Challenge_gpt_summary_original":"The user has encountered an issue with the requirements.txt file not having the complete dependency tree defined while working with Sagemaker. The possible fix is to modify the requirements.txt file to include the complete tree of dependencies and their respective versions.",
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/gitlab.com\/fluidattacks\/universe\/-\/issues\/8382",
        "Challenge_link_count":1,
        "Challenge_participation_count":13,
        "Challenge_readability":11.1,
        "Challenge_reading_time":6.8,
        "Challenge_repo_contributor_count":41.0,
        "Challenge_repo_fork_count":2.0,
        "Challenge_repo_issue_count":5537.0,
        "Challenge_repo_star_count":16.0,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_closed":null,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":1102.8986563889,
        "Challenge_title":"[Sorts] Add sagemaker dependencies",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":null,
        "Challenge_word_count":66,
        "Platform":"Gitlab",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"Added and pinned the additional dependencies. @mriveraatfluid mentioned in commit d54bbb59bc42db6a66848d1cefe4b8ab29f68690 mentioned in merge request !36356 mentioned in commit 24b795e9436ea7c45379486b5541f6a84f967c15 mentioned in commit b3eda78ae28bb6810c052d94edd675a82cff6129 marked the checklist item **Make sure that the** as completed The complete tree of dependencies has been added and pinned properly in the requirements file. @mriveraatfluid mentioned in commit 9ecc0c84c69f7b0422f0a30239d522c031b0d7ab mentioned in merge request !34151 mentioned in commit cf649ea2f6fab7a2e8308aa813e1841bf4d23c95 unassigned @auribeatfluid assigned to @rrodriguezatfluid assigned to @auribeatfluid",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":11.2,
        "Solution_reading_time":9.12,
        "Solution_score_count":null,
        "Solution_sentence_count":5.0,
        "Solution_word_count":71.0,
        "Tool":"Amazon SageMaker"
    }
]