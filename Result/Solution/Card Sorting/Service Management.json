[
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":5.1511888889,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi,  <\/p>\n<p>I am getting the following error message:  <br \/>\n&quot;WebserviceException: WebserviceException: Message: Service diabetes-service with the same name already exists, please use a different service name or delete the existing service. InnerException None ErrorResponse { &quot;error&quot;: { &quot;message&quot;: &quot;Service diabetes-service with the same name.&quot;  <\/p>\n<p>Please can you help with deleting the service in question?  <\/p>\n<p>Thanks,  <\/p>\n<p>Naveen  <\/p>",
        "Challenge_closed_time":1610680137287,
        "Challenge_comment_count":0,
        "Challenge_created_time":1610661593007,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/231106\/webserviceexception-how-to-delete-an-existing-serv",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":10.7,
        "Challenge_reading_time":6.96,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":5.1511888889,
        "Challenge_title":"WebserviceException: How to delete an existing service",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":65,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hello, Naveen. This error message means that in your current AML workspace, there already exists a real-time endpoint(or service) whose name is &quot;diabetes-service&quot;, so you can't deploy a new service with this same name because it will cause duplication.   <\/p>\n<p>You can check your workspace in our portal <a href=\"https:\/\/ml.azure.com\/selectWorkspace\">https:\/\/ml.azure.com\/selectWorkspace<\/a> , in the sidebar you can find a &quot;Endpoints&quot; button, you can find all your &quot;real-time endpoint&quot; there. Then please delete the dup service, after deletion you can deploy your new service with the name &quot;diabetes-service&quot;.<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":11.6,
        "Solution_reading_time":8.4,
        "Solution_score_count":0.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":85.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1360655430743,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Belgium",
        "Answerer_reputation_count":2947.0,
        "Answerer_view_count":355.0,
        "Challenge_adjusted_solved_time":291.4625380556,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am trying to call an AzureML UDF from Stream Analytics query and that UDF expects an array of 5 rows and 2 columns.  The input data is streamed from an IoT hub and we have two fields in the incoming messages: temperature &amp; humidity.<\/p>\n<p>This would be the 'passthrough query' :<\/p>\n<pre><code>SELECT GetMetadataPropertyValue([room-telemetry], 'IoTHub.ConnectionDeviceId') AS RoomId, \n       Temperature, Humidity\nINTO\n    [maintenance-alerts]\nFROM\n    [room-telemetry]\n<\/code><\/pre>\n<p>I have an AzureML UDF (successfully created) that should be called with the last 5 records per RoomId and that will return one value from the ML Model.  Obviously, there are multiple rooms in my stream, so I need to find a way to get some kind of windowing of 5 records Grouped per RoomId.  I don't seem to find a way to call the UDF with the right arrays selected from the input stream.  I know I can create a Javascript UDF that would return an array from the specific fields, but that would be record\/by record, where here I would need this with multiple records that are grouped by the RoomId.<\/p>\n<p>Someone has any insights?<\/p>\n<p>Best regards<\/p>",
        "Challenge_closed_time":1597227776727,
        "Challenge_comment_count":4,
        "Challenge_created_time":1596178511590,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/63187116",
        "Challenge_link_count":0,
        "Challenge_participation_count":5,
        "Challenge_readability":9.8,
        "Challenge_reading_time":15.17,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":2.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":10,
        "Challenge_solved_time":291.4625380556,
        "Challenge_title":"Call Azure Stream Analytics UDF with multi-dimensional array of last 5 records, grouped by record",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":374.0,
        "Challenge_word_count":197,
        "Platform":"Stack Overflow",
        "Poster_created_time":1360655430743,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Belgium",
        "Poster_reputation_count":2947.0,
        "Poster_view_count":355.0,
        "Solution_body":"<p>After the good suggestion of @jean-s\u00e9bastien and an answer to an isolated question for the <a href=\"https:\/\/stackoverflow.com\/questions\/63357901\/how-to-convert-a-dictionary-like-structure-in-azure-stream-analytics-to-a-mult\/63373103#63373103\">array-parsing<\/a>, I finally was able to stitch everything together in a solution that builds.  (still have to get it to run at runtime, though).<\/p>\n<p>So, the solution exists in using <code>CollectTop<\/code> to aggregate the latest rows of the entity you want to group by, including the specification of a Time Window.<\/p>\n<p>And the next step was to create the javascript UDF to take that data structure and parse it into a multi-dimensional array.<\/p>\n<p>This is the query I have right now:<\/p>\n<pre class=\"lang-sql prettyprint-override\"><code>-- Taking relevant fields from the input stream\nWITH RelevantTelemetry AS\n(\n    SELECT  engineid, tmp, hum, eventtime\n    FROM    [engine-telemetry] \n    WHERE   engineid IS NOT NULL\n),\n-- Grouping by engineid in TimeWindows\nTimeWindows AS\n(\n    SELECT engineid, \n        CollectTop(2) OVER (ORDER BY eventtime DESC) as TimeWindow\n    FROM\n        [RelevantTelemetry]\n    WHERE engineid IS NOT NULL\n    GROUP BY TumblingWindow(hour, 24), engineid\n)\n--Output timewindows for verification purposes\nSELECT engineid, Udf.Predict(Udf.getTimeWindows(TimeWindow)) as Prediction\nINTO debug\nFROM TimeWindows\n<\/code><\/pre>\n<p>And this is the Javascript UDF:<\/p>\n<pre class=\"lang-js prettyprint-override\"><code>    function getTimeWindows(input){\n        var output = [];\n        for(var x in input){\n            var array = [];\n            array.push(input[x].value.tmp);\n            array.push(input[x].value.hum);\n            output.push(array);\n        }\n        return output;\n    }\n<\/code><\/pre>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":16.2,
        "Solution_reading_time":21.2,
        "Solution_score_count":1.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":191.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1595479476676,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Massachusetts, USA",
        "Answerer_reputation_count":246.0,
        "Answerer_view_count":21.0,
        "Challenge_adjusted_solved_time":0.3625030556,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I am trying to build a machine learning algorithm an deploy it with REST API. While I am doing this I got some error like &quot;MALFORMED_REQUEST&quot;, &quot;message&quot;: &quot;Failed to parse input from JSON. Ensure that input is a valid JSON formatted string.&quot;. In below you can see my code. Can you please tell me what am I doing wrong? Thanks in advance.<\/p>\n<pre><code>import json\nimport requests\nimport base64\n\n#data = 'cat_Test2.jpg'\n\n\nwith open('.\/Dataset\/test2\/cat_Test2.jpg', mode='rb') as file:\n    img = file.read()\ndata = base64.encodebytes(img).decode('utf-8')\n\n#print(json.dumps(data))\n#print(data)\nheaders = {'Content-Type': 'application\/json'}\nrequest_uri = 'http:\/\/127.0.0.1:5000\/invocations'\n\nif __name__ == '__main__':\n    try:\n        response = requests.post(request_uri, data=data, headers=headers)\n        print(response.content)\n        print('done!!!')\n    except Exception as ex:\n        raise (ex)\n<\/code><\/pre>",
        "Challenge_closed_time":1628035745368,
        "Challenge_comment_count":0,
        "Challenge_created_time":1628034440357,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/68643893",
        "Challenge_link_count":1,
        "Challenge_participation_count":2,
        "Challenge_readability":8.5,
        "Challenge_reading_time":12.1,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":15,
        "Challenge_solved_time":0.3625030556,
        "Challenge_title":"Upload an image file with JSON Format",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":389.0,
        "Challenge_word_count":109,
        "Platform":"Stack Overflow",
        "Poster_created_time":1460657116247,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":98.0,
        "Poster_view_count":19.0,
        "Solution_body":"<p>The MLflow model server accepts as input either JSON (pandas split-orient format) or CSV.\n<a href=\"https:\/\/mlflow.org\/docs\/latest\/models.html#deploy-mlflow-models\" rel=\"nofollow noreferrer\">https:\/\/mlflow.org\/docs\/latest\/models.html#deploy-mlflow-models<\/a><\/p>\n<p>You will need to convert your image into one of those two formats. Example:\n<a href=\"https:\/\/github.com\/amesar\/mlflow-examples\/tree\/master\/python\/keras_tf_mnist#score-mnist-png-file\" rel=\"nofollow noreferrer\">https:\/\/github.com\/amesar\/mlflow-examples\/tree\/master\/python\/keras_tf_mnist#score-mnist-png-file<\/a><\/p>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":4.0,
        "Solution_readability":21.4,
        "Solution_reading_time":8.02,
        "Solution_score_count":1.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":36.0,
        "Tool":"MLflow"
    },
    {
        "Answerer_created_time":1369787017728,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Atlanta, Georgia",
        "Answerer_reputation_count":55.0,
        "Answerer_view_count":49.0,
        "Challenge_adjusted_solved_time":115.0280841667,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>This is what I use to deploy an Auto-ML model:<\/p>\n<pre><code>            MachineSpec machineSpec = MachineSpec.newBuilder().setMachineType(&quot;n1-standard-2&quot;).build();\n            DedicatedResources dedicatedResources =\n                    DedicatedResources.newBuilder().setMinReplicaCount(1).setMachineSpec(machineSpec).build();            \n            String model = ModelName.of(project, location, modelId).toString();\n            DeployedModel deployedModel =\n                    DeployedModel.newBuilder()\n                            .setModel(model)\n                            .setDisplayName(deployedModelDisplayName)\n                            .setDedicatedResources(dedicatedResources)\n                            .build();\n            Map&lt;String, Integer&gt; trafficSplit = new HashMap&lt;&gt;();\n            trafficSplit.put(&quot;0&quot;, 100);\n            EndpointName endpoint = EndpointName.of(project, location, endpointId);\n            OperationFuture&lt;DeployModelResponse, DeployModelOperationMetadata&gt; response =\n                    client.deployModelAsync(endpoint, deployedModel, trafficSplit);\n            response.getInitialFuture().get().getName());\n<\/code><\/pre>\n<p>The error appears when I hit this line <code>response.getInitialFuture().get().getName());<\/code><\/p>\n<p>Here is the error:\n<code>INVALID_ARGUMENT: 'dedicated_resources' is not supported for Model projects\/***\/locations\/us-central1\/models\/***<\/code><\/p>\n<p>I can deploy the model using cloud console but not programmatically using java 8. It is a new model and the endpoint is also new without any assigned model to it.<\/p>",
        "Challenge_closed_time":1640820603630,
        "Challenge_comment_count":8,
        "Challenge_created_time":1640406502527,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/70477987",
        "Challenge_link_count":0,
        "Challenge_participation_count":9,
        "Challenge_readability":21.9,
        "Challenge_reading_time":18.8,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":13,
        "Challenge_solved_time":115.0280841667,
        "Challenge_title":"Vertex Ai issue when deploying a model using Java",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":244.0,
        "Challenge_word_count":109,
        "Platform":"Stack Overflow",
        "Poster_created_time":1369787017728,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Atlanta, Georgia",
        "Poster_reputation_count":55.0,
        "Poster_view_count":49.0,
        "Solution_body":"<p>I am sorry everyone, I was implementing the wrong section of the documentation. I had to follow AutoML image, not Custom-trained one.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/a4xPR.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/a4xPR.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":12.9,
        "Solution_reading_time":4.07,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":32.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_created_time":1263294862568,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":183045.0,
        "Answerer_view_count":13691.0,
        "Challenge_adjusted_solved_time":0.3125277778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am trying to invoke a SageMaker enpoint from AWS Lambda using a lambda function.<\/p>\n<p>This is a sample API call to the endpoint from SageMaker Studio, working as expected:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/3iTPN.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/3iTPN.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>here's my Lambda function (<a href=\"https:\/\/aws.amazon.com\/blogs\/machine-learning\/call-an-amazon-sagemaker-model-endpoint-using-amazon-api-gateway-and-aws-lambda\/\" rel=\"nofollow noreferrer\">inspired from documentation<\/a>):<\/p>\n<pre><code>import os\nimport io\nimport boto3\nimport json\n\n\nENDPOINT_NAME = 'iris-autoscale-6'\nruntime= boto3.client('runtime.sagemaker')\n\ndef lambda_handler(event, context):\n    # print(&quot;Received event: &quot; + json.dumps(event, indent=2))\n    payload = json.loads(json.dumps(event))\n    print(payload)\n    \n    response = runtime.invoke_endpoint(EndpointName=ENDPOINT_NAME, ContentType='application\/json', Body=payload)\n    print(response)\n    result = json.loads(response['Body'].read().decode())\n    print(result)\n    \n    return result\n<\/code><\/pre>\n<p>My error message:<\/p>\n<pre><code>Test Event Name\nProperTest\n\nResponse\n{\n  &quot;errorMessage&quot;: &quot;Parameter validation failed:\\nInvalid type for parameter Body, value: {'sepal_length': [5.1, 4.9, 4.7, 4.6, 5], 'sepal_width': [3.5, 3, 3.2, 3.1, 3.6], 'petal_length': [1.4, 1.4, 1.3, 1.5, 1.4], 'petal_width': [0.2, 0.2, 0.2, 0.2, 0.2]}, type: &lt;class 'dict'&gt;, valid types: &lt;class 'bytes'&gt;, &lt;class 'bytearray'&gt;, file-like object&quot;,\n  &quot;errorType&quot;: &quot;ParamValidationError&quot;,\n  &quot;stackTrace&quot;: [\n    &quot;  File \\&quot;\/var\/task\/lambda_function.py\\&quot;, line 17, in lambda_handler\\n    response = runtime.invoke_endpoint(EndpointName=ENDPOINT_NAME, ContentType='application\/json', Body=payload)\\n&quot;,\n    &quot;  File \\&quot;\/var\/runtime\/botocore\/client.py\\&quot;, line 386, in _api_call\\n    return self._make_api_call(operation_name, kwargs)\\n&quot;,\n    &quot;  File \\&quot;\/var\/runtime\/botocore\/client.py\\&quot;, line 678, in _make_api_call\\n    api_params, operation_model, context=request_context)\\n&quot;,\n    &quot;  File \\&quot;\/var\/runtime\/botocore\/client.py\\&quot;, line 726, in _convert_to_request_dict\\n    api_params, operation_model)\\n&quot;,\n    &quot;  File \\&quot;\/var\/runtime\/botocore\/validate.py\\&quot;, line 319, in serialize_to_request\\n    raise ParamValidationError(report=report.generate_report())\\n&quot;\n  ]\n}\n\nFunction Logs\nSTART RequestId: 70278b9f-f75e-4ac9-a827-7ad35d162512 Version: $LATEST\n{'sepal_length': [5.1, 4.9, 4.7, 4.6, 5], 'sepal_width': [3.5, 3, 3.2, 3.1, 3.6], 'petal_length': [1.4, 1.4, 1.3, 1.5, 1.4], 'petal_width': [0.2, 0.2, 0.2, 0.2, 0.2]}\n[ERROR] ParamValidationError: Parameter validation failed:\nInvalid type for parameter Body, value: {'sepal_length': [5.1, 4.9, 4.7, 4.6, 5], 'sepal_width': [3.5, 3, 3.2, 3.1, 3.6], 'petal_length': [1.4, 1.4, 1.3, 1.5, 1.4], 'petal_width': [0.2, 0.2, 0.2, 0.2, 0.2]}, type: &lt;class 'dict'&gt;, valid types: &lt;class 'bytes'&gt;, &lt;class 'bytearray'&gt;, file-like object\nTraceback (most recent call last):\n\u00a0\u00a0File &quot;\/var\/task\/lambda_function.py&quot;, line 17, in lambda_handler\n\u00a0\u00a0\u00a0\u00a0response = runtime.invoke_endpoint(EndpointName=ENDPOINT_NAME, ContentType='application\/json', Body=payload)\n\u00a0\u00a0File &quot;\/var\/runtime\/botocore\/client.py&quot;, line 386, in _api_call\n\u00a0\u00a0\u00a0\u00a0return self._make_api_call(operation_name, kwargs)\n\u00a0\u00a0File &quot;\/var\/runtime\/botocore\/client.py&quot;, line 678, in _make_api_call\n\u00a0\u00a0\u00a0\u00a0api_params, operation_model, context=request_context)\n\u00a0\u00a0File &quot;\/var\/runtime\/botocore\/client.py&quot;, line 726, in _convert_to_request_dict\n\u00a0\u00a0\u00a0\u00a0api_params, operation_model)\n\u00a0\u00a0File &quot;\/var\/runtime\/botocore\/validate.py&quot;, line 319, in serialize_to_request\n\u00a0\u00a0\u00a0\u00a0raise ParamValidationError(report=report.generate_report())\nEND RequestId: 70278b9f-f75e-4ac9-a827-7ad35d162512\nREPORT RequestId: 70278b9f-f75e-4ac9-a827-7ad35d162512  Duration: 26.70 ms  Billed Duration: 27 ms  Memory Size: 128 MB Max Memory Used: 76 MB  Init Duration: 343.10 ms\n<\/code><\/pre>\n<p>Here's the policy attached to the lambda function:<\/p>\n<pre><code>{\n    &quot;Version&quot;: &quot;2012-10-17&quot;,\n    &quot;Statement&quot;: [\n        {\n            &quot;Sid&quot;: &quot;VisualEditor0&quot;,\n            &quot;Effect&quot;: &quot;Allow&quot;,\n            &quot;Action&quot;: &quot;sagemaker:InvokeEndpoint&quot;,\n            &quot;Resource&quot;: &quot;arn:aws:sagemaker:ap-south-1:&lt;my-account-id&gt;:endpoint\/iris-autoscale-6&quot;\n        }\n    ]\n}\n<\/code><\/pre>",
        "Challenge_closed_time":1629024434667,
        "Challenge_comment_count":0,
        "Challenge_created_time":1629022235437,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1629023309567,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/68790568",
        "Challenge_link_count":3,
        "Challenge_participation_count":1,
        "Challenge_readability":16.0,
        "Challenge_reading_time":60.93,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":44,
        "Challenge_solved_time":0.6108972222,
        "Challenge_title":"\"errorMessage\": \"Parameter validation failed in Lambda calling SageMaker endpoint",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":499.0,
        "Challenge_word_count":370,
        "Platform":"Stack Overflow",
        "Poster_created_time":1559910246180,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Bengaluru, Karnataka, India",
        "Poster_reputation_count":2046.0,
        "Poster_view_count":369.0,
        "Solution_body":"<p>The issue is that your <code>payload<\/code> has invalid format. It should be one of:<\/p>\n<pre><code>&lt;class 'bytes'&gt;, &lt;class 'bytearray'&gt;, file-like object\n<\/code><\/pre>\n<p>The following should address the error (note: you may have many other issues in your code):<\/p>\n<pre><code>    payload = json.dumps(event)\n    print(payload)\n    \n    response = runtime.invoke_endpoint(EndpointName=ENDPOINT_NAME, ContentType='application\/json', Body=payload.encode())\n<\/code><\/pre>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":13.7,
        "Solution_reading_time":6.2,
        "Solution_score_count":1.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":46.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1646907459852,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Hyderabad, Telangana, India",
        "Answerer_reputation_count":1624.0,
        "Answerer_view_count":1376.0,
        "Challenge_adjusted_solved_time":3.4251711111,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I developed a machine learning model using Azure ML's clustering. Few of the requests made from the cluster are triggering 404 HTTP error. I followed the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-advanced-entry-script\" rel=\"nofollow noreferrer\">document<\/a> to do modifications in my swagger.json file. Finally ended up with &quot;list index out of range&quot; error. It seems to be having issue with the global parameter but I am no sure about it. I am using the API from postman with some default headers like mentioned in the body below<\/p>\n<pre><code>{\n    &quot;Inputs&quot;: {\n         &quot;input_1&quot; : &quot;content&quot;\n         &quot;input_2: : &quot;content&quot;\n         ......\n    },\n    &quot;GlobalParameters&quot;: 0\n}\n<\/code><\/pre>",
        "Challenge_closed_time":1651111084096,
        "Challenge_comment_count":0,
        "Challenge_created_time":1651094225790,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1651098753480,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/72035391",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":11.0,
        "Challenge_reading_time":10.28,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":4.6828627778,
        "Challenge_title":"AzureML schema \"list index out of range\" error",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":78.0,
        "Challenge_word_count":97,
        "Platform":"Stack Overflow",
        "Poster_created_time":1651093614703,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Netherland",
        "Poster_reputation_count":19.0,
        "Poster_view_count":12.0,
        "Solution_body":"<p>Change the &quot;GlobalParameter&quot; value to any floating number other than 1.0 or even you can remove it and execute. Sometimes, Global parameter will cause the issue. Check the below documentation.<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/746784\/azure-ml-studio-error-while-testing-real-time-endp.html\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/746784\/azure-ml-studio-error-while-testing-real-time-endp.html<\/a><\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":22.0,
        "Solution_reading_time":6.63,
        "Solution_score_count":0.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":34.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1424453610300,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":1237.0,
        "Answerer_view_count":116.0,
        "Challenge_adjusted_solved_time":12.2603875,
        "Challenge_answer_count":3,
        "Challenge_body":"<p>I've searched for hours for this and can't find a single thing that answers the question. I've created and published a new Azure Machine Learning service, and have created an endpoint. I can call the service using the Postman REST CLient, but accessing it via a JavaScript webpage returns a console log saying that CORS is enabled for the service. Now, for the life of me, I can't figure out how to disable CORS for Azure Machine Learning services. Any help would be much appreciated, thanks!<\/p>",
        "Challenge_closed_time":1454387492627,
        "Challenge_comment_count":4,
        "Challenge_created_time":1421424031317,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1454343355232,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/27987910",
        "Challenge_link_count":0,
        "Challenge_participation_count":7,
        "Challenge_readability":6.7,
        "Challenge_reading_time":6.46,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":12.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":9156.5170305556,
        "Challenge_title":"Azure Machine Learning - CORS",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":3242.0,
        "Challenge_word_count":89,
        "Platform":"Stack Overflow",
        "Poster_created_time":1403948655636,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":135.0,
        "Poster_view_count":15.0,
        "Solution_body":"<p>Currently, we don't support disabling CORS on API side but you can either use the above option or you can use the API management service to disable CORS. The links below should help you with this<\/p>\n\n<p>Here are the links: <a href=\"http:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/api-management-get-started\/\" rel=\"noreferrer\">step by step<\/a> guide, also this <a href=\"http:\/\/channel9.msdn.com\/Blogs\/AzureApiMgmt\/Last-mile-Security\" rel=\"noreferrer\">video<\/a> on setting headers, and <a href=\"https:\/\/msdn.microsoft.com\/en-us\/library\/azure\/dn894084.aspx#JSONP\" rel=\"noreferrer\">this doc<\/a> on policies.<\/p>\n\n<p>API Management service allow CORS by enabling it in the API configuration page<\/p>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":3.0,
        "Solution_readability":11.6,
        "Solution_reading_time":9.27,
        "Solution_score_count":4.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":74.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1340833876128,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":751.0,
        "Answerer_view_count":73.0,
        "Challenge_adjusted_solved_time":1.1074488889,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I'm trying to call an Azure Machine Learning Pipeline Endpoint I've set up using C# &amp; the Machine Learning REST api.<\/p>\n<p>I am certain that I have the Service Principal configured correctly, as I can successfully authenticate &amp; hit the endpoint using the <code>azureml-core<\/code> python sdk:<\/p>\n<pre><code>sp = ServicePrincipalAuthentication(\n    tenant_id=tenant_id,\n    service_principal_id=service_principal_id,\n    service_principal_password=service_principal_password)\nws =Workspace.get(\n    name=workspace_name, \n    resource_group=resource_group, \n    subscription_id=subscription_id, \n    auth=sp)\n\nendpoint = PipelineEndpoint.get(ws, name='MyEndpoint')\nendpoint.submit('Test_Experiment')\n<\/code><\/pre>\n<p>I'm using the following example in C# to attempt to run my endpoint: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-pipelines#run-a-published-pipeline-using-c\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-pipelines#run-a-published-pipeline-using-c<\/a><\/p>\n<p>I'm attempting to fill <code>auth_key<\/code> with the following code:<\/p>\n<pre><code>var clientId = Environment.GetEnvironmentVariable(&quot;AZURE_CLIENT_ID&quot;);\nvar clientSecret = Environment.GetEnvironmentVariable(&quot;AZURE_CLIENT_SECRET&quot;);\nvar tenantId = Environment.GetEnvironmentVariable(&quot;AZURE_TENANT_ID&quot;);\n\nvar cred = new ClientSecretCredential(tenantId, clientId, clientSecret);\nvar auth_key = cred.GetToken(new Azure.Core.TokenRequestContext(new string[] {&quot;.default&quot; }));\n<\/code><\/pre>\n<p>I receive a 401 (unauthorized).<\/p>\n<p>What am I am doing wrong?<\/p>\n<ul>\n<li>UPDATE *<\/li>\n<\/ul>\n<p>I changed the 'scopes' param in the <code>TokenRequestContext<\/code> to look like:<\/p>\n<pre><code>var auth_key = cred.GetToken(new Azure.Core.TokenRequestContext(new string[] { &quot;http:\/\/DataTriggerApp\/.default&quot; }));\n<\/code><\/pre>\n<p><code>http:\/\/DataTriggerApp<\/code> is one of the <code>servicePrincipalNames<\/code> that shows up when i query my Service Principal from the azure CLI.<\/p>\n<p>Now, when I attempt to use the returned token to call the Machine Learning Pipeline Endpoint, I receive a 403 instead of a 401.  Maybe some progress?<\/p>",
        "Challenge_closed_time":1634160031172,
        "Challenge_comment_count":0,
        "Challenge_created_time":1634153827710,
        "Challenge_favorite_count":1.0,
        "Challenge_last_edit_time":1634156473112,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/69561386",
        "Challenge_link_count":4,
        "Challenge_participation_count":1,
        "Challenge_readability":15.7,
        "Challenge_reading_time":30.97,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":19,
        "Challenge_solved_time":1.7231838889,
        "Challenge_title":"How do I use Service Principal authentication with an Azure Machine Learning Pipeline Endpoint in C#?",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":752.0,
        "Challenge_word_count":204,
        "Platform":"Stack Overflow",
        "Poster_created_time":1340833876128,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":751.0,
        "Poster_view_count":73.0,
        "Solution_body":"<p>Ok, through a lot of trial-and-error I was able to come up with two ways of acquiring a token that allows me to hit my Azure Machine Learning Pipeline Endpoint through the REST api.  One uses Microsoft.Identity.Client &amp; one uses Azure.Identity.<\/p>\n<pre><code>using Microsoft.Identity.Client;\n\n...\n\npublic static async Task&lt;string&gt; GetAccessToken()\n{\n      var clientId = Environment.GetEnvironmentVariable(&quot;AZURE_CLIENT_ID&quot;);\n      var clientSecret = Environment.GetEnvironmentVariable(&quot;AZURE_CLIENT_SECRET&quot;);\n      var tenantId = Environment.GetEnvironmentVariable(&quot;AZURE_TENANT_ID&quot;);\n\n   \n      var app = ConfidentialClientApplicationBuilder.Create(clientId)\n                                                .WithClientSecret(clientSecret)                                                \n                                                .WithAuthority(AzureCloudInstance.AzurePublic, tenantId)\n                                                .Build();\n      var result = await app.AcquireTokenForClient(new string[] { &quot;https:\/\/ml.azure.com\/.default&quot; }).ExecuteAsync();\n      return result.AccessToken;\n}\n<\/code><\/pre>\n<p>Or:<\/p>\n<pre><code>using Azure.Identity;\n...\n\npublic static async Task&lt;string&gt; GetAccessToken()\n{\n      var clientId = Environment.GetEnvironmentVariable(&quot;AZURE_CLIENT_ID&quot;);\n      var clientSecret = Environment.GetEnvironmentVariable(&quot;AZURE_CLIENT_SECRET&quot;);\n      var tenantId = Environment.GetEnvironmentVariable(&quot;AZURE_TENANT_ID&quot;);\n\n\n      var cred = new ClientSecretCredential(tenantId, clientId, clientSecret);\n      var token =  await cred.GetTokenAsync(new Azure.Core.TokenRequestContext(new string[] { &quot;https:\/\/ml.azure.com\/.default&quot; }));\n      return token.Token;\n}\n<\/code><\/pre>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1634160459928,
        "Solution_link_count":2.0,
        "Solution_readability":22.1,
        "Solution_reading_time":20.67,
        "Solution_score_count":1.0,
        "Solution_sentence_count":18.0,
        "Solution_word_count":107.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":32.7057008333,
        "Challenge_answer_count":5,
        "Challenge_body":"<p>I am new to the Azure ML Studio and just deployed the bike-rental regression model. When I tried to test it using the built in test tool in the studio, I am getting the attached error. Similar results running the Python code as well. Can someone please help me?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/176918-mlerror.png?platform=QnA\" alt=\"176918-mlerror.png\" \/>    <\/p>",
        "Challenge_closed_time":1645695329740,
        "Challenge_comment_count":4,
        "Challenge_created_time":1645577589217,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/746784\/azure-ml-studio-error-while-testing-real-time-endp",
        "Challenge_link_count":1,
        "Challenge_participation_count":9,
        "Challenge_readability":8.8,
        "Challenge_reading_time":6.13,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":32.7057008333,
        "Challenge_title":"Azure ML Studio error while testing real-time endpoint -  list index out of range",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":66,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=b7844017-59f9-4d2e-a021-76c2270e06ca\">@Kumar, Priya  <\/a> Thanks for the question. It's known issue and the product team working on the fix to change in the UI.    <\/p>\n<p>Workaround: As shown below please set the GlobalParameters flag to 1.0 or a float number or remove it.     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/177485-image.png?platform=QnA\" alt=\"177485-image.png\" \/>    <\/p>\n",
        "Solution_comment_count":3.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":9.4,
        "Solution_reading_time":5.69,
        "Solution_score_count":3.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":48.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1415722650716,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Verona, VR, Italy",
        "Answerer_reputation_count":4811.0,
        "Answerer_view_count":713.0,
        "Challenge_adjusted_solved_time":72.4820763889,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am using Azure Machine Learning Service to deploy a ML model as web service.<\/p>\n<p>I <a href=\"https:\/\/stackoverflow.com\/a\/55281703\/4240413\">registered a <code>model<\/code><\/a> and now would like to deploy it as an ACI web service as in <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-deploy-and-where#aci\" rel=\"nofollow noreferrer\">the guide<\/a>.<\/p>\n<p>To do so I define<\/p>\n<pre><code>from azureml.core.webservice import Webservice, AciWebservice\nfrom azureml.core.image import ContainerImage\n\naciconfig = AciWebservice.deploy_configuration(cpu_cores=4, \n                      memory_gb=32, \n                      tags={&quot;data&quot;: &quot;text&quot;,  &quot;method&quot; : &quot;NB&quot;}, \n                      description='Predict something')\n<\/code><\/pre>\n<p>and<\/p>\n<pre><code>image_config = ContainerImage.image_configuration(execution_script=&quot;score.py&quot;, \n                      docker_file=&quot;Dockerfile&quot;,\n                      runtime=&quot;python&quot;, \n                      conda_file=&quot;myenv.yml&quot;)\n<\/code><\/pre>\n<p>and create an image with<\/p>\n<pre><code>image = ContainerImage.create(name = &quot;scorer-image&quot;,\n                      models = [model],\n                      image_config = image_config,\n                      workspace = ws\n                      )\n<\/code><\/pre>\n<p>Image creation succeeds with<\/p>\n<blockquote>\n<p>Creating image Image creation operation finished for image\nscorer-image:5, operation &quot;Succeeded&quot;<\/p>\n<\/blockquote>\n<p>Also, troubleshooting the image by running it locally on an Azure VM with<\/p>\n<pre><code>sudo docker run -p 8002:5001 myscorer0588419434.azurecr.io\/scorer-image:5\n<\/code><\/pre>\n<p>allows me to run (locally) queries successfully against <code>http:\/\/localhost:8002\/score<\/code>.<\/p>\n<p>However, deployment with<\/p>\n<pre><code>service_name = 'scorer-svc'\nservice = Webservice.deploy_from_image(deployment_config = aciconfig,\n                                        image = image,\n                                        name = service_name,\n                                        workspace = ws)\n<\/code><\/pre>\n<p>fails with<\/p>\n<blockquote>\n<p>Creating service<br \/>\nRunning.<br \/>\nFailedACI service creation operation finished, operation &quot;Failed&quot;<br \/>\nService creation polling reached terminal state, current service state: Transitioning<br \/>\nService creation polling reached terminal state, unexpected response received. Transitioning<\/p>\n<\/blockquote>\n<p>I tried setting in the <code>aciconfig<\/code> more generous <code>memory_gb<\/code>, but to no avail: the deployment stays in a <em>transitioning<\/em> state (like in the image below if monitored on the Azure portal):\n<a href=\"https:\/\/i.stack.imgur.com\/gCjI3.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/gCjI3.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Also, running <code>service.get_logs()<\/code> gives me<\/p>\n<blockquote>\n<p>WebserviceException: Received bad response from Model Management\nService: Response Code: 404<\/p>\n<\/blockquote>\n<p>What could possibly be the culprit?<\/p>",
        "Challenge_closed_time":1553818018048,
        "Challenge_comment_count":2,
        "Challenge_created_time":1553557082573,
        "Challenge_favorite_count":3.0,
        "Challenge_last_edit_time":1597618502196,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/55347910",
        "Challenge_link_count":5,
        "Challenge_participation_count":3,
        "Challenge_readability":15.5,
        "Challenge_reading_time":38.47,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":4.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":20,
        "Challenge_solved_time":72.4820763889,
        "Challenge_title":"Why does my ML model deployment in Azure Container Instance still fail with \"current service state: Transitioning\"?",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":3489.0,
        "Challenge_word_count":261,
        "Platform":"Stack Overflow",
        "Poster_created_time":1415722650716,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Verona, VR, Italy",
        "Poster_reputation_count":4811.0,
        "Poster_view_count":713.0,
        "Solution_body":"<p>If ACI deployment fails, one solution is trying to allocate <em>less<\/em> resources, e.g.<\/p>\n\n<pre><code>aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n                  memory_gb=8, \n                  tags={\"data\": \"text\",  \"method\" : \"NB\"}, \n                  description='Predict something')\n<\/code><\/pre>\n\n<p>While the error messages thrown are not particularly informative, this is actually clearly stated in the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/container-instances\/container-instances-region-availability\" rel=\"nofollow noreferrer\">documentation<\/a>:<\/p>\n\n<blockquote>\n  <p>When a region is under heavy load, you may experience a failure when\n  deploying instances. To mitigate such a deployment failure, try\n  deploying instances with lower resource settings [...]<\/p>\n<\/blockquote>\n\n<p>The documentation also states which are the maximum values of the CPU\/RAM resources available in the different regions (at the time of writing, requiring a deployment with <code>memory_gb=32<\/code> would likely fail in all regions because of insufficient resources).<\/p>\n\n<p>Upon requiring less resources, deployment should succeed with <\/p>\n\n<blockquote>\n  <p>Creating service<br>\n  Running......................................................<br>\n  SucceededACI service creation operation finished, operation<br>\n  \"Succeeded\" Healthy<\/p>\n<\/blockquote>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1554115865523,
        "Solution_link_count":1.0,
        "Solution_readability":15.7,
        "Solution_reading_time":17.17,
        "Solution_score_count":3.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":134.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1587281590603,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":473.0,
        "Answerer_view_count":37.0,
        "Challenge_adjusted_solved_time":511.5126291667,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I'm using sagemaker model monitor.<\/p>\n\n<p>When capturing data, it outputs the following json file.<\/p>\n\n<pre><code>{\"captureData\":{\"endpointInput\":{\"observedContentType\":\"text\/csv\",\"mode\":\"INPUT\",\"data\":\"MSwwLjUzLDAuNDIsMC4xMzUsMC42NzcsMC4yNTY1LDAuMTQxNSwwLjIx\",\"encoding\":\"BASE64\"},\"endpointOutput\":{\"observedContentType\":\"text\/csv; charset=utf-8\",\"mode\":\"OUTPUT\",\"data\":\"MTEuNjQzNDU1NTA1MzcxMDk0\",\"encoding\":\"BASE64\"}},\"eventMetadata\":{\"eventId\":\"33404924-c0d4-4044-9dc2-1e1f5575cb0a\",\"inferenceTime\":\"2020-06-04T05:45:45Z\"},\"eventVersion\":\"0\"}\n<\/code><\/pre>\n\n<p>I want the encoding to be csv but somehow it outputs base64.<br>\nWhen or where do we change the setting of the encoding?<br>\nIs it during the invoking the endpoint? or set when making endpoint config.<br>\nI looked for some documents but I couldn't find it.<\/p>",
        "Challenge_closed_time":1593091560008,
        "Challenge_comment_count":0,
        "Challenge_created_time":1591250114543,
        "Challenge_favorite_count":1.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/62187748",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":17.2,
        "Challenge_reading_time":11.74,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":8,
        "Challenge_solved_time":511.5126291667,
        "Challenge_title":"Change datacapture encoding data to csv",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":620.0,
        "Challenge_word_count":68,
        "Platform":"Stack Overflow",
        "Poster_created_time":1532422348876,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":27.0,
        "Poster_view_count":4.0,
        "Solution_body":"<p>I just came across this same problem! Seems like you need to specify <code>CaptureContentTypeHeader<\/code> params to tell SageMaker which content type headers to treat as CSV (or JSON), versus the default which is to base64 encode the payload!<\/p>\n<p>So e.g. adding the following to your <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/APIReference\/API_CreateEndpointConfig.html\" rel=\"nofollow noreferrer\">CreateEndpointConfig<\/a> call or boto3\/sagemaker SDK equivalent should fix it:<\/p>\n<pre><code>{\n   &quot;DataCaptureConfig&quot;: { \n      &quot;CaptureContentTypeHeader&quot;: { \n         &quot;CsvContentTypes&quot;: [ &quot;text\/csv&quot; ]\n      },\n   }\n}\n<\/code><\/pre>\n<p>I guess this is to allow for non-standard Content-Type headers? Providing a layer of config to resolve e.g:<\/p>\n<ul>\n<li><code>application\/x-mycoolmodel<\/code> -&gt; <code>JSON<\/code>, versus<\/li>\n<li><code>application\/x-secretsauce<\/code> -&gt; <code>BASE64<\/code><\/li>\n<\/ul>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":14.2,
        "Solution_reading_time":12.37,
        "Solution_score_count":2.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":90.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1504757520827,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":19041.0,
        "Answerer_view_count":968.0,
        "Challenge_adjusted_solved_time":90.3055055556,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I am trying to compare the service with a list of available service names, if service is found in the list then do update the service otherwise deploy the service.\nBut below condition only deploying new service even when service available in list variable?<\/p>\n<pre><code>SERVNAME=ner\nSERVICE=$(az ml service list -g $(ml_rg) --workspace-name $(ml_ws) --model-name $(model_name) --query &quot;[].name&quot;)\n\nif [[ &quot;$SERVNAME&quot; == &quot;$SERVICE&quot; ]];\nthen\n   echo &quot;Service Found: $(SERVNAME) and updating the service&quot;\n   az ml service update --name $(AKS_DEPLOYMENT_NAME) \\\n          --model '$(MODEL_NAME):$(MODEL_VERSION)' \\\n          --dc aksDeploymentConfig.json \\\n          --ic inferenceConfig.json \\\n          -e $(ml_env_name) --ev $(ml_env_version) \\\n          -g $(ml_rg) --workspace-name $(ml_ws) -v ;\nelse\n   echo &quot;Service Not found and starting deploying new service&quot;\n   az ml model deploy --name $(AKS_DEPLOYMENT_NAME) --model \\\n   '$(MODEL_NAME):$(MODEL_VERSION)' \\\n          --compute-target $(ml_aks_name) \\\n          --ic inferenceConfig.json \\\n          -e $(ml_env_name) --ev $(ml_env_version) \\\n          --dc aksDeploymentConfig.json \\\n          -g $(ml_rg) --workspace-name $(ml_ws) \\\n          --overwrite -v ;\nfi\n<\/code><\/pre>\n<p>Example list<\/p>\n<pre><code>SERVNAME=&quot;ner&quot;\nSERVICE=[ &quot;ner&quot;, &quot;aks-gpu-ner-0306210907&quot;, &quot;aks-gpu-ner-30012231&quot;, &quot;aks-gpu-ner-1305211336&quot;]\n<\/code><\/pre>",
        "Challenge_closed_time":1634000233752,
        "Challenge_comment_count":2,
        "Challenge_created_time":1633936791707,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1633953732907,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/69522401",
        "Challenge_link_count":0,
        "Challenge_participation_count":4,
        "Challenge_readability":14.2,
        "Challenge_reading_time":18.38,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":17.6227902778,
        "Challenge_title":"Compare String with list of strings in bash",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":1153.0,
        "Challenge_word_count":142,
        "Platform":"Stack Overflow",
        "Poster_created_time":1527066589807,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":35.0,
        "Poster_view_count":4.0,
        "Solution_body":"<p>Assuming the <code>az ml<\/code> command returns a json array string and you want to\ncheck if the array includes the value of variable <code>SERVNAME<\/code>, would you\nplease try:<\/p>\n<pre><code>SERVNAME=&quot;ner&quot;\nSERVICE='[ &quot;ner&quot;, &quot;aks-gpu-ner-0306210907&quot;, &quot;aks-gpu-ner-30012231&quot;, &quot;aks-gpu-ner-1305211336&quot;]'\n\nif [[ $SERVICE =~ &quot;\\&quot;$SERVNAME\\&quot;&quot; ]]; then\n    echo &quot;Service Found&quot;\n    # put your command here to update the service\nelse\n    echo &quot;Service Not Found&quot;\n    # put your command here to deploy new service\nfi\n<\/code><\/pre>\n<p>The regex operator <code>$SERVICE =~ &quot;\\&quot;$SERVNAME\\&quot;&quot;<\/code> matches if the string <code>$SERVICE<\/code>\ncontains the substring <code>$SERVNAME<\/code> enclosed with double quotes.<\/p>\n<p>If <code>jq<\/code> is available, you could also say:<\/p>\n<pre><code>result=$(echo &quot;$SERVICE&quot; | jq --arg var &quot;$SERVNAME&quot; '. | index($var)')\nif [[ $result != &quot;null&quot; ]]; then\n    echo &quot;Service Found&quot;\nelse\n    echo &quot;Service Not Found&quot;\nfi\n<\/code><\/pre>",
        "Solution_comment_count":6.0,
        "Solution_last_edit_time":1634278832727,
        "Solution_link_count":0.0,
        "Solution_readability":16.5,
        "Solution_reading_time":14.34,
        "Solution_score_count":2.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":111.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":25.5450377778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am facing error when I deploy in ACI. Is there a way to deploy the models when AMLS and  vnet are in different resource groups?<\/p>",
        "Challenge_closed_time":1601265795363,
        "Challenge_comment_count":1,
        "Challenge_created_time":1601173833227,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/108659\/from-amls-deploying-models-in-aci-in-a-vnet",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":5.3,
        "Challenge_reading_time":2.14,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":25.5450377778,
        "Challenge_title":"From AMLS Deploying  models in ACI in a vnet",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":34,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=abfc7f57-eb48-411e-acbd-c71bd241842b\">@AI866  <\/a> Thanks, If you are using AMLS SDK, Unfortunately this is a limitation today that we plan to address this in the near future.    <br \/>\nYou can create a pipeline, DevOps or manual process to deploy to any ACI in any VNET\/different subscription    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/container-instances\/container-instances-vnet\">https:\/\/learn.microsoft.com\/en-us\/azure\/container-instances\/container-instances-vnet<\/a>    <\/p>\n<p>Please follow the below for common troubleshooting issues.    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/container-instances\/container-instances-troubleshooting\">https:\/\/learn.microsoft.com\/en-us\/azure\/container-instances\/container-instances-troubleshooting<\/a>    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":19.9,
        "Solution_reading_time":10.75,
        "Solution_score_count":1.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":61.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":18.75,
        "Challenge_answer_count":2,
        "Challenge_body":"I have a model hosted on a Google Cloud endpoint and I would like to access it via the Java client.\u00a0 I've created a service account and a key for that service account with the , when I run my client code with the GOOGLE_APPLICATION_CREDENTIALS env var pointed to the key, I am able to call the service.\u00a0 When I try to authenticate explicitly using FixedCredentialProvider, it fails with an \"unauthenticated\" message.\u00a0\u00a0\n\nThe code is as follows\n\n```\n\nPredictionServiceSettings predictionServiceSettings =\n        PredictionServiceSettings.newBuilder().setEndpoint(location + \"-aiplatform.googleapis.com:443\")\n                .setCredentialsProvider(FixedCredentialsProvider.create(ServiceAccountCredentials.fromStream(new FileInputStream(\"\/Users\/ME\/Downloads\/XYZ.json\"))))\n                .build();\npredictionServiceClient = PredictionServiceClient.create(predictionServiceSettings);\nendpointName = EndpointName.of(project, location, endpointId);\nValue featureVal = Value.newBuilder().setStructValue(features).build();\nPredictResponse response =  predictionServiceClient.predict(\n        endpointName,\n        Collections.singletonList(featureVal),\n        Value.newBuilder().setNullValue(NullValue.NULL_VALUE).build());\n\n\n\n```",
        "Challenge_closed_time":1669109220000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1669041720000,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-can-I-explicitly-authenticate-to-the-ai-platform-using-the\/td-p\/491537\/jump-to\/first-unread-message",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":20.5,
        "Challenge_reading_time":16.53,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":10,
        "Challenge_solved_time":18.75,
        "Challenge_title":"How can I explicitly authenticate to the ai-platform using the java PredictionServiceClient",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":223.0,
        "Challenge_word_count":109,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"Hi,\n\nUpon checking your code, FixedCredentialsProvider.create()\u00a0accepts\u00a0com.google.auth.Credentials\u00a0as a parameter. Can you try a Credentials object to\u00a0FixedCredentialsProvider.create()? See code below:\n\nGoogleCredentials credentials = GoogleCredentials.fromStream(new FileInputStream(\"\/Users\/ME\/Downloads\/XYZ.json\")).createScoped(Lists.newArrayList(\"https:\/\/www.googleapis.com\/auth\/cloud-platform\"));\n\n\u00a0If code above did not work, can you provide the stack trace of the error? Also what roles did you assign on your service account?\n\nView solution in original post",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":13.1,
        "Solution_reading_time":7.4,
        "Solution_score_count":0.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":56.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":6.8756194445,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have created an ML model and created a real time endpoint with the model and also published the pipeline. I retrained it with a different parameter and ran the experiment. Also I have published the endpoint. Now how do I deploy it or replace it with the already created endpoint? <\/p>",
        "Challenge_closed_time":1612984587887,
        "Challenge_comment_count":0,
        "Challenge_created_time":1612959835657,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/267341\/how-do-i-deploy-the-run-after-retraining-a-publish",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":8.4,
        "Challenge_reading_time":4.45,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":6.8756194445,
        "Challenge_title":"How do I deploy the run after retraining a published endpoint and consume it?",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":65,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hi, this document provides information on how to <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-update-web-service\">update a web service<\/a> that was deployed with Azure Machine Learning. Hope this helps.    <\/p>\n",
        "Solution_comment_count":5.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":11.1,
        "Solution_reading_time":3.26,
        "Solution_score_count":0.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":24.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":25.7594230556,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>Hi, I trained and deployed a ML model via Auto ML. The result looks like this:  <br \/>\n&quot;\\&quot;{\\\\&quot;result\\\\&quot;: [\\\\&quot;Test\\\\&quot;]}\\&quot;&quot;<\/p>\n<p>Once I did the same with an endpoint created with the Azure ML Designer my result looks like this:  <br \/>\n&quot;{\\&quot;Results\\&quot;: {\\&quot;WebServiceOutput0\\&quot;: [{\\&quot;Scored Labels\\&quot;: \\&quot;Test\\&quot;}]}}&quot;<\/p>\n<p>Is there a way to configure the response that it looks similar to the AutoML response?<\/p>\n<p>Thanks :)<\/p>",
        "Challenge_closed_time":1606912260000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1606819526077,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/181635\/how-to-configute-webserviceoutput",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":8.5,
        "Challenge_reading_time":7.11,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":25.7594230556,
        "Challenge_title":"How to configute WebServiceOutput?",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":65,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=fe5bc84e-425f-4db0-a234-78d2a8fbbae1\">@ID_27051995  <\/a> Unfortunately, AutoML and AML Designer currently generates 2 different swagger format automatically, and there is no way to configure the output format. We are working on to address this inconsistency, and the Designer swagger format will be the converged format. Cheers!<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":16.6,
        "Solution_reading_time":4.67,
        "Solution_score_count":1.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":44.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":316.8641666667,
        "Challenge_answer_count":8,
        "Challenge_body":"## Expected Behavior\r\n`dbx deploy --environment=default` succeeds\r\n\r\n## Current Behavior\r\nThe command returns \r\n`mlflow.exceptions.RestException: INVALID_PARAMETER_VALUE: Experiment with id '2170254243754186' does not exist.`\r\n\r\n## Steps to Reproduce (for bugs)\r\nFollow the instructions at https:\/\/docs.gcp.databricks.com\/dev-tools\/ide-how-to.html#run-with-dbx\r\n\r\n## Context\r\nTrying to set up dbx for the first time.\r\n\r\n## Your Environment\r\nmac os m1 2021 with macos Monterey 12.5\r\n\r\n* dbx version used: DataBricks eXtensions aka dbx, version ~> 0.6.11\r\n* Databricks Runtime version: Version 0.17.1",
        "Challenge_closed_time":1661539227000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1660398516000,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/github.com\/databrickslabs\/dbx\/issues\/385",
        "Challenge_link_count":1,
        "Challenge_participation_count":8,
        "Challenge_readability":11.6,
        "Challenge_reading_time":8.05,
        "Challenge_repo_contributor_count":28.0,
        "Challenge_repo_fork_count":79.0,
        "Challenge_repo_issue_count":582.0,
        "Challenge_repo_star_count":246.0,
        "Challenge_repo_watch_count":16.0,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":8,
        "Challenge_solved_time":316.8641666667,
        "Challenge_title":"dbx deploy fails due to mlflow experiment not found",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":73,
        "Platform":"Github",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"hi @zermelozf , \r\ncould you please provide full stack trace?  Sure, here it is:\r\n\r\n```\r\ndbx deploy --environment=default\r\n[dbx][2022-08-13 22:46:37.005] Starting new deployment for environment default\r\n[dbx][2022-08-13 22:46:37.006] Using profile provided from the project file\r\n[dbx][2022-08-13 22:46:37.006] Found auth config from provider ProfileEnvConfigProvider, verifying it\r\n[dbx][2022-08-13 22:46:37.007] Found auth config from provider ProfileEnvConfigProvider, verification successful\r\n[dbx][2022-08-13 22:46:37.007] Profile DEFAULT will be used for deployment\r\nTraceback (most recent call last):\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/bin\/dbx\", line 8, in <module>\r\n    sys.exit(cli())\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/click\/core.py\", line 1130, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/click\/core.py\", line 1055, in main\r\n    rv = self.invoke(ctx)\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/click\/core.py\", line 1657, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/click\/core.py\", line 1404, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/click\/core.py\", line 760, in invoke\r\n    return __callback(*args, **kwargs)\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/dbx\/commands\/deploy.py\", line 143, in deploy\r\n    api_client = prepare_environment(environment)\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/dbx\/utils\/common.py\", line 38, in prepare_environment\r\n    MlflowStorageConfigurationManager.prepare(info)\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/dbx\/api\/storage\/mlflow_based.py\", line 42, in prepare\r\n    cls._setup_experiment(properties)\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/dbx\/api\/storage\/mlflow_based.py\", line 53, in _setup_experiment\r\n    experiment: Optional[Experiment] = mlflow.get_experiment_by_name(properties.workspace_dir)\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/mlflow\/tracking\/fluent.py\", line 1042, in get_experiment_by_name\r\n    return MlflowClient().get_experiment_by_name(name)\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/mlflow\/tracking\/client.py\", line 566, in get_experiment_by_name\r\n    return self._tracking_client.get_experiment_by_name(name)\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py\", line 226, in get_experiment_by_name\r\n    return self.store.get_experiment_by_name(name)\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 365, in get_experiment_by_name\r\n    raise e\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 351, in get_experiment_by_name\r\n    response_proto = self._call_endpoint(GetExperimentByName, req_body)\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 57, in _call_endpoint\r\n    return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/mlflow\/utils\/rest_utils.py\", line 274, in call_endpoint\r\n    response = verify_rest_response(response, endpoint)\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/mlflow\/utils\/rest_utils.py\", line 200, in verify_rest_response\r\n    raise RestException(json.loads(response.text))\r\nmlflow.exceptions.RestException: INVALID_PARAMETER_VALUE: Experiment with id '2170254243754186' does not exist.\r\n``` hi @zermelozf , \r\nit seems to me that you're using an old version of `dbx`. Please upgrade to the latest 0.7.0 (or at least to 0.6.12).  hi @renardeinside I had the same issue mentioned here. I upgraded to dbx 0.7.0 and now the error looks like this:\r\nRestException: INVALID_PARAMETER_VALUE: Experiment with id '2624352622693299' does not exist.\r\nIt only happens if you deploy a job for the first time. Deploying changes to an existing job works fine. hi @frida-ah , \r\nwhat's the MLflow version you're using? I'm asking because I'm not running into this issue in any of the tests  could you please also verify that you have correct [databricks profile configured as in Step 3 point 4 of the public doc](https:\/\/docs.gcp.databricks.com\/dev-tools\/ide-how-to.html#step-3-install-the-code-samples-dependencies)?\r\n\r\nif it's still the case, please provide the deploy command with `dbx deploy --debug` option (please feel free to omit the host url)? \r\nReally curious where is this coming from.\r\n Hi @renardeinside I don't have mlflow in my requirements.txt. I can also confirm that I have the correct databricks profile configured in the deployment.json file as such:\r\n\r\n{\r\n  \"environments\": {\r\n    \"default\": {\r\n      \"profile\": \"DEFAULT\",\r\n      \"workspace_dir\": \"\/Shared\/dbx\/projects\/<project_name>\/<...>\",\r\n      \"artifact_location\": \"dbfs:\/Shared\/dbx\/projects\/<project_name>\/<...>\"\r\n    }\r\n  }\r\n}\r\n\r\ndbx deploy --environment default --deployment-file=conf\/deployment.json --jobs=<job_name>\r\n\r\nI have fixed the issue using a workaround - sorry I didn't have more time to invest in this. I created an artifact manually through the UI in the location where the artifact should be. Then I deleted it. And then the artifact was created again through the IDE and GitHub Actions. \r\n\r\nI think the issue is with Databricks having a bug when creating an artifact for the first time.  hi @frida-ah , \r\nstill pretty strange behaviour, but thanks a lot anyways. We're going to change the mlflow client logic accordingly to fix this issue.",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":14.8,
        "Solution_reading_time":77.33,
        "Solution_score_count":0.0,
        "Solution_sentence_count":61.0,
        "Solution_word_count":510.0,
        "Tool":"MLflow"
    },
    {
        "Answerer_created_time":1619163566860,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":1730.0,
        "Answerer_view_count":555.0,
        "Challenge_adjusted_solved_time":23.8292419444,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have multiple models in Google Vertex AI and I want to create an endpoint to serve my predictions.\nI need to run aggregation algorithms, like the Voting algorithm on the output of my models.\nI have not found any ways of using the models together so that I can run the voting algorithms on the results.\nDo I have to create a new model, curl my existing models and then run my algorithms on the results?<\/p>",
        "Challenge_closed_time":1647950025928,
        "Challenge_comment_count":3,
        "Challenge_created_time":1647864699137,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/71557442",
        "Challenge_link_count":0,
        "Challenge_participation_count":4,
        "Challenge_readability":8.8,
        "Challenge_reading_time":5.69,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":23.7018863889,
        "Challenge_title":"How combine results from multiple models in Google Vertex AI?",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":253.0,
        "Challenge_word_count":86,
        "Platform":"Stack Overflow",
        "Poster_created_time":1372407778700,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Oslo, Norway",
        "Poster_reputation_count":134.0,
        "Poster_view_count":74.0,
        "Solution_body":"<p>There is no in-built provision to implement aggregation algorithms in Vertex AI. To <code>curl<\/code> results from the models then aggregate them, we would need to deploy all of them to individual endpoints. Instead, I would suggest the below method to deploy the models and the meta-model(aggregate model) to a single endpoint using <a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/predictions\/use-custom-container\" rel=\"nofollow noreferrer\">custom containers for prediction<\/a>. The custom container requirements can be found <a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/predictions\/custom-container-requirements\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>\n<p>You can load the model artifacts from GCS into a custom container. If the same set of models are used (i.e) the input models to the meta-model do not change, you can package them inside the container to reduce load time. Then, a custom HTTP logic can be used to return the aggregation output like so. This is a sample custom flask server logic.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def get_models_from_gcs():\n    ## Pull the required model artifacts from GCS and load them here.\n    models = [model_1, model_2, model_3]\n    return models\n\ndef aggregate_predictions(predictions):\n    ## Your aggregation algorithm here\n    return aggregated_result\n\n\n@app.post(os.environ['AIP_PREDICT_ROUTE'])\nasync def predict(request: Request):\n    body = await request.json()\n    instances = body[&quot;instances&quot;]\n    inputs = np.asarray(instances)\n    preprocessed_inputs = _preprocessor.preprocess(inputs)\n\n    models = get_models_from_gcs()\n    predictions = []\n    \n    for model in models:\n        predictions.append(model.predict(preprocessed_inputs))\n\n    aggregated_result = aggregate_predictions(predictions)\n\n    return {&quot;aggregated_predictions&quot;: aggregated_result}\n<\/code><\/pre>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1647950484408,
        "Solution_link_count":2.0,
        "Solution_readability":14.5,
        "Solution_reading_time":23.43,
        "Solution_score_count":1.0,
        "Solution_sentence_count":18.0,
        "Solution_word_count":191.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_created_time":1442180190107,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":3203.0,
        "Answerer_view_count":400.0,
        "Challenge_adjusted_solved_time":14.5543175,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am trying to invoke a MultiModel Endpoint with a RandomCutForest Model. I receive error though, 'Error loading model'. I can invoke the endpoint with models given from the examples.\nAm I missing something e.g. limitations on what models I can use? <\/p>\n\n<p>For MultiModel inspiration I am using below:<\/p>\n\n<blockquote>\n  <p><a href=\"https:\/\/github.com\/awslabs\/amazon-sagemaker-examples\/blob\/master\/advanced_functionality\/multi_model_xgboost_home_value\/xgboost_multi_model_endpoint_home_value.ipynb\" rel=\"nofollow noreferrer\">https:\/\/github.com\/awslabs\/amazon-sagemaker-examples\/blob\/master\/advanced_functionality\/multi_model_xgboost_home_value\/xgboost_multi_model_endpoint_home_value.ipynb<\/a><\/p>\n  \n  <p><a href=\"https:\/\/aws.amazon.com\/blogs\/machine-learning\/save-on-inference-costs-by-using-amazon-sagemaker-multi-model-endpoints\/\" rel=\"nofollow noreferrer\">https:\/\/aws.amazon.com\/blogs\/machine-learning\/save-on-inference-costs-by-using-amazon-sagemaker-multi-model-endpoints\/<\/a><\/p>\n<\/blockquote>\n\n<p>I am trying to deploy the outputted 'model.tar.gz' from below RCF example in the MultiModel endpoint:<\/p>\n\n<blockquote>\n  <p><a href=\"https:\/\/github.com\/awslabs\/amazon-sagemaker-examples\/blob\/master\/introduction_to_amazon_algorithms\/random_cut_forest\/random_cut_forest.ipynb\" rel=\"nofollow noreferrer\">https:\/\/github.com\/awslabs\/amazon-sagemaker-examples\/blob\/master\/introduction_to_amazon_algorithms\/random_cut_forest\/random_cut_forest.ipynb<\/a><\/p>\n<\/blockquote>\n\n<pre><code>model_name = 'model'\nfull_model_name = '{}.tar.gz'.format(model_name)\nfeatures = data\n\nbody = ','.join(map(str, features)) + '\\n'\nresponse = runtime_sm_client.invoke_endpoint(\n                    EndpointName=endpoint_name,\n                    ContentType='text\/csv',\n                    TargetModel=full_model_name,\n                    Body=body)\nprint(response)\n<\/code><\/pre>\n\n<p><strong>Cloudwatch log Error:<\/strong><\/p>\n\n<pre><code>&gt; 2020-04-27 17:28:59,005 [INFO ]\n&gt; W-9003-b39b888fb4a3fa6cf83bb34a9-stdout\n&gt; com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Error loading model: Unable\n&gt; to load model: invalid load key, '{'. [17:28:59]\n&gt; \/workspace\/src\/learner.cc:334: Check failed: fi-&gt;Read(&amp;mparam_,\n&gt; sizeof(mparam_)) == sizeof(mparam_) (25 vs. 136) : BoostLearner: wrong\n&gt; model format 2020-04-27 17:28:59,005 [INFO ]\n&gt; W-9003-b39b888fb4a3fa6cf83bb34a9-stdout\n&gt; com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Stack trace: 2020-04-27\n&gt; 17:28:59,005 [INFO ] W-9003-b39b888fb4a3fa6cf83bb34a9-stdout\n&gt; com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   [bt] (0)\n&gt; \/miniconda3\/xgboost\/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24)\n&gt; [0x7f37ce1cacb4] 2020-04-27 17:28:59,005 [INFO ]\n&gt; W-9003-b39b888fb4a3fa6cf83bb34a9 com.amazonaws.ml.mms.wlm.WorkerThread\n&gt; - Backend response time: 0 2020-04-27 17:28:59,005 [INFO ] W-9003-b39b888fb4a3fa6cf83bb34a9-stdout\n&gt; com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   [bt] (1)\n&gt; \/miniconda3\/xgboost\/libxgboost.so(xgboost::LearnerImpl::Load(dmlc::Stream*)+0x4b5)\n&gt; [0x7f37ce266985] 2020-04-27 17:28:59,005 [INFO ]\n&gt; W-9003-b39b888fb4a3fa6cf83bb34a9-stdout\n&gt; com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   [bt] (2)\n&gt; \/miniconda3\/xgboost\/libxgboost.so(XGBoosterLoadModel+0x37)\n&gt; [0x7f37ce1bf417] 2020-04-27 17:28:59,005 [INFO ]\n&gt; W-9003-b39b888fb4a3fa6cf83bb34a9-stdout\n&gt; com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   [bt] (3)\n&gt; \/miniconda3\/lib\/python3.7\/lib-dynload\/..\/..\/libffi.so.6(ffi_call_unix64+0x4c)\n&gt; [0x7f37ee993ec0] 2020-04-27 17:28:59,005 [INFO ]\n&gt; W-9003-b39b888fb4a3fa6cf83bb34a9-stdout\n&gt; com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   [bt] (4)\n&gt; \/miniconda3\/lib\/python3.7\/lib-dynload\/..\/..\/libffi.so.6(ffi_call+0x22d)\n&gt; [0x7f37ee99387d] 2020-04-27 17:28:59,005 [INFO ]\n&gt; W-9003-b39b888fb4a3fa6cf83bb34a9-stdout\n&gt; com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   [bt] (5)\n&gt; \/miniconda3\/lib\/python3.7\/lib-dynload\/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce)\n&gt; [0x7f37eeba91de] 2020-04-27 17:28:59,005 [INFO ]\n&gt; W-9003-b39b888fb4a3fa6cf83bb34a9-stdout\n&gt; com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   [bt] (6)\n&gt; \/miniconda3\/lib\/python3.7\/lib-dynload\/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12c14)\n&gt; [0x7f37eeba9c14] 2020-04-27 17:28:59,005 [INFO ]\n&gt; W-9003-b39b888fb4a3fa6cf83bb34a9-stdout\n&gt; com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   [bt] (7)\n&gt; \/miniconda3\/bin\/python(_PyObject_FastCallKeywords+0x48b)\n&gt; [0x563d71b4218b] 2020-04-27 17:28:59,005 [INFO ]\n&gt; W-9003-b39b888fb4a3fa6cf83bb34a9-stdout\n&gt; com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   [bt] (8)\n&gt; \/miniconda3\/bin\/python(_PyEval_EvalFrameDefault+0x52cf)\n&gt; [0x563d71b91e8f] 2020-04-27 17:28:59,005 [INFO ]\n&gt; W-9003-b39b888fb4a3fa6cf83bb34a9-stdout\n&gt; com.amazonaws.ml.mms.wlm.WorkerLifeCycle -  2020-04-27 17:28:59,005\n&gt; [WARN ] W-9003-b39b888fb4a3fa6cf83bb34a9\n&gt; com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker thread\n&gt; exception. java.lang.IllegalArgumentException: reasonPhrase contains\n&gt; one of the following prohibited characters: \\r\\n: Unable to load\n&gt; model: Unable to load model: invalid load key, '{'. [17:28:59]\n&gt; \/workspace\/src\/learner.cc:334: Check failed: fi-&gt;Read(&amp;mparam_,\n&gt; sizeof(mparam_)) == sizeof(mparam_) (25 vs. 136) : BoostLearner: wrong\n&gt; model format Stack trace:   [bt] (0)\n&gt; \/miniconda3\/xgboost\/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24)\n&gt; [0x7f37ce1cacb4]   [bt] (1)\n&gt; \/miniconda3\/xgboost\/libxgboost.so(xgboost::LearnerImpl::Load(dmlc::Stream*)+0x4b5)\n&gt; [0x7f37ce266985]   [bt] (2)\n&gt; \/miniconda3\/xgboost\/libxgboost.so(XGBoosterLoadModel+0x37)\n&gt; [0x7f37ce1bf417]   [bt] (3)\n&gt; \/miniconda3\/lib\/python3.7\/lib-dynload\/..\/..\/libffi.so.6(ffi_call_unix64+0x4c)\n&gt; [0x7f37ee993ec0]   [bt] (4)\n&gt; \/miniconda3\/lib\/python3.7\/lib-dynload\/..\/..\/libffi.so.6(ffi_call+0x22d)\n&gt; [0x7f37ee99387d]   [bt] (5)\n&gt; \/miniconda3\/lib\/python3.7\/lib-dynload\/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce)\n&gt; [0x7f37eeba91de]   [bt] (6)\n&gt; \/miniconda3\/lib\/python3.7\/lib-dynload\/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12c14)\n&gt; [0x7f37eeba9c14]   [bt] (7)\n&gt; \/miniconda3\/bin\/python(_PyObject_FastCallKeywords+0x48b)\n&gt; [0x563d71b4218b]   [bt] (8)\n&gt; \/miniconda3\/bin\/python(_PyEval_EvalFrameDefault+0x52cf)\n&gt; [0x563d71b91e8f]\n<\/code><\/pre>",
        "Challenge_closed_time":1588061581360,
        "Challenge_comment_count":0,
        "Challenge_created_time":1588009185817,
        "Challenge_favorite_count":1.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/61464960",
        "Challenge_link_count":6,
        "Challenge_participation_count":1,
        "Challenge_readability":22.8,
        "Challenge_reading_time":86.51,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":52,
        "Challenge_solved_time":14.5543175,
        "Challenge_title":"SageMaker multimodel and RandomCutForest",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":324.0,
        "Challenge_word_count":394,
        "Platform":"Stack Overflow",
        "Poster_created_time":1426492930156,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":398.0,
        "Poster_view_count":84.0,
        "Solution_body":"<p>SageMaker Random Cut Forest is part of the <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/algos.html\" rel=\"nofollow noreferrer\">built-in algorithm library<\/a> and cannot be deployed in multi-model endpoint (MME). Built-in algorithms currently cannot be deployed to MME. XGboost is an exception, since it has an open-source container <a href=\"https:\/\/github.com\/aws\/sagemaker-xgboost-container\" rel=\"nofollow noreferrer\">https:\/\/github.com\/aws\/sagemaker-xgboost-container<\/a>.<\/p>\n\n<p>If you really need to deploy a RCF to a multi-model endpoint, one option is to find a reasonably similar open-source implementation (for example <a href=\"https:\/\/github.com\/kLabUM\/rrcf\" rel=\"nofollow noreferrer\"><code>rrcf<\/code><\/a> looks reasonably serious: based <a href=\"http:\/\/proceedings.mlr.press\/v48\/guha16.pdf\" rel=\"nofollow noreferrer\">on the same paper from Guha et al<\/a> and with 170+ github stars) and create a custom MME docker container. The <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/build-multi-model-build-container.html\" rel=\"nofollow noreferrer\">documentation is here<\/a> and there is <a href=\"https:\/\/github.com\/giuseppeporcelli\/sagemaker-custom-serving-containers\/blob\/master\/multi-model-server-container\/notebook\/multi-model-server-container.ipynb\" rel=\"nofollow noreferrer\">an excellent tuto here<\/a><\/p>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":7.0,
        "Solution_readability":19.2,
        "Solution_reading_time":17.98,
        "Solution_score_count":2.0,
        "Solution_sentence_count":11.0,
        "Solution_word_count":116.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1442180190107,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":3203.0,
        "Answerer_view_count":400.0,
        "Challenge_adjusted_solved_time":141.7067575,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>With an <code>sagemaker.estimator.Estimator<\/code>, I want to re-<a href=\"https:\/\/sagemaker.readthedocs.io\/en\/stable\/api\/training\/estimators.html#sagemaker.estimator.EstimatorBase.deploy\" rel=\"nofollow noreferrer\">deploy<\/a> a model after retraining (calling <code>fit<\/code> with new data).<\/p>\n<p>When I call this<\/p>\n<pre><code>estimator.deploy(initial_instance_count=1, instance_type='ml.m5.xlarge')\n<\/code><\/pre>\n<p>I get an error<\/p>\n<pre><code>botocore.exceptions.ClientError: An error occurred (ValidationException) \nwhen calling the CreateEndpoint operation: \nCannot create already existing endpoint &quot;arn:aws:sagemaker:eu-east- \n1:1776401913911:endpoint\/zyx&quot;.\n<\/code><\/pre>\n<p>Apparently I want to use functionality like <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/APIReference\/API_UpdateEndpoint.html\" rel=\"nofollow noreferrer\">UpdateEndpoint<\/a>. How do I access that functionality from this API?<\/p>",
        "Challenge_closed_time":1601891469683,
        "Challenge_comment_count":0,
        "Challenge_created_time":1601630651783,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/64169189",
        "Challenge_link_count":2,
        "Challenge_participation_count":2,
        "Challenge_readability":20.5,
        "Challenge_reading_time":13.46,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":3.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":10,
        "Challenge_solved_time":72.4494166667,
        "Challenge_title":"How can I deploy a re-trained Sagemaker model to an endpoint?",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":1958.0,
        "Challenge_word_count":78,
        "Platform":"Stack Overflow",
        "Poster_created_time":1227171471292,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Israel",
        "Poster_reputation_count":17500.0,
        "Poster_view_count":1561.0,
        "Solution_body":"<p>Yes, under the hood the <code>model.deploy<\/code> creates a model, an endpoint configuration and an endpoint. When you call again the method from an already-deployed, trained estimator it will create an error because a similarly-configured endpoint is already deployed. What I encourage you to try:<\/p>\n<ul>\n<li><p>use the <code>update_endpoint=True<\/code> parameter. From the <a href=\"https:\/\/sagemaker.readthedocs.io\/en\/stable\/overview.html\" rel=\"noreferrer\">SageMaker SDK doc<\/a>:\n<em>&quot;Additionally, it is possible to deploy a different endpoint configuration, which links to your model, to an already existing\nSageMaker endpoint. This can be done by specifying the existing\nendpoint name for the <code>endpoint_name<\/code> parameter along with the\n<code>update_endpoint<\/code> parameter as True within your <code>deploy()<\/code> call.&quot;<\/em><\/p>\n<\/li>\n<li><p>Alternatively, if you want to create a separate model you can specify a new <code>model_name<\/code> in your <code>deploy<\/code><\/p>\n<\/li>\n<\/ul>",
        "Solution_comment_count":2.0,
        "Solution_last_edit_time":1602140796110,
        "Solution_link_count":1.0,
        "Solution_readability":14.0,
        "Solution_reading_time":13.16,
        "Solution_score_count":6.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":123.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1467237684900,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":613.0,
        "Answerer_view_count":39.0,
        "Challenge_adjusted_solved_time":1.5730691667,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I've trained a model on sagemaker and have created the endpoint. I'm trying to invoke the endpoint using postman. But when training the model and even after that, I have not specified any header for the training data. I'm at a loss as to how to create payload while sending a post request to sagemaker<\/p>",
        "Challenge_closed_time":1522946255432,
        "Challenge_comment_count":0,
        "Challenge_created_time":1522940592383,
        "Challenge_favorite_count":2.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/49675637",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":7.0,
        "Challenge_reading_time":4.33,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":8.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":1.5730691667,
        "Challenge_title":"How to pass a request to sagemaker using postman",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":6746.0,
        "Challenge_word_count":63,
        "Platform":"Stack Overflow",
        "Poster_created_time":1410972175307,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":1124.0,
        "Poster_view_count":153.0,
        "Solution_body":"<p>Once the endpoint is created, you can invoke it as any other restful service, with credentials and payload. <\/p>\n\n<p>I am guessing, there could be two places where might be stuck. \nOne could be, sending an actual PostMan Request with all the headers and everything. \nNewer version of Postman has AWS Signature as one of the Authorization types. You can use that to invoke the service. There are no other spacial headers required. Note that there is a bug in Postman still open (<a href=\"https:\/\/github.com\/postmanlabs\/postman-app-support\/issues\/1663\" rel=\"noreferrer\">issue-1663<\/a>) that only affects if you are a AWS federated account. Individual accounts should not be affected by this issue. <\/p>\n\n<p>Or, you could be stuck at the actual payload. When you invoke the SageMaker endpoint, the payload is passed as is to the model. If you want to preprocess the input before feeding it to the model, you'd have to implement an input_fn method and specify that when instantiating the model. <\/p>\n\n<p>You might also be able to invoke SageMaker endpoint using AWS SDK boto3 as follows <\/p>\n\n<pre><code>import boto3\nruntime= boto3.client('runtime.sagemaker')\n\npayload = getImageData()\n\n\nresult  = runtime.invoke_endpoint(\n    EndpointName='my_endpoint_name',\n    Body=payload,\n    ContentType='image\/jpeg'\n)\n<\/code><\/pre>\n\n<p>Hope this helps.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":9.4,
        "Solution_reading_time":16.63,
        "Solution_score_count":11.0,
        "Solution_sentence_count":15.0,
        "Solution_word_count":189.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1587507179987,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":1.0,
        "Answerer_view_count":5.0,
        "Challenge_adjusted_solved_time":0.0376611111,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I try to use AWS SageMaker following documentation. I successfully loaded data, trained and deployed the model.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/4Mjew.png\" rel=\"nofollow noreferrer\">deployed-model<\/a><\/p>\n<p>My next step have to be using AWS Lambda, connect it to this SageMaker endpoint.\nI saw, that I need to give Lambda IAM execution role permission to invoke a model endpoint.\nI add some data to IAM policy JSON and now it has this view<\/p>\n<pre><code>{\n&quot;Version&quot;: &quot;2012-10-17&quot;,\n&quot;Statement&quot;: [\n    {\n        &quot;Effect&quot;: &quot;Allow&quot;,\n        &quot;Action&quot;: &quot;logs:CreateLogGroup&quot;,\n        &quot;Resource&quot;: &quot;arn:aws:logs:us-east-1:&lt;my-account&gt;:*&quot;\n    },\n    {\n        &quot;Effect&quot;: &quot;Allow&quot;,\n        &quot;Action&quot;: [\n            &quot;logs:CreateLogStream&quot;,\n            &quot;logs:PutLogEvents&quot;\n        ],\n        &quot;Resource&quot;: [\n            &quot;arn:aws:logs:us-east-1:&lt;my-account&gt;:log-group:\/aws\/lambda\/test-sagemaker:*&quot;\n        ]\n    },\n    {\n        &quot;Effect&quot;: &quot;Allow&quot;,\n        &quot;Action&quot;: &quot;sagemaker:InvokeEndpoint&quot;,\n        &quot;Resource&quot;: &quot;*&quot;\n    }\n]\n<\/code><\/pre>\n<p>}<\/p>\n<p>Problem that even with role that have permission for invoking SageMaker endpoint my Lambda function didn't see it<\/p>\n<pre><code>An error occurred (ValidationError) when calling the InvokeEndpoint operation: Endpoint xgboost-2020-10-02-12-15-36-097 of account &lt;my-account&gt; not found.: ValidationError\n<\/code><\/pre>",
        "Challenge_closed_time":1601906782043,
        "Challenge_comment_count":0,
        "Challenge_created_time":1601650547150,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1601906646463,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/64173739",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":18.8,
        "Challenge_reading_time":19.63,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":71.1763591667,
        "Challenge_title":"AWS Sagemaker + AWS Lambda",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":623.0,
        "Challenge_word_count":131,
        "Platform":"Stack Overflow",
        "Poster_created_time":1587507179987,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":1.0,
        "Poster_view_count":5.0,
        "Solution_body":"<p>I found an error by myself. Problem was in different regions. For training and deploying model I used us-east-2 and for lambda I used us-east-1. Just creating all in same region fixed this issue!<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":5.4,
        "Solution_reading_time":2.48,
        "Solution_score_count":0.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":34.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1274693802127,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Hyderabad, India",
        "Answerer_reputation_count":1561.0,
        "Answerer_view_count":243.0,
        "Challenge_adjusted_solved_time":93.8230269445,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>When running the Azure ML Online endpoint commands, it works locally. But when I try to deploy it to Azure I get this error.\nCommand - <code>az ml online-deployment create --name blue --endpoint &quot;unique-name&quot; -f endpoints\/online\/managed\/sample\/blue-deployment.yml --all-traffic<\/code><\/p>\n<pre><code>{\n    &quot;status&quot;: &quot;Failed&quot;,\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;DriverFileNotFound&quot;,\n        &quot;message&quot;: &quot;Driver file with name score.py not found in provided dependencies. Please check the name of your file.&quot;,\n        &quot;details&quot;: [\n            {\n                &quot;code&quot;: &quot;DriverFileNotFound&quot;,\n                &quot;message&quot;: &quot;Driver file with name score.py not found in provided dependencies. Please check the name of your file.\\nThe build log is available in the workspace blob store \\&quot;coloraiamlsa\\&quot; under the path \\&quot;\/azureml\/ImageLogs\/1673692e-e30b-4306-ab81-2eed9dfd4020\/build.log\\&quot;&quot;,\n                &quot;details&quot;: [],\n                &quot;additionalInfo&quot;: []\n            }\n        ],\n        \n<\/code><\/pre>\n<p>This is the deployment YAML taken straight from <a href=\"https:\/\/github.com\/Azure\/azureml-examples\" rel=\"nofollow noreferrer\">azureml-examples<\/a> repo<\/p>\n<pre><code>$schema: https:\/\/azuremlschemas.azureedge.net\/latest\/managedOnlineDeployment.schema.json\nname: blue\nendpoint_name: my-endpoint\nmodel:\n  local_path: ..\/..\/model-1\/model\/sklearn_regression_model.pkl\ncode_configuration:\n  code: \n    local_path: ..\/..\/model-1\/onlinescoring\/\n  scoring_script: score.py\nenvironment: \n  conda_file: ..\/..\/model-1\/environment\/conda.yml\n  image: mcr.microsoft.com\/azureml\/openmpi3.1.2-ubuntu18.04:20210727.v1\ninstance_type: Standard_F2s_v2\ninstance_count: 1\n<\/code><\/pre>",
        "Challenge_closed_time":1642392913590,
        "Challenge_comment_count":0,
        "Challenge_created_time":1642055150693,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/70692270",
        "Challenge_link_count":2,
        "Challenge_participation_count":1,
        "Challenge_readability":14.5,
        "Challenge_reading_time":23.36,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":2.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":19,
        "Challenge_solved_time":93.8230269445,
        "Challenge_title":"Azure ML Online Endpoint deployment DriverFileNotFound Error",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":130.0,
        "Challenge_word_count":142,
        "Platform":"Stack Overflow",
        "Poster_created_time":1274693802127,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Hyderabad, India",
        "Poster_reputation_count":1561.0,
        "Poster_view_count":243.0,
        "Solution_body":"<p>Finally after lot of head banging, I have been able to consistently repro this bug in another Azure ML Workspace.<\/p>\n<p>I tried deploying the same sample in a brand new Azure ML workspace created and it went smoothly.<\/p>\n<p>At this point I remembered that I had upgraded the Storage Account of my previous AML Workspace to DataLake Gen2.<\/p>\n<p>So I did the same upgrade in this new workspace\u2019s storage account. After the upgrade, when I try to deploy the same endpoint, I get the same <code>DriverFileNotFoundError<\/code>!<\/p>\n<p>It seems Azure ML does not support Storage Account with DataLake Gen2 capabilities although the support page says otherwise. <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data#supported-data-storage-service-types\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data#supported-data-storage-service-types<\/a>.<\/p>\n<p>At this point my only option is to recreate a new workspace and deploy my code there. Hope Azure team fixes this soon.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":10.2,
        "Solution_reading_time":13.57,
        "Solution_score_count":0.0,
        "Solution_sentence_count":9.0,
        "Solution_word_count":132.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":0.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":144.7355655556,
        "Challenge_answer_count":1,
        "Challenge_body":"I want to enable data capture for a specific endpoint (so far, only via the console). The endpoint works fine and also logs & returns the desired results. However, no files are written to the specified S3 location.\n\n### Endpoint Configuration ###\n\nThe endpoint is based on a training job with a scikit learn classifier. It has only one variant which is a `ml.m4.xlarge` instance type. Data Capture is enabled with a sampling percentage of 100%. As data capture storage locations I tried `s3:\/\/<bucket-name>` as well as `s3:\/\/<bucket-name>\/<some-other-path>`. With the \"Capture content type\" I tried leaving everything blank, setting `text\/csv` in \"CSV\/Text\" and `application\/json` in \"JSON\".\n\n### Endpoint Invokation ###\n\nThe endpoint is invoked in a Lambda function with a client. Here's the call:\n```\nsagemaker_body_source = {\n            \"segments\": segments,\n            \"language\": language\n        }\npayload = json.dumps(sagemaker_body_source).encode()\nresponse = self.client.invoke_endpoint(EndpointName=endpoint_name,\n                                       Body=payload,\n                                       ContentType='application\/json',\n                                       Accept='application\/json')\nresult = json.loads(response['Body'].read().decode())\nreturn result[\"predictions\"]\n```\nInternally, the endpoint uses a Flask API with an `\/invocation` path that returns the result.\n\n### Logs ###\n\nThe endpoint itself works fine and the Flask API is logging input and output:\n```\nINFO:api:body: {'segments': [<strings...>], 'language': 'de'}\n```\n\n```\nINFO:api:output: {'predictions': [{'text': 'some text', 'label': 'some_label'}, ....]}\n```",
        "Challenge_closed_time":1660656368966,
        "Challenge_comment_count":0,
        "Challenge_created_time":1660135320930,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1668490449198,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUKWPP4eXTTZe5qIUDJAXnsQ\/sagemaker-data-capture-does-not-write-files",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":9.9,
        "Challenge_reading_time":19.7,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":17,
        "Challenge_solved_time":144.7355655556,
        "Challenge_title":"Sagemaker Data Capture does not write files",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":74.0,
        "Challenge_word_count":183,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"So the issue seemed to be related to the IAM role. The default role (`ModelEndpoint-Role`) does not have access to write S3 files. It worked via the SDK since it uses another role in the sagemaker studio. I did not receive any error message about this.",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1660656368966,
        "Solution_link_count":0.0,
        "Solution_readability":5.4,
        "Solution_reading_time":3.04,
        "Solution_score_count":0.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":46.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1577817693600,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Seattle, WA, USA",
        "Answerer_reputation_count":56.0,
        "Answerer_view_count":9.0,
        "Challenge_adjusted_solved_time":329.4975816667,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am aware that Sagemaker <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/multi-model-endpoints.html#multi-model-support\" rel=\"nofollow noreferrer\">does not support multi-model endpoints for their built-in image classification algorithm<\/a>. However, in the documentation they hint at building a custom container to use &quot;any other framework or algorithm&quot; with the multi-model endpoint functionality:<\/p>\n<blockquote>\n<p>To use any other framework or algorithm, use the SageMaker inference toolkit to build a container that supports multi-model endpoints. For information, see <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/build-multi-model-build-container.html\" rel=\"nofollow noreferrer\">Build Your Own Container with Multi Model Server<\/a>.<\/p>\n<\/blockquote>\n<p>Ideally, I would like to deploy many (20+) image classification models I have already trained to a single endpoint to save on costs. However, after reading the &quot;Build Your Own Container&quot; guide it is still not exactly clear to me how to build a custom inference container for the models produced by a non-custom algorithm. Most of the tutorials and example notebooks refer to using Pytorch or Sklearn. It is not clear to me that I could make inferences using these libraries on the models I've created with the built-in image classification algorithm.<\/p>\n<p><em>Is<\/em> it possible to create a container to support multi-model endpoints for unsupported built-in Sagemaker algorithms? If so, would somebody be able to hint at how this might be done?<\/p>",
        "Challenge_closed_time":1612378891027,
        "Challenge_comment_count":0,
        "Challenge_created_time":1611192699733,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/65819978",
        "Challenge_link_count":2,
        "Challenge_participation_count":1,
        "Challenge_readability":14.8,
        "Challenge_reading_time":20.87,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":12,
        "Challenge_solved_time":329.4975816667,
        "Challenge_title":"Sagemaker multi-model endpoints with unsupported built-in algorithms",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":524.0,
        "Challenge_word_count":207,
        "Platform":"Stack Overflow",
        "Poster_created_time":1611191329712,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":3.0,
        "Poster_view_count":4.0,
        "Solution_body":"<p>yes, it is possible to deploy the built in image classification models as a SageMaker multi model endpoint. The key is that the image classification uses <a href=\"https:\/\/mxnet.apache.org\/versions\/1.7.0\/\" rel=\"nofollow noreferrer\">Apache MXNet<\/a>. You can extract the model artifacts (SageMaker stores them in a zip file named model.tar.gz in S3), then load them in to MXNet. The SageMaker MXNet container supports multi model endpoints, so you can use that to deploy the model.<\/p>\n<p>If you unzip the model.tar.gz from this algorithm, you'll find three files:<\/p>\n<p>image-classification-****.params<\/p>\n<p>image-classification-symbol.json<\/p>\n<p>model-shapes.json<\/p>\n<p>The MxNet container expects these files to be named <strong>image-classification-0000.params, model-symbol.json, and model-shapes.json<\/strong>. So I unzipped the zip file, renamed the files and rezipped them. For more information on the MXNet container check out the <a href=\"https:\/\/github.com\/aws\/sagemaker-mxnet-inference-toolkit\" rel=\"nofollow noreferrer\">GitHub repository<\/a>.<\/p>\n<p>After that you can deploy the model as a single MXNet endpoint using the SageMaker SDK with the following code:<\/p>\n<pre><code>from sagemaker import get_execution_role\nfrom sagemaker.mxnet.model import MXNetModel\n\nrole = get_execution_role()\n\nmxnet_model = MXNetModel(model_data=s3_model, role=role, \n                         entry_point='built_in_image_classifier.py', \n                         framework_version='1.4.1',\n                         py_version='py3')\n\npredictor = mxnet_model.deploy(instance_type='ml.c4.xlarge', initial_instance_count=1)\n<\/code><\/pre>\n<p>The entry point Python script can be an empty Python file for now. We will be using the default inference handling provided by the MXNet container.<\/p>\n<p>The default MXNet container only accepts JSON, CSV, and Numpy arrays as valid input. So you will have to format your input in to one of these three formats. The code below demonstrates how I did it with Numpy arrays:<\/p>\n<pre><code>import cv2\nimport io\n\nnp_array = cv2.imread(filename=img_filename)\nnp_array = np_array.transpose((2,0,1))\nnp_array = np.expand_dims(np_array, axis=0)\n\nbuffer = io.BytesIO()\nnp.save(buffer, np_array)\n\nresponse = sm.invoke_endpoint(EndpointName='Your_Endpoint_name', Body=buffer.getvalue(), ContentType='application\/x-npy')\n<\/code><\/pre>\n<p>Once you have a single endpoint working with MXNet container, you should be able to get it running in multi model endpoint using the <a href=\"https:\/\/sagemaker.readthedocs.io\/en\/stable\/api\/inference\/multi_data_model.html\" rel=\"nofollow noreferrer\">SageMaker MultiDataModel constructor<\/a>.<\/p>\n<p>If you want to use a different input data type so you don't have to do the preprocessing in your application code, you can overwrite the input_fn method in the MxNet container by providing it in the entry_point script. <a href=\"https:\/\/sagemaker.readthedocs.io\/en\/stable\/frameworks\/mxnet\/using_mxnet.html\" rel=\"nofollow noreferrer\">See here<\/a> for more information. If you do this, you could pass the image bytes directly to SageMaker, without formatting the numpy arrays.<\/p>",
        "Solution_comment_count":3.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":4.0,
        "Solution_readability":12.5,
        "Solution_reading_time":39.71,
        "Solution_score_count":0.0,
        "Solution_sentence_count":30.0,
        "Solution_word_count":347.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1434295027120,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Lusaka, Zambia",
        "Answerer_reputation_count":951.0,
        "Answerer_view_count":157.0,
        "Challenge_adjusted_solved_time":164.0830111111,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I need to use the <a href=\"https:\/\/aws.amazon.com\/marketplace\/pp\/prodview-7y6xdiukxucr2\" rel=\"nofollow noreferrer\">WireframeToCode<\/a> model from the AWS Marketplace, I used Nodejs to read and send the file data to the model like this:<\/p>\n\n<pre><code>var sageMakerRuntime = new AWS.SageMakerRuntime();\n\nvar bitmap = fs.readFileSync(\"sample.jpeg\", \"utf8\");\nvar buffer = new Buffer.from(bitmap, \"base64\");\n\nvar params = {\n  Body: buffer.toJSON(),\n  EndpointName: \"wireframe-to-code\",\n  Accept: \"image\/jpeg\",\n  ContentType: \"application\/json\"\n};\n\nsageMakerRuntime.invokeEndpoint(params, function(err, data) {\n  if (err) console.log(err, err.stack);\n  else console.log(data);\n});\n<\/code><\/pre>\n\n<p>but i get this error:<\/p>\n\n<blockquote>\n  <p>message: 'Expected params.Body to be a string, Buffer, Stream, Blob,\n  or typed array object',   code: 'InvalidParameterType',   time:\n  2020-03-30T11:06:27.535Z<\/p>\n<\/blockquote>\n\n<p>From the documentation, the supported content type for input is  <code>image\/jpeg<\/code> output is <code>application\/json<\/code>.<\/p>\n\n<p>when I try to convert the Body to a string like this: <code>JSON.stringify(buffer.toJSON())<\/code> I get this error:<\/p>\n\n<blockquote>\n  <p>Received client error (415) from model with message \"This predictor\n  only supports JSON formatted data\"<\/p>\n<\/blockquote>",
        "Challenge_closed_time":1586158824067,
        "Challenge_comment_count":0,
        "Challenge_created_time":1585568125227,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/60929678",
        "Challenge_link_count":1,
        "Challenge_participation_count":2,
        "Challenge_readability":11.9,
        "Challenge_reading_time":17.42,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":14,
        "Challenge_solved_time":164.0830111111,
        "Challenge_title":"How to pass image to AWS SageMaker endpoint",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":2170.0,
        "Challenge_word_count":142,
        "Platform":"Stack Overflow",
        "Poster_created_time":1434295027120,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Lusaka, Zambia",
        "Poster_reputation_count":951.0,
        "Poster_view_count":157.0,
        "Solution_body":"<p>I had to pass in bitmap and change <code>ContentType<\/code> to <code>\"image\/jpeg\"<\/code><\/p>\n\n<pre><code>const AWS = require(\"aws-sdk\");\nconst fs = require(\"fs\");\n\nconst sageMakerRuntime = new AWS.SageMakerRuntime({\n  region: \"us-east-1\",\n  accessKeyId: \"XXXXXXXXXXXX\",\n  secretAccessKey: \"XXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n});\n\nconst bitmap = fs.readFileSync(\"sample.jpeg\");\n\nvar params = {\n  Body: bitmap,\n  EndpointName: \"wireframe-to-code\",\n  ContentType: \"image\/jpeg\"\n};\n\nsageMakerRuntime.invokeEndpoint(params, function(err, data) {\n  if (err) {\n    console.log(err, err.stack);\n  } else {\n    responseData = JSON.parse(Buffer.from(data.Body).toString());\n    console.log(responseData);\n  }\n});\n<\/code><\/pre>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":17.8,
        "Solution_reading_time":9.0,
        "Solution_score_count":3.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":50.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1533631086080,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":11.0,
        "Answerer_view_count":1.0,
        "Challenge_adjusted_solved_time":26.7891236111,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I'm writing a lambda (in node.js 6.10) to update an endpoint SageMaker. To do so I have to create a new HyperParamterTuningJob (and then describe it).\nI succeeded to call all functions of the service SageMaker from the sdk (like listModels, createTrainingJob, ...) (<a href=\"https:\/\/docs.aws.amazon.com\/AWSJavaScriptSDK\/latest\/AWS\/SageMaker.html\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/AWSJavaScriptSDK\/latest\/AWS\/SageMaker.html<\/a>) except some of them.<\/p>\n\n<p>All the functions that are related to HyperParameterTuningJob \n(createHyperParameterTuningJob, describeHyperParameterTuningJob, listHyperParameterTuningJobs and stopHyperParameterTuningJob) \nare not known in the sdk by the lambda.<\/p>\n\n<p>I have attached the policy 'AmazonSageMakerFullAccess' to the role IAM used (where all these functions are allowed). So the error can't come from a problem of authorization.<\/p>\n\n<p>I have already created a HyperParameterTuningJob (by the interface of AWS) called 'myTuningJob'.\nI have an error everytime I use the function describeHyperParamterTuningJob.\nHere is my lambda code : <\/p>\n\n<pre><code>const AWS = require('aws-sdk');\nconst sagemaker = new AWS.SageMaker({region: 'eu-west-1', apiVersion: '2017-07-24'});\nvar role = 'arn:aws:iam::xxxxxxxxxxxx:role\/service-role\/AmazonSageMaker-ExecutionRole-xxxxxxxxxxxxxxx';\n\nexports.handler = (event, context, callback) =&gt; {\n    var params = {\n        HyperParameterTuningJobName: 'myTuningJob'\n    };\n\n    sagemaker.describeHyperParameterTuningJob(params, function(err, data) {\n        if (err) console.log(err, err.stack);\n        else console.log(data);\n    });\n};\n<\/code><\/pre>\n\n<p>When I try to test this code in AWS lambda, it returns this result in the console :<\/p>\n\n<pre><code>Function Logs:\nSTART RequestId: 6e79aaa4-9a18-11e8-8dcd-d58423b413c1 Version: $LATEST\n2018-08-07T08:03:56.336Z    6e79aaa4-9a18-11e8-8dcd-d58423b413c1    TypeError: sagemaker.describeHyperParameterTuningJob is not a function\nat exports.handler (\/var\/task\/index.js:10:15)\nEND RequestId: 6e79aaa4-9a18-11e8-8dcd-d58423b413c1\nREPORT RequestId: 6e79aaa4-9a18-11e8-8dcd-d58423b413c1  Duration: 50.00 ms   \nBilled Duration: 100 ms Memory Size: 128 MB Max Memory Used: 32 MB  \nRequestId: 6e79aaa4-9a18-11e8-8dcd-d58423b413c1 Process exited before completing request\n<\/code><\/pre>\n\n<p>When I call all other functions of the SageMaker service from the sdk, it runs correctly, whitout any error.<\/p>\n\n<p>I don't find any explanation in the documentation of why these functions related to HyperParameterTuningJob are not recognized as functions in the sdk.<\/p>\n\n<p>Does anyone have any idea of why it doesn't work ? Or any solutions to call theses functions ?<\/p>",
        "Challenge_closed_time":1533728073932,
        "Challenge_comment_count":0,
        "Challenge_created_time":1533631633087,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/51722555",
        "Challenge_link_count":2,
        "Challenge_participation_count":1,
        "Challenge_readability":12.6,
        "Challenge_reading_time":35.31,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":25,
        "Challenge_solved_time":26.7891236111,
        "Challenge_title":"Functions of sagemaker service from js-sdk not recognize by AWS Lambda",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":212.0,
        "Challenge_word_count":296,
        "Platform":"Stack Overflow",
        "Poster_created_time":1533631086080,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":11.0,
        "Poster_view_count":1.0,
        "Solution_body":"<p>In AWS Lambda, only the sdk that have a sable version are available.\nThe sdk of the SageMaker service is not stable yet, so functions related to HyperParameterTuningJob are not in the version of the sdk included in AWS Lambda.<\/p>\n\n<p>To use theses functions, you need to install the latest version of the sdk on local on your machine (with npm install aws-sdk). \nThen zip the node_modules folder and your script (called index.js), then upload this zip folder into the AWS lambda.<\/p>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":8.5,
        "Solution_reading_time":5.93,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":82.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1500629225150,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":5939.0,
        "Answerer_view_count":886.0,
        "Challenge_adjusted_solved_time":133.8006258333,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I'm trying to create a module for Sagemaker endpoints. There's an optional object variable called <code>async_inference_config<\/code>. If you omit it, the endpoint being deployed is synchronous, but if you include it, the endpoint deployed is asynchronous. To satisfy both of these usecases, the <code>async_inference_config<\/code> needs to be an optional block.<\/p>\n<p>I am unsure of how to make this block optional though.<br \/>\nAny guidance would be greatly appreciated. See example below of structure of the optional parameter.<\/p>\n<p><strong>Example:<\/strong><\/p>\n<pre><code>resource &quot;aws_sagemaker_endpoint_configuration&quot; &quot;sagemaker_endpoint_configuration&quot; {\n  count = var.create ? 1 : 0\n\n  name = var.endpoint_configuration_name\n  production_variants {\n    instance_type          = var.instance_type\n    initial_instance_count = var.instance_count\n    model_name             = var.model_name\n    variant_name           = var.variant_name\n  }\n  async_inference_config {\n    output_config {\n      s3_output_path = var.s3_output_path\n    }\n    client_config {\n      max_concurrent_invocations_per_instance = var.max_concurrent_invocations_per_instance\n    }\n  }\n  lifecycle {\n    create_before_destroy = true\n    ignore_changes        = [&quot;name&quot;]\n  }\n\n  tags = var.tags\n\n  depends_on = [aws_sagemaker_model.sagemaker_model]\n}\n<\/code><\/pre>\n<p><strong>Update:<\/strong> What I tried based on the below suggestion, which seemed to work<\/p>\n<pre><code>dynamic &quot;async_inference_config&quot; {\n    for_each = var.async_inference_config == null ? [] : [true]\n    content {\n      output_config {\n        s3_output_path = lookup(var.async_inference_config, &quot;s3_output_path&quot;, null)\n      }\n      client_config {\n        max_concurrent_invocations_per_instance = lookup(var.async_inference_config, &quot;max_concurrent_invocations_per_instance&quot;, null)\n      }\n    }\n  }\n<\/code><\/pre>",
        "Challenge_closed_time":1658387166296,
        "Challenge_comment_count":0,
        "Challenge_created_time":1658386596203,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1658442017223,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/73061907",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":17.7,
        "Challenge_reading_time":23.65,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":22,
        "Challenge_solved_time":0.1583591667,
        "Challenge_title":"Terraform - Optional Nested Variable",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":55.0,
        "Challenge_word_count":146,
        "Platform":"Stack Overflow",
        "Poster_created_time":1443225809767,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Vancouver, BC, Canada",
        "Poster_reputation_count":2332.0,
        "Poster_view_count":560.0,
        "Solution_body":"<p>You could use a <code>dynamic<\/code> block [1] in combination with <code>for_each<\/code> meta-argument [2]. It would look something like:<\/p>\n<pre><code>dynamic &quot;async_inference_config&quot; {\n    for_each = var.s3_output_path != null &amp;&amp; var.max_concurrent_invocations_per_instance != null ? [1] : []\n    content {\n    output_config {\n      s3_output_path = var.s3_output_path\n    }\n    client_config {\n      max_concurrent_invocations_per_instance = var.max_concurrent_invocations_per_instance\n    }\n  }\n}\n<\/code><\/pre>\n<p>Of course, you could come up with a different variable, say <code>enable_async_inference_config<\/code> (probalby of type <code>bool<\/code>) and base the <code>for_each<\/code> on that, e.g.:<\/p>\n<pre><code>dynamic &quot;async_inference_config&quot; {\n    for_each = var.enable_async_inference_config ? [1] : []\n    content {\n    output_config {\n      s3_output_path = var.s3_output_path\n    }\n    client_config {\n      max_concurrent_invocations_per_instance = var.max_concurrent_invocations_per_instance\n    }\n  }\n}\n<\/code><\/pre>\n<hr \/>\n<p>[1] <a href=\"https:\/\/www.terraform.io\/language\/expressions\/dynamic-blocks\" rel=\"nofollow noreferrer\">https:\/\/www.terraform.io\/language\/expressions\/dynamic-blocks<\/a><\/p>\n<p>[2] <a href=\"https:\/\/www.terraform.io\/language\/meta-arguments\/for_each\" rel=\"nofollow noreferrer\">https:\/\/www.terraform.io\/language\/meta-arguments\/for_each<\/a><\/p>",
        "Solution_comment_count":13.0,
        "Solution_last_edit_time":1658923699476,
        "Solution_link_count":4.0,
        "Solution_readability":23.4,
        "Solution_reading_time":18.04,
        "Solution_score_count":2.0,
        "Solution_sentence_count":13.0,
        "Solution_word_count":82.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":70.6300730556,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi,  <\/p>\n<p>I have made deployment of the model from the AutoML experiment, due to the issue in the resources associated. Deployment has failed.  <\/p>\n<p>But the real-time endpoint has been in the transition state for few hours,  I can't delete it and the model registered along with it due to this. How can I force delete in this case. Please provide a solution.   <\/p>\n<p>Thanks  <\/p>",
        "Challenge_closed_time":1629112596936,
        "Challenge_comment_count":1,
        "Challenge_created_time":1628858328673,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/513012\/how-to-delete-azure-ml-real-time-endpoints-which-i",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":5.3,
        "Challenge_reading_time":5.57,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":70.6300730556,
        "Challenge_title":"how to delete Azure ML real-time endpoints which is in transition state",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":78,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Thank you for the response <a href=\"\/users\/na\/?userid=bc467a93-95da-4dea-bc82-06951da4cfad\">@romungi-MSFT  <\/a>. I have left the feedback to the team.<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":8.8,
        "Solution_reading_time":2.07,
        "Solution_score_count":0.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":16.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":158.8487369445,
        "Challenge_answer_count":3,
        "Challenge_body":"<p>do I still have the access to it? <\/p>",
        "Challenge_closed_time":1655315539550,
        "Challenge_comment_count":0,
        "Challenge_created_time":1654743684097,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/882424\/will-experiments-disappear-if-i-don-t-migrate-to-d",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":6.6,
        "Challenge_reading_time":1.23,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":2,
        "Challenge_solved_time":158.8487369445,
        "Challenge_title":"will experiments disappear if I don\u2019t migrate to Designer?",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":17,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=ce84de18-8973-44f3-8101-f191f9216b1f\">@Alexandre  <\/a>     <\/p>\n<p>I hope Rohit's reponse is helpful, please let us know if you have more question. All the data of studio will be avaiable till August 2024, you still have time to decide if you want to keep them, but Designer will provide the same experience and supporting the same function, you may want to try.     <\/p>\n<p>Please kindly accept the answer if you feel helpful to support the community, thanks a lot.    <\/p>\n<p>Regards,    <br \/>\nYutong<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":7.2,
        "Solution_reading_time":6.57,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":81.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1489593596310,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":162.0,
        "Answerer_view_count":9.0,
        "Challenge_adjusted_solved_time":0.2549580556,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I am retrieving a list of image filenames from DynamoDB and using those image filenames to replace the default <code>src=<\/code> image in a portion of a website.<\/p>\n\n<p>I'm a JS novice, so I'm certainly missing something, but my function is returning the list of filenames too late.<\/p>\n\n<p>My inline script is:<\/p>\n\n<pre><code>&lt;script&gt;\n        customElements.whenDefined( 'crowd-bounding-box' ).then( () =&gt; {  \n        var imgBox = document.getElementById('annotator');\n        newImg = imageslist();\n        console.log(\"Result of newImg is: \" + newImg);\n        imgBox.src = \"https:\/\/my-images-bucket.s3.amazonaws.com\/\" + newImg;\n    } )\n&lt;\/script&gt;\n<\/code><\/pre>\n\n<p>My JS function is:<\/p>\n\n<pre><code>async function imageslist() {\n    const username = \"sampleuser\";\n    const params = {\n        TableName: \"mytable\",\n        FilterExpression: \"attribute_not_exists(\" + username + \")\",\n        ReturnConsumedCapacity: \"NONE\"\n    };\n    try {\n        var data = await ddb.scan(params).promise()\n        var imglist = [];\n        for(let i = 0; i &lt; data.Items.length; i++) {\n            imglist.push(data.Items[i].img.S);\n        };\n        imglist.sort();\n        var firstimg = imglist[0];\n        console.log(firstimg);\n        return imglist\n    } catch(error) {\n        console.error(error);\n    }\n}\n<\/code><\/pre>\n\n<p>The console reports <code>Result of newImg is: [object Promise]<\/code> and shortly after that, it reports the expected filename.  After the page has been rendered, I can input <code>newImg<\/code> in the console and I receive the expected result.<\/p>\n\n<p>Am I using the <strong>await<\/strong> syntax improperly?<\/p>\n\n<p>Side note: This site uses the Crowd HTML Elements (for Ground Truth and Mechanical Turk), so I'm forced to have the <code>src=<\/code> attribute present in my <code>crowd-bounding-box<\/code> tag and it must be a non-zero value.  I'm loading a default image and replacing it with another image.<\/p>",
        "Challenge_closed_time":1588365818456,
        "Challenge_comment_count":1,
        "Challenge_created_time":1588364900607,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/61550297",
        "Challenge_link_count":1,
        "Challenge_participation_count":3,
        "Challenge_readability":10.4,
        "Challenge_reading_time":22.89,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":17,
        "Challenge_solved_time":0.2549580556,
        "Challenge_title":"Await returns too soon",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":63.0,
        "Challenge_word_count":208,
        "Platform":"Stack Overflow",
        "Poster_created_time":1483444144907,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Hoth",
        "Poster_reputation_count":312.0,
        "Poster_view_count":65.0,
        "Solution_body":"<p>Anytime you use the <code>await<\/code> keyword, you must use the <code>async<\/code> keyword before the function definition (which you have done). The thing is, any time an async function is called, it will always return a <code>Promise<\/code> object since it expects that some asynchronous task will take place within the function.<\/p>\n\n<p>Therefore,you'll need to <code>await<\/code> the result of the imageslist function and make the surrounding function <code>async<\/code>.<\/p>\n\n<pre class=\"lang-js prettyprint-override\"><code>&lt;script&gt;\n    customElements.whenDefined( 'crowd-bounding-box' ).then( async () =&gt; {  \n        var imgBox = document.getElementById('annotator');\n        newImg = await imageslist();\n        console.log(\"Result of newImg is: \" + newImg);\n        imgBox.src = \"https:\/\/my-images-bucket.s3.amazonaws.com\/\" + newImg;\n    } )\n&lt;\/script&gt;\n<\/code><\/pre>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":10.1,
        "Solution_reading_time":10.99,
        "Solution_score_count":1.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":90.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":123.0280555556,
        "Challenge_answer_count":1,
        "Challenge_body":"The team uses Azure ML CLI to deploy a container to AKS (az ml model deploy). Now and then (not always), they get an internal server error, see stack trace. They could not detect a clear pattern when this error occurs. Although it would be possible to create a retry loop in their Azure DevOps pipeline when this error occurs (as the error message also tells), this would not resolve the underlying issue.\r\n\r\n```\r\n2020-02-14T11:11:07.1739375Z ERROR: {'Azure-cli-ml Version': '1.0.85', 'Error': WebserviceException:\r\n\r\n2020-02-14T11:11:07.1739694Z \tMessage: Received bad response from Model Management Service:\r\n\r\n2020-02-14T11:11:07.1739785Z Response Code: 500\r\n\r\n2020-02-14T11:11:07.1740533Z Headers: {'Date': 'Fri, 14 Feb 2020 11:11:07 GMT', 'Content-Type': 'application\/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Request-Context': 'appId=cid-v1:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\r\n\r\n2020-02-14T11:11:07.1741400Z Content: b'{\"code\":\"InternalServerError\",\"statusCode\":500,\"message\":\"An internal server error occurred. Please try again. If the problem persists, contact support\"}'\r\n\r\n2020-02-14T11:11:07.1741516Z \tInnerException None\r\n\r\n2020-02-14T11:11:07.1741641Z \tErrorResponse \r\n\r\n2020-02-14T11:11:07.1741708Z {\r\n\r\n2020-02-14T11:11:07.1741813Z     \"error\": {\r\n\r\n2020-02-14T11:11:07.1742819Z         \"message\": \"Received bad response from Model Management Service:\\nResponse Code: 500\\nHeaders: {'Date': 'Fri, 14 Feb 2020 11:11:07 GMT', 'Content-Type': 'application\/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Request-Context': 'appId=cid-v1:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\\nContent: b'{\\\"code\\\":\\\"InternalServerError\\\",\\\"statusCode\\\":500,\\\"message\\\":\\\"An internal server error occurred. Please try again. If the problem persists, contact support\\\"}'\"\r\n\r\n2020-02-14T11:11:07.1743119Z     }\r\n\r\n2020-02-14T11:11:07.1743227Z }}\r\n```",
        "Challenge_closed_time":1583847372000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1583404471000,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/841",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":10.6,
        "Challenge_reading_time":28.94,
        "Challenge_repo_contributor_count":55.0,
        "Challenge_repo_fork_count":2296.0,
        "Challenge_repo_issue_count":1858.0,
        "Challenge_repo_star_count":3528.0,
        "Challenge_repo_watch_count":2030.0,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":21,
        "Challenge_solved_time":123.0280555556,
        "Challenge_title":"Internal server error when deploying from Azure ML to AKS",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":201,
        "Platform":"Github",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"@robinvdheijden \r\n\r\nThanks for reaching out to us. This is forum for Machine Learning Notebook only. Please open a new forum thread in [MSDN forum](https:\/\/social.msdn.microsoft.com\/Forums\/en-US\/home?forum=AzureMachineLearningService)as it could be better place to get help on your scenario. These forum community members could provide their expert guidance on your scenario based on their experience. Thanks.\r\n\r\nWe will now proceed to close this thread. If there are further questions regarding this matter, please respond here and @YutongTie-MSFT and we will gladly continue the discussion.",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":8.9,
        "Solution_reading_time":7.43,
        "Solution_score_count":0.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":80.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1439246522636,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":36.0,
        "Answerer_view_count":16.0,
        "Challenge_adjusted_solved_time":0.0595647222,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>When I try to test my Azure ML model, I get the following error: \u201cError code: InternalError, Http status code: 500\u201d, so it appears something is failing inside of the machine learning service. How do I get around this error?<\/p>",
        "Challenge_closed_time":1439848076380,
        "Challenge_comment_count":0,
        "Challenge_created_time":1439847861947,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1439906222223,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/32060196",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":7.7,
        "Challenge_reading_time":3.11,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":0.0595647222,
        "Challenge_title":"Azure ML Internal Error",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":1408.0,
        "Challenge_word_count":43,
        "Platform":"Stack Overflow",
        "Poster_created_time":1439847618300,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":13.0,
        "Poster_view_count":4.0,
        "Solution_body":"<p>I've run into this error before, and unfortunately, the only workaround I found was to create a new ML workspace backed by a storage account that you know is online. Then copy your experiment over to the new workspace, and things should work. It can be a bit cumbersome, but it should get rid of your error message. With the service being relatively new, things sometimes get corrupted as updates are being made, so I recommend checking the box labeled \"disable updates\" within your experiment.  Hope that helps!<\/p>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":9.0,
        "Solution_reading_time":6.33,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":88.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":20.3918425,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I created a new azure automl experiment and deployed it to an endpoint and can access the scoring URI via postman but how do I consume it in excel? Classic ml studio had the excel addin you can use but I don't see the same for URIs created and deployed from an automl experiment.   <\/p>\n<p>This Microsoft Developer video has a demo of exactly what I'm looking to do around the 32 min mark.  <br \/>\n<a href=\"https:\/\/youtu.be\/9FGuf55_Xtk?t=1915\">https:\/\/youtu.be\/9FGuf55_Xtk?t=1915<\/a>  <\/p>",
        "Challenge_closed_time":1611147165400,
        "Challenge_comment_count":0,
        "Challenge_created_time":1611073754767,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/236781\/consume-scoreing-api-in-excel",
        "Challenge_link_count":1,
        "Challenge_participation_count":2,
        "Challenge_readability":8.5,
        "Challenge_reading_time":6.4,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":20.3918425,
        "Challenge_title":"Consume scoreing api in excel",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":82,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p><a href=\"#\">@Anonymous  <\/a>  Thanks for the question, Have a look here:    <br \/>\n<a href=\"https:\/\/github.com\/retkowsky\/AzureML_Excel\">https:\/\/github.com\/retkowsky\/AzureML_Excel<\/a>    <\/p>\n<p>There is an Excel macro in the Excel file that call an Azure ML service deployed model.    <br \/>\nThere is a quick description of the process in the Word document available in this repo.    <br \/>\nYou can find here as well the Python notebook for creating &amp; deploying the model. No autoML in it but not a big deal to adapt.    <\/p>\n<p>Please try the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service?tabs=python\">Consume web services portion<\/a> Azure ML documentation? That could help you get started.     <\/p>\n",
        "Solution_comment_count":2.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":7.9,
        "Solution_reading_time":9.36,
        "Solution_score_count":1.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":95.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1626973229036,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":199.0,
        "Answerer_view_count":37.0,
        "Challenge_adjusted_solved_time":171.8247852778,
        "Challenge_answer_count":1,
        "Challenge_body":"<pre><code>import os\nimport io\nimport boto3\nimport json\nimport csv\n\n\n# grab environment variables\nENDPOINT_NAME = os.environ['ENDPOINT_NAME']\n# grab runtime client\nruntime = boto3.client('runtime.sagemaker')\n\ndef lambda_handler(event, context):\n    # Load data from POST request\n    data = json.loads(json.dumps(event))\n    \n    # Grab the payload\n    payload = data['body']\n    \n    # Invoke the model. In this case the data type is a JSON but can be other things such as a CSV\n    response = runtime.invoke_endpoint(EndpointName=ENDPOINT_NAME,\n                                   ContentType='application\/json',\n                                   Body=payload)\n    \n    # Get the body of the response from the model\n    result = response['Body'].read().decode()\n\n    # Return it along with the status code of 200 meaning this was succesful \n    return {\n        'statusCode': 200,\n        'body': result\n    }\n<\/code><\/pre>\n<p><strong>response from AWS Lambda<\/strong><\/p>\n<pre><code>{\n  &quot;errorMessage&quot;: &quot;'body'&quot;,\n  &quot;errorType&quot;: &quot;KeyError&quot;,\n  &quot;stackTrace&quot;: [\n    [\n      &quot;\/var\/task\/lambda_function.py&quot;,\n      18,\n      &quot;lambda_handler&quot;,\n      &quot;payload = data['body']&quot;\n    ]\n  ]\n}\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/h8wvA.png\" rel=\"nofollow noreferrer\">response from Postman 500 Internal Server Error<\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/cuknX.png\" rel=\"nofollow noreferrer\">but successfully invoke POST 200 in SageMaker Endpoint<\/a><\/p>",
        "Challenge_closed_time":1626975923230,
        "Challenge_comment_count":1,
        "Challenge_created_time":1626360722473,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1626360827356,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/68396088",
        "Challenge_link_count":2,
        "Challenge_participation_count":2,
        "Challenge_readability":14.2,
        "Challenge_reading_time":19.02,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":11,
        "Challenge_solved_time":170.8890991667,
        "Challenge_title":"Why AWS Lambda Internel Server Error 500 but successfully \/invocations POST 200 in Endpoint SageMaker?",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":277.0,
        "Challenge_word_count":141,
        "Platform":"Stack Overflow",
        "Poster_created_time":1512933739527,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Petaling Jaya, Selangor, Malaysia",
        "Poster_reputation_count":3.0,
        "Poster_view_count":0.0,
        "Solution_body":"<p>The issue is when you are trying to parse your payload with data['body']. The data is not being passed in the format that the endpoint is expecting. Use the following code snippet to properly format\/serialize your data for the endpoint. Also to make all this clearer make sure to check for your payload type to make sure you have not serialized again by accident.<\/p>\n<pre><code>    data = json.loads(json.dumps(event))\n    payload = json.dumps(data)\n    response = runtime.invoke_endpoint(EndpointName=ENDPOINT_NAME,\n                                       ContentType='application\/json',\n                                       Body=payload)\n    result = json.loads(response['Body'].read().decode())\n<\/code><\/pre>\n<p>I work for AWS &amp; my opinions are my own<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1626979396583,
        "Solution_link_count":0.0,
        "Solution_readability":9.4,
        "Solution_reading_time":8.59,
        "Solution_score_count":0.0,
        "Solution_sentence_count":9.0,
        "Solution_word_count":86.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1369207318272,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Seattle, WA, USA",
        "Answerer_reputation_count":35.0,
        "Answerer_view_count":7.0,
        "Challenge_adjusted_solved_time":84.9611705556,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I am trying to take the environment variables as parameters for the template:\n<a href=\"https:\/\/docs.aws.amazon.com\/AWSCloudFormation\/latest\/UserGuide\/aws-properties-sagemaker-model-containerdefinition.html\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/AWSCloudFormation\/latest\/UserGuide\/aws-properties-sagemaker-model-containerdefinition.html<\/a><\/p>\n<p>The type seems to be Json in the template and I dont understand how to populate it.<\/p>\n<p>It seems like I can define this if i hardcode environment variables as below:<\/p>\n<pre><code>Resources:\n  SageMakerModel:\n    Type: 'AWS::SageMaker::Model'\n    Properties:\n      ExecutionRoleArn: \n        Ref: ExecutionRoleArn\n      EnableNetworkIsolation: false\n      PrimaryContainer:\n        Environment:\n          REQUEST_KEEP_ALIVE_TIME_SEC: '90'\n        Image: \n          Ref: ImageURI\n<\/code><\/pre>\n<p>However, there doesnt seem to be a way pass this in ? Anyone figured this out or any recommended way to do this ?<\/p>",
        "Challenge_closed_time":1635277709907,
        "Challenge_comment_count":0,
        "Challenge_created_time":1634971849693,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/69685819",
        "Challenge_link_count":2,
        "Challenge_participation_count":2,
        "Challenge_readability":19.0,
        "Challenge_reading_time":12.79,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":84.9611705556,
        "Challenge_title":"Taking Json type as parameter for cloudformation template",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":415.0,
        "Challenge_word_count":96,
        "Platform":"Stack Overflow",
        "Poster_created_time":1369207318272,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Seattle, WA, USA",
        "Poster_reputation_count":35.0,
        "Poster_view_count":7.0,
        "Solution_body":"<p>I was able to get this to work by using AWS:Include and Fn:Transform and storing my environment variables as json in passed s3 file.<\/p>\n<p>My cfn template looks like:<\/p>\n<pre><code>Resources:\n  SageMakerModel:\n    Type: 'AWS::SageMaker::Model'\n    Properties:\n      ExecutionRoleArn: \n        Ref: ExecutionRoleArn\n      EnableNetworkIsolation: false\n      PrimaryContainer:\n        Environment:\n          Fn::Transform:\n            Name: AWS::Include\n            Parameters:\n              Location: &lt;your S3 file&gt;\n        Image: \n          Ref: ImageURI\n<\/code><\/pre>\n<p>My s3 file looks like:<\/p>\n<pre><code>{\n  &quot;REQUEST_KEEP_ALIVE_TIME_SEC&quot;: &quot;90&quot;\n}\n<\/code><\/pre>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":20.1,
        "Solution_reading_time":7.64,
        "Solution_score_count":0.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":62.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1601729162436,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Bengaluru, Karnataka, India",
        "Answerer_reputation_count":887.0,
        "Answerer_view_count":130.0,
        "Challenge_adjusted_solved_time":41.0861802778,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>In Azure Machine Learning Service, when we deploy a Model as an AKS Webservice Endpoint, how can we raise exceptions to let the end-user get proper feedback if their API call is unsuccessful? Azure mentions using <code>azureml.exceptions.WebserviceException<\/code> in their <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.exceptions.webserviceexception?view=azure-ml-py\" rel=\"nofollow noreferrer\">documentation<\/a>. However, how do we use this class to raise exceptions in case the API call cannot be processed properly and the end-user is responsible for it?<\/p>",
        "Challenge_closed_time":1617344350896,
        "Challenge_comment_count":0,
        "Challenge_created_time":1617196440647,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/66888622",
        "Challenge_link_count":1,
        "Challenge_participation_count":2,
        "Challenge_readability":13.6,
        "Challenge_reading_time":9.06,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":41.0861802778,
        "Challenge_title":"How to effectively use azureml.exceptions.WebserviceException for efficient REST API Error Management?",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":250.0,
        "Challenge_word_count":79,
        "Platform":"Stack Overflow",
        "Poster_created_time":1601729162436,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Bengaluru, Karnataka, India",
        "Poster_reputation_count":887.0,
        "Poster_view_count":130.0,
        "Solution_body":"<p>To raise exceptions to let the end-user get proper feedback if their API call is unsuccessful, we use the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-contrib-services\/azureml.contrib.services.aml_response.amlresponse?view=azure-ml-py\" rel=\"nofollow noreferrer\"><code>azureml.contrib.services.aml_response.AMLResponse<\/code> Class<\/a>.<\/p>\n<p>Example of use in <code>score.py<\/code>:<\/p>\n<pre><code>if [some-condition]:    \n    return AMLResponse(&quot;bad request&quot;, 500)\n<\/code><\/pre>\n<p>Documentation Link can be found <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-advanced-entry-script#binary-data\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":24.5,
        "Solution_reading_time":9.49,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":45.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1250158552416,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Romania",
        "Answerer_reputation_count":7916.0,
        "Answerer_view_count":801.0,
        "Challenge_adjusted_solved_time":3.3004461111,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I am trying out <a href=\"https:\/\/azure.microsoft.com\/en-us\/services\/machine-learning-service\/\" rel=\"nofollow noreferrer\">Azure Machine Learning Service<\/a> to deploy a ML model as web service.<\/p>\n\n<p>I have already <a href=\"https:\/\/stackoverflow.com\/a\/55281703\/4240413\">registered a model<\/a> and now would like to deploy it as web service following the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/tutorial-deploy-models-with-aml#deploy-in-container-instances\" rel=\"nofollow noreferrer\">guide<\/a> using Azure (Python) Notebooks.<\/p>\n\n<p>The step<\/p>\n\n<pre><code> service = Webservice.deploy_from_model(my-model-svc',\n                                   deployment_config=aciconfig,\n                                   models=[model],\n                                   image_config=image_config)\n<\/code><\/pre>\n\n<p>fails for me with<\/p>\n\n<blockquote>\n  <p>Creating image<br>\n  Image creation operation finished for image my-model-svc:5, operation \"Succeeded\" Creating service<br>\n  Running.<br>\n  FailedACI service creation operation finished, operation<br>\n  \"Failed\" Service creation polling reached terminal state, current\n  service state: Transitioning Service creation polling reached terminal\n  state, unexpected response received.<\/p>\n<\/blockquote>\n\n<p>Not sure about what could be the root cause, as (AFAIK) I have no ways to access logs of the deployment in Azure portal.<\/p>\n\n<p>Can someone shed some light on this?<\/p>",
        "Challenge_closed_time":1553197455296,
        "Challenge_comment_count":0,
        "Challenge_created_time":1553185573690,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1559204803203,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/55285043",
        "Challenge_link_count":3,
        "Challenge_participation_count":2,
        "Challenge_readability":14.1,
        "Challenge_reading_time":18.33,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":11,
        "Challenge_solved_time":3.3004461111,
        "Challenge_title":"How can I troubleshoot my Azure ML service deployment?",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":1236.0,
        "Challenge_word_count":140,
        "Platform":"Stack Overflow",
        "Poster_created_time":1415722650716,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Verona, VR, Italy",
        "Poster_reputation_count":4811.0,
        "Poster_view_count":713.0,
        "Solution_body":"<p>I think that your <code>init<\/code> function is failing. I would first try to isolate the image creation from the image deployment, and just test the image first:<\/p>\n\n<ul>\n<li>Create the image first, it's very much ok if do it through the interface<\/li>\n<li>Pull the image locally with Docker (for this you'll need <a href=\"https:\/\/www.docker.com\" rel=\"nofollow noreferrer\">Docker<\/a> and the <a href=\"https:\/\/docs.microsoft.com\/en-us\/cli\/azure\/install-azure-cli?view=azure-cli-latest\" rel=\"nofollow noreferrer\">Azure CLI<\/a> installed):<\/li>\n<\/ul>\n\n<pre class=\"lang-python prettyprint-override\"><code>az acr login -n &lt;container-registry&gt;\ndocker run -p 8000:5001  &lt;container-registry&gt;.azurecr.io\/&lt;image-name&gt;:&lt;image-version&gt;\n# basically, the entire image location, see pic below\n<\/code><\/pre>\n\n<ul>\n<li>test the image locally, it listens on the 8000 port:<\/li>\n<\/ul>\n\n<pre><code>POST http:\/\/localhost:8000\/score\nContent-Type: application\/json\n<\/code><\/pre>\n\n<ul>\n<li>if this works deploy it on ACI <\/li>\n<\/ul>\n\n<p><code>&lt;container-registry&gt;<\/code> is the name of the <code>Container Registry<\/code> associated with the ML Workspace, you can also extract it from the image location, taking care to remove everything after the first dot:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/W6YYj.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/W6YYj.png\" alt=\"image location\"><\/a><\/p>",
        "Solution_comment_count":3.0,
        "Solution_last_edit_time":1554828275376,
        "Solution_link_count":5.0,
        "Solution_readability":15.3,
        "Solution_reading_time":18.61,
        "Solution_score_count":3.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":151.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1554186784008,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Hyderabad, Telangana, India",
        "Answerer_reputation_count":2175.0,
        "Answerer_view_count":434.0,
        "Challenge_adjusted_solved_time":10.4660813889,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>For AzureML we\u2019re using the REST api provided in published pipelines to launch them as part of scheduled jobs.<\/p>\n<p>It looks like if we republish an endpoint the GUID at the end of the URL changes.\nDo you have any recommendations for how to alias this so the URL can remain the same for a caller or keep it constant?<\/p>",
        "Challenge_closed_time":1640952460163,
        "Challenge_comment_count":0,
        "Challenge_created_time":1640914782270,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/70538271",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":7.6,
        "Challenge_reading_time":4.66,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":10.4660813889,
        "Challenge_title":"Any recommendation on republish an endpoint to remain same",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":124.0,
        "Challenge_word_count":68,
        "Platform":"Stack Overflow",
        "Poster_created_time":1632461310820,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":107.0,
        "Poster_view_count":2.0,
        "Solution_body":"<p>These are static, unique URLs that can be associated with multiple published pipeline versions (you can make one pipeline the default).<\/p>\n<p>Pipeline Endpoints:<a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-pipeline-core\/azureml.pipeline.core.pipelineendpoint?view=azure-ml-py\" rel=\"nofollow noreferrer\">azureml.pipeline.core.PipelineEndpoint class - Azure Machine Learning Python | Microsoft Docs<\/a><\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":11.2,
        "Solution_reading_time":5.73,
        "Solution_score_count":2.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":33.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1495715386880,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":51.0,
        "Answerer_view_count":5.0,
        "Challenge_adjusted_solved_time":43.8940630556,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am trying to send a request on a model on sagemaker using .NET. The code I am using is: <\/p>\n\n<pre><code>var data = File.ReadAllBytes(@\"C:\\path\\file.csv\");\nvar credentials = new Amazon.Runtime.BasicAWSCredentials(\"\",\"\");\nvar awsClient = new AmazonSageMakerRuntimeClient(credentials, RegionEndpoint.EUCentral1);\nvar request = new Amazon.SageMakerRuntime.Model.InvokeEndpointRequest\n{\n    EndpointName = \"EndpointName\",\n    ContentType = \"text\/csv\",\n    Body = new MemoryStream(data),\n};\n\nvar response = awsClient.InvokeEndpoint(request);\nvar predictions = Encoding.UTF8.GetString(response.Body.ToArray());\n<\/code><\/pre>\n\n<p>the error that I am getting on <code>awsClient.InvokeEndpoint(request)<\/code><\/p>\n\n<p>is:<\/p>\n\n<blockquote>\n  <p>Amazon.SageMakerRuntime.Model.ModelErrorException: 'The service\n  returned an error with Error Code ModelError and HTTP Body:\n  {\"ErrorCode\":\"INTERNAL_FAILURE_FROM_MODEL\",\"LogStreamArn\":\"arn:aws:logs:eu-central-1:xxxxxxxx:log-group:\/aws\/sagemaker\/Endpoints\/myEndpoint\",\"Message\":\"Received\n  server error (500) from model with message \\\"\\\". See\n  \"https:\/\/ url_to_logs_on_amazon\"\n  in account xxxxxxxxxxx for more\n  information.\",\"OriginalMessage\":\"\",\"OriginalStatusCode\":500}'<\/p>\n<\/blockquote>\n\n<p>the url that the error message suggests for more information does not help at all.<\/p>\n\n<p>I believe that it is a data format issue but I was not able to find a solution.<\/p>\n\n<p>Does anyone has encountered this behavior before?<\/p>",
        "Challenge_closed_time":1535104925600,
        "Challenge_comment_count":1,
        "Challenge_created_time":1534946906973,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/51968742",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":15.1,
        "Challenge_reading_time":19.68,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":3.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":15,
        "Challenge_solved_time":43.8940630556,
        "Challenge_title":"AWS sagemaker invokeEndpoint model internal error",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":4385.0,
        "Challenge_word_count":137,
        "Platform":"Stack Overflow",
        "Poster_created_time":1495715386880,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":51.0,
        "Poster_view_count":5.0,
        "Solution_body":"<p>The problem relied on the data format as suspected. In my case all I had to do is send the data as a json serialized string array and use <code>ContentType = application\/json<\/code> because the python function running on the endpoint which is responsible for sending the data to the predictor was only accepting json strings. <\/p>\n\n<p>Another way to solve this issues is to modify the python function which is responsible for the input handling to accept all content types and modify the data in a way that the predictor will understand.<\/p>\n\n<p>example of working code for my case:<\/p>\n\n<pre><code>        var data = new string[] { \"this movie was extremely good .\", \"the plot was very boring .\" };\n        var serializedData = JsonConvert.SerializeObject(data);\n\n        var credentials = new Amazon.Runtime.BasicAWSCredentials(\"\",\"\");\n        var awsClient = new AmazonSageMakerRuntimeClient(credentials, RegionEndpoint.EUCentral1);\n        var request = new Amazon.SageMakerRuntime.Model.InvokeEndpointRequest\n        {\n            EndpointName = \"endpoint\",\n            ContentType = \"application\/json\",\n            Body = new MemoryStream(Encoding.ASCII.GetBytes(serializedData)),\n        };\n\n        var response = awsClient.InvokeEndpoint(request);\n        var predictions = Encoding.UTF8.GetString(response.Body.ToArray());\n<\/code><\/pre>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":13.8,
        "Solution_reading_time":15.84,
        "Solution_score_count":2.0,
        "Solution_sentence_count":12.0,
        "Solution_word_count":143.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1606724007903,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":5969.0,
        "Answerer_view_count":2590.0,
        "Challenge_adjusted_solved_time":9.3958480556,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I trained a model on GCP Vertex AI, and deployed it on an endpoint.<\/p>\n<p>I am able to execute predictions from a sample to my model with this python code <a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/predictions\/online-predictions-automl#aiplatform_predict_image_classification_sample-python\" rel=\"nofollow noreferrer\">https:\/\/cloud.google.com\/vertex-ai\/docs\/predictions\/online-predictions-automl#aiplatform_predict_image_classification_sample-python<\/a><\/p>\n<p>It works within my GCP project.<\/p>\n<p>My question is, is it possible to request this endpoint from another GCP project ? If I set a service account and set IAM role in both projects ?<\/p>",
        "Challenge_closed_time":1643080918688,
        "Challenge_comment_count":0,
        "Challenge_created_time":1643047926007,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/70838510",
        "Challenge_link_count":2,
        "Challenge_participation_count":1,
        "Challenge_readability":13.6,
        "Challenge_reading_time":9.56,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":9.1646336111,
        "Challenge_title":"Is it possible to request a Vertex AI endpoint from another GCP project?",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":417.0,
        "Challenge_word_count":80,
        "Platform":"Stack Overflow",
        "Poster_created_time":1598873976143,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Versailles, France",
        "Poster_reputation_count":140.0,
        "Poster_view_count":7.0,
        "Solution_body":"<p>Yes it is possible. For example you have Project A and Project B, assuming that Project A hosts the model.<\/p>\n<ul>\n<li><p>Add service account of Project B in Project A and provide at least <code>roles\/aiplatform.user<\/code> predefined role. See <a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/general\/access-control#predefined-roles\" rel=\"nofollow noreferrer\">predefined roles<\/a> and look for <code>roles\/aiplatform.user<\/code> to see complete roles it contains.<\/p>\n<\/li>\n<li><p>This role contains <strong>aiplatform.endpoints.<\/strong>* and <strong>aiplatform.batchPredictionJobs.<\/strong>* as these are the roles needed to run predictions.<\/p>\n<blockquote>\n<p>See <a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/general\/iam-permissions\" rel=\"nofollow noreferrer\">IAM permissions for Vertex AI<\/a><\/p>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th>Resource<\/th>\n<th>Operation<\/th>\n<th>Permissions needed<\/th>\n<\/tr>\n<\/thead>\n<tbody>\n<tr>\n<td>batchPredictionJobs<\/td>\n<td>Create a batchPredictionJob<\/td>\n<td>aiplatform.batchPredictionJobs.create (permission needed on the parent resource)<\/td>\n<\/tr>\n<tr>\n<td>endpoints<\/td>\n<td>Predict an endpoint<\/td>\n<td>aiplatform.endpoints.predict (permission needed on the endpoint resource)<\/td>\n<\/tr>\n<\/tbody>\n<\/table>\n<\/div><\/blockquote>\n<\/li>\n<\/ul>\n<p>With this set up, Project B will be able to use the model in Project A to run predictions.<\/p>\n<p>NOTE: Just make sure that the script of Project B points to the resources in Project A like <code>project_id<\/code> and <code>endpoint_id<\/code>.<\/p>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":1643081751060,
        "Solution_link_count":2.0,
        "Solution_readability":11.1,
        "Solution_reading_time":20.79,
        "Solution_score_count":1.0,
        "Solution_sentence_count":15.0,
        "Solution_word_count":163.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_created_time":1263294862568,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":183045.0,
        "Answerer_view_count":13691.0,
        "Challenge_adjusted_solved_time":1.7019194444,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>It took 45 minutes to create my endpoint from the stored endpoint configuration. (I tested it and it works too). This is the first time that I've used boto3 to do this, whereas previously I just used the Sagemaker web GUI to create an endpoint from endpoint configuration.  Suggestions to my code are appreciated:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import boto3\n\nsagemaker_client = boto3.client('sagemaker')\n\nresponse = sagemaker_client.create_endpoint(\n    EndpointName='sagemaker-tensorflow-x',\n    EndpointConfigName='sagemaker-tensorflow-x'\n)\n<\/code><\/pre>\n<p>Note: I've replaced the last part of my endpoint name with <code>x<\/code>.<\/p>",
        "Challenge_closed_time":1598923278260,
        "Challenge_comment_count":0,
        "Challenge_created_time":1598917151350,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1598923606240,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/63679503",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":10.7,
        "Challenge_reading_time":9.31,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":2.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":1.7019194444,
        "Challenge_title":"Why did it take so long to create endpoint with AWS Sagemaker using Boto3?",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":373.0,
        "Challenge_word_count":90,
        "Platform":"Stack Overflow",
        "Poster_created_time":1347733578128,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Chicago, IL, United States",
        "Poster_reputation_count":16557.0,
        "Poster_view_count":461.0,
        "Solution_body":"<p>AWS has currently <a href=\"https:\/\/status.aws.amazon.com\/\" rel=\"nofollow noreferrer\">issues<\/a> with Sagemaker:<\/p>\n<blockquote>\n<p>Increased Error Rates and Latencies for Multiple API operations<\/p>\n<\/blockquote>\n<blockquote>\n<p>5:33 PM PDT We are investigating increased error rates and latencies for CreateTrainingJob, CreateHyperParameterTuningJob, and CreateEndpoint API operations in the US-EAST-1 Region. Previously created jobs and endpoints are unaffected.<\/p>\n<\/blockquote>\n<blockquote>\n<p>6:04 PM PDT We are continuing to investigate increased error rates and latencies for CreateTrainingJob, CreateHyperParameterTuningJob, and CreateEndpoint API operations in the US-EAST-1 Region. Previously created jobs and endpoints are unaffected.<\/p>\n<\/blockquote>\n<p><a href=\"https:\/\/i.stack.imgur.com\/rQHQC.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/rQHQC.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":3.0,
        "Solution_readability":16.2,
        "Solution_reading_time":12.38,
        "Solution_score_count":1.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":94.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1280527017200,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":3035.0,
        "Answerer_view_count":129.0,
        "Challenge_adjusted_solved_time":114.9383547222,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>After setting up an endpoint for my model on Amazon SageMaker, I am trying to invoke it with a POST request which contains a file with a key <code>image<\/code> &amp; content type as <code>multipart\/form-data<\/code>.<\/p>\n\n<p>My AWS CLI command is like this:<\/p>\n\n<pre><code>aws sagemaker-runtime invoke-endpoint --endpoint-name &lt;endpoint-name&gt; --body image=@\/local\/file\/path\/dummy.jpg --content-type multipart\/form-data output.json --region us-east-1\n<\/code><\/pre>\n\n<p>which should be an equivalent of:<\/p>\n\n<pre><code>curl -X POST -F \"image=@\/local\/file\/path\/dummy.jpg\" http:\/\/&lt;endpoint&gt;\n<\/code><\/pre>\n\n<p>After running the <code>aws<\/code> command, the file is not transferred via the request, and my model is receiving the request without any file in it.<\/p>\n\n<p>Can someone please tell me what should be the correct format of the <code>aws<\/code> command in order to achieve this?<\/p>",
        "Challenge_closed_time":1533918119980,
        "Challenge_comment_count":2,
        "Challenge_created_time":1533504341903,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/51698373",
        "Challenge_link_count":1,
        "Challenge_participation_count":3,
        "Challenge_readability":12.3,
        "Challenge_reading_time":12.41,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":6.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":114.9383547222,
        "Challenge_title":"Amazon SageMaker: Invoke endpoint with file as multipart\/form-data",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":2346.0,
        "Challenge_word_count":119,
        "Platform":"Stack Overflow",
        "Poster_created_time":1472843515756,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":95.0,
        "Poster_view_count":33.0,
        "Solution_body":"<p>The first problem is that you're using 'http' for your CURL request. Virtually all AWS services strictly use 'https' as their protocol, SageMaker included. <a href=\"https:\/\/docs.aws.amazon.com\/general\/latest\/gr\/rande.html\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/general\/latest\/gr\/rande.html<\/a>. I'm going to assume this was a typo though.<\/p>\n\n<p>You can check the verbose output of the AWS CLI by passing the '--debug' argument to your call. I re-ran a similar experiment with my favorite duck.jpg image:<\/p>\n\n<pre><code>aws --debug sagemaker-runtime invoke-endpoint --endpoint-name MyEndpoint --body image=@\/duck.jpg --content-type multipart\/form-data  &gt;(cat)\n<\/code><\/pre>\n\n<p>Looking at the output, I see:<\/p>\n\n<pre><code>2018-08-10 08:42:20,870 - MainThread - botocore.endpoint - DEBUG - Making request for OperationModel(name=InvokeEndpoint) (verify_ssl=True) with params: {'body': 'image=@\/duck.jpg', 'url': u'https:\/\/sagemaker.us-west-2.amazonaws.com\/endpoints\/MyEndpoint\/invocations', 'headers': {u'Content-Type': 'multipart\/form-data', 'User-Agent': 'aws-cli\/1.15.14 Python\/2.7.10 Darwin\/16.7.0 botocore\/1.10.14'}, 'context': {'auth_type': None, 'client_region': 'us-west-2', 'has_streaming_input': True, 'client_config': &lt;botocore.config.Config object at 0x109a58ed0&gt;}, 'query_string': {}, 'url_path': u'\/endpoints\/MyEndpoint\/invocations', 'method': u'POST'}\n<\/code><\/pre>\n\n<p>It looks like the AWS CLI is using the string literal '@\/duck.jpg', not the file contents.<\/p>\n\n<p>Trying again with curl and the \"--verbose\" flag:<\/p>\n\n<pre><code>curl --verbose -X POST -F \"image=@\/duck.jpg\" https:\/\/sagemaker.us-west-2.amazonaws.com\/endpoints\/MyEndpoint\/invocations\n<\/code><\/pre>\n\n<p>I see the following:<\/p>\n\n<pre><code>Content-Length: 63097\n<\/code><\/pre>\n\n<p>Much better. The '@' operator is a CURL specific feature. The AWS CLI does have a way to pass files though: <\/p>\n\n<pre><code>--body fileb:\/\/\/duck.jpg\n<\/code><\/pre>\n\n<p>There is also a 'file' for non-binary files such as JSON. Unfortunately you cannot have the prefix. That is, you cannot say:<\/p>\n\n<pre><code> --body image=fileb:\/\/\/duck.jpg\n<\/code><\/pre>\n\n<p>You can prepend the string 'image=' to your file with a command such as the following. (You'll probably need to be more clever if your images are really big; this is really inefficient.)<\/p>\n\n<pre><code> echo -e \"image=$(cat \/duck.jpg)\" &gt; duck_with_prefix\n<\/code><\/pre>\n\n<p>Your final command would then be:<\/p>\n\n<pre><code> aws sagemaker-runtime invoke-endpoint --endpoint-name MyEndpoint --body fileb:\/\/\/duck_with_prefix --content-type multipart\/form-data  &gt;(cat)\n<\/code><\/pre>\n\n<p>Another note: Using raw curl with AWS services is extremely difficult due to the AWS Auth signing requirements - <a href=\"https:\/\/docs.aws.amazon.com\/AmazonS3\/latest\/API\/sig-v4-authenticating-requests.html\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/AmazonS3\/latest\/API\/sig-v4-authenticating-requests.html<\/a> <\/p>\n\n<p>It can be done, but you'll likely be more productive by using the AWS CLI or a pre-existing tool such as Postman - <a href=\"https:\/\/docs.aws.amazon.com\/apigateway\/latest\/developerguide\/how-to-use-postman-to-call-api.html\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/apigateway\/latest\/developerguide\/how-to-use-postman-to-call-api.html<\/a> <\/p>",
        "Solution_comment_count":2.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":8.0,
        "Solution_readability":14.9,
        "Solution_reading_time":43.72,
        "Solution_score_count":3.0,
        "Solution_sentence_count":28.0,
        "Solution_word_count":323.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":1.7104872222,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>We have a customer that is interested in the Azure OpenAI Service and had a few question:  <\/p>\n<p>What are the advantages for  using Azure OpenAI vs. OpenAI API.  <\/p>",
        "Challenge_closed_time":1648131698047,
        "Challenge_comment_count":0,
        "Challenge_created_time":1648125540293,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/785866\/azure-openai-advantages",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":8.4,
        "Challenge_reading_time":2.37,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":2,
        "Challenge_solved_time":1.7104872222,
        "Challenge_title":"Azure OpenAI advantages",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":32,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>@App-4824  Thanks for the question. The Azure OpenAI team always works to make the latest models available in Azure as soon as they are available from OpenAI. This is an active area of work for the team to tighten release date for future models.  <br \/>\nThe Azure service is backed by an SLA (which typically a customer's primary need for high availability, low latency), and the support that comes along with Azure services. This is the first commercialized model of its kind from any public cloud provider. This is  unique advantage to be first to market and to work closely with customer to adopt\/embrace these models for production use. <\/p>\n",
        "Solution_comment_count":2.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":8.1,
        "Solution_reading_time":7.86,
        "Solution_score_count":1.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":110.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":24.8830416667,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have a webservice which exposes a predictive model. It has been deployed with Auzure ML Studio. Since the last model re-training and webservice deployment, in circa 1% of the cases in production, I get the following out-of-memory (possibly correlated) errors:<\/p>\n<p>1) &quot;The model consumed more memory than was appropriated for it. Maximum allowed memory for the model is 2560 MB. Please check your model for issues.&quot;  <br \/>\n2) &quot;The following error occurred during evaluation of R script: R_tryEval: return error: Error: cannot allocate vector of size 57.6 Mb&quot;<\/p>\n<p>Please note that these errors occur exclusively while trying to consume the webservice, and not while model training, evaluation and deployment.<\/p>\n<p>Also, consuming the webservice in batch mode, as suggested <a href=\"https:\/\/social.microsoft.com\/Forums\/azure\/he-IL\/ccf4c683-f904-4117-8a4e-3258a56515f9\/azureml-execure-r-script-cannot-allocate-vector-of-size-818-mb?forum=MachineLearning\">here<\/a>, is not a viable option for our business use case.<\/p>\n<p>Is there a way to increase the memory limit for Azure webservices?<\/p>\n<p>Thank you<\/p>",
        "Challenge_closed_time":1592916913067,
        "Challenge_comment_count":0,
        "Challenge_created_time":1592827334117,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/38509\/out-of-memory-error-webservice-deployed-with-azure",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":11.8,
        "Challenge_reading_time":15.38,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":12,
        "Challenge_solved_time":24.8830416667,
        "Challenge_title":"Out-of-memory error webservice deployed with Azure ML Studio",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":152,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Thanks for reaching out. Currently, there's no way to increase memory limit in Classic Studio. We encourage customers to try <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-designer\">Azure Machine Learning designer (preview)<\/a>, which provides similar drag and drop ML modules plus scalability, version control, and enterprise security. Furthermore, with Designer, the endpoints are deployed to AKS where no limit other than cluster resource is imposed.    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":11.5,
        "Solution_reading_time":6.3,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":60.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1554186784008,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Hyderabad, Telangana, India",
        "Answerer_reputation_count":2175.0,
        "Answerer_view_count":434.0,
        "Challenge_adjusted_solved_time":235.0291777778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>When using Inference Schema to autogenerate the swagger doc for my AzureML endpoint (as detailed <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-advanced-entry-script\" rel=\"nofollow noreferrer\">here<\/a> and <a href=\"https:\/\/github.com\/Azure\/InferenceSchema\" rel=\"nofollow noreferrer\">here<\/a>), I see that it creates a wrapper around my input_sample. Is there a way to\nnot wrap the input inside this &quot;data&quot; wrapper?<\/p>\n<p>Here is what my score.py looks like:<\/p>\n<pre><code>input_sample = {\n                &quot;id&quot;: 123,\n                &quot;language&quot;: &quot;en&quot;\n                &quot;items&quot;: [{\n                    &quot;item&quot;: 1,\n                    &quot;desc&quot;: &quot;desc&quot;\n                }]\n            }\noutput_sample = [{'prediction': 'true', 'predictionConfidence': 0.8279970776764844}]\n\n@input_schema('data', StandardPythonParameterType(input_sample))\n@output_schema(StandardPythonParameterType(output_sample))\ndef run(data):\n&quot;&quot;&quot;\n    {\n        data: { --&gt; DON'T WANT this &quot;data&quot; wrapper\n                &quot;id&quot;: 123,\n                &quot;language&quot;: &quot;en&quot;\n                &quot;items&quot;: [{\n                    &quot;item&quot;: 1,\n                    &quot;desc&quot;: &quot;desc&quot;\n                }]\n            }\n    }\n    &quot;&quot;&quot;\n    try:\n        id = data['id']\n        ...\n        \n<\/code><\/pre>",
        "Challenge_closed_time":1601883755636,
        "Challenge_comment_count":1,
        "Challenge_created_time":1600982458753,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1601039285472,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/64054587",
        "Challenge_link_count":2,
        "Challenge_participation_count":2,
        "Challenge_readability":14.5,
        "Challenge_reading_time":16.61,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":2.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":8,
        "Challenge_solved_time":250.3602452778,
        "Challenge_title":"How can I remove the wrapper around the input when using Inference Schema",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":173.0,
        "Challenge_word_count":108,
        "Platform":"Stack Overflow",
        "Poster_created_time":1406298639460,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":435.0,
        "Poster_view_count":48.0,
        "Solution_body":"<p>InferenceSchema used with Azure Machine Learning deployments, then the code for this package was recently published at <a href=\"https:\/\/github.com\/Azure\/InferenceSchema\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/InferenceSchema<\/a> under an MIT license. So you could possibly use that to create a version specific to your needs.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1601885390512,
        "Solution_link_count":2.0,
        "Solution_readability":10.7,
        "Solution_reading_time":4.5,
        "Solution_score_count":0.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":39.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":0.5291666667,
        "Challenge_answer_count":1,
        "Challenge_body":"I have an Endpoint inference pipeline model deployed from an AutoPilot training job. Now that this is successful, I want to add model monitor. I have a script for online validation of the endpoint, and the F1 score is ~99%. This indicates that the endpoint interprets the call correctly. \n\nModel Monitor is recognizing the data in my jsonl files as the data not being CSV formatted. When my Model Monitor processing job runs, I receive the following constraint violation: \"There are missing columns in current dataset. Number of columns in current dataset: 1, Number of columns in baseline constraints: 225\".\n\nGiven the results from the Endpoint and this Model Monitor constraint violation, I perceive there is a conflict between how the Endpoint is storing the data and how the Model Monitor Processing Job wants to consume the data.\n\nHere is one sample prediction from the jsonl file. The data value is comma separated. \n\n    {\"captureData\":{\"endpointInput\":{\"observedContentType\":\"text\/csv\",\"mode\":\"INPUT\",\"data\":\"JHB,44443000.0,-0.0334,,44264000.0,,,,-2014000.0,,-2014000.0,,,,,,,-0.04,-0.04,55872000.0,,,0.996,,,,,,,,-0.0453,,2845000.0,,2845000.0,11636000.0,,,,,,,,,,,,190000000.0,,,,,,,,-18718000.0,,,,,,,,29000000.0,,,,,,,,-33000000.0,,-4000000.0,,,,,,,,,,,,,,,0.0,,,0.995972369102,1.0,-0.045316472785366,0.0,,,,,,,0.0,,,,,,,,,95.5638,,,,,,1.0,1.0,,0.15263157894737,,,,,,0.65252120693923,0.0,0.15263157894737,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,18606500.0,,,95.5638,,,2.3886,,,,,-0.0326,,-1.0449,,-1.05,-1.05,,0.0,,-0.1471,,,,,,,,,,,,,,,,,-0.5451,,,,,,,Financial Services,16.67890010036862\",\"encoding\":\"CSV\"},\"endpointOutput\":{\"observedContentType\":\"text\/csv; charset=utf-8\",\"mode\":\"OUTPUT\",\"data\":\"1\\n\",\"encoding\":\"CSV\"}},\"eventMetadata\":{\"eventId\":\"c97df615-0a2e-414d-9be3-bf3a14eb6363\",\"inferenceTime\":\"2020-04-15T16:26:46Z\"},\"eventVersion\":\"0\"}\n\nHere is the point within the log that the processing job recognizes a column mismatch. I see that it pulls down the data to store locally, pulls down the statistics and constraints files, errors with this constraint, and then gracefully ends the Processing Job. If more logs are needed to analyze, I have the Processing Job logs in CloudWatch Logs.\n\n    2020-04-15 17:11:49 INFO  FileUtil:66 - Read file from path \/opt\/ml\/processing\/baseline\/constraints\/constraints.json.\n    2020-04-15 17:11:50 INFO  FileUtil:66 - Read file from path \/opt\/ml\/processing\/baseline\/stats\/statistics.json.\n    2020-04-15 17:11:50 ERROR DataAnalyzer:65 - There are missing columns in current dataset. Number of columns in current dataset: 1, Number of columns in baseline constraints: 225\n    Skipping further processing because of column count mismatch.\n\nI could not find Model Monitor documentation on how to deal with column mismatch constraint violations.",
        "Challenge_closed_time":1586976185000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1586974280000,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1668600874335,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QU8Xkelo1ARA2zcn4rHuk09w\/sagemaker-model-monitor-missing-columns-constraint-violation",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":11.6,
        "Challenge_reading_time":37.44,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":19,
        "Challenge_solved_time":0.5291666667,
        "Challenge_title":"SageMaker Model Monitor Missing Columns Constraint Violation",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":360.0,
        "Challenge_word_count":289,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"That violation fires when, for example, input to your endpoint has fewer columns than baseline input does. This is helpful to flag data quality issues. https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/model-monitor-interpreting-violations.html\n\nIn this case, however, this is an artifact of how we perform the analysis. We concatenate output and input CSVs into a single CSV to analyze the whole thing in one go. E.g. it would look like:\n\n```\noutput_col,input_col_1,input_col_2,...,input_col_n\n```\n\nIn this case, however, your output has a trailing newline which means that after concatenating this looks like:\n\n```\noutput_col # embedded newline in your output\n,input_col_1,input_col_2,...,input_col_n\n```\n\nTriggering the code to think there is only one column in dataset and hence failing the job.\n\nWe have a fix flowing through the pipeline now, while that goes out you can add a preprocessing script to your schedule to strip out the trailing newline from the output. We will create a sample notebook for this, in the meantime docs are at\nhttps:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/model-monitor-pre-and-post-processing.html#model-monitor-pre-processing-script",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1667925546704,
        "Solution_link_count":2.0,
        "Solution_readability":12.2,
        "Solution_reading_time":14.76,
        "Solution_score_count":0.0,
        "Solution_sentence_count":9.0,
        "Solution_word_count":152.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":766.1991666667,
        "Challenge_answer_count":7,
        "Challenge_body":"<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Look through existing open and closed issues to see if someone has reported the issue before -->\r\n\r\n## Expected Behavior\r\n<WARNING:elasticsearch:PUT https:\/\/my aws ES endpoint\/table_a54a9a96-c246-4bcd-b417-2d8c005c3290 [status:400 request:0.069s]\r\nINFO:databuilder.callback.call_back:No callbacks to notify\r\nTraceback (most recent call last):\r\n  File \"example\/scripts\/sample_data_loader_neptune.py\", line 403, in <module>\r\n    job_es_table.launch()\r\n  File \"\/tmp\/amundsen\/venv\/lib\/python3.7\/site-packages\/databuilder\/job\/job.py\", line 76, in launch\r\n    raise e\r\n  File \"\/tmp\/amundsen\/venv\/lib\/python3.7\/site-packages\/databuilder\/job\/job.py\", line 72, in launch\r\n    self.publisher.publish()\r\n  File \"\/tmp\/amundsen\/venv\/lib\/python3.7\/site-packages\/databuilder\/publisher\/base_publisher.py\", line 40, in publish\r\n    raise e\r\n  File \"\/tmp\/amundsen\/venv\/lib\/python3.7\/site-packages\/databuilder\/publisher\/base_publisher.py\", line 37, in publish\r\n    self.publish_impl()\r\n  File \"\/tmp\/damundsen\/venv\/lib\/python3.7\/site-packages\/databuilder\/publisher\/elasticsearch_publisher.py\", line 93, in publish_impl\r\n    self.elasticsearch_client.indices.create(index=self.elasticsearch_new_index, body=self.elasticsearch_mapping)\r\n  File \"\/tmp\/amundsen\/venv\/lib\/python3.7\/site-packages\/elasticsearch\/client\/utils.py\", line 347, in _wrapped\r\n    return func(*args, params=params, headers=headers, **kwargs)\r\n  File \"\/tmp\/amundsen\/venv\/lib\/python3.7\/site-packages\/elasticsearch\/client\/indices.py\", line 146, in create\r\n    \"PUT\", _make_path(index), params=params, headers=headers, body=body\r\n  File \"\/tmp\/amundsen\/venv\/lib\/python3.7\/site-packages\/elasticsearch\/transport.py\", line 466, in perform_request\r\n    raise e\r\n  File \"\/tmp\/damundsen\/venv\/lib\/python3.7\/site-packages\/elasticsearch\/transport.py\", line 434, in perform_request\r\n    timeout=timeout,\r\n  File \"\/tmp\/amundsen\/venv\/lib\/python3.7\/site-packages\/elasticsearch\/connection\/http_requests.py\", line 216, in perform_request\r\n    self._raise_error(response.status_code, raw_data)\r\n  File \"\/tmp\/amundsen\/venv\/lib\/python3.7\/site-packages\/elasticsearch\/connection\/base.py\", line 329, in _raise_error\r\n    status_code, error_message, additional_info\r\n\r\n\r\nelasticsearch.exceptions.RequestError: RequestError(400, 'mapper_parsing_exception', 'Root mapping definition has unsupported parameters:  [schema : {analyzer=simple, type=text, fields={raw={type=keyword}}}] [cluster : {analyzer=simple, type=text, fields={raw={type=keyword}}}] [description : {analyzer=simple, type=text}] [display_name : {type=keyword}] [column_descriptions : {analyzer=simple, type=text}] [programmatic_descriptions : {analyzer=simple, type=text}] [tags : {type=keyword}] [badges : {type=keyword}] [database : {analyzer=simple, type=text, fields={raw={type=keyword}}}] [total_usage : {type=long}] [name : {analyzer=simple, type=text, fields={raw={type=keyword}}}] [last_updated_timestamp : {format=epoch_second, type=date}] [unique_usage : {type=long}] [column_names : {analyzer=simple, type=text, fields={raw={normalizer=column_names_normalizer, type=keyword}}}] [key : {type=keyword}]')->\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n* Amunsen version used: Databuilder: 6.7.1 Common 0.26.0 Amundsen-Gremlin 0.0.13 AWS ES : 6.8\r\n",
        "Challenge_closed_time":1649071896000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1646313579000,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/github.com\/amundsen-io\/amundsen\/issues\/1748",
        "Challenge_link_count":1,
        "Challenge_participation_count":7,
        "Challenge_readability":22.0,
        "Challenge_reading_time":43.86,
        "Challenge_repo_contributor_count":207.0,
        "Challenge_repo_fork_count":890.0,
        "Challenge_repo_issue_count":2023.0,
        "Challenge_repo_star_count":3674.0,
        "Challenge_repo_watch_count":245.0,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":25,
        "Challenge_solved_time":766.1991666667,
        "Challenge_title":"Bug Report elasticsearch exception for sample_neptune_loader",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":216,
        "Platform":"Github",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"Thanks for opening your first issue here!\n This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs.\n Same problem here, does you solved? @amandeep848 could you fix the problem? @amandeep848 could you fix the problem? Hello!\r\n\r\nI have been fixed the problem by putting the version of amundsen-common to 0.24.1\r\n\r\n- My `requirements.txt` file is setup as shown below:\r\n\r\n```text\r\namundsen-databuilder==6.5.2\r\namundsen-gremlin==0.0.13\r\ngremlinpython==3.4.10\r\nrequests-aws4auth==1.1.1\r\nboto3==1.21.23\r\nbotocore==1.24.23\r\ntyping-extensions==4.1.1\r\noverrides==6.1.0\r\namundsen-common==0.24.1\r\n```\r\n\r\n- My Glue databuilder script:\r\n\r\n```python\r\nimport logging\r\nimport os\r\nimport uuid\r\nimport boto3\r\nimport textwrap\r\nimport json\r\n\r\nfrom datetime import date\r\n\r\nfrom elasticsearch import Elasticsearch\r\nfrom pyhocon import ConfigFactory\r\n\r\nfrom databuilder.clients.neptune_client import NeptuneSessionClient\r\nfrom databuilder.extractor.es_last_updated_extractor import EsLastUpdatedExtractor\r\nfrom databuilder.extractor.neptune_search_data_extractor import NeptuneSearchDataExtractor\r\n\r\nfrom databuilder.job.job import DefaultJob\r\nfrom databuilder.loader.file_system_elasticsearch_json_loader import FSElasticsearchJSONLoader\r\nfrom databuilder.loader.file_system_neptune_csv_loader import FSNeptuneCSVLoader\r\nfrom databuilder.publisher.elasticsearch_constants import (\r\n    DASHBOARD_ELASTICSEARCH_INDEX_MAPPING, USER_ELASTICSEARCH_INDEX_MAPPING,\r\n)\r\nfrom databuilder.publisher.elasticsearch_publisher import ElasticsearchPublisher\r\nfrom databuilder.publisher.neptune_csv_publisher import NeptuneCSVPublisher\r\nfrom databuilder.task.task import DefaultTask\r\nfrom databuilder.transformer.base_transformer import ChainedTransformer, NoopTransformer\r\nfrom databuilder.transformer.dict_to_model import MODEL_CLASS, DictToModel\r\nfrom databuilder.transformer.generic_transformer import (\r\n    CALLBACK_FUNCTION, FIELD_NAME, GenericTransformer,\r\n)\r\n\r\nfrom databuilder.extractor.glue_extractor import GlueExtractor\r\nfrom databuilder.task.neptune_staleness_removal_task import NeptuneStalenessRemovalTask\r\n\r\n\r\nes_host = os.getenv('ES_HOST')\r\n\r\nneptune_host = os.getenv('NEPTUNE_HOST')\r\nneptune_port = os.getenv('NEPTUNE_PORT', 8182)\r\nneptune_iam_role_name = os.getenv('NEPTUNE_IAM_ROLE')\r\n\r\nS3_BUCKET_NAME = os.getenv('S3_BUCKET_NAME')\r\ntoday = date.today()\r\nS3_DATA_PATH = f'amundsen_data\/glue_extractor\/year={today.year}\/month={today.month}\/day={today.day}'\r\n\r\nAWS_REGION = os.getenv('AWS_REGION')\r\nGLUE_DATABASE_IDENTIFIER = os.getenv('GLUE_DATABASE_IDENTIFIER')\r\n\r\nes = Elasticsearch(\r\n    '{}'.format(es_host),\r\n    scheme=\"https\",\r\n    port=443,\r\n)\r\n\r\nNEPTUNE_ENDPOINT = '{}:{}'.format(neptune_host, neptune_port)\r\n\r\nLOGGER = logging.getLogger(__name__)\r\n\r\n\r\ndef run_glue_job(job_name):\r\n    \"\"\"Run Glue metadata extraction\r\n\r\n    Args:\r\n        job_name (string): job name\r\n    \"\"\"\r\n\r\n    tmp_folder = '\/var\/tmp\/amundsen\/{job_name}'.format(job_name=job_name)\r\n    node_files_folder = '{tmp_folder}\/nodes'.format(tmp_folder=tmp_folder)\r\n    relationship_files_folder = '{tmp_folder}\/relationships'.format(tmp_folder=tmp_folder)\r\n\r\n    loader = FSNeptuneCSVLoader()\r\n    publisher = NeptuneCSVPublisher()\r\n\r\n    with open(\"databases.json\") as jsonFile:\r\n\r\n        filters = json.load(jsonFile)\r\n\r\n    job_config = ConfigFactory.from_dict({\r\n        f'extractor.glue.{GlueExtractor.CLUSTER_KEY}': GLUE_DATABASE_IDENTIFIER,\r\n        f'extractor.glue.{GlueExtractor.FILTER_KEY}': filters,\r\n        loader.get_scope(): {\r\n            FSNeptuneCSVLoader.NODE_DIR_PATH: node_files_folder,\r\n            FSNeptuneCSVLoader.RELATION_DIR_PATH: relationship_files_folder,\r\n            FSNeptuneCSVLoader.SHOULD_DELETE_CREATED_DIR: True,\r\n            FSNeptuneCSVLoader.JOB_PUBLISHER_TAG: 'unique_tag'\r\n        },\r\n        publisher.get_scope(): {\r\n            NeptuneCSVPublisher.NODE_FILES_DIR: node_files_folder,\r\n            NeptuneCSVPublisher.RELATION_FILES_DIR: relationship_files_folder,\r\n            NeptuneCSVPublisher.AWS_S3_BUCKET_NAME: S3_BUCKET_NAME,\r\n            NeptuneCSVPublisher.AWS_BASE_S3_DATA_PATH: S3_DATA_PATH,\r\n            NeptuneCSVPublisher.NEPTUNE_HOST: NEPTUNE_ENDPOINT,\r\n            NeptuneCSVPublisher.AWS_IAM_ROLE_NAME: neptune_iam_role_name,\r\n            NeptuneCSVPublisher.AWS_REGION: AWS_REGION\r\n        },\r\n    })\r\n\r\n    DefaultJob(\r\n        conf=job_config,\r\n        task=DefaultTask(\r\n            extractor=GlueExtractor(),\r\n            loader=loader,\r\n            transformer=NoopTransformer()\r\n        ),\r\n        publisher=publisher\r\n    ).launch()\r\n\r\ndef create_remove_stale_data_job():\r\n    \"\"\"Run remove stale data from Neptune\r\n\r\n    Returns:\r\n        NeptuneStalenessRemovalTask: Neptune stateleness data job\r\n    \"\"\"\r\n\r\n    target_relations = ['DESCRIPTION', 'DESCRIPTION_OF', 'COLUMN', 'COLUMN_OF', 'TABLE', 'TABLE_OF']\r\n    target_nodes = ['Table', 'Column', 'Programmatic_Description', \"Schema\"]\r\n\r\n    staleness_max_pct = 5\r\n\r\n    while True:\r\n\r\n        try:\r\n\r\n            LOGGER.info(f'Delete stale data at threshold - {staleness_max_pct}%')\r\n\r\n            job_config = ConfigFactory.from_dict({\r\n                'task.remove_stale_data': {\r\n                    NeptuneStalenessRemovalTask.TARGET_RELATIONS: target_relations,\r\n                    NeptuneStalenessRemovalTask.TARGET_NODES: target_nodes,\r\n                    NeptuneStalenessRemovalTask.STALENESS_CUT_OFF_IN_SECONDS: 86400,  # 1 day\r\n                    NeptuneStalenessRemovalTask.STALENESS_MAX_PCT: staleness_max_pct,\r\n                    'neptune.client': {\r\n                        NeptuneSessionClient.NEPTUNE_HOST_NAME: NEPTUNE_ENDPOINT,\r\n                        NeptuneSessionClient.AWS_REGION: AWS_REGION,\r\n                    }\r\n                }\r\n            })\r\n\r\n            job = DefaultJob(\r\n                conf=job_config,\r\n                task=NeptuneStalenessRemovalTask()\r\n            )\r\n\r\n            job.launch()\r\n\r\n            break\r\n\r\n        except Exception as ex:\r\n\r\n            LOGGER.error(ex)\r\n            LOGGER.info(f'Increase stale data threshold')\r\n\r\n            staleness_max_pct += 5\r\n\r\n            if staleness_max_pct == 105:\r\n\r\n                break\r\n\r\n\r\ndef create_es_publisher_job(elasticsearch_index_alias='table_search_index',\r\n                            elasticsearch_doc_type_key='table',\r\n                            model_name='databuilder.models.table_elasticsearch_document.TableESDocument',\r\n                            entity_type='table',\r\n                            elasticsearch_mapping=None):\r\n    \"\"\"\r\n    :param elasticsearch_index_alias:  alias for Elasticsearch used in\r\n                                       amundsensearchlibrary\/search_service\/config.py as an index\r\n    :param elasticsearch_doc_type_key: name the ElasticSearch index is prepended with. Defaults to `table` resulting in\r\n                                       `table_{uuid}`\r\n    :param model_name:                 the Databuilder model class used in transporting between Extractor and Loader\r\n    :param entity_type:                Entity type handed to the `Neo4jSearchDataExtractor` class, used to determine\r\n                                       Cypher query to extract data from Neo4j. Defaults to `table`.\r\n    :param elasticsearch_mapping:      Elasticsearch field mapping \"DDL\" handed to the `ElasticsearchPublisher` class,\r\n                                       if None is given (default) it uses the `Table` query baked into the Publisher\r\n    \"\"\"\r\n    # loader saves data to this location and publisher reads it from here\r\n    extracted_search_data_path = '\/var\/tmp\/amundsen\/search_data.json'\r\n    loader = FSElasticsearchJSONLoader()\r\n    extractor = NeptuneSearchDataExtractor()\r\n\r\n    task = DefaultTask(\r\n        loader=loader,\r\n        extractor=extractor,\r\n        transformer=NoopTransformer()\r\n    )\r\n\r\n    # elastic search client instance\r\n    elasticsearch_client = es\r\n\r\n    # unique name of new index in Elasticsearch\r\n    elasticsearch_new_index_key = '{}_'.format(elasticsearch_doc_type_key) + str(uuid.uuid4())\r\n\r\n    publisher = ElasticsearchPublisher()\r\n\r\n    session = boto3.Session(region_name=AWS_REGION)\r\n\r\n    aws_creds = session.get_credentials()\r\n    aws_access_key = aws_creds.access_key\r\n    aws_access_secret = aws_creds.secret_key\r\n    aws_token = aws_creds.token\r\n\r\n    job_config = ConfigFactory.from_dict({\r\n        extractor.get_scope(): {\r\n            NeptuneSearchDataExtractor.ENTITY_TYPE_CONFIG_KEY: entity_type,\r\n            NeptuneSearchDataExtractor.MODEL_CLASS_CONFIG_KEY: model_name,\r\n            'neptune.client': {\r\n                NeptuneSessionClient.NEPTUNE_HOST_NAME: NEPTUNE_ENDPOINT,\r\n                NeptuneSessionClient.AWS_REGION: AWS_REGION,\r\n                NeptuneSessionClient.AWS_ACCESS_KEY: aws_access_key,\r\n                NeptuneSessionClient.AWS_SECRET_ACCESS_KEY: aws_access_secret,\r\n                NeptuneSessionClient.AWS_SESSION_TOKEN: aws_token\r\n            }\r\n        },\r\n        'loader.filesystem.elasticsearch.file_path': extracted_search_data_path,\r\n        'loader.filesystem.elasticsearch.mode': 'w',\r\n        publisher.get_scope(): {\r\n            'file_path': extracted_search_data_path,\r\n            'mode': 'r',\r\n            'client': elasticsearch_client,\r\n            'new_index': elasticsearch_new_index_key,\r\n            'doc_type': elasticsearch_doc_type_key,\r\n            'alias': elasticsearch_index_alias\r\n        }\r\n    })\r\n\r\n    # only optionally add these keys, so need to dynamically `put` them\r\n    if elasticsearch_mapping:\r\n        job_config.put('publisher.elasticsearch.{}'.format(ElasticsearchPublisher.ELASTICSEARCH_MAPPING_CONFIG_KEY),\r\n                       elasticsearch_mapping)\r\n\r\n    job = DefaultJob(\r\n        conf=job_config,\r\n        task=task,\r\n        publisher=ElasticsearchPublisher()\r\n    )\r\n\r\n    return job\r\n\r\n\r\nif __name__ == \"__main__\":\r\n\r\n    logging.basicConfig(level=logging.INFO)\r\n\r\n    LOGGER.info('ES Host: ' +  es_host)\r\n    LOGGER.info('Neptune Host: ' + neptune_host)\r\n    LOGGER.info('Neptune Port: ' + str(neptune_port))\r\n    LOGGER.info('Neptune IAM Role Name: ' + neptune_iam_role_name)\r\n    LOGGER.info('S3 Bucket Name: ' + S3_BUCKET_NAME)\r\n    LOGGER.info('S3 Data Path: ' + S3_DATA_PATH)\r\n    LOGGER.info('AWS Region: ' + AWS_REGION)\r\n\r\n    logging.info('>>> Running Remove Stale Data Job <<<')\r\n\r\n    create_remove_stale_data_job()\r\n\r\n    logging.info('>>> Running Glue Extractor <<<')\r\n\r\n    run_glue_job('amundsen_glue_extractor')\r\n\r\n    logging.info('>>> Running ES Publisher <<<')\r\n\r\n    job_es_table = create_es_publisher_job(\r\n        elasticsearch_index_alias='table_search_index',\r\n        elasticsearch_doc_type_key='table',\r\n        entity_type='table',\r\n        model_name='databuilder.models.table_elasticsearch_document.TableESDocument'\r\n    )\r\n    job_es_table.launch()\r\n```\r\n\r\n- databases.json\r\n\r\n```json\r\n[]\r\n```\r\n\r\n- .env\r\n\r\n```env\r\nES_HOST=<ES_HOST>\r\nNEPTUNE_HOST=<NEPTUNE_HOST>\r\nNEPTUNE_PORT=8182\r\nNEPTUNE_IAM_ROLE=<NEPTUNE_IAM_ROLE>\r\nS3_BUCKET_NAME=<S3_BUCKET_NAME>\r\nAWS_REGION=<AWS_REGION>\r\nSECRET_NAME=<SECRET_NAME>\r\nGLUE_DATABASE_IDENTIFIER=<GLUE_DATABASE_IDENTIFIER>\r\n```\r\n\r\n\r\nHope this help!\r\n\r\nBest Regards.\r\nBill\r\n I encountered this issue, too, as I installed data builder from codebase with `python setup.py install`, and after rebase with the main branch, the previous version was not clean up when we simply rerun `python setup.py install`, the way out was to do `pip uninstall amundsen-databuilder` and `pip uninstall amundsen-common` until non of packages existed(there could be multiple versions left, more than once per each package could be required).\r\n\r\nThen the expected elastic-related code is up to date w\/o this error anymore.",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":20.1,
        "Solution_reading_time":132.24,
        "Solution_score_count":1.0,
        "Solution_sentence_count":103.0,
        "Solution_word_count":698.0,
        "Tool":"Neptune"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":3.340015,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi! I wanted to see if VBA and Azure Machine Learning Excel Add In can be connected to each other. Are there any way to code VBA (use VBA) for controlling or altering Azure Machine Learning Excel Add In? I have used Azure Machine Learning to rate candidate feedback as negative or positive, but it has like a 75 -80% success rate - there are still a good chunk of comments that are rated wrong. However, it is still an amazing tool that I want to use v- I was just wondering if I can increase the accuracy of it somehow by creating a VBA code that connects it to Azure Machine Learning where I can add words related to negative responses or vice versa for positive response to increase the accuracy. <\/p>",
        "Challenge_closed_time":1610161769647,
        "Challenge_comment_count":0,
        "Challenge_created_time":1610149745593,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/224491\/vba-and-azure-machine-learning-excel-add-in",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":11.8,
        "Challenge_reading_time":8.99,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":3.340015,
        "Challenge_title":"VBA  And Azure Machine Learning Excel Add In",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":139,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hi, we currently don't support VBA and Azure ML Excel add-in integration. You'll need to apply <a href=\"https:\/\/stackoverflow.com\/questions\/41447104\/how-to-improve-classification-accuracy-for-machine-learning\">ML techniques for improving your model<\/a> and re-deploy your model.  <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":15.2,
        "Solution_reading_time":3.8,
        "Solution_score_count":0.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":28.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1432829415467,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":501.0,
        "Answerer_view_count":76.0,
        "Challenge_adjusted_solved_time":523.8942158334,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I'm posting this more as a 'probe' question and plan to expand the discussion in case some interest shows up. The reason behind this is that in my experience, the SO community on <code>azure-ml<\/code> (and related) is still developing and there is not much feedback - but I would be happy to help it grow stronger. <\/p>\n\n<p>My situation is as follows: I have an experiment in Azure ML which does all its work inside an <code>R<\/code> module. I published this as a web service and set the 'max concurrent calls' slider to 10 - which I believe guarantees me that there will be at most 10 instances of my web service up and running at any time, to serve requests (please correct me if i am wrong). <\/p>\n\n<p>Now, I am trying to do some performance testing by firing 10 parallel calls to my webservice, but get unexpected results...<\/p>\n\n<p>I am trying to run the load tests and log where each of them actually goes to (which instance). My idea is to get a glimpse into how these calls are actually distributed to the instances by the load balancer, under certain max number of concurrent calls = X. I am doing this by firing a call to \"bot.whatismyipaddress.com\" from inside the <code>R<\/code> script. Here is the important snip of the code:<\/p>\n\n<pre><code>library(rjson)\nmachine.ip &lt;- readLines(\"http:\/\/bot.whatismyipaddress.com\/\", warn=F)\nresult$MachineIP &lt;- machine.ip\n<\/code><\/pre>\n\n<p>Additionally, I am using the sample <code>R<\/code> code from the web service RRS help page to fire up to 70 (sequential) calls to my web service. This sample code returns some info back to the console : the results of my web service as well as some info on to which hostname the call goes through. Here is a sample :<\/p>\n\n<pre><code>* Hostname was NOT found in DNS cache\n*   Trying 40.114.242.9...\n* Connected to europewest.services.azureml.net (40.114.242.9) port 443 (#0)\n<\/code><\/pre>\n\n<p>The difficulty that I am facing is that I cannot <strong>uniquely identify<\/strong> the different instances of my web service. The info out to console from the call (the second snippet) often shows a different IP address than the one from inside-<code>R<\/code>-code logs (<code>result$MachineIP<\/code>)...<\/p>\n\n<p>Can someone point out what am i doing wrong, and how could i uniquely identify the different instances that are serving the calls? Any help would be really appreciated. Thanks!<\/p>\n\n<p>P.S. I've tried <a href=\"https:\/\/stackoverflow.com\/questions\/14357219\/function-for-retrieving-own-ip-address-from-within-r\">this<\/a> as well, but the first apporach does not work when calling it from inside the <code>R<\/code> script and I'm using a modified version of the second apporach (the one suggested there does not work). <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/azure\/en-US\/93f07abf-f0ec-4baa-8225-1ca1a072ca2d\/system-call-from-inside-r-script-does-not-work?forum=MachineLearning\" rel=\"nofollow noreferrer\">Here<\/a> are also my <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/azure\/en-US\/ee6ff5a6-2995-4f3f-b4db-0229b1d9d1d3\/lifetime-of-azure-ml-web-service-container?forum=MachineLearning\" rel=\"nofollow noreferrer\">questions<\/a> on the Azure forum, in case someone is interested.<\/p>\n\n<p>If anyone could help or point me to some source of info I would be really grateful! <\/p>",
        "Challenge_closed_time":1452244028967,
        "Challenge_comment_count":0,
        "Challenge_created_time":1450358009790,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1495540319592,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/34335483",
        "Challenge_link_count":4,
        "Challenge_participation_count":1,
        "Challenge_readability":10.2,
        "Challenge_reading_time":42.07,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":26,
        "Challenge_solved_time":523.8942158334,
        "Challenge_title":"Uniquely identify instances of VMs (Azure ML - web services)",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":61.0,
        "Challenge_word_count":464,
        "Platform":"Stack Overflow",
        "Poster_created_time":1432829415467,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":501.0,
        "Poster_view_count":76.0,
        "Solution_body":"<p>This question was resolved thanks to some people on the Azure ML forum so \nI'm going to post an answer for anyone landing here in search for some answers...<\/p>\n\n<p>The short answer is no, this is not possible. The more detailed version is:<br>\n\"From within the R script you cannot identify the internal AzureML IP addresses or the unique web service instances. When you make an external network call from the R script to an outside URL, that URL will see one of the AzureML public virtual IP's as the source IP. These are IP's of the load balancers, and not of the machines that are physically running the web service. AzureML dynamically allocates the instances of R engine in the backend, handles failures, and uses multiple nodes for running the web service for high availability. The exact layout of these for a given web service is not programmatically discoverable.\"<br>\nHere is also the <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/azure\/en-US\/dd1f0658-7b0b-46d8-8e32-3fe4e96ec4be\/uniquely-identify-instances-of-vms-web-services?forum=MachineLearning#cde28631-828d-4d83-9c93-1a1cf0dfb6fb\" rel=\"nofollow\">link<\/a> to the original discussion. <\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":11.5,
        "Solution_reading_time":14.66,
        "Solution_score_count":0.0,
        "Solution_sentence_count":9.0,
        "Solution_word_count":162.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1565376125572,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":31.0,
        "Answerer_view_count":2.0,
        "Challenge_adjusted_solved_time":10701.8852247222,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have a endpoint in Amazon SageMaker (Image-classification algorithm) in Jupyter notebook that works fine. In Lambda function works fine too, when I call the Lambda function from API Gateway, from test of API Gateway, works fine too.<\/p>\n<p>The problem is when I call the API from Postman according this answer: <a href=\"https:\/\/stackoverflow.com\/questions\/39660074\/post-image-data-using-postman\">&quot;Post Image data using POSTMAN&quot;<\/a><\/p>\n<p>The code in Lambda is:<\/p>\n<pre><code>import boto3\nimport json\nimport base64\n\nENDPOINT_NAME = &quot;DEMO-XGBoostEndpoint-Multilabel&quot;\nruntime= boto3.client(&quot;runtime.sagemaker&quot;)\nimagen_ = &quot;\/tmp\/imageToProcess.jpg&quot;\n\ndef write_to_file(save_path, data):\n    with open(save_path, &quot;wb&quot;) as f:\n        f.write(base64.b64decode(data))\n\ndef lambda_handler(event, context):\n    img_json = json.loads(json.dumps(event))\n\n    write_to_file(imagen_, json.dumps(event, indent=2))\n\n    with open(imagen_, &quot;rb&quot;) as image:\n        f = image.read()\n        b = bytearray(f)\n\n    payload = b\n\n    response = runtime.invoke_endpoint(EndpointName=ENDPOINT_NAME,\n                                       ContentType=&quot;application\/x-image&quot;,\n                                       Body=payload)\n\n    #print(response)\n    result = json.loads(response[&quot;Body&quot;].read().decode())\n    print(result)\n    predicted_label=[]\n    classes = [&quot;chair&quot;, &quot;handbag&quot;, &quot;person&quot;, &quot;traffic light&quot;, &quot;clock&quot;]\n    for idx, val in enumerate(classes):\n        print(&quot;%s:%f &quot;%(classes[idx], result[idx]), end=&quot;&quot;)\n        predicted_label += (classes[idx], result[idx])\n\n    return {\n      &quot;statusCode&quot;: 200,\n      &quot;headers&quot;: { &quot;content-type&quot;: &quot;application\/json&quot;},\n      &quot;body&quot;:  predicted_label\n}\n<\/code><\/pre>\n<p>The error is:<\/p>\n<pre><code>Traceback (most recent call last):\n  File &quot;\/var\/task\/lambda_function.py&quot;, line 26, in lambda_handler\n    Body=payload)\n  File &quot;\/var\/runtime\/botocore\/client.py&quot;, line 316, in _api_call\n    return self._make_api_call(operation_name, kwargs)\n  File &quot;\/var\/runtime\/botocore\/client.py&quot;, line 626, in _make_api_call\n    raise error_class(parsed_response, operation_name)\nbotocore.errorfactory.ModelError: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from model with message &quot;unable to evaluate payload provided&quot;. See https:\/\/us-east-2.console.aws.amazon.com\/cloudwatch\/home?region=us-east-2#logEventViewer:group=\/aws\/sagemaker\/Endpoints\/DEMO-XGBoostEndpoint-Multilabel in account 866341179300 for more information. ```\n<\/code><\/pre>",
        "Challenge_closed_time":1597003004372,
        "Challenge_comment_count":2,
        "Challenge_created_time":1595742856227,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1595997749087,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/63096583",
        "Challenge_link_count":2,
        "Challenge_participation_count":3,
        "Challenge_readability":18.4,
        "Challenge_reading_time":35.59,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":2.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":19,
        "Challenge_solved_time":350.0411513889,
        "Challenge_title":"SageMaker: An error occurred (ModelError) when calling the InvokeEndpoint operation: unable to evaluate payload provided",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":3996.0,
        "Challenge_word_count":218,
        "Platform":"Stack Overflow",
        "Poster_created_time":1565376125572,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":31.0,
        "Poster_view_count":2.0,
        "Solution_body":"<p>I resolved with <a href=\"https:\/\/medium.com\/swlh\/upload-binary-files-to-s3-using-aws-api-gateway-with-aws-lambda-2b4ba8c70b8e\" rel=\"nofollow noreferrer\">this<\/a> post:<\/p>\n<p>Thank all<\/p>\n<p>Finally the code in lambda function is:<\/p>\n<pre><code>import os\nimport boto3\nimport json\nimport base64\n\nENDPOINT_NAME = os.environ['endPointName']\nCLASSES = &quot;[&quot;chair&quot;, &quot;handbag&quot;, &quot;person&quot;, &quot;traffic light&quot;, &quot;clock&quot;]&quot;\nruntime= boto3.client(&quot;runtime.sagemaker&quot;)\n\ndef lambda_handler(event, context):\n    file_content = base64.b64decode(event['content'])\n\n    payload = file_content\n    response = runtime.invoke_endpoint(EndpointName=ENDPOINT_NAME, ContentType=&quot;application\/x-image&quot;, Body=payload)\n\n    result = json.loads(response[&quot;Body&quot;].read().decode())\n    print(result)\n    predicted_label=[]\n    classes = CLASSES\n    for idx, val in enumerate(classes):\n       print(&quot;%s:%f &quot;%(classes[idx], result[idx]), end=&quot;&quot;)\n       predicted_label += (classes[idx], result[idx])\n\n    return {\n      &quot;statusCode&quot;: 200,\n      &quot;headers&quot;: { &quot;content-type&quot;: &quot;application\/json&quot;},\n      &quot;body&quot;:  predicted_label\n    }\n<\/code><\/pre>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1634524535896,
        "Solution_link_count":1.0,
        "Solution_readability":22.8,
        "Solution_reading_time":16.28,
        "Solution_score_count":1.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":74.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":7.2911030556,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>There is a requirement -    <\/p>\n<ol>\n<li> ML models are created by third party vendors in their Azure environment. ML models will be readily available for consumption.    <\/li>\n<li> As an admin, we need to setup new environment for Azure machine learning for our organization.    <\/li>\n<li> Once point#2 is completed, need to import ML models from point#1 to the newly setup ML environment.    <\/li>\n<\/ol>\n<p>Can you please let us know all possible ways to do this?    <\/p>\n<p>Thank You!    <\/p>\n<p>Regards,    <br \/>\nPreetha    <\/p>",
        "Challenge_closed_time":1673007028248,
        "Challenge_comment_count":0,
        "Challenge_created_time":1672980780277,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1153982\/all-possible-options-to-import-exising-azure-ml-mo",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":7.0,
        "Challenge_reading_time":7.43,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":8,
        "Challenge_solved_time":7.2911030556,
        "Challenge_title":"All possible options to import exising Azure ML models to newly created Azure ML environment!",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":100,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=9dd3fdca-62ad-43a4-9e40-b142520a64a4\">@Preetha Rajesh  <\/a> I believe the models are trained in another workspace or subscription that are used by your company which you would need to use in your workspace or environment.    <\/p>\n<p>The common scenario is to register the models in your workspace by providing a valid path or through studio\/cli\/SDK. This <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-models?tabs=use-local%2Ccli\">document<\/a> should help you setup the same.    <br \/>\nThe newer or a <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-share-models-pipelines-across-workspaces-with-registries?tabs=cli\">preview version<\/a> of sharing the models across workspaces is available to use, you can try the same and check if this works for your organization.    <\/p>\n<p>Once the models are registered in your workspace, the usage of the same in an environment is pretty much the same as using the models you have trained in your workspace. Initially, you might want to use the UI but the SDK and CLI can also be used for automating if you have large number of models from your vendors.     <\/p>\n<p>The documents referenced contains all possible ways to achieve this, I hope this helps!!    <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":4.0,
        "Solution_readability":12.0,
        "Solution_reading_time":21.14,
        "Solution_score_count":1.0,
        "Solution_sentence_count":12.0,
        "Solution_word_count":195.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1446841002932,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Trondheim, Norway",
        "Answerer_reputation_count":226.0,
        "Answerer_view_count":60.0,
        "Challenge_adjusted_solved_time":0.2383613889,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have created an Azure ML Web service which outputs JSON response on request, and the structure of the sample request is as following:<\/p>\n\n<pre><code>{\n  \"Inputs\": {\n    \"input1\": {\n      \"ColumnNames\": [\n        \"gender\",\n        \"age\",\n        \"income\"\n      ],\n      \"Values\": [\n        [\n          \"value\",\n          \"0\",\n          \"0\"\n        ],\n        [\n          \"value\",\n          \"0\",\n          \"0\"\n        ]\n      ]\n    }\n  },\n  \"GlobalParameters\": {}\n}\n<\/code><\/pre>\n\n<p>And the input parameters are supposedly like this:<\/p>\n\n<p>gender  String<br>\nage Numeric<br>\nincome  Numeric     <\/p>\n\n<p>My Post method looks like this:<\/p>\n\n<pre><code>    [HttpPost]\n        public ActionResult GetPredictionFromWebService()\n        {\n            var gender = Request.Form[\"gender\"];\n            var age = Request.Form[\"age\"];\n\n\n            if (!string.IsNullOrEmpty(gender) &amp;&amp; !string.IsNullOrEmpty(age))\n            {\n                var resultResponse = _incomeWebService.InvokeRequestResponseService&lt;ResultOutcome&gt;(gender, age).Result;\n\n\n                if (resultResponse != null)\n                {\n                    var result = resultResponse.Results.Output1.Value.Values;\n                    PersonResult = new Person\n                    {\n                        Gender = result[0, 0],\n                        Age = Int32.Parse(result[0, 1]),\n                        Income = Int32.Parse(result[0, 2])\n                    };\n                }\n            }\n\n\n\n\n            return RedirectToAction(\"index\");\n        }\n<\/code><\/pre>\n\n<p>But for whatever reason; the Azure ML Webservice doesn\u2019t seem to respond anything to my request.\nDoes anyone know what the reason might be? I see no error or anything, just an empty response.<\/p>",
        "Challenge_closed_time":1456314151448,
        "Challenge_comment_count":0,
        "Challenge_created_time":1456313293347,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1456839908307,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/35600907",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":13.1,
        "Challenge_reading_time":16.85,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":11,
        "Challenge_solved_time":0.2383613889,
        "Challenge_title":"Azure ML Web Service request not working in C#",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":480.0,
        "Challenge_word_count":143,
        "Platform":"Stack Overflow",
        "Poster_created_time":1456309738852,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":39.0,
        "Poster_view_count":6.0,
        "Solution_body":"<p>The answer to your problem is that the \u201cNumeric\u201d datatype which is written in the input parameters in Azure ML is in fact a float and not an integer for your income measure. So when trying to request a response from Azure ML, you are not providing it the \u201cadequate\u201d information needed in the right format for it to respond correctly, resulting in it not giving you any response.<\/p>\n\n<p>I believe your model would look something similar to this based on your input parameters:<\/p>\n\n<pre><code>public class Person\n    {\n        public string Gender { get; set; }\n        public int Age { get; set; }\n        public int Income { get; set; }\n\n\n        public override string ToString()\n        {\n            return Gender + \",\" + Age + \",\" + Income;\n        }\n    }\n<\/code><\/pre>\n\n<p>You would have to change your Income datatype into float like so:<\/p>\n\n<pre><code>public class Person\n{\n    public string Gender { get; set; }\n    public int Age { get; set; }\n    public float Income { get; set; }\n\n    public override string ToString()\n    {\n        return Gender + \",\" + Age + \",\" + Income;\n    }\n}\n<\/code><\/pre>\n\n<p>And then your post-method would look something like this:<\/p>\n\n<pre><code>    [HttpPost]\n    public ActionResult GetPredictionFromWebService()\n    {\n        var gender = Request.Form[\"gender\"];\n        var age = Request.Form[\"age\"];\n\n        if (!string.IsNullOrEmpty(gender) &amp;&amp; !string.IsNullOrEmpty(age))\n        {\n            var resultResponse = _incomeWebService.InvokeRequestResponseService&lt;ResultOutcome&gt;(gender, age).Result;\n\n                if (resultResponse != null)\n                {\n                    var result = resultResponse.Results.Output1.Value.Values;\n                    PersonResult = new Person\n                    {\n                        Gender = result[0, 0],\n                        Age = Int32.Parse(result[0, 1]),\n                        Income = float.Parse(result[0, 3], CultureInfo.InvariantCulture.NumberFormat)\n                };\n            }\n        }\n\n        ViewBag.myData = PersonResult.Income.ToString();\n        return View(\"Index\");\n    }\n<\/code><\/pre>\n\n<p>The key here is simply:<\/p>\n\n<pre><code>Income = float.Parse(result[0, 3], CultureInfo.InvariantCulture.NumberFormat)\n<\/code><\/pre>\n\n<p>Rather than your legacy <\/p>\n\n<pre><code>Income = Int32.Parse(result[0, 2])\n<\/code><\/pre>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":13.0,
        "Solution_reading_time":24.94,
        "Solution_score_count":2.0,
        "Solution_sentence_count":14.0,
        "Solution_word_count":221.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1495175179307,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Warsaw, Poland",
        "Answerer_reputation_count":46.0,
        "Answerer_view_count":3.0,
        "Challenge_adjusted_solved_time":14.4048166667,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Recently I started using Neptune (via <a href=\"https:\/\/go.neptune.deepsense.io\/\" rel=\"nofollow noreferrer\">Neptune Go<\/a>) and want to have a well-organised history of experiments. How to set tags to a given experiment? (Do I do it before running it, or after?)<\/p>",
        "Challenge_closed_time":1495176106327,
        "Challenge_comment_count":0,
        "Challenge_created_time":1495124248987,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/44053028",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":7.7,
        "Challenge_reading_time":3.78,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":14.4048166667,
        "Challenge_title":"Setting job tags for Neptune",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":57.0,
        "Challenge_word_count":41,
        "Platform":"Stack Overflow",
        "Poster_created_time":1314097464768,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Warsaw, Poland",
        "Poster_reputation_count":11056.0,
        "Poster_view_count":544.0,
        "Solution_body":"<p>There are four ways to set tags to your experiment:<\/p>\n\n<ol>\n<li>In the <code>run\/enqueue\/exec<\/code> command, i.e:<\/li>\n<\/ol>\n\n<p><code>neptune run --tags tag1 tag2 tag3 tag4<\/code><\/p>\n\n<ol start=\"2\">\n<li>In the configuration file:<\/li>\n<\/ol>\n\n<p><code>tags: [tag1, tag2, tag3, tag4]<\/code><\/p>\n\n<ol start=\"3\">\n<li>In your code:<\/li>\n<\/ol>\n\n<p><code>ctx.job.tags.append('new-tag')<\/code><\/p>\n\n<ol start=\"4\">\n<li>In the Web UI. In the experiment dashboard you have to click on \"Job Properties\" in the top left corner of the screen. Side panel will appear where you can modify job properties.<\/li>\n<\/ol>\n\n<p>So you can change tags of your experiment in every phase of your experiment execution.<\/p>\n\n<p>Sources: <\/p>\n\n<ul>\n<li><p><a href=\"http:\/\/neptune.deepsense.io\/versions\/latest\/reference-guides\/cli.html#tags\" rel=\"nofollow noreferrer\">http:\/\/neptune.deepsense.io\/versions\/latest\/reference-guides\/cli.html#tags<\/a><\/p><\/li>\n<li><p><a href=\"http:\/\/neptune.deepsense.io\/versions\/latest\/reference-guides\/job-and-experiment.html#tags\" rel=\"nofollow noreferrer\">http:\/\/neptune.deepsense.io\/versions\/latest\/reference-guides\/job-and-experiment.html#tags<\/a> <\/p><\/li>\n<\/ul>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":4.0,
        "Solution_readability":14.2,
        "Solution_reading_time":15.56,
        "Solution_score_count":3.0,
        "Solution_sentence_count":11.0,
        "Solution_word_count":107.0,
        "Tool":"Neptune"
    },
    {
        "Answerer_created_time":1416346350292,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Jesi, Italy",
        "Answerer_reputation_count":2302.0,
        "Answerer_view_count":227.0,
        "Challenge_adjusted_solved_time":7.1241191666,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>similar question to\n<a href=\"https:\/\/stackoverflow.com\/a\/66683538\/6896705\">AWS Lambda send image file to Amazon Sagemaker<\/a><\/p>\n<p>I try to make simple-mnist work (the model was built by referring to <a href=\"https:\/\/sagemaker-immersionday.workshop.aws\/en\/lab3\/option1.html\" rel=\"nofollow noreferrer\">aws tutorial<\/a>)<\/p>\n<p>Then I am using API gateway (REST API w\/ proxy integration) to post image data to lambda, and would like to send it to sagemaker endpoint and make an inference.<\/p>\n<p>In lambda function, I wrote the code(.py) like this.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>runtime = boto3.Session().client('sagemaker-runtime')\n\nendpoint_name = 'tensorflow-training-YYYY-mm-dd-...'\nres = runtime.invoke_endpoint(EndpointName=endpoint_name,\n                              Body=Image,\n                              ContentType='image\/jpeg',\n                              Accept='image\/jpeg')\n<\/code><\/pre>\n<p>However, when I send image to lambda via API gateway, this error occurs.<\/p>\n<blockquote>\n<p>[ERROR] ModelError: An error occurred (ModelError) when calling the\nInvokeEndpoint operation: Received client error (415) from model with\nmessage &quot; {\n&quot;error&quot;: &quot;Unsupported Media Type: image\/jpeg&quot; }<\/p>\n<\/blockquote>\n<p>I think I need to do something referring to <a href=\"https:\/\/docs.aws.amazon.com\/apigateway\/latest\/developerguide\/api-gateway-payload-encodings.html\" rel=\"nofollow noreferrer\">Working with binary media types for REST APIs\n<\/a><\/p>\n<p>But since I am very new, I have no idea about the appropriate thing to do, on which page (maybe API Gateway page?) or how...<\/p>\n<p>I need some clues to solve this problem. Thank you in advance.<\/p>",
        "Challenge_closed_time":1626967022752,
        "Challenge_comment_count":0,
        "Challenge_created_time":1626929018517,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1626941375923,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/68479297",
        "Challenge_link_count":3,
        "Challenge_participation_count":1,
        "Challenge_readability":12.6,
        "Challenge_reading_time":21.89,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":13,
        "Challenge_solved_time":10.5567319444,
        "Challenge_title":"AWS send image to Sagemaker from Lambda: how to set content handling?",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":390.0,
        "Challenge_word_count":191,
        "Platform":"Stack Overflow",
        "Poster_created_time":1475109151950,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":43.0,
        "Poster_view_count":18.0,
        "Solution_body":"<p>Looking <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/adapt-inference-container.html\" rel=\"nofollow noreferrer\">here<\/a> you can see that only some specific content types are supported by default, and images are not in this list. I think you have to either implement your <code>input_fn<\/code> function or adapt your data to one of the supported content types.<\/p>",
        "Solution_comment_count":2.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":12.8,
        "Solution_reading_time":4.89,
        "Solution_score_count":0.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":46.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":11.1486111111,
        "Challenge_answer_count":1,
        "Challenge_body":"Hi,  \n  \nI am new to SageMaker and I am trying to deploy my model to an endpoint but am getting the following error:  \n  \n**Failure reason**  \nUnable to locate at least 2 availability zone(s) with the requested instance type ml.t2.medium that overlap with SageMaker subnets  \n  \nI have tried using different instance types but always the same error  \n  \nI was under the impression that SageMaker will create the required instances for me and I do not need to create the instances first? I am using the EU-WEST-1 zone and using the console to setup the endpoint",
        "Challenge_closed_time":1553556696000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1553516561000,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1668612166704,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUySs_fgNpSE6wuY-6W7MwqQ\/unable-to-create-endpoint",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":11.6,
        "Challenge_reading_time":6.87,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":11.1486111111,
        "Challenge_title":"Unable to create endpoint",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":657.0,
        "Challenge_word_count":97,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"Hello,  \n  \nSagemaker engineer here. I looked at the VpcConfig of your model and found only one subnet configured.   \n  \nThe error message \"Unable to locate at least 2 availability zone(s) with the requested instance type XYZ that overlap with SageMaker subnets\" usually indicates misconfigured VPCs. Sagemaker imposes mandatory requirement for at least 2 availability zones in your VPC subnets even if you only request one instance, to account for the potential use of auto-scaling in the future.   \n  \nIn order to create the endpoint, the number of subnets in your model needs to be at least 2 in distinct availability zones, and ideally as close to the total number of availability zones as possible in the region.   \n  \nHope it helps,   \nWenzhao",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1553556696000,
        "Solution_link_count":0.0,
        "Solution_readability":11.0,
        "Solution_reading_time":8.89,
        "Solution_score_count":0.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":119.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":16.75,
        "Challenge_answer_count":3,
        "Challenge_body":"Does anyone know which locations can be used to set the variable \"location\" in the following code snippet from a .js program designed to use Google Cloud Translation (Advanced) to translate asynchronously a .docx file stored in the subdirectory of a bucket into another supported language?\n\n\u00a0\n\n\/\/ Set your project ID, location and bucket name here\nconst projectId = ....\nconst location = ....\nconst bucketName\u00a0 = ....\n\nMy VM instance is located in \"europe-north1-a\", but is it possible to also use this as a valid region\/zone to set the \"const location\" variable to? I don't\u00a0 see anything about this in the documentation.",
        "Challenge_closed_time":1681397820000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1681337520000,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/location-variable-setting-for-the-Google-Cloud-Translation-API\/td-p\/543332\/jump-to\/first-unread-message",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":9.1,
        "Challenge_reading_time":8.48,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":16.75,
        "Challenge_title":"location variable setting for the Google Cloud Translation API (Advanced)",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":74.0,
        "Challenge_word_count":105,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"Hi\u00a0@legrandtimonier,\u00a0\n\nWelcome back to Google Cloud Support,\n\nThe area \"europe-north1-a\" is a valid location, You may able to generate resources like buckets and VM instances there, you may use it as the location value for the location variable in the code snippet you gave.\n\nThe location parameter of the Google Cloud Translation API indicates the region in which the Translation API service is hosted. The following locations are listed as being accessible for the API service in the official documentation:\n\nasia-east1\neurope-west2\nus-central1\n\nTo reduce latency and increase speed while using services, You may pick the area that is either closest to your users or where your resources are located.\n\nHere are some references that might help you:\nhttps:\/\/cloud.google.com\/compute\/docs\/regions-zones?_ga=2.183424358.-1392753435.1676655686\n\nhttps:\/\/cloud.google.com\/translate\n\nView solution in original post",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":14.3,
        "Solution_reading_time":11.37,
        "Solution_score_count":1.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":126.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_created_time":1285219808283,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Perth WA, Australia",
        "Answerer_reputation_count":6770.0,
        "Answerer_view_count":1127.0,
        "Challenge_adjusted_solved_time":0.0213536111,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I'm currently trying to integrate an ML model currently deployed as a webservice on AzureML with PowerBI.<\/p>\n<p>I see that it can be <a href=\"https:\/\/docs.microsoft.com\/en-us\/power-bi\/transform-model\/service-machine-learning-integration#invoking-the-azure-ml-model-in-power-bi\" rel=\"nofollow noreferrer\">integrated<\/a> but the model requires the addition of a schema file when it is <a href=\"https:\/\/docs.microsoft.com\/en-us\/power-bi\/transform-model\/service-machine-learning-integration#schema-discovery-for-machine-learning-models\" rel=\"nofollow noreferrer\">being deployed as a webservice<\/a>. Without this, the model can't be viewed in PowerBI.<\/p>\n<p>The problem that I have come up against is that I use MLflow to log ML model performances and subsequently to deploy a selected model onto AzureML as a webservice using MLflow's AzureML integration - mlflow.azureml.deploy(). This unfortunately doesn't have the option to define a schema file before the model is deployed, thus resulting in no model being available in PowerBI as it lacks the required schema file.<\/p>\n<p>My options seem to be:<\/p>\n<ol>\n<li>Find a workaround, possibly using the working <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/databricks\/applications\/mlflow\/model-serving\" rel=\"nofollow noreferrer\">REST api of the model in a power query<\/a>.<\/li>\n<li>Rewrite the deployment code and handle the webservice deployment steps in Azure instead of MLflow.<\/li>\n<\/ol>\n<p>I thought I would ask to see if I am maybe missing something as I can't find a workaround using my current code to define a schema file in MLflow when deploying with mlflow.azureml.deploy().<\/p>",
        "Challenge_closed_time":1600604920243,
        "Challenge_comment_count":0,
        "Challenge_created_time":1600261190477,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1600855880503,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/63920599",
        "Challenge_link_count":3,
        "Challenge_participation_count":1,
        "Challenge_readability":12.3,
        "Challenge_reading_time":21.83,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":12,
        "Challenge_solved_time":95.4804905556,
        "Challenge_title":"PowerBI and MLflow integration (through AzureML)",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":405.0,
        "Challenge_word_count":204,
        "Platform":"Stack Overflow",
        "Poster_created_time":1600260166047,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":15.0,
        "Poster_view_count":4.0,
        "Solution_body":"<p>Point number 2 is the way we solved this issue. Instead of using MLflow to deploy to a scoring service on Azure, we wrote a custom code which load MLflow model when container is initialised.<\/p>\n<p>Scoring code is something like this:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import os\nimport json\nfrom mlflow.pyfunc import load_model\n\nfrom inference_schema.schema_decorators import input_schema, output_schema\nfrom inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n\ndef init():\n    global model\n    model = load_model(os.path.join(os.environ.get(&quot;AZUREML_MODEL_DIR&quot;), &quot;awesome_model&quot;))\n\n@input_schema('data', NumpyParameterType(input_sample))\n@output_schema(NumpyParameterType(output_sample))\n\ndef run(data):\n    return model.predict(data)\n<\/code><\/pre>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":1600855957376,
        "Solution_link_count":0.0,
        "Solution_readability":16.9,
        "Solution_reading_time":10.68,
        "Solution_score_count":0.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":75.0,
        "Tool":"MLflow"
    },
    {
        "Answerer_created_time":1554186784008,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Hyderabad, Telangana, India",
        "Answerer_reputation_count":2175.0,
        "Answerer_view_count":434.0,
        "Challenge_adjusted_solved_time":136.3803758333,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have created an experiment in Machine Learning Studio and deployed it as a web service. I've got a request-response API in my workspace that works. Can it be also used by other people?<\/p>",
        "Challenge_closed_time":1597984478140,
        "Challenge_comment_count":1,
        "Challenge_created_time":1597493508787,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/63425902",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":6.0,
        "Challenge_reading_time":3.03,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":136.3803758333,
        "Challenge_title":"Are Machine Learning Studios's web services public?",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":39.0,
        "Challenge_word_count":40,
        "Platform":"Stack Overflow",
        "Poster_created_time":1575044869560,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":21.0,
        "Poster_view_count":7.0,
        "Solution_body":"<p>When you deploy a model, a Webservice object is returned with information about the service.<\/p>\n<pre><code>from azureml.core.webservice import AciWebservice, Webservice\nfrom azureml.core.model import Model\n\ndeployment_config = AciWebservice.deploy_configuration(cpu_cores = 3, memory_gb = 15, location = &quot;centralus&quot;)\nservice = Model.deploy(ws, &quot;aciservice&quot;, [model], inference_config, deployment_config)\nservice.wait_for_deployment(show_output = True)\nprint(service.state)\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/AvVgY.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/AvVgY.png\" alt=\"enter image description here\" \/><\/a>\nPlease follow the below to Consume an Azure Machine Learning model deployed as a web service\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service<\/a><\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":4.0,
        "Solution_readability":20.0,
        "Solution_reading_time":13.22,
        "Solution_score_count":0.0,
        "Solution_sentence_count":11.0,
        "Solution_word_count":71.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":0.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":17.3883747222,
        "Challenge_answer_count":1,
        "Challenge_body":"Does Data Capture feature used for model monitor and analytics work with the multi model endpoint (one container).. we ran into an error.  See error \" An error occurred (ValidationException) when calling the CreateEndPointConfig operation: Data Capture Feature is not supported with MultiModel mode\"\nTheoretically, it should work because it is calling the DataCaptureConfig:\n\nfrom sagemaker.model_monitor import DataCaptureConfig\n\nendpoint_name = 'your-pred-model-monitor-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\nprint(\"EndpointName={}\".format(endpoint_name))\n\ndata_capture_config=DataCaptureConfig(\n                        enable_capture = True,\n                        sampling_percentage=100,\n                        destination_s3_uri=s3_capture_upload_path)",
        "Challenge_closed_time":1649857157628,
        "Challenge_comment_count":0,
        "Challenge_created_time":1649794559479,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1668514048207,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUlAvpGSsISyqu0MyebgRJDA\/sagemaker-multi-model-endpoint-and-inference-data-capture-feature",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":20.0,
        "Challenge_reading_time":9.95,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":17.3883747222,
        "Challenge_title":"SageMaker Multi Model EndPoint and Inference Data Capture feature",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":403.0,
        "Challenge_word_count":75,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"SageMaker multi-model endpoints do not have support for SageMaker Model monitor as of writing this answer. So the error is pointing to exactly that. \n\nHowever, if you are looking to implement data drift using sagemaker model monitor then you can do that my mimicking data capture config functionality by capturing inference input and prediction output and storing it in the format supported by Model Monitor. And then setup a customer monitoring container using the instructions listed [https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/model-monitor-byoc-containers.html]()",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":1649857157628,
        "Solution_link_count":1.0,
        "Solution_readability":16.7,
        "Solution_reading_time":7.26,
        "Solution_score_count":0.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":77.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":0.1111111111,
        "Challenge_answer_count":1,
        "Challenge_body":"Does SageMaker Multi-Model Endpoint support SageMaker Model Monitor?",
        "Challenge_closed_time":1590501508000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1590501108000,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1668554201782,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUq2z-BEt7TnmZ8vFYs-Hu7g\/does-sagemaker-multi-model-endpoint-support-sagemaker-model-monitor",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":19.2,
        "Challenge_reading_time":1.81,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":2,
        "Challenge_solved_time":0.1111111111,
        "Challenge_title":"Does SageMaker Multi-Model Endpoint support SageMaker Model Monitor?",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":237.0,
        "Challenge_word_count":15,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":1.0,
        "Poster_isModerator":0.0,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"Amazon SageMaker Model Monitor currently supports only endpoints that host a single model and does not support monitoring multi-model endpoints. For information on using multi-model endpoints, see Host Multiple Models with Multi-Model Endpoints .  https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/model-monitor.html",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1667925566336,
        "Solution_link_count":1.0,
        "Solution_readability":20.5,
        "Solution_reading_time":4.1,
        "Solution_score_count":0.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":34.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1641848506127,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Mumbai, India",
        "Answerer_reputation_count":2252.0,
        "Answerer_view_count":131.0,
        "Challenge_adjusted_solved_time":1.7314472222,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I'm currently developing some ETL for my ML model with AWS. The thing is that I want to <strong>trigger<\/strong> a Lambda when some Sagemaker Processing Job is finished. And the <strong>event<\/strong> passed to the Lambda, should be the configuration info (job name, arguments, etc..) of the Sagemaker Processing Job.<\/p>\n<p><strong>Q1<\/strong>: How can I do to <em>trigger the event<\/em> when the Processing Job is finished?<\/p>\n<p><strong>Q2<\/strong>: How can I do to pass the <em>Processing Job configurations as an event<\/em> for the Lambda?<\/p>",
        "Challenge_closed_time":1643913781760,
        "Challenge_comment_count":0,
        "Challenge_created_time":1643907548550,
        "Challenge_favorite_count":1.0,
        "Challenge_last_edit_time":1643931586140,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/70975320",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":8.1,
        "Challenge_reading_time":7.67,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":3.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":1.7314472222,
        "Challenge_title":"EventBridge trigger: Sagemaker Processing Job finished",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":504.0,
        "Challenge_word_count":86,
        "Platform":"Stack Overflow",
        "Poster_created_time":1519511545083,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":43.0,
        "Poster_view_count":2.0,
        "Solution_body":"<p>You can use the following EventBridge rule pattern:<\/p>\n<pre class=\"lang-json prettyprint-override\"><code>{\n  &quot;source&quot;: [&quot;aws.sagemaker&quot;],\n  &quot;detail-type&quot;: [&quot;SageMaker Processing Job State Change&quot;],\n  &quot;detail&quot;: {\n    &quot;ProcessingJobStatus&quot;: [&quot;Failed&quot;, &quot;Completed&quot;, &quot;Stopped&quot;]\n  }\n}\n<\/code><\/pre>\n<p>The ProcessingJobStatus list can be modified based on which statuses you want to handle.<\/p>\n<p>You can set a Lambda function as the target of your EventBridge rule.<\/p>\n<p>Here is a sample event which will be passed to your Lambda, taken from AWS console:<\/p>\n<pre class=\"lang-json prettyprint-override\"><code>{\n  &quot;version&quot;: &quot;0&quot;,\n  &quot;id&quot;: &quot;0a15f67d-aa23-0123-0123-01a23w89r01t&quot;,\n  &quot;detail-type&quot;: &quot;SageMaker Processing Job State Change&quot;,\n  &quot;source&quot;: &quot;aws.sagemaker&quot;,\n  &quot;account&quot;: &quot;123456789012&quot;,\n  &quot;time&quot;: &quot;2019-05-31T21:49:54Z&quot;,\n  &quot;region&quot;: &quot;us-east-1&quot;,\n  &quot;resources&quot;: [&quot;arn:aws:sagemaker:us-west-2:012345678987:processing-job\/integ-test-analytics-algo-54ee3282-5899-4aa3-afc2-7ce1d02&quot;],\n  &quot;detail&quot;: {\n    &quot;ProcessingInputs&quot;: [{\n      &quot;InputName&quot;: &quot;InputName&quot;,\n      &quot;S3Input&quot;: {\n        &quot;S3Uri&quot;: &quot;s3:\/\/input\/s3\/uri&quot;,\n        &quot;LocalPath&quot;: &quot;\/opt\/ml\/processing\/input\/local\/path&quot;,\n        &quot;S3DataType&quot;: &quot;MANIFEST_FILE&quot;,\n        &quot;S3InputMode&quot;: &quot;PIPE&quot;,\n        &quot;S3DataDistributionType&quot;: &quot;FULLYREPLICATED&quot;\n      }\n    }],\n    &quot;ProcessingOutputConfig&quot;: {\n      &quot;Outputs&quot;: [{\n        &quot;OutputName&quot;: &quot;OutputName&quot;,\n        &quot;S3Output&quot;: {\n          &quot;S3Uri&quot;: &quot;s3:\/\/output\/s3\/uri&quot;,\n          &quot;LocalPath&quot;: &quot;\/opt\/ml\/processing\/output\/local\/path&quot;,\n          &quot;S3UploadMode&quot;: &quot;CONTINUOUS&quot;\n        }\n      }],\n      &quot;KmsKeyId&quot;: &quot;KmsKeyId&quot;\n    },\n    &quot;ProcessingJobName&quot;: &quot;integ-test-analytics-algo-54ee3282-5899-4aa3-afc2-7ce1d02&quot;,\n    &quot;ProcessingResources&quot;: {\n      &quot;ClusterConfig&quot;: {\n        &quot;InstanceCount&quot;: 3,\n        &quot;InstanceType&quot;: &quot;ml.c5.xlarge&quot;,\n        &quot;VolumeSizeInGB&quot;: 5,\n        &quot;VolumeKmsKeyId&quot;: &quot;VolumeKmsKeyId&quot;\n      }\n    },\n    &quot;StoppingCondition&quot;: {\n      &quot;MaxRuntimeInSeconds&quot;: 2000\n    },\n    &quot;AppSpecification&quot;: {\n      &quot;ImageUri&quot;: &quot;012345678901.dkr.ecr.us-west-2.amazonaws.com\/processing-uri:latest&quot;\n    },\n    &quot;NetworkConfig&quot;: {\n      &quot;EnableInterContainerTrafficEncryption&quot;: true,\n      &quot;EnableNetworkIsolation&quot;: false,\n      &quot;VpcConfig&quot;: {\n        &quot;SecurityGroupIds&quot;: [&quot;SecurityGroupId1&quot;, &quot;SecurityGroupId2&quot;, &quot;SecurityGroupId3&quot;],\n        &quot;Subnets&quot;: [&quot;Subnet1&quot;, &quot;Subnet2&quot;]\n      }\n    },\n    &quot;RoleArn&quot;: &quot;arn:aws:iam::012345678987:role\/SageMakerPowerUser&quot;,\n    &quot;ExperimentConfig&quot;: {},\n    &quot;ProcessingJobArn&quot;: &quot;arn:aws:sagemaker:us-west-2:012345678987:processing-job\/integ-test-analytics-algo-54ee3282-5899-4aa3-afc2-7ce1d02&quot;,\n    &quot;ProcessingJobStatus&quot;: &quot;Completed&quot;,\n    &quot;LastModifiedTime&quot;: 1589879735000,\n    &quot;CreationTime&quot;: 1589879735000\n  }\n}\n<\/code><\/pre>\n<p><strong>Edit:<\/strong><\/p>\n<p>If you want to match a ProcessingJobName with specific prefix:<\/p>\n<pre class=\"lang-json prettyprint-override\"><code>{\n  &quot;source&quot;: [&quot;aws.sagemaker&quot;],\n  &quot;detail-type&quot;: [&quot;SageMaker Processing Job State Change&quot;],\n  &quot;detail&quot;: {\n    &quot;ProcessingJobStatus&quot;: [&quot;Failed&quot;, &quot;Completed&quot;, &quot;Stopped&quot;],\n    &quot;ProcessingJobName&quot;: [{\n      &quot;prefix&quot;: &quot;standarize-data&quot;\n    }]\n  }\n}\n<\/code><\/pre>",
        "Solution_comment_count":5.0,
        "Solution_last_edit_time":1643920466910,
        "Solution_link_count":0.0,
        "Solution_readability":31.6,
        "Solution_reading_time":52.65,
        "Solution_score_count":3.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":193.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1488711530187,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":29.0,
        "Answerer_view_count":12.0,
        "Challenge_adjusted_solved_time":21.4251527778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am using a Classic Web Service with a non-default endpoint for a Update Resource activity on the Azure Data Factory. This is the error I get:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/shK0R.png\" rel=\"nofollow noreferrer\">Screenshot of Error<\/a><\/p>\n\n<p>I didn't find any info on the web and couldn't figure it out myself. <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/data-factory\/data-factory-azure-ml-update-resource-activity\" rel=\"nofollow noreferrer\">This<\/a> website shows an example that I used by just filling in my values for mlEndpoint, apiKey and updateRessourceEndpoint:<\/p>\n\n<pre><code>{\n    \"name\": \"updatableScoringEndpoint2\",\n    \"properties\": {\n        \"type\": \"AzureML\",\n        \"typeProperties\": {\n            \"mlEndpoint\": \"https:\/\/ussouthcentral.services.azureml.net\/workspaces\/xxx\/services\/--scoring experiment--\/jobs\",\n            \"apiKey\": \"endpoint2Key\",\n            \"updateResourceEndpoint\": \"https:\/\/management.azureml.net\/workspaces\/xxx\/webservices\/--scoring experiment--\/endpoints\/endpoint2\"\n        }\n    }\n}\n<\/code><\/pre>\n\n<p>There is no mention of a token that needs to be passed...<\/p>",
        "Challenge_closed_time":1503393687923,
        "Challenge_comment_count":0,
        "Challenge_created_time":1503316557373,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/45796489",
        "Challenge_link_count":4,
        "Challenge_participation_count":1,
        "Challenge_readability":14.9,
        "Challenge_reading_time":14.48,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":21.4251527778,
        "Challenge_title":"Azure Machine Learning: What error is this?",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":253.0,
        "Challenge_word_count":103,
        "Platform":"Stack Overflow",
        "Poster_created_time":1476806455803,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Holzkirchen, Deutschland",
        "Poster_reputation_count":3068.0,
        "Poster_view_count":386.0,
        "Solution_body":"<p>this error is basically saying the apiKey you provided is invalid to perform the update resource operation. Here is some posts for your reference: <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/azure\/en-US\/3bb77e37-8860-43c6-bcaa-d6ebd70617b8\/retrain-predictive-web-service-programmatically-when-do-not-have-access-to-managementazuremlnet?forum=MachineLearning\" rel=\"nofollow noreferrer\">https:\/\/social.msdn.microsoft.com\/Forums\/azure\/en-US\/3bb77e37-8860-43c6-bcaa-d6ebd70617b8\/retrain-predictive-web-service-programmatically-when-do-not-have-access-to-managementazuremlnet?forum=MachineLearning<\/a><\/p>\n\n<p>Please also be noted that if you modified your linked service in ADF, remember to re-deploy the pipeline as well to reflect your change in time.<\/p>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":25.1,
        "Solution_reading_time":10.4,
        "Solution_score_count":0.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":54.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1460437080990,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":386.0,
        "Answerer_view_count":42.0,
        "Challenge_adjusted_solved_time":4.9508216667,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have an AzureML free account in South Central US. At some point I set up a web service, which I no longer need. I also suspect it's blocking my other web services as I'm getting 503 errors whenever I try to use them.<\/p>\n\n<p>When I try to delete the web service it gives the error message:\n<code>Cannot delete web service \"azuremlweb\" because one or more additional endpoints were created for it. These endpoints must be deleted before you can delete the web service.<\/code><\/p>\n\n<p>I didn't intentionally set up any extra endpoints and when trying to follow the instructions <a href=\"https:\/\/azure.microsoft.com\/en-gb\/documentation\/articles\/machine-learning-manage-workspace\/\" rel=\"nofollow noreferrer\">on this doc page<\/a> I couldn't see any endpoints listed that I can remove.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/n5Kg2.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/n5Kg2.jpg\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>The only unusual thing I can think of about the service was that it had multiple inputs.<\/p>\n\n<p>I've more or less deleted everything in the workspace now: experiments, other web services, but it still won't go. Any thoughts?<\/p>",
        "Challenge_closed_time":1463407717728,
        "Challenge_comment_count":0,
        "Challenge_created_time":1463389894770,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/37250368",
        "Challenge_link_count":3,
        "Challenge_participation_count":1,
        "Challenge_readability":8.9,
        "Challenge_reading_time":15.75,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":12,
        "Challenge_solved_time":4.9508216667,
        "Challenge_title":"How to delete web service in AzureML with mystery endpoint",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":1550.0,
        "Challenge_word_count":172,
        "Platform":"Stack Overflow",
        "Poster_created_time":1374576589267,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"UK",
        "Poster_reputation_count":635.0,
        "Poster_view_count":48.0,
        "Solution_body":"<p>You can try to use Azure ML PowerShell module to discover and delete web service endpoints, and web service.<\/p>\n\n<p><a href=\"http:\/\/aka.ms\/amlps\" rel=\"nofollow\">http:\/\/aka.ms\/amlps<\/a><\/p>",
        "Solution_comment_count":2.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":8.8,
        "Solution_reading_time":2.5,
        "Solution_score_count":3.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":22.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":157.0440930556,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi there, I'm trying to register a ML model to the mlflow model registry to be served from an Azure web app. I'm wondering if the databricks networking configuration will apply to the model api endpoint, as in, calls to the api from outside the VNET which the databricks is deployed to with private endpoints and disabled public access will be rejected and the call from within the vnet integrated web app will be successful?    <\/p>\n<p>Thank you!<\/p>",
        "Challenge_closed_time":1663046075632,
        "Challenge_comment_count":4,
        "Challenge_created_time":1662480716897,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/996163\/databricks-mlflow-model-serving-networking",
        "Challenge_link_count":0,
        "Challenge_participation_count":5,
        "Challenge_readability":10.1,
        "Challenge_reading_time":6.07,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":157.0440930556,
        "Challenge_title":"Databricks mlflow model serving networking",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":82,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=72c1697f-78db-46b7-813e-f61c7171cb88\">@Chammie Ho  <\/a>,    <\/p>\n<p>Thanks for the question and using MS Q&amp;A platform.    <\/p>\n<blockquote>\n<p>I'm wondering if the databricks networking configuration will apply to the model api endpoint    <\/p>\n<\/blockquote>\n<p>Yes, it will. The single node cluster on which the model is hosted (classic), is deployed in data plane and will have a private IP.     <\/p>\n<blockquote>\n<p>I should be able to call the model with the url &lt;databricks-instance&gt;\/model\/&lt;registered-model-name&gt;\/&lt;model-version&gt;\/invocations, my question is whether this url will have the same restrictions as the databricks where it resides    <\/p>\n<\/blockquote>\n<p>I believe, this should work as long as you have not defined any IP access list. The PAT will let you authenticate.    <\/p>\n<blockquote>\n<p>but I can't find information for IP restrictions    <\/p>\n<\/blockquote>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/databricks\/security\/network\/ip-access-list\">IP access lists - Azure Databricks | Microsoft Learn<\/a>    <\/p>\n<p>Hope this will help. Please let us know if any further queries.    <\/p>\n<p>------------------------------    <\/p>\n<ul>\n<li> Please don't forget to click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.pngsfe?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.pngjust?platform=QnA\" alt=\"130671-image.png\" \/> button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/25904\/accepted-answers.html\">how<\/a>    <\/li>\n<li> Want a reminder to come back and check responses? Here is how to subscribe to a <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/67444\/email-notifications.htmlstr\">notification<\/a>    <\/li>\n<li> If you are interested in joining the VM program and help shape the future of Q&amp;A: Here is jhow you can be part of <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/support\/community-champions-program\">Q&amp;A Volunteer Moderators<\/a>    <\/li>\n<\/ul>\n",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":6.0,
        "Solution_readability":12.1,
        "Solution_reading_time":28.75,
        "Solution_score_count":1.0,
        "Solution_sentence_count":18.0,
        "Solution_word_count":241.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":6.4686769445,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hello team, I see there is a custom component module in Designer. I am curious about it. Does it mean I can customize my own component? Any reference I can read?<\/p>\n<p>Can you let me know what is custom component and how to define it? <\/p>\n<p>It\u2019s known that designer has very less flexibility so we are always considering SDK. How could it help? <\/p>\n<p>Meanwhile I am very surprised by the new release, anywhere we should look for those releasing news? <\/p>",
        "Challenge_closed_time":1677573962083,
        "Challenge_comment_count":0,
        "Challenge_created_time":1677550674846,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1184883\/how-should-i-customize-my-own-component-and-how-sh",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":5.1,
        "Challenge_reading_time":6.38,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":6.4686769445,
        "Challenge_title":"How should I customize my own component and how should I use it.",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":95,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hello <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=0d974fba-0e6f-4b9f-a796-c7257f76884f\">kamala dey<\/a><\/p>\n<p>Thanks for reaching out to us. Yes, this helps. Designer supports two type of components, classic prebuilt components and <strong>custom components.<\/strong> These two types of components are not compatible.<\/p>\n<p>Classic prebuilt components provides prebuilt components majorly for data processing and traditional machine learning tasks like regression and classification. This type of component continues to be supported but will not have any new components added.<\/p>\n<p><strong>Custom components allow you to provide your own code as a component. It supports sharing across workspaces and seamless authoring across Studio, CLI, and SDK interfaces.<\/strong><\/p>\n<p>To build pipeline using components in UI, you need to register components to your workspace first. You can use CLI or SDK to register components to your workspace, so that you can share and reuse the component within the workspace. Registered components support automatic versioning so you can update the component but assure that pipelines that require an older version will continue to work.<\/p>\n<p>In the example below take using CLI for example. If you want to learn more about how to build a component, see <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-component-pipelines-cli\">Create and run pipelines using components with CLI<\/a>.<\/p>\n<ol>\n<li> From the <code>cli\/jobs\/pipelines-with-components\/basics<\/code> directory of the <a href=\"https:\/\/github.com\/Azure\/azureml-examples\"><code>azureml-examples<\/code> repository<\/a>, navigate to the <code>1b_e2e_registered_components<\/code> subdirectory.<\/li>\n<li> Register the components to Azure Machine Learning workspace using following commands. Learn more about <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-component\">ML components<\/a>.\n    CLICopy<\/li>\n<\/ol>\n<pre><code>    az ml component create --file train.yml\naz ml component create --file score.yml\naz ml component create --file eval.yml\n    ```\n    \n    \n1. After register component successfully, you can see your component in the studio UI.\n    \n[![Screenshot showing registered component in component page.](https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/media\/how-to-create-component-pipelines-ui\/component-page.png)\n\n](https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/media\/how-to-create-component-pipelines-ui\/component-page.png#lightbox)Please refer to this guidance for how to leverage your custom components - [https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-component-pipelines-ui#create-pipeline-using-registered-component](https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-component-pipelines-ui#create-pipeline-using-registered-component)\n\nCurrently registered components and the designer built-in components cannot be used together.\n\n\nI hope this helps, please have a try and let me know if you have any questions. \n\nRegards,\n\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.\n\n<\/code><\/pre>\n",
        "Solution_comment_count":2.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":7.0,
        "Solution_readability":13.7,
        "Solution_reading_time":41.54,
        "Solution_score_count":1.0,
        "Solution_sentence_count":28.0,
        "Solution_word_count":326.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":212.0517972223,
        "Challenge_answer_count":1,
        "Challenge_body":"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/model-monitor-data-capture-endpoint.html\n\nI have followed the steps mentioned in this and it appears I cannot change the encoding for EndpointOutput in datacapture file. It's coming BASE64 for xgboost model. I am using latest version 1.2.3.\n\nFor monitor scheduler it required both EndpointOutput and EndpointInput to have the same encoding. My EndpointInput  is CSV but EndpointOutput is coming to be BASE64 and nothing can change it.\n\nThis is causing issue while run of analyzer. After baseline is generated and data is captured, when monitoring schedule runs the analyzer it throws error of Encoding mismatch. For it to run EndpointOutput and EndpointInput should have same encoding.\n\nI saw we cannot do anything to change the encoding of output. I used LightGBM, CatBoost algorithms also and found for these EndpointOuput encoding is JSON, which is readable but still not solving the purpose.\n\nIs there a way we can change EndpointOutput Encoding for DataCapture.",
        "Challenge_closed_time":1675066186694,
        "Challenge_comment_count":1,
        "Challenge_created_time":1673956972508,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1674302800224,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUGSFVfrFJS_KsdrOMeepDPg\/model-monitor-capture-data-endpointoutput-encoding-is-base64",
        "Challenge_link_count":1,
        "Challenge_participation_count":2,
        "Challenge_readability":9.5,
        "Challenge_reading_time":13.44,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":12,
        "Challenge_solved_time":308.1150516667,
        "Challenge_title":"Model Monitor Capture data - EndpointOutput Encoding is BASE64",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":69.0,
        "Challenge_word_count":156,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"Output encoding can be configured by using the [CaptureContentTypeHeader \nin EndpointConfig.DataCaptureConfig](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/APIReference\/API_DataCaptureConfig.html#sagemaker-Type-DataCaptureConfig-CaptureContentTypeHeader). I believe since this is not being set, default encoding i.e. base64 is being used. \n\nPlease try once with this attribute set as below:\n```\n\"CaptureContentTypeHeader\": { \n         \"CsvContentTypes\": [ \"text\/csv\" ]\n      }\n```\n> Assuming that content_type\/accept is \"text_csv\" for the concerned model.",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":1675066186694,
        "Solution_link_count":1.0,
        "Solution_readability":22.1,
        "Solution_reading_time":7.1,
        "Solution_score_count":0.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":47.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1546566576912,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":25.0,
        "Answerer_view_count":11.0,
        "Challenge_adjusted_solved_time":49.4712094445,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I built a chalice web-app that is hosted in an s3 bucket and calls an xgboost endpoint. I keep getting an error when I invoke the model through the web-app. When I looked into the Lambda log files I discovered my input is not properly decoding. <code>input_text = app.current_request.raw_body.decode()<\/code> What would be the correct code to decode the input from binary so I can pass in a regular string to my endpoint?<\/p>\n\n<p>Here is the error:<\/p>\n\n<p>botocore.errorfactory.ModelError: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (415) from model with message \"could not convert string to float: user_input=1%\". <\/p>\n\n<p>Here is my index.html file:<\/p>\n\n<pre><code>&lt;html&gt;\n&lt;head&gt;&lt;\/head&gt;\n&lt;body&gt;\n&lt;form method=\"post\" action=\"&lt;chalice_deployed_http&gt;\"&gt;\n\n&lt;input type=\"text\" name=\"user_input\"&gt;&lt;br&gt;\n\n&lt;input type=\"submit\" value=\"Submit\"&gt;\n&lt;\/form&gt;\n&lt;\/body&gt;\n&lt;\/html&gt;\n<\/code><\/pre>\n\n<p>Here is my app.py file:<\/p>\n\n<pre><code>try:\n    from StringIO import StringIO\nexcept ImportError:\n    from io import StringIO\n\nfrom io import BytesIO\nimport csv\nimport sys, os, base64, datetime, hashlib, hmac\nfrom chalice import Chalice, NotFoundError, BadRequestError\nimport boto3\n\n\napp = Chalice(app_name='&lt;name_of_chalice_app&gt;')\napp.debug = True\n\nsagemaker = boto3.client('sagemaker-runtime')\n\n@app.route('\/', methods=['POST'], content_types=['application\/x-www-form-urlencoded'])\ndef handle_data():\n    input_text = app.current_request.raw_body.decode()\n\n    res = sagemaker.invoke_endpoint(\n                    EndpointName='&lt;endpoint_name&gt;',\n                    Body=input_text,\n                    ContentType='text\/csv',\n                    Accept='Accept'\n                )\n    return res['Body'].read().decode()[0]\n<\/code><\/pre>\n\n<p>I should be able to pass in a string like this:<\/p>\n\n<p>'1,4,26,0.076923077,2,3,1,0.611940299,0.7818181820000001,0.40376569,0.571611506,0.12,12,1,0.0,2,1.0,1,2,6,3,1,1,1,1,1,3,1,0.000666667,1,1,2,2,-1.0,0.490196078,-1.0,0.633928571,6.0,145,2,2,1,3,2,2,1,3,2,3,3,-1.0,1,3,1,1,2,1,2,3,1,3,3,1,3,2,3,-1.0,3,3,1,2,2,1,3,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0.3497921158934803,0'<\/p>\n\n<p>and get output like this:<\/p>\n\n<p>'5'<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/sb5Nw.jpg\" rel=\"nofollow noreferrer\">When I run it in a jupyter notebook it works.<\/a><\/p>",
        "Challenge_closed_time":1547657753670,
        "Challenge_comment_count":0,
        "Challenge_created_time":1547243089770,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1547479657316,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/54154455",
        "Challenge_link_count":1,
        "Challenge_participation_count":2,
        "Challenge_readability":11.9,
        "Challenge_reading_time":32.05,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":17,
        "Challenge_solved_time":115.1844166667,
        "Challenge_title":"How do you invoke a sagemaker xgboost endpoint from a chalice app?",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":805.0,
        "Challenge_word_count":223,
        "Platform":"Stack Overflow",
        "Poster_created_time":1546566576912,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":25.0,
        "Poster_view_count":11.0,
        "Solution_body":"<p>This worked:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>    input_text = app.current_request.raw_body\n    d = parse_qs(input_text)\n    lst = d[b'user_input'][0].decode()\n    res = sagemaker.invoke_endpoint(\n                    EndpointName='&lt;name-of-SageMaker-Endpoint&gt;',\n                    Body=lst,\n                    ContentType='text\/csv',\n                    Accept='Accept'\n                )\n<\/code><\/pre>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":23.9,
        "Solution_reading_time":4.38,
        "Solution_score_count":1.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":18.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1254957460063,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"North Carolina, USA",
        "Answerer_reputation_count":2484.0,
        "Answerer_view_count":362.0,
        "Challenge_adjusted_solved_time":2.6018694445,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I used Machine learning tutorial: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/create-experiment\" rel=\"nofollow noreferrer\">Create your first data science experiment in Azure Machine Learning Studio<\/a> to create an <code>Experiment<\/code> and then converted it to a <code>predictive experiment<\/code>. Now I'm trying to deploy it as a Web Service by following this article that was referenced in the above article: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/publish-a-machine-learning-web-service#deploy-it-as-a-web-service\" rel=\"nofollow noreferrer\">Deploy it as a web service<\/a>. But when I click on <code>Run<\/code> and then on <code>Deploy Web Service<\/code>, I don't see the <code>Price Plan<\/code> dropdown and <code>Plan Name<\/code> input box etc as mentioned in the section <code>Machine Learning Web Service portal Deploy Experiment Page<\/code> of the second article above. After I clicked on Deploy Web Service link in ML studio, I got the page shown below.<strong>Question<\/strong>: What I may be doing wrong?<\/p>\n\n<p>Note: You can click on the picture to get a larger view.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/G3TKo.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/G3TKo.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Challenge_closed_time":1526322971967,
        "Challenge_comment_count":0,
        "Challenge_created_time":1526313605237,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/50334563",
        "Challenge_link_count":4,
        "Challenge_participation_count":1,
        "Challenge_readability":12.1,
        "Challenge_reading_time":18.3,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":12,
        "Challenge_solved_time":2.6018694445,
        "Challenge_title":"Deployment of an Azure ML Experiment as a Web Service through Azure Machine Learning Studio",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":330.0,
        "Challenge_word_count":162,
        "Platform":"Stack Overflow",
        "Poster_created_time":1330144099340,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":19815.0,
        "Poster_view_count":2272.0,
        "Solution_body":"<p>I think it depends on what workspace you're in. If you're in the free one then you get the screen that you already get, but if you create a workspace in the Azure portal and use that one, then you will get a screen like below.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/drRpa.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/drRpa.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>To create a new workspace, in the Azure Portal, create a new \"Machine Learning Studio Workspace\" and when you go to Azure ML Studio select the new workspace from the top right.<\/p>",
        "Solution_comment_count":4.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":7.7,
        "Solution_reading_time":7.3,
        "Solution_score_count":1.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":87.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1432655047272,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":463.0,
        "Answerer_view_count":76.0,
        "Challenge_adjusted_solved_time":264.5982422222,
        "Challenge_answer_count":4,
        "Challenge_body":"<p>What is a is the curl command to make a POST request to sage-maker and receive a ML inference?<\/p>",
        "Challenge_closed_time":1514326523572,
        "Challenge_comment_count":1,
        "Challenge_created_time":1513373969900,
        "Challenge_favorite_count":2.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/47840209",
        "Challenge_link_count":0,
        "Challenge_participation_count":5,
        "Challenge_readability":8.2,
        "Challenge_reading_time":1.73,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":11.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":2,
        "Challenge_solved_time":264.5982422222,
        "Challenge_title":"How to Curl an Amazon Sagemaker Endpoint",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":6889.0,
        "Challenge_word_count":25,
        "Platform":"Stack Overflow",
        "Poster_created_time":1443201378360,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":749.0,
        "Poster_view_count":49.0,
        "Solution_body":"<p>Rather than using curl, it's recommended that you use the SageMaker Runtime client to send data and get back inferences from a SageMaker Endpoint:<\/p>\n\n<p><a href=\"http:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/API_runtime_InvokeEndpoint.html\" rel=\"nofollow noreferrer\">http:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/API_runtime_InvokeEndpoint.html<\/a><\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":21.7,
        "Solution_reading_time":4.86,
        "Solution_score_count":4.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":28.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1585590244876,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":55.0,
        "Answerer_view_count":12.0,
        "Challenge_adjusted_solved_time":0.0392458333,
        "Challenge_answer_count":3,
        "Challenge_body":"<p>We created a webservice endpoint and tested it with the following code, and also with POSTMAN.<\/p>\n\n<p>We deployed the service to an AKS in the same resource group and subscription as the AML resource.<\/p>\n\n<p><strong>UPDATE: the attached AKS had a custom networking configuration and rejected external connections.<\/strong><\/p>\n\n<pre><code>import numpy\nimport os, json, datetime, sys\nfrom operator import attrgetter\nfrom azureml.core import Workspace\nfrom azureml.core.model import Model\nfrom azureml.core.image import Image\nfrom azureml.core.webservice import Webservice\nfrom azureml.core.authentication import AzureCliAuthentication\n\ncli_auth = AzureCliAuthentication()\n# Get workspace\nws = Workspace.from_config(auth=cli_auth)\n\n# Get the AKS Details\ntry:\n    with open(\"..\/aml_config\/aks_webservice.json\") as f:\n        config = json.load(f)\nexcept:\n    print(\"No new model, thus no deployment on AKS\")\n    # raise Exception('No new model to register as production model perform better')\n    sys.exit(0)\n\nservice_name = config[\"aks_service_name\"]\n# Get the hosted web service\nservice = Webservice(workspace=ws, name=service_name)\n\n# Input for Model with all features\ninput_j = [[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [10, 9, 8, 7, 6, 5, 4, 3, 2, 1]]\nprint(input_j)\ntest_sample = json.dumps({\"data\": input_j})\ntest_sample = bytes(test_sample, encoding=\"utf8\")\ntry:\n    prediction = service.run(input_data=test_sample)\n    print(prediction)\nexcept Exception as e:\n    result = str(e)\n    print(result)\n    raise Exception(\"AKS service is not working as expected\")\n<\/code><\/pre>\n\n<p>In AML Studio, the deployment state is \"Healthy\".<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/RTB10.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/RTB10.png\" alt=\"Endpoint attributes\"><\/a><\/p>\n\n<p>We get the following error when testing:<\/p>\n\n<pre><code>Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'\n<\/code><\/pre>\n\n<p><strong>Log just after deploying the AKS Webservice <a href=\"http:\/\/t.ly\/t79b\" rel=\"nofollow noreferrer\">here<\/a>.<\/strong><\/p>\n\n<p><strong>Log after running the test script <a href=\"http:\/\/t.ly\/79k5\" rel=\"nofollow noreferrer\">here<\/a>.<\/strong><\/p>\n\n<p>How can we know what is causing this problem and fix it?<\/p>",
        "Challenge_closed_time":1592590202852,
        "Challenge_comment_count":0,
        "Challenge_created_time":1592508291480,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1592590061567,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/62457880",
        "Challenge_link_count":4,
        "Challenge_participation_count":3,
        "Challenge_readability":12.7,
        "Challenge_reading_time":30.97,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":2.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":23,
        "Challenge_solved_time":22.7531588889,
        "Challenge_title":"AML - Web service TimeoutError",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":332.0,
        "Challenge_word_count":275,
        "Platform":"Stack Overflow",
        "Poster_created_time":1585590244876,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":55.0,
        "Poster_view_count":12.0,
        "Solution_body":"<p>We checked the AKS networking configuration and realized it has an Azure CNI profile.<\/p>\n\n<p>In order to test the webservice we need to do it from inside the created virtual network.\nIt worked well!<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":6.5,
        "Solution_reading_time":2.53,
        "Solution_score_count":1.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":34.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":2830.1302777778,
        "Challenge_answer_count":2,
        "Challenge_body":"At the moment, an mlflow byom predictor with arbitrary URLs can be created. We should first check whether an actual mlflow model is served at that URL before creating\/linking said model.",
        "Challenge_closed_time":1656947080000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1646758611000,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/github.com\/mindsdb\/mindsdb\/issues\/2043",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":8.2,
        "Challenge_reading_time":2.98,
        "Challenge_repo_contributor_count":241.0,
        "Challenge_repo_fork_count":1404.0,
        "Challenge_repo_issue_count":4035.0,
        "Challenge_repo_star_count":12007.0,
        "Challenge_repo_watch_count":327.0,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":2830.1302777778,
        "Challenge_title":"[ BYOM MLflow ] Check valid URL when creating predictor",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":38,
        "Platform":"Github",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"Can we close this @paxcema and @ea-rus  I think we need to merge the above PR after checking there are no conflicts (because it's a bit outdated by now), but once merged we can close this issue.",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":13.0,
        "Solution_reading_time":2.31,
        "Solution_score_count":0.0,
        "Solution_sentence_count":1.0,
        "Solution_word_count":37.0,
        "Tool":"MLflow"
    },
    {
        "Answerer_created_time":1517578984080,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":2090.0,
        "Answerer_view_count":163.0,
        "Challenge_adjusted_solved_time":1.8957083334,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have been playing with Amazon Sagemaker. They have amazing sample notebooks in different areas. However, for testing purposes, I want to create an endpoint that returns the result from a function. From what I have seen so far, my understanding is that we can deploy only models but I would like to clarify it.<\/p>\n\n<p>Let's say I want to invoke the endpoint and it should give me the square of the input value. So, I will first create a function:<\/p>\n\n<pre><code>def my_square(x):\n    return x**2\n<\/code><\/pre>\n\n<p>Can we deploy this simple function in Amazon Sagemaker?<\/p>",
        "Challenge_closed_time":1534153182207,
        "Challenge_comment_count":0,
        "Challenge_created_time":1534146357657,
        "Challenge_favorite_count":1.0,
        "Challenge_last_edit_time":1534368379667,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/51817494",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":7.7,
        "Challenge_reading_time":7.59,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":3.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":1.8957083334,
        "Challenge_title":"deploy a simple function to amazon sagemaker",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":216.0,
        "Challenge_word_count":101,
        "Platform":"Stack Overflow",
        "Poster_created_time":1429147641928,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":2282.0,
        "Poster_view_count":264.0,
        "Solution_body":"<p>Yes this is possible but it will need some overhead:\nYou can pass your own docker images for training and inference to sagemaker.<\/p>\n\n<p>Inside this containers you can do anything you want including return your <code>my_square<\/code> function. Keep in mind that you have to write your own flask microservice including proxy and wsgi server(if needed).<\/p>\n\n<p>In my opinion <a href=\"https:\/\/github.com\/awslabs\/amazon-sagemaker-examples\/blob\/master\/advanced_functionality\/scikit_bring_your_own\/scikit_bring_your_own.ipynb\" rel=\"nofollow noreferrer\">this example<\/a> is the most helpfull one.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":12.1,
        "Solution_reading_time":7.77,
        "Solution_score_count":3.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":68.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1342685175156,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Germany",
        "Answerer_reputation_count":12103.0,
        "Answerer_view_count":1451.0,
        "Challenge_adjusted_solved_time":1.8368638889,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>When we deploy a model as an ACIWebService in Azure Machine Learning Service, we do not need to specify any <code>deployment_target<\/code>.<\/p>\n<p>According to the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.model?view=azure-ml-py#deploy-workspace--name--models--inference-config-none--deployment-config-none--deployment-target-none--overwrite-false-\" rel=\"nofollow noreferrer\">AzureML documentation<\/a> for <code>azureml.core.model.model<\/code> class,<\/p>\n<pre><code>deployment_target\nComputeTarget\ndefault value: None\nA ComputeTarget to deploy the Webservice to. As Azure Container Instances has no associated ComputeTarget, leave this parameter as None to deploy to Azure Container Instances.\n<\/code><\/pre>\n<p>What does Microsoft mean by<\/p>\n<blockquote>\n<p>As Azure Container Instances has no associated ComputeTarget<\/p>\n<\/blockquote>\n<p>In which &quot;Compute Target&quot; is an ACIWebService deployed?<\/p>",
        "Challenge_closed_time":1610958655960,
        "Challenge_comment_count":0,
        "Challenge_created_time":1610952043250,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/65769868",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":18.0,
        "Challenge_reading_time":13.44,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":2.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":1.8368638889,
        "Challenge_title":"Where does the Azure Machine ACI Webservice deploy?",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":317.0,
        "Challenge_word_count":94,
        "Platform":"Stack Overflow",
        "Poster_created_time":1601729162436,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Bengaluru, Karnataka, India",
        "Poster_reputation_count":887.0,
        "Poster_view_count":130.0,
        "Solution_body":"<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/container-instances\/container-instances-overview\" rel=\"nofollow noreferrer\">Azure Container Instances<\/a> itself is the compute platform. It spins up a container in a serverless-fashion.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":17.6,
        "Solution_reading_time":3.28,
        "Solution_score_count":3.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":19.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1520413126203,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":37123.0,
        "Answerer_view_count":4058.0,
        "Challenge_adjusted_solved_time":29.5944916667,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I deployed a web-service from an experiment in ML studio. I tested the API, and everything was working fine. I tested it in Postman. After 2 hours, I got an authentication error when I sent a request using the same API. So to resolve this, I republished my Web Service and got new authentication code, so the API is working fine for now. I have two questions:<\/p>\n\n<p>1) Does the primary key automatically expire after a while or by signing out from ML studio? \n2) What is the application of the second key in ML Studio APIs? Where do we need the second key? <\/p>",
        "Challenge_closed_time":1535450343787,
        "Challenge_comment_count":0,
        "Challenge_created_time":1535343803617,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/52032535",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":7.1,
        "Challenge_reading_time":7.49,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":29.5944916667,
        "Challenge_title":"Does the primary key of Web Service API in ML Studio expire?",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":228.0,
        "Challenge_word_count":116,
        "Platform":"Stack Overflow",
        "Poster_created_time":1501114346136,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Australia",
        "Poster_reputation_count":37.0,
        "Poster_view_count":8.0,
        "Solution_body":"<blockquote>\n  <p>1) Does the primary key automatically expire after a while or by signing out from ML studio?<\/p>\n<\/blockquote>\n\n<p>I could not find any limit of the primary key in the office docs. Per my test, my primary key does not expire more than two hours or sign out from ML studio.<\/p>\n\n<blockquote>\n  <p>2) What is the application of the second key in ML Studio APIs? Where do we need the second key?<\/p>\n<\/blockquote>\n\n<p>The second key is the same usage of the primary key, like a backup of the primary key. Also, the primary key equals the API key in the ML studio.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":6.7,
        "Solution_reading_time":6.93,
        "Solution_score_count":0.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":104.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":49.2027833334,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>As far as I can tell there is no way to use the Excel add in for Azure ML using the new Azure ML service, it only works for the Classic. Is there any plan to provide a replacement add in that brings this functionality to the new Azure ML before Classic stops being supported in 2024?<\/p>",
        "Challenge_closed_time":1647857647663,
        "Challenge_comment_count":1,
        "Challenge_created_time":1647680517643,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/778717\/replacement-for-azure-ml-classic-excel-add-in",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":8.1,
        "Challenge_reading_time":4.01,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":49.2027833334,
        "Challenge_title":"Replacement for Azure ML Classic Excel Add In",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":64,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=325bba53-0a8f-4bf1-ab22-527f5cbac10d\">@Tim Cahill  <\/a>  Thanks for the question. Currently it's on roadmap to support in the near  future.  Excel add in feature similar to studio classic, it will be built on top on v2 online endpoints.    <br \/>\nCurrently, managed endpoints are not integrated with Designer, we need to first provide capability to do a no code designer deployment on v2 online endpoints and integrating excel add in for v2 endpoints.<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":10.1,
        "Solution_reading_time":5.99,
        "Solution_score_count":0.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":70.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1621658973823,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Hyderabad, Telangana, India",
        "Answerer_reputation_count":3213.0,
        "Answerer_view_count":1896.0,
        "Challenge_adjusted_solved_time":5.4727108333,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have been following the learning path for <a href=\"https:\/\/docs.microsoft.com\/en-us\/learn\/certifications\/exams\/ai-900\" rel=\"nofollow noreferrer\">Microsoft Azure AI 900<\/a>. In the second module, I have deployed my model as an endpoint. It says Container instances for compute type. How much will this cost me. Azure doesn't seem to show any pricing for this. Is this endpoint always active? If yes how much does it cost?<\/p>",
        "Challenge_closed_time":1635505501916,
        "Challenge_comment_count":1,
        "Challenge_created_time":1635485800157,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/69764100",
        "Challenge_link_count":1,
        "Challenge_participation_count":2,
        "Challenge_readability":6.1,
        "Challenge_reading_time":5.95,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":3.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":5.4727108333,
        "Challenge_title":"Endpoints cost on Azure Machine Learning",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":633.0,
        "Challenge_word_count":66,
        "Platform":"Stack Overflow",
        "Poster_created_time":1566078293736,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Mumbai, Maharashtra, India",
        "Poster_reputation_count":449.0,
        "Poster_view_count":77.0,
        "Solution_body":"<p>The price depends on the number of <strong>vCPU<\/strong> and <strong>GBs<\/strong> of memory requested for the container group. You are charged based on the <strong>vCPU request<\/strong> for your container group rounded up to the nearest whole number for the duration (measured in seconds) <strong>your instance is running<\/strong>. You are also charged for the <strong>GB request<\/strong> for your container group rounded up to the nearest tenths place for the duration (measured in seconds) your <strong>container group is running<\/strong>. There is an additional charge of $0.000012 per vCPU second for Windows software duration on Windows container groups. Check here <a href=\"https:\/\/azure.microsoft.com\/en-us\/pricing\/details\/container-instances\/\" rel=\"nofollow noreferrer\">Pricing - Container Instances | Microsoft Azure<\/a> for details<\/p>\n<ul>\n<li>After Deployed the Azure Machine Learning managed online endpoint (preview).<\/li>\n<li>Have at least <a href=\"https:\/\/github.com\/MicrosoftDocs\/azure-docs\/blob\/master\/articles\/role-based-access-control\/role-assignments-portal.md\" rel=\"nofollow noreferrer\">Billing Reader<\/a> access on the subscription where the endpoint is deployed<\/li>\n<\/ul>\n<p>To know the costs estimation<\/p>\n<ol>\n<li><p>In the <a href=\"https:\/\/portal.azure.com\/\" rel=\"nofollow noreferrer\">Azure portal<\/a>, Go to your subscription<\/p>\n<\/li>\n<li><p>Select <strong>Cost Analysis<\/strong> for your subscription.<\/p>\n<\/li>\n<\/ol>\n<p><img src=\"https:\/\/i.imgur.com\/W2eaRIO.png\" alt=\"enter image description here\" \/><\/p>\n<p>Create a filter to scope data to your Azure Machine learning workspace resource:<\/p>\n<ol>\n<li><p>At the top navigation bar, select <strong>Add filter<\/strong>.<\/p>\n<\/li>\n<li><p>In the first filter dropdown, select <strong>Resource<\/strong> for the filter type.<\/p>\n<\/li>\n<li><p>In the second filter dropdown, select your Azure Machine Learning workspace.<\/p>\n<\/li>\n<\/ol>\n<p><img src=\"https:\/\/i.imgur.com\/HEvprph.png\" alt=\"enter image description here\" \/><\/p>\n<p>Create a tag filter to show your managed online endpoint and\/or managed online deployment:<\/p>\n<ol>\n<li><p>Select <strong>Add filter<\/strong> &gt; <strong>Tag<\/strong> &gt; <strong>azuremlendpoint<\/strong>: &quot;&lt; your endpoint name&gt;&quot;<\/p>\n<\/li>\n<li><p>Select <strong>Add filter<\/strong> &gt; <strong>Tag<\/strong> &gt; <strong>azuremldeployment<\/strong>: &quot;&lt; your deployment name&gt;&quot;.<\/p>\n<\/li>\n<\/ol>\n<p><img src=\"https:\/\/i.imgur.com\/1aapYGB.png\" alt=\"enter image description here\" \/><\/p>\n<p>Refer  <a href=\"https:\/\/github.com\/MicrosoftDocs\/azure-docs\/blob\/master\/articles\/machine-learning\/how-to-view-online-endpoints-costs.md\" rel=\"nofollow noreferrer\">here <\/a> for more detailed steps<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":7.0,
        "Solution_readability":12.6,
        "Solution_reading_time":35.84,
        "Solution_score_count":2.0,
        "Solution_sentence_count":19.0,
        "Solution_word_count":280.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1254957460063,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"North Carolina, USA",
        "Answerer_reputation_count":2484.0,
        "Answerer_view_count":362.0,
        "Challenge_adjusted_solved_time":3.0221416667,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Suppose I have a trained model in <a href=\"https:\/\/studio.azureml.net\" rel=\"nofollow noreferrer\">Azure ML<\/a> and I deployed it as a Web Service. Is it possible to export the model, embed it in an Android app and use it <em>locally<\/em>, without making any requests to Azure Web service?<\/p>",
        "Challenge_closed_time":1527019984807,
        "Challenge_comment_count":0,
        "Challenge_created_time":1527009105097,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/50473170",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":7.9,
        "Challenge_reading_time":3.98,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":3.0221416667,
        "Challenge_title":"Embedded Azure MLmodel",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":85.0,
        "Challenge_word_count":47,
        "Platform":"Stack Overflow",
        "Poster_created_time":1485085240960,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Ivanovo, Ivanovo Oblast, Russia",
        "Poster_reputation_count":490.0,
        "Poster_view_count":196.0,
        "Solution_body":"<p>From <a href=\"https:\/\/stackoverflow.com\/questions\/41236871\/how-to-download-the-trained-models-from-azure-machine-studio\">this answer<\/a> you won't be able to save the model locally if you do everything within Azure ML Studio.<\/p>\n\n<p>If you create the model using Python or R and execute it within Azure ML Studio, then you can save it from the library that you use.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":10.7,
        "Solution_reading_time":4.77,
        "Solution_score_count":1.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":48.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1337759214688,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Pune India",
        "Answerer_reputation_count":1036.0,
        "Answerer_view_count":124.0,
        "Challenge_adjusted_solved_time":810.2160711111,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I have implemented machine learning algorithms through sagemaker.<\/p>\n\n<p>I have installed SDK for .net, and tried by executing below code.<\/p>\n\n<pre><code>Uri sagemakerEndPointURI = new Uri(\"https:\/\/runtime.sagemaker.us-east-2.amazonaws.com\/endpoints\/MyEndpointName\/invocations\");\nAmazon.SageMakerRuntime.Model.InvokeEndpointRequest request = new Amazon.SageMakerRuntime.Model.InvokeEndpointRequest();\nrequest.EndpointName = \"MyEndpointName\";\nAmazonSageMakerRuntimeClient aawsClient = new AmazonSageMakerRuntimeClient(myAwsAccessKey,myAwsSecreteKey);            \nAmazon.SageMakerRuntime.Model.InvokeEndpointResponse resposnse= aawsClient.InvokeEndpoint(request);\n<\/code><\/pre>\n\n<p>By executing this, I am getting validation error as \"<code>1 validation error detected: Value at 'body' failed to satisfy constraint: Member must not be null<\/code>\"<\/p>\n\n<p>Can anyone guide me on how and what more input data I need to pass to call the given API?<\/p>\n\n<p>EDIT<\/p>\n\n<p>Further I'd tried by provinding body parameter which contains a MemoryStream written by a '.gz' or '.pkl' file, and it giving me error as : \"Error unmarshalling response back from AWS,  HTTP content length exceeded 5246976 bytes.\"<\/p>\n\n<p>EDIT 1\/23\/2018<\/p>\n\n<p>Further I came up with the error message as <\/p>\n\n<blockquote>\n  <p>ERROR - model server - 'TypeError' object has no attribute 'message'<\/p>\n<\/blockquote>\n\n<p>Thanks<\/p>",
        "Challenge_closed_time":1519637555372,
        "Challenge_comment_count":4,
        "Challenge_created_time":1516531050743,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1516720777516,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/48365866",
        "Challenge_link_count":1,
        "Challenge_participation_count":6,
        "Challenge_readability":14.2,
        "Challenge_reading_time":18.7,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":8.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":12,
        "Challenge_solved_time":862.9179525,
        "Challenge_title":"How to call Sagemaker training model endpoint API in C#",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":2093.0,
        "Challenge_word_count":153,
        "Platform":"Stack Overflow",
        "Poster_created_time":1337759214688,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Pune India",
        "Poster_reputation_count":1036.0,
        "Poster_view_count":124.0,
        "Solution_body":"<p>Later solved it by <code>Encoding.ASCII.GetBytes<\/code>as in below code.<\/p>\n\n<pre><code> byte[] bytes = System.IO.File.ReadAllBytes(@\"EXCEL_FILE_PATH\");\n    string listA = \"\";\n    while (!reader.EndOfStream)\n        {\n            var line = reader.ReadLine();\n            listA = listA + line + \"\\n\";\n        }\n    byte[] bytes = Encoding.ASCII.GetBytes(listA);\n    request.Body = new MemoryStream(bytes);\n    InvokeEndpointResponse response = sagemakerRunTimeClient.InvokeEndpoint(request);\n    string predictions = Encoding.UTF8.GetString(response.Body.ToArray());\n<\/code><\/pre>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":16.8,
        "Solution_reading_time":6.92,
        "Solution_score_count":1.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":36.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":1.0,
        "Answerer_isModerator":0.0,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":6.5138261111,
        "Challenge_answer_count":1,
        "Challenge_body":"We deployed a LighGBM Regression model and endpoint using Sagemaker Jumpstart.\nWe have attempted to configure this endpoint as 'asynchronous' via the console.\nReceiving Error: ValidationException-Network Isolation is not supported when specifying an AsyncInferenceConfig.\n\nLooking at the model's network details the model has Enable Network Isolation set as 'True'.\nThis was default output setting set by JumpStart.\n\nHow can we diasble Network Isolation to in order to make this endpoint asynchronous?",
        "Challenge_closed_time":1653023938004,
        "Challenge_comment_count":0,
        "Challenge_created_time":1653000488230,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1668013027784,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUZNbZZQHhSl2RYUtLU8zpSQ\/sagemaker-asynchronous-endpoint-configuration",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":11.0,
        "Challenge_reading_time":6.93,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":6.5138261111,
        "Challenge_title":"Sagemaker Asynchronous Endpoint Configuration",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":120.0,
        "Challenge_word_count":74,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"Vanilla SageMaker \"Models\" (as opposed to versioned ModelPackages) are immutable in the API with no \"UpdateModel\" action... But I think you should be able to create a new Model copying the settings of the current one.\n\nI'd suggest to:\n\n1. Use [DescribeModel](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/APIReference\/API_DescribeModel.html) (via [boto3.client(\"sagemaker\").describe_model()](https:\/\/boto3.amazonaws.com\/v1\/documentation\/api\/latest\/reference\/services\/sagemaker.html#SageMaker.Client.describe_model), assuming you're using Python) to fetch all the parameters of the existing JumpStart model such as the S3 artifact location and other settings\n2. Use [CreateModel](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/APIReference\/API_CreateModel.html) ([create_model()](https:\/\/boto3.amazonaws.com\/v1\/documentation\/api\/latest\/reference\/services\/sagemaker.html#SageMaker.Client.create_model)) to create a new model with same configuration but network isolation disabled\n3. Use your new model to try and deploy an async endpoint\n\nProbably you'd find the low-level boto3 SDK more intuitive for this task than the high-level `sagemaker` SDK's [Model class](https:\/\/sagemaker.readthedocs.io\/en\/stable\/api\/inference\/model.html) - because the latter does some magic that makes typical build\/train\/deploy workflows easier but can be less natural for hacking around with existing model definitions. For example, creating an SMSDK `Model` object doesn't actually create a Model in the SageMaker API, because deployment instance type affects choice of container image so that gets deferred until a `.deploy()` call or similar later.",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":1653023938006,
        "Solution_link_count":5.0,
        "Solution_readability":18.3,
        "Solution_reading_time":21.3,
        "Solution_score_count":1.0,
        "Solution_sentence_count":10.0,
        "Solution_word_count":174.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":139.9080961111,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi,     <\/p>\n<p>I have created a an ML model in Azure ML using auto ML. This has been deployed as an endpoint using the UI.     <br \/>\nThis is a sample of the original dataset:     <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/111244-image.png?platform=QnA\" alt=\"111244-image.png\" \/>    <\/p>\n<p>Its deployed as a container instance and the deployment state is healthy.     <\/p>\n<p>When I test the endpoint, it pre-populates the test form with some example values, for the various paratmeters which are strings and ints.     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/110980-image.png?platform=QnA\" alt=\"110980-image.png\" \/>    <\/p>\n<p>However, if I populate the blank fields with ints and leave the strings, .     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/111051-image.png?platform=QnA\" alt=\"111051-image.png\" \/>    <\/p>\n<p>then test the service, I get an error that suggests it is trying to convert attribute13 to an int    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/110994-image.png?platform=QnA\" alt=\"110994-image.png\" \/>    <\/p>\n<p>as you can see, it is fine with the productName parameter being a string, but tries to convert Attribute13 to an int.     <br \/>\nThe same happens with the other attributesXX.     <br \/>\nIf I set all the attributes to numerical values, the test completes and the endpoint returns a value from the model as expected.     <\/p>\n<p>IF i check the swagger file, it shows that the api is expecting a string:     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/111018-image.png?platform=QnA\" alt=\"111018-image.png\" \/>    <\/p>\n<p>So that all suggests the issue exists somewhere in the python code created automatically.     <br \/>\nThis is kinda where I get stuck - I see <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-deployment-local\">resources on debugging<\/a> the python code, I can see in my score.py file the example sample passes specifies these as 'object' dtypes:     <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/111025-image.png?platform=QnA\" alt=\"111025-image.png\" \/>    <\/p>\n<p>And after that I dont know where to go from here - feels like it should just work 'out of the box' as I got to this point purely through the UI.     <\/p>\n<p>Any help greatly appreciated.     <\/p>\n<p>Steve    <\/p>",
        "Challenge_closed_time":1625655157923,
        "Challenge_comment_count":2,
        "Challenge_created_time":1625151488777,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/459799\/azure-machine-learning-endpoint-attempting-to-cast",
        "Challenge_link_count":7,
        "Challenge_participation_count":3,
        "Challenge_readability":11.2,
        "Challenge_reading_time":31.2,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":21,
        "Challenge_solved_time":139.9080961111,
        "Challenge_title":"Azure Machine Learning Endpoint attempting to cast string parameter as an int",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":299,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>TL;DR: Don't have column names that are numerical.     <\/p>\n<p>I have discovered that if I send the attributes in the order the appear in they dataset - ignoring the order that they are named on the api, then they are all parsed to the correct type. Effectively the 3 columns named 341, 513, 514 belong at the end, but for some reason have been lined up with the wrong parameter names.     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/112439-image.png?platform=QnA\" alt=\"112439-image.png\" \/>    <br \/>\n(this returns expected values)    <\/p>\n<p>So i renamed the columns in my training data pandas dataframe so they are not numerical (e.g. System341, System513, System514) and re-ran the AutoML, and deployed the new model.     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/112552-image.png?platform=QnA\" alt=\"112552-image.png\" \/>    <\/p>\n<p>now the order of columns matches that of the dataset- and IT WORKS!     <\/p>\n",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":9.5,
        "Solution_reading_time":12.02,
        "Solution_score_count":3.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":128.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":4.7692930556,
        "Challenge_answer_count":2,
        "Challenge_body":"Hi\nCouldn't find answers in the documentation for the following questions when selling a model package on the AWS Marketplace:\n\n1. Pricing: Can we offer only private offers? (completely disable the hourly and per inference pricing)\n\n2. Autoscaling: Is it possible to define an autoscaling policy for a hosted endpoint that runs a model package?\n\n3. Parameters: What's the interface for making an inference call? Can we pass any parameters to the inference endpoint?\n\n4. S3: Can we use S3 to load additional dependencies?\n\nThank you very much!",
        "Challenge_closed_time":1673208081703,
        "Challenge_comment_count":0,
        "Challenge_created_time":1673190912248,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1673538025192,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUghZxipLKTSSn45EOV-S_Yg\/sagemaker-on-aws-marketplace-autoscaling-parameters-pricing-and-s3",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":8.6,
        "Challenge_reading_time":7.52,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":4.7692930556,
        "Challenge_title":"SageMaker on AWS Marketplace - autoscaling, parameters, pricing and S3",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":58.0,
        "Challenge_word_count":96,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"Hi,\n\n1. In general, AWS Marketplace uses a pay-as-you-go pricing model, which means that customers are charged for the resources they consume on an hourly or per-inference basis. I'm not aware of any way to disable this pricing model when selling a model package on AWS Marketplace. However, it's worth noting that AWS Marketplace also offers private listings, which allow you to sell your model package directly to a specific customer or group of customers. Private offers are not discoverable by other customers and are not subject to the same pricing and billing terms as public listings. You may want to consider using a private listing if you want to offer a different pricing model for your model package. Reference: https:\/\/docs.aws.amazon.com\/marketplace\/latest\/buyerguide\/buyer-private-offers.html\n\n2. Yes, it is possible to define an auto scaling policy for a hosted Amazon SageMaker endpoint that runs a model package. To define an auto scaling policy for a SageMaker endpoint, you can use the *UpdateEndpoint* API or the SageMaker console. When updating an endpoint, you can specify the desired number of instances and the minimum and maximum number of instances for the auto scaling policy. SageMaker will automatically scale the number of instances up or down based on the incoming traffic and the defined policy.\n\nHere's an example of how you can use the *UpdateEndpoint* API to update an endpoint with an auto scaling policy:\n\n```\nimport boto3\n\nsm = boto3.client('sagemaker')\n\nresponse = sm.update_endpoint(\n    EndpointName='your-endpoint-name',\n    DesiredInferenceUnits=1,\n    MinInferenceUnits=1,\n    MaxInferenceUnits=8\n)\n\n```\nMore details: https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/APIReference\/API_UpdateEndpoint.html\n\n3. To make an inference call to a hosted Amazon SageMaker endpoint, you can use the *invoke_endpoint* method of the SageMaker runtime client. This method allows you to send an HTTP POST request to the endpoint and receive the prediction results in the response.\n\nHere's an example of how you can use the *invoke_endpoint* method to make an inference request:\n\n```\nimport boto3\n\nsm = boto3.client('sagemaker-runtime')\n\nresponse = sm.invoke_endpoint(\n    EndpointName='your-endpoint-name',\n    Body=b'your-request-data',\n    ContentType='application\/json'\n)\nprediction = response['Body'].read()\n\n```\nYou can pass any parameters that your model expects in the request body. The format of the request data and the expected parameters depend on the specific model that you are using. For example, if your model expects a JSON object with a single field called \"input\", you can pass the input data as a JSON string in the request body.\n\nMore details: https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/APIReference\/API_runtime_InvokeEndpoint.html\n\n4. Yes, you can use S3 to store additional dependencies for your ML model and load them into Amazon SageMaker. SageMaker allows you to specify additional code and libraries to be included in your training or inference environment by using the CodeRepository parameter of the CreateTrainingJob or CreateEndpoint API. The CodeRepository parameter should be set to the Amazon S3 URI of a Git repository that contains the code and dependencies you want to include. SageMaker will clone the repository and build the code as part of the training or inference environment.\n\nHere's an example of how you can use the CodeRepository parameter to specify an S3-based Git repository in a CreateTrainingJob request:\n\n```\nimport boto3\n\nsm = boto3.client('sagemaker')\n\nresponse = sm.create_training_job(\n    TrainingJobName='your-training-job-name',\n    HyperParameters={...},\n    InputDataConfig=[{...}],\n    OutputDataConfig={...},\n    ResourceConfig={...},\n    RoleArn='your-role-arn',\n    CodeRepository='s3:\/\/your-bucket\/your-repository.git'\n)\n\n```\nMore details: https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/APIReference\/API_CreateTrainingJob.html",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":1673208081703,
        "Solution_link_count":4.0,
        "Solution_readability":13.6,
        "Solution_reading_time":48.81,
        "Solution_score_count":0.0,
        "Solution_sentence_count":29.0,
        "Solution_word_count":504.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1253986272627,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":11930.0,
        "Answerer_view_count":2649.0,
        "Challenge_adjusted_solved_time":66.306625,
        "Challenge_answer_count":3,
        "Challenge_body":"<p>I've deployed an endpoint in sagemaker and was trying to invoke it through my python program. I had tested it using postman and it worked perfectly ok. Then I wrote the invocation code as follows<\/p>\n\n<pre><code>import boto3\nimport pandas as pd\nimport io\nimport numpy as np\n\ndef np2csv(arr):\n    csv = io.BytesIO()\n    np.savetxt(csv, arr, delimiter=',', fmt='%g')\n    return csv.getvalue().decode().rstrip()\n\n\nruntime= boto3.client('runtime.sagemaker')\npayload = np2csv(test_X)\n\nruntime.invoke_endpoint(\n    EndpointName='&lt;my-endpoint-name&gt;',\n    Body=payload,\n    ContentType='text\/csv',\n    Accept='Accept'\n)\n<\/code><\/pre>\n\n<p>Now whe I run this I get a validation error<\/p>\n\n<pre><code>ValidationError: An error occurred (ValidationError) when calling the InvokeEndpoint operation: Endpoint &lt;my-endpoint-name&gt; of account &lt;some-unknown-account-number&gt; not found.\n<\/code><\/pre>\n\n<p>While using postman i had given my access key and secret key but I'm not sure how to pass it when using sagemaker apis. I'm not able to find it in the documentation also. <\/p>\n\n<p>So my question is, how can I use sagemaker api from my local machine to invoke my endpoint?<\/p>",
        "Challenge_closed_time":1517113913470,
        "Challenge_comment_count":0,
        "Challenge_created_time":1516867519790,
        "Challenge_favorite_count":1.0,
        "Challenge_last_edit_time":1516875209620,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/48438202",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":11.1,
        "Challenge_reading_time":15.26,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":5.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":11,
        "Challenge_solved_time":68.4426888889,
        "Challenge_title":"Errors while using sagemaker api to invoke endpoints",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":4467.0,
        "Challenge_word_count":155,
        "Platform":"Stack Overflow",
        "Poster_created_time":1410972175307,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":1124.0,
        "Poster_view_count":153.0,
        "Solution_body":"<p>When you are using any of the AWS SDK (including the one for Amazon SageMaker), you need to configure the credentials of your AWS account on the machine that you are using to run your code. If you are using your local machine, you can use the AWS CLI flow. You can find detailed instructions on the Python SDK page: <a href=\"https:\/\/aws.amazon.com\/developers\/getting-started\/python\/\" rel=\"nofollow noreferrer\">https:\/\/aws.amazon.com\/developers\/getting-started\/python\/<\/a> <\/p>\n\n<p>Please note that when you are deploying the code to a different machine, you will have to make sure that you are giving the EC2, ECS, Lambda or any other target a role that will allow the call to this specific endpoint. While in your local machine it can be OK to give you admin rights or other permissive permissions, when you are deploying to a remote instance, you should restrict the permissions as much as possible. <\/p>\n\n<pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"VisualEditor0\",\n            \"Effect\": \"Allow\",\n            \"Action\": \"sagemaker:InvokeEndpoint\",\n            \"Resource\": \"arn:aws:sagemaker:*:1234567890:endpoint\/&lt;my-endpoint-name&gt;\"\n        }\n    ]\n}\n<\/code><\/pre>",
        "Solution_comment_count":2.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":12.0,
        "Solution_reading_time":14.44,
        "Solution_score_count":4.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":156.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1442180190107,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":3203.0,
        "Answerer_view_count":400.0,
        "Challenge_adjusted_solved_time":42.3125619445,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I'm trying to create a Machine Learning algorithm following this tutorial : <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/gs-console.html\" rel=\"nofollow noreferrer\">Get Started with Amazon SageMaker<\/a><\/p>\n\n<p>Unless I missed something in the tutorial, I didn't find any steps where we specify the target variable. Can someone explain where \/ when we specify our target variable when creating an ML model using SageMaker built-in algorithms? <\/p>\n\n<p>Thanks a lot! <\/p>",
        "Challenge_closed_time":1579512805583,
        "Challenge_comment_count":1,
        "Challenge_created_time":1579360480360,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/59801874",
        "Challenge_link_count":1,
        "Challenge_participation_count":3,
        "Challenge_readability":12.4,
        "Challenge_reading_time":7.02,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":2.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":42.3125619445,
        "Challenge_title":"When do you specify the Target variable in a SageMaker Training job?",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":715.0,
        "Challenge_word_count":72,
        "Platform":"Stack Overflow",
        "Poster_created_time":1562055808543,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":895.0,
        "Poster_view_count":53.0,
        "Solution_body":"<p>It depends on the scientific paradigm you're using in SageMaker :)<\/p>\n\n<ul>\n<li>SageMaker Built-in algorithms all have their input specification,\ndescribed in their respective documentation. For example, for\n<a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/linear-learner.html#ll-input_output\" rel=\"nofollow noreferrer\">SageMaker Linear Learner<\/a> and <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/xgboost.html#InputOutput-XGBoost\" rel=\"nofollow noreferrer\">SageMaker XGBoost<\/a> the target is assumed\nto be the first column.<\/li>\n<li>With custom code, such as Bring-Your-Own-Docker or SageMaker Framework containers (for Sklearn, TF, PyTorch, MXNet) since you are the one writing the code you can write any sort of logic, and the target can be any column of your dataset.<\/li>\n<\/ul>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":16.2,
        "Solution_reading_time":10.53,
        "Solution_score_count":4.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":90.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1535490052056,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Seattle, WA, USA",
        "Answerer_reputation_count":81.0,
        "Answerer_view_count":6.0,
        "Challenge_adjusted_solved_time":76.4050927778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have ~5MB json string that I want to send to my endpoint. I am using boto3.client to invoke the endpoint from my python client. It throws ConnectionResetError. <\/p>\n\n<pre><code>    File \"C:\\Users\\corona\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\urllib3\\connectionpool.py\", line 600, in urlopen\n    chunked=chunked)\n  File \"C:\\Users\\corona\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\urllib3\\connectionpool.py\", line 354, in _make_request\n    conn.request(method, url, **httplib_request_kw)\n  File \"C:\\Users\\corona\\AppData\\Local\\Programs\\Python\\Python37\\lib\\http\\client.py\", line 1229, in request\n    self._send_request(method, url, body, headers, encode_chunked)\n  File \"C:\\Users\\corona\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\botocore\\awsrequest.py\", line 92, in _send_request\n    method, url, body, headers, *args, **kwargs)\n  File \"C:\\Users\\corona\\AppData\\Local\\Programs\\Python\\Python37\\lib\\http\\client.py\", line 1275, in _send_request\n    self.endheaders(body, encode_chunked=encode_chunked)\n  File \"C:\\Users\\corona\\AppData\\Local\\Programs\\Python\\Python37\\lib\\http\\client.py\", line 1224, in endheaders\n    self._send_output(message_body, encode_chunked=encode_chunked)\n  File \"C:\\Users\\corona\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\botocore\\awsrequest.py\", line 119, in _send_output\n    self.send(msg)\n  File \"C:\\Users\\corona\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\botocore\\awsrequest.py\", line 203, in send\n    return super(AWSConnection, self).send(str)\n  File \"C:\\Users\\corona\\AppData\\Local\\Programs\\Python\\Python37\\lib\\http\\client.py\", line 977, in send\n    self.sock.sendall(data)\n  File \"C:\\Users\\corona\\AppData\\Local\\Programs\\Python\\Python37\\lib\\ssl.py\", line 1012, in sendall\n    v = self.send(byte_view[count:])\n  File \"C:\\Users\\corona\\AppData\\Local\\Programs\\Python\\Python37\\lib\\ssl.py\", line 981, in send\n    return self._sslobj.write(data)\nConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n<\/code><\/pre>\n\n<p>Looking at the trace, I am guessing it is due to json string size. Could someone please help me how to get around this? <\/p>",
        "Challenge_closed_time":1586421549190,
        "Challenge_comment_count":0,
        "Challenge_created_time":1586140541570,
        "Challenge_favorite_count":1.0,
        "Challenge_last_edit_time":1586146490856,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/61052173",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":16.4,
        "Challenge_reading_time":29.47,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":27,
        "Challenge_solved_time":78.0576722223,
        "Challenge_title":"Is there a limit on input json string for aws sagemaker endpoint?",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":1281.0,
        "Challenge_word_count":174,
        "Platform":"Stack Overflow",
        "Poster_created_time":1584461369092,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":13.0,
        "Poster_view_count":4.0,
        "Solution_body":"<p>Exceeding the payload size limit does result in a connection reset from the SageMaker Runtime service.<\/p>\n\n<p>From the SageMaker <a href=\"https:\/\/docs.aws.amazon.com\/general\/latest\/gr\/sagemaker.html\" rel=\"nofollow noreferrer\">documentation<\/a>:<\/p>\n\n<blockquote>\n  <p>Maximum payload size for endpoint invocation |    5 MB<\/p>\n<\/blockquote>\n\n<p>There are likely more space-efficient data formats than JSON that you could use to transmit the payload, but the available options will depend on the type of data and what model image you are using (i.e. whether Amazon-provided or a custom implementation).<\/p>",
        "Solution_comment_count":2.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":15.3,
        "Solution_reading_time":7.73,
        "Solution_score_count":2.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":75.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":0.3402777778,
        "Challenge_answer_count":1,
        "Challenge_body":"If I deploy a SageMaker model, am I incurring hosting charges even while no one is accessing my model?",
        "Challenge_closed_time":1592313864000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1592312639000,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1668454706295,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUlNS8ujYmQqePwWS-mgso3Q\/sagemaker-model-spend",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":8.6,
        "Challenge_reading_time":1.53,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":2,
        "Challenge_solved_time":0.3402777778,
        "Challenge_title":"SageMaker Model Spend",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":148.0,
        "Challenge_word_count":21,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"When you deploy a SageMaker model, it deploys it behind a SageMaker endpoint for real-time inference. You are charged by the second for on-demand ML hosting. Check the model deployment section of each region on the [SageMaker Pricing page][1]. In some use cases, you can save on inference cost by hosting several models behind the same endpoint (check [this blog post][2]).\n\n\n  [1]: https:\/\/aws.amazon.com\/sagemaker\/pricing\/?nc1=h_ls\n  [2]: https:\/\/aws.amazon.com\/fr\/blogs\/machine-learning\/save-on-inference-costs-by-using-amazon-sagemaker-multi-model-endpoints\/",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1612926624243,
        "Solution_link_count":2.0,
        "Solution_readability":13.1,
        "Solution_reading_time":7.23,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":65.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1505166133223,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":146.0,
        "Answerer_view_count":3.0,
        "Challenge_adjusted_solved_time":73.5019452778,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I am new to Sagemaker. I have deployed my well trained model in tensorflow  by using Json and Weight file. But it is strange that in my note book, I didn't see it says \"Endpoint successfully built\". Only the below is shown:<\/p>\n\n<pre><code>--------------------------------------------------------------------------------!\n<\/code><\/pre>\n\n<p>Instead, I found the endpoint number from my console. <\/p>\n\n<pre><code>import sagemaker\nfrom sagemaker.tensorflow.model import TensorFlowModel\n        predictor=sagemaker.tensorflow.model.TensorFlowPredictor(endpoint_name, sagemaker_session)\ndata= test_out2\npredictor.predict(data)\n<\/code><\/pre>\n\n<p>Then I try to invoke the endpoint by using 2D array:\n(1) If my 2D array is in size of (5000, 170), I am getting the error:<\/p>\n\n<pre><code>ConnectionResetError: [Errno 104] Connection reset by peer\n<\/code><\/pre>\n\n<p>(2) If reducing the array to size of (10,170), error is :<\/p>\n\n<pre><code>ModelError: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from model with message \"\". See https:\/\/us-east-2.console.aws.amazon.com\/cloudwatch\/home?region=us-east-2#logEventViewer:group=\/aws\/sagemaker\/Endpoints\/sagemaker-tensorflow-2019-04-28-XXXXXXXXX in account 15XXXXXXXX for more information.\n<\/code><\/pre>\n\n<p>Any suggestion please? Found similar case in github, <a href=\"https:\/\/github.com\/awslabs\/amazon-sagemaker-examples\/issues\/589\" rel=\"nofollow noreferrer\">https:\/\/github.com\/awslabs\/amazon-sagemaker-examples\/issues\/589<\/a>.<\/p>\n\n<p>Is it the similar case please?<\/p>\n\n<p>Thank you very much in advance!<\/p>",
        "Challenge_closed_time":1556735063680,
        "Challenge_comment_count":0,
        "Challenge_created_time":1556470456677,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/55892554",
        "Challenge_link_count":3,
        "Challenge_participation_count":2,
        "Challenge_readability":13.4,
        "Challenge_reading_time":21.87,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":16,
        "Challenge_solved_time":73.5019452778,
        "Challenge_title":"Invoke endpoint after model deployment : [Err 104] Connection reset by peer",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":465.0,
        "Challenge_word_count":174,
        "Platform":"Stack Overflow",
        "Poster_created_time":1401287882528,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":61.0,
        "Poster_view_count":13.0,
        "Solution_body":"<p>The first error with data size (5000, 170) might be due to a capacity issue. SageMaker endpoint prediction has a size limit of 5mb. So if your data is larger than 5mb, you need to chop it into pieces and call predict multiple times. <\/p>\n\n<p>For the second error with data size (10, 170), the error message asks you to look into logs. Did you find anything interesting in the cloudwatch log? Anything can be shared in this question?<\/p>",
        "Solution_comment_count":2.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":6.1,
        "Solution_reading_time":5.29,
        "Solution_score_count":1.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":79.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1515120748952,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":76.0,
        "Answerer_view_count":9.0,
        "Challenge_adjusted_solved_time":17.4135575,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I'm trying to invoke the iris endpointfrom the <a href=\"https:\/\/github.com\/awslabs\/amazon-sagemaker-examples\/blob\/master\/sagemaker-python-sdk\/tensorflow_iris_dnn_classifier_using_estimators\/tensorflow_iris_dnn_classifier_using_estimators.ipynb\" rel=\"nofollow noreferrer\">SageMaker example notebooks<\/a> using the aws cli. I've tried using the following command:<\/p>\n\n<pre><code>!aws sagemaker-runtime invoke-endpoint \\\n--endpoint-name sagemaker-tensorflow-py2-cpu-2018-03-19-21-27-52-956 \\\n--body \"[6.4, 3.2, 4.5, 1.5]\" \\\n--content-type \"application\/json\" \\\noutput.json\n<\/code><\/pre>\n\n<p>I get the following response:<\/p>\n\n<pre><code>{\n    \"InvokedProductionVariant\": \"AllTraffic\", \n    \"ContentType\": \"*\/*\"\n}\n<\/code><\/pre>\n\n<p>What am I doing wrong?<\/p>",
        "Challenge_closed_time":1521567781630,
        "Challenge_comment_count":0,
        "Challenge_created_time":1521505092823,
        "Challenge_favorite_count":1.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/49374476",
        "Challenge_link_count":1,
        "Challenge_participation_count":2,
        "Challenge_readability":19.8,
        "Challenge_reading_time":10.72,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":3.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":17.4135575,
        "Challenge_title":"How do I call a SageMaker Endpoint using the AWS CLI (",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":4027.0,
        "Challenge_word_count":64,
        "Platform":"Stack Overflow",
        "Poster_created_time":1443201378360,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":749.0,
        "Poster_view_count":49.0,
        "Solution_body":"<p>If you've gotten that response, your request is successful. The output should be in the output file you specified - output.json :)<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":7.4,
        "Solution_reading_time":1.7,
        "Solution_score_count":5.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":21.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1421596186347,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":812.0,
        "Answerer_view_count":55.0,
        "Challenge_adjusted_solved_time":59.8581247222,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>In the SageMaker documentation, both <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/multi-model-endpoints.html\" rel=\"nofollow noreferrer\">Multi-Model Endpoints<\/a> and <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/multi-container-direct.html\" rel=\"nofollow noreferrer\">Multi-Container Endpoints with Direct Invocation<\/a> are described as very similar methods to host multiple models on a single endpoint. The given use cases appear identical except that <strong>Multi-Model Endpoints<\/strong> include many more advanced features.<\/p>\n<p>For example, <strong>Multi-Model Endpoints<\/strong> can host <em>n<\/em> number of models and support features such as resource sharing and model caching while <strong>Multi-Container Endpoints with Direct Invocation<\/strong> are limited to hosting only 5 models and lack model caching.<\/p>\n<p>When does it make sense to use <strong>Multi-Container Endpoints with Direct Invocation<\/strong> instead of <strong>Multi-Model Endpoints<\/strong>?<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/2EQAA.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/2EQAA.png\" alt=\"Multi-Model Endpoint\" \/><\/a>\n<a href=\"https:\/\/i.stack.imgur.com\/A6jyS.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/A6jyS.png\" alt=\"Multi-Container Endpoint with Direct Invocation\" \/><\/a><\/p>",
        "Challenge_closed_time":1630054299816,
        "Challenge_comment_count":0,
        "Challenge_created_time":1629838066340,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1629838810567,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/68913914",
        "Challenge_link_count":6,
        "Challenge_participation_count":1,
        "Challenge_readability":18.0,
        "Challenge_reading_time":18.92,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":12,
        "Challenge_solved_time":60.0648544444,
        "Challenge_title":"Why Use Multi-Container Endpoints instead of Multi-Model Endpoints?",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":224.0,
        "Challenge_word_count":127,
        "Platform":"Stack Overflow",
        "Poster_created_time":1531231343652,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"St. Louis, MO, USA",
        "Poster_reputation_count":676.0,
        "Poster_view_count":70.0,
        "Solution_body":"<p>If you want to serve multiple models from the same framework using the same endpoint then you can use multi-model endpoints. Due to using the same framework (e.g. only sklearn models), multi-model endpoints make it to the endpoint when they are called. You can have thousands of those models under one endpoint. Multi-container endpoints on the other hand allow serving models from multiple frameworks, e.g. one TensorFlow, one XGBoost and so on, with direct invocation again. However in this case there's <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/multi-container-direct.html\" rel=\"nofollow noreferrer\">limit of 5 different models<\/a> on a single endpoint.<\/p>\n<p>So depending on the problem you are working, if you need to use multiple frameworks on a single endpoint then you will need to use multi-container endpoint with direct invocation. Otherwise you can use the multi-model endpoint.<\/p>\n<p><a href=\"https:\/\/towardsdatascience.com\/deploy-thousands-of-models-on-sagemaker-real-time-endpoints-with-automatic-retraining-pipelines-4eef7521d5a3\" rel=\"nofollow noreferrer\">Reference<\/a><\/p>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":12.4,
        "Solution_reading_time":14.35,
        "Solution_score_count":1.0,
        "Solution_sentence_count":12.0,
        "Solution_word_count":134.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":3.7982433333,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>Is there any way to integrate MS Dynamics Customer Insights with Azure Machine Learning (designer)?I know there is an integration between CI and Azure Machine Learning studio (classic). Please help to integrate these two services.<\/p>",
        "Challenge_closed_time":1656632594976,
        "Challenge_comment_count":1,
        "Challenge_created_time":1656618921300,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/909965\/azure-machine-learning",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":6.9,
        "Challenge_reading_time":3.29,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":3.7982433333,
        "Challenge_title":"Azure machine learning",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":37,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hello @Yasuo-9899     <\/p>\n<p>Thanks for reaching out to us for this question. Are you looking for this document? <a href=\"https:\/\/learn.microsoft.com\/en-us\/dynamics365\/customer-insights\/azure-machine-learning-experiments\">https:\/\/learn.microsoft.com\/en-us\/dynamics365\/customer-insights\/azure-machine-learning-experiments<\/a>    <\/p>\n<p>I have found one pic which is described the structure well:    <br \/>\n<img src=\"https:\/\/github.com\/ArtisConsulting\/customer-insights-azure-data-workshop\/raw\/main\/images\/workshop-playbook\/media\/image2.png\" alt=\"image2.png\" \/>    <\/p>\n<p>And also a repo you may want to refer to: <a href=\"https:\/\/github.com\/ArtisConsulting\/customer-insights-azure-data-workshop\/blob\/main\/README.md\">https:\/\/github.com\/ArtisConsulting\/customer-insights-azure-data-workshop\/blob\/main\/README.md<\/a>    <\/p>\n<p>Please let us know more details you are interested in so that we can help. Thanks.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":3.0,
        "Solution_readability":20.9,
        "Solution_reading_time":12.6,
        "Solution_score_count":0.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":71.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1631803441500,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"mexico",
        "Answerer_reputation_count":1258.0,
        "Answerer_view_count":685.0,
        "Challenge_adjusted_solved_time":23.1295969444,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am trying to set up mlops for Vertex AI, following <a href=\"https:\/\/github.com\/GoogleCloudPlatform\/mlops-with-vertex-ai\/blob\/main\/01-dataset-management.ipynb\" rel=\"nofollow noreferrer\">this notebook<\/a>. It works until, near the end, I try:<\/p>\n<pre><code>vertex_ai.init(\nproject=PROJECT,\n    location=REGION)\n<\/code><\/pre>\n<p>which gives:<\/p>\n<pre><code> module 'google.cloud.aiplatform.constants' has no attribute 'SUPPORTED_REGIONS\n<\/code><\/pre>\n<p>I am using <code>us-central1<\/code> which is supported. I wondered if maybe <code>from google.cloud import aiplatform as vertex_ai<\/code> has been changed but don't know how to find out. Any help is much appreciated.<\/p>",
        "Challenge_closed_time":1652193787552,
        "Challenge_comment_count":2,
        "Challenge_created_time":1652110521003,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/72174602",
        "Challenge_link_count":1,
        "Challenge_participation_count":3,
        "Challenge_readability":11.2,
        "Challenge_reading_time":10.31,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":10,
        "Challenge_solved_time":23.1295969444,
        "Challenge_title":"Why do I get 'google.cloud.aiplatform.constants' has no attribute 'SUPPORTED_REGIONS error for Vertex AI init?",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":298.0,
        "Challenge_word_count":83,
        "Platform":"Stack Overflow",
        "Poster_created_time":1351154914716,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":2564.0,
        "Poster_view_count":451.0,
        "Solution_body":"<p>I followed the same Notebook as you, even though I didn't have any issue. What could be happening to you is that you are using an <a href=\"https:\/\/github.com\/googleapis\/python-aiplatform\/releases\" rel=\"nofollow noreferrer\">older version of the library<\/a>.<\/p>\n<p>You can use the command to upgrade the library that is the following one: <code>pip3 install google-cloud-aiplatform --upgrade<\/code>.<\/p>\n<p>Sometimes this happens with the basic installation of the library; the problems could be in the <a href=\"https:\/\/github.com\/googleapis\/python-aiplatform#installation\" rel=\"nofollow noreferrer\">dependencies, versions and indirectly permissions<\/a>.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":10.6,
        "Solution_reading_time":8.59,
        "Solution_score_count":1.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":76.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_created_time":1254957460063,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"North Carolina, USA",
        "Answerer_reputation_count":2484.0,
        "Answerer_view_count":362.0,
        "Challenge_adjusted_solved_time":190.7561563889,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I wanted to know how exactly the following works in backend<\/p>\n\n<p><strong>Scenario :<\/strong> <\/p>\n\n<blockquote>\n  <p>-> We get data from Edgex foundry in UTC format and we it store it in Azure Document DB in (CST\/CDT timezone) format<\/p>\n  \n  <p>-> We trained ML model on data(with Date in CST\/CDT timezone) and Deploy web service.<\/p>\n<\/blockquote>\n\n<p><strong>So I have few basic doubts below<\/strong><\/p>\n\n<blockquote>\n  <ol>\n  <li><p>When web job hits our predictive webservice , will the trained ML model be run again?<\/p><\/li>\n  <li><p>Do we need to convert the UTC timezone for new incoming test data( which we want to predict) into CST\/CDT timezone, as TimeStamp does\n  matter for our prediction?<\/p><\/li>\n  <li><p>What happens in backend when predictive webservice API is called?<\/p><\/li>\n  <\/ol>\n<\/blockquote>",
        "Challenge_closed_time":1521026355920,
        "Challenge_comment_count":0,
        "Challenge_created_time":1520339633757,
        "Challenge_favorite_count":1.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/49130977",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":10.8,
        "Challenge_reading_time":11.08,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":190.7561563889,
        "Challenge_title":"Does a call to \"Deploy web service(via API key) \" re run trained Azure ML model again",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":92.0,
        "Challenge_word_count":133,
        "Platform":"Stack Overflow",
        "Poster_created_time":1504867604870,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Pune, Maharashtra, India",
        "Poster_reputation_count":391.0,
        "Poster_view_count":125.0,
        "Solution_body":"<p>This is only based on my experience with Azure ML, but I think I can help with your questions.<\/p>\n\n<blockquote>\n  <p>When web job hits our predictive webservice, will the trained ML model be run again?<\/p>\n<\/blockquote>\n\n<p>Yes, in the sense that it will call the <code>predict<\/code> (or similar) method on the model on the new data. For instance, in <code>scikit-learn<\/code> you would train your model using the <code>fit<\/code> method. Once the model is in production, only the <code>predict<\/code> method would be called.<\/p>\n\n<p>It will also run the whole workflow you have set up to be deployed as the web service. As an example below is a workflow I've played around with before. Each time the web service is run with new data, this whole thing will be run. This is like creating a Pipeline in <code>scikit-learn<\/code>.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/YMFZb.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/YMFZb.png\" alt=\"Azure ML Workflow\"><\/a><\/p>\n\n<blockquote>\n  <p>Do we need to convert the UTC timezone for new incoming test data( which we want to predict) into CST\/CDT timezone, as TimeStamp does matter for our prediction?<\/p>\n<\/blockquote>\n\n<p>I would say yes, you would need to convert to the timezone that was used when training in the model. This can be done by adding a step in your workflow then when you call the web service it will do the necessary converting for you before making a prediction.<\/p>\n\n<blockquote>\n  <p>What happens in backend when predictive webservice API is called?<\/p>\n<\/blockquote>\n\n<p>I'm not sure if anyone knows for sure other than the folks at Microsoft, but for sure it will run the workflow you have set up.<\/p>\n\n<hr>\n\n<p>I know it's not much, but I hope this helps or at least gets you on the right track for what you need.<\/p>",
        "Solution_comment_count":2.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":7.5,
        "Solution_reading_time":22.21,
        "Solution_score_count":1.0,
        "Solution_sentence_count":17.0,
        "Solution_word_count":286.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1537030909472,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":31.0,
        "Answerer_view_count":18.0,
        "Challenge_adjusted_solved_time":30.1278613889,
        "Challenge_answer_count":3,
        "Challenge_body":"<p>The title sums it up. Essentially, I'd like to offer my own closed-source proprietary ML algorithms to Amazon AWS customers on a pay-to-use basis API - e.g., sales volumes prediction algorithm service licensed monthly or annually or per call. Most information found talks about how to build and give it away, or use it internally within one's company, but I'm looking to offer it to the public as a commercial offering on AWS.<\/p>\n\n<p>Thank you in advance for your help - links to articles, help pages, or direct steps on how to do this.<\/p>",
        "Challenge_closed_time":1537318983688,
        "Challenge_comment_count":0,
        "Challenge_created_time":1537142950110,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1537210523387,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/52359397",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":8.9,
        "Challenge_reading_time":7.65,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":2.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":48.8982161111,
        "Challenge_title":"AWS-ML: How to deploy\/setup my own ML algorithms on AWS platform as pay-to-use API?",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":167.0,
        "Challenge_word_count":105,
        "Platform":"Stack Overflow",
        "Poster_created_time":1537030909472,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":31.0,
        "Poster_view_count":18.0,
        "Solution_body":"<p>Allow me please to answer my own question. Although not a 100% what I was hoping for, there's certainly support for this in the platform which is great to see: <a href=\"https:\/\/docs.aws.amazon.com\/marketplace\/latest\/userguide\/saas-products.html\" rel=\"nofollow noreferrer\">Software-as-a-Service-Based Products<\/a><\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":11.4,
        "Solution_reading_time":4.19,
        "Solution_score_count":1.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":35.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":7.2653166667,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have 2 experiments A and B in Azure MLS classic. I need the web service output of experiment A as one of the web service inputs for experiment B.  Please let me know if it is possible and if yes, how I can do it.<\/p>",
        "Challenge_closed_time":1592433417623,
        "Challenge_comment_count":2,
        "Challenge_created_time":1592407262483,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/37128\/connect-2-separate-experiments-via-webservice-azur",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":7.4,
        "Challenge_reading_time":3.41,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":7.2653166667,
        "Challenge_title":"Connect 2 separate experiments via webservice - Azure MLS Classic",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":54,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>I used export module in experiment A and import module in experiment B to transfer the output of A as input of B.<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":12.3,
        "Solution_reading_time":1.44,
        "Solution_score_count":0.0,
        "Solution_sentence_count":1.0,
        "Solution_word_count":23.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":10.8978944445,
        "Challenge_answer_count":3,
        "Challenge_body":"<p>Is there any way to return a custom HTTP status code from R Web Service in Azure ML?  <\/p>\n<p>All the examples of entry scripts in documentation return the response body from the scoring function. In Python Web Service, it is possible to return a HTTP response object with a custom status code. However, R's httr library does not seem to have any function to create response objects directly (only via HTTP method objects such as POST, which call a given URL).  <\/p>\n<p>I would like to implement a custom exception handling scheme in R Web Service. Is there any way to return a custom HTTP code from the entry script?  <\/p>\n<p>EDIT: Found this idea on the feedback forum, which suggests that the option is not available in Python Web Service either:  <br \/>\n<a href=\"https:\/\/feedback.azure.com\/forums\/257792-machine-learning\/suggestions\/40122838-make-http-status-codes-controllable-from-your-scor\">https:\/\/feedback.azure.com\/forums\/257792-machine-learning\/suggestions\/40122838-make-http-status-codes-controllable-from-your-scor<\/a>  <\/p>",
        "Challenge_closed_time":1612394092687,
        "Challenge_comment_count":0,
        "Challenge_created_time":1612354860267,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/257156\/how-to-specify-http-response-status-code-in-aml-r",
        "Challenge_link_count":1,
        "Challenge_participation_count":3,
        "Challenge_readability":12.9,
        "Challenge_reading_time":13.94,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":8,
        "Challenge_solved_time":10.8978944445,
        "Challenge_title":"How to specify HTTP response status code in AML R Web Service",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":148,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hello Lauri,  <\/p>\n<p>Thanks for the feedback. Yes, we have this product idea in our backlog. I will help to bump up this idea to product group again. ^^  <\/p>\n<p>Regards,  <br \/>\nYutong<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":2.9,
        "Solution_reading_time":2.31,
        "Solution_score_count":0.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":32.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1466260908296,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":71.0,
        "Answerer_view_count":28.0,
        "Challenge_adjusted_solved_time":1174.7564730556,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am using the azure recommendation api on <a href=\"http:\/\/recommendations.azurewebsites.net\/\" rel=\"nofollow noreferrer\">http:\/\/recommendations.azurewebsites.net\/<\/a>.\nI prepared the catalog to be like <code>&lt;Item Id&gt;<\/code>, <code>&lt;Item Name&gt;<\/code>, <code>&lt;Item Category&gt;<\/code>, <code>&lt;Features list&gt;<\/code> and the usage file : <code>&lt;userId&gt;<\/code>, <code>&lt;ItemId&gt;<\/code>.\nNow when I test the recommender, I always get a probability of 0.5 for all items, so I had to presume something is not right.\nIn order to know what's the problem I added two items to the catalog \none with same features as an other item but with different name and id,\nand an other item with different id and one different feature.\nI still get the 0.5 probability and now i'm sure something is not right but I still can figure out what the problem.<\/p>\n\n<p>here is a screenshot of what I get when I add the item to the cart<\/p>\n\n<p><img src=\"https:\/\/i.stack.imgur.com\/zhwiq.png\" alt=\"\"><\/p>\n\n<p>Is there any possibility to use the azure ml matchbox recommender with features and without ratings? <\/p>",
        "Challenge_closed_time":1476373208683,
        "Challenge_comment_count":0,
        "Challenge_created_time":1472144085380,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1491136060303,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/39150834",
        "Challenge_link_count":3,
        "Challenge_participation_count":1,
        "Challenge_readability":8.9,
        "Challenge_reading_time":14.59,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":11,
        "Challenge_solved_time":1174.7564730556,
        "Challenge_title":"probability on azure recommendations api",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":98.0,
        "Challenge_word_count":160,
        "Platform":"Stack Overflow",
        "Poster_created_time":1447254948300,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Tunis, Gouvernorat de Tunis, Tunisie",
        "Poster_reputation_count":31.0,
        "Poster_view_count":19.0,
        "Solution_body":"<p>Tayehi, <\/p>\n\n<p>Nice to meet you. I am the program manager in charge of the recommendations API.\n2 things:<\/p>\n\n<ol>\n<li><p>If you get a 0.5 probability you are most likely getting \"default recommendations\". This usually means that you do not have enough training data or that there are not enough co-occurrences for the item you are testing in the data. To describe the extreme case, imagine an item A that only gets purchased with an item B only one or two times -- it would be hard to say with confidence (statistical significance) that someone that likes item A is also likely to like item B.<\/p><\/li>\n<li><p>It looks like you are still using the old recommendations API. I would like to encourage you to use our newer version (the Recommendations API cognitive service). Please take a look at <a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/cognitive-services-migration-from-dm\/to\" rel=\"nofollow\">https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/cognitive-services-migration-from-dm\/to<\/a> help you in this process.<\/p><\/li>\n<\/ol>\n\n<p>Thanks!\nLuis Cabrera\nCortana Intelligence Applications.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1476476017407,
        "Solution_link_count":2.0,
        "Solution_readability":9.4,
        "Solution_reading_time":14.31,
        "Solution_score_count":0.0,
        "Solution_sentence_count":12.0,
        "Solution_word_count":152.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1433841188323,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Wuxi, Jiangsu, China",
        "Answerer_reputation_count":22467.0,
        "Answerer_view_count":2692.0,
        "Challenge_adjusted_solved_time":24.0835044444,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have deployed a model as a Webservice in Azure ML.Its a simple one and all it does is do a linear Regression .The underlying code is python . Now i need to pass which all columns have to selected as independent variables, dynamically, from the client side . How may i do this in Azure ML studio?<\/p>",
        "Challenge_closed_time":1458632118243,
        "Challenge_comment_count":0,
        "Challenge_created_time":1458567955050,
        "Challenge_favorite_count":1.0,
        "Challenge_last_edit_time":1458612577147,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/36132719",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":6.1,
        "Challenge_reading_time":4.2,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":17.8231091667,
        "Challenge_title":"Select columns dynamically in Azure ML model",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":238.0,
        "Challenge_word_count":62,
        "Platform":"Stack Overflow",
        "Poster_created_time":1422821109972,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"India",
        "Poster_reputation_count":1238.0,
        "Poster_view_count":172.0,
        "Solution_body":"<p>Based on my understanding, I think you want to dynamically get the selected columns data via request the Azure ML webservice with some parameters on the client.<\/p>\n\n<p>You can refer to the offical document <a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-web-service-parameters\/\" rel=\"nofollow\">Use Azure Machine Learning Web Service Parameters<\/a> and the blog <a href=\"https:\/\/blogs.technet.microsoft.com\/machinelearning\/2014\/11\/25\/azureml-web-service-parameters\/\" rel=\"nofollow\">AzureML Web Service Parameters<\/a> to know how to set and use the web service parameters to implement your needs via add the selected column names as array into the json parameter <code>GlobalParameters<\/code>.<\/p>\n\n<p>Meanwhile, there is a client sample on GitHub <a href=\"https:\/\/github.com\/nk773\/AzureML_RRSApp\" rel=\"nofollow\">https:\/\/github.com\/nk773\/AzureML_RRSApp<\/a>. Althought it was writen in Java, I think it is easy to understand, then you can rewrite in Python with <code>requests<\/code> package.<\/p>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":1458699277763,
        "Solution_link_count":4.0,
        "Solution_readability":16.5,
        "Solution_reading_time":13.49,
        "Solution_score_count":0.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":113.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1334762714136,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Boston, MA",
        "Answerer_reputation_count":6557.0,
        "Answerer_view_count":2005.0,
        "Challenge_adjusted_solved_time":3.7098786111,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>So I am currently working with an Azure Machine Learning experiment. I was able to create a model and post it as a web service. I was also able to get the response using the sample request\/response code in C# provided in the API documentation that was generated when I created the web service.<\/p>\n\n<p>My problem is, the response provided by the web service contains many information (a long string of info) including the Prediction Score which is the only thing I need for my C# application. The only thing that comes in mind is to use string manipulation methods in order to extract the info I want. But I think there's a better way than that. I am new to HTTP Request\/Response, so please elaborate answers and explanations about it.<\/p>\n\n<p>Here's my code:<\/p>\n\n<pre><code>HttpResponseMessage response = await client.PostAsJsonAsync(\"\", scoreRequest);\n\nif (response.IsSuccessStatusCode)\n{\n    string result = await response.Content.ReadAsStringAsync();\n    Console.WriteLine(\"Result: {0}\", result);\n}\n\nelse\n{\n    Console.WriteLine(string.Format(\"The request failed with status code: {0}\", response.StatusCode));\n\n    \/\/ Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n    Console.WriteLine(response.Headers.ToString());\n\n    string responseContent = await response.Content.ReadAsStringAsync();\n    Console.WriteLine(responseContent);\n}\n<\/code><\/pre>\n\n<p>Here is the Response Message:<\/p>\n\n<pre><code>{\"Results\":{\"output1\":{\"type\":\"table\",\"value\":{\"ColumnNames\":[\"clump_thickness\",\"size_uniformity\",\"shape_uniformity\",\"marginal_adhesion\",\"epithelial_size\",\"bare_nucleoli\",\"bland_chromatin\",\"normal_nucleoli\",\"mitoses\",\"Scored Labels\",\"Scored Probabilities\"],\"ColumnTypes\":[\"Int32\",\"Int32\",\"Int32\",\"Int32\",\"Int32\",\"Nullable`1\",\"Int32\",\"Int32\",\"Int32\",\"Double\",\"Double\"],\"Values\":[[\"10\",\"10\",\"4\",\"8\",\"1\",\"8\",\"3\",\"10\",\"1\",\"1\",\"0.979712069034576\"],[\"10\",\"10\",\"4\",\"8\",\"1\",\"8\",\"3\",\"10\",\"1\",\"1\",\"0.979712069034576\"]]}}}}\n<\/code><\/pre>\n\n<p>I only want the value within \"Values\":[[...]], which in this case, the 9th index or \"1\".<\/p>",
        "Challenge_closed_time":1456185272736,
        "Challenge_comment_count":0,
        "Challenge_created_time":1456171917173,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1456850000163,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/35562896",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":12.8,
        "Challenge_reading_time":28.15,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":2.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":18,
        "Challenge_solved_time":3.7098786111,
        "Challenge_title":"How to get the Prediction Score in a HttpResponseMessage provided by a Azure ML Web Service?",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":264.0,
        "Challenge_word_count":222,
        "Platform":"Stack Overflow",
        "Poster_created_time":1453137182072,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":79.0,
        "Poster_view_count":4.0,
        "Solution_body":"<p>You need to use project columns in your AML experiment. Currently, you have a module connected to Web Service Output. Use a <code>project columns<\/code> module before your <code>web service output<\/code> to select just the columns you would like to send to our output instead. <\/p>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":8.0,
        "Solution_reading_time":3.53,
        "Solution_score_count":1.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":45.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":29.6317019444,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I trained a model with Designer, created a real-time inference pipeline which was succesfully submitted. When deploying to either ACI or AKS it fails and I get the error &quot;ModuleNotFoundError: No module named 'azureml.api'&quot;. I've had no problems deploying this model many times in the past and haven't changed anything. Even if I use one of the sample pipelines (automobiles basic), I get the same error when deploying to real-time. <\/p>",
        "Challenge_closed_time":1632968850120,
        "Challenge_comment_count":2,
        "Challenge_created_time":1632862175993,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/569925\/deployment-from-designer-fails-in-every-possible-w",
        "Challenge_link_count":0,
        "Challenge_participation_count":4,
        "Challenge_readability":9.4,
        "Challenge_reading_time":6.24,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":29.6317019444,
        "Challenge_title":"Deployment from Designer fails in every possible way",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":78,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>It's an known issue caused by unexpected module version upgrade. It's been resolved by applying hotfix to all regions. For users, please rerun training pipeline by check on &quot;Regenerate Output&quot;, and run corresponding inference pipeline and try deployment again.<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":9.5,
        "Solution_reading_time":3.51,
        "Solution_score_count":1.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":39.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":25.1956663889,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Deploying my model to ACI takes forever and fails without any error message. In the ML workspace, the status of the deployed endpoint is unhealthy. I checked common errors while deployment but could not solve the problem. Pleas help. The deployment is never successful and it keeps running.<\/p>",
        "Challenge_closed_time":1649231254492,
        "Challenge_comment_count":0,
        "Challenge_created_time":1649140550093,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/800334\/issue-in-my-mlops-cd-pipeline",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":6.2,
        "Challenge_reading_time":4.05,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":25.1956663889,
        "Challenge_title":"Issue in my MLOPs CD pipeline.",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":53,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p><em>anonymous user<\/em> Thanks for the question. Could you clarify the architecture of your model deployment? In particular, are you using a custom docker container for it?  Also, usually ACI would be used for testing, but I'd recommend investigating AKS for production model deployment.     <\/p>\n<p> I would deploy the container into a local machine\/VM with Docker to see the exact detail error message which you don't see via ACI deployment.<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":9.9,
        "Solution_reading_time":5.52,
        "Solution_score_count":1.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":70.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1424453610300,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":1237.0,
        "Answerer_view_count":116.0,
        "Challenge_adjusted_solved_time":6.3089888889,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have an R script in Azure Machine Learning that takes two inputs. I have since been working on a project that will take advantage of the webservice I created within Azure. When I use whole numbers as the values, everything works fine. In my C# code, these values are still doubles, and I use ToString to format them for the HTTP request.  I can send the data, and get 100% accurate results back. However, when I send values that actually contain digits after the decimal, I get a bad request response. I think the issue is with how the R script reads in from Azure Machine Learning inputs. So far I have this:<\/p>\n\n<pre><code>#R Script in Azure ML:\n1:    objCoFrame &lt;- maml.mapInputPort(2) # class: data.frame\n2:    objCoVector &lt;- as.vector(objCoFrame[1,])\n<\/code><\/pre>\n\n<p>which was doing the trick with integers. I have also tried <\/p>\n\n<pre><code>2:    objCoVector &lt;- as.vector(as.numeric(objCoFrame[1,]))\n<\/code><\/pre>\n\n<p>but got the same result.<\/p>\n\n<p>The Bad Request Response Content reads:<\/p>\n\n<pre><code>{\n    \"error\":\n    {\n        \"code\":\"BadArgument\",\n        \"message\":\"Invalid argument provided.\",\n        \"details\":\n        [{\n            \"code\":\"InputParseError\",\n            \"target\":\"rhsValues\",\n            \"message\":\"Parsing of input vector failed.  Verify the input vector has the correct number of columns and data types.  Additional details: Input string was not in a correct format..\"\n        }]\n    }\n}\n<\/code><\/pre>",
        "Challenge_closed_time":1458012604667,
        "Challenge_comment_count":0,
        "Challenge_created_time":1457989892307,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/35998155",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":7.7,
        "Challenge_reading_time":17.55,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":2.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":18,
        "Challenge_solved_time":6.3089888889,
        "Challenge_title":"Bad Request Response from Azure Machine Learning",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":522.0,
        "Challenge_word_count":202,
        "Platform":"Stack Overflow",
        "Poster_created_time":1457988600436,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Omaha, NE, USA",
        "Poster_reputation_count":380.0,
        "Poster_view_count":27.0,
        "Solution_body":"<p>Can you force the type using Meta-Editor before passing to execute-R<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":7.6,
        "Solution_reading_time":0.95,
        "Solution_score_count":2.0,
        "Solution_sentence_count":1.0,
        "Solution_word_count":11.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1431724059856,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":66.0,
        "Answerer_view_count":9.0,
        "Challenge_adjusted_solved_time":77.2317477778,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I have created an experiment and successfully published a web service which requires inputs.<\/p>\n\n<p>When I schedule this web service as a HTTPS POST JOB it shows this error<\/p>\n\n<blockquote>\n  <p>Http Action - Response from host\n  'ussouthcentral.services.azureml.net': 'BadRequest' Response Headers:\n  x-ms-request-id: 51fb1d34-5bc7-4832-ad9f-b19826468ea0 Date: Mon, 11\n  May 2015 11:02:01 GMT Server: Microsoft-HTTPAPI\/2.0  Body:\n  {\"error\":{\"code\":\"BadArgument\",\"message\":\"Invalid argument\n  provided.\",\"details\":[{\"code\":\"MissingInputBlobInformation\",\"target\":\"Inputs\",\"message\":\"Missing\n  Azure storage blob information. Provide a valid connection string and\n  relative path or URI and try again.\"}]}}<\/p>\n<\/blockquote>\n\n<p>My data is not located in Azure Blob Storage. I am am trying to pass this web input as part as a HTTPS POST BODY.<\/p>",
        "Challenge_closed_time":1431724580932,
        "Challenge_comment_count":0,
        "Challenge_created_time":1431360087507,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1431446546640,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/30172382",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":9.3,
        "Challenge_reading_time":11.72,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":101.2481736111,
        "Challenge_title":"How to write the body for HTTPS POST job in Azure Schedular without Azure Blob",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":460.0,
        "Challenge_word_count":111,
        "Platform":"Stack Overflow",
        "Poster_created_time":1403541426412,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Bengaluru, India",
        "Poster_reputation_count":191.0,
        "Poster_view_count":22.0,
        "Solution_body":"<p>If you are using BES with web service input and output, you would need to provide the Storage information for the data. \nWith the Reader and Writer modules, you can remove the web service input and output ports.\nThen when the web service is called, it executes without using the Storage blob. It will read from the Reader and write to the destination specified in the Writer.\nI have uploaded a <a href=\"https:\/\/azuremlbesclienttemplate.codeplex.com\/documentation\" rel=\"nofollow\">Visual Studio template to CodePlex<\/a> that you can install. The NoInputOutput.aspx of that project does the above. And it should show you the workflow.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":8.0,
        "Solution_reading_time":7.95,
        "Solution_score_count":1.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":97.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":14.3124580556,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi all;    <\/p>\n<p>I am creating an app to handle volunteers for a NGO. One of the things volunteers will be allowed to do is create events &amp; other projects. And a concern we have is a troll enters something hateful that they then point reporters to.    <\/p>\n<p>So... and I know this is probably beyond ML at present (but it never hurts to ask), is there an AzureML service\/app that we could feed all the text for the proposed event and it would rate the likelihood of it being problematic?     <\/p>\n<p>And if there isn't one that can work with no data from us, is there a service\/app that we could train for this once we have say 100,000 projects? We have no data for this at present but after running for a year we likely will have 100,000 projects to use for training.    <\/p>\n<p>thanks - dave<\/p>",
        "Challenge_closed_time":1671617821856,
        "Challenge_comment_count":0,
        "Challenge_created_time":1671566297007,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1136505\/recognizing-problematic-content",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":7.1,
        "Challenge_reading_time":9.93,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":8,
        "Challenge_solved_time":14.3124580556,
        "Challenge_title":"Recognizing problematic content",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":150,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=2e000d14-7fa3-4e41-9299-8306855b228f\">@David Thielen  <\/a> It is possible to use Azure language services' <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/language-service\/sentiment-opinion-mining\/overview\">sentiment analysis and opinion mining<\/a> offering to identify such problematic comments from your projects. This feature of the service does not require any training as the models behind the service are trained to provide sentiment of the text passed to the service. It returns either a postive, neutral or negative sentiment along with a score to justify the same. I think this should help you solve the issue that you are currently facing to identify trolls.    <\/p>\n<p>The service currently does not have an option to train custom sentiment models, the current recommendation for custom text is to use the azure machine learning service to train your own models.     <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":3.0,
        "Solution_readability":13.3,
        "Solution_reading_time":16.72,
        "Solution_score_count":0.0,
        "Solution_sentence_count":9.0,
        "Solution_word_count":149.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1227171471292,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Israel",
        "Answerer_reputation_count":17500.0,
        "Answerer_view_count":1561.0,
        "Challenge_adjusted_solved_time":233.4898177778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Invoking a multimodel Sagemaker Endpoint, I get an error that it is not multimodel. I create it like this.<\/p>\n<pre><code>create_endpoint_config_response = client.create_endpoint_config(\n    EndpointConfigName=endpoint_config_name,\n    ProductionVariants=[\n        {\n            &quot;InstanceType&quot;: &quot;ml.m5.large&quot;,\n            &quot;InitialVariantWeight&quot;: 0.5,\n            &quot;InitialInstanceCount&quot;: 1,\n            &quot;ModelName&quot;: model_name1,\n            &quot;VariantName&quot;: model_name1,\n        },\n         {\n            &quot;InstanceType&quot;: &quot;ml.m5.large&quot;,\n            &quot;InitialVariantWeight&quot;: 0.5,\n            &quot;InitialInstanceCount&quot;: 1,\n            &quot;ModelName&quot;: model_name2,\n            &quot;VariantName&quot;: model_name2,\n        }\n    ]\n)\n<\/code><\/pre>\n<p>I confirm in the GUI that it in fact has multiple models. I invoke it like this:<\/p>\n<pre><code>response = client.invoke_endpoint(\n    EndpointName=endpoint_name, \n    TargetModel=model_name1,\n    ContentType=&quot;text\/x-libsvm&quot;, \n    Body=payload\n)\n<\/code><\/pre>\n<p>and get this error:<\/p>\n<blockquote>\n<p>ValidationError: An error occurred (ValidationError) when calling the\nInvokeEndpoint operation: Endpoint\nmy-endpoint1 is not a multi-model endpoint\nand does not support target model header.<\/p>\n<\/blockquote>\n<p>The same problem was discussed <a href=\"https:\/\/github.com\/aws\/amazon-sagemaker-examples\/issues\/1026\" rel=\"nofollow noreferrer\">here<\/a> with no resolution.<\/p>\n<p>How can I invoke a multimodel endpoint?<\/p>",
        "Challenge_closed_time":1629283623048,
        "Challenge_comment_count":0,
        "Challenge_created_time":1629114933853,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1629119102992,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/68802388",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":16.4,
        "Challenge_reading_time":19.77,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":14,
        "Challenge_solved_time":46.8581097222,
        "Challenge_title":"Why do I get an error that Sagemaker Endpoint does not have multiple models when it does?",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":247.0,
        "Challenge_word_count":133,
        "Platform":"Stack Overflow",
        "Poster_created_time":1227171471292,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Israel",
        "Poster_reputation_count":17500.0,
        "Poster_view_count":1561.0,
        "Solution_body":"<p>The answer (see <a href=\"https:\/\/github.com\/aws\/amazon-sagemaker-examples\/issues\/1026\" rel=\"nofollow noreferrer\">GitHub<\/a> discussion) is that this error message is simply false.<\/p>\n<p>To avoid this error, the model's local filename (usually for the form <code>model_filename.tar.gz<\/code>) must be used, not the model name.<\/p>\n<p>The <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/invoke-multi-model-endpoint.html\" rel=\"nofollow noreferrer\">documentation<\/a> does say this, though it lacks essential detail.<\/p>\n<p>I found <a href=\"https:\/\/github.com\/aws\/amazon-sagemaker-examples\/blob\/master\/advanced_functionality\/multi_model_xgboost_home_value\/xgboost_multi_model_endpoint_home_value.ipynb\" rel=\"nofollow noreferrer\">this to be the best example<\/a>.  See the last part  of that Notebook, in which <code>invoke_endpoint<\/code> is used (rather than a predictor as used earlier in the Notebook).<\/p>\n<p>As to the location of that model file: This <a href=\"https:\/\/github.com\/aws\/amazon-sagemaker-examples\/blob\/master\/advanced_functionality\/multi_model_bring_your_own\/multi_model_endpoint_bring_your_own.ipynb\" rel=\"nofollow noreferrer\">Notebook<\/a> says:<\/p>\n<blockquote>\n<p>When creating the Model entity for multi-model endpoints, the container's ModelDataUrl is the S3 prefix where the model\nartifacts that are invokable by the endpoint are located. The rest of the S3 path will be specified when invoking the model.<\/p>\n<\/blockquote>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1629959666336,
        "Solution_link_count":4.0,
        "Solution_readability":17.2,
        "Solution_reading_time":19.32,
        "Solution_score_count":0.0,
        "Solution_sentence_count":12.0,
        "Solution_word_count":138.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1492048364132,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Cambridge, MA, USA",
        "Answerer_reputation_count":4436.0,
        "Answerer_view_count":713.0,
        "Challenge_adjusted_solved_time":0.2273408334,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I have created an endpoint on us-east-1. try to create a predictor:<\/p>\n\n<pre><code>In [106]: sagemaker.predictor.RealTimePredictor(&lt;endpoint name&gt;)\n<\/code><\/pre>\n\n<p>and get<\/p>\n\n<pre><code>ClientError: An error occurred (ValidationException) when calling the DescribeEndpoint operation: \nCould not find endpoint \"arn:aws:sagemaker:us-east-2:&lt;account number&gt;:endpoint\/&lt;endpoint name&gt;\".\n<\/code><\/pre>\n\n<p>which is perfectly correct, since the endpoint is on us-east-1.  Probably I could change some defaults, but I'd rather not - I work on us-east-2 99% of the time.<\/p>\n\n<p>So, how can I set a different region when initializing the predictor?<\/p>",
        "Challenge_closed_time":1573497881147,
        "Challenge_comment_count":1,
        "Challenge_created_time":1573497062720,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/58806807",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":11.6,
        "Challenge_reading_time":9.31,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":0.2273408334,
        "Challenge_title":"Create a predictor from an endpoint in a different region",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":478.0,
        "Challenge_word_count":86,
        "Platform":"Stack Overflow",
        "Poster_created_time":1553808322940,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":67.0,
        "Poster_view_count":7.0,
        "Solution_body":"<p>The (python) <code>Predictors<\/code> <a href=\"https:\/\/sagemaker.readthedocs.io\/en\/stable\/predictors.html\" rel=\"nofollow noreferrer\">documentation<\/a> shows that you can pass a <code>Session<\/code> object. In turn, the <code>Session<\/code> can be <a href=\"https:\/\/sagemaker.readthedocs.io\/en\/stable\/session.html#sagemaker.session.Session\" rel=\"nofollow noreferrer\">initialized<\/a> with a <em>client<\/em> and a <em>runtime client<\/em> - the former does everything except endpoint invocations, the latter does... endpoint invocations.<\/p>\n\n<p>Those clients are tied to specific regions. It seems like you should be able to set the runtime client region to match your endpoint, by manually instantiating it, while leaving the regular client alone (disclaimer here: I haven't tried this - if you do, let me\/us know how it goes :)).<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":14.1,
        "Solution_reading_time":10.83,
        "Solution_score_count":0.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":94.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1460664823627,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":81.0,
        "Answerer_view_count":6.0,
        "Challenge_adjusted_solved_time":170.4113630556,
        "Challenge_answer_count":3,
        "Challenge_body":"<p>I wanted to know if there is a way to call the Azure Machine Learning webservice using JavaScript Ajax.<\/p>\n\n<p>The Azure ML gives sample code for C#, Python and R.<\/p>\n\n<p>I did try out to call the webservice using JQuery Ajax but it returns a failure.<\/p>\n\n<p>I am able to call the same service using a python script.<\/p>\n\n<p>Here is my Ajax code : <\/p>\n\n<pre><code>  $.ajax({\n        url: webserviceurl,\n        type: \"POST\",           \n        data: sampleData,            \n        dataType:'jsonp',                        \n        headers: {\n        \"Content-Type\":\"application\/json\",            \n        \"Authorization\":\"Bearer \" + apiKey                       \n        },\n        success: function (data) {\n          console.log('Success');\n        },\n        error: function (data) {\n           console.log('Failure ' +  data.statusText + \" \" + data.status);\n        },\n  });\n<\/code><\/pre>",
        "Challenge_closed_time":1464718210400,
        "Challenge_comment_count":2,
        "Challenge_created_time":1464104729493,
        "Challenge_favorite_count":1.0,
        "Challenge_last_edit_time":1526047792276,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/37418265",
        "Challenge_link_count":0,
        "Challenge_participation_count":5,
        "Challenge_readability":7.9,
        "Challenge_reading_time":9.3,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":2.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":8,
        "Challenge_solved_time":170.4113630556,
        "Challenge_title":"Azure Machine Learning using Javascript Ajax call",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":1607.0,
        "Challenge_word_count":94,
        "Platform":"Stack Overflow",
        "Poster_created_time":1460664823627,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":81.0,
        "Poster_view_count":6.0,
        "Solution_body":"<p>Well after a lot of RnD, I was able to finally call Azure ML using some workarounds.<\/p>\n\n<p>Wrapping Azure ML webservice on Azure API is one option.<\/p>\n\n<p>But, what I did was that I created a python webservice which calls the Azure webservice.<\/p>\n\n<p>So now my HTML App calls the python webservice which calls Azure ML and returns data to the HTML App.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":5.9,
        "Solution_reading_time":4.38,
        "Solution_score_count":2.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":63.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1619163566860,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":1730.0,
        "Answerer_view_count":555.0,
        "Challenge_adjusted_solved_time":15.7482980556,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Our use case is as follows:\nWe have multiple custom trained models (in the hundreds, and the number increases as we allow the user of our application to create models through the UI, which we then train and deploy on the fly) and so deploying each model to a separate endpoint is expensive as Vertex AI <a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/predictions\/deploy-model-console#custom-trained\" rel=\"nofollow noreferrer\">charges per node used<\/a>. Based on the <a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/general\/deployment#models-endpoint\" rel=\"nofollow noreferrer\">documentation<\/a> it seems that we can deploy models of different types to the same endpoint but I am not sure how that would work. Let's say I have 2 different custom trained models deployed using custom containers for prediction to the same endpoint. Also, say I specify the traffic split to be 50% for the two models. Now, how do I send a request to a specific model? Using the python SDK, we make calls to the endpoint, like so:<\/p>\n<pre><code>from google.cloud import aiplatform\nendpoint = aiplatform.Endpoint(endpoint_id)\nprediction = endpoint.predict(instances=instances)\n\n# where endpoint_id is the id of the endpoint and instances are the observations for which a prediction is required\n<\/code><\/pre>\n<p>My understanding is that in this scenario, vertex AI will route some calls to one model and some to the other based on the traffic split. I could use the parameters field, as specified in the <a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/predictions\/custom-container-requirements#prediction\" rel=\"nofollow noreferrer\">docs<\/a>, to specify the model and then process the request accordingly in the custom prediction container, but still some calls will end up going to a model which it will not be able to process (because Vertex AI is not going to be sending all requests to all models, otherwise the traffic split wouldn't make sense). How do I then deploy multiple models to the same endpoint and make sure that every prediction request is guaranteed to be served?<\/p>",
        "Challenge_closed_time":1636404890008,
        "Challenge_comment_count":9,
        "Challenge_created_time":1636348555970,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/69878915",
        "Challenge_link_count":3,
        "Challenge_participation_count":10,
        "Challenge_readability":12.3,
        "Challenge_reading_time":26.69,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":15,
        "Challenge_solved_time":15.6483438889,
        "Challenge_title":"Deploying multiple models to same endpoint in Vertex AI",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":1271.0,
        "Challenge_word_count":303,
        "Platform":"Stack Overflow",
        "Poster_created_time":1471292986790,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":700.0,
        "Poster_view_count":90.0,
        "Solution_body":"<p>This <a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/general\/deployment#models-endpoint\" rel=\"nofollow noreferrer\">documentation<\/a> talks about a use case where 2 models are trained on the same feature set and are sharing the ingress prediction traffic. As you have understood correctly, this does not apply to models that have been trained on different feature sets, that is, different models.<\/p>\n<p>Unfortunately, deploying different models to the same endpoint utilizing only one node is not possible in Vertex AI at the moment. There is an ongoing feature request that is being worked on. However, we cannot provide an exact ETA on when that feature will be available.<\/p>\n<p>I reproduced the multi-model setup and noticed the below points.<\/p>\n<p><strong>Traffic Splitting<\/strong><\/p>\n<blockquote>\n<p>I deployed 2 different models to the same endpoint and sent predictions to it. I set a 50-50 traffic splitting rule and saw errors that implied requests being sent to the wrong model.<\/p>\n<\/blockquote>\n<p><strong>Cost Optimization<\/strong><\/p>\n<blockquote>\n<p>When multiple models are deployed to the same endpoint, they are deployed to separate, independent nodes. So, you will still be charged for each node used. Also, node autoscaling happens at the model level, not at the endpoint level.<\/p>\n<\/blockquote>\n<p>A plausible workaround would be to pack all your models into a single container and use a custom HTTP server logic to send prediction requests to the appropriate model. This could be achieved using the <a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/predictions\/custom-container-requirements#request_requirements\" rel=\"nofollow noreferrer\"><code>parameters<\/code><\/a> field of the prediction request body. The custom logic would look something like this.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>@app.post(os.environ['AIP_PREDICT_ROUTE'])\nasync def predict(request: Request):\n    body = await request.json()\n    parameters = body[&quot;parameters&quot;]\n    instances = body[&quot;instances&quot;]\n    inputs = np.asarray(instances)\n    preprocessed_inputs = _preprocessor.preprocess(inputs)\n\n    if(parameters[&quot;model_name&quot;]==&quot;random_forest&quot;):\n        print(parameters[&quot;model_name&quot;])\n        outputs = _random_forest_model.predict(preprocessed_inputs)\n    else:\n        print(parameters[&quot;model_name&quot;])\n        outputs = _decision_tree_model.predict(inputs)\n\n    return {&quot;predictions&quot;: [_class_names[class_num] for class_num in outputs]}\n<\/code><\/pre>",
        "Solution_comment_count":5.0,
        "Solution_last_edit_time":1636405249843,
        "Solution_link_count":2.0,
        "Solution_readability":12.7,
        "Solution_reading_time":32.24,
        "Solution_score_count":1.0,
        "Solution_sentence_count":23.0,
        "Solution_word_count":273.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":245.3151869444,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am getting the following error from the Evaluate Model module in Azure Machine Learning Designer:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/101409-screenshot-2021-06-01-at-100708-pm.png?platform=QnA\" alt=\"101409-screenshot-2021-06-01-at-100708-pm.png\" \/>    <\/p>\n<p>When I open the Assigned Data to Clusters module everything seems fine. I downloaded the output for Assigned Data to Clusters and played with cluster number 31 and there doesn't seem to be any issue. Additionally, I am using Azure Modules, so I am confused as to why this is failing. Please provide some clarity into this issue. This is a part of my pipeline:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/101399-screenshot-2021-06-01-at-104512-pm.png?platform=QnA\" alt=\"101399-screenshot-2021-06-01-at-104512-pm.png\" \/>    <\/p>\n<p>Additionally, it seems unless I successfully run the Evaluate Model module, I cannot create an inference pipeline. If this is untrue, please help me out here as well. There is no option for me to 'Create an Inference Pipeline' which shown in <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-deploy\">this tutorial; step 1.<\/a>    <\/p>\n<p>Please let me know if you need any other information.    <\/p>\n<p>Thanks in advance.    <\/p>",
        "Challenge_closed_time":1623450957476,
        "Challenge_comment_count":3,
        "Challenge_created_time":1622567822803,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/418016\/ambiguous-error-in-azure-machine-learning-designer",
        "Challenge_link_count":3,
        "Challenge_participation_count":4,
        "Challenge_readability":11.7,
        "Challenge_reading_time":18.14,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":13,
        "Challenge_solved_time":245.3151869444,
        "Challenge_title":"Ambiguous error in Azure Machine Learning Designer 'Evaluate Model' Module",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":163,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Can you please check if the Assignment cluster 31 has NaN value? The <strong>Assign Data to Clusters<\/strong> leverages SKlearn, and from the error message, seems the Assignment column had NaN value which resulted in an error. If that's the case, let us know, so we can enable <strong>Evaluate<\/strong> Module module to deal with NaN values, and in the meantime, here's a short-term workaround:    <\/p>\n<ul>\n<li> Connect <strong>Clean Missing Data<\/strong> module to Assign Data to Cluster module, to clean the missing values.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/104943-image.png?platform=QnA\" alt=\"104943-image.png\" \/>    <\/li>\n<li> Use <strong>Edit Metadata<\/strong> module to convert Assignment to Integer and categorical type, this is because if Assignment column has NaN value before and its column type was double, we need to convert it to integer.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/104888-image.png?platform=QnA\" alt=\"104888-image.png\" \/>    <\/li>\n<li> Connect <strong>Edit Metadata<\/strong> to Evaluate Model module.    <\/li>\n<\/ul>\n<p>Hope this help!    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":12.6,
        "Solution_reading_time":14.44,
        "Solution_score_count":1.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":142.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1441691980488,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Seattle, WA, USA",
        "Answerer_reputation_count":860.0,
        "Answerer_view_count":44.0,
        "Challenge_adjusted_solved_time":30.4880244444,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>We have created an endpoint in Vertex AI. We have got the <a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/predictions\/online-predictions-custom-models\" rel=\"nofollow noreferrer\">client library<\/a> route working. However, we also want to figure out the gRPC route since that is closest to the gRPC route we had with self managed TF-Serving.\nCan someone provide a code pointer for Vertex AI model serving using gRPC (preferably in Python)?<\/p>",
        "Challenge_closed_time":1662511382056,
        "Challenge_comment_count":0,
        "Challenge_created_time":1662394780720,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1662401625168,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/73612214",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":10.0,
        "Challenge_reading_time":6.46,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":32.38926,
        "Challenge_title":"Vertex AI model serving - gRPC access - code pointers \/ samples",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":36.0,
        "Challenge_word_count":67,
        "Platform":"Stack Overflow",
        "Poster_created_time":1280773677816,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Jersey City, NJ",
        "Poster_reputation_count":4339.0,
        "Poster_view_count":479.0,
        "Solution_body":"<p>gRPC can be used through Vertex Prediction private endpoint, but it is not yet officially supported. See sample here: <a href=\"https:\/\/github.com\/GoogleCloudPlatform\/vertex-ai-samples\/blob\/main\/notebooks\/community\/vertex_endpoints\/optimized_tensorflow_runtime\/tabular_optimized_online_prediction.ipynb\" rel=\"nofollow noreferrer\">https:\/\/github.com\/GoogleCloudPlatform\/vertex-ai-samples\/blob\/main\/notebooks\/community\/vertex_endpoints\/optimized_tensorflow_runtime\/tabular_optimized_online_prediction.ipynb<\/a><\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":41.7,
        "Solution_reading_time":7.23,
        "Solution_score_count":2.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":23.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_created_time":1452696930640,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":746.0,
        "Answerer_view_count":112.0,
        "Challenge_adjusted_solved_time":54.3866655556,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Because of a faulty score.py file in my InferenceConfig, a Model.Deploy failed to Azure Machine Learning, using ACI.  I wanted to create the endpoint in the cloud, but the only state I can see in the portal is Unhealthy.  My local script to deploy the model (using ) keeps running, until it times out. (using the <code>service.wait_for_deployment(show_output=True)<\/code>statement).<\/p>\n\n<p>Is there an option to get more insights in the actual reason\/error message of the deployment turning \"Unhealthy\"?<\/p>",
        "Challenge_closed_time":1584133364176,
        "Challenge_comment_count":0,
        "Challenge_created_time":1583937572180,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1584215688008,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/60638587",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":7.4,
        "Challenge_reading_time":7.35,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":3.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":8,
        "Challenge_solved_time":54.3866655556,
        "Challenge_title":"How to get insights in exceptions and logging of AzureML endpoint deployment",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":364.0,
        "Challenge_word_count":85,
        "Platform":"Stack Overflow",
        "Poster_created_time":1360655430743,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Belgium",
        "Poster_reputation_count":2947.0,
        "Poster_view_count":355.0,
        "Solution_body":"<p>Usually the timeout is caused by an error in init() function in scoring script. You can get the detailed logs using <code>print(service.get_logs())<\/code> to find the Python error.<\/p>\n\n<p>For more comprehensive troubleshooting guide, see:<\/p>\n\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-deployment\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-deployment<\/a><\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":13.3,
        "Solution_reading_time":6.32,
        "Solution_score_count":2.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":37.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1550713581256,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Santiago, Chile",
        "Answerer_reputation_count":301.0,
        "Answerer_view_count":72.0,
        "Challenge_adjusted_solved_time":0.7812944445,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I've tried deleting\/recreating endpoints with the same name, and wasted a lot of time before I realized that changes do not get applied unless you also delete the corresponding Model and Endpoint configuration so that new ones can be created with that name. <\/p>\n\n<p>Is there a way with the sagemaker python api to delete all three instead of just the endpoint?<\/p>",
        "Challenge_closed_time":1550714082127,
        "Challenge_comment_count":0,
        "Challenge_created_time":1550711269467,
        "Challenge_favorite_count":1.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/54797698",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":11.2,
        "Challenge_reading_time":5.38,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":4.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":0.7812944445,
        "Challenge_title":"SageMaker delete Models and Endpoint configurations with python API",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":4760.0,
        "Challenge_word_count":70,
        "Platform":"Stack Overflow",
        "Poster_created_time":1361339272692,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"NYC",
        "Poster_reputation_count":6281.0,
        "Poster_view_count":958.0,
        "Solution_body":"<p>It looks like AWS is currently in the process of supporting model deletion via API with <a href=\"https:\/\/github.com\/aws\/sagemaker-python-sdk\/pull\/647\" rel=\"nofollow noreferrer\" title=\"sagemaker-python-sdk\/pull\/647\">this<\/a> pull request. <\/p>\n\n<p>For the time being Amazon's only <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/ex1-cleanup.html\" rel=\"nofollow noreferrer\" title=\"docs.aws.amazon.com\/sagemaker\">recommendation<\/a> is to delete everything via the console. <\/p>\n\n<p>If this is critical to your system you can probably manage everything via Cloud Formation and create\/delete services containing your Sagemaker models and endpoints.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":14.7,
        "Solution_reading_time":8.68,
        "Solution_score_count":2.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":67.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1342685175156,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Germany",
        "Answerer_reputation_count":12103.0,
        "Answerer_view_count":1451.0,
        "Challenge_adjusted_solved_time":12.8997730556,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I am able to deploy a Azure Machine learning prediction service in my workspace <code>ws<\/code> using the syntax<\/p>\n\n<pre><code>aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n                                               memory_gb=8, \n                                               tags={\"method\" : \"some method\"}, \n                                               description='Predict something')\n<\/code><\/pre>\n\n<p>and then<\/p>\n\n<pre><code>service = Webservice.deploy_from_image(deployment_config = aciconfig,\n                                       image = image,\n                                       name = service_name,\n                                       workspace = ws)\n<\/code><\/pre>\n\n<p>as described in the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-deploy-and-where#aci\" rel=\"nofollow noreferrer\">documentation<\/a>.<br>\nHowever, this exposes a service publicly and this is not really optimal.<\/p>\n\n<p>What's the easiest way to shield the ACI service? I understand that passing an <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.webservice.aciwebservice?view=azure-ml-py#deploy-configuration-cpu-cores-none--memory-gb-none--tags-none--properties-none--description-none--location-none--auth-enabled-none--ssl-enabled-none--enable-app-insights-none--ssl-cert-pem-file-none--ssl-key-pem-file-none--ssl-cname-none-\" rel=\"nofollow noreferrer\"><code>auth_enabled=True<\/code><\/a> parameter may do the job, but then how can I instruct a client (say, using <code>curl<\/code> or Postman) to use the service afterwards? <\/p>",
        "Challenge_closed_time":1556182170523,
        "Challenge_comment_count":0,
        "Challenge_created_time":1556135731340,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1556186547292,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/55837639",
        "Challenge_link_count":2,
        "Challenge_participation_count":2,
        "Challenge_readability":18.8,
        "Challenge_reading_time":19.24,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":12.8997730556,
        "Challenge_title":"How to enable authentication for an ACI webservice in Azure Machine Learning service?",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":676.0,
        "Challenge_word_count":113,
        "Platform":"Stack Overflow",
        "Poster_created_time":1415722650716,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Verona, VR, Italy",
        "Poster_reputation_count":4811.0,
        "Poster_view_count":713.0,
        "Solution_body":"<p>See <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-consume-web-service#call-the-service-c\" rel=\"nofollow noreferrer\">here<\/a> for an example (in C#). When you enable auth, you will need to send the API key in the \"Authorization\" header in the HTTP request:<\/p>\n\n<pre><code>client.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue(\"Bearer\", authKey);\n<\/code><\/pre>\n\n<p>See <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-consume-web-service#authentication-key\" rel=\"nofollow noreferrer\">here<\/a> how to retrieve the key.<\/p>",
        "Solution_comment_count":4.0,
        "Solution_last_edit_time":1556183204092,
        "Solution_link_count":2.0,
        "Solution_readability":19.8,
        "Solution_reading_time":8.26,
        "Solution_score_count":2.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":45.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1302088276340,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Dubai, United Arab Emirates",
        "Answerer_reputation_count":5263.0,
        "Answerer_view_count":637.0,
        "Challenge_adjusted_solved_time":1.5271127778,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>Working on a IoT telemetry project that receives humidity and weather pollution data from different sites on the field. I will then apply Machine Learning on the collected data. I'm using Event Hubs and Stream Analytics. Is there a way of pulling the data to Azure Machine Learning without the hassle of writing an application to get it from Stream Analytics and push to AML web service?<\/p>",
        "Challenge_closed_time":1467284456456,
        "Challenge_comment_count":0,
        "Challenge_created_time":1467278958850,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/38119062",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":9.1,
        "Challenge_reading_time":5.6,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":1.5271127778,
        "Challenge_title":"Pulling data from Stream Analytics to Azure Machine Learning",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":627.0,
        "Challenge_word_count":75,
        "Platform":"Stack Overflow",
        "Poster_created_time":1311017514580,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Beirut, Lebanon",
        "Poster_reputation_count":408.0,
        "Poster_view_count":32.0,
        "Solution_body":"<p>Stream Analytics has a functionality called the \u201c<a href=\"https:\/\/blogs.technet.microsoft.com\/machinelearning\/2015\/12\/10\/azure-ml-now-available-as-a-function-in-azure-stream-analytics\/\" rel=\"nofollow\">Functions<\/a>\u201d. You can call any web service you\u2019ve published using AML from within Stream Analytics and apply it within your Stream Analytics query. Check this <a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/stream-analytics-machine-learning-integration-tutorial\/\" rel=\"nofollow\">link for a tutorial<\/a>.\nExample workflow in your case would be like the following;<\/p>\n\n<ul>\n<li>Telemetry arrives and reaches Stream Analytics<\/li>\n<li>Streaming Analytics (SA) calls the Machine Learning function to apply it on the data<\/li>\n<li>SA redirects it to the output accordingly, here you can use the PowerBI to create a predictions dashboards.<\/li>\n<\/ul>\n\n<p>Another way would be using R, and here\u2019s a good tutorial showing that <a href=\"https:\/\/blogs.technet.microsoft.com\/machinelearning\/2015\/12\/10\/azure-ml-now-available-as-a-function-in-azure-stream-analytics\/\" rel=\"nofollow\">https:\/\/blogs.technet.microsoft.com\/machinelearning\/2015\/12\/10\/azure-ml-now-available-as-a-function-in-azure-stream-analytics\/<\/a> . \nIt is more work of course but can give you more control as you control the code.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":4.0,
        "Solution_readability":19.6,
        "Solution_reading_time":17.45,
        "Solution_score_count":3.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":123.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1343167997556,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":191.0,
        "Answerer_view_count":27.0,
        "Challenge_adjusted_solved_time":132.4537347222,
        "Challenge_answer_count":2,
        "Challenge_body":"<h2><strong>ASKING THIS HERE AT THE EXPLICIT REQUEST OF THE MICROSOFT AZURE SUPPORT TEAM.<\/strong><\/h2>\n\n<p>I've been attempting to call the MS Luis.ai <em>programmatic<\/em> API (bit.ly\/2iev01n) and have been receiving a 401 unauthorized response to every request. Here's a simple GET example: <code>https:\/\/api.projectoxford.ai\/luis\/v1.0\/prog\/apps\/{appId}\/entities?subscription-key={subscription_key}<\/code>.  <\/p>\n\n<p>I am providing my appId from the Luis.ai GUI (as specified by the API docs), here:<br>\n<img src=\"https:\/\/i.stack.imgur.com\/Cg2Fw.png\" alt=\"Luis.ai App Settings App Id\"><\/p>\n\n<p>I am providing my subscription key from Azure (as specified by the API docs), here:<br>\n<img src=\"https:\/\/i.stack.imgur.com\/GS2Fe.png\" alt=\"Azure Console\"><\/p>\n\n<p>The app ID and subscription key, sourced from above, are the exact same as what I'm using to hit the query API successfully (see note at bottom). My account is pay-as-you-go (not free).<\/p>\n\n<p><strong><em>Am I doing something wrong here? Is this API deprecated, moved, down, or out-of-sync with the docs?<\/em><\/strong><\/p>\n\n<p><strong>NOTE:<\/strong> I can manipulate my model through the online GUI but that approach will be far too manual for our business needs where our model will need to be programmatically updated as new business entities come into existence.  <\/p>\n\n<p><strong>NOTE:<\/strong> The programmatic API is different from the query API which has this request URL, which is working fine for me:<br>\n<code>https:\/\/api.projectoxford.ai\/luis\/v2.0\/apps\/{appId}?subscription-key={subscription_key}&amp;verbose=true&amp;q={utterance}<\/code>  <\/p>\n\n<p><strong>NOTE:<\/strong> There doesn't seem to be a Luis.ai programmatic API for v2.0--which is why the URLs from the query and programmatic APIs have different versions.  <\/p>",
        "Challenge_closed_time":1484669845332,
        "Challenge_comment_count":2,
        "Challenge_created_time":1484180085280,
        "Challenge_favorite_count":1.0,
        "Challenge_last_edit_time":1484193011887,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/41603082",
        "Challenge_link_count":4,
        "Challenge_participation_count":4,
        "Challenge_readability":10.4,
        "Challenge_reading_time":23.71,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":4.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":19,
        "Challenge_solved_time":136.0444588889,
        "Challenge_title":"401 Errors Calling the Microsoft Luis.ai Programmatic API",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":1280.0,
        "Challenge_word_count":229,
        "Platform":"Stack Overflow",
        "Poster_created_time":1343167997556,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":191.0,
        "Poster_view_count":27.0,
        "Solution_body":"<p>Answering my own question here:<\/p>\n\n<p>I have found my LUIS.ai programmatic API key. It is found by:\nLUIS.ai dashboard -> username (upper-right) -> settings in dropdown -> Subscription Keys tab -> Programmatic API Key<\/p>\n\n<p>It was not immediately obvious since it's found nowhere else: not alongside any of the other key listings in cognitive services or the LUIS.<\/p>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":8.6,
        "Solution_reading_time":4.63,
        "Solution_score_count":7.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":54.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":40.3672083333,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Using API Management - can I import from a Swagger JSON file definition AND where that endpoint requires the following injection to a header so that it can call\/retrieve that Swagger JSON?<\/p>\n<p>The API in question is actually an Azure Machine Learning Online Endpoint - and that contains a Swagger JSON definition. In order to see the definition you have to inject the following header records into the HTTP call...<\/p>\n<pre><code>Authorization: Bearer longRandomtokengeneratedbyAML12345\nazureml-model-deployment: nameofmyamlmodeldendpointdeployment\n<\/code><\/pre>\n<p>Using API Management - can I somehow import this Swagger JSON ? I can't find a way to reach the endpoint and specify the x2 header records it requires<\/p>\n<p>Thanks<\/p>",
        "Challenge_closed_time":1675215836676,
        "Challenge_comment_count":1,
        "Challenge_created_time":1675070514726,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1165334\/api-management-can-you-import-from-swagger-json-th",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":11.9,
        "Challenge_reading_time":10.39,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":40.3672083333,
        "Challenge_title":"API Management - Can you import from Swagger JSON that requires HTTP Header records?",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":114,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>@<a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=0ec06fb6-513e-4f5c-9aff-281bc5e44e22\">Neil McAlister<\/a> Thanks for posting it in Microsoft Q&amp;A. Based on the statement above, it looks like you are importing Swagger JSON to APIM via portal, CLI or PowerShell with specification URL, correct?<\/p>\n<p>If so, unfortunately that's not possible right now. There is no way to specify headers with <code>--specification-url<\/code> in <a href=\"https:\/\/learn.microsoft.com\/en-us\/cli\/azure\/apim\/api?view=azure-cli-latest#az-apim-api-import\">az apim api import<\/a> (or <a href=\"https:\/\/learn.microsoft.com\/en-us\/powershell\/module\/az.apimanagement\/import-azapimanagementapi\">Import-AzApiManagementApi<\/a> - PowerShell) and you would need to download swagger JSON in your pipeline and then use it with <code>--specification-path<\/code>(check size limitation when using this parameter <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/api-management\/api-management-api-import-restrictions#openapi-specifications\">here<\/a>) or place it in another location where APIM can directly access it. <\/p>\n<p>If you are interested in this feature and like to submit feedback to our product team, please submit it via <a href=\"https:\/\/aka.ms\/apimwish\">https:\/\/aka.ms\/apimwish<\/a> and would help our product team to prioritize the features. Also, others with similar interests can upvote it too.<\/p>\n<p>Feel free to reach out if you have any other questions.<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":5.0,
        "Solution_readability":14.5,
        "Solution_reading_time":19.13,
        "Solution_score_count":0.0,
        "Solution_sentence_count":11.0,
        "Solution_word_count":151.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1549666221947,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":56.0,
        "Answerer_view_count":4.0,
        "Challenge_adjusted_solved_time":2121.3562466667,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have created 2 models which are not too complex and renamed them and placed them into a same location in S3 bucket.<\/p>\n\n<p>I need to create a multi model endpoint such that the 2 models have a same end point. \nThe model i am using is AWS in built Linear-learner model type regressor. <\/p>\n\n<p>I am stuck as to how they should be deployed. <\/p>",
        "Challenge_closed_time":1582590253856,
        "Challenge_comment_count":1,
        "Challenge_created_time":1574954456480,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/59091944",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":6.7,
        "Challenge_reading_time":4.82,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":2121.0548266667,
        "Challenge_title":"Create a Multi Model Endpoint using AWS Sagemaker Boto",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":364.0,
        "Challenge_word_count":74,
        "Platform":"Stack Overflow",
        "Poster_created_time":1574954057270,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Carlow, Ireland",
        "Poster_reputation_count":13.0,
        "Poster_view_count":0.0,
        "Solution_body":"<p>SageMaker's Linear Learner algorithm container does not currently implement the requirements for <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/build-multi-model-build-container.html\" rel=\"nofollow noreferrer\">multi-model endpoints<\/a>. You could request support in the <a href=\"https:\/\/forums.aws.amazon.com\/forum.jspa?forumID=285&amp;start=0\" rel=\"nofollow noreferrer\">AWS Forums<\/a>.<\/p>\n\n<p>You could also build your own version of the Linear Learner algorithm. To deploy the models to a multi-model endpoint you would need to build your own container that meets the requirements for multi-model endpoints and implement your own version of the Linear Learner algorithm. This sample notebook gives an example of how you would create your multi-model compatible container that serves MxNet models, but you could adapt it to implement a Linear Learner algorithm:<\/p>\n\n<p><a href=\"https:\/\/github.com\/awslabs\/amazon-sagemaker-examples\/blob\/master\/advanced_functionality\/multi_model_bring_your_own\/multi_model_endpoint_bring_your_own.ipynb\" rel=\"nofollow noreferrer\">https:\/\/github.com\/awslabs\/amazon-sagemaker-examples\/blob\/master\/advanced_functionality\/multi_model_bring_your_own\/multi_model_endpoint_bring_your_own.ipynb<\/a><\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1582591338968,
        "Solution_link_count":4.0,
        "Solution_readability":21.5,
        "Solution_reading_time":16.66,
        "Solution_score_count":0.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":107.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1631803441500,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"mexico",
        "Answerer_reputation_count":1258.0,
        "Answerer_view_count":685.0,
        "Challenge_adjusted_solved_time":26.1469897223,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am trying to un-deploy model from an endpoint following <a href=\"https:\/\/cloud.google.com\/python\/docs\/reference\/aiplatform\/latest\/google.cloud.aiplatform.Endpoint#google_cloud_aiplatform_Endpoint_undeploy\" rel=\"nofollow noreferrer\">this documentation<\/a>.<\/p>\n<pre><code>Endpoint.undeploy(deployed_model_id=model_id)\n<\/code><\/pre>\n<p>I even tried <a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/reference\/rest\/v1\/projects.locations.endpoints\/undeployModel\" rel=\"nofollow noreferrer\">google api<\/a>. Same Issue with this as well.<\/p>\n<p>Getting 404 error<\/p>\n<blockquote>\n<p>The Deployed Model with ID <code>2367889687867<\/code> is missing.<\/p>\n<\/blockquote>\n<p><strong>INFO:<\/strong><\/p>\n<ol>\n<li>Both model and Endpoint are in same region.<\/li>\n<li>There is a single model deployed in the endpoint with <code>traffic_percentage=100<\/code>.<\/li>\n<\/ol>",
        "Challenge_closed_time":1655314821510,
        "Challenge_comment_count":4,
        "Challenge_created_time":1655220692347,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1655954014260,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/72619696",
        "Challenge_link_count":2,
        "Challenge_participation_count":5,
        "Challenge_readability":16.2,
        "Challenge_reading_time":12.97,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":26.1469897223,
        "Challenge_title":"GCP AI Platform Vertex endpoint model undeploy : 404 The DeployedModel with ID `2367889687867` is missing",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":271.0,
        "Challenge_word_count":80,
        "Platform":"Stack Overflow",
        "Poster_created_time":1550779047856,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":363.0,
        "Poster_view_count":9.0,
        "Solution_body":"<p>The <code>deployed_model_id<\/code> is different from the <code>model_id<\/code>.That\u2019s why you are getting the Error 404, it is searching for something that is not the same.<\/p>\n<p>You can get the <code>deployed_model_id<\/code> by:<\/p>\n<ul>\n<li>list_models()<\/li>\n<li>list()<\/li>\n<\/ul>\n<p>Using <code>list_models()<\/code> brings you a list of all the deployed models ids, while using <code>list()<\/code> only brings one, you can add filters such as <code>display_name<\/code>, <code>model_id<\/code>, <code>region<\/code>, etc.<\/p>\n<pre><code>list(\n    filter= \u2018display_name= \u201cdisplay_name\u201d\u2019,\n)\n<\/code><\/pre>\n<p>You also can get the <code>deployed_model_id<\/code> using the Cloud SDK.<\/p>\n<pre><code>gcloud ai models list --region=$REGION --filter=&quot;DISPLAY_NAME: $NAME&quot; | grep &quot;MODEL_ID&quot; | cut -f2 -d: | sed 's\/\\s\/\/'\n<\/code><\/pre>\n<p>Additionally, you can specify the <code>deployed_model_id<\/code> when you are deploying your model using Cloud SDK the command should look like:<\/p>\n<pre><code>gcloud ai endpoints deploy-model $endpoint --project=$project --region=$region --model=$model_id --display-name=$model_name --deployed-model-id=$deployed_model_id\n<\/code><\/pre>\n<p>There are some flags that are required when you deploy a model such as endpoint, project, region, model and display name. And there are others that are <a href=\"https:\/\/cloud.google.com\/sdk\/gcloud\/reference\/ai\/endpoints\/deploy-model#:%7E:text=the%20uploaded%20model.-,OPTIONAL%20FLAGS,-%2D%2Daccelerator%3D%5Bcount\" rel=\"nofollow noreferrer\">optional flags<\/a> that you can use deployed_model_id is one of them.(I don\u2019t know if this is possible but you could set the deployed_model_id as the same as the model_id).<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":15.7,
        "Solution_reading_time":22.36,
        "Solution_score_count":1.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":182.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":26.8941822222,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi All    <\/p>\n<p>I have been working with Azure Machine Learning Studio (Classic) and have always found its integration with Excel super mega useful.    <\/p>\n<p>All I had to do was to get the URI and the API_Key of my web service and paste them on the Azure Machine Learning Add-In, that I had downloaded. Easy and useful.    <\/p>\n<p>However, with the new Azure Machine Learning studio that does not seem possible any more.     <\/p>\n<p>Under the new Azure Machine Learning studio when I deploy a model I get a REST endpoint and that's it? !? I cannot find anywhere the API_key for my web service. I cannot even find a web service section  as such.     <\/p>\n<ol>\n<li> How do I get the API_Key for the web service I need?    <\/li>\n<li> If I get the API_Key could I use it on the Excel Azure Machine Learning add-in. It looks as if this is no longer an option and we need to start using Power BI instead.    <\/li>\n<li>  I have read this interesting post where someone mentions a work around that consist of creating an Excel macro. Is this the best option? <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/236781\/consume-scoreing-api-in-excel.html\">https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/236781\/consume-scoreing-api-in-excel.html<\/a>     <\/li>\n<\/ol>\n<p>Thank you    <\/p>",
        "Challenge_closed_time":1651319301696,
        "Challenge_comment_count":0,
        "Challenge_created_time":1651222482640,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/831512\/new-azure-machine-learning-excel",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":7.8,
        "Challenge_reading_time":16.07,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":14,
        "Challenge_solved_time":26.8941822222,
        "Challenge_title":"New Azure Machine Learning & Excel",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":204,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hi, thanks for reaching out. The new AzureML integration with Excel isn't supported at this time. More details are provided on this <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/778717\/replacement-for-azure-ml-classic-excel-add-in.html\">thread<\/a>. The alternative approach would be to use a Client or PowerBI to <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service?tabs=python\">consume<\/a> the model. For future reference, you can find your webservice endpoint and keys under Studio &gt; Endpoints &gt; Endpoint &gt; Consume.    <\/p>\n<p>--please don't forget to <code>Accept Answer<\/code> if the reply is helpful. Thanks.--<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":10.8,
        "Solution_reading_time":8.99,
        "Solution_score_count":0.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":72.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1424453610300,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":1237.0,
        "Answerer_view_count":116.0,
        "Challenge_adjusted_solved_time":5.6297925,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I'm using Microsoft Azure Machine Learning and was wondering if anyone had done some experiments on date time features. Doe sit automatically derive additional features like \"day of week\", \"day of month\", \"hour of day\" from them, or do I have to provide these?<\/p>\n\n<p>I could not find any info in the official documentation (and a lack of a Microsoft support forum =)<\/p>",
        "Challenge_closed_time":1434736380420,
        "Challenge_comment_count":2,
        "Challenge_created_time":1434716113167,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1445833326870,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/30937903",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":10.3,
        "Challenge_reading_time":5.41,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":5.6297925,
        "Challenge_title":"How are date features utilized in Microsoft Azure Machine Studio",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":806.0,
        "Challenge_word_count":72,
        "Platform":"Stack Overflow",
        "Poster_created_time":1221999894423,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Delaware",
        "Poster_reputation_count":2603.0,
        "Poster_view_count":225.0,
        "Solution_body":"<p>Azure ML supports \"execute-R\" module which can be easily used to accomplish this in R - few examples below<\/p>\n\n<p>x&lt;-as.Date(\"12\/3\/2009\", \"%m\/%d\/%Y\")<\/p>\n\n<blockquote>\n  <p>months.Date(x)<\/p>\n<\/blockquote>\n\n<p>[1] \"December\"<\/p>\n\n<blockquote>\n  <p>weekdays.Date(x)<\/p>\n<\/blockquote>\n\n<p>[1] \"Thursday\"<\/p>\n\n<blockquote>\n  <p>quarters(x)<\/p>\n<\/blockquote>\n\n<p>[1] \"Q4\"<\/p>",
        "Solution_comment_count":2.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":10.3,
        "Solution_reading_time":4.85,
        "Solution_score_count":2.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":35.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1421401313787,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":326.0,
        "Answerer_view_count":21.0,
        "Challenge_adjusted_solved_time":7.6450513889,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am running the below code to store tags and then to retrieve them. As you can see below, Mlflow is storing one set of tags and returning another.<\/p>\n<pre><code>import mlflow\nwith mlflow.start_run() as active_run:\n    tw = { &quot;run_id&quot;: 1}\n    mlflow.set_tags(tw)            \n    print(&quot;Tags are &quot;, active_run.data.tags)\n    print(type(active_run.data.tags))\n<\/code><\/pre>\n<p>Output<\/p>\n<pre><code>Tags are  {'mlflow.source.name': '\/media\/Space\/AI\/anaconda4\/lib\/python3.7\/site-packages\/ipykernel_launcher.py', 'mlflow.source.type': 'LOCAL', 'mlflow.user': 'adeel'}\n<\/code><\/pre>\n<p>Looking at the stored tags through mlflow ui, I can see that the tag &quot;run_id&quot; set by the code is actually stored in the run. However, only the header information of the run seems to be getting returned by active_run.data.tags.<\/p>",
        "Challenge_closed_time":1610128097448,
        "Challenge_comment_count":0,
        "Challenge_created_time":1610100575263,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1611139529420,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/65627039",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":7.3,
        "Challenge_reading_time":11.12,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":10,
        "Challenge_solved_time":7.6450513889,
        "Challenge_title":"MLflow stores tags but does not return them",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":173.0,
        "Challenge_word_count":102,
        "Platform":"Stack Overflow",
        "Poster_created_time":1445990517172,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Sydney, New South Wales, Australia",
        "Poster_reputation_count":689.0,
        "Poster_view_count":87.0,
        "Solution_body":"<p>At the moment, you have to query your run again in MLflow to get the run with all the info that you logged. In the example below, I call <code>mlflow.get_run(&lt;run_id&gt;)<\/code> to achieve this.<\/p>\n<pre><code>import mlflow\n\n\nwith mlflow.start_run() as active_run:\n  tags = { &quot;my_tag&quot;: 1}\n  mlflow.set_tags(tags)            \n  # Keep track of the run ID of the active run\n  run_id = active_run.info.run_id\n\nrun = mlflow.get_run(run_id)\nprint(&quot;The tags are &quot;, run.data.tags)\n<\/code><\/pre>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":4.0,
        "Solution_reading_time":6.21,
        "Solution_score_count":2.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":63.0,
        "Tool":"MLflow"
    },
    {
        "Answerer_created_time":1454844135036,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"T\u00fcrkiye",
        "Answerer_reputation_count":462.0,
        "Answerer_view_count":83.0,
        "Challenge_adjusted_solved_time":151.3788311111,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I am trying out <strong>Amazon Sagemaker<\/strong>, I haven't figured out how we can have Continuous training.\n<br>\nFor example if i have a CSV file in s3 and I want to train each time the CSV file is updated.<\/p>\n\n<p>I know we can go again to the notebook and re-run the whole notebook to make this happen.\n<br>\nBut i am looking for an automated way, with some python scripts or using a lambda function with s3 events etc<\/p>",
        "Challenge_closed_time":1530199631932,
        "Challenge_comment_count":3,
        "Challenge_created_time":1529654311630,
        "Challenge_favorite_count":1.0,
        "Challenge_last_edit_time":1529654668140,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/50983316",
        "Challenge_link_count":0,
        "Challenge_participation_count":5,
        "Challenge_readability":7.3,
        "Challenge_reading_time":5.57,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":4.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":151.4778616667,
        "Challenge_title":"Continuous Training in Sagemaker",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":1191.0,
        "Challenge_word_count":82,
        "Platform":"Stack Overflow",
        "Poster_created_time":1440734188430,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"India",
        "Poster_reputation_count":1491.0,
        "Poster_view_count":112.0,
        "Solution_body":"<p>You can use boto3 sdk for python to start training on lambda then you need to trigger the lambda when csv is update.<\/p>\n\n<blockquote>\n  <p><a href=\"http:\/\/boto3.readthedocs.io\/en\/latest\/reference\/services\/sagemaker.html\" rel=\"nofollow noreferrer\">http:\/\/boto3.readthedocs.io\/en\/latest\/reference\/services\/sagemaker.html<\/a><\/p>\n<\/blockquote>\n\n<p>Example python code<\/p>\n\n<blockquote>\n  <p><a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/ex1-train-model-create-training-job.html\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/ex1-train-model-create-training-job.html<\/a><\/p>\n<\/blockquote>\n\n<p>Addition: You dont need to use lambda you just start\/cronjob the python script any kind of instance which has python and aws sdk in it.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":4.0,
        "Solution_readability":18.0,
        "Solution_reading_time":10.3,
        "Solution_score_count":2.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":63.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1221667848150,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Seattle, WA",
        "Answerer_reputation_count":849.0,
        "Answerer_view_count":142.0,
        "Challenge_adjusted_solved_time":1013.8935497222,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>AWS pricing page describes how much it costs per hour to run AWS Sagemaker for online realtime inference.\n<a href=\"https:\/\/aws.amazon.com\/sagemaker\/pricing\/\" rel=\"nofollow noreferrer\">https:\/\/aws.amazon.com\/sagemaker\/pricing\/<\/a><\/p>\n<p>But AWS usually also charges for API requests.\nDo they charge extra per every API inference request to the Sagemaker model?<\/p>",
        "Challenge_closed_time":1608159311612,
        "Challenge_comment_count":0,
        "Challenge_created_time":1604509294833,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/64684503",
        "Challenge_link_count":2,
        "Challenge_participation_count":1,
        "Challenge_readability":10.7,
        "Challenge_reading_time":5.38,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":1013.8935497222,
        "Challenge_title":"Does AWS Sagemaker charges you per API request?",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":187.0,
        "Challenge_word_count":50,
        "Platform":"Stack Overflow",
        "Poster_created_time":1501710710163,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"London, \u0412\u0435\u043b\u0438\u043a\u043e\u0431\u0440\u0438\u0442\u0430\u043d\u0438\u044f",
        "Poster_reputation_count":404.0,
        "Poster_view_count":25.0,
        "Solution_body":"<p>I am on the AWS SageMaker team.  For &quot;Real-Time Inference&quot; you are only charged for:<\/p>\n<ol>\n<li>usage of the instance types you choose (instance hours)<\/li>\n<li>storage attached to those instance (GB storage hours)<\/li>\n<li>data in and out of your Endpoint (Bytes in\/out)<\/li>\n<\/ol>\n<p>See &quot;Pricing Example #6: Real-Time Inference&quot; as well.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":13.2,
        "Solution_reading_time":4.67,
        "Solution_score_count":1.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":51.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":56.8854483334,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>My question centers around working with AML models that have been published as web services, as described here:    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service?tabs=azure-portal\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service?tabs=azure-portal<\/a>    <\/p>\n<p>Are there any endpoints or ways of obtaining more detailed information about a published model? For example, the documentation states that inputs to the model are passed in via a &quot;data&quot; property, and obviously, this will vary my the model:    <\/p>\n<p>{    <br \/>\n    &quot;data&quot;:  <br \/>\n        [  <br \/>\n            &lt;model-specific-data-structure&gt;  <br \/>\n        ]  <br \/>\n}    <\/p>\n<p>Is there a way to programatically find out what the model expects as input?     <\/p>\n<p>The full 'wish-list' of metadata info we'd like is listed here:     <\/p>\n<ul>\n<li> What models are available for serving    <\/li>\n<li> What is the model prediction endpoint    <\/li>\n<li> What are the required inputs and their data types    <\/li>\n<li> What are the model outputs and data types    <\/li>\n<\/ul>\n<p>Are there any endpoints or any way at getting to this information?    <\/p>",
        "Challenge_closed_time":1649630016347,
        "Challenge_comment_count":0,
        "Challenge_created_time":1649425228733,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/805976\/endpoints-for-getting-metadata-about-published-mod",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":16.7,
        "Challenge_reading_time":15.47,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":56.8854483334,
        "Challenge_title":"Endpoints for getting metadata about published models?",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":157,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=32325e98-f4ed-442a-83f3-7d1edc203dea\">@MK RP  <\/a>    <\/p>\n<p>Thanks for reaching out to us, I will answer your question below, at the meantime, if you feel like I am not getting your point well, please point it out and correct me.    <\/p>\n<p>I think you are mentioning how to monitor published model and collect data, there are several choice depends on the data you want to collect:    <\/p>\n<ol>\n<li> Collect data from models in production - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-enable-data-collection\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-enable-data-collection<\/a>    <\/li>\n<\/ol>\n<p>The following data can be collected:    <\/p>\n<p><strong>Model input data<\/strong> from web services deployed in an AKS cluster. Voice audio, images, and video are not collected.    <br \/>\n<strong>Model predictions<\/strong> using production input data.    <\/p>\n<p>Once collection is enabled, the data you collect helps you:    <\/p>\n<p>Monitor data drifts on the production data you collect.    <br \/>\nAnalyze collected data using Power BI or Azure Databricks    <br \/>\nMake better decisions about when to retrain or optimize your model.    <br \/>\nRetrain your model with the collected data.    <\/p>\n<p>2 . Monitor and collect data from ML web service endpoints - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-enable-app-insights\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-enable-app-insights<\/a>    <\/p>\n<p>You can use Azure Application Insights to collect the following data from an endpoint:    <\/p>\n<p>Output data    <br \/>\nResponses    <br \/>\nRequest rates, response times, and failure rates    <br \/>\nDependency rates, response times, and failure rates    <br \/>\nExceptions    <\/p>\n<p>3 . More details from Data Drift - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-monitor-datasets?tabs=python\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-monitor-datasets?tabs=python<\/a>    <\/p>\n<p>With Azure Machine Learning dataset monitors (preview), you can:    <\/p>\n<p>Analyze drift in your data to understand how it changes over time.    <br \/>\nMonitor model data for differences between training and serving datasets. Start by collecting model data from deployed models.    <br \/>\nMonitor new data for differences between any baseline and target dataset.    <br \/>\nProfile features in data to track how statistical properties change over time.    <br \/>\nSet up alerts on data drift for early warnings to potential issues.    <br \/>\nCreate a new dataset version when you determine the data has drifted too much.    <\/p>\n<p>Hope above information helps, please let us know if you need further helps!    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p><em>-Please kindly accept the answer if you feel helpful, thanks a lot.<\/em>    <\/p>\n",
        "Solution_comment_count":6.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":3.0,
        "Solution_readability":12.1,
        "Solution_reading_time":35.96,
        "Solution_score_count":0.0,
        "Solution_sentence_count":21.0,
        "Solution_word_count":349.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1324988509368,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Moscow, Russia",
        "Answerer_reputation_count":1593.0,
        "Answerer_view_count":93.0,
        "Challenge_adjusted_solved_time":812.6895558333,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am trying to Invoke Endpoint, previously deployed on Amazon SageMaker.\nHere is my code:<\/p>\n\n<pre><code>import numpy as np\nimport boto3\n\nclient = boto3.client('sagemaker-runtime')\n\ndef np2csv(arr):\n    csv = io.BytesIO()\n    np.savetxt(csv, arr, delimiter=',', fmt='%g')\n    return csv.getvalue().decode().rstrip()\n\nendpoint_name = 'DEMO-XGBoostEndpoint-2018-12-12-22-07-28'\ntest_vector = np.array([3.60606061e+00, \n                        3.91395664e+00, \n                        1.34200000e+03, \n                        4.56100000e+03,\n                        2.00000000e+02, \n                        2.00000000e+02]) \ncsv_test_vector = np2csv(test_vector)\n\nresponse = client.invoke_endpoint(EndpointName=endpoint_name,\n                               ContentType='text\/csv',\n                               Body=csv_test_vector)\n<\/code><\/pre>\n\n<p>And here is the error I get:<\/p>\n\n<blockquote>\n  <p>ModelErrorTraceback (most recent call last)\n   in ()\n        1 response = client.invoke_endpoint(EndpointName=endpoint_name,\n        2                                    ContentType='text\/csv',\n  ----> 3                                    Body=csv_test_vector)<\/p>\n  \n  <p>\/home\/ec2-user\/anaconda3\/envs\/python2\/lib\/python2.7\/site-packages\/botocore\/client.pyc\n  in _api_call(self, *args, **kwargs)\n      318                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n      319             # The \"self\" in this scope is referring to the BaseClient.\n  --> 320             return self._make_api_call(operation_name, kwargs)\n      321 \n      322         _api_call.<strong>name<\/strong> = str(py_operation_name)<\/p>\n  \n  <p>\/home\/ec2-user\/anaconda3\/envs\/python2\/lib\/python2.7\/site-packages\/botocore\/client.pyc\n  in _make_api_call(self, operation_name, api_params)\n      621             error_code = parsed_response.get(\"Error\", {}).get(\"Code\")\n      622             error_class = self.exceptions.from_code(error_code)\n  --> 623             raise error_class(parsed_response, operation_name)\n      624         else:\n      625             return parsed_response<\/p>\n  \n  <p>ModelError: An error occurred (ModelError) when calling the\n  InvokeEndpoint operation: Received client error (415) from model with\n  message \"setting an array element with a sequence.\". See\n  <a href=\"https:\/\/us-east-1.console.aws.amazon.com\/cloudwatch\/home?region=us-east-1#logEventViewer:group=\/aws\/sagemaker\/Endpoints\/DEMO-XGBoostEndpoint-2018-12-12-22-07-28\" rel=\"nofollow noreferrer\">https:\/\/us-east-1.console.aws.amazon.com\/cloudwatch\/home?region=us-east-1#logEventViewer:group=\/aws\/sagemaker\/Endpoints\/DEMO-XGBoostEndpoint-2018-12-12-22-07-28<\/a>\n  in account 249707424405 for more information.<\/p>\n<\/blockquote>",
        "Challenge_closed_time":1547665192368,
        "Challenge_comment_count":0,
        "Challenge_created_time":1544739509967,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/53770876",
        "Challenge_link_count":2,
        "Challenge_participation_count":1,
        "Challenge_readability":17.3,
        "Challenge_reading_time":31.39,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":2.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":20,
        "Challenge_solved_time":812.6895558333,
        "Challenge_title":"AWS Sagemaker, InvokeEndpoint operation, Model error: \"setting an array element with a sequence.\"",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":2561.0,
        "Challenge_word_count":171,
        "Platform":"Stack Overflow",
        "Poster_created_time":1324988509368,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Moscow, Russia",
        "Poster_reputation_count":1593.0,
        "Poster_view_count":93.0,
        "Solution_body":"<p>This works:<\/p>\n\n<pre><code>import numpy as np\nimport boto3\n\nclient = boto3.client('sagemaker-runtime')\nendpoint_name = 'DEMO-XGBoostEndpoint-2018-12-12-22-07-28'\ntest_vector = [3.60606061e+00, \n               3.91395664e+00, \n               1.34200000e+03, \n               4.56100000e+03,\n               2.00000000e+02, \n               2.00000000e+02]) \n\nbody = ',',join([str(item) for item in test_vector])\nresponse = client.invoke_endpoint(EndpointName=endpoint_name,\n                               ContentType='text\/csv',\n                               Body=body)\n<\/code><\/pre>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":12.1,
        "Solution_reading_time":5.95,
        "Solution_score_count":3.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":30.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1374169767267,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"San Francisco, CA, USA",
        "Answerer_reputation_count":548.0,
        "Answerer_view_count":70.0,
        "Challenge_adjusted_solved_time":15.3127302778,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>A bit confused with automatisation of Sagemaker retraining the model.<\/p>\n<p>Currently I have a notebook instance with Sagemaker <code>LinearLerner<\/code> model making the classification task. So using <code>Estimator<\/code> I'm making training, then deploying the model creating <code>Endpoint<\/code>. Afterwards using <code>Lambda<\/code> function for invoke this endpoint, I add it to the <code>API Gateway<\/code> receiving the api endpoint which can be used for POST requests and sending back response with class.<\/p>\n<p>Now I'm facing with the problem of retraining. For that I use <code>serverless<\/code> approach and <code>lambda<\/code> function getting environment variables for training_jobs. But the problem that Sagemaker not allow to rewrite training job and you can only create new one. My goal is to automatise the part when the new training job and the new endpoint config will apply to the existing endpoint that I don't need to change anything in API gateway. Is that somehow possible to automatically attach new endpoint config with existing endpoint?<\/p>\n<p>Thanks<\/p>",
        "Challenge_closed_time":1594485516256,
        "Challenge_comment_count":0,
        "Challenge_created_time":1594430390427,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1594502576883,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/62844211",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":10.7,
        "Challenge_reading_time":14.53,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":5.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":10,
        "Challenge_solved_time":15.3127302778,
        "Challenge_title":"Updating Sagemaker Endpoint with new Endpoint Configuration",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":3443.0,
        "Challenge_word_count":161,
        "Platform":"Stack Overflow",
        "Poster_created_time":1386491614716,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":2778.0,
        "Poster_view_count":352.0,
        "Solution_body":"<p>If I am understanding the question correctly, you should be able to use <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/APIReference\/API_CreateEndpointConfig.html\" rel=\"nofollow noreferrer\">CreateEndpointConfig<\/a> near the end of the training job, then use <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/APIReference\/API_UpdateEndpoint.html\" rel=\"nofollow noreferrer\">UpdateEndpoint<\/a>:<\/p>\n<p><code>Deploys the new EndpointConfig specified in the request, switches to using newly created endpoint, and then deletes resources provisioned for the endpoint using the previous EndpointConfig (there is no availability loss).<\/code><\/p>\n<p>If the API Gateway \/ Lambda is routed via the endpoint ARN, that should not change after using <code>UpdateEndpoint<\/code>.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":18.1,
        "Solution_reading_time":10.31,
        "Solution_score_count":3.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":79.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":158.096525,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>My Azure ML studio web service used to run fine but is unavailable for me to use now. Anybody know a fix?  <\/p>\n<p>Error Message: Could not authorize the request. Make sure the request has an Authorization header with a bearer token, of the form &quot;Authorization: Bearer [token]&quot;. See online help to find which tokens are valid for this request.  <br \/>\nSite Path: \/workspaces\/fde0912ad97d4a94b9b2baaafd54c3e1\/webservices\/378f095e8260497697790a6d65fe9ff8\/endpoints\/default  <br \/>\nActivity ID: 82e53138-b3b9-4a94-8695-0b8152c505ac  <br \/>\nRequest ID: e3e8fbe7-6161-411b-9c2c-e2a609436353  <br \/>\nWorkspace ID: fde0912ad97d4a94b9b2baaafd54c3e1  <br \/>\nWorkspace Type: Free  <br \/>\nUser Role: Owner  <br \/>\nTenant ID: f8cdef31-a31e-4b4a-93e4-5f571e91255a<\/p>",
        "Challenge_closed_time":1649047941240,
        "Challenge_comment_count":2,
        "Challenge_created_time":1648478793750,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/790341\/authorization-bearer-(token)-error",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":7.2,
        "Challenge_reading_time":10.25,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":158.096525,
        "Challenge_title":"Authorization: Bearer [token] Error",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":91,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=4f826b11-7b14-4523-b00c-cbe2449313bf\">@dasa8  <\/a>     <\/p>\n<p>Update: The bug has been confirmed and the ETA is 2-3 weeks for the bug fixing. I am sorry for all the inconveniences.     <\/p>\n<p>The workaround for now is to use studio classic portal to manage the classic web service as below screenshot:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/189568-microsoftteams-image-9.png?platform=QnA\" alt=\"189568-microsoftteams-image-9.png\" \/>    <\/p>\n<p>Thanks for the understanding and sorry for the experience again.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p><em>-Please kindly accept the answer if you feel helpful, thanks a lot!<\/em>    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":10.9,
        "Solution_reading_time":8.87,
        "Solution_score_count":1.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":81.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":0.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":4.1845747222,
        "Challenge_answer_count":1,
        "Challenge_body":"Hi,\nCan I use serverless inference as a pricing model for selling a SageMaker Model Package on the AWS Marketplace?",
        "Challenge_closed_time":1673186904128,
        "Challenge_comment_count":0,
        "Challenge_created_time":1673171839659,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1673517930936,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUcZwxBuy-SROI7OF3-NFslA\/sagemaker-serverless-on-aws-marketplace",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":10.3,
        "Challenge_reading_time":1.95,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":2,
        "Challenge_solved_time":4.1845747222,
        "Challenge_title":"SageMaker Serverless on AWS Marketplace?",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":55.0,
        "Challenge_word_count":24,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"No, quoting from SageMaker documentation:\n\n\n```\n\u2026features currently available for SageMaker Real-time Inference are not supported for Serverless Inference, including GPUs, AWS marketplace model packages\u2026\n```\n\nReference: https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/serverless-endpoints.html#serverless-endpoints-how-it-works-exclusions",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1673186904128,
        "Solution_link_count":1.0,
        "Solution_readability":28.8,
        "Solution_reading_time":4.52,
        "Solution_score_count":0.0,
        "Solution_sentence_count":1.0,
        "Solution_word_count":26.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":0.3166666667,
        "Challenge_answer_count":2,
        "Challenge_body":"I just want to clarify my understanding. I can use my own servers for calling webhooks correct (as long as they return the json structure required). The webhooks will essentially reach out another API service and return data for fulfillment. Thanks in advance for your time.",
        "Challenge_closed_time":1673513220000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1673512080000,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Webhooks\/td-p\/509590\/jump-to\/first-unread-message",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":6.6,
        "Challenge_reading_time":3.5,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":0.3166666667,
        "Challenge_title":"Webhooks",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":88.0,
        "Challenge_word_count":46,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"Exactly correct.\u00a0 During the processing of a conversation, if you have a Web Hook enabled, the Dialogflow engine will call-out to the target URL passing in a JSON payload and expecting a correctly formatted JSON response.\n\nSee the following for details:\n\nhttps:\/\/cloud.google.com\/dialogflow\/cx\/docs\/concept\/webhook\n\nTake care to notice that the target service MUST be callable through HTTPS which means that it has a valid SSL certificate.\n\nView solution in original post",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":10.0,
        "Solution_reading_time":5.85,
        "Solution_score_count":0.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":69.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":93.4837152778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>So, I created an experiment, based on one of many examples and picked a dataset that required some transformations, columns choosing and categorical features. The model creation worked just fine, with only smaller hiccups. However as I deployed the webservice, the API is requesting the new column data set (created after the feature transformation) and not the original data set. This does not serve my purpose, as my aim for creating a service that would adhere to the original dataset features.  <\/p>\n<p>What am I doing wrong? Or shall I be required to implement the data transformation. Also, the feature I am trying to predict is also showing up as a input feature, and that does not make sense.  <\/p>\n<p>Any pointers?  <\/p>",
        "Challenge_closed_time":1602859603928,
        "Challenge_comment_count":4,
        "Challenge_created_time":1602523062553,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/123854\/azure-ml-classic-webservices-deploy-error-when-doi",
        "Challenge_link_count":0,
        "Challenge_participation_count":5,
        "Challenge_readability":9.0,
        "Challenge_reading_time":9.9,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":93.4837152778,
        "Challenge_title":"Azure ML classic webservices deploy - Error When Doing Test Request-Response",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":132,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>After further investigation, it has been determined that by design, studio (classic) will echo this error when using convert to indicator values transformation, hence, we suggest not using convert to indicator values block in the inference pipeline. However, in <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/convert-to-indicator-values\">designer<\/a>, indicator values transformation is saved so that this module can be used in the inference pipeline. Sorry for the inconvenience, but hope this helps!    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":15.6,
        "Solution_reading_time":7.2,
        "Solution_score_count":1.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":66.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1298044626600,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":1476.0,
        "Answerer_view_count":105.0,
        "Challenge_adjusted_solved_time":2.4293805556,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Is there an API to receive list of published webservices?<\/p>\n<p>I have workspace id and auth token, I can get list of projects and experiments, but I can't get list of services created from experiments. Specifically I need the URL in order to post requests.\n<a href=\"https:\/\/i.stack.imgur.com\/6YHP1.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/6YHP1.png\" alt=\"\" \/><\/a><br \/>\n<sub>(source: <a href=\"https:\/\/msdnshared.blob.core.windows.net\/media\/TNBlogsFS\/prod.evol.blogs.technet.com\/CommunityServer.Blogs.Components.WeblogFiles\/00\/00\/01\/02\/52\/JupRay-2.png\" rel=\"nofollow noreferrer\">windows.net<\/a>)<\/sub><\/p>\n<p>In client api I see if we publish a new service we can get it, but do we have more options?<\/p>",
        "Challenge_closed_time":1462276416390,
        "Challenge_comment_count":0,
        "Challenge_created_time":1462267670620,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1639596690136,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/37000397",
        "Challenge_link_count":3,
        "Challenge_participation_count":1,
        "Challenge_readability":11.0,
        "Challenge_reading_time":10.12,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":8,
        "Challenge_solved_time":2.4293805556,
        "Challenge_title":"How to get list of services in Azure ML?",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":42.0,
        "Challenge_word_count":86,
        "Platform":"Stack Overflow",
        "Poster_created_time":1369681858647,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":464.0,
        "Poster_view_count":34.0,
        "Solution_body":"<p>The R Azure ML API has that. Excerpt from <a href=\"https:\/\/htmlpreview.github.io\/?https:\/\/github.com\/RevolutionAnalytics\/AzureML\/blob\/master\/vignettes\/getting_started.html\" rel=\"nofollow\">https:\/\/htmlpreview.github.io\/?https:\/\/github.com\/RevolutionAnalytics\/AzureML\/blob\/master\/vignettes\/getting_started.html<\/a> : <\/p>\n\n<p><code>\n(webservices &lt;- services(ws, name = \"AzureML-vignette-silly\"))\n<\/code><\/p>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":37.8,
        "Solution_reading_time":5.71,
        "Solution_score_count":1.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":20.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1554186784008,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Hyderabad, Telangana, India",
        "Answerer_reputation_count":2175.0,
        "Answerer_view_count":434.0,
        "Challenge_adjusted_solved_time":90.3942838889,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>My workflow is running perfect on Experimentation, but after deployed to web service, I receive this error while post.<\/p>\n\n<p>Python Code:<\/p>\n\n<pre><code># -*- coding: utf-8 -*-\n\n#import sys\nimport pickle\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree \n\ndef azureml_main(dataframe1 = None, dataframe2 = None):\n    print('input dataframe1 ',dataframe1)\n    decision_tree_pkl_predictive_maint = r'.\\Script Bundle\\decision_tree_pkl_predictive_maint.pkl'\n\n    #sys.path.insert(0,\".\\Script Bundle\")\n    #model = pickle.load(open(\".\\Script Bundle\\decision_tree_pkl_predictive_maint.pkl\", 'rb'))\n\n    modle_file = open(decision_tree_pkl_predictive_maint,\"rb\")\n    model = pickle.load(modle_file)\n\n    #return the mode of prediciton\n    result = model.predict(dataframe1)\n    print(result)\n    result_df = pd.DataFrame({'prediction_class':result})\n    return result_df,\n<\/code><\/pre>\n\n<p>ERROR:<\/p>\n\n<p>Execute Python Script RRS : Error 0085: The following error occurred during script evaluation, please view the output log for more information: ---------- Start of error message from Python interpreter ---------- Caught exception while executing function: Traceback (most recent call last): File \"\\server\\InvokePy.py\", line 120, in executeScript outframe = mod.azureml_main(*inframes) File \"\\temp-1036260731852293620.py\", line 46, in azureml_main modle_file = open(decision_tree_pkl_predictive_maint,\"rb\") FileNotFoundError: [Errno 2] No such file or directory: '.\\Script Bundle\\decision_tree_pkl_predictive_maint.pkl' ---------- End of error message from Python interpreter ----------<\/p>\n\n<p>Please, Advice.<\/p>",
        "Challenge_closed_time":1580091525612,
        "Challenge_comment_count":0,
        "Challenge_created_time":1579766106190,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/59873804",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":14.1,
        "Challenge_reading_time":22.23,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":13,
        "Challenge_solved_time":90.3942838889,
        "Challenge_title":"Error 0085 while executing python script in Azure Web service but not in ML Experiment",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":215.0,
        "Challenge_word_count":163,
        "Platform":"Stack Overflow",
        "Poster_created_time":1554724240183,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Bangalore, Karnataka, India",
        "Poster_reputation_count":29.0,
        "Poster_view_count":16.0,
        "Solution_body":"<p>The issue has to do with your file path. Ensure that you have included the correct path.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":3.1,
        "Solution_reading_time":1.16,
        "Solution_score_count":0.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":17.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":1.0,
        "Answerer_isModerator":0.0,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":5.6422222222,
        "Challenge_answer_count":1,
        "Challenge_body":"I have a customer asking me about the [Rendezvous architecture](https:\/\/towardsdatascience.com\/rendezvous-architecture-for-data-science-in-production-79c4d48f12b). What I'm thinking is, we could implement this in a number of ways, all using endpoint variants:\n\n- Lambda (and probably SQS) around the endpoint;\n- A custom monitoring job;\n- Step Functions\n\nWithout going into details of the above options or of how the evaluation and SLA check will be done, it looks like the several models would fit very well as variants of an endpoint. The thing is, the architecture expects to call them all. Is there a way to directly call all variants of a model, or will a wrapper to identify the variants, call them all and process the results be needed?",
        "Challenge_closed_time":1604506964000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1604486652000,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1667925743687,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QU6bm-EMtOQV6robgbTXClLQ\/running-a-request-against-all-variants-in-an-endpoint",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":12.7,
        "Challenge_reading_time":9.87,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":5.6422222222,
        "Challenge_title":"Running a request against all variants in an endpoint",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":37.0,
        "Challenge_word_count":121,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"When I last looked into it, it was not possible to query all versions\/variants of the model automatically. You can specify what variant to use when using the `invoke_endpoint` method. I would therefore write a lambda function to invoke each of the endpoints one-by-one (see here: https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/APIReference\/API_runtime_InvokeEndpoint.html). To be especially rigorous about it, you can add a function in your lambda code that first retrieves all the endpoint variants (see here: https:\/\/boto3.amazonaws.com\/v1\/documentation\/api\/latest\/reference\/services\/sagemaker.html#SageMaker.Client.describe_endpoint) then queries them one-by-one, and returns all the results.",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1607685345047,
        "Solution_link_count":2.0,
        "Solution_readability":14.3,
        "Solution_reading_time":9.0,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":81.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":8.1582452778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am running this tutorial: <a href=\"https:\/\/learn.microsoft.com\/de-de\/azure\/machine-learning\/tutorial-first-experiment-automated-ml\">https:\/\/learn.microsoft.com\/de-de\/azure\/machine-learning\/tutorial-first-experiment-automated-ml<\/a>    <\/p>\n<p>and struggle under &quot;next steps&quot; to deploy this model to a browser user interface of some kind (where I can manually type in the input values and press &quot;predict&quot; to get the output value).     <\/p>\n<p>Background: I would like to present this for a seminar &quot;AI without any code&quot; and hence I will not call this REST-API in any other place but try to stay in the (Azure) web ecosystem. Any chance to get such a webinterface (functionality)?<\/p>",
        "Challenge_closed_time":1603319937640,
        "Challenge_comment_count":0,
        "Challenge_created_time":1603290567957,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/134024\/unable-to-deploy-a-automl-as-a-webservice-without",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":14.9,
        "Challenge_reading_time":10.36,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":8.1582452778,
        "Challenge_title":"Unable to deploy a autoML as a webservice without using C#, Go, Java, or Python (just a browser)",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":103,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Thanks for reaching out. Currently, Azure AutoML does not support consuming deployed web services via UI. You can create a client for the service, or use python to consume the web service via Azure ML Notebooks. Sorry for the inconvenience.<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":6.0,
        "Solution_reading_time":3.06,
        "Solution_score_count":0.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":40.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1582182357612,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":155.0,
        "Answerer_view_count":27.0,
        "Challenge_adjusted_solved_time":392.2279305556,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have an ML model (trained locally) in python. Previously the model has been deployed to a Windows IIS server and it's working fine.<\/p>\n<p>Now, I am trying to deploy it as a service on Azure container instance (ACI) with 1 core, and 1 GB of memory. I took references from <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python\" rel=\"nofollow noreferrer\">one<\/a> and <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-existing-model\" rel=\"nofollow noreferrer\">two<\/a> Microsoft docs. The docs use SDK for all the steps, but <strong>I am using the GUI feature from the Azure portal<\/strong>.<\/p>\n<p>After registering the model, I created an entry script and a conda environment YAML file (see below), and uploaded both to &quot;Custom deployment asset&quot; (at Deploy model area).<\/p>\n<p>Unfortunately, after hitting deploy, the Deployment state is stuck at Transitioning state. Even after 4 hours, the state remains the same and there were no Deployment logs too, so I am unable to find what I am doing wrong here.<\/p>\n<blockquote>\n<p>NOTE: below is just an excerpt of the entry script<\/p>\n<\/blockquote>\n<pre class=\"lang-py prettyprint-override\"><code>import pandas as pd\nimport pickle\nimport re, json\nimport numpy as np\nimport sklearn\n\ndef init():\n    global model \n    global classes\n    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'randomForest50.pkl')\n    model = pickle.load(open(model_path, &quot;rb&quot;))\n\n    classes = lambda x : [&quot;F&quot;, &quot;M&quot;][x]\n\ndef run(data):\n    try:\n        namesList = json.loads(data)[&quot;data&quot;][&quot;names&quot;]\n        pred = list(map(classes, model.predict(preprocessing(namesList))))\n        return str(pred[0])\n    except Exception as e:\n        error = str(e)\n        return error\n<\/code><\/pre>\n<pre class=\"lang-yaml prettyprint-override\"><code>name: gender_prediction\ndependencies:\n- python\n- numpy\n- scikit-learn\n- pip:\n    - pandas\n    - pickle\n    - re\n    - json\n<\/code><\/pre>",
        "Challenge_closed_time":1612491964670,
        "Challenge_comment_count":1,
        "Challenge_created_time":1611073723990,
        "Challenge_favorite_count":1.0,
        "Challenge_last_edit_time":1611079944120,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/65795579",
        "Challenge_link_count":2,
        "Challenge_participation_count":2,
        "Challenge_readability":11.3,
        "Challenge_reading_time":25.53,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":16,
        "Challenge_solved_time":393.9557444445,
        "Challenge_title":"Debugging AML Model Deployment",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":106.0,
        "Challenge_word_count":231,
        "Platform":"Stack Overflow",
        "Poster_created_time":1582182357612,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":155.0,
        "Poster_view_count":27.0,
        "Solution_body":"<p>The issue was in the YAML file. <strong>The dependencies\/libraries in the YAML should be according to conda environment<\/strong>. So, I changed everything accordingly, and it worked.<\/p>\n<p>Modified YAML file:<\/p>\n<pre><code>name: gender_prediction\ndependencies:\n- python=3.7\n- numpy\n- scikit-learn\n- pip:\n    - azureml-defaults\n    - pandas\n    - pickle4\n    - regex\n    - inference-schema[numpy-support]   \n<\/code><\/pre>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":10.1,
        "Solution_reading_time":5.17,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":42.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1285219808283,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Perth WA, Australia",
        "Answerer_reputation_count":6770.0,
        "Answerer_view_count":1127.0,
        "Challenge_adjusted_solved_time":0.0213536111,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I'm currently trying to integrate an ML model currently deployed as a webservice on AzureML with PowerBI.<\/p>\n<p>I see that it can be <a href=\"https:\/\/docs.microsoft.com\/en-us\/power-bi\/transform-model\/service-machine-learning-integration#invoking-the-azure-ml-model-in-power-bi\" rel=\"nofollow noreferrer\">integrated<\/a> but the model requires the addition of a schema file when it is <a href=\"https:\/\/docs.microsoft.com\/en-us\/power-bi\/transform-model\/service-machine-learning-integration#schema-discovery-for-machine-learning-models\" rel=\"nofollow noreferrer\">being deployed as a webservice<\/a>. Without this, the model can't be viewed in PowerBI.<\/p>\n<p>The problem that I have come up against is that I use MLflow to log ML model performances and subsequently to deploy a selected model onto AzureML as a webservice using MLflow's AzureML integration - mlflow.azureml.deploy(). This unfortunately doesn't have the option to define a schema file before the model is deployed, thus resulting in no model being available in PowerBI as it lacks the required schema file.<\/p>\n<p>My options seem to be:<\/p>\n<ol>\n<li>Find a workaround, possibly using the working <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/databricks\/applications\/mlflow\/model-serving\" rel=\"nofollow noreferrer\">REST api of the model in a power query<\/a>.<\/li>\n<li>Rewrite the deployment code and handle the webservice deployment steps in Azure instead of MLflow.<\/li>\n<\/ol>\n<p>I thought I would ask to see if I am maybe missing something as I can't find a workaround using my current code to define a schema file in MLflow when deploying with mlflow.azureml.deploy().<\/p>",
        "Challenge_closed_time":1600604920243,
        "Challenge_comment_count":0,
        "Challenge_created_time":1600261190477,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1600855880503,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/63920599",
        "Challenge_link_count":3,
        "Challenge_participation_count":1,
        "Challenge_readability":12.3,
        "Challenge_reading_time":21.83,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":12,
        "Challenge_solved_time":95.4804905556,
        "Challenge_title":"PowerBI and MLflow integration (through AzureML)",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":405.0,
        "Challenge_word_count":204,
        "Platform":"Stack Overflow",
        "Poster_created_time":1600260166047,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":15.0,
        "Poster_view_count":4.0,
        "Solution_body":"<p>Point number 2 is the way we solved this issue. Instead of using MLflow to deploy to a scoring service on Azure, we wrote a custom code which load MLflow model when container is initialised.<\/p>\n<p>Scoring code is something like this:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import os\nimport json\nfrom mlflow.pyfunc import load_model\n\nfrom inference_schema.schema_decorators import input_schema, output_schema\nfrom inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n\ndef init():\n    global model\n    model = load_model(os.path.join(os.environ.get(&quot;AZUREML_MODEL_DIR&quot;), &quot;awesome_model&quot;))\n\n@input_schema('data', NumpyParameterType(input_sample))\n@output_schema(NumpyParameterType(output_sample))\n\ndef run(data):\n    return model.predict(data)\n<\/code><\/pre>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":1600855957376,
        "Solution_link_count":0.0,
        "Solution_readability":16.9,
        "Solution_reading_time":10.68,
        "Solution_score_count":0.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":75.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":3.2849888889,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>How do I get access to the Azure OpenAI service to evaluate it's capabilities?<\/p>",
        "Challenge_closed_time":1664001167767,
        "Challenge_comment_count":1,
        "Challenge_created_time":1663989341807,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1021561\/azure-openai-service-capabilities",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":10.1,
        "Challenge_reading_time":1.51,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":2,
        "Challenge_solved_time":3.2849888889,
        "Challenge_title":"Azure OpenAI service capabilities",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":17,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=71c0cf97-895c-43f1-ac54-98e1e9833ae4\">@A-4824  <\/a> Thanks for the question. It is a Limited Access service so you have to apply for it <a href=\"https:\/\/aka.ms\/oai\/access\">https:\/\/aka.ms\/oai\/access<\/a><\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":11.1,
        "Solution_reading_time":3.13,
        "Solution_score_count":0.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":22.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1645475560783,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":466.0,
        "Answerer_view_count":32.0,
        "Challenge_adjusted_solved_time":2025.5465147222,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Status:<\/p>\n<ul>\n<li>Custom container is built using the doc - <a href=\"https:\/\/github.com\/aws\/amazon-sagemaker-examples\/tree\/master\/advanced_functionality\/scikit_bring_your_own\" rel=\"nofollow noreferrer\">https:\/\/github.com\/aws\/amazon-sagemaker-examples\/tree\/master\/advanced_functionality\/scikit_bring_your_own<\/a><\/li>\n<li>predict.py is coded to accommodate the custom inference script and its working well<\/li>\n<li>Using the classsagemaker.model.Model() class to pass the trained model.tar.gz and custom container image inorder to deploy the model<\/li>\n<\/ul>\n<p>Challenge:<\/p>\n<ul>\n<li>In the same Model class there is a ENV  parameter through which we can apparently send the environment variables to the custom image<\/li>\n<li>Tried passing a python dict to this , but facing difficulty to read this json dict inide the predict.py script<\/li>\n<\/ul>\n<p>Somebody faced the same difficulty ?<\/p>",
        "Challenge_closed_time":1645489319000,
        "Challenge_comment_count":7,
        "Challenge_created_time":1638197351547,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/70156631",
        "Challenge_link_count":2,
        "Challenge_participation_count":8,
        "Challenge_readability":15.2,
        "Challenge_reading_time":12.85,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":2025.5465147222,
        "Challenge_title":"How to pass additional parameters (as a dict) to sagemeker custom inference container?",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":183.0,
        "Challenge_word_count":108,
        "Platform":"Stack Overflow",
        "Poster_created_time":1604146329127,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":95.0,
        "Poster_view_count":7.0,
        "Solution_body":"<p>You can pass your environment dict in your Model as:<\/p>\n<pre><code>Model(\n.\n.\nenv= {&quot;my_env&quot;: &quot;my_env_value&quot;}\n.\n.\n)\n<\/code><\/pre>\n<p>SageMaker will pass the enviroments dict to your container and you can access it in your predict.py script for example with:<\/p>\n<pre><code>my_env = os.environ.get('my_env',&quot;env key not set in Model&quot;)\nprint(my_env)\n<\/code><\/pre>\n<p>If your env dict was passed to your Model containing they <code>my_env<\/code> then you will receive the output : <code>my_env_value<\/code>. Else, then you will receive <code>env key not set in Model<\/code><\/p>\n<p>I work for AWS and my opinions are my own.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":8.8,
        "Solution_reading_time":8.33,
        "Solution_score_count":1.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":85.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1253986272627,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":11930.0,
        "Answerer_view_count":2649.0,
        "Challenge_adjusted_solved_time":20.1381897222,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am new to AWS infra and currently doing some POC\/Feasibility for new work.<\/p>\n\n<p>So I have created a S3 bucket in Ireland server, train and publish Sagemaker endpoint in Ireland server and its giving result in Jupyter notebook there. Now I want to use that endpoint in my browser javascript library to show some graphics. When I try to test my endpoint in Postman then its giving region specific error <\/p>\n\n<pre><code> {\n        \"message\": \"Credential should be scoped to a valid region, not 'us-east-1'. \nCredential should be scoped to correct service: 'sagemaker'. \"\n }\n<\/code><\/pre>\n\n<p>My AWS account is not yet enterprise managed so I am using as 'root user', Whenever I go to my profile>Security_Credential page and generate any security credential then it always create for 'us-east-1' region, As Sagemaker is region specific service, I am not able to find the way to create region specific security key for root user, can someone please help<\/p>",
        "Challenge_closed_time":1526179930343,
        "Challenge_comment_count":0,
        "Challenge_created_time":1526107432860,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/50303607",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":12.3,
        "Challenge_reading_time":12.49,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":20.1381897222,
        "Challenge_title":"AWS Sagemaker | region specific security credentials for endpoint",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":750.0,
        "Challenge_word_count":161,
        "Platform":"Stack Overflow",
        "Poster_created_time":1501403168107,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Delhi, India",
        "Poster_reputation_count":1370.0,
        "Poster_view_count":125.0,
        "Solution_body":"<p>You should create an IAM role first that defines what should be permitted (mainly calling the invoke-endpoint API call for SageMaker runtime). Then you should create an IAM user, add the above role to that user, and then generate credentials that you can use in your Postman to call the service. Here you can find some details about the IAM role for SageMaker that you can use in this process: <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/using-identity-based-policies.html\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/using-identity-based-policies.html<\/a><\/p>\n\n<p>A popular option to achieve external access to a SageMaker endpoint, is to create an API Gateway that calls a Lambda Function that is then calling the invoke-endpoint API. This chain is giving you various options such as different authentication options for the users and API keys as part of API-GW, processing the user input and inference output using API-GW and Lambda code, and giving the permission to call the SageMaker endpoint to the Lambda function. This chain removes the need for the credentials creation, update and distribution.  <\/p>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":13.6,
        "Solution_reading_time":14.59,
        "Solution_score_count":2.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":163.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1452696930640,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":746.0,
        "Answerer_view_count":112.0,
        "Challenge_adjusted_solved_time":1.3582819445,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>In my AML pipeline, I've got a model built and deployed to the AciWebservice. I now have a need to include some additional data that would be used by score.py. This data is in json format (~1mb) and is specific to the model that's built. To accomplish this, I was thinking of sticking this file in blob store and updating some \"placholder\" vars in the score.py during deployment, but it seems hacky. <\/p>\n\n<p>Here are some options I was contemplating but wasn't sure on the practicality<\/p>\n\n<p><strong>Option 1:<\/strong>\nIs it possible to include this file, during the model deployment itself so that it's part of the docker image? <\/p>\n\n<p><strong>Option 2:<\/strong>\nAnother possibility I was contemplating, would it be possible to include this json data part of the Model artifacts?<\/p>\n\n<p><strong>Option 3:<\/strong>\nHow about registering it as a dataset and pull that in the score file?<\/p>\n\n<p>What is the recommended way to deploy dependent files in a model deployment scenario?<\/p>",
        "Challenge_closed_time":1589484511663,
        "Challenge_comment_count":0,
        "Challenge_created_time":1589475408817,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1589479621848,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/61803031",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":9.8,
        "Challenge_reading_time":12.93,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":3.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":10,
        "Challenge_solved_time":2.5285683334,
        "Challenge_title":"Azure ML: Include additional files during model deployment",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":866.0,
        "Challenge_word_count":167,
        "Platform":"Stack Overflow",
        "Poster_created_time":1330016065408,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":1704.0,
        "Poster_view_count":232.0,
        "Solution_body":"<p>There are few ways to accomplish this:<\/p>\n\n<ol>\n<li><p>Put the additional file in the same folder as your model file, and <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.model?view=azure-ml-py#register-workspace--model-path--model-name--tags-none--properties-none--description-none--datasets-none--model-framework-none--model-framework-version-none--child-paths-none--sample-input-dataset-none--sample-output-dataset-none--resource-configuration-none-\" rel=\"nofollow noreferrer\">register<\/a> the whole folder as the model. In this approach the file is stored alongside the model.<\/p><\/li>\n<li><p>Put the file in a local folder, and specify that folder as source_directory in <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.inferenceconfig?view=azure-ml-py\" rel=\"nofollow noreferrer\">InferenceConfig<\/a>. In this approach the file is re-uploaded every time you deploy a new endpoint.<\/p><\/li>\n<li><p>Use custom base image in InferenceConfig to bake the file into Docker image itself.<\/p><\/li>\n<\/ol>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":18.8,
        "Solution_reading_time":14.5,
        "Solution_score_count":2.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":88.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1417744681680,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":4211.0,
        "Answerer_view_count":716.0,
        "Challenge_adjusted_solved_time":74.6835766667,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am trying to invoke an AWS SageMaker endpoint through the following simple code using boto3<\/p>\n<pre><code>import boto3\n\nsession = boto3.Session(profile_name='mlacc',\n                        region_name='us-west-2')\n\nsagemaker_client = session.client('sagemaker-runtime')\n\nrequest_body = &quot;{\\n    \\&quot;requestSource\\&quot;: \\&quot;unittest\\&quot;,\\n    \\&quot;clusters\\&quot;: [{\\n        \\&quot;clusterMetadata\\&quot;: {\\n &quot;\n&quot;\\&quot;clusterId\\&quot;: \\&quot;id1\\&quot;,\\n            \\&quot;topic\\&quot;: [\\&quot;corona virus\\&quot;, \\&quot;Donald Trump\\&quot;],\\n            &quot;\n&quot;\\&quot;clusterSize\\&quot;: 2\\n        },\\n        \\&quot;documents\\&quot;: [{\\n            \\&quot;uid\\&quot;: \\&quot;1\\&quot;,\\n            &quot;\n&quot;\\&quot;content\\&quot;: \\&quot;content2\\&quot;,\\n            \\&quot;domain\\&quot;: \\&quot;CNN.com\\&quot;,\\n            \\&quot;title\\&quot;: \\&quot;This is a &quot;\n&quot;title\\&quot;,\\n            \\&quot;similarityScore\\&quot;: 1.3,\\n            \\&quot;published_at\\&quot;: 1566264017,\\n            &quot;\n&quot;\\&quot;domain_rank\\&quot;: 1,\\n            \\&quot;trust_domain_score\\&quot;: 1\\n        }, {\\n            \\&quot;uid\\&quot;: \\&quot;2\\&quot;,&quot;\n&quot;\\n            \\&quot;content\\&quot;: \\&quot;content2\\&quot;,\\n            \\&quot;domain\\&quot;: \\&quot;CNN.com\\&quot;,\\n            \\&quot;title\\&quot;: &quot;\n&quot;\\&quot;This is a title\\&quot;,\\n            \\&quot;similarityScore\\&quot;: 1.3,\\n            \\&quot;published_at\\&quot;: 1566264017,&quot;\n&quot;\\n            \\&quot;domain_rank\\&quot;: 1,\\n            \\&quot;trust_domain_score\\&quot;: 1\\n        }, {\\n            \\&quot;uid\\&quot;: &quot;\n&quot;\\&quot;2\\&quot;,\\n            \\&quot;content\\&quot;: \\&quot;content3\\&quot;,\\n            \\&quot;domain\\&quot;: \\&quot;CNN.com\\&quot;,\\n            \\&quot;title\\&quot;: &quot;\n&quot;\\&quot;This is a title\\&quot;,\\n            \\&quot;similarityScore\\&quot;: 1.3,\\n            \\&quot;published_at\\&quot;: 1566264017,&quot;\n&quot;\\n            \\&quot;domain_rank\\&quot;: 1,\\n            \\&quot;trust_domain_score\\&quot;: 1\\n        }]\\n    }]\\n}&quot;\n\n\nresponse = sagemaker_client.invoke_endpoint(\n    EndpointName='myEndpoint22',\n    Body=request_body,\n    ContentType='application\/json',\n)\n\nresponse_json = response['Body'].read().decode('utf-8')\n\nprint(response_json)\n<\/code><\/pre>\n<p>I get the following error when I run this code<\/p>\n<pre><code>Traceback (most recent call last):\n  File &quot;\/Users\/rppatwa\/Desktop\/WorkDocs\/CodePlayground\/SimplePythonProject\/src\/PrototypeTesting\/SummarizationLocal.py&quot;, line 205, in &lt;module&gt;\n    main()\n  File &quot;\/Users\/rppatwa\/Desktop\/WorkDocs\/CodePlayground\/SimplePythonProject\/src\/PrototypeTesting\/SummarizationLocal.py&quot;, line 186, in main\n    ContentType='application\/json',\n  File &quot;\/Users\/rppatwa\/anaconda3\/lib\/python3.7\/site-packages\/botocore\/client.py&quot;, line 316, in _api_call\n    return self._make_api_call(operation_name, kwargs)\n  File &quot;\/Users\/rppatwa\/anaconda3\/lib\/python3.7\/site-packages\/botocore\/client.py&quot;, line 635, in _make_api_call\n    raise error_class(parsed_response, operation_name)\nbotocore.errorfactory.ModelError: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from model with message &quot;Unable to parse data as JSON. Make sure the Content-Type header is set to &quot;application\/json&quot;&quot;. See https:\/\/us-west-2.console.aws.amazon.com\/cloudwatch\/home?region=us-west-2#logEventViewer:group=\/aws\/sagemaker\/Endpoints\/KeyurshaASMLModel in account 753843489946 for more information.\n<\/code><\/pre>\n<p>If I inline the Body (not using the request_json) this call succeeds. Please let me know what I am missing.<\/p>\n<p>Thanks<\/p>",
        "Challenge_closed_time":1598927909716,
        "Challenge_comment_count":3,
        "Challenge_created_time":1598659048840,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/63642175",
        "Challenge_link_count":1,
        "Challenge_participation_count":4,
        "Challenge_readability":18.2,
        "Challenge_reading_time":47.9,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":23,
        "Challenge_solved_time":74.6835766667,
        "Challenge_title":"Error when invoking AWS SageMaker endpoint using boto3 : \"Unable to parse data as JSON. Make sure the Content-Type header is set to \"application\/json\"",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":1170.0,
        "Challenge_word_count":256,
        "Platform":"Stack Overflow",
        "Poster_created_time":1470101805440,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Santa Monica, CA, USA",
        "Poster_reputation_count":107.0,
        "Poster_view_count":21.0,
        "Solution_body":"<p>You need to remove the trailing comma after  <code>ContentType='application\/json',<\/code> and try below snippet for passing JSON to body field.<\/p>\n<pre><code>import json \njson.dumps(request_body) \ntest=json.dumps(request_body).encode()\n<\/code><\/pre>\n<p>This will also validate the JSON that you are passing.Now pass test to body for invoking the endopoint.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":12.1,
        "Solution_reading_time":4.7,
        "Solution_score_count":1.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":42.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1569423384323,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":96.0,
        "Answerer_view_count":6.0,
        "Challenge_adjusted_solved_time":8089.9413483334,
        "Challenge_answer_count":3,
        "Challenge_body":"<p>Im working on sentence classification using in-build  blazing text algorithm, while invoking endpoint inside lambda function it throughs the content type mismatching error. <\/p>\n\n<p>-- For blazing text it support only application\/jsonlines or application\/json but while invoking , it throughs the error like , it accepts only byte or bytearray<\/p>\n\n<pre><code>input format . application\/json\nevent={\n  \"features\": [\n    \"sensor_subtype Thermostats Thermal Switches product_features Hermetically sealed n Tight tolerances n Tight differentials n Logic level contacts n applications Computers n Medical electronics n Power supplies n Industrial controls n Test equipment n Infotech n description Technical Specifications technical_specs CloseTolerance 2 8 C 5 F DielectricStrength MIL STD 202 Method 301 1250 Vac 60 Hz Terminal to Case ContactResistance MIL STD\"\n  ]\n}\n<\/code><\/pre>\n\n<p>and also i tried application\/jsonlines<\/p>\n\n<p>My code looks like this>>>>>>>>>>>>>>>>>>>>>>>><\/p>\n\n<pre><code>def transform_data(data):\n    try:\n        features = data.copy()\n\n        return features\n\n    except Exception as err:\n        print('Error when transforming: {0},{1}'.format(data,err))\n        raise Exception('Error when transforming: {0},{1}'.format(data,err))\n\n\ndef lambda_handler(event, context):\n    try:    \n        print(\"Received event: \" + json.dumps(event, indent=2))\n\n        request = json.loads(json.dumps(event))\n\n        transformed_data = str(transform_data(request['features'])) #for instance in request['features'])\n        print(ENDPOINT_NAME, \"-------&gt;&gt;&gt;&gt;\")\n        payload=transformed_data\n        result = client.invoke_endpoint(EndpointName=ENDPOINT_NAME, \n                              Body=(payload.encode('utf-8')),\n                              ContentType='application\/json')\n        return result\n<\/code><\/pre>\n\n<pre><code>  \"statusCode\": 400,\n  \"isBase64Encoded\": false,\n  \"body\": \"Call Failed An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (406) from model with message \\\"Invalid payload format\\\".\n_______________LOGS__________________________________\n\uf141\n11:35:22\n[08\/18\/2019 11:35:22 ERROR 140074862942016] Customer Error: Unable to decode payload: Incorrect data format. (caused by ValueError)\n\uf141\n11:35:22\nCaused by: No JSON object could be decoded\n\uf141\n11:35:22\nTraceback (most recent call last): File \"\/opt\/amazon\/lib\/python2.7\/site-packages\/blazingtext\/serve.py\", line 317, in invocations data = json.loads(payload.decode(\"utf-8\")) File \"\/opt\/amazon\/python2.7\/lib\/python2.7\/json\/__init__.py\", line 339, in loads return _default_decoder.decode(s) File \"\/opt\/amazon\/python2.7\/lib\/python2.7\/json\/decoder.py\", line 364, in decode obj, end = self.\n\uf141\n11:35:22\nValueError: No JSON object could be decoded\n<\/code><\/pre>\n\n<p>I need to predict the sentence in realtime using invoke_endpoint option but it shows invalid payload format <\/p>\n\n<p>I tried with byte format and apllication\/jsonlines format.<\/p>",
        "Challenge_closed_time":1595256539003,
        "Challenge_comment_count":1,
        "Challenge_created_time":1566128809927,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1566133069936,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/57544237",
        "Challenge_link_count":0,
        "Challenge_participation_count":4,
        "Challenge_readability":15.8,
        "Challenge_reading_time":37.83,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":18,
        "Challenge_solved_time":8091.0358544445,
        "Challenge_title":"Inside lambda function - Blazing text algorithm invoke endpoint doesn't support the input content type",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":493.0,
        "Challenge_word_count":305,
        "Platform":"Stack Overflow",
        "Poster_created_time":1541220234400,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Singapore",
        "Poster_reputation_count":13.0,
        "Poster_view_count":5.0,
        "Solution_body":"<p>I encountered the same problem when trying to predict on text classification with a BlazingText container. What worked for me was simply changing the key in the payload while keeping the ContentType as application\/json:<\/p>\n<pre><code>sentence = &quot;I'm selling my PS4, practically brand new&quot;\n\npayload = {&quot;instances&quot;: [sentence]}\n\nresponse = client.invoke_endpoint(\n        EndpointName=&quot;text_classification&quot;,\n        Body=json.dumps(payload),\n        ContentType='application\/json'\n        \n    )\n<\/code><\/pre>\n<p>After playing around a little with the payload it seems that blazing text models only accept payloads as a dictionary with &quot;instances&quot; as its key and a list containing your data you want to predict on as its value.<\/p>\n<p>To get to your predictions simply :<\/p>\n<pre><code>print(&quot;ResponseMetadata:&quot;, response[&quot;ResponseMetadata&quot;])\nprint()\nprint(&quot;Body:&quot;, response['Body'].read())\n<\/code><\/pre>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1595256858790,
        "Solution_link_count":0.0,
        "Solution_readability":16.0,
        "Solution_reading_time":12.21,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":103.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":0.5504083334,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I'm working for a campany located in Germany. We want to use Azure Machine Learning (and other stuff like that).   <br \/>\nWe are only allowed to use Azure in the Region &quot;Germany&quot;, because the data of our customers cannot left germany.  <\/p>\n<p>Now I saw, that a lot of stuff in Azure Machine Learning is not available in Germany?  <\/p>\n<p>Questions:  <\/p>\n<ol>\n<li> Is that true?  <\/li>\n<li> Does some one now, at what time Microsoft plans to make the stuff available in Germany?  <\/li>\n<\/ol>\n<p>Thank you for a answer!  <\/p>\n<p>Patrick  <\/p>",
        "Challenge_closed_time":1612862196647,
        "Challenge_comment_count":0,
        "Challenge_created_time":1612860215177,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/265151\/azure-machine-learning-(and-cognitive-services)-is",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":5.5,
        "Challenge_reading_time":7.73,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":0.5504083334,
        "Challenge_title":"Azure Machine Learning (and cognitive services) is not supported in Region \"Germany\"?",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":106,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hi <a href=\"\/users\/na\/?userid=1d5d0740-76fa-4574-b01a-5fcee1ddf5b1\">@Patrick Huber  <\/a>     <br \/>\nYes, Azure Machine Learning is not available in Germany region.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/65687-image.png?platform=QnA\" alt=\"65687-image.png\" \/>    <\/p>\n<p><a href=\"https:\/\/feedback.azure.com\/forums\/34192--general-feedback\">Please check in Azure feedback<\/a>    <\/p>\n<p>If the Answer is helpful, please click <code>Accept Answer<\/code> and <strong>up-vote<\/strong>, this can be beneficial to other community members.    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":14.1,
        "Solution_reading_time":7.51,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":48.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":10.8094663889,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>As part of our MLOps flow, we need to retrain a machine learning model using the AML designer, and then update the AKS webservice with the new machine learning model (+ a couple of other supplementary training artifacts), also from the designer.  <\/p>\n<p>We have built an inference pipeline to do this, and are able to run it manually. However, the solution requirements require this process to be automated. We have previously successfully automated this through the python SDK and the akswebservice.update method, but this solution has a hard requirement to use the designer only (custom python code blocks would be allowed, however).  <\/p>\n<p>Is there a way, using any Azure services (eg Azure Data Factory, Azure DevOps), that we can kick off a designer real time inference update pipeline immediately after its associated training pipeline finishes executing, in order to get the latest model version into the webservice, without any manual intervention? To be clear though, manual intervention is acceptable to build the initial inference pipeline for version 1, but not on the retraining cycle.<\/p>",
        "Challenge_closed_time":1620691417852,
        "Challenge_comment_count":0,
        "Challenge_created_time":1620652503773,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/389170\/azure-ml-designer-automatically-update-aks-webserv",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":13.4,
        "Challenge_reading_time":14.59,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":8,
        "Challenge_solved_time":10.8094663889,
        "Challenge_title":"Azure ML Designer: Automatically Update AKS Webservice After Training",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":183,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hi, thanks for reaching out. Currently, you can only use the Azure Machine Learning SDK to automatically <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-update-web-service\">update the web service<\/a>. I'm inquiring from the product team whether there are plans to support this scenario (will share updates accordingly). Hope this helps.    <\/p>\n",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":9.1,
        "Solution_reading_time":4.89,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":44.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":0.2877788889,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am trying to figure out about standard connectors between SAP ERP product and Azure ML especially for NLP scenarios. Can you please suggest on this.<\/p>",
        "Challenge_closed_time":1664542897547,
        "Challenge_comment_count":0,
        "Challenge_created_time":1664541861543,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1030800\/azure-ml-for-sap-erp",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":6.0,
        "Challenge_reading_time":2.19,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":0.2877788889,
        "Challenge_title":"Azure ML for SAP ERP",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":30,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=dfa9d536-725c-462d-87c8-47fbafb1a2bc\">@D-0887  <\/a> Thanks for the question. Here is the blog that could help and <a href=\"https:\/\/github.com\/microsoft\/nlp-recipes\">nlp recipes<\/a>.    <br \/>\n<a href=\"https:\/\/blogs.sap.com\/2022\/08\/03\/azure-machine-learning-triggering-calculations-ml-in-sap-data-warehouse-cloud\/\">https:\/\/blogs.sap.com\/2022\/08\/03\/azure-machine-learning-triggering-calculations-ml-in-sap-data-warehouse-cloud\/<\/a>    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":26.2,
        "Solution_reading_time":6.43,
        "Solution_score_count":0.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":22.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1559910246180,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Bengaluru, Karnataka, India",
        "Answerer_reputation_count":2046.0,
        "Answerer_view_count":369.0,
        "Challenge_adjusted_solved_time":1095.2252230556,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>based on the aws documentation, maximum timeout limit is less that 30 seconds in api gateway.so hooking up an sagemaker endpoint with api gateway wouldn't make sense, if the request\/response is going to take more than 30 seconds. is there any workaround ? adding a lambda in between api gateway and sagemaker endpoint is going to add more time to process request\/response, which i would like to avoid. also, there will be added time for lambda cold starts and sagemaker serverless endpoints are built on top of lambda so that will also add cold start time. is there a way to invoke the serverless sagemaker endpoints , without these overhead?<\/p>",
        "Challenge_closed_time":1645795642143,
        "Challenge_comment_count":0,
        "Challenge_created_time":1645755688313,
        "Challenge_favorite_count":1.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/71260306",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":8.5,
        "Challenge_reading_time":8.68,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":3.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":11.0982861111,
        "Challenge_title":"How to access\/invoke a sagemaker endpoint without lambda?",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":1122.0,
        "Challenge_word_count":115,
        "Platform":"Stack Overflow",
        "Poster_created_time":1590797441983,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":525.0,
        "Poster_view_count":98.0,
        "Solution_body":"<p>It is indeed possible to invoke sagemaker endpoints from sagemaker without using any other AWS services and that is also manifested by the fact that they have invocation URLs.<\/p>\n<p>Here's how you set it up:<\/p>\n<ol>\n<li>create an user with only programmatic access and attach a policy json that should look something like below:<\/li>\n<\/ol>\n<pre><code>{\n    &quot;Version&quot;: &quot;2012-10-17&quot;,\n    &quot;Statement&quot;: [\n        {\n            &quot;Sid&quot;: &quot;VisualEditor0&quot;,\n            &quot;Effect&quot;: &quot;Allow&quot;,\n            &quot;Action&quot;: &quot;sagemaker:InvokeEndpoint&quot;,\n            &quot;Resource&quot;: &quot;arn:aws:sagemaker:&lt;region&gt;:&lt;account-id&gt;:endpoint\/&lt;endpoint-name&gt;&quot;\n        }\n    ]\n} \n<\/code><\/pre>\n<p>you can replace <code>&lt;endpoint-name&gt;<\/code> with <code>*<\/code> to let this user invoke all endpoints.<\/p>\n<ol start=\"2\">\n<li><p>use the ACCESS-KEY and SECRET-ACCESS-KEY to configure authorisation in postman like shown in this screenshot. also add the parameters in advanced tab like shown in the screenshot.\n<a href=\"https:\/\/i.stack.imgur.com\/cYkTf.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/cYkTf.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<\/li>\n<li><p>then fill up your body with the relevant content type.<\/p>\n<\/li>\n<li><p>then add or remove additional headers like variant-name or model-name, if you have them set up and the headers should look like shown in this screenshot: <a href=\"https:\/\/i.stack.imgur.com\/NLqkV.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/NLqkV.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<\/li>\n<li><p>send the request to receive reponse like this\n<a href=\"https:\/\/i.stack.imgur.com\/uA4kF.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/uA4kF.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<\/li>\n<\/ol>\n<p><em><strong>URL and credentials in the above screenshots doesn't work anymore, duh!<\/strong><\/em><\/p>\n<p>and if you want code to invoke the endpoint directly using some back-end language, <a href=\"https:\/\/stackoverflow.com\/a\/70803026\/11814996\">here's code for python<\/a>.<\/p>",
        "Solution_comment_count":5.0,
        "Solution_last_edit_time":1649698499116,
        "Solution_link_count":7.0,
        "Solution_readability":13.4,
        "Solution_reading_time":27.72,
        "Solution_score_count":3.0,
        "Solution_sentence_count":13.0,
        "Solution_word_count":219.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":7.2898647222,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>Hi, I have seen some questions in this forum saying v2 is in preview, but some functions are there already. Can you share the release plan?<\/p>",
        "Challenge_closed_time":1658348954516,
        "Challenge_comment_count":0,
        "Challenge_created_time":1658322711003,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/934478\/azure-machine-learning-sdk-v2-release-plan",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":3.9,
        "Challenge_reading_time":2.32,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":7.2898647222,
        "Challenge_title":"Azure machine learning sdk v2 release plan",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":32,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=ce84de18-8973-44f3-8101-f191f9216b1f\">@Alexandre  <\/a><\/p>\n<p>SDK v2 is currently in public preview. The preview version is provided without a service level agreement, and it's not recommended for production workloads. Certain features might not be supported or might have constrained capabilities. For more information, see Supplemental Terms of Use for Microsoft Azure Previews. <a href=\"https:\/\/azure.microsoft.com\/en-us\/support\/legal\/preview-supplemental-terms\/\">https:\/\/azure.microsoft.com\/en-us\/support\/legal\/preview-supplemental-terms\/<\/a><\/p>\n<p>Some of the functions is still in private preview of SDK v2, so at this time, we are not recommending it for production, but you could try it for testing. We are working on bringing features to v2 step by step.<\/p>\n<p>Azure ML Python SDK v2 is an updated Python SDK package, which allows users to:<\/p>\n<ul>\n<li>\n<ul>\n<li> Submit training jobs<\/li>\n<\/ul>\n<\/li>\n<li> Manage data, models, environments<\/li>\n<li> Perform managed inferencing (real time and batch)<\/li>\n<li> Stitch together multiple tasks and production workflows using Azure ML pipelines<\/li>\n<li> The SDK v2 is on par with CLI v2 functionality and is consistent in how assets (nouns) and actions (verbs) are used between SDK and CLI. For example, to list an asset, the list action can be used in both CLI and SDK. The same list action can be used to list a compute, model, environment, and so on.<\/li>\n<li><\/li>\n<\/ul>\n<p>I hope this helps.<\/p>\n<p>Regards,  <br \/>\nYutong  <br \/>\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Solution_comment_count":2.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":10.7,
        "Solution_reading_time":20.49,
        "Solution_score_count":0.0,
        "Solution_sentence_count":12.0,
        "Solution_word_count":229.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":24.7769444444,
        "Challenge_answer_count":2,
        "Challenge_body":"In Azure Machine Learning Service, when we deploy a Model as an AKS Webservice Endpoint, how can we raise exceptions to let the end-user get proper feedback if their API call is unsuccessful? Azure mentions using `azureml.exceptions.WebserviceException` in their documentation. However, how do we use this class to raise exceptions in case the API call cannot be processed properly and the end-user is responsible for it?",
        "Challenge_closed_time":1617344140000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1617254943000,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1413",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":10.6,
        "Challenge_reading_time":6.6,
        "Challenge_repo_contributor_count":55.0,
        "Challenge_repo_fork_count":2296.0,
        "Challenge_repo_issue_count":1858.0,
        "Challenge_repo_star_count":3528.0,
        "Challenge_repo_watch_count":2030.0,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":24.7769444444,
        "Challenge_title":"How to effectively use azureml.exceptions.WebserviceException for efficient REST API Error Management?",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":76,
        "Platform":"Github",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"@anirbansaha96 can you link to the doc you mention? The only doc I'm aware of about authoring errors is here: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-advanced-entry-script#binary-data\r\n \r\nWhich mentions using AMLResponse in the scoring file.\r\n\r\nAMLResponse will allow the writer of the scoring file to set a custom error message and api response code. Yes `return AMLResponse(\"Message\", status-code)` is what I was looking for. The documentation I was referring to: https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.exceptions.webserviceexception?view=azure-ml-py",
        "Solution_comment_count":null,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":13.4,
        "Solution_reading_time":7.89,
        "Solution_score_count":0.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":65.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1474169038352,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":66.0,
        "Answerer_view_count":7.0,
        "Challenge_adjusted_solved_time":67.8472183333,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Recently, while using a known-good endpoint configuration, I keep on receiving a: \"The model data archive is too large. Please reduce the size of the model data archive or move to an instance type with more memory.\" error. The tar.gz file is 7.7G but is not loaded in memory (only a small part of it is). I am wondering if anything changes recently that may be causing this issue. <\/p>\n\n<p>Thanks for any insights<\/p>\n\n<p>Emmanuel<\/p>",
        "Challenge_closed_time":1561639686816,
        "Challenge_comment_count":0,
        "Challenge_created_time":1561395436830,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/56740984",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":7.0,
        "Challenge_reading_time":6.45,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":67.8472183333,
        "Challenge_title":"Sagemaker custom model : \"The model data archive is too large\" error when creation endpoint",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":444.0,
        "Challenge_word_count":88,
        "Platform":"Stack Overflow",
        "Poster_created_time":1315924476963,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Lyon, France",
        "Poster_reputation_count":4510.0,
        "Poster_view_count":285.0,
        "Solution_body":"<p>When an Endpoint is created with SageMaker, the model data artifact is downloaded and uncompressed onto the associated disk\/EBS volume on the instance. This volume size is proportional[1] to the instance type that you chose. <\/p>\n\n<p>Please make sure that the instance type that you picked has enough disk space to accommodate the uncompressed .tar.gz file. (It does not matter if it is fully or partially loaded onto memory later on, it has to fit in the disk uncompressed).<\/p>\n\n<p>[1] Volume size for instance types - <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/host-instance-storage.html\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/host-instance-storage.html<\/a><\/p>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":12.6,
        "Solution_reading_time":9.2,
        "Solution_score_count":1.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":89.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1554186784008,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Hyderabad, Telangana, India",
        "Answerer_reputation_count":2175.0,
        "Answerer_view_count":434.0,
        "Challenge_adjusted_solved_time":14.9545102778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>In Advanced Scoring Scripting for AzureML webservice, to automatically generate a schema for our web service, we provide a sample of the input and\/or output in the constructor for one of the defined type objects. The type and sample are used to automatically create the schema.\nTo use schema generation, we include the open-source inference-schema package version 1.1.0 or above. The types that I can find include Numpy Type, Pandas Type, Abstract Parameter type.\nHow do we define the schema for a Nested Dictionary of (generalized) format:<\/p>\n<pre><code>{    &quot;top_level_key&quot;: [\n                         {&quot;nested_key_1&quot;: &quot;string_1&quot;,\n                          &quot;nested_key_2&quot;: &lt;float_number&gt;, \n                          &quot;nested_key_3&quot;: &lt;True\/False&gt;}\n                      ]\n}\n<\/code><\/pre>",
        "Challenge_closed_time":1622006064007,
        "Challenge_comment_count":0,
        "Challenge_created_time":1621952227770,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/67689868",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":10.6,
        "Challenge_reading_time":10.96,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":2.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":14.9545102778,
        "Challenge_title":"How to generate Inference Schema for Dictionary with nested structure using Azure InferenceSchema package?",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":172.0,
        "Challenge_word_count":109,
        "Platform":"Stack Overflow",
        "Poster_created_time":1601729162436,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Bengaluru, Karnataka, India",
        "Poster_reputation_count":887.0,
        "Poster_view_count":130.0,
        "Solution_body":"<p>we don\u2019t have a good way to extend the handling for generic Python class objects. However, we are planning to add support for that, basically by providing more information on the necessary hooks, and allowing users to extend a base class to implement the hook to match the desired class structure.\nThese types are currently supported:<\/p>\n<p>pandas\nnumpy\npyspark\nStandard Python object<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-advanced-entry-script#automatically-generate-a-swagger-schema\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-advanced-entry-script#automatically-generate-a-swagger-schema<\/a><\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":18.0,
        "Solution_reading_time":9.37,
        "Solution_score_count":2.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":66.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1576948018896,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Portugal",
        "Answerer_reputation_count":580.0,
        "Answerer_view_count":135.0,
        "Challenge_adjusted_solved_time":0.1342122222,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hey guys so recently i started working with sagemaker and I was testing autopilot and it got a fairly good accuracy and I wanted to test it on some more data so I chose the one with best ACC and created an endpoint. The problem now is that I don't know how to use the endpoit properly. I tried using AWS CLI but I keep getting the following errors:<\/p>\n<p>The command:<\/p>\n<pre><code>aws sagemaker-runtime invoke-endpoint --endpoint-name autopilottest --body 'SW0gaGFwcHk=' f\n<\/code><\/pre>\n<p>The error message:<\/p>\n<pre><code>An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (415) from container-1 with message &quot;'application\/json' is an unsupported content type.&quot;. See https:\/\/eu-west-2.console.aws.amazon.com\/cloudwatch\/home?region=eu-west-2#logEventViewer:group=\/aws\/sagemaker\/Endpoints\/autopilottest in account 288240193481 for more information.\n<\/code><\/pre>\n<p>The command:<\/p>\n<pre><code>aws sagemaker-runtime invoke-endpoint --endpoint-name autopilottest --body 'Im happy!' f\n<\/code><\/pre>\n<p>The error message:<\/p>\n<pre><code>Invalid base64: &quot;Im happy!&quot;\n<\/code><\/pre>\n<p>Endpoit configuration:\n<a href=\"https:\/\/i.stack.imgur.com\/11qAt.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/11qAt.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Challenge_closed_time":1633716252927,
        "Challenge_comment_count":0,
        "Challenge_created_time":1633715769763,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/69499960",
        "Challenge_link_count":3,
        "Challenge_participation_count":1,
        "Challenge_readability":13.9,
        "Challenge_reading_time":18.07,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":10,
        "Challenge_solved_time":0.1342122222,
        "Challenge_title":"Sagemaker Endpoint returning strange error",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":521.0,
        "Challenge_word_count":151,
        "Platform":"Stack Overflow",
        "Poster_created_time":1576948018896,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Portugal",
        "Poster_reputation_count":580.0,
        "Poster_view_count":135.0,
        "Solution_body":"<p>Ended up fixing the issue by adding <code>--content-type text\/csv<\/code> and using base64 and it worked like a charm.<\/p>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":8.0,
        "Solution_reading_time":1.57,
        "Solution_score_count":0.0,
        "Solution_sentence_count":1.0,
        "Solution_word_count":18.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1525449880547,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Madrid, Spain",
        "Answerer_reputation_count":81.0,
        "Answerer_view_count":5.0,
        "Challenge_adjusted_solved_time":68.6075986111,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I am starting to use aws sagemaker on the development of my machine learning model and I'm trying to build a lambda function to process the responses of a sagemaker labeling job. I already created my own lambda function but when I try to read the event contents I can see that the event dict is completely empty, so I'm not getting any data to read.<\/p>\n\n<p>I have already given enough permissions to the role of the lambda function. Including:\n- AmazonS3FullAccess.\n- AmazonSagemakerFullAccess.\n- AWSLambdaBasicExecutionRole<\/p>\n\n<p>I've tried using this code for the Post-annotation Lambda (adapted for python 3.6):<\/p>\n\n<p><a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/sms-custom-templates-step2-demo1.html#sms-custom-templates-step2-demo1-post-annotation\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/sms-custom-templates-step2-demo1.html#sms-custom-templates-step2-demo1-post-annotation<\/a><\/p>\n\n<p>As well as this one in this git repository:<\/p>\n\n<p><a href=\"https:\/\/github.com\/aws-samples\/aws-sagemaker-ground-truth-recipe\/blob\/master\/aws_sagemaker_ground_truth_sample_lambda\/annotation_consolidation_lambda.py\" rel=\"nofollow noreferrer\">https:\/\/github.com\/aws-samples\/aws-sagemaker-ground-truth-recipe\/blob\/master\/aws_sagemaker_ground_truth_sample_lambda\/annotation_consolidation_lambda.py<\/a><\/p>\n\n<p>But none of them seemed to work.<\/p>\n\n<p>For creating the labeling job I'm using boto3's functions for sagemaker:\n<a href=\"https:\/\/boto3.amazonaws.com\/v1\/documentation\/api\/latest\/reference\/services\/sagemaker.html#SageMaker.Client.create_labeling_job\" rel=\"nofollow noreferrer\">https:\/\/boto3.amazonaws.com\/v1\/documentation\/api\/latest\/reference\/services\/sagemaker.html#SageMaker.Client.create_labeling_job<\/a><\/p>\n\n<p>This is the code i have for creating the labeling job:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>def create_labeling_job(client,bucket_name ,labeling_job_name, manifest_uri, output_path):\n\n    print(\"Creating labeling job with name: %s\"%(labeling_job_name))\n\n    response = client.create_labeling_job(\n        LabelingJobName=labeling_job_name,\n        LabelAttributeName='annotations',\n        InputConfig={\n            'DataSource': {\n                'S3DataSource': {\n                    'ManifestS3Uri': manifest_uri\n                }\n            },\n            'DataAttributes': {\n                'ContentClassifiers': [\n                    'FreeOfAdultContent',\n                ]\n            }\n        },\n        OutputConfig={\n            'S3OutputPath': output_path\n        },\n        RoleArn='arn:aws:myrolearn',\n        LabelCategoryConfigS3Uri='s3:\/\/'+bucket_name+'\/config.json',\n        StoppingConditions={\n            'MaxPercentageOfInputDatasetLabeled': 100,\n        },\n        LabelingJobAlgorithmsConfig={\n            'LabelingJobAlgorithmSpecificationArn': 'arn:image-classification'\n        },\n        HumanTaskConfig={\n            'WorkteamArn': 'arn:my-private-workforce-arn',\n            'UiConfig': {\n                'UiTemplateS3Uri':'s3:\/\/'+bucket_name+'\/templatefile'\n            },\n            'PreHumanTaskLambdaArn': 'arn:aws:lambda:us-east-1:432418664414:function:PRE-BoundingBox',\n            'TaskTitle': 'Title',\n            'TaskDescription': 'Description',\n            'NumberOfHumanWorkersPerDataObject': 1,\n            'TaskTimeLimitInSeconds': 600,\n            'AnnotationConsolidationConfig': {\n                'AnnotationConsolidationLambdaArn': 'arn:aws:my-custom-post-annotation-lambda'\n            }\n        }\n    )\n\n    return response\n<\/code><\/pre>\n\n<p>And this is the one i have for the lambda function:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>    print(\"Received event: \" + json.dumps(event, indent=2))\n    print(\"event: %s\"%(event))\n    print(\"context: %s\"%(context))\n    print(\"event headers: %s\"%(event[\"headers\"]))\n\n    parsed_url = urlparse(event['payload']['s3Uri']);\n    print(\"parsed_url: \",parsed_url)\n\n    labeling_job_arn = event[\"labelingJobArn\"]\n    label_attribute_name = event[\"labelAttributeName\"]\n\n    label_categories = None\n    if \"label_categories\" in event:\n        label_categories = event[\"labelCategories\"]\n        print(\" Label Categories are : \" + label_categories)\n\n    payload = event[\"payload\"]\n    role_arn = event[\"roleArn\"]\n\n    output_config = None # Output s3 location. You can choose to write your annotation to this location\n    if \"outputConfig\" in event:\n        output_config = event[\"outputConfig\"]\n\n    # If you specified a KMS key in your labeling job, you can use the key to write\n    # consolidated_output to s3 location specified in outputConfig.\n    kms_key_id = None\n    if \"kmsKeyId\" in event:\n        kms_key_id = event[\"kmsKeyId\"]\n\n    # Create s3 client object\n    s3_client = S3Client(role_arn, kms_key_id)\n\n    # Perform consolidation\n    return do_consolidation(labeling_job_arn, payload, label_attribute_name, s3_client)\n<\/code><\/pre>\n\n<p>I've tried debugging the event object with:<\/p>\n\n<pre><code>    print(\"Received event: \" + json.dumps(event, indent=2))\n<\/code><\/pre>\n\n<p>But it just prints an empty dictionary: <code>Received event: {}<\/code><\/p>\n\n<p>I expect the output to be something like:<\/p>\n\n<pre><code>    #Content of an example event:\n    {\n        \"version\": \"2018-10-16\",\n        \"labelingJobArn\": &lt;labelingJobArn&gt;,\n        \"labelCategories\": [&lt;string&gt;],  # If you created labeling job using aws console, labelCategories will be null\n        \"labelAttributeName\": &lt;string&gt;,\n        \"roleArn\" : \"string\",\n        \"payload\": {\n            \"s3Uri\": &lt;string&gt;\n        }\n        \"outputConfig\":\"s3:\/\/&lt;consolidated_output configured for labeling job&gt;\"\n    }\n<\/code><\/pre>\n\n<p>Lastly, when I try yo get the labeling job ARN with:<\/p>\n\n<pre><code>    labeling_job_arn = event[\"labelingJobArn\"]\n<\/code><\/pre>\n\n<p>I just get a KeyError (which makes sense because the dictionary is empty).<\/p>",
        "Challenge_closed_time":1564741689012,
        "Challenge_comment_count":0,
        "Challenge_created_time":1564494701657,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1575462189052,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/57273357",
        "Challenge_link_count":6,
        "Challenge_participation_count":2,
        "Challenge_readability":23.8,
        "Challenge_reading_time":70.66,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":3.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":19,
        "Challenge_solved_time":68.6075986111,
        "Challenge_title":"Empty dictionary on AnnotationConsolidation lambda event for aws Sagemaker",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":846.0,
        "Challenge_word_count":425,
        "Platform":"Stack Overflow",
        "Poster_created_time":1525449880547,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Madrid, Spain",
        "Poster_reputation_count":81.0,
        "Poster_view_count":5.0,
        "Solution_body":"<p>I found the problem, I needed to add the ARN of the role used by my Lamda function as a Trusted Entity on the Role used for the Sagemaker Labeling Job.<\/p>\n\n<p>I just went to <code>Roles &gt; MySagemakerExecutionRole &gt; Trust Relationships<\/code> and added:<\/p>\n\n<pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"AWS\": [\n          \"arn:aws:iam::xxxxxxxxx:role\/My-Lambda-Role\",\n           ...\n        ],\n        \"Service\": [\n          \"lambda.amazonaws.com\",\n          \"sagemaker.amazonaws.com\",\n           ...\n        ]\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\n<\/code><\/pre>\n\n<p>This made it work for me.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":14.0,
        "Solution_reading_time":7.24,
        "Solution_score_count":0.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":64.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":3.4447222222,
        "Challenge_answer_count":1,
        "Challenge_body":"Has SAS code ever been successfully ran on SageMaker?",
        "Challenge_closed_time":1596117765000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1596105364000,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1668622375212,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUqMU2EBqGTDCMTPsB5rjNoQ\/has-sas-code-ever-been-successfully-ran-on-sagemaker",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":9.0,
        "Challenge_reading_time":1.34,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":2,
        "Challenge_solved_time":3.4447222222,
        "Challenge_title":"Has SAS code ever been successfully ran on SageMaker?",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":232.0,
        "Challenge_word_count":17,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":1.0,
        "Poster_isModerator":0.0,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"I\u2019ve helped customers run SAS on a notebook through a kernel and that was their main use case, but we also showed them how they can containerize SAS. Worked well",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1667925587744,
        "Solution_link_count":0.0,
        "Solution_readability":10.3,
        "Solution_reading_time":1.94,
        "Solution_score_count":0.0,
        "Solution_sentence_count":1.0,
        "Solution_word_count":30.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":32.9444641667,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I have been used Azure for the first time, and I am overwelmed by the huge quantity of information about Azure.    <\/p>\n<p>I think that the information about security on Azure is not unified.    <\/p>\n<p>For example, in <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/security\/fundamentals\/identity-management-best-practices\">Identity Management and access control security best practices<\/a> page, sometimes there are multiple best practices per one section header.    <br \/>\nHowever, in <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/storage\/blobs\/security-recommendations?toc=\/azure\/security\/fundamentals\/toc.json&amp;bc=\/azure\/security\/breadcrumb\/toc.json\">Security recommendations for Blob storage<\/a> page,security recommendations are documented in the form of table, one issue per one row.    <\/p>\n<p>I wish there was a cross-sectional, unified security check list for Azure as follows.    <\/p>\n<ul>\n<li> We could select Azure services we use.    <\/li>\n<li> When we select the services, the security check list are displayed or could be downloaded as text file.    <\/li>\n<li> The security check list are documented so that we can easily understand what we should do. (where on the Azure portal UI, which item, or how to do set the item which is related to security, etc)    <\/li>\n<\/ul>\n<p>I have used Azure services as follows.    <\/p>\n<ul>\n<li> Azure Data Factory    <\/li>\n<li> Azure Data Lake Storage Gen2    <\/li>\n<li> Azure Functions (App Service)    <\/li>\n<li> Azure Database for MySQL    <\/li>\n<li> Azure Machine Learning    <\/li>\n<li> Azure Monitor (for Application Insights)    <\/li>\n<\/ul>\n<p>Even if I take one service (for example, Azure Data Lake Storage Gen2), I think that I have to check at least two pages (<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/storage\/blobs\/security-recommendations?toc=\/azure\/security\/fundamentals\/toc.json&amp;bc=\/azure\/security\/breadcrumb\/toc.json\">here<\/a> and <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/security\/fundamentals\/paas-applications-using-storage\">here<\/a> ).    <br \/>\nHowever, I'm not sure if it's covered. Do you have any good ideas?    <\/p>\n<p>Regards.<\/p>",
        "Challenge_closed_time":1638553979008,
        "Challenge_comment_count":0,
        "Challenge_created_time":1638435378937,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/648921\/is-there-a-cross-sectional-unified-security-check",
        "Challenge_link_count":4,
        "Challenge_participation_count":2,
        "Challenge_readability":13.3,
        "Challenge_reading_time":27.68,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":16,
        "Challenge_solved_time":32.9444641667,
        "Challenge_title":"Is there a cross-sectional, unified security check list for Azure?",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":267,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hi <a href=\"\/users\/na\/?userid=c624669d-08b4-4372-b158-6b43fc05d41a\">@Makoto Oda  <\/a>,    <\/p>\n<p>Thanks for using Microsoft Q&amp;A!!    <\/p>\n<p>I do not think that we have a single document which can provide you a consolidated view of security across all Azure services.  You may need to go through the documentation available for individual services to get the required information.  However, you can try checking - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/security\/\">Azure security documentation<\/a> and <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/architecture\/framework\/security\/overview\">Security considerations for Azure Architecture center<\/a> if this helps you getting anything specific you are looking in Azure at higher level.     <\/p>\n<p>Hope this helps.    <\/p>\n<p>Thanks    <br \/>\nSaurabh    <\/p>\n",
        "Solution_comment_count":2.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":10.8,
        "Solution_reading_time":10.43,
        "Solution_score_count":0.0,
        "Solution_sentence_count":9.0,
        "Solution_word_count":93.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1548390570396,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":124.0,
        "Answerer_view_count":86.0,
        "Challenge_adjusted_solved_time":26.2102008333,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I'm doing following tutorial. I failed to run &quot;Create a control script&quot;.<\/p>\n<p>What could be wrong?<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-hello-world\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-hello-world<\/a><\/p>\n<pre><code>azureuser@kensmlcompute:~\/cloudfiles\/code\/Users\/my.name\/get-started$ python run-hello.py \nFailure while loading azureml_run_type_providers. Failed to load entrypoint automl = \nazureml.train.automl.run:AutoMLRun._from_run_dto with exception (pyarrow 4.0.0 \n(\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages), \nRequirement.parse('pyarrow&lt;4.0.0,&gt;=0.17.0'), {'azureml-dataset-runtime'}).\nhttps:\/\/ml.azure.com\/runs\/day1-experiment-hello_1623766747_073126f5? \nwsid=\/subscriptions\/1679753a-501e-4e46-9bff- \n6120ed5694cf\/resourcegroups\/kensazuremlrg\/workspaces\/kensazuremlws&amp;tid=94fe1041-ba47-4f49- \n866b- \n06c297c116cc\nazureuser@kensmlcompute:~\/cloudfiles\/code\/Users\/my.name\/get-started$\n<\/code><\/pre>",
        "Challenge_closed_time":1623861331176,
        "Challenge_comment_count":0,
        "Challenge_created_time":1623766974453,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/67988138",
        "Challenge_link_count":3,
        "Challenge_participation_count":2,
        "Challenge_readability":26.4,
        "Challenge_reading_time":15.59,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":11,
        "Challenge_solved_time":26.2102008333,
        "Challenge_title":"Azure ML Tutorial - Failed to load entrypoint automl",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":1241.0,
        "Challenge_word_count":54,
        "Platform":"Stack Overflow",
        "Poster_created_time":1478251050692,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Finland",
        "Poster_reputation_count":1519.0,
        "Poster_view_count":375.0,
        "Solution_body":"<p>I think the error indicates that your environment is using pyarrow package which is of version 4.0.0 whereas azureml-dataset-runtime requires the package to be &gt;=0.17.0 but &lt;4.0.0<\/p>\n<p>It would be easier for you to uninstall the package and install a specific version. The list of releases of pyarrow are available here.<\/p>\n<p>Since you are using a notebook create new cells and run these commands.<\/p>\n<pre><code> !pip uninstall pyarrow\n !pip install -y pyarrow==3.0.0\n<\/code><\/pre>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":5.7,
        "Solution_reading_time":6.2,
        "Solution_score_count":1.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":73.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1467237684900,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":613.0,
        "Answerer_view_count":39.0,
        "Challenge_adjusted_solved_time":30715.9147230556,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am a newbie when it comes to Python SageMaker (my background is C#). Currently, I have a problem because the last method call (I mean the fit method) results in a \"NoCredentialsError\". I do not understand that. The AWS credentials have been set and I do use them to communicate with AWS, for example to communicate with S3. How can I prevent this error? <\/p>\n\n<pre><code>import io\nimport os\nimport gzip\nimport pickle\nimport urllib.request\nimport boto3\nimport sagemaker\nimport sagemaker.amazon.common as smac\n\nDOWNLOADED_FILENAME = 'C:\/Users\/Daan\/PycharmProjects\/downloads\/mnist.pkl.gz'\nif not os.path.exists(DOWNLOADED_FILENAME):\n    urllib.request.urlretrieve(\"http:\/\/deeplearning.net\/data\/mnist\/mnist.pkl.gz\", DOWNLOADED_FILENAME)\n\nwith gzip.open(DOWNLOADED_FILENAME, 'rb') as f:\n    train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\nvectors = train_set[0].T\nbuf = io.BytesIO()\nsmac.write_numpy_to_dense_tensor(buf, vectors)\nbuf.seek(0)\nkey = 'recordio-pb-data'\nbucket_name = 'SOMEKINDOFBUCKETNAME'\nprefix = 'sagemaker\/pca'\npath = os.path.join(prefix, 'train', key)\nprint(path)\n\nsession = boto3.session.Session(aws_access_key_id='SECRET',aws_secret_access_key='SECRET',region_name='eu-west-1')\nclient = boto3.client('sagemaker',region_name='eu-west-1',aws_access_key_id='SECRET',aws_secret_access_key='SECRET')\nregion='eu-west-1'\nsagemakerSession= sagemaker.Session(sagemaker_client=client,boto_session=session)\ns3_resource=session.resource('s3')\nbucket = s3_resource.Bucket(bucket_name)\ncurrent_bucket = bucket.Object(path)\n\ntrain_data = 's3:\/\/{}\/{}\/train\/{}'.format(bucket_name, prefix, key)\nprint('uploading training data location: {}'.format(train_data))\ncurrent_bucket.upload_fileobj(buf)\n\noutput_location = 's3:\/\/{}\/{}\/output'.format('SOMEBUCKETNAME', prefix)\nprint('training artifacts will be uploaded to: {}'.format(output_location))\n\nregion='eu-west-1'\n\ncontainers = {'us-west-2': 'SOMELOCATION',\n              'us-east-1': 'SOMELOCATION',\n              'us-east-2': 'SOMELOCATION',\n              'eu-west-1': 'SOMELOCATION'}\ncontainer = containers[region]\n\nrole='AmazonSageMaker-ExecutionRole-SOMEVALUE'\npca = sagemaker.estimator.Estimator(container,\n                                    role,\n                                    train_instance_count=1,\n                                    train_instance_type='ml.c4.xlarge',\n                                    output_path=output_location,\n                                    sagemaker_session=sagemakerSession)\n\n\npca.set_hyperparameters(feature_dim=50000,\n                        num_components=10,\n                        subtract_mean=True,\n                        algorithm_mode='randomized',\n                        mini_batch_size=200)\n\npca.fit(inputs=train_data)\n\nprint('END')\n<\/code><\/pre>",
        "Challenge_closed_time":1526405500043,
        "Challenge_comment_count":0,
        "Challenge_created_time":1526393414957,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/50352412",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":19.9,
        "Challenge_reading_time":33.99,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":2.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":30,
        "Challenge_solved_time":3.3569683334,
        "Challenge_title":"How to prevent a NoCredentialsError when calling the fit method in SageMaker?",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":447.0,
        "Challenge_word_count":190,
        "Platform":"Stack Overflow",
        "Poster_created_time":1358429250663,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":2120.0,
        "Poster_view_count":279.0,
        "Solution_body":"<p>I am not sure if you have masked the actual access id and key or this is what you are running.<\/p>\n<pre><code>session = boto3.session.Session(aws_access_key_id='SECRET',aws_secret_access_key='SECRET',region_name='eu-west-1')\nclient = boto3.client('sagemaker',region_name='eu-west-1',aws_access_key_id='SECRET',aws_secret_access_key='SECRET')\n<\/code><\/pre>\n<p>I am hoping you are providing the actual aws_access_key_id and aws_secret_access_key in the above lines of code.<\/p>\n<p>Another way of specifying the same and not hardcoding in the code is to create a credentials file in your profile directory i.e.<\/p>\n<p>in Mac    ~\/.aws\/<\/p>\n<p>and in Windows <code>&quot;%UserProfile%\\.aws&quot;<\/code><\/p>\n<p>the file is a plain text file with a name &quot;credentials&quot; (without the quotes).\nfile contains<\/p>\n<pre><code>[default]\naws_access_key_id=XXXXXXXXXXXXXX\naws_secret_access_key=YYYYYYYYYYYYYYYYYYYYYYYYYYY\n<\/code><\/pre>\n<p>AWS CLI would pick it up from the above location and use it. You can also use non-default profiles and pass on the profile with<\/p>\n<pre><code>os.environ[&quot;AWS_PROFILE&quot;] = &quot;profile-name&quot;\n<\/code><\/pre>\n<p>Hope this helps.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1636970707960,
        "Solution_link_count":0.0,
        "Solution_readability":10.1,
        "Solution_reading_time":15.42,
        "Solution_score_count":2.0,
        "Solution_sentence_count":11.0,
        "Solution_word_count":124.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1342685175156,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Germany",
        "Answerer_reputation_count":12103.0,
        "Answerer_view_count":1451.0,
        "Challenge_adjusted_solved_time":257.7152338889,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I'm completely new to Azure ML, but I wanted to try out their automated ML UX. So I've followed the instructions to finally deploy my app (<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-create-portal-experiments#deploy-your-model\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-create-portal-experiments#deploy-your-model<\/a>). Now I've got my \"Scoring URI\", but I don't know how to use it? <strong>How can I test an input and get an output - can I do it with Postman?<\/strong><\/p>\n\n<ul>\n<li>the tutorial doesn't tell me what to do with this \"Scoring URI\", and so I am stuck<\/li>\n<\/ul>",
        "Challenge_closed_time":1565163075267,
        "Challenge_comment_count":0,
        "Challenge_created_time":1565145529467,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1565163086470,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/57386269",
        "Challenge_link_count":2,
        "Challenge_participation_count":1,
        "Challenge_readability":10.4,
        "Challenge_reading_time":9.08,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":4.8738333334,
        "Challenge_title":"How to use Azure ML Scoring URI?",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":826.0,
        "Challenge_word_count":85,
        "Platform":"Stack Overflow",
        "Poster_created_time":1526863814910,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":45.0,
        "Poster_view_count":26.0,
        "Solution_body":"<p>On the bottom of the page that you have linked above, there is a link:<\/p>\n\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-consume-web-service\" rel=\"nofollow noreferrer\">Learn how to consume a web service.<\/a><\/p>\n\n<p>This is exactly on that topic on how to use the deployed web service for scoring (sending an input and getting an output).<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1566090861312,
        "Solution_link_count":1.0,
        "Solution_readability":10.7,
        "Solution_reading_time":4.91,
        "Solution_score_count":1.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":48.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1403541426412,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Bengaluru, India",
        "Answerer_reputation_count":191.0,
        "Answerer_view_count":22.0,
        "Challenge_adjusted_solved_time":2355.5938513889,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have created the Azure ML experiment with R script module \nit works fine while we run the experiment but\n when we publish the web service it throws error http 500 \n ( I believe the error is causing in the R script module because other modules are running fine in web service but i can't debug the problem<\/p>\n\n<blockquote>\n  <p>Http status code: 500, Timestamp: Fri, 08 May 2015 04:23:14 GMT<\/p>\n<\/blockquote>\n\n<p>Also is there any limitation in r e.g. some function which wont work in web service<\/p>",
        "Challenge_closed_time":1439539745912,
        "Challenge_comment_count":0,
        "Challenge_created_time":1431059608047,
        "Challenge_favorite_count":1.0,
        "Challenge_last_edit_time":1446192965568,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/30115812",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":13.7,
        "Challenge_reading_time":7.12,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":1.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":2355.5938513889,
        "Challenge_title":"Error while running Azure Machine Learning web service but the experiment works fine",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":415.0,
        "Challenge_word_count":98,
        "Platform":"Stack Overflow",
        "Poster_created_time":1403541426412,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Bengaluru, India",
        "Poster_reputation_count":191.0,
        "Poster_view_count":22.0,
        "Solution_body":"<p>I found the problem. I was facing this error because the R module in the Azure ML was was taking variable as the other data type and not producing any outputs results which i was checking through for loop which is why i was getting this error.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":8.9,
        "Solution_reading_time":3.0,
        "Solution_score_count":1.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":47.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":0.1320822222,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>Experts,  <\/p>\n<p>I just try studio classic which is good but retired soon  <\/p>\n<p>I am moving to the new studio in azure portal. Any guidance for newbie?<\/p>",
        "Challenge_closed_time":1653988525023,
        "Challenge_comment_count":0,
        "Challenge_created_time":1653988049527,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/871064\/migrate-to-portal-studio",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":4.9,
        "Challenge_reading_time":2.28,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":0.1320822222,
        "Challenge_title":"Migrate to portal studio",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":31,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=e2f80e7a-2be8-4813-bb67-9ef92ac27f43\">@Alexandre  <\/a>     <\/p>\n<p>Welcome to Microsoft Q&amp;A Platform,    <\/p>\n<p>I would start checking the docs below:    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/overview-what-is-machine-learning-studio\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/overview-what-is-machine-learning-studio<\/a>    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-overview\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-overview<\/a>    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-rebuild-experiment\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-rebuild-experiment<\/a>    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-register-dataset\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-register-dataset<\/a>    <\/p>\n<p>I hope this helps!      <\/p>\n<p>----------    <\/p>\n<p>Please don\u2019t forget to &quot;<strong>Accept the answer<\/strong>&quot; and \u201c<strong>up-vote<\/strong>\u201d wherever the information provided helps you, this can be beneficial to other community members.<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":4.0,
        "Solution_readability":25.6,
        "Solution_reading_time":16.69,
        "Solution_score_count":0.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":61.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1566583092316,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":479.0,
        "Answerer_view_count":51.0,
        "Challenge_adjusted_solved_time":23.6450469444,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>My webservice deployed with Azure Machine Learning Studio exposes a classification model. Since the last re-training and re-deployment, in circa 1% of the processed cases in production, I get either of the two  following out-of-memory (possibly correlated) errors:<\/p>\n<ol>\n<li>&quot;The model consumed more memory than was appropriated for it. Maximum allowed memory for the model is 2560 MB. Please check your model for issues.&quot;<\/li>\n<li>&quot;The following error occurred during evaluation of R script: R_tryEval: return error: Error: cannot allocate vector of size 57.6 Mb&quot;<\/li>\n<\/ol>\n<p>I did not mange to find anything to solve this issue according to the official documentation.<\/p>\n<p>Note that these errors occur exclusively while trying to consume the webservice (and not while training, evaluation and deployment).<\/p>\n<p>Also, consuming the webservice in batch mode, as suggested <a href=\"https:\/\/social.microsoft.com\/Forums\/azure\/he-IL\/ccf4c683-f904-4117-8a4e-3258a56515f9\/azureml-execure-r-script-cannot-allocate-vector-of-size-818-mb?forum=MachineLearning\" rel=\"nofollow noreferrer\">here<\/a>, is not a viable option for my business use case.<\/p>\n<p>Is there a way to increase the memory usage limit for webservices deployed in Azure ML Studio?<\/p>",
        "Challenge_closed_time":1592917003232,
        "Challenge_comment_count":0,
        "Challenge_created_time":1592831881063,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/62515398",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":12.8,
        "Challenge_reading_time":17.17,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":11,
        "Challenge_solved_time":23.6450469444,
        "Challenge_title":"Out-of-memory error webservice deployed with Azure ML Studio",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":341.0,
        "Challenge_word_count":167,
        "Platform":"Stack Overflow",
        "Poster_created_time":1500322674452,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":91.0,
        "Poster_view_count":21.0,
        "Solution_body":"<p>Currently, there's no way to increase memory limit in Classic Studio. We encouraged customers to try <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-designer\" rel=\"nofollow noreferrer\">Azure Machine Learning designer (preview)<\/a>, which provides similar drag and drop ML modules plus scalability, version control, and enterprise security. Furthermore, with Designer, the endpoints are deployed to AKS where no limit other than cluster resource is imposed.<\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":13.6,
        "Solution_reading_time":6.35,
        "Solution_score_count":0.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":57.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":51.6131461111,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I'm trying to use Azure ML to host an image classification model trained in lobe.ai (externally trained model).     <\/p>\n<p>I've used the 'no code' model deployment approach described <a href=\"https:\/\/learn.microsoft.com\/en-gb\/azure\/machine-learning\/how-to-deploy-no-code-deployment\">here<\/a>     <\/p>\n<p>I've been able to authenticate my workspace and register my TensorFlow model, but the endpoint is stuck on transitioning for over 2 hours.     <\/p>\n<p>Any ideas?    <\/p>\n<pre><code>from azureml.core import Model  \n  \nmodel = Model.register(workspace=ws,  \n                       model_name='cxr',                            # Name of the registered model in your workspace.  \n                       model_path='cxr_test',                       # Local Tensorflow SavedModel folder to upload and register as a model.  \n                       model_framework=Model.Framework.TENSORFLOW,  # Framework used to create the model.  \n                       model_framework_version='1.15.3',            # Version of Tensorflow used to create the model.  \n                       description='Pneumonia-prediction model')  \n  \nservice_name = 'tensorflow-cxr-service'  \nservice = Model.deploy(ws, service_name, [model])  \n<\/code><\/pre>",
        "Challenge_closed_time":1605125180896,
        "Challenge_comment_count":5,
        "Challenge_created_time":1604939373570,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/156439\/endpoint-stuck-in-transitioning-state",
        "Challenge_link_count":1,
        "Challenge_participation_count":6,
        "Challenge_readability":11.2,
        "Challenge_reading_time":13.75,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":14,
        "Challenge_solved_time":51.6131461111,
        "Challenge_title":"Endpoint stuck in 'transitioning' state",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":114,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>We have created a support ticket for this issue and we will update the solution later. Thanks.  <\/p>\n<p>Regards,  <br \/>\nYutong<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":6.2,
        "Solution_reading_time":1.63,
        "Solution_score_count":0.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":21.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1442180190107,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":3203.0,
        "Answerer_view_count":400.0,
        "Challenge_adjusted_solved_time":20.4671011111,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>We currently have a system running on AWS Sagemaker whereby several units have their own trained machine learning model artifact (using an SKLearn training script with the Sagemaker SKLearn estimator).<\/p>\n<p>Through the use of Sagemaker's multi-model endpoints, we are able to host all of these units on a single instance.<\/p>\n<p>The problem we have is that we need to scale this system up such that we can train individual models for hundreds of thousand of units and then host the resulting model artifacts on a multi-model endpoint. But, Sagemaker has a limit to the number of models you can train in parallel (our limit is 30).<\/p>\n<p>Aside from training our models in batches, does anyone have any ideas how to go about implementing a system in AWS Sagemaker whereby for hundreds of thousands of units, we can have a separate trained model artifact for each unit?<\/p>\n<p>Is there a way to output multiple model artifacts for 1 sagemaker training job with the use of an SKLearn estimator?<\/p>\n<p>Furthermore, how does Sagemaker make use of multiple CPUs when a training script is submitted? Does this have to be specified in the training script\/estimator object or is this handled automatically?<\/p>",
        "Challenge_closed_time":1603790179687,
        "Challenge_comment_count":0,
        "Challenge_created_time":1603715439387,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1603716498123,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/64537150",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":12.0,
        "Challenge_reading_time":15.32,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":20.7611944445,
        "Challenge_title":"AWS Sagemaker Multiple Training Jobs",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":1053.0,
        "Challenge_word_count":202,
        "Platform":"Stack Overflow",
        "Poster_created_time":1592311727163,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":153.0,
        "Poster_view_count":15.0,
        "Solution_body":"<p>Here are some ideas:<\/p>\n<p><em><strong>1. does anyone have any ideas how to go about implementing a system in AWS Sagemaker whereby for hundreds of thousands of units, we can have a separate trained model artifact for each unit? Is there a way to output multiple model artifacts for 1 sagemaker training job with the use of an SKLearn estimator?<\/strong><\/em><\/p>\n<p>I don't know if the 30-training job concurrency is a hard limit, if it is a blocker you should try and open a support ticket to ask if it is and try and get it raised. Otherwise as you can point out, you can try and train multiple models in one job, and produce multiple artifacts that you can either (a) send to S3 manually, or (b) save to <code>opt\/ml\/model<\/code> so that they all get sent to the model.tar.gz artifact in S3. Note that if this artifact gets too big this could get impractical though<\/p>\n<p><em><strong>2. how does Sagemaker make use of multiple CPUs when a training script is submitted? Does this have to be specified in the training script\/estimator object or is this handled automatically?<\/strong><\/em><\/p>\n<p>This depends on the type of training container you are using. SageMaker built-in containers are developed by Amazon teams and designed to efficiently use available resources. If you use your own code such as custom python in the Sklearn container, you are responsible for making sure that your code is efficiently written and uses available hardware. Hence framework choice is quite important :) for example, some sklearn models support explicitly using multiple CPUs (eg the <code>n_jobs<\/code> parameter in the <a href=\"https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.RandomForestClassifier.html\" rel=\"nofollow noreferrer\">random forest<\/a>), but I don't think that Sklearn natively supports GPU, multi-GPU or multi-node training.<\/p>",
        "Solution_comment_count":3.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":11.1,
        "Solution_reading_time":23.18,
        "Solution_score_count":2.0,
        "Solution_sentence_count":14.0,
        "Solution_word_count":281.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1454844135036,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"T\u00fcrkiye",
        "Answerer_reputation_count":462.0,
        "Answerer_view_count":83.0,
        "Challenge_adjusted_solved_time":1.2255941667,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I created an endpoint in <code>aws sagemaker<\/code> and it works well, I created a <code>lambda<\/code> function(<code>python3.6<\/code>) that takes files from <code>S3<\/code>, invoke the endpoint and then put the output in a file in <code>S3<\/code>. <\/p>\n\n<p>I wonder if I can create the endpoint at every event(a file uploaded in an <code>s3 bucket)<\/code> and then delete the endpoint <\/p>",
        "Challenge_closed_time":1550836836772,
        "Challenge_comment_count":0,
        "Challenge_created_time":1550832424633,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1550840459832,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/54825390",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":9.5,
        "Challenge_reading_time":5.57,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":1.2255941667,
        "Challenge_title":"create aws sagemker endpoint with lambda function",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":180.0,
        "Challenge_word_count":64,
        "Platform":"Stack Overflow",
        "Poster_created_time":1502010899808,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Tunis, Tunisia",
        "Poster_reputation_count":109.0,
        "Poster_view_count":14.0,
        "Solution_body":"<p>Yes you can Using <code>S3<\/code> event notification for object-created and call a <code>lambda<\/code> for creating endpoint for <code>sagemaker<\/code>.<\/p>\n\n<p>This example shows how to make <code>object-created event trigger lambda<\/code><\/p>\n\n<p><a href=\"https:\/\/docs.aws.amazon.com\/lambda\/latest\/dg\/with-s3.html\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/lambda\/latest\/dg\/with-s3.html<\/a><\/p>\n\n<p>You can use <code>python sdk<\/code> to create endpoint for <code>sagemaker<\/code><\/p>\n\n<p><a href=\"https:\/\/boto3.amazonaws.com\/v1\/documentation\/api\/latest\/reference\/services\/sagemaker.html#SageMaker.Client.create_endpoint\" rel=\"nofollow noreferrer\">https:\/\/boto3.amazonaws.com\/v1\/documentation\/api\/latest\/reference\/services\/sagemaker.html#SageMaker.Client.create_endpoint<\/a><\/p>\n\n<p>But it might be slow for creating endpoint so you may be need to wait.<\/p>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":1550837083230,
        "Solution_link_count":4.0,
        "Solution_readability":23.8,
        "Solution_reading_time":11.88,
        "Solution_score_count":0.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":61.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":12.2930863889,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hello,    <\/p>\n<p>We are sending data from IoT Central to Event Hubs and then to Data Explorer, with the hopes of then sending the data to Azure Machine Learning.    <\/p>\n<p>In order to send data from Event Hubs to Data Explorer it needs a data ingestion into a table on data explorer.    <\/p>\n<p>For this data ingestion, it needs a json mapping.    <\/p>\n<p>We could ingest the data, but the message from the iot central data goes to event hubs that goes to data explorer carries the telemetry data as a dynamic type (a json inside a json).     <\/p>\n<pre><code>(&quot;telemetry&quot;:{&quot;Temp:&quot;37&quot;,&quot;Vol&quot;:&quot;97&quot;})  \n<\/code><\/pre>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/90018-data.jpg?platform=QnA\" alt=\"90018-data.jpg\" \/>    <br \/>\nWe want to separate the telemetry data in different columns.    <\/p>\n<p>So Temp will have one column and Vol another.    <\/p>\n<p>I am wondering how that can be done?    <\/p>\n<p>And additionally, since we would like to send the data to ML, can data explorer be used as a datastore in ML?    <\/p>\n<p>Thanks!!    <\/p>",
        "Challenge_closed_time":1619080604288,
        "Challenge_comment_count":0,
        "Challenge_created_time":1619036349177,
        "Challenge_favorite_count":null,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/366532\/separate-data-in-data-explorer-and-use-as-datastor",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":9.8,
        "Challenge_reading_time":14.03,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":10,
        "Challenge_solved_time":12.2930863889,
        "Challenge_title":"Separate data in data explorer and use as datastore",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":168,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=a706cc9a-ba35-4065-a95e-7fd5a2c7ba9d\">@yjay  <\/a>,    <\/p>\n<p>You can use <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/data-explorer\/kusto\/query\/parseoperator\">parse operator<\/a> - Evaluates a string expression and parses its value into one or more calculated columns. The calculated columns will have nulls, for unsuccessfully parsed strings.     <\/p>\n<p>For more details, refer <a href=\"https:\/\/stackoverflow.com\/questions\/63779632\/split-column-string-with-delimiters-into-separate-columns-in-azure-kusto\">SO<\/a> thread addressing similar issue.     <\/p>\n<blockquote>\n<p>Unfortuantely, Azure Data Explorer is not a supported storage solution with Azure Machine Learning.     <\/p>\n<\/blockquote>\n<p>Datastores currently support storing connection information to the storage services listed in the following matrix.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/90159-image.png?platform=QnA\" alt=\"90159-image.png\" \/>    <\/p>\n<p>For unsupported storage solutions, and to save data egress cost during ML experiments, move your data to a supported Azure storage solution.    <\/p>\n<p><strong>Reference:<\/strong> <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data\">Connect to storage services on Azure - Azure Machine Learning<\/a>.     <\/p>\n<p>Hope this helps. Do let us know if you any further queries.    <\/p>\n<p>------------    <\/p>\n<p>Please don\u2019t forget to <code>Accept Answer<\/code> and <code>Up-Vote<\/code> wherever the information provided helps you, this can be beneficial to other community members.    <\/p>\n",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":4.0,
        "Solution_readability":14.5,
        "Solution_reading_time":20.83,
        "Solution_score_count":1.0,
        "Solution_sentence_count":15.0,
        "Solution_word_count":157.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":0.1647222222,
        "Challenge_answer_count":1,
        "Challenge_body":"We would like to make algorithms shareable and re-usable across teams. Is it possible to create a private Amazon SageMaker algorithm marketplace?",
        "Challenge_closed_time":1556296138000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1556295545000,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1668245479612,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUCu2f_chpRL2mDtFiGqwVNg\/private-marketplace-for-sagemaker-algorithms",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":10.2,
        "Challenge_reading_time":2.42,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":0.1647222222,
        "Challenge_title":"Private Marketplace for SageMaker algorithms",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":120.0,
        "Challenge_word_count":26,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":1.0,
        "Poster_isModerator":0.0,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"[Private Marketplace](https:\/\/aws.amazon.com\/marketplace\/privatemarketplace\/) is a feature of the AWS Marketplace platform that AWS customers can use to create a private catalog of products containing both algorithms and models which are available in AWS Marketplace. To create a private catalog containing algorithms which have not been published in AWS Marketplace, you can use AWS Service Catalog. [AWS Service Catalog](https:\/\/aws.amazon.com\/servicecatalog\/) lets users create and share algorithms packaged via a CloudFormation template. However, you do have to make the container image and model artifacts available in the destination account outside AWS Service Catalog. Here is a sample template for sharing a model - https:\/\/github.com\/aws-samples\/aws-service-catalog-reference-architectures\/blob\/master\/sagemaker\/sagemaker_vend_endpoint.yml ",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1612474519792,
        "Solution_link_count":3.0,
        "Solution_readability":15.6,
        "Solution_reading_time":11.02,
        "Solution_score_count":0.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":99.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1646907459852,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Hyderabad, Telangana, India",
        "Answerer_reputation_count":1624.0,
        "Answerer_view_count":1376.0,
        "Challenge_adjusted_solved_time":79.1199802778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>We are defining in Databricks a PythonScriptStep(). When using PythonScriptStep() within our pipeline script we can't find the scoring.py file.<\/p>\n<pre><code>scoring_step = PythonScriptStep(\n    name=&quot;Scoring_Step&quot;,\n    source_directory=os.getenv(&quot;DATABRICKS_NOTEBOOK_PATH&quot;, &quot;\/Users\/USER_NAME\/source_directory&quot;),\n    script_name=&quot;.\/scoring.py&quot;,\n    arguments=[&quot;--input_dataset&quot;, ds_consumption],\n    compute_target=pipeline_cluster,\n    runconfig=pipeline_run_config,\n    allow_reuse=False)\n<\/code><\/pre>\n<p>We getting the following error message:<\/p>\n<pre><code>Step [Scoring_Step]: script not found at: \/databricks\/driver\/scoring.py. Make sure to specify an appropriate source_directory on the Step or default_source_directory on the Pipeline.\n<\/code><\/pre>\n<p>For some reason Databricks is searching for the file in '\/databricks\/driver\/' instead of the folder we entered.<\/p>\n<p>There is also the way to use DatabricksStep() instead of PythonScriptStep(), but because of specific reasons we need to use the PythonSriptStep() class.<\/p>\n<p>Could anybody help us with this specific problem?<\/p>\n<p>Thank you very much for any help!<\/p>",
        "Challenge_closed_time":1656324774632,
        "Challenge_comment_count":0,
        "Challenge_created_time":1655997421433,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1656039942703,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/72732616",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":10.8,
        "Challenge_reading_time":16.23,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":12,
        "Challenge_solved_time":90.9314441667,
        "Challenge_title":"Can't find scoring.py when using PythonScriptStep() in Databricks",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":68.0,
        "Challenge_word_count":123,
        "Platform":"Stack Overflow",
        "Poster_created_time":1544598969960,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Germany",
        "Poster_reputation_count":37.0,
        "Poster_view_count":21.0,
        "Solution_body":"<pre><code>scoring_step = PythonScriptStep(\n    name=&quot;Scoring_Step&quot;,\n    source_directory=os.getenv(&quot;DATABRICKS_NOTEBOOK_PATH&quot;, &quot;\/Users\/USER_NAME\/source_directory&quot;),\n    script_name=&quot;.\/scoring.py&quot;,\n    arguments=[&quot;--input_dataset&quot;, ds_consumption],\n    compute_target=pipeline_cluster,\n    runconfig=pipeline_run_config,\n    allow_reuse=False)\n<\/code><\/pre>\n<p>Change the above code block with below code block. It will resolve the error<\/p>\n<pre><code>data_ref = OutputFileDatasetConfig(\n    name='data_ref',\n    destination=(ds, '\/data')\n).as_upload()\n\n\ndata_prep_step = PythonScriptStep(\n    name='data_prep',\n    script_name='pipeline_steps\/data_prep.py',\n    source_directory='\/.',\n    arguments=[\n        '--main_path', main_ref,\n        '--data_ref_folder', data_ref\n                ],\n    inputs=[main_ref, data_ref],\n    outputs=[data_ref],\n    runconfig=arbitrary_run_config,\n    allow_reuse=False\n)\n<\/code><\/pre>\n<p>Reference link for the <a href=\"https:\/\/scoring_step%20=%20PythonScriptStep(%20%20%20%20%20name=%22Scoring_Step%22,%20%20%20%20%20source_directory=os.getenv(%22DATABRICKS_NOTEBOOK_PATH%22,%20%22\/Users\/USER_NAME\/source_directory%22),%20%20%20%20%20script_name=%22.\/scoring.py%22,%20%20%20%20%20arguments=%5B%22--input_dataset%22,%20ds_consumption%5D,%20%20%20%20%20compute_target=pipeline_cluster,%20%20%20%20%20runconfig=pipeline_run_config,%20%20%20%20%20allow_reuse=False)\" rel=\"nofollow noreferrer\">documentation<\/a><\/p>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":32.4,
        "Solution_reading_time":19.66,
        "Solution_score_count":0.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":56.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":133.3984755556,
        "Challenge_answer_count":1,
        "Challenge_body":"I have a customer already standardized Artifactory as the centralized image registration. They disabled ECR service at Org level. Now we want to understand the potential impact on customer's day-2-day use of SageMaker Studio as a platform to support their full ML lifecycle. \n\n(If customer only use built-in SageMaker algorithm or framework and use prebuilt SageMaker container images)\n\nEspecially when customer trying to deploy the model to endpoint, does that need ECR service to be enabled in customer account?",
        "Challenge_closed_time":1650300385539,
        "Challenge_comment_count":0,
        "Challenge_created_time":1649820151027,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1668444527276,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUXZB0Oki3QamlQ5ijtVSuzQ\/without-ecr-being-enabled-in-aws-account-at-organization-level-what-s-the-impact-to-sagemaker-studio",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":11.8,
        "Challenge_reading_time":7.64,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":133.3984755556,
        "Challenge_title":"Without ECR being enabled in AWS account at Organization Level, what's the impact to SageMaker Studio?",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":179.0,
        "Challenge_word_count":94,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"Hi, yes, if you're restricting the user to only built-in algorithms and frameworks, and prebuilt images for Studio, you should be able to use it seamlessly (to deploy endpoints as well). That said, it severely restricts the data scientist from using custom images that could be built to their needs and packages, or bringing their own container for machine learning.",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1650300385539,
        "Solution_link_count":0.0,
        "Solution_readability":13.8,
        "Solution_reading_time":4.51,
        "Solution_score_count":1.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":60.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1499772840847,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":46.0,
        "Answerer_view_count":4.0,
        "Challenge_adjusted_solved_time":39.9339302778,
        "Challenge_answer_count":1,
        "Challenge_body":"<h1>Context<\/h1>\n<p>Hi!<\/p>\n<p>In <code>wandb<\/code> I can download a model based on a tag (<code>prod<\/code> for example), but I would like to also get all metrics associated to that run by using tags.<\/p>\n<p>The problem is that I don't know how to a get specific run ID based a tag.<\/p>\n<h1>Example<\/h1>\n<p>Using the code bellow we can extract a run summary metrics, but setting run IDs is setting me back.<\/p>\n<p>So if I can get run IDs based on tag or just explicitly download metrics  with another API call, like with a special sintax in <code>api.run<\/code>, that would be great! In the code example bellow I would like to use the <code>what_i_want_to_use<\/code> string to call the API instead of <code>what_i_use<\/code>.<\/p>\n<pre><code>import wandb\nfrom ast import literal_eval\napi = wandb.Api()\n\nwhat_i_use = &quot;team_name\/project_name\/runID_h3h3h4h4h4h4&quot;\n# what_i_want_to_use = &quot;team_name\/project_name\/artifact_name\/prod_tag&quot;\n\n# run is specified by &lt;entity&gt;\/&lt;project&gt;\/&lt;run_id&gt;\nrun = api.run(what_i_use)\n\n\n# save the metrics for the run to a csv file\nmetrics_dataframe = run.summary\nprint(metrics_dataframe['a_summary_metric'])\n\n<\/code><\/pre>\n<p>By running through the docs I didn't find any solution so far. Any ideias?<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/mWl3I.png\" rel=\"nofollow noreferrer\">wandb public api run details<\/a><\/p>\n<p>Thanks for reading!<\/p>",
        "Challenge_closed_time":1650458488356,
        "Challenge_comment_count":0,
        "Challenge_created_time":1650314726207,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/71916901",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":10.0,
        "Challenge_reading_time":18.29,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":13,
        "Challenge_solved_time":39.9339302778,
        "Challenge_title":"WANDB Getting a run id based on tag",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":645.0,
        "Challenge_word_count":184,
        "Platform":"Stack Overflow",
        "Poster_created_time":1444675970627,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":null,
        "Poster_reputation_count":5.0,
        "Poster_view_count":6.0,
        "Solution_body":"<p>It is possible to filter runs by tags as well. You can read more about it <a href=\"https:\/\/docs.wandb.ai\/ref\/python\/public-api\/api#runs\" rel=\"nofollow noreferrer\">here<\/a>:<\/p>\n<pre><code>You can filter by config.*, summary_metrics.*, tags, state, entity, createdAt, etc.\n<\/code><\/pre>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":11.1,
        "Solution_reading_time":3.78,
        "Solution_score_count":0.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":32.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_created_time":null,
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":1.0,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Challenge_adjusted_solved_time":1753.1691666667,
        "Challenge_answer_count":1,
        "Challenge_body":"Customer wants to host multiple DNN models on same SageMaker container due to latency concerns. Customer does not want to spin-up different containers for each model due to network adding additional latency. Thus, my customer asked me a question below -\n\n> Can one SageMaker host more than one model? Each model then share the\n> same input and produce different outputs concatenated together?\n\nI answered as below -\n\nYes. Amazon SageMaker supports you hosting multiple models in several different ways \u2013\n\n 1. Using Multi-model Inference endpoints: \nAmazon SageMaker supports serving multiple models from same Inference endpoint. Details can be found [here](1). The sample code can be found [here](2).  Currently, this feature do not support Elastic Inference or serial inference pipelines. Multi-model endpoints also enable time-sharing of memory resources across your models. This works best when the models are fairly similar in size and invocation latency. When this is the case, multi-model endpoints can effectively use instances across all models. If you have models that have significantly higher transactions per second (TPS) or latency requirements, we recommend hosting them on dedicated endpoints. Multi-model endpoints are also well suited to scenarios that can tolerate occasional cold-start-related latency penalties that occur when invoking infrequently used models\n\n 2. Using Bring your own algorithm on SageMaker\nYou can also bring your own container with your own libs and runtime\/programming language for serving and training. See the example notebook on how you can bring your own algorithm\/container image on sagemaker [here](3)\n\n 3. Using Multi-model serving container by using multi-model archive file\n      You can find a sample example here [4] for tensorflow serving\n 4. If models are called sequentially, the SageMaker inference pipeline allows you to chain up to 5 models called one after the other on the same endpoint\nSagemaker endpoints include optimizations that will save costs, such as (1) 1-click deploy to pre-configured environments for popular ML frameworks with a managed serving stack, (2) autoscaling, (3) model compilation, (4) cost-effective hardware acceleration via Elastic Inference, (5) multi-variant model deployment for testing and overlapped model replacement, (6) multi-AZ backend. It is not necessarily a good idea to have multiple models on same endpoint (unless you have the reasons and requirements I mentioned in Option A above). Having one model per endpoint creates an isolation which has positive benefits on fault tolerance, security and scalability. Please keep in mind that SageMaker works on containers that runs on top of EC2.\n\n[1]https:\/\/aws.amazon.com\/blogs\/machine-learning\/save-on-inference-costs-by-using-amazon-sagemaker-multi-model-endpoints\/\n\n[2]https:\/\/github.com\/awslabs\/amazon-sagemaker-examples\/blob\/master\/advanced_functionality\/multi_model_bring_your_own\/multi_model_endpoint_bring_your_own.ipynb\n\n[3]https:\/\/github.com\/awslabs\/amazon-sagemaker-examples\/blob\/master\/advanced_functionality\/scikit_bring_your_own\/scikit_bring_your_own.ipynb\n\n[4]https:\/\/github.com\/aws\/sagemaker-python-sdk\/blob\/master\/src\/sagemaker\/tensorflow\/deploying_tensorflow_serving.rst#deploying-more-than-one-model-to-your-endpoint\n\n[5]https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/inference-pipelines.html\n\nAm I missing anything? Any other suggestions in terms of other approaches?",
        "Challenge_closed_time":1593677528000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1587366119000,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1668583474750,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUfmnWJIIZQs6_2K1uIH9stQ\/sagemaker-with-multiple-models",
        "Challenge_link_count":5,
        "Challenge_participation_count":1,
        "Challenge_readability":15.7,
        "Challenge_reading_time":44.33,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":0.0,
        "Challenge_self_resolution":null,
        "Challenge_sentence_count":25,
        "Challenge_solved_time":1753.1691666667,
        "Challenge_title":"SageMaker with multiple models",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":683.0,
        "Challenge_word_count":419,
        "Platform":"Tool-specific",
        "Poster_created_time":null,
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Solution_body":"> Customer does not want to spin-up different containers for each model due to network adding additional latency. \n\nI am assuming this is a pipeline scenario where different models need to be chained.\nIf so, it's important to keep in mind that all containers in pipeline run on the __same EC2 instance__ so that \"inferences run with low latency because the containers are co-located on the same EC2 instances.\"[1]\n\nHope this is useful.   \n[1] https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/inference-pipelines.html",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":1667925593992,
        "Solution_link_count":1.0,
        "Solution_readability":11.7,
        "Solution_reading_time":6.39,
        "Solution_score_count":0.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":74.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1426694564423,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Paris",
        "Answerer_reputation_count":2425.0,
        "Answerer_view_count":459.0,
        "Challenge_adjusted_solved_time":111.6768886111,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have some data in S3 and I want to create a lambda function to predict the output with my deployed aws sagemaker endpoint then I put the outputs in S3 again. Is it necessary in this case to create an api gateway like decribed in this <a href=\"https:\/\/aws.amazon.com\/blogs\/machine-learning\/call-an-amazon-sagemaker-model-endpoint-using-amazon-api-gateway-and-aws-lambda\/\" rel=\"nofollow noreferrer\">link<\/a> ? and in the lambda function what I have to put. I expect to put (where to find the data, how to invoke the endpoint, where to put the data) <\/p>\n\n<p>Thanks<\/p>",
        "Challenge_closed_time":1549874448016,
        "Challenge_comment_count":0,
        "Challenge_created_time":1549472411217,
        "Challenge_favorite_count":1.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/54558832",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":10.1,
        "Challenge_reading_time":7.77,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":2.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":111.6768886111,
        "Challenge_title":"call sagemaker endpoint using lambda function",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":5259.0,
        "Challenge_word_count":87,
        "Platform":"Stack Overflow",
        "Poster_created_time":1502010899808,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Tunis, Tunisia",
        "Poster_reputation_count":109.0,
        "Poster_view_count":14.0,
        "Solution_body":"<p>you definitely don't have to create an API in API Gateway. You can invoke the endpoint directly using the invoke_endpoint() API, passing the endpoint name, the content type, and the payload.<\/p>\n\n<p>For example:<\/p>\n\n<pre><code>import boto3\n\nendpoint_name = &lt;INSERT_ENDPOINT_NAME&gt;\nruntime = boto3.Session().client(service_name='sagemaker-runtime',region_name='us-east-1')\n\nresponse = runtime.invoke_endpoint(EndpointName=endpoint_name, ContentType='application\/x-image', Body=payload)\nprint(response['Body'].read())\n<\/code><\/pre>\n\n<p>More examples here using a Lambda function: <a href=\"https:\/\/medium.com\/@julsimon\/using-chalice-to-serve-sagemaker-predictions-a2015c02b033\" rel=\"nofollow noreferrer\">https:\/\/medium.com\/@julsimon\/using-chalice-to-serve-sagemaker-predictions-a2015c02b033<\/a><\/p>",
        "Solution_comment_count":2.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":2.0,
        "Solution_readability":20.6,
        "Solution_reading_time":10.89,
        "Solution_score_count":4.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":56.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_created_time":1395422283667,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":null,
        "Answerer_reputation_count":1411.0,
        "Answerer_view_count":45.0,
        "Challenge_adjusted_solved_time":0.6555202778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have deployed an AzureML published experiment with deployed web service. I tried to use the <a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-consume-web-services\/\" rel=\"nofollow\">sample code provided in the configuration page<\/a>, but universal apps do not implement Http.Formatting yet, thus I couldn't use <a href=\"https:\/\/msdn.microsoft.com\/en-us\/library\/hh944521(v=vs.118).aspx\" rel=\"nofollow\">postasjsonasync<\/a>.<\/p>\n\n<p>I tried to follow the sample code as much as possible, but I'm getting statuscode of 415 \"Unsupported Media Type\", What's the mistake I'm doing?<\/p>\n\n<pre><code>var client = new HttpClient();\nclient.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue(\"Bearer\", apiKey);\n\/\/ client.BaseAddress = uri;\n\nvar scoreRequest = new\n{\n            Inputs = new Dictionary&lt;string, StringTable&gt;() {\n                    {\n                        \"dataInput\",\n                        new StringTable()\n                        {\n                            ColumnNames = new [] {\"Direction\", \"meanX\", \"meanY\", \"meanZ\"},\n                            Values = new [,] {  { \"\", x.ToString(), y.ToString(), z.ToString() },  }\n                        }\n                    },\n                },\n            GlobalParameters = new Dictionary&lt;string, string&gt;() { }\n };\n var stringContent = new StringContent(scoreRequest.ToString());\n HttpResponseMessage response = await client.PostAsync(uri, stringContent);\n<\/code><\/pre>\n\n<p>Many Thanks<\/p>",
        "Challenge_closed_time":1452007973623,
        "Challenge_comment_count":0,
        "Challenge_created_time":1452005613750,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/34614582",
        "Challenge_link_count":2,
        "Challenge_participation_count":1,
        "Challenge_readability":13.0,
        "Challenge_reading_time":16.98,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":12,
        "Challenge_solved_time":0.6555202778,
        "Challenge_title":"Send request as Json on UWP",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":3194.0,
        "Challenge_word_count":117,
        "Platform":"Stack Overflow",
        "Poster_created_time":1352139399460,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Cyprus",
        "Poster_reputation_count":820.0,
        "Poster_view_count":256.0,
        "Solution_body":"<p>You'll need to serialize the object to a JSON string (I recommend using NewtonSoft.Json to make it easier) and set the content type accordingly. Here's an implementation I'm using in my UWP apps (note that <code>_client<\/code> is an <code>HttpClient<\/code>):<\/p>\n\n<pre><code>    public async Task&lt;HttpResponseMessage&gt; PostAsJsonAsync&lt;T&gt;(Uri uri, T item)\n    {\n        var itemAsJson = JsonConvert.SerializeObject(item);\n        var content = new StringContent(itemAsJson);\n        content.Headers.ContentType = new MediaTypeHeaderValue(\"application\/json\");\n\n        return await _client.PostAsync(uri, content);\n    }\n<\/code><\/pre>",
        "Solution_comment_count":0.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":0.0,
        "Solution_readability":13.2,
        "Solution_reading_time":7.86,
        "Solution_score_count":3.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":62.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1225669466307,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"Cambridge, United Kingdom",
        "Answerer_reputation_count":236107.0,
        "Answerer_view_count":18730.0,
        "Challenge_adjusted_solved_time":0.1705583334,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am working with Azure ML and I have the code sample to invoke my web  service (alas it is only in C#).  Can someone help me translate this to F#?  I have everything but the async and await done.<\/p>\n\n<pre><code> static async Task InvokeRequestResponseService()\n        {\n            using (var client = new HttpClient())\n            {\n                ScoreData scoreData = new ScoreData()\n                {\n                    FeatureVector = new Dictionary&lt;string, string&gt;() \n                    {\n                        { \"Zip Code\", \"0\" },\n                        { \"Race\", \"0\" },\n                        { \"Party\", \"0\" },\n                        { \"Gender\", \"0\" },\n                        { \"Age\", \"0\" },\n                        { \"Voted Ind\", \"0\" },\n                    },\n                    GlobalParameters = new Dictionary&lt;string, string&gt;() \n                    {\n                    }\n                };\n\n                ScoreRequest scoreRequest = new ScoreRequest()\n                {\n                    Id = \"score00001\",\n                    Instance = scoreData\n                };\n\n                const string apiKey = \"abc123\"; \/\/ Replace this with the API key for the web service\n                client.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue( \"Bearer\", apiKey);\n\n                client.BaseAddress = new Uri(\"https:\/\/ussouthcentral.services.azureml.net\/workspaces\/19a2e623b6a944a3a7f07c74b31c3b6d\/services\/f51945a42efa42a49f563a59561f5014\/score\");\n                HttpResponseMessage response = await client.PostAsJsonAsync(\"\", scoreRequest);\n                if (response.IsSuccessStatusCode)\n                {\n                    string result = await response.Content.ReadAsStringAsync();\n                    Console.WriteLine(\"Result: {0}\", result);\n                }\n                else\n                {\n                    Console.WriteLine(\"Failed with status code: {0}\", response.StatusCode);\n                }\n            }\n<\/code><\/pre>\n\n<p>Thanks<\/p>",
        "Challenge_closed_time":1410733358503,
        "Challenge_comment_count":3,
        "Challenge_created_time":1410732744493,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":1446025307110,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/25838512",
        "Challenge_link_count":1,
        "Challenge_participation_count":4,
        "Challenge_readability":10.9,
        "Challenge_reading_time":17.94,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":2.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":13,
        "Challenge_solved_time":0.1705583334,
        "Challenge_title":"C# async\/await to F# using Azure ML example",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":607.0,
        "Challenge_word_count":136,
        "Platform":"Stack Overflow",
        "Poster_created_time":1349689794400,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Denver, CO, USA",
        "Poster_reputation_count":4174.0,
        "Poster_view_count":396.0,
        "Solution_body":"<p>I was not able to compile and run the code, but you probably need something like this:<\/p>\n\n<pre><code>let invokeRequestResponseService() = async {\n    use client = new HttpClient()\n    let scoreData = (...)\n    let apiKey = \"abc123\"\n    client.DefaultRequestHeaders.Authorization &lt;- \n        new AuthenticationHeaderValue(\"Bearer\", apiKey)\n    client.BaseAddress &lt;- Uri(\"https:\/\/ussouthcentral....\/score\");\n    let! response = client.PostAsJsonAsync(\"\", scoreRequest) |&gt; Async.AwaitTask\n    if response.IsSuccessStatusCode then\n        let! result = response.Content.ReadAsStringAsync() |&gt; Async.AwaitTask\n        Console.WriteLine(\"Result: {0}\", result);\n    else\n        Console.WriteLine(\"Failed with status code: {0}\", response.StatusCode) }\n<\/code><\/pre>\n\n<ul>\n<li><p>Wrapping the code in the <code>async { .. }<\/code> block makes it asynchronous and lets you use <code>let!<\/code> inside the block to perform asynchronous waiting (i.e. in places where you'd use <code>await<\/code> in C#)<\/p><\/li>\n<li><p>F# uses type <code>Async&lt;T&gt;<\/code> instead of .NET Task, so when you're awaiting a task, you need to insert <code>Async.AwaitTask<\/code> (or you can write wrappers for the most frequently used operations)<\/p><\/li>\n<li><p>The <code>invokeRequestResponseService()<\/code> function returns F# async, so if you need to pass it to some other library function (or if it needs to return a task), you can use <code>Async.StartAsTask<\/code><\/p><\/li>\n<\/ul>",
        "Solution_comment_count":5.0,
        "Solution_last_edit_time":null,
        "Solution_link_count":1.0,
        "Solution_readability":8.3,
        "Solution_reading_time":18.27,
        "Solution_score_count":4.0,
        "Solution_sentence_count":16.0,
        "Solution_word_count":156.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_created_time":1565528932887,
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Answerer_location":"United Kingdom",
        "Answerer_reputation_count":1579.0,
        "Answerer_view_count":91.0,
        "Challenge_adjusted_solved_time":17.8840719444,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am deploying 50 NLP models on Azure Container Instances via the Azure Machine Learning service. All 50 models are quite similar and have the same input\/output format with just the model implementation changing slightly. <\/p>\n\n<p>I want to write a generic score.py entry file and pass in the model name as a parameter. The interface method signature does not allow a parameter in the init() method of score.py, so I moved the model loading into the run method. I am assuming the init() method gets run once whereas Run(data) will get executed on every invocation, so this is possibly not ideal (the models are 1 gig in size)<\/p>\n\n<p>So how can I pass in some value to the init() method of my container to tell it what model to load? <\/p>\n\n<p>Here is my current, working code:<\/p>\n\n<pre><code>def init():\n\ndef loadModel(model_name):\n    model_path = Model.get_model_path(model_name)  \n    return fasttext.load_model(model_path)\n\ndef run(raw_data):\n    # extract model_name from raw_data omitted...\n    model = loadModel(model_name)\n\n    ...\n<\/code><\/pre>\n\n<p>but this is what I would like to do (which breaks the interface)<\/p>\n\n<pre><code>def init(model_name):\n    model = loadModel(model_name)\n\ndef loadModel(model_name):\n    model_path = Model.get_model_path(model_name)  \n    return fasttext.load_model(model_path)\n\ndef run(raw_data):\n    ...\n<\/code><\/pre>",
        "Challenge_closed_time":1572381894847,
        "Challenge_comment_count":0,
        "Challenge_created_time":1572325608637,
        "Challenge_favorite_count":0.0,
        "Challenge_last_edit_time":null,
        "Challenge_link":"https:\/\/stackoverflow.com\/questions\/58601697",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":9.9,
        "Challenge_reading_time":17.45,
        "Challenge_repo_contributor_count":null,
        "Challenge_repo_fork_count":null,
        "Challenge_repo_issue_count":null,
        "Challenge_repo_star_count":null,
        "Challenge_repo_watch_count":null,
        "Challenge_score_count":1.0,
        "Challenge_self_resolution":0.0,
        "Challenge_sentence_count":14,
        "Challenge_solved_time":15.6350583334,
        "Challenge_title":"How to pass in the model name during init in Azure Machine Learning Service?",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":851.0,
        "Challenge_word_count":195,
        "Platform":"Stack Overflow",
        "Poster_created_time":1256089885500,
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Poster_location":"Sydney, Australia",
        "Poster_reputation_count":4947.0,
        "Poster_view_count":531.0,
        "Solution_body":"<p>If you're looking to use the same deployed container and switch models between requests; it's not the preferred design choice for Azure machine learning service, we need to specify the model name to load during build\/deploy.<\/p>\n\n<p>Ideally, each deployed web-service endpoint should allow inference of one model only; with the model name defined before the container the image starts building\/deploying. <\/p>\n\n<p>It is mandatory that the entry script has both <code>init()<\/code> and <code>run(raw_data)<\/code> with those <strong>exact<\/strong> signatures. <\/p>\n\n<p>At the moment, we can't change the signature of <code>init()<\/code> method to take a parameter like in <code>init(model_name)<\/code>.  <\/p>\n\n<p>The only dynamic user input you'd ever get to pass into this web-service is via <code>run(raw_data)<\/code> method. As you have tried, given the size of your model passing it via run is not feasible. <\/p>\n\n<p><code>init()<\/code> is run first and only <strong>once<\/strong> after your web-service deploy. Even if <code>init()<\/code> took the <code>model_name<\/code> parameter, there isn't a straight forward way to call this method directly and pass your desired model name.<\/p>\n\n<hr>\n\n<p>But, one possible solution is: <\/p>\n\n<p>You can create params file like below and store the file in azure blob storage.<\/p>\n\n<p>Example runtime parameters generation script:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import pickle\n\nparams = {'model_name': 'YOUR_MODEL_NAME_TO_USE'}\n\nwith open('runtime_params.pkl', 'wb') as file:\n    pickle.dump(params, file)\n\n<\/code><\/pre>\n\n<p>You'll need to use <a href=\"https:\/\/github.com\/Azure\/azure-storage-python\" rel=\"nofollow noreferrer\">Azure Storage Python SDK<\/a> to write code that can read from your blob storage account. This also mentioned in the official docs <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-deploy-and-where#prepare-to-deploy\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>\n\n<p>Then you can access this from <code>init()<\/code> function in your score script. <\/p>\n\n<p>Example <code>score.py<\/code> script:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from azure.storage.blob import BlockBlobService\nimport pickle\n\ndef init():\n\n  global model\n\n  block_blob_service = BlockBlobService(connection_string='your_connection_string')\n\n  blob_item = block_blob_service.get_blob_to_bytes('your-container-name','runtime_params.pkl')\n\n  params = pickle.load(blob_item.content)\n\n  model = loadModel(params['model_name'])\n<\/code><\/pre>\n\n<p>You can store connection strings in Azure KeyVault for secure access. Azure ML Workspaces comes with built-in KeyVault integration. More info <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.keyvault.keyvault?view=azure-ml-py#get-secret-name-\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>\n\n<p>With this approach, you're abstracting runtime params config to another cloud location rather than the container itself. So you wouldn't need to re-build the image or deploy the web-service again. Simply restarting the container will work.<\/p>\n\n<hr>\n\n<p>If you're looking to simply re-use <code>score.py<\/code> (not changing code) for <strong>multiple model deployments in multiple containers<\/strong> then here's another possible solution.<\/p>\n\n<p>You can define your model name to use in web-service in a text file and read it in score.py. You'll need to pass this text file as a dependency when setting up the image config.<\/p>\n\n<p>This would, however, need multiple params files for each container deployment.<\/p>\n\n<p>Passing 'runtime_params.pkl' in <code>dependencies<\/code> to your image config (More detail example <a href=\"https:\/\/github.com\/rithinch\/heartfulness-similar-content-service\/blob\/master\/experiments\/notebooks\/Deploy%20Model%20-%20Azure.ipynb\" rel=\"nofollow noreferrer\">here<\/a>):<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>image_config = ContainerImage.image_configuration(execution_script=\"score.py\", \n                                                  runtime=\"python\", \n                                                  conda_file=\"myenv.yml\",\n                                                  dependencies=[\"runtime_params.pkl\"],\n                                                  docker_file=\"Dockerfile\")\n<\/code><\/pre>\n\n<p>Reading this in your score.py <code>init()<\/code> function:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>def init():\n\n  global model\n\n  with open('runtime_params.pkl', 'rb') as file:\n    params = pickle.load(file)\n\n  model = loadModel(params['model_name'])\n\n<\/code><\/pre>\n\n<p>Since your creating a new image config with this approach, you'll need to build the image and re-deploy the service.<\/p>",
        "Solution_comment_count":1.0,
        "Solution_last_edit_time":1572389991296,
        "Solution_link_count":4.0,
        "Solution_readability":12.7,
        "Solution_reading_time":58.32,
        "Solution_score_count":3.0,
        "Solution_sentence_count":40.0,
        "Solution_word_count":476.0,
        "Tool":"Azure Machine Learning"
    }
]