[
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":4.6135575,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Currently! I'm experimenting with the azure data labelling tool in the machine learning workspace for image classification, what I found was azure shows only the unlabelled data to each user i.e if a user has already labelled an image, other users won't be shown the same image again.   <br \/>\nIs there any setting that exists, which can be enabled or disabled so that we can let more than one labeller label the same data?   <\/p>",
        "Challenge_closed_time":1625073229547,
        "Challenge_comment_count":0,
        "Challenge_created_time":1625056620740,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/458004\/azure-machine-learning-data-labelling-is-it-possib",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":11.7,
        "Challenge_reading_time":6.98,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":4.6135575,
        "Challenge_title":"Azure machine learning data labelling- Is it possible to assign different labelers to label same data in a single project to reach a consensus?",
        "Challenge_topic":"Data Labeling",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":null,
        "Challenge_word_count":98,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Thanks for reaching to us. This capability is currently in development, and expected to release soon.<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":8.8,
        "Solution_reading_time":1.37,
        "Solution_score_count":0.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":16.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":1.30024,
        "Challenge_answer_count":3,
        "Challenge_body":"<p>Trying to download a report as latex causes an instrument.js error, and the waiting symbol turns forever. I use chrome on MacOS.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/4\/4c88c4ac7b283a2fef287aa3cd58a712426c2f77.jpeg\" data-download-href=\"\/uploads\/short-url\/aV3jmQ0drwgzx2rJ9iyEpD7TJQj.jpeg?dl=1\" title=\"Bildschirmfoto 2023-02-13 um 17.42.14\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/4\/4c88c4ac7b283a2fef287aa3cd58a712426c2f77_2_690x307.jpeg\" alt=\"Bildschirmfoto 2023-02-13 um 17.42.14\" data-base62-sha1=\"aV3jmQ0drwgzx2rJ9iyEpD7TJQj\" width=\"690\" height=\"307\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/4\/4c88c4ac7b283a2fef287aa3cd58a712426c2f77_2_690x307.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/4\/4c88c4ac7b283a2fef287aa3cd58a712426c2f77_2_1035x460.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/4\/4c88c4ac7b283a2fef287aa3cd58a712426c2f77_2_1380x614.jpeg 2x\" data-dominant-color=\"959190\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Bildschirmfoto 2023-02-13 um 17.42.14<\/span><span class=\"informations\">1886\u00d7841 173 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Challenge_closed_time":1676311598268,
        "Challenge_comment_count":0,
        "Challenge_created_time":1676306917404,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/download-report-as-latex-causes-js-errors\/3872",
        "Challenge_link_count":5,
        "Challenge_participation_count":3,
        "Challenge_readability":24.9,
        "Challenge_reading_time":21.95,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":11,
        "Challenge_solved_time":1.30024,
        "Challenge_title":"Download report as latex causes js errors",
        "Challenge_topic":"Compute Management",
        "Challenge_topic_macro":"Computation Management",
        "Challenge_view_count":210.0,
        "Challenge_word_count":76,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Found a solution: When carefully loading each graph by scrolling slowly over the whole page, the download finally works.<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":9.5,
        "Solution_reading_time":1.6,
        "Solution_score_count":null,
        "Solution_sentence_count":1.0,
        "Solution_word_count":19.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":167.2076163889,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>In this <a href=\"https:\/\/github.com\/MicrosoftLearning\/DP100\/blob\/master\/07B%20-%20Creating%20a%20Batch%20Inferencing%20Service.ipynb\">example<\/a>, all data files for the parallel run step are stored in <strong>one<\/strong> folder.    <\/p>\n<p>I also want to create a parallel run step. The task for each of the several <strong>folders<\/strong>, in which the multiple data files are stored, is exactly identical.     <\/p>\n<p>The folders:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/182769-image.png?platform=QnA\" alt=\"182769-image.png\" \/>    <\/p>\n<p>The content of each folder:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/182833-image.png?platform=QnA\" alt=\"182833-image.png\" \/>    <\/p>\n<p>How should I define the <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-pipeline-steps\/azureml.pipeline.steps.parallelrunstep?view=azure-ml-py\">ParallelRunStep<\/a>-class so that the identical task for each folder (here 'a', 'b', 'c', 'd' and 'e') is executed in parallel?    <br \/>\nTwo folders should run simultaneously in parallel.    <\/p>\n<p>Moreover, I would like to ask how to get <strong>only<\/strong> the stored folder names or folder paths from a given directory path of a blob storage container.    <\/p>",
        "Challenge_closed_time":1647858343236,
        "Challenge_comment_count":1,
        "Challenge_created_time":1647256395817,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/771015\/list-of-folder-names-as-input-for-parallelrunstep",
        "Challenge_link_count":4,
        "Challenge_participation_count":2,
        "Challenge_readability":12.8,
        "Challenge_reading_time":17.16,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":11,
        "Challenge_solved_time":167.2076163889,
        "Challenge_title":"list of folder names as input for ParallelRunStep-class",
        "Challenge_topic":"Pipeline Configuration",
        "Challenge_topic_macro":"Lifecycle Management",
        "Challenge_view_count":null,
        "Challenge_word_count":134,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>@@AlexanderPakakis-0994 Thanks, An Azure ML dataset is just metadata pointing to a path or collection of paths in an Azure storage account. You should first &quot;merge&quot; those datasets into a collection of adjacent folders (e.g. root\/dataset1\/, root\/dataset2\/, ...) and then run PRS against root\/**.<\/p>\n",
        "Solution_comment_count":3.0,
        "Solution_link_count":0.0,
        "Solution_readability":7.7,
        "Solution_reading_time":3.94,
        "Solution_score_count":1.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":43.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":0.0855555556,
        "Challenge_answer_count":0,
        "Challenge_body":"From slack\n\nI am currently defining some machines configuration using machine-env1.yaml, machine-env2.yaml which basically contains node selectors and CPU, GPU, and TPU requests configuration, and then running:\n\npolyaxon run -f polyaxonfile.yaml -f machine-env1.yaml\n\nI have two problems with this approach:\n\nI need to copy the env files to all our git repos, which means if I make a change I need to perform several pull requests\nI need to tell the data-scientits to pull the last commit, sometimes that's not possible because they can not merge\/rebase the changes.\n\nBased on those two issues, in the end we tell data-scientists to just use:\n\nenvironment:\n  nodeSelector:\n    nodes: large-pool\n...\nrun:\n  ...\n  container:\n      resources:\n        limits:\n          cpu: 3000m\n          memory: 6000Mi\n        requests:\n          cpu: 2000m\n          memory: 4000Mi\n\nWhich is error prone and confusing for them, and make the files bigger and difficult to change.\n\nAny elegant way to abstract this type of configuration from the data-scientists?",
        "Challenge_closed_time":1649337274000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1649336966000,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1484",
        "Challenge_link_count":0,
        "Challenge_participation_count":0,
        "Challenge_readability":11.6,
        "Challenge_reading_time":13.74,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":8,
        "Challenge_solved_time":0.0855555556,
        "Challenge_title":"I would like to configure Polyaxon in a way to avoid asking data-scientists to configure pre-emptible node-pools or request TPUs on their own",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":null,
        "Challenge_word_count":170,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"We have already shared a resource on how to configure the environments in this guide\n\nif you are using multiple git repos and you do not want to replicate the yaml files in all repos you can register those files as presets:\n\nUsers will be able to use --presets machine1 or --presets=env1\n\nNote that in the example in that link, it shows that it defines a queue but you do not have to define a queue, a preset is just any YAML file that can be used with the override operator -f main.yaml -f override1.yaml -f override2.yaml in this case override1.yaml and override2.yaml it can be saved as organization presets using the UI.\n\nMore info from the intro section about presets and the UI section\n\nAlso, when you define presets you can use them directly on the operation or component\n\npresets: [preset1, preset2]\n\nThis is similar to the CLI command\n\npolyaxon run -f polyaxon.yaml --presets preset1,preset2",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":8.5,
        "Solution_reading_time":10.83,
        "Solution_score_count":1.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":156.0,
        "Tool":"Polyaxon"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":24.0520611111,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>Can we connect Azure ML Notebooks directly to Snowflake using Private end-points, my ML Workspace is inside a VNet.<\/p>",
        "Challenge_closed_time":1653034845860,
        "Challenge_comment_count":0,
        "Challenge_created_time":1652948258440,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/855820\/connect-azure-ml-with-snowflake-using-private-endp",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":7.2,
        "Challenge_reading_time":2.25,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":2,
        "Challenge_solved_time":24.0520611111,
        "Challenge_title":"Connect Azure ML with Snowflake using Private endpoint?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":26,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=03343194-9922-4c28-abc7-1d7c46b6d2d6\">@Varun  <\/a>     <\/p>\n<p>Thanks for reaching out to us, currently there is no internal way in Azure Machine Learning Studio to connect to Snowflake. I am sorry for all inconveniences.     <\/p>\n<p>But you can run a  Python 3 code to use the Snowflake python connector - <a href=\"https:\/\/docs.snowflake.com\/en\/user-guide\/python-connector.html\">https:\/\/docs.snowflake.com\/en\/user-guide\/python-connector.html<\/a>    <\/p>\n<p>With Azure ML Studio, there's no built-in support for SnowFlake, I will forward your feedback to product group to see if there any plan in the future.     <\/p>\n<p>Hope this helps!    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p><em>-Please kindly accept the answer if you feel helpful, thanks a lot for supporting the community.<\/em>     <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":1.0,
        "Solution_readability":9.0,
        "Solution_reading_time":10.31,
        "Solution_score_count":0.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":103.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":176.3419125,
        "Challenge_answer_count":5,
        "Challenge_body":"<p>I got this on win10,it\u2019s stucked<br>\nthe enviornment is<\/p>\n<ul>\n<li>python3.7.10<\/li>\n<li>wandb 0.12.9<\/li>\n<\/ul>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/b2ce90f5e63f7db9be89aa163ee55f0ab468a430.png\" data-download-href=\"\/uploads\/short-url\/pvNysR6Ps6qxY0fl0Y5gjzfovBK.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/b2ce90f5e63f7db9be89aa163ee55f0ab468a430.png\" alt=\"image\" data-base62-sha1=\"pvNysR6Ps6qxY0fl0Y5gjzfovBK\" width=\"547\" height=\"500\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/b2ce90f5e63f7db9be89aa163ee55f0ab468a430_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">686\u00d7626 26.9 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Challenge_closed_time":1641690199763,
        "Challenge_comment_count":0,
        "Challenge_created_time":1641055368878,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/error-with-wandb-on-win10\/1656",
        "Challenge_link_count":3,
        "Challenge_participation_count":5,
        "Challenge_readability":25.9,
        "Challenge_reading_time":15.89,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":8,
        "Challenge_solved_time":176.3419125,
        "Challenge_title":"Error with wandb on win10",
        "Challenge_topic":"Compute Management",
        "Challenge_topic_macro":"Computation Management",
        "Challenge_view_count":235.0,
        "Challenge_word_count":52,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>I\u2019ve deleted wandb in docker and pip ,then I reinstalled them.<br>\nAnd I got the right page after waiting about 5 or 6 minutes.<br>\nBut I don\u2019t know whtether the reason is the versions are different or something.<br>\nThis time I didn\u2019t set the LOCAL_RESOTRE var, I don\u2019t know whether the time will decrease.<br>\nAnd I notice that once I get the right page, the next time I can get in immediately.<br>\nThanks a lot.<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":4.6,
        "Solution_reading_time":5.1,
        "Solution_score_count":null,
        "Solution_sentence_count":6.0,
        "Solution_word_count":75.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":9.7155897222,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I'm trying to follow the steps given here - <a href=\"https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/explore-analyze-data-with-python\/2-exercise-explore-data\">https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/explore-analyze-data-with-python\/2-exercise-explore-data<\/a>    <\/p>\n<p>I've tried regions east us2 and east us for creating the instance but it fails after taking more than half an hour. I tried virtual machine sizes - Standard_DS11_v2 &amp; Standard_DS3_v2.    <\/p>\n<p>Any help would be appreciated.     <\/p>\n<p>Edit - I don't have any other instances running in my subscription, so it should not be a quota issue. The error message says &quot;An internal server error occurred.&quot;.<\/p>",
        "Challenge_closed_time":1616282059876,
        "Challenge_comment_count":0,
        "Challenge_created_time":1616247083753,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/323742\/unable-to-creata-a-compute-instance",
        "Challenge_link_count":1,
        "Challenge_participation_count":2,
        "Challenge_readability":12.5,
        "Challenge_reading_time":9.46,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":9.7155897222,
        "Challenge_title":"Unable to creata a compute instance",
        "Challenge_topic":"Quota Management",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":null,
        "Challenge_word_count":81,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Good day <a href=\"\/users\/na\/?userid=79ab735d-44c2-44c3-954b-5a6233041e68\">@Aatish Suman  <\/a>      <\/p>\n<p>Did you read the comment in the compute page?    <\/p>\n<p>Please confirm that you are using an account which fit the limitations    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/79891-image.png?platform=QnA\" alt=\"79891-image.png\" \/>    <\/p>\n<p>For more information please check this post:    <\/p>\n<p><a href=\"https:\/\/azure.microsoft.com\/en-us\/blog\/update-2-on-microsoft-cloud-services-continuity\/\">https:\/\/azure.microsoft.com\/en-us\/blog\/update-2-on-microsoft-cloud-services-continuity\/<\/a>    <\/p>\n<p>Note: I followed the tutorial which you provided the link to and it is working well for me. Therefore, I assume the issue is related to the above comment.     <\/p>\n",
        "Solution_comment_count":2.0,
        "Solution_link_count":2.0,
        "Solution_readability":12.9,
        "Solution_reading_time":10.28,
        "Solution_score_count":0.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":75.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":185.8020663889,
        "Challenge_answer_count":7,
        "Challenge_body":"<p>Dear W&amp;B Community,<\/p>\n<p>I have system metrics logged like the \u201c<em>time per step<\/em>\u201d or \u201c<em>time per backward pass<\/em>\u201d for a model.<br>\nWhen doing this on different hardware, I would like to compare the effect this has on these metrics.<br>\nIn the following examples, I profile the basic Torch CIFAR10 model on a 1,2,4,8,16 and 32 CPU VM.<\/p>\n<p>When looking at a <code>Linechart<\/code>, the full history of these metrics is visible, however, it is very hard to compare them due to the overlapping and oscillation:<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/fc4a70f56ac98f28ece07b404e7c5e734d81d351.png\" data-download-href=\"\/uploads\/short-url\/zZROm2jlGDN4WUrxx2lQXAA8jYZ.png?dl=1\" title=\"W&amp;amp;B Chart 9_19_2022, 6_22_16 PM\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/fc4a70f56ac98f28ece07b404e7c5e734d81d351_2_690x362.png\" alt=\"W&amp;B Chart 9_19_2022, 6_22_16 PM\" data-base62-sha1=\"zZROm2jlGDN4WUrxx2lQXAA8jYZ\" width=\"690\" height=\"362\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/fc4a70f56ac98f28ece07b404e7c5e734d81d351_2_690x362.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/fc4a70f56ac98f28ece07b404e7c5e734d81d351_2_1035x543.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/fc4a70f56ac98f28ece07b404e7c5e734d81d351_2_1380x724.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/fc4a70f56ac98f28ece07b404e7c5e734d81d351_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">W&amp;amp;B Chart 9_19_2022, 6_22_16 PM<\/span><span class=\"informations\">3539\u00d71859 509 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>When using a <code>Barchart<\/code>, only the last value is visualized:<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/48a4597177e867b3eb511112ad23b561f18f1137.png\" data-download-href=\"\/uploads\/short-url\/amCuG3pzRgnimYoyoJeru5muDMH.png?dl=1\" title=\"W&amp;amp;B Chart 9_19_2022, 6_20_31 PM\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/48a4597177e867b3eb511112ad23b561f18f1137_2_690x362.png\" alt=\"W&amp;B Chart 9_19_2022, 6_20_31 PM\" data-base62-sha1=\"amCuG3pzRgnimYoyoJeru5muDMH\" width=\"690\" height=\"362\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/48a4597177e867b3eb511112ad23b561f18f1137_2_690x362.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/48a4597177e867b3eb511112ad23b561f18f1137_2_1035x543.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/48a4597177e867b3eb511112ad23b561f18f1137_2_1380x724.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/48a4597177e867b3eb511112ad23b561f18f1137_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">W&amp;amp;B Chart 9_19_2022, 6_20_31 PM<\/span><span class=\"informations\">3539\u00d71859 251 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>The functionality that would be nice is to group values based on their count or occurrence, as grouping by runs already works perfectly. Here\u2019s the same data but run through <code>seaborn.barplot<\/code>:<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/379ac43b0eee017cfc2884cd7a3635262eb5d479.png\" data-download-href=\"\/uploads\/short-url\/7VTQur5SLq8cPHTQtTqGrDuwPRn.png?dl=1\" title=\"download\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/379ac43b0eee017cfc2884cd7a3635262eb5d479_2_690x427.png\" alt=\"download\" data-base62-sha1=\"7VTQur5SLq8cPHTQtTqGrDuwPRn\" width=\"690\" height=\"427\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/379ac43b0eee017cfc2884cd7a3635262eb5d479_2_690x427.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/379ac43b0eee017cfc2884cd7a3635262eb5d479_2_1035x640.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/379ac43b0eee017cfc2884cd7a3635262eb5d479_2_1380x854.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/379ac43b0eee017cfc2884cd7a3635262eb5d479_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">download<\/span><span class=\"informations\">3777\u00d72341 159 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>Would this be possible to implement? Or does anybody know a way to get that functionality?<\/p>\n<p>My current workaround is to download the data manually and run it through seaborn. Unfortunately, I did not understand the errors I\u2019ve gotten with the <code>Custom Chart<\/code> functionality when trying to port Vega examples to use wandb as a data basis.<\/p>\n<p>I\u2019d be very glad if anybody can point me to a tutorial on how to migrate existing Vega examples to be used with wandb (and the common problems, like differences between v3\/v4\/v5, as these seemed to be an issue for me).<\/p>",
        "Challenge_closed_time":1664274024356,
        "Challenge_comment_count":0,
        "Challenge_created_time":1663605136917,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/barchart-grouping-by-time-step-count\/3157",
        "Challenge_link_count":18,
        "Challenge_participation_count":7,
        "Challenge_readability":21.3,
        "Challenge_reading_time":80.47,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":23,
        "Challenge_solved_time":185.8020663889,
        "Challenge_title":"Barchart Grouping by Time\/Step\/Count",
        "Challenge_topic":"Metric Logging",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":796.0,
        "Challenge_word_count":367,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi Alexander,<\/p>\n<p>Thanks for sending this detailed explanation! I have been exploring it and I think that the issue here is that, in lines 22, 29 and 43 you have \u201cdata\u201d: \u201ctable\u201d but as the name has been changed to \u201cwandb\u201d, then you should have \u201cdata\u201d: \u201cwandb\u201d. To solve the error between lines 4 and 6, you can use <span class=\"chcklst-box fa fa-square-o fa-fw\"><\/span> and it is solved, but it seems that it is not affecting to the chart.<\/p>\n<pre><code>\"data\": [{ \"name\": \"wandb\" }]\n<\/code><\/pre>\n<p>Please let me know if this would be useful for you!<\/p>\n<p>Best,<br>\nLuis<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":7.2,
        "Solution_reading_time":7.17,
        "Solution_score_count":null,
        "Solution_sentence_count":5.0,
        "Solution_word_count":96.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":1.2138261111,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have a question about <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-register-datasets#tabulardataset\">the source of TabularDataset on Azure Machine Learnigng<\/a>.    <\/p>\n<p>Can I use compressed data saved Azure Data Lake Storage Gen2 like below on TablarDataset without expansion?    <\/p>\n<ul>\n<li> csv with bzip2(.bz2)    <\/li>\n<li> parquet with gzip(gz)    <\/li>\n<li> parquet with snappy    <\/li>\n<\/ul>",
        "Challenge_closed_time":1638238520327,
        "Challenge_comment_count":0,
        "Challenge_created_time":1638234150553,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/645118\/can-i-use-compressed-data-on-tabulardataset",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":8.1,
        "Challenge_reading_time":6.16,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":1.2138261111,
        "Challenge_title":"Can I use compressed data on TabularDataset?",
        "Challenge_topic":"Dataset Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":null,
        "Challenge_word_count":56,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi, tabular dataset does not support compressed files. You'll need to extract the data as shown <a href=\"https:\/\/medium.com\/mlearning-ai\/load-json-gz-files-to-azure-ml-dataset-b7039ec9da34\">here<\/a> for example before creating a tabular dataset. However, file dataset supports any format.<\/p>\n<hr \/>\n<p>--- *Kindly <em><strong>Accept Answer<\/strong><\/em> if the information helps. Thanks.*<\/p>\n",
        "Solution_comment_count":1.0,
        "Solution_link_count":1.0,
        "Solution_readability":10.0,
        "Solution_reading_time":5.21,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":41.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":2.6086344444,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hey experts, I am looking for a document of how features in SDK V1 mapping to SDK v2 to show my team and plan how we should move to SDK v2. I cannot find a summary for that. Can you please help with this <\/p>",
        "Challenge_closed_time":1682725999300,
        "Challenge_comment_count":0,
        "Challenge_created_time":1682716608216,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1266094\/sdk-features-mapping",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":4.4,
        "Challenge_reading_time":2.73,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":2.6086344444,
        "Challenge_title":"SDK features mapping",
        "Challenge_topic":"Compute Management",
        "Challenge_topic_macro":"Computation Management",
        "Challenge_view_count":null,
        "Challenge_word_count":47,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello <a href=\"https:\/\/learn.microsoft.com\/users\/na\/?userid=9603a4b0-3119-4f80-93b6-9637337c7a94\">@otto atler<\/a> <\/p>\n<p>Thanks for reaching out to us again, please see below list: <\/p>\n<p>For workspace - <\/p>\n<p>V1 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.workspace.workspace\">Method\/API in SDK v1 (use links to ref docs)<\/a>    <\/p>\n<p>V2 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azure-ai-ml\/azure.ai.ml.entities.workspace\">Method\/API in SDK v2 (use links to ref docs)<\/a><\/p>\n<p>For compute - <\/p>\n<p>V1 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.compute.amlcompute(class)\">Method\/API in SDK v1 (use links to ref docs)<\/a><\/p>\n<p>V2 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azure-ai-ml\/azure.ai.ml.entities.amlcompute\">Method\/API in SDK v2 (use links to ref docs)<\/a><\/p>\n<p>For datastore -<\/p>\n<p>V1 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.azure_storage_datastore.azureblobdatastore?view=azure-ml-py&amp;preserve-view=true\">azureml_blob_datastore<\/a><\/p>\n<p>V2 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azure-ai-ml\/azure.ai.ml.entities.azuredatalakegen1datastore\">azureml_blob_datastore<\/a><\/p>\n<p>V1 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.azure_data_lake_datastore.azuredatalakedatastore?view=azure-ml-py&amp;preserve-view=true\">azureml_data_lake_gen1_datastore<\/a><\/p>\n<p>V2 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azure-ai-ml\/azure.ai.ml.entities.azuredatalakegen1datastore\">azureml_data_lake_gen1_datastore<\/a><\/p>\n<p>V1 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.azure_data_lake_datastore.azuredatalakegen2datastore?view=azure-ml-py&amp;preserve-view=true\">azureml_data_lake_gen2_datastore<\/a><\/p>\n<p>V2 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azure-ai-ml\/azure.ai.ml.entities.azuredatalakegen2datastore\">azureml_data_lake_gen2_datastore<\/a><\/p>\n<p>V1 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.azure_sql_database_datastore.azuresqldatabasedatastore?view=azure-ml-py&amp;preserve-view=true\">azuremlml_sql_database_datastore<\/a><\/p>\n<p>V2 Will be supported via import &amp; export functionalities|<\/p>\n<p>V1 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.azure_my_sql_datastore.azuremysqldatastore?view=azure-ml-py&amp;preserve-view=true\">azuremlml_my_sql_datastore<\/a><\/p>\n<p>V2 Will be supported via import &amp; export functionalities|<\/p>\n<p>V1 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.azure_postgre_sql_datastore.azurepostgresqldatastore?view=azure-ml-py&amp;preserve-view=true\">azuremlml_postgre_sql_datastore<\/a><\/p>\n<p>V2 Will be supported via import &amp; export functionalities|<\/p>\n<p>For data assets - <\/p>\n<p>V1 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data\">Method\/API in SDK v1<\/a><\/p>\n<p>V2 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azure-ai-ml\/azure.ai.ml.entities\">Method\/API in SDK v2<\/a><\/p>\n<p>For model assets - <\/p>\n<p>V1 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model(class)#azureml-core-model-register\">Model.register<\/a><\/p>\n<p>V2 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azure-ai-ml\/azure.ai.ml.mlclient#azure-ai-ml-mlclient-create-or-update\">ml_client.models.create_or_update<\/a><\/p>\n<p>V1 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.run.run#azureml-core-run-run-register-model\">run.register_model<\/a><\/p>\n<p>V2 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azure-ai-ml\/azure.ai.ml.mlclient#azure-ai-ml-mlclient-create-or-update\">ml_client.models.create_or_update<\/a><\/p>\n<p>V1 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model(class)#azureml-core-model-deploy\">Model.deploy<\/a><\/p>\n<p>V2 <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azure-ai-ml\/azure.ai.ml.mlclient#azure-ai-ml-mlclient-begin-create-or-update\">ml_client.begin_create_or_update(blue_deployment)<\/a><\/p>\n<p>I hope this helps, please let me know if you have any questions.<\/p>\n<p>Regards,<\/p>\n<p>Yutong<\/p>\n<p>-Please kindly accept the answer and vote 'Yes' if you feel helpful to support he community, thanks a lot.<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":22.0,
        "Solution_readability":30.1,
        "Solution_reading_time":61.37,
        "Solution_score_count":0.0,
        "Solution_sentence_count":24.0,
        "Solution_word_count":197.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":13.2144094444,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I work with Azure Machine Learning Service for modeling. To track and analyze the result of a binary classification problem, I use a method named <strong>score-classification<\/strong> in <em>azureml.training.tabular.score.scoring<\/em> library. I invoke the method like this:<\/p>\n<pre><code>metrics = score_classification( y_test, y_pred_probs, metrics_names_list, class_labels, train_labels, sample_weight=sample_weights, use_binary=True)\n\n<\/code><\/pre>\n<p>Input arguments are: <\/p>\n<ul>\n<li> <em>y_test<\/em> is an array of 0 and 1. <\/li>\n<li> <em>y_pred<\/em> is an array of float values for each item. <\/li>\n<li> <em>metrics_names_list<\/em> is the list of the name of the metrics I want to calculate:['f1_score_classwise', 'confusion_matrix']. <\/li>\n<li> <em>class_labels<\/em> is a two-item array of [0, 1].<\/li>\n<li> <em>train_labels<\/em> is a two-item list of ['False', 'True']. <\/li>\n<\/ul>\n<p>When it calculates the metrics I sent as <em>metrics_names_list<\/em>, the results are shown in the Azure ML portal in the metrics page. <\/p>\n<p>Confusion matrix is one of the metrics I draw each time. It has a combo box for the representation. This combo box could be set as <strong>Raw<\/strong> to show the number of items for each cell, and <strong>Normalized<\/strong> to show the percentage of the cells.<\/p>\n<p>The problem is that I see float value for the Raw configuration of this matrix! I do not know how to handle this issue? <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/92357b82-b9f4-4cc4-8630-9619d4584bfa?platform=QnA\" alt=\"enter image description here\" \/><\/p>",
        "Challenge_closed_time":1681173478840,
        "Challenge_comment_count":0,
        "Challenge_created_time":1681125906966,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1213742\/how-to-fix-the-bug-for-float-values-in-confusion-m",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":8.7,
        "Challenge_reading_time":21.34,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":16,
        "Challenge_solved_time":13.2144094444,
        "Challenge_title":"How to fix the bug for float values in confusion matrix in Azure ML service?",
        "Challenge_topic":"Data Labeling",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":null,
        "Challenge_word_count":223,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=e2b5cca4-3304-4fb3-9c9d-7d0f840d76b8\">@Elahe Dorani  <\/a><\/p>\n<p>Thanks for reaching out to us, I am not very clear about your question, so if I am not in the right way, please let me know. It sounds like the issue you are experiencing is that the confusion matrix is being displayed as float values instead of integers when you select the &quot;Raw&quot; option in the combo box.\nOne possible explanation for this behavior is that the <strong><code>score_classification<\/code><\/strong> function is returning the confusion matrix as a numpy array of float values instead of integers. This could happen if the function is doing some kind of normalization or scaling of the values.<\/p>\n<p>To address this issue, you could try converting the confusion matrix to integers before passing it to the <strong><code>score_classification<\/code><\/strong> function. You can use the numpy <strong><code>round<\/code><\/strong> function to round the float values to the nearest integer:<\/p>\n<pre><code>pythonCopy code\nconfusion_matrix = np.round(confusion_matrix).astype(int)\n<\/code><\/pre>\n<p>Then, when you call the <strong><code>score_classification<\/code><\/strong> function, pass in the rounded confusion matrix instead of the original one.<\/p>\n<p>If this does not work, another option is to modify the <strong><code>score_classification<\/code><\/strong> function to return the confusion matrix as integers instead of floats. You can do this by using the numpy <strong><code>astype<\/code><\/strong> function to convert the matrix to the <strong><code>int<\/code><\/strong> data type:<\/p>\n<pre><code>arduinoCopy code\nconfusion_matrix = confusion_matrix.astype(int)\n<\/code><\/pre>\n<p>I hope this helps.<\/p>\n<p>Regards,\nYutong<\/p>\n",
        "Solution_comment_count":1.0,
        "Solution_link_count":0.0,
        "Solution_readability":12.8,
        "Solution_reading_time":22.39,
        "Solution_score_count":1.0,
        "Solution_sentence_count":12.0,
        "Solution_word_count":219.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":0.3402777778,
        "Challenge_answer_count":1,
        "Challenge_body":"If I deploy a SageMaker model, am I incurring hosting charges even while no one is accessing my model?",
        "Challenge_closed_time":1592313864000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1592312639000,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUlNS8ujYmQqePwWS-mgso3Q\/sagemaker-model-spend",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":8.6,
        "Challenge_reading_time":1.53,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":2,
        "Challenge_solved_time":0.3402777778,
        "Challenge_title":"SageMaker Model Spend",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":148.0,
        "Challenge_word_count":21,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"When you deploy a SageMaker model, it deploys it behind a SageMaker endpoint for real-time inference. You are charged by the second for on-demand ML hosting. Check the model deployment section of each region on the [SageMaker Pricing page][1]. In some use cases, you can save on inference cost by hosting several models behind the same endpoint (check [this blog post][2]).\n\n\n  [1]: https:\/\/aws.amazon.com\/sagemaker\/pricing\/?nc1=h_ls\n  [2]: https:\/\/aws.amazon.com\/fr\/blogs\/machine-learning\/save-on-inference-costs-by-using-amazon-sagemaker-multi-model-endpoints\/",
        "Solution_comment_count":0.0,
        "Solution_link_count":2.0,
        "Solution_readability":13.1,
        "Solution_reading_time":7.23,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":65.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":213.2411183333,
        "Challenge_answer_count":9,
        "Challenge_body":"<p>I am loving <a href=\"http:\/\/wandb.ai\">wandb.ai<\/a> and all it can do for me. I have a question whose answer I cannot find anywhere.<br>\nAmong the various fields in the wandb.config file are a few that wandb generates automatically. One of them is <code>Description<\/code>. I tried setting it from a Python program via my configuration file, but to no avail. So I am wondering how to set the Description field programmatically. This will allow me to \u201cdescribe\u201d several hundred simulations for easy retrieval. Thanks,<\/p>",
        "Challenge_closed_time":1660860326460,
        "Challenge_comment_count":0,
        "Challenge_created_time":1660092658434,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/description-field\/2881",
        "Challenge_link_count":1,
        "Challenge_participation_count":9,
        "Challenge_readability":6.9,
        "Challenge_reading_time":6.73,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":213.2411183333,
        "Challenge_title":"Description field",
        "Challenge_topic":"Compute Management",
        "Challenge_topic_macro":"Computation Management",
        "Challenge_view_count":127.0,
        "Challenge_word_count":83,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi <a class=\"mention\" href=\"\/u\/erlebacher\">@erlebacher<\/a> , It\u2019s pretty expensive to do pattern filtering in MySQL, especially on a large column like <code>notes<\/code> . The engineering team decided this feature will not be implemented. I will mark this resolved but please let me know if there is anything else I can answer for you.<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":9.8,
        "Solution_reading_time":4.27,
        "Solution_score_count":null,
        "Solution_sentence_count":3.0,
        "Solution_word_count":50.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":1.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":2.8071302778,
        "Challenge_answer_count":1,
        "Challenge_body":"I have a state-machine workflow with 3 following states:  \n\n[screenshot-of-my-workflow](https:\/\/i.stack.imgur.com\/4xJTE.png)   \n\n1. A 'Pass' block that adds a list of strings(SageMaker endpoint names) to the original input. (*this 'Pass' will be replaced by a call to DynamoDB to fetch list in future.*) \n2. Use map to call SageMaker endpoints dictated by the array(or list) from above result.\n3. Send the result of above 'Map' to a Lambda function and exit the workflow.\n\n\nHere's the entire workflow in .asl.json, inspired from [this aws blog](https:\/\/docs.aws.amazon.com\/step-functions\/latest\/dg\/sample-map-state.html).\n```\n{\n  \"Comment\": \"A description of my state machine\",\n  \"StartAt\": \"Pass\",\n  \"States\": {\n    \"Pass\": {\n      \"Type\": \"Pass\",\n      \"Next\": \"InvokeEndpoints\",\n      \"Result\": {\n        \"Endpoints\": [\n          \"sagemaker-endpoint-1\",\n          \"sagemaker-endpoint-2\",\n          \"sagemaker-endpoint-3\"\n        ]\n      },\n      \"ResultPath\": \"$.EndpointList\"\n    },\n    \"InvokeEndpoints\": {\n      \"Type\": \"Map\",\n      \"Next\": \"Post-Processor Lambda\",\n      \"Iterator\": {\n        \"StartAt\": \"InvokeEndpoint\",\n        \"States\": {\n          \"InvokeEndpoint\": {\n            \"Type\": \"Task\",\n            \"End\": true,\n            \"Parameters\": {\n              \"Body\": \"$.InvocationBody\",\n              \"EndpointName\": \"$.EndpointName\"\n            },\n            \"Resource\": \"arn:aws:states:::aws-sdk:sagemakerruntime:invokeEndpoint\",\n            \"ResultPath\": \"$.InvocationResult\"\n          }\n        }\n      },\n      \"ItemsPath\": \"$.EndpointList.Endpoints\",\n      \"MaxConcurrency\": 300,\n      \"Parameters\": {\n        \"InvocationBody.$\": \"$.body.InputData\",\n        \"EndpointName.$\": \"$$.Map.Item.Value\"\n      },\n      \"ResultPath\": \"$.InvocationResults\"\n    },\n    \"Post-Processor Lambda\": {\n      \"Type\": \"Task\",\n      \"Resource\": \"arn:aws:states:::lambda:invoke\",\n      \"Parameters\": {\n        \"Payload.$\": \"$\",\n        \"FunctionName\": \"arn:aws:lambda:<my-region>:<my-account-id>:function:<my-lambda-function-name>:$LATEST\"\n      },\n      \"Retry\": [\n        {\n          \"ErrorEquals\": [\n            \"Lambda.ServiceException\",\n            \"Lambda.AWSLambdaException\",\n            \"Lambda.SdkClientException\"\n          ],\n          \"IntervalSeconds\": 2,\n          \"MaxAttempts\": 6,\n          \"BackoffRate\": 2\n        }\n      ],\n      \"End\": true\n    }\n  }\n}\n```\n\nAs can be seen in the workflow, I am iterating over the list from the previous 'Pass' block and mapping those to iterate inside 'Map' block and trying to access the Parameters of 'Map' block inside each iteration. Iteration works fine with number of iterators, but I can't access the Parameters inside the iteration. I get this error:\n```\n{\n  \"resourceType\": \"aws-sdk:sagemakerruntime\",\n  \"resource\": \"invokeEndpoint\",\n  \"error\": \"SageMakerRuntime.ValidationErrorException\",\n  \"cause\": \"1 validation error detected: Value '$.EndpointName' at 'endpointName' failed to satisfy constraint: Member must satisfy regular expression pattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])* (Service: SageMakerRuntime, Status Code: 400, Request ID: ed5cad0c-28d9-4913-853b-e5f9ac924444)\"\n}\n```\nSo, I presume the error is because \"$.EndpointName\" is not being filled with the relevant value. How do I avoid this.\n\nBut, when I open the failed execution and check the InvokeEndpoint block from graph-inspector, input to that is what I expected and above JSON-Paths to fetch the parameters should work, but they don't.  \n[screenshot-of-graph-inspector](https:\/\/i.stack.imgur.com\/3gXsM.jpg)\n\nWhat's causing the error and How do I fix this?",
        "Challenge_closed_time":1647513967263,
        "Challenge_comment_count":0,
        "Challenge_created_time":1647503861594,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUDc1foN9TQhe3OYkkGzCKhQ\/aws-stepfunctions-sagemaker-s-invokeendpoint-block-throws-validation-error-when-fetching-parameters-for-itself-inside-iterator-of-map-block",
        "Challenge_link_count":3,
        "Challenge_participation_count":1,
        "Challenge_readability":13.7,
        "Challenge_reading_time":41.85,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":23,
        "Challenge_solved_time":2.8071302778,
        "Challenge_title":"AWS StepFunctions - SageMaker's InvokeEndpoint block throws \"validation error\" when fetching parameters for itself inside iterator of Map block",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":296.0,
        "Challenge_word_count":336,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"In general (as mentioned [here in the parameters doc](https:\/\/docs.aws.amazon.com\/step-functions\/latest\/dg\/connect-parameters.html)), you also need to **end the parameter name** with `.$` when using a JSON Path.\n\nIt looks like you're doing that some places in your sample JSON (e.g. `\"InvocationBody.$\": \"$.body.InputData\"`), but not in others (`\"EndpointName\": \"$.EndpointName\"`), so I think the reason you're seeing the validation error here is that Step Functions is trying to interpret `$.EndpointName` as literally the name of the endpoint (which doesn't satisfy `^[a-zA-Z0-9](-*[a-zA-Z0-9])*`!)\n\nSo suggest you change to `EndpointName.$` and `Body.$` in your InvokeEndpoint parameters",
        "Solution_comment_count":0.0,
        "Solution_link_count":1.0,
        "Solution_readability":10.6,
        "Solution_reading_time":8.83,
        "Solution_score_count":1.0,
        "Solution_sentence_count":9.0,
        "Solution_word_count":87.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":0.5504083334,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I'm working for a campany located in Germany. We want to use Azure Machine Learning (and other stuff like that).   <br \/>\nWe are only allowed to use Azure in the Region &quot;Germany&quot;, because the data of our customers cannot left germany.  <\/p>\n<p>Now I saw, that a lot of stuff in Azure Machine Learning is not available in Germany?  <\/p>\n<p>Questions:  <\/p>\n<ol>\n<li> Is that true?  <\/li>\n<li> Does some one now, at what time Microsoft plans to make the stuff available in Germany?  <\/li>\n<\/ol>\n<p>Thank you for a answer!  <\/p>\n<p>Patrick  <\/p>",
        "Challenge_closed_time":1612862196647,
        "Challenge_comment_count":0,
        "Challenge_created_time":1612860215177,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/265151\/azure-machine-learning-(and-cognitive-services)-is",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":5.5,
        "Challenge_reading_time":7.73,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":0.5504083334,
        "Challenge_title":"Azure Machine Learning (and cognitive services) is not supported in Region \"Germany\"?",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":106,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi <a href=\"\/users\/na\/?userid=1d5d0740-76fa-4574-b01a-5fcee1ddf5b1\">@Patrick Huber  <\/a>     <br \/>\nYes, Azure Machine Learning is not available in Germany region.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/65687-image.png?platform=QnA\" alt=\"65687-image.png\" \/>    <\/p>\n<p><a href=\"https:\/\/feedback.azure.com\/forums\/34192--general-feedback\">Please check in Azure feedback<\/a>    <\/p>\n<p>If the Answer is helpful, please click <code>Accept Answer<\/code> and <strong>up-vote<\/strong>, this can be beneficial to other community members.    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":2.0,
        "Solution_readability":14.1,
        "Solution_reading_time":7.51,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":48.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":59.2573102778,
        "Challenge_answer_count":2,
        "Challenge_body":"<p><strong>Issue<\/strong>  <br \/>\nI am trying prepare and then submit a new experiment to Azure Machine Learning from an Azure Function in Python. I therefore register a new dataset for my Azure ML workspace, which contains the training data for my ML model using <code>dataset.register(...<\/code>. However, when I try to create this dataset with the following line of code  <\/p>\n<pre><code>dataset = Dataset.Tabular.from_delimited_files(path = datastore_paths)\n<\/code><\/pre>\n<p>then I get a <code>Failure Exception: OSError: [Errno 30] Read-only file system ...<\/code>.  <\/p>\n<p><strong>Ideas<\/strong>  <\/p>\n<ol>\n<li> I know that I shouldn't write to the file system from within an Azure function if possible. But I actually don't want to write anything to the local file system. I only want to create the dataset as a reference to my blob storage under <code>datastore_path<\/code> and then register this to my Azure Machine Learning workspace. But it seems that the method <code>from_delimited_files<\/code> is trying to write to the file system anyway (maybe some caching?).  <\/li>\n<li> I also know that there is a temp folder in which writing temporary files is permitted. However, I belive I cannot really control where this method is writing data. I already tried changing the current working directory to this temp folder just before the function call using <code>os.chdir(tempfile.gettempdir())<\/code>, but that didn't help.  <\/li>\n<\/ol>\n<p>Any other ideas? I don't think I am doing something particularly unusually...  <\/p>\n<p><strong>Details<\/strong>  <br \/>\nI am using python 3.7 and azureml-sdk 1.9.0 and I can run the python script locally without problems. I currently deploy from VSCode using the Azure Functions extension version 0.23.0 (and an Azure DevOps pipeline for CI\/CD).  <\/p>\n<p>Here is my full stack trace:  <\/p>\n<pre><code>Microsoft.Azure.WebJobs.Host.FunctionInvocationException: Exception while executing function: Functions.HttpTrigger_Train\n ---&gt; Microsoft.Azure.WebJobs.Script.Workers.Rpc.RpcException: Result: Failure\nException: OSError: [Errno 30] Read-only file system: '\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/dotnetcore2\/bin\/deps.lock'\nStack:   File &quot;\/azure-functions-host\/workers\/python\/3.7\/LINUX\/X64\/azure_functions_worker\/dispatcher.py&quot;, line 345, in _handle__invocation_request\n    self.__run_sync_func, invocation_id, fi.func, args)\n  File &quot;\/usr\/local\/lib\/python3.7\/concurrent\/futures\/thread.py&quot;, line 57, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File &quot;\/azure-functions-host\/workers\/python\/3.7\/LINUX\/X64\/azure_functions_worker\/dispatcher.py&quot;, line 480, in __run_sync_func\n    return func(**params)\n  File &quot;\/home\/site\/wwwroot\/HttpTrigger_Train\/__init__.py&quot;, line 11, in main\n    train()\n  File &quot;\/home\/site\/wwwroot\/shared_code\/train.py&quot;, line 70, in train\n    dataset = Dataset.Tabular.from_delimited_files(path = datastore_paths)\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/data\/_loggerfactory.py&quot;, line 126, in wrapper\n    return func(*args, **kwargs)\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/data\/dataset_factory.py&quot;, line 308, in from_delimited_files\n    quoting=support_multi_line)\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/readers.py&quot;, line 100, in read_csv\n    df = Dataflow._path_to_get_files_block(path, archive_options)\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/dataflow.py&quot;, line 2387, in _path_to_get_files_block\n    return datastore_to_dataflow(path)\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/_datastore_helper.py&quot;, line 41, in datastore_to_dataflow\n    datastore, datastore_value = get_datastore_value(source)\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/_datastore_helper.py&quot;, line 83, in get_datastore_value\n    _set_auth_type(workspace)\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/_datastore_helper.py&quot;, line 134, in _set_auth_type\n    get_engine_api().set_aml_auth(SetAmlAuthMessageArgument(AuthType.SERVICEPRINCIPAL, json.dumps(auth)))\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/engineapi\/api.py&quot;, line 18, in get_engine_api\n    _engine_api = EngineAPI()\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/engineapi\/api.py&quot;, line 55, in __init__\n    self._message_channel = launch_engine()\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/engineapi\/engine.py&quot;, line 300, in launch_engine\n    dependencies_path = runtime.ensure_dependencies()\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/dotnetcore2\/runtime.py&quot;, line 141, in ensure_dependencies\n    with _FileLock(deps_lock_path, raise_on_timeout=timeout_exception):\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/dotnetcore2\/runtime.py&quot;, line 113, in __enter__\n    self.acquire()\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/dotnetcore2\/runtime.py&quot;, line 72, in acquire\n    self.lockfile = os.open(self.lockfile_path, os.O_CREAT | os.O_EXCL | os.O_RDWR)\n\n   at Microsoft.Azure.WebJobs.Script.Description.WorkerFunctionInvoker.InvokeCore(Object[] parameters, FunctionInvocationContext context) in \/src\/azure-functions-host\/src\/WebJobs.Script\/Description\/Workers\/WorkerFunctionInvoker.cs:line 85\n   at Microsoft.Azure.WebJobs.Script.Description.FunctionInvokerBase.Invoke(Object[] parameters) in \/src\/azure-functions-host\/src\/WebJobs.Script\/Description\/FunctionInvokerBase.cs:line 85\n   at Microsoft.Azure.WebJobs.Script.Description.FunctionGenerator.Coerce[T](Task`1 src) in \/src\/azure-functions-host\/src\/WebJobs.Script\/Description\/FunctionGenerator.cs:line 225\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionInvoker`2.InvokeAsync(Object instance, Object[] arguments) in C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionInvoker.cs:line 52\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor.InvokeAsync(IFunctionInvoker invoker, ParameterHelper parameterHelper, CancellationTokenSource timeoutTokenSource, CancellationTokenSource functionCancellationTokenSource, Boolean throwOnTimeout, TimeSpan timerInterval, IFunctionInstance instance) in C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:line 587\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor.ExecuteWithWatchersAsync(IFunctionInstanceEx instance, ParameterHelper parameterHelper, ILogger logger, CancellationTokenSource functionCancellationTokenSource) in C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:line 532\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor.ExecuteWithLoggingAsync(IFunctionInstanceEx instance, ParameterHelper parameterHelper, IFunctionOutputDefinition outputDefinition, ILogger logger, CancellationTokenSource functionCancellationTokenSource) in C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:line 470\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor.ExecuteWithLoggingAsync(IFunctionInstanceEx instance, FunctionStartedMessage message, FunctionInstanceLogEntry instanceLogEntry, ParameterHelper parameterHelper, ILogger logger, CancellationToken cancellationToken) in C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:line 278\n   --- End of inner exception stack trace ---\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor.ExecuteWithLoggingAsync(IFunctionInstanceEx instance, FunctionStartedMessage message, FunctionInstanceLogEntry instanceLogEntry, ParameterHelper parameterHelper, ILogger logger, CancellationToken cancellationToken) in C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:line 325\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor.TryExecuteAsyncCore(IFunctionInstanceEx functionInstance, CancellationToken cancellationToken) in C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:line 117\n<\/code><\/pre>",
        "Challenge_closed_time":1597616477787,
        "Challenge_comment_count":1,
        "Challenge_created_time":1597403151470,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/67126\/failure-exception-oserror-(errno-30)-read-only-fil",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":25.3,
        "Challenge_reading_time":114.76,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":73,
        "Challenge_solved_time":59.2573102778,
        "Challenge_title":"\u201cFailure Exception: OSError: [Errno 30] Read-only file system\u201d when using AzureML in Python Azure Function",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":null,
        "Challenge_word_count":575,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>The issue was an incompatible OS version in my virtual environment.    <\/p>\n<p>A huge thanks goes to <a href=\"https:\/\/learn.microsoft.com\/answers\/users\/111253\/pramodvalavala-msft.html\">PramodValavala-MSFT<\/a> for his idea to create a docker container! Following his suggestion, I suddenly got the following error message for the  <code>dataset = Dataset.Tabular.from_delimited_files(path = datastore_paths)<\/code> command:    <\/p>\n<blockquote>\n<p>Exception: NotImplementedError: Unsupported Linux distribution debian 10.    <\/p>\n<\/blockquote>\n<p>which reminded me of the following warning in the azure machine learning documentation:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/17829-image.png?platform=QnA\" alt=\"17829-image.png\" \/>    <\/p>\n<p>Choosing the predefined docker image <code>2.0-python3.7<\/code> (running Debian 9) instead of  <code>3.0-python3.7<\/code> (running Debian 10) solved the issue (see <a href=\"https:\/\/hub.docker.com\/_\/microsoft-azure-functions-python\">https:\/\/hub.docker.com\/_\/microsoft-azure-functions-python<\/a>).    <\/p>\n<p>I suspect that the default virtual environment, which I was using originally, also ran on an incompatible OS.    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":3.0,
        "Solution_readability":16.0,
        "Solution_reading_time":15.64,
        "Solution_score_count":1.0,
        "Solution_sentence_count":10.0,
        "Solution_word_count":113.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":80.6917763889,
        "Challenge_answer_count":5,
        "Challenge_body":"<p>Hi!<br>\nI want to run a bayesian HP sweep with 5-fold CV. In other words I want the bayesian sweep to decide upon a configuration, run 5 runs with that configuration and log each run. The easiest way to do this would be to have a variable in the sweep, called e.g. fold_id which simply can take the values 1,2,3,4,5 and force the agent to always test all the fold_ids per configuration.<\/p>\n<p>Is there any way to make this possible? I.e force the sweep agent to always test a variable, even though running a bayesian sweep. In a way it would be like running a grid sweep over a bayesian sweep.<\/p>\n<p>One way I\u2019ve thought of is by making all parameters nested inside the fold_id variable but it still won\u2019t probably do what I\u2019m after.<\/p>\n<p>I\u2019ve seen the k-fold CV example code, but it\u2019s quite advanced and does not seem to work when running on CUDA and my understanding of multiprocessing is limited.<\/p>\n<p>Thank you!<\/p>",
        "Challenge_closed_time":1663260668920,
        "Challenge_comment_count":0,
        "Challenge_created_time":1662970178525,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/force-bayesian-sweep-to-run-certain-variable-tests\/3098",
        "Challenge_link_count":0,
        "Challenge_participation_count":5,
        "Challenge_readability":5.8,
        "Challenge_reading_time":11.87,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":11,
        "Challenge_solved_time":80.6917763889,
        "Challenge_title":"Force Bayesian sweep to run certain variable tests",
        "Challenge_topic":"Hyperparameter Tuning",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":131.0,
        "Challenge_word_count":172,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>You can create a nested sweep where each fold could be a list and then you can then iterate over those values.  Make sure that the run name changes per run so that way the runs don\u2019t overwrite one another.<\/p>\n<p>Here\u2019s an example config of a nested sweep:<\/p>\n<pre><code class=\"lang-auto\">command:\n  - ${env}\n  - python3\n  - ${program}\n  - ${args}\nmethod: random\nparameters:\n  MULTI_STAGE_TRAINING:\n    value:\n      DEPTH_SCALE:\n        - 100\n        - 100\n      HEAD:\n        - OBJECT_DETECTION\n      NETWORK:\n        - net_a\n        - net_b\n        - net_c\n      NUM_EPOCHS_IN_EACH_STAGE:\n        - 0\n        - 1\n        - 2\n        - 3\n      NUM_STAGES:\n        - 0\n        - 1\n        - 2\n        - 3\n        - 4\n        - 5\n        - 6\n        - 7\n        - 8\n        - 9\n      OPTIMIZER_PARAMS_PER_STAGE:\n        lr:\n          - 0\n          - 1\n          - 2\n          - 3\n          - 4\n          - 5\n          - 6\n          - 7\n          - 8\n          - 9\n        momentum:\n          - 0\n          - 1\n          - 2\n          - 3\n          - 4\n          - 5\n          - 6\n          - 7\n          - 8\n          - 9\n        weight_decay:\n          - 0\n          - 1\n          - 2\n          - 3\n          - 4\n          - 5\n          - 6\n          - 7\n          - 8\n          - 9\n  epochs:\n    value: 10\nprogram: script.py\n<\/code><\/pre>\n<p>And here\u2019s a script that is able to run it:<\/p>\n<pre><code class=\"lang-auto\">import wandb\n\u200b\ndef create_sweep(\n    sweep_config:dict,\n    update:bool,\n    project:str,\n    entity:str):\n    \n    parameters_dict = {'MULTI_STAGE_TRAINING':\n                   {'value':\n                    {'NUM_STAGES':list(range(10)),\n                     'OPTIMIZER_PARAMS_PER_STAGE':\n                     {'lr':list(range(10)),'momentum': list(range(10)),'weight_decay':list(range(10))},\n                     'NUM_EPOCHS_IN_EACH_STAGE':list(range(4)),\n                     'NETWORK':['net_a','net_b','net_c'],\n                     'HEAD':['OBJECT_DETECTION'],\n                     'DEPTH_SCALE': [100,100]\n                     }\n                    }\n                   }\n    sweep_config['parameters'] = parameters_dict\n    \n    parameters_dict.update({\n    'epochs': {\n        'value': 10}\n    })\n    return wandb.sweep(sweep_config,entity=entity,project=project)\n\u200b\nif __name__ == '__main__':\n\u200b\n    SWEEP_CONFIG = {\n    'method': 'random',\n    'program':'script.py',\n    'command':['${env}', 'python3', '${program}','${args}']\n    }\n    ENTITY = 'demonstrations'\n    PROJECT = 'sweep_gm'\n    UPDATE = True\n\u200b\n    sweep = create_sweep(\n        sweep_config=SWEEP_CONFIG,\n        entity=ENTITY,\n        project=PROJECT,\n        update=UPDATE)\n<\/code><\/pre>\n<p>Let me know if you need any further help with this!<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":17.8,
        "Solution_reading_time":23.25,
        "Solution_score_count":null,
        "Solution_sentence_count":7.0,
        "Solution_word_count":197.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":0.2003183333,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hello,  <\/p>\n<p>no practice exam for the Azure certification DP-100 seems to be available in the official channels. It would, however, be very helpful for preparing.  <br \/>\nBy any chance, do you plan to introduce such a resource any time soon?  <\/p>\n<p>Thanks and best regards  <br \/>\nTim<\/p>",
        "Challenge_closed_time":1593083339536,
        "Challenge_comment_count":0,
        "Challenge_created_time":1593082618390,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/39948\/practice-exam-for-dp-100",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":4.9,
        "Challenge_reading_time":3.89,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":0.2003183333,
        "Challenge_title":"Practice Exam for DP-100",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":51,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi,    <\/p>\n<p>Microsoft Certification \/ Exams are currently not supported in the Q&amp;A forums, the supported products are listed over here <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/products\">https:\/\/learn.microsoft.com\/en-us\/answers\/products<\/a> (more to be added later on).      <\/p>\n<p>You can ask the experts in the dedicated <strong>Microsoft Certification - Preparation Resources<\/strong> forum over here:        <br \/>\n<a href=\"https:\/\/trainingsupport.microsoft.com\/en-us\/mcp\/forum\/mcp_exams-mcp_prep\">https:\/\/trainingsupport.microsoft.com\/en-us\/mcp\/forum\/mcp_exams-mcp_prep<\/a>    <\/p>\n<p>(Please don't forget to accept helpful replies as answer)      <\/p>\n<p>Best regards,      <br \/>\nLeon    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":2.0,
        "Solution_readability":17.7,
        "Solution_reading_time":9.15,
        "Solution_score_count":2.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":63.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":16.7097122222,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I'm in classic Azure ML mode. I am working on my first ever experiment, so please be patient..    <\/p>\n<p>I cannot locate column selector for CSV data to filter out columns. I found this:    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/select-columns-in-dataset\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/select-columns-in-dataset<\/a>    <\/p>\n<p>And I'm following a tutorial (behind pay wall, from 2017) that shows it in the right hand side properties pane. It says in his example to add the &quot;Select columns in dataset&quot; and it shows the option of &quot;launch column selector&quot;.    <\/p>\n<p>I have browsed through every single choice in the left menu, but cannot locate it... I have no idea what I am missing.    <\/p>\n<p>I need to exclude columns from the data set. Then later I need to make some of the fields &quot;categorical&quot;. Input on that would be appreciated too, unless it becomes obvious from other information provided.    <\/p>\n<p>Please help me :) Thanks in advance for patience and\/or assistance.<\/p>",
        "Challenge_closed_time":1619488667407,
        "Challenge_comment_count":0,
        "Challenge_created_time":1619428512443,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/371634\/beginner-question-cannot-locate-column-selector-fo",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":9.3,
        "Challenge_reading_time":15.09,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":13,
        "Challenge_solved_time":16.7097122222,
        "Challenge_title":"Beginner question - Cannot locate column selector for CSV data to filter out columns",
        "Challenge_topic":"Dataset Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":null,
        "Challenge_word_count":162,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello,    <\/p>\n<p>First you need to navigate to Data Transformation  - &gt; Manipulation -&gt; Select columns in dataset, drag that into your process.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/91523-image.png?platform=QnA\" alt=\"91523-image.png\" \/>    <\/p>\n<p>Then, left click on the module and click launch column selector.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/91497-image.png?platform=QnA\" alt=\"91497-image.png\" \/>    <\/p>\n<p>And you can do you want now.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/91524-image.png?platform=QnA\" alt=\"91524-image.png\" \/>    <\/p>\n<p>Please accept the answer if you feel helpful, thanks.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":3.0,
        "Solution_readability":13.7,
        "Solution_reading_time":9.81,
        "Solution_score_count":0.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":69.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":6.0913719444,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hello, I am trying to add a user Id column to my dataset but I don't want the user Id to impact the results of the ML.  <\/p>\n<p>I am using Auto ML on my dataset to generate a model and then deployed the model to an endpoint.  <\/p>\n<p>Currently I am calling the endpoint like:  <\/p>\n<pre><code>{&quot;data&quot;:[\n       {\n          &quot;TEMP&quot;:&quot;X&quot;,\n        }\n    ]\n}\n<\/code><\/pre>\n<p>and I would like to call it like:  <\/p>\n<pre><code>{&quot;data&quot;:[\n    {\n      &quot;TEMP&quot;:&quot;X&quot;,\n      &quot;userID&quot;: 5434643\n     }\n  ]}\n<\/code><\/pre>\n<p>I'm wondering if there is a way I can do this? I've seen about using Clear Feature in Edit Metadata for the Designer but I'm wondering if something similar can be done for automated ML?  <\/p>\n<p>Thanks so much!  <\/p>",
        "Challenge_closed_time":1627949805196,
        "Challenge_comment_count":0,
        "Challenge_created_time":1627927876257,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/498759\/clear-feature-with-auto-ml",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":8.6,
        "Challenge_reading_time":9.42,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":6.0913719444,
        "Challenge_title":"Clear Feature with Auto ML",
        "Challenge_topic":"Dataset Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":null,
        "Challenge_word_count":118,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi, thanks for reaching out. You can customize featurization in automl to only include features relevant for prediction. Here's the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-features#customize-featurization\">documentation<\/a>. Hope it helps!    <\/p>\n",
        "Solution_comment_count":3.0,
        "Solution_link_count":1.0,
        "Solution_readability":16.4,
        "Solution_reading_time":3.97,
        "Solution_score_count":0.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":26.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":0.4346333334,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi , i would like to know if it is possible to change the location of AzureML workspace after creating it ?  <br \/>\nRight now i do not find any option to change it manually on the UI. We want to move the server location to a different country.  <br \/>\nAny leads would be helpful. Thanks<\/p>",
        "Challenge_closed_time":1643796022067,
        "Challenge_comment_count":0,
        "Challenge_created_time":1643794457387,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/719406\/change-location-of-azure-ml-workspace",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":4.4,
        "Challenge_reading_time":3.94,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":0.4346333334,
        "Challenge_title":"change location of Azure ML workspace?",
        "Challenge_topic":"Compute Management",
        "Challenge_topic_macro":"Computation Management",
        "Challenge_view_count":null,
        "Challenge_word_count":59,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Based on the below document, ML workspace can't be moved across region. Probably, you will have to create a new resource in target region and move artifacts \/ pipelines \/ child resources to it (not so familiar with ML)     <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/azure-resource-manager\/management\/move-support-resources#microsoftmachinelearning\">https:\/\/learn.microsoft.com\/en-us\/azure\/azure-resource-manager\/management\/move-support-resources#microsoftmachinelearning<\/a>    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-move-workspace#limitations\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-move-workspace#limitations<\/a>    <\/p>\n<p>----------    <\/p>\n<p>Please don't forget to <strong>Accept Answer<\/strong> and <strong>Up-vote<\/strong> if the response helped -- Vaibhav<\/p>\n",
        "Solution_comment_count":2.0,
        "Solution_link_count":2.0,
        "Solution_readability":20.9,
        "Solution_reading_time":11.43,
        "Solution_score_count":1.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":59.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":20.1061447222,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>Hi,<br>\nI am tuning hyper-params with <code>wandb.sweep<\/code>. For now, in order to get the best group of hyper-params, I have to look for the best group on my own and record those params manually. I wonder whether there is a way to extract or collect reuslts of hyper-params automatically by <code>wandb<\/code>?<br>\nThanks a lot!<\/p>",
        "Challenge_closed_time":1682009719808,
        "Challenge_comment_count":0,
        "Challenge_created_time":1681937337687,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/collect-results-from-sweep\/4238",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":6.6,
        "Challenge_reading_time":4.54,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":20.1061447222,
        "Challenge_title":"Collect results from sweep",
        "Challenge_topic":"Hyperparameter Tuning",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":37.0,
        "Challenge_word_count":57,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello!<\/p>\n<p>We have <a href=\"https:\/\/colab.research.google.com\/github\/wandb\/examples\/blob\/master\/colabs\/pytorch\/Organizing_Hyperparameter_Sweeps_in_PyTorch_with_W%26B.ipynb#scrollTo=G01IM4yVkc6u\" rel=\"noopener nofollow ugc\">Parallel Coordinate plots and Hyper Parameter Importance Plots<\/a> in the UI that can help with looking for the best group! In terms of collecting results of sweeps, the hyperparameters are automatically logged to the <code>config.yaml<\/code> file in your run\u2019s file tab.  However, if you want to collect the hyperparameters  yourself, you can also access individual hyperparameter values using <code>wandb.config['hyperparameter-name']<\/code> within the <code>main()<\/code> function you are running your sweep on. <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/config\">Here<\/a> is our documentation on ways to use access and update the config file.<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":2.0,
        "Solution_readability":16.6,
        "Solution_reading_time":11.56,
        "Solution_score_count":null,
        "Solution_sentence_count":7.0,
        "Solution_word_count":91.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":1.0,
        "Challenge_adjusted_solved_time":7.9730555556,
        "Challenge_answer_count":1,
        "Challenge_body":"Can Amazon SageMaker endpoints be fitted with multiple Amazon Elastic Inference accelerators?\n\nI see that [in EC2 it's possible][1], however I don't see it mentioned in Amazon SageMaker documentation.\n\n\n  [1]: https:\/\/docs.aws.amazon.com\/elastic-inference\/latest\/developerguide\/basics.html",
        "Challenge_closed_time":1604506639000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1604477936000,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUwU8IHcSVQ3eH9-fGx0KZCA\/can-amazon-sagemaker-endpoints-be-fitted-with-multiple-amazon-elastic-inference-accelerators",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":18.2,
        "Challenge_reading_time":4.95,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":7.9730555556,
        "Challenge_title":"Can Amazon SageMaker endpoints be fitted with multiple Amazon Elastic Inference accelerators?",
        "Challenge_topic":"CloudWatch Monitoring",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":76.0,
        "Challenge_word_count":42,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":1.0,
        "Poster_isModerator":0.0,
        "Solution_body":"No, they cant be; multi-attach is only supported with EC2.",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":7.2,
        "Solution_reading_time":0.72,
        "Solution_score_count":0.0,
        "Solution_sentence_count":1.0,
        "Solution_word_count":10.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":36.5390777778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi, here is the details of my issue.  <br \/>\nI want to execute a distributed training run with the Tensorflow framework and Horovod.  <br \/>\nTo do this, I've configured a environment called &quot;tf_env&quot; as follow :<\/p>\n<pre><code># Create the environment : the dependencies are in the .yml file\ntf_env = Environment.from_conda_specification(name=&quot;tensorflow_environment&quot;, file_path=&quot;experiments\/package-list.yml&quot;)\n\n# Register the environment\ntf_env.register(workspace=ws)\n\n# Specify a GPU base image\ntf_env.docker.enabled = True\ntf_env.docker.base_image = 'mcr.microsoft.com\/azureml\/openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04'\n<\/code><\/pre>\n<p>Where my &quot;package-list.yml&quot; contains all the dependencies my &quot;train_script.py&quot; requires.  <br \/>\nI've defined my ScriptConfigRun as follow :<\/p>\n<pre><code>arguments = [\n    (... other arguments ...)\n    &quot;--ds&quot;,  images_ds.as_mount()\n]\n\nsrc = ScriptRunConfig(\n    source_directory=&quot;experiments&quot;,\n    script='train_script.py',\n    arguments=arguments,\n    compute_target=compute_target,\n    environment=tf_env,\n    distributed_job_config=MpiConfiguration(node_count=2)\n)\n<\/code><\/pre>\n<p>Then, when I want to submit the run :<\/p>\n<pre><code>run = best_model_experiment.submit(config=src)\n<\/code><\/pre>\n<p>... it raises this error I don't understand :<\/p>\n<pre><code>ExperimentExecutionException: ExperimentExecutionException:\n    Message: {\n    &quot;error_details&quot;: {\n        &quot;componentName&quot;: &quot;execution&quot;,\n        &quot;correlation&quot;: {\n            &quot;operation&quot;: &quot;***&quot;,\n            &quot;request&quot;: &quot;***&quot;\n        },\n        &quot;environment&quot;: &quot;westeurope&quot;,\n        &quot;error&quot;: {\n            &quot;code&quot;: &quot;UserError&quot;,\n            &quot;message&quot;: &quot;Error when parsing request; unable to deserialize request body&quot;\n        },\n        &quot;location&quot;: &quot;westeurope&quot;,\n        &quot;time&quot;: &quot;***&quot;\n    },\n    &quot;status_code&quot;: 400,\n    &quot;url&quot;: &quot;https:\/\/westeurope.experiments.azureml.net\/execution\/v1.0\/subscriptions\/***\/resourceGroups\/***\/providers\/Microsoft.MachineLearningServices\/workspaces\/***\/experiments\/experiment\/snapshotrun?runId=experiment***&quot;\n}\n    InnerException None\n    ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;message&quot;: &quot;{\\n    \\&quot;error_details\\&quot;: {\\n        \\&quot;componentName\\&quot;: \\&quot;execution\\&quot;,\\n        \\&quot;correlation\\&quot;: {\\n            \\&quot;operation\\&quot;: \\&quot;***\\&quot;,\\n            \\&quot;request\\&quot;: \\&quot;***\\&quot;\\n        },\\n        \\&quot;environment\\&quot;: \\&quot;westeurope\\&quot;,\\n        \\&quot;error\\&quot;: {\\n            \\&quot;code\\&quot;: \\&quot;UserError\\&quot;,\\n            \\&quot;message\\&quot;: \\&quot;Error when parsing request; unable to deserialize request body\\&quot;\\n        },\\n        \\&quot;location\\&quot;: \\&quot;westeurope\\&quot;,\\n        \\&quot;time\\&quot;: \\&quot;***\\&quot;\\n    },\\n    \\&quot;status_code\\&quot;: 400,\\n    \\&quot;url\\&quot;: \\&quot;https:\/\/westeurope.experiments.azureml.net\/execution\/v1.0\/subscriptions\/***\/resourceGroups\/***\/providers\/Microsoft.MachineLearningServices\/workspaces\/***\/experiments\/experiment\/snapshotrun?runId=experiment_***\\&quot;\\n}&quot;\n    }\n}\n<\/code><\/pre>\n<p>Could you please help me decrypt this error ?  <br \/>\nThank you.<\/p>",
        "Challenge_closed_time":1620024521707,
        "Challenge_comment_count":0,
        "Challenge_created_time":1619892981027,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/379458\/azure-machine-learning-experimentexecutionexceptio",
        "Challenge_link_count":2,
        "Challenge_participation_count":1,
        "Challenge_readability":24.5,
        "Challenge_reading_time":44.31,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":18,
        "Challenge_solved_time":36.5390777778,
        "Challenge_title":"Azure Machine Learning ExperimentExecutionException while submitting a distributed training run !",
        "Challenge_topic":"TensorBoard Logging",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":null,
        "Challenge_word_count":216,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Issue solved ! I've given a list in arguments to argparse so it could'nt deserialized the object.<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":10.7,
        "Solution_reading_time":1.29,
        "Solution_score_count":0.0,
        "Solution_sentence_count":1.0,
        "Solution_word_count":16.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":1.3832386111,
        "Challenge_answer_count":1,
        "Challenge_body":"Hello,\nAre there any drawbacks I should be aware of if we restrict user access to only a single region? \n\nWe use a variety of AWS services but mainly S3 and Sagemaker Studio. Our team is located in various locations so their default regions are different.  It has been a challenge to keep track of studio instances when they are created in different regions so we are now considering restricting access to a single region. Are there issues that we may face in that case? Any services we may miss?",
        "Challenge_closed_time":1642705784219,
        "Challenge_comment_count":0,
        "Challenge_created_time":1642700804560,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUxt7fqO9HQrKWDfi4V4Lagg\/pros-and-cons-of-restricting-user-access-to-certain-regions",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":7.6,
        "Challenge_reading_time":6.68,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":1.3832386111,
        "Challenge_title":"Pros and cons of restricting user access to certain regions",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":95.0,
        "Challenge_word_count":99,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"I would take a look at [this](https:\/\/docs.aws.amazon.com\/organizations\/latest\/userguide\/orgs_manage_policies_scps_examples_general.html#example-scp-deny-region) for some potential edge cases. In summary, you may need to allow us-east-1 and us-west-2 in addition to whatever regions your team is in since they host some of the global service endpoints (like IAM, Route 53, Global Accelerator, and a few others). For STS, I would use the [regional endpoints](https:\/\/docs.aws.amazon.com\/IAM\/latest\/UserGuide\/id_credentials_temp_enable-regions.html) if you aren't already.",
        "Solution_comment_count":1.0,
        "Solution_link_count":2.0,
        "Solution_readability":15.2,
        "Solution_reading_time":7.48,
        "Solution_score_count":4.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":62.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":39.0455230556,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>Hello,<\/p>\n<p>As I cannot simply upload infinitely many weights using artifacts, I also want to store some locally.<br>\nFor naming, I would like to use the sweep id and\/or the run id.<\/p>\n<p>Can I access that somehow in the train function I hand over to the agent?<\/p>\n<p>Thanks<\/p>\n<p>Markus<\/p>",
        "Challenge_closed_time":1660860269032,
        "Challenge_comment_count":0,
        "Challenge_created_time":1660719705149,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/access-sweep-id-and-run-id-within-train-function-for-local-weight-storage\/2948",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":5.5,
        "Challenge_reading_time":4.66,
        "Challenge_score_count":2.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":39.0455230556,
        "Challenge_title":"Access sweep_id and run_id within train() function for local weight storage",
        "Challenge_topic":"Hyperparameter Tuning",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":143.0,
        "Challenge_word_count":59,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hey <a class=\"mention\" href=\"\/u\/markuskarner\">@markuskarner<\/a>!<\/p>\n<p>The <code>wandb.Run<\/code> object that is returned from <code>wandb.init<\/code> contains this information as properties. You should be able to access <code>run.id<\/code> and <code>run.sweep_id<\/code> in the train function after calling <code>run = wandb.init(...)<\/code>.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":8.6,
        "Solution_reading_time":4.98,
        "Solution_score_count":null,
        "Solution_sentence_count":8.0,
        "Solution_word_count":36.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":1.7286111111,
        "Challenge_answer_count":0,
        "Challenge_body":"Context\n\nLet's say I have following structure\n\nroot\n\u251c\u2500\u2500model_files\n\u251c\u2500\u2500polyaxonfiles\n\u2502      \u251c\u2500\u2500build.yml\n\u2502      \u2514\u2500\u2500run.yml\n\u251c\u2500\u2500utils\n\u2514\u2500\u2500dockerfiles\n         \u251c\u2500\u2500Dockerfile.0\n         \u2514\u2500\u2500Dockerfile.1\n\n\nmy build looks as simple as:\n\nversion: 1.1\nkind: operation\nname: build\nparams:\n  context:\n    value: \"{{ globals.run_artifacts_path }}\/uploads\"\n  destination:\n    connection: docker-registry\n    value: machine-learning\/polyaxon-tutorial:1\n\nhubRef: kaniko\n\nRunning this with command\n\npolyaxon run -f polyaxonfiles\/build.yml -u\n\nGives me very much expected error:\n\nError: error resolving dockerfile path: please provide a valid path to a Dockerfile within the build context with --dockerfile\n\nSo the Kaniko expects Dockerfile to exist in root of the context by default. Does the polyaxonfile specification exposes a way to overwrite the default as suggested with error message?",
        "Challenge_closed_time":1620665885000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1620659662000,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1315",
        "Challenge_link_count":0,
        "Challenge_participation_count":0,
        "Challenge_readability":11.1,
        "Challenge_reading_time":11.08,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":8,
        "Challenge_solved_time":1.7286111111,
        "Challenge_title":"(How) Can I pass path to Dockerfile using Kaniko?",
        "Challenge_topic":"Docker Configuration",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":null,
        "Challenge_word_count":112,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"Hi @captainCapitalism, next release we will be pushing a new set of guides, including guides for building containers and how to pass a custom dockerfile context.\n\nWe will update this thread as soon as we start updating the documentation's guides section.",
        "Solution_comment_count":4.0,
        "Solution_link_count":0.0,
        "Solution_readability":11.3,
        "Solution_reading_time":3.13,
        "Solution_score_count":2.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":41.0,
        "Tool":"Polyaxon"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":115.1236055556,
        "Challenge_answer_count":3,
        "Challenge_body":"<p>Dear community,<\/p>\n<p>I want to use WandB locally in my VSCode project, but my Ipython kernel keeps dying. After restarting the kernel it always prints out the errore message: \u201cFailed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\u201d and \u201cwandb: Currently logged in as: XXX. Use <code>wandb login --relogin<\/code> to force relogin\u201d<\/p>\n<p>I already tried to import os, as well as setting the environment variabele to my local notebook, but this didnt change a thing. I am using python 3.9.12<\/p>\n<p>I hope you can help me in this matter<\/p>",
        "Challenge_closed_time":1675104696691,
        "Challenge_comment_count":0,
        "Challenge_created_time":1674690251711,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/using-wandb-in-visual-studio-code\/3752",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":8.1,
        "Challenge_reading_time":8.18,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":115.1236055556,
        "Challenge_title":"Using WandB in Visual Studio Code",
        "Challenge_topic":"Environment Installation",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":123.0,
        "Challenge_word_count":107,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi <a class=\"mention\" href=\"\/u\/martin-woschitz\">@martin-woschitz<\/a> thank you for reporting this issue. This first message is just a warning so it shouldn\u2019t cause any issues running your code, also the second message  is an informatio output about the user account that you\u2019ve logged in. When does the Ipython kernel stops working, is it when you\u2019re running a python script? would it be possible to make a new virtual environment and install <code>wandb<\/code> only there to test if that\u2019s what\u2019s causing the issue for you?<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":11.3,
        "Solution_reading_time":6.6,
        "Solution_score_count":null,
        "Solution_sentence_count":4.0,
        "Solution_word_count":82.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":0.1086111111,
        "Challenge_answer_count":0,
        "Challenge_body":"From slack\n\nI would like to compare the top 4 experiments based on a specific metrics.\n\nCurrently I query the top experiment using the cli:\n\npolyaxon ops ls -q \"name: GROUP_NAME, metrics.loss:<0.002\"  -s \"metrics.loss\" -l 5\n\nAnd then I copy\/paste the run UUIDs to:\n\npolyaxon run --hub tensorboard:mulit-run -P uuids=UUID1,UUID2,UUID3,UUID4,UUID5",
        "Challenge_closed_time":1649336377000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1649335986000,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1483",
        "Challenge_link_count":0,
        "Challenge_participation_count":0,
        "Challenge_readability":8.0,
        "Challenge_reading_time":4.94,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":0.1086111111,
        "Challenge_title":"How can I start a Tensorboard for the top 5 experiments",
        "Challenge_topic":"TensorBoard Logging",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":null,
        "Challenge_word_count":60,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"From the UI or using a YAML file, you can run:\n\nversion: 1.1\nkind: operation\nhubRef: tensorboard:multi-run\njoins:\n- query: \"name: GROUP_NAME, metrics.loss:<0.002,  kind:job\"  \n  sort: \"metrics.loss\"\n  limit: 5\n  params:\n    uuids: {value: \"globals.uuid\"}\n\nNote that in the UI if create a filter \/ sort configuration, you can automatically create a multi-run Tensorboard based on that query, for example:",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":8.8,
        "Solution_reading_time":4.88,
        "Solution_score_count":1.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":55.0,
        "Tool":"Polyaxon"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":28.0968075,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>ML studio is, by default picking up Python 3.6 kernel, even when I'm specifying use Python 3.8 AzureML kernel. In UI, it's changed but not actually.     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/183312-image.png?platform=QnA\" alt=\"183312-image.png\" \/>    <\/p>",
        "Challenge_closed_time":1647451118727,
        "Challenge_comment_count":0,
        "Challenge_created_time":1647349970220,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/772790\/azure-ml-studio-is-bugged-out-and-can-not-create-a",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":8.4,
        "Challenge_reading_time":4.99,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":28.0968075,
        "Challenge_title":"Azure ML Studio is bugged out and can not create a Microsoft ticket under MSDN. Need a few suggestions",
        "Challenge_topic":"Environment Installation",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":null,
        "Challenge_word_count":49,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi, thanks for reaching out.  It looks like the command you ran isn't supported. A better command to test kernel changes is shown below:  <\/p>\n<pre><code>from platform import python_version\nprint(python_version())\n<\/code><\/pre>\n<p>Hope this helps!<\/p>\n",
        "Solution_comment_count":6.0,
        "Solution_link_count":0.0,
        "Solution_readability":6.5,
        "Solution_reading_time":3.22,
        "Solution_score_count":0.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":34.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":2.5933255556,
        "Challenge_answer_count":7,
        "Challenge_body":"<p>Hello,<\/p>\n<p>I was wondering if anybody from the W&amp;B team can confirm that there is an outage at the moment.<\/p>\n<p>I\u2019ve been having issues starting runs and it seems like other folks are having issues syncing runs with a network time out error (<a href=\"https:\/\/github.com\/wandb\/wandb\/issues\/4424\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">[CLI]: canno't sync my runs \u00b7 Issue #4424 \u00b7 wandb\/wandb \u00b7 GitHub<\/a>). It\u2019s been ongoing for about 2 hours now.<\/p>\n<p>The status page is saying everything is fine - <a href=\"https:\/\/status.wandb.com\" rel=\"noopener nofollow ugc\">https:\/\/status.wandb.com<\/a><\/p>\n<p>All the best,<br>\nAlexey<\/p>",
        "Challenge_closed_time":1667343090214,
        "Challenge_comment_count":0,
        "Challenge_created_time":1667333754242,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/w-b-outage-11-1-2022\/3360",
        "Challenge_link_count":3,
        "Challenge_participation_count":7,
        "Challenge_readability":8.0,
        "Challenge_reading_time":8.59,
        "Challenge_score_count":3.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":2.5933255556,
        "Challenge_title":"W&B Outage? 11\/1\/2022",
        "Challenge_topic":"Compute Management",
        "Challenge_topic_macro":"Computation Management",
        "Challenge_view_count":106.0,
        "Challenge_word_count":84,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Thank you for your patience! Our engineers were able to push a fix for this. There\u2019s still currently an issue regarding batch moving runs, but for the most part this issue has been resolved.<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":4.2,
        "Solution_reading_time":2.41,
        "Solution_score_count":null,
        "Solution_sentence_count":3.0,
        "Solution_word_count":34.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":19.7083872222,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>How to import data not by passing it as an argument,     <br \/>\nI do not want to do as the tutorial <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-with-datasets?source=docs\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-with-datasets?source=docs<\/a><\/p>",
        "Challenge_closed_time":1654106099667,
        "Challenge_comment_count":0,
        "Challenge_created_time":1654035149473,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/872050\/azure-machine-learning-sdk",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":17.8,
        "Challenge_reading_time":4.54,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":2,
        "Challenge_solved_time":19.7083872222,
        "Challenge_title":"azure machine learning SDK",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":26,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=fd7f30ec-b4f1-4575-a425-a49ca6a1a14e\">@ben wu  <\/a>     <\/p>\n<p>Thanks for reaching out to us, there is the code sample from engineering team    <\/p>\n<pre><code>from azureml.core import ScriptRunConfig  \n  \ninput_data=titanic_ds.as_named_input('input_data').as_mount()  \nsrc = ScriptRunConfig(source_directory=script_folder,  \n                      script='train_titanic.py',  \n                      compute_target=compute_target)  \nsrc.run_config.data = {input_data.name: input_data }  \n# Submit the run configuration for your training run  \nrun = experiment.submit(src)  \nrun.wait_for_completion(show_output=True)    \n<\/code><\/pre>\n<p>In your script, you can get the mounted path via environment variable, which is the value you specified in as_named_input. For the sample code above, the environment variable will be input_data.    <\/p>\n<p>I hopet this helps.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":12.0,
        "Solution_reading_time":12.47,
        "Solution_score_count":0.0,
        "Solution_sentence_count":10.0,
        "Solution_word_count":103.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":0.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":1.3894444444,
        "Challenge_answer_count":1,
        "Challenge_body":"Hi,\n\nCustomer who loads the e-bike data to S3 wants to get AI\/ML insight from sensor data.\nThe e-bike sensor data are size about 4KB files each and posted in S3 buckets.\nThe sensor data is put into format like this\n\ntimestamp1, sensorA, sensorB, sensorC, ..., sensorZ\ntimestamp2, sensorA, sensorB, sensorC, ..., sensorZ\ntimestamp3, sensorA, sensorB, sensorC, ..., sensorZ\n...\n\nThen these sensor data are put into one file about 4KB size.\n\nThe plan I have is to\n\n* Read S3 objects\n* Parse S3 object with Lambda. I thought about Glue but wanted to put data in DynamoDB where Glue does not seem to support. Also, Glue seems to be more expensive.\n* Put the data in DynamoDB with bike ID as primary key and timestamp as sort key.\n* Use SageMaker to learn with the DynamoDB data. There will be separate discussion on choosing which model and making time-series inferencing.\n* If we need to re-learn, it will use the DynamoDB data, not from S3. I think it will be faster to get data from DynamoDB instead from the raw S3 data.\n* Also, I think we can filter out some bad input or apply little modification to DynamoDB data (shifting time stamps to the correct time, etc.)\n* Make inferencing output based on the model.\n\nWhat do you think? Would you agree? Would you approach the problem differently?\nWould you rather learn from S3 directly via Athena or direct S3 access?\nOr would you rather use Glue and Redshift?\nBut the data about 100MB would be sufficient to train the model we have in mind.\nGlue and Redshift maybe overkill.\nCurrently, Korea region does not support Timestream database. So, time series database closest in Korea could be DynamoDB.\n\nPlease share your thoughts.\n\nThanks!",
        "Challenge_closed_time":1607362919000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1607357917000,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUebPx1UeWSGOb_3i0TXlBWA\/ai-ml-data-acquisition-and-preprocessing",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":5.1,
        "Challenge_reading_time":20.82,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":27,
        "Challenge_solved_time":1.3894444444,
        "Challenge_title":"[AI\/ML] Data acquisition and preprocessing",
        "Challenge_topic":"Dataset Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":81.0,
        "Challenge_word_count":289,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"**Thoughts about DynamoDB**\n\nPer GB, DynamoDB is around 5X more cost per GB of data stored. On top of that, you have RCU\/WCU cost.\n\nI would recommend keeping data in S3. Not only is it more cost effective, but with S3, you do not have to worry about RCU\/WCU cost or throughput of DynamoDB. \n\nSageMaker notebooks and training instances can read directly from S3, and S3 has high-throughput. I don't think you will have a problem with 100 MB datasets. \n\nIf you need to prep\/transform your data, you can do the transformations \"in place\" in S3 using Glue, Athena, Glue DataBrew, GlueStudio, etc. \n\n\n**Glue and DynamoDB**\n\n> I thought about Glue but wanted to put data in DynamoDB where Glue does not seem to support.\n\nGlue supports both Python and Spark jobs. If you use a Glue Python job, you can import the boto3 (AWS SDK) library and write to DynamoDB.\n\n**Other strategies**\n\nHow is your customer ingesting the sensor data \/ how is it being written to S3? Are they using AWS IoT Core? \n\nRegardless, the pattern you've described thus far is:\n\nDevice -> Sensor data in S3 -> Transform with Lambda -> store data in DynamoDB\n\nAn alternative approach you could consider is using Kinesis Firehose with Lambda transformations. This will allow you to do \"in-line\" parsing \/ transformation of your data before it is ever written to S3, this removing the need to re-read the data from S3 and apply transformations after the fact. Firehose also allows you to write the stored data in formats such as Parquet, which can help with cost and subsequent query performance. \n\nIf you want to store both raw data and transformed data, you can use a \"fanout\" pattern with Kinesis Streams\/Firehose, where one output is raw data to S3 and the other is a transformed stream.",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":8.2,
        "Solution_reading_time":20.98,
        "Solution_score_count":0.0,
        "Solution_sentence_count":16.0,
        "Solution_word_count":299.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":7.2541636111,
        "Challenge_answer_count":4,
        "Challenge_body":"<p>I have a few questions regarding the hyperparameter sweeps from Python.<br>\nI am wanting to essentially start a few tmux sessions on my server, and connect them all to the same sweep agent, but no keyword in the sweep_config (that i have found) allow me to connect to a specific sweep ID, and rather just a sweep name that doesnt connect to the same sweep, but just makes multiple sweeps of the same name.  If this possible or strongly advised against due to computational usage or similar?<\/p>\n<p>Furthermore, sweeps take up a great deal of storage requirements due to saving all the models, is it possible to store the model file from the best model only, while keeping the statistics from all the models for plots and interpretation? This would allow me to keep the great information gathered from sweeps, while not taking up 100+ GB from a single sweep.<\/p>\n<p>Thanks!<\/p>",
        "Challenge_closed_time":1641593349991,
        "Challenge_comment_count":0,
        "Challenge_created_time":1641567235002,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/connecting-to-existing-sweep-from-python\/1721",
        "Challenge_link_count":0,
        "Challenge_participation_count":4,
        "Challenge_readability":12.3,
        "Challenge_reading_time":11.22,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":7.2541636111,
        "Challenge_title":"Connecting to existing sweep from Python",
        "Challenge_topic":"Metric Logging",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":248.0,
        "Challenge_word_count":156,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>I found the issue, i was trying to create a new wandb.sweep(config, project, entity) and pass the ID into the config dictionary, but instead i just needed to take the ID directly, and just do sweep_id = sweep_id_string which worked.<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":9.7,
        "Solution_reading_time":2.94,
        "Solution_score_count":null,
        "Solution_sentence_count":2.0,
        "Solution_word_count":39.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":285.5134875,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I can't see a data drift module anywhere in v2 of the Azure ML Python SDK. Is this missing or what's the deal? If so, are there any plans of bringing it into v2?<\/p>",
        "Challenge_closed_time":1658311324112,
        "Challenge_comment_count":1,
        "Challenge_created_time":1657283475557,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/919651\/datadrift-in-azure-ml-sdk-v2",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":2.4,
        "Challenge_reading_time":2.34,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":285.5134875,
        "Challenge_title":"Datadrift in Azure ML SDK v2",
        "Challenge_topic":"Dataset Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":null,
        "Challenge_word_count":39,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=1dc2a0bd-ac4b-413b-bae7-930e0079e70d\">@SH  <\/a>     <\/p>\n<p>I have a good news for you, I just got confirmation from product team, the datadrift function will be in SDK V2 for sure. But for now we don't have an exact date for when. I have forwarded this feedback to product group and we hope we can bring this feature in near future.     <\/p>\n<p>I hope this helps.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Solution_comment_count":1.0,
        "Solution_link_count":0.0,
        "Solution_readability":5.3,
        "Solution_reading_time":6.49,
        "Solution_score_count":0.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":85.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":16.3358102778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi,     <\/p>\n<p>is it possible (or will be in the future) using Python SDK v2 to create pipeline endpoint (or endpoint + deployment)?    <br \/>\nIm looking for a way to submit a job for a created pipeline with a REST request.     <\/p>\n<p>For SDK v1 pipeline i was able to acquire satisfying result using Pipeline.publish method.    <\/p>\n<p>Thanks for any advice!<\/p>",
        "Challenge_closed_time":1664861262760,
        "Challenge_comment_count":0,
        "Challenge_created_time":1664802453843,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1033206\/publishing-aml-pipelines-with-sdk-v2",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":6.0,
        "Challenge_reading_time":4.77,
        "Challenge_score_count":5.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":16.3358102778,
        "Challenge_title":"Publishing AML Pipelines with SDK v2",
        "Challenge_topic":"Pipeline Configuration",
        "Challenge_topic_macro":"Lifecycle Management",
        "Challenge_view_count":null,
        "Challenge_word_count":65,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=c12c38b8-0908-400e-b8ac-72519d30e7db\">@Maciej Stefaniak  <\/a>    <\/p>\n<p>Thanks for using Microsoft Q&amp;A platform. For how to publish pipeline, I don't find anything currently. But for deploy endpoint, please check on this sample repo for SDK v2, there are several samples for you to refer about how to deploy endpoint - <a href=\"https:\/\/github.com\/Azure\/azureml-examples\/tree\/v2samplesreorg\/sdk\/python\">https:\/\/github.com\/Azure\/azureml-examples\/tree\/v2samplesreorg\/sdk\/python<\/a>    <\/p>\n<p>Also, there is an example about using Azure Machine Learning (Azure ML) to create a production ready machine learning (ML) project, using AzureML Python SDK v2 (preview). - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-pipeline-python-sdk\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-pipeline-python-sdk<\/a>    <\/p>\n<p>I hope this helps, please let me know if you need more information or have any questiion regarding to above examples.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Solution_comment_count":5.0,
        "Solution_link_count":2.0,
        "Solution_readability":13.7,
        "Solution_reading_time":14.97,
        "Solution_score_count":0.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":123.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":32.21595,
        "Challenge_answer_count":5,
        "Challenge_body":"<p>The usage in the <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/advanced\/environment-variables#optional-environment-variables\">Docs<\/a> is:<\/p>\n<blockquote>\n<p>Set this to a comma separated list of file globs to ignore. These files will not be synced to the cloud<\/p>\n<\/blockquote>\n<p>So, is the below code correct?<\/p>\n<pre><code class=\"lang-python\">os.environ['WANDB_IGNORE_GLOBS'] = '[*.pth, *.npy]'\n<\/code><\/pre>",
        "Challenge_closed_time":1668698260971,
        "Challenge_comment_count":0,
        "Challenge_created_time":1668582283551,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/how-to-set-the-environment-variable-wandb-ignore-globs-correctly\/3423",
        "Challenge_link_count":1,
        "Challenge_participation_count":5,
        "Challenge_readability":11.8,
        "Challenge_reading_time":6.38,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":32.21595,
        "Challenge_title":"How to set the environment variable WANDB_IGNORE_GLOBS correctly?",
        "Challenge_topic":"Dataset Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":137.0,
        "Challenge_word_count":48,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi <a class=\"mention\" href=\"\/u\/geyao\">@geyao<\/a> thank you for writing in! Could you please check if the following would work for you?<\/p>\n<pre><code class=\"lang-auto\">os.environ['WANDB_IGNORE_GLOBS'] = '*.pth,*.npy'\n<\/code><\/pre>",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":8.8,
        "Solution_reading_time":3.07,
        "Solution_score_count":null,
        "Solution_sentence_count":3.0,
        "Solution_word_count":24.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":1.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":2.6611111111,
        "Challenge_answer_count":2,
        "Challenge_body":"When I try to import Hugging Face BERT models to the **conda_pytorch_p36** kernal of my Amazon SageMaker Notebook instance using the following pip command, the kernal always dies:\n```\n! pip install transformers\n```\nThe result is the same for Hugging Face BERT, RoBERTa, and GPT2 models on ml.c5.2xlarge and ml.c5d.4xlarge Amazon SageMaker instances.\n\nWhy is this happening, and how do I resolve the issue?",
        "Challenge_closed_time":1604527535000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1604517955000,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUsO3sfUGpTKeHiU8W9k1Kwg\/why-does-my-kernal-keep-dying-when-i-try-to-import-hugging-face-bert-models-to-amazon-sagemaker",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":8.4,
        "Challenge_reading_time":6.17,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":2.6611111111,
        "Challenge_title":"Why does my kernal keep dying when I try to import Hugging Face BERT models to Amazon SageMaker?",
        "Challenge_topic":"TensorFlow Model Development",
        "Challenge_topic_macro":"Model Management",
        "Challenge_view_count":1123.0,
        "Challenge_word_count":79,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":1.0,
        "Poster_isModerator":0.0,
        "Solution_body":"This issue occurs when the latest sentence piece breaks. The workaround is to force install sentencepiece==0.1.91. \n\n```\npip install sentencepiece==0.1.91\n\n```",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":6.9,
        "Solution_reading_time":2.0,
        "Solution_score_count":0.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":19.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":1.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":32.6179794445,
        "Challenge_answer_count":1,
        "Challenge_body":"Using Sagemaker's Python SDK 2.11 when I run my pipeline, I see this strange warning message: \n```\n\/personal_dir\/lib\/python3.8\/site-packages\/sagemaker\/workflow\/pipeline_context.py:233: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n```\n Before, I ran the exact same pipeline script with LocalPipelineSession without any problems and without any kind of weird warning messages. \n\nThis is how I am creating the PipelineSession object:\n```\ndef get_session(region, default_bucket):\n    boto_session = boto3.Session(region_name=region)\n    sagemaker_client = boto_session.client(\"sagemaker\")\n\n    return PipelineSession(\n        boto_session=boto_session,\n        sagemaker_client=sagemaker_client,\n        default_bucket=default_bucket\n    )\n```\nIm getting the region in the following way:\n```\nimport boto3\n\nregion = boto3.Session().region_name\n```\nI have tried to search the web for the meaning of that warning message, but could not find anything. What does that warning message means?? Am I doing something wrong and what can I do to make that warning disapear",
        "Challenge_closed_time":1669741153535,
        "Challenge_comment_count":0,
        "Challenge_created_time":1669623728809,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUm9Ml6PX2QdOA5VIaDMblQg\/sagemaker-pipeline-strange-warning-message",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":10.3,
        "Challenge_reading_time":14.29,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":11,
        "Challenge_solved_time":32.6179794445,
        "Challenge_title":"Sagemaker Pipeline strange warning message",
        "Challenge_topic":"Pipeline Configuration",
        "Challenge_topic_macro":"Lifecycle Management",
        "Challenge_view_count":110.0,
        "Challenge_word_count":132,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"Hi, this warning is simply to clarify that running in a pipeline session will defer execution of jobs - generating pipeline step definitions instead of kicking off the jobs straight away.\n\nFor example calls such as `Estimator.fit()` or `Processor.run()` when using a pipeline session won't **start a job** (or wait for it to complete, or stream logs from CloudWatch), just prepare a definition to build up a pipeline that can be started later.\n\nIf you're already familiar with how PipelineSession works, I would say you can ignore it :-)  If not, can refer to the [SDK docs here for more details](https:\/\/sagemaker.readthedocs.io\/en\/stable\/amazon_sagemaker_model_building_pipeline.html#pipeline-session).\n\nCould be that there's an inconsistency between `LocalPipelineSession` versus `PipelineSession` in showing the message? Or that you disagree this message should be at warning level... Either way I'd suggest raising an issue on the [SageMaker Python SDK GitHub](https:\/\/github.com\/aws\/sagemaker-python-sdk) might be a good way to log that feedback with the team!",
        "Solution_comment_count":0.0,
        "Solution_link_count":2.0,
        "Solution_readability":10.9,
        "Solution_reading_time":13.4,
        "Solution_score_count":1.0,
        "Solution_sentence_count":9.0,
        "Solution_word_count":149.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":8.6181130556,
        "Challenge_answer_count":1,
        "Challenge_body":"According to [Sagemaker's Pipeline Python SDK documenation](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/build-and-manage-steps.html), looks like there is no specific pipeline step for model deployment. \n\nCan you please confirm this and, also, if there is a plan to have such a step? \n\nWhat is the recommended way to add a pipeline step to deploy the trained model, resulting in an enpoint being created?",
        "Challenge_closed_time":1669881877547,
        "Challenge_comment_count":0,
        "Challenge_created_time":1669850852340,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUiGdmBa_oQJuiiewjUhe9OA\/sagemaker-pipeline-deploy-model-step",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":10.3,
        "Challenge_reading_time":5.6,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":8.6181130556,
        "Challenge_title":"Sagemaker Pipeline Deploy Model Step",
        "Challenge_topic":"Pipeline Configuration",
        "Challenge_topic_macro":"Lifecycle Management",
        "Challenge_view_count":298.0,
        "Challenge_word_count":60,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"Hi, there is indeed no specific pipeline step for model deployment. The idea is that SageMaker Pipelines is more about \"batch mode\", but customers do ask for this feature, so it might be added. \n\nYou can implement it quite easily using Lambda Step.\n\n1st create a Lambda function to deploy\/update the model:\n```\n%%writefile deploy_model_lambda.py\n\n\n\"\"\"\nThis Lambda function deploys the model to SageMaker Endpoint. \nIf Endpoint exists, then Endpoint will be updated with new Endpoint Config.\n\"\"\"\n\nimport json\nimport boto3\nimport time\n\n\nsm_client = boto3.client(\"sagemaker\")\n\n\ndef lambda_handler(event, context):\n\n    print(f\"Received Event: {event}\")\n\n    current_time = time.strftime(\"%m-%d-%H-%M-%S\", time.localtime())\n    endpoint_instance_type = event[\"endpoint_instance_type\"]\n    model_name = event[\"model_name\"]\n    endpoint_config_name = \"{}-{}\".format(event[\"endpoint_config_name\"], current_time)\n    endpoint_name = event[\"endpoint_name\"]\n\n    # Create Endpoint Configuration\n    create_endpoint_config_response = sm_client.create_endpoint_config(\n        EndpointConfigName=endpoint_config_name,\n        ProductionVariants=[\n            {\n                \"InstanceType\": endpoint_instance_type,\n                \"InitialVariantWeight\": 1,\n                \"InitialInstanceCount\": 1,\n                \"ModelName\": model_name,\n                \"VariantName\": \"AllTraffic\",\n            }\n        ],\n    )\n    print(f\"create_endpoint_config_response: {create_endpoint_config_response}\")\n\n    # Check if an endpoint exists. If no - Create new endpoint, if yes - Update existing endpoint\n    list_endpoints_response = sm_client.list_endpoints(\n        SortBy=\"CreationTime\",\n        SortOrder=\"Descending\",\n        NameContains=endpoint_name,\n    )\n    print(f\"list_endpoints_response: {list_endpoints_response}\")\n\n    if len(list_endpoints_response[\"Endpoints\"]) > 0:\n        print(\"Updating Endpoint with new Endpoint Configuration\")\n        update_endpoint_response = sm_client.update_endpoint(\n            EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n        )\n        print(f\"update_endpoint_response: {update_endpoint_response}\")\n    else:\n        print(\"Creating Endpoint\")\n        create_endpoint_response = sm_client.create_endpoint(\n            EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n        )\n        print(f\"create_endpoint_response: {create_endpoint_response}\")\n\n    return {\"statusCode\": 200, \"body\": json.dumps(\"Endpoint Created Successfully\")}\n```\n\nThen create the Lambda step:\n```\ndeploy_model_lambda_function_name = \"sagemaker-deploy-model-lambda-\" + current_time\n\ndeploy_model_lambda_function = Lambda(\n    function_name=deploy_model_lambda_function_name,\n    execution_role_arn=lambda_role,\n    script=\"deploy_model_lambda.py\",\n    handler=\"deploy_model_lambda.lambda_handler\",\n)\n```\n\nYou can see a full working example in [this notebook](https:\/\/github.com\/aws\/amazon-sagemaker-examples\/blob\/main\/sagemaker-pipelines\/tabular\/tensorflow2-california-housing-sagemaker-pipelines-deploy-endpoint\/tensorflow2-california-housing-sagemaker-pipelines-deploy-endpoint.ipynb).",
        "Solution_comment_count":0.0,
        "Solution_link_count":1.0,
        "Solution_readability":23.2,
        "Solution_reading_time":37.71,
        "Solution_score_count":2.0,
        "Solution_sentence_count":17.0,
        "Solution_word_count":197.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":1.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":2.8375316667,
        "Challenge_answer_count":1,
        "Challenge_body":"I want to use an Amazon Sagemaker endpoint for a custom classification model. The endpoint should only handle sporadic input (say a few times a week). \nFor this purpose I want to employ autoscaling that scales the number of instances down to 0 when the endpoint is not used. \n\nAre there any costs associated with having an endpoint with 0 instances? \n\nThanks!",
        "Challenge_closed_time":1666371029704,
        "Challenge_comment_count":0,
        "Challenge_created_time":1666360814590,
        "Challenge_favorite_count":1.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QU0VGYdZe8TRivmtGHoiDDHw\/cost-of-autoscaling-endpoint-amazon-sagemaker-endpoint-to-zero",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":7.6,
        "Challenge_reading_time":5.11,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":2.8375316667,
        "Challenge_title":"Cost of autoscaling endpoint Amazon SageMaker endpoint to zero",
        "Challenge_topic":"CloudWatch Monitoring",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":468.0,
        "Challenge_word_count":70,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"You dont pay any compute costs for the duration when the endpoint size scales down to 0. But i think you can design it better. There are few other options for you to use in SageMaker Endpoint(assuming you are using realtime endpoint)\n\n1. Try using [SageMaker Serverless Inference](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/serverless-endpoints.html) instead. Its purely serverless in nature so you pay only when the endpoint is serving inference. i think that would fit your requirement better.\n2. You can think of using Lambda as well which will reduce your hosting costs. but you have to do more work in setting up the inference stack all by yourself.\n3. There is also an option of [SageMaker asynchronous inference](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/async-inference.html) but its mostly useful for inference which require longer time to process each request. The reason i mention this is it also support scale to 0 when no traffic is coming.",
        "Solution_comment_count":1.0,
        "Solution_link_count":2.0,
        "Solution_readability":8.4,
        "Solution_reading_time":12.05,
        "Solution_score_count":2.0,
        "Solution_sentence_count":11.0,
        "Solution_word_count":144.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":0.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":0.0858333333,
        "Challenge_answer_count":3,
        "Challenge_body":"Hi Team,  \nI'm trying to package sagemaker dependencies as external dependcies to upload to lambda.  \nBut I'm getting the max size limit error. Package size is more than allowed size limit i.e..  deployment package size is 50 MB.  \nAnd the reason I'm trying to do this is, 'get_image_uri' api is not accessible with boto3.  \nsample code for this api :   \n#Import the get_image_url utility function Amazon SageMaker Python SDK and get the location of the XGBoost container.  \n  \nimport sagemaker  \nfrom sagemaker.amazon.amazon_estimator import get_image_uri  \ncontainer = get_image_uri(boto3.Session().region_name, 'xgboost')  \n  \nAny reference would be of great help. Thank you.",
        "Challenge_closed_time":1568642184000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1568641875000,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUg5l3Jjl4SISDvnjIVYcqaA\/not-able-to-add-sagemaker-dependencies-as-external-dependencies-to-lambda",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":9.7,
        "Challenge_reading_time":9.12,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":10,
        "Challenge_solved_time":0.0858333333,
        "Challenge_title":"not able to add sagemaker dependencies as external dependencies to lambda",
        "Challenge_topic":"Quota Management",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":331.0,
        "Challenge_word_count":104,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"Could you explain in more detail why do you want to have sagemaker inside of a lambda please?",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":6.8,
        "Solution_reading_time":1.12,
        "Solution_score_count":0.0,
        "Solution_sentence_count":1.0,
        "Solution_word_count":18.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":157.7512475,
        "Challenge_answer_count":4,
        "Challenge_body":"<p>I log model scores by steps and at every step I have metric value, confidence interval lower bound, confidence interval upper bound. Is it possible to log confidence intervals (on one graph) and show the confidence interval using different color?<\/p>",
        "Challenge_closed_time":1674027872136,
        "Challenge_comment_count":0,
        "Challenge_created_time":1673459967645,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/is-it-possible-to-log-confidence-intervals\/3684",
        "Challenge_link_count":0,
        "Challenge_participation_count":4,
        "Challenge_readability":11.6,
        "Challenge_reading_time":3.7,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":157.7512475,
        "Challenge_title":"Is it possible to log confidence intervals?",
        "Challenge_topic":"Metric Logging",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":207.0,
        "Challenge_word_count":46,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Thank you so much for the example! This helps a whole lot. Currently this isn\u2019t a feature we have in our product, but I\u2019ll create a feature request for this and our team will reach out to you once there are any updates on this ticket.<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":5.7,
        "Solution_reading_time":2.88,
        "Solution_score_count":null,
        "Solution_sentence_count":3.0,
        "Solution_word_count":46.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":17.7779194445,
        "Challenge_answer_count":3,
        "Challenge_body":"<p>Bonjour    <br \/>\nJe suis le cours en ligne concernant l'impl\u00e9mentation d'algorithmes de machine learning    <br \/>\nA l'\u00e9tape Create compute resources    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/use-automated-machine-learning\/create-compute\">https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/use-automated-machine-learning\/create-compute<\/a>    <\/p>\n<p>On me demande Search for and select Standard_DS11_v2    <\/p>\n<p>Hors, l'interface me dit que je n'ai pas les quotas disponibles.    <br \/>\nJ'utilise l'offre d'essai \u00e0 200 USD.    <br \/>\nComment faire pour que cela fonctionne ?    <br \/>\nCordialement    <br \/>\nThibaut<\/p>",
        "Challenge_closed_time":1638432598510,
        "Challenge_comment_count":1,
        "Challenge_created_time":1638368598000,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/647767\/comment-s-lectionner-standard-ds11-v2",
        "Challenge_link_count":1,
        "Challenge_participation_count":4,
        "Challenge_readability":14.5,
        "Challenge_reading_time":8.64,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":17.7779194445,
        "Challenge_title":"Comment s\u00e9lectionner Standard_DS11_v2",
        "Challenge_topic":"Quota Management",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":null,
        "Challenge_word_count":64,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=e0b4def2-2525-4e3c-954a-129251c1bdb4\">@Thibaut Jacquin  <\/a> For a free account only 200$ credit is available and not all compute can be created or selected because of this limitation. You can choose a lower priced VM and proceed with the creation of compute or upgrade to a pay-as-you-go account for your subscription and select the required compute type. I hope this helps.    <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Solution_comment_count":1.0,
        "Solution_link_count":2.0,
        "Solution_readability":12.4,
        "Solution_reading_time":10.09,
        "Solution_score_count":0.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":86.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":1.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":0.5700419445,
        "Challenge_answer_count":1,
        "Challenge_body":"I am exploring the Sagemaker Built-in algorithms, and I am curious to learn more about the details of the algorithms. However, I am surprised that it is hard to find any references for the research background and implementation details in the numerous documents and tutorials for particular algorithms. If such information exists somewhere, I would highly appreciate a pointer. Thanks a lot in advance!",
        "Challenge_closed_time":1652688680111,
        "Challenge_comment_count":0,
        "Challenge_created_time":1652686627960,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUDkYruiibS9S05bzFSkLaxg\/sagemaker-built-in-algorithms",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":10.8,
        "Challenge_reading_time":5.39,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":0.5700419445,
        "Challenge_title":"Sagemaker Built-in Algorithms",
        "Challenge_topic":"Hyperparameter Tuning",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":125.0,
        "Challenge_word_count":66,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"thanks for your interest in the built-in algorithms! You can find research papers in the documentation of many of them. And documentation page has a section \"how it works\" explaining the science of every algorithm. For example:\n\n - **BlazingText**: *[BlazingText: Scaling and Accelerating Word2Vec using Multiple GPUs](https:\/\/dl.acm.org\/doi\/10.1145\/3146347.3146354)*, Gupta et Khare\n - **[DeepAR](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/deepar_how-it-works.html)** *[DeepAR: Probabilistic Forecasting with Autoregressive Recurrent Networks](https:\/\/arxiv.org\/abs\/1704.04110)*, Salinas et al.\n - **[Factorization Machines](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/fact-machines-howitworks.html)**\n - **[IP Insights](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/ip-insights-howitworks.html)**\n - **[KMeans](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/algo-kmeans-tech-notes.html)**\n - **[KNN](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/kNN_how-it-works.html)**\n - **[LDA](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/lda-how-it-works.html)**\n - **[Linear Learner](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/linear-learner.html)**\n - **[NTM](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/ntm.html)**\n - **[Object2Vec](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/object2vec-howitworks.html)**\n - **[Object Detection](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/algo-object-detection-tech-notes.html)** (it's an SSD model)\n - **[PCA](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/how-pca-works.html)**\n - **[Random Cut Forest](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/rcf_how-it-works.html)**: *[Robust Random Cut Forest Based Anomaly Detection On Streams](https:\/\/proceedings.mlr.press\/v48\/guha16.pdf)*, Guha et al\n - **[Semantic Segmentation](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/semantic-segmentation.html)**\n - **[Seq2seq](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/seq-2-seq-howitworks.html)**\n - **[XGBoost](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/xgboost-HowItWorks.html)**",
        "Solution_comment_count":2.0,
        "Solution_link_count":18.0,
        "Solution_readability":37.8,
        "Solution_reading_time":28.28,
        "Solution_score_count":0.0,
        "Solution_sentence_count":14.0,
        "Solution_word_count":97.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":4.330165,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am using below code to connect to my workspace but it failed -<\/p>\n<p>Any idea what I missed?<\/p>\n<pre><code>from azure.ai.ml import MLClient\nfrom azure.identity import DefaultAzureCredential\n\n# authenticate\ncredential = DefaultAzureCredential()\n# # Get a handle to the workspace\nml_client = MLClient(\n    credential=credential,\n    subscription_id=&quot;&lt;SUBSCRIPTION_ID&gt;&quot;,\n    resource_group_name=&quot;&lt;RESOURCE_GROUP&gt;&quot;,\n    workspace_name=&quot;&lt;AML_WORKSPACE_NAME&gt;&quot;,\n)\n\n<\/code><\/pre>",
        "Challenge_closed_time":1684460862600,
        "Challenge_comment_count":0,
        "Challenge_created_time":1684445274006,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1287364\/creating-a-handle-not-connect-to-the-workspace",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":14.3,
        "Challenge_reading_time":7.35,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":4.330165,
        "Challenge_title":"Creating a handle not connect to the workspace",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":50,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=edebe9f5-ae1e-44d4-a89d-d7af3c288565\">@Ammar Huss  <\/a><\/p>\n<p>Thanks for reaching out to us. Have you tried to make a call? As the document describes -<\/p>\n<p>Creating MLClient will not connect to the workspace. The client initialization is lazy, it will wait for the first time it needs to make a call (this will happen in the next code cell).<\/p>\n<p>Please call it at least once to make the connection.<\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-explore-data?view=azureml-api-2#create-handle-to-workspace\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-explore-data?view=azureml-api-2#create-handle-to-workspace<\/a><\/p>\n<p>I hope this helps. Please let me know if that happened after you make a call but still not succeed. <\/p>\n<p>Thanks,<\/p>\n<p>Yutong<\/p>\n<p>-Please kindly accept the answer and vote 'Yes' if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":1.0,
        "Solution_readability":8.8,
        "Solution_reading_time":12.59,
        "Solution_score_count":1.0,
        "Solution_sentence_count":10.0,
        "Solution_word_count":111.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":12.724685,
        "Challenge_answer_count":4,
        "Challenge_body":"<p>Hi,<\/p>\n<p>I need some help trying to understand why I can't see any GIT options (left panel and top selection drop down menu) in my Azure machine learning JupyterLab.<\/p>\n<p>I did the following steps:<\/p>\n<pre><code> jupyter labextension install @jupyterlab\/git\n pip install --upgrade jupyterlab-git\n jupyter serverextension enable --py jupyterlab_git\n jupyter lab build\n<\/code><\/pre>\n<p>I've restarted my jupyterLab a couple of times, if I check the command:<\/p>\n<pre><code> jupyter labextension list\n<\/code><\/pre>\n<p>I get that @jupyterlab\/git v0,20,0 is enabled and ok.  <br \/>\nWhat am I doing wrong?<\/p>\n<p>Thank you in advance,  <br \/>\nCarla<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/12015-issue1.png?platform=QnA\" alt=\"12015-issue1.png\" \/><\/p>",
        "Challenge_closed_time":1594762360103,
        "Challenge_comment_count":5,
        "Challenge_created_time":1594716551237,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/46614\/azure-machine-learning-and-jupyterlab-git-extensio",
        "Challenge_link_count":1,
        "Challenge_participation_count":9,
        "Challenge_readability":11.3,
        "Challenge_reading_time":10.84,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":12.724685,
        "Challenge_title":"Azure Machine Learning and jupyterlab git extension not working",
        "Challenge_topic":"Environment Installation",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":null,
        "Challenge_word_count":103,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi <a>@ramr-msft<\/a> ,<\/p>\n<p>I did the steps mention in the link you gave me (<a href=\"https:\/\/github.com\/jupyterlab\/jupyterlab-git\">https:\/\/github.com\/jupyterlab\/jupyterlab-git<\/a>) but still I can't open the Git extension from the Git tab on the left panel because it still doesn't exists.<\/p>\n<p>You mentioned we can still manage git repositories using the command line. Do you have any useful documentation on this approach?<\/p>\n<p>Once again, thank you in advance.  <br \/>\nCarla<\/p>\n",
        "Solution_comment_count":3.0,
        "Solution_link_count":1.0,
        "Solution_readability":8.4,
        "Solution_reading_time":6.23,
        "Solution_score_count":1.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":66.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":0.3654761111,
        "Challenge_answer_count":1,
        "Challenge_body":"I work in SM Studio, and I do not understand why CPU and memory usage do not appear in the notebook toolbar. These metrics should be there, at least given this description:\n\nhttps:\/\/docs.amazonaws.cn\/en_us\/sagemaker\/latest\/dg\/notebooks-menu.html\n\nWhen I open a notebook in SM Studio, I see the same toolbar but without CPU and memory usage listed. Moreover, I see 'cluster' before the kernel's name in my toolbar.\n\nHas anyone experienced sth similar? I assume an alternative for me would be to use CloudWatch.",
        "Challenge_closed_time":1652798353412,
        "Challenge_comment_count":0,
        "Challenge_created_time":1652797037698,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUGQfGnTgqQcyNbWVb3U9V8Q\/cpu-memory-usage-missing-from-sm-studio-notebook-toolbar",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":9.4,
        "Challenge_reading_time":7.01,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":0.3654761111,
        "Challenge_title":"CPU + memory usage missing from SM Studio notebook toolbar",
        "Challenge_topic":"Environment Installation",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":603.0,
        "Challenge_word_count":88,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"Hi, you should be able to see your CPU and Memory on the bottom toolbar, looks like `Kernel: Idle | Instance MEM`. You can click on that text to show the kernel and instance usage metrics.",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":6.6,
        "Solution_reading_time":2.25,
        "Solution_score_count":1.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":35.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":723.7180555556,
        "Challenge_answer_count":1,
        "Challenge_body":"A customer is using SageMaker Studio in VpcOnly mode (VPC, protected subnets **without** internet access, **NO** NAT gateways). \nThe all functionality is fine. However, when I try create a SageMaker projects - as described [here](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/sagemaker-projects-create.html), SageMaker Studio is unable to list the project templates (timeout and unspecified error) resulting in empty list of the available project templates.\n\nProjects are enabled for the users - as described [here](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/sagemaker-projects-studio-updates.html). The problem is with project creation.\n\nIs internet access (e.g. via NAT gateways) is needed for SageMaker projects?",
        "Challenge_closed_time":1618085440000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1615480055000,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUcyhpq1pxRTmtjkDRAh_MDA\/sagemaker-studio-projects-in-vpconly-mode-without-internet-access",
        "Challenge_link_count":2,
        "Challenge_participation_count":1,
        "Challenge_readability":11.9,
        "Challenge_reading_time":10.18,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":723.7180555556,
        "Challenge_title":"SageMaker Studio projects in VpcOnly mode without internet access",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":659.0,
        "Challenge_word_count":91,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"Figured it out. SageMaker Studio projects need Service Catalog access and VPCE for `com.amazonaws.${AWS::Region}.servicecatalog`",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":15.5,
        "Solution_reading_time":1.69,
        "Solution_score_count":0.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":14.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":1.1990072222,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>We are planing for next gen of product. Will V2 provide way more changes than V1? <\/p>",
        "Challenge_closed_time":1661981560816,
        "Challenge_comment_count":0,
        "Challenge_created_time":1661977244390,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/989368\/sdk-v1-or-v2",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":1.2,
        "Challenge_reading_time":1.22,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":1.1990072222,
        "Challenge_title":"SDK v1 or V2",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":20,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=7f2ff54e-2fc4-4d74-b946-fc6ec46d4863\">@nam  <\/a>    <\/p>\n<p>Thanks for using Microsoft Q&amp;A. I will recommend you keeping in V1 at this moment.     <\/p>\n<p>SDK v2 is currently in public preview. The preview version is provided without a service level agreement, and it's not recommended for production workloads. Certain features might not be supported or might have constrained capabilities. For more information, see Supplemental Terms of Use for Microsoft Azure Previews.    <\/p>\n<p><a href=\"https:\/\/azure.microsoft.com\/support\/legal\/preview-supplemental-terms\/\">https:\/\/azure.microsoft.com\/support\/legal\/preview-supplemental-terms\/<\/a>    <\/p>\n<p>I hope this helps.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":1.0,
        "Solution_readability":10.6,
        "Solution_reading_time":10.77,
        "Solution_score_count":0.0,
        "Solution_sentence_count":10.0,
        "Solution_word_count":97.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":7.0585394444,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>Hi is there a way for Azure Machine Learning to be able to perform analytics using data from an on premise SQL Server?    <\/p>\n<p>Only found the below article which is for Azure Machine Learning Studio (classic):    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/studio\/use-data-from-an-on-premises-sql-server\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/studio\/use-data-from-an-on-premises-sql-server<\/a>    <\/p>\n<p>Thanks.    <\/p>",
        "Challenge_closed_time":1592900268572,
        "Challenge_comment_count":0,
        "Challenge_created_time":1592874857830,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/38894\/azure-machine-learning-with-on-premise-sql-server",
        "Challenge_link_count":1,
        "Challenge_participation_count":2,
        "Challenge_readability":11.7,
        "Challenge_reading_time":6.79,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":7.0585394444,
        "Challenge_title":"Azure Machine Learning with on premise SQL Server",
        "Challenge_topic":"Dataset Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":null,
        "Challenge_word_count":50,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a>@conrad<\/a> Here is the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-register-datasets#access-datasets-in-your-script\">link<\/a> to connect with the Azure SQL server.  <br \/>\n<a href=\"https:\/\/stackoverflow.com\/questions\/61806350\/database-communication-link-error-occurded-on-azure-ml-service-used-azure-sql-s\/61950481#61950481\">https:\/\/stackoverflow.com\/questions\/61806350\/database-communication-link-error-occurded-on-azure-ml-service-used-azure-sql-s\/61950481#61950481<\/a><\/p>\n",
        "Solution_comment_count":2.0,
        "Solution_link_count":2.0,
        "Solution_readability":43.1,
        "Solution_reading_time":7.36,
        "Solution_score_count":1.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":16.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":2.3068894444,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>The Python package <a href=\"https:\/\/pypi.org\/project\/azureml-train\/\">azureml-train<\/a> is deprecated and seems basically a wrapper around <a href=\"https:\/\/pypi.org\/project\/azureml-train-core\/\">azureml-train-core<\/a>. When installing <code>azureml-train<\/code>, if I'm correct it tries to install the <code>azureml-train-core<\/code> package with the same version number. However, on the 24th of August 2021 the <code>azureml-train<\/code> package was <a href=\"https:\/\/pypi.org\/project\/azureml-train\/#history\">updated<\/a> to version 1.33.1 whereas <code>azureml-train-core<\/code> <a href=\"https:\/\/pypi.org\/project\/azureml-train-core\/#history\">wasn't updated<\/a>. This causes the installation of <code>azureml-train<\/code> to fail.   <\/p>\n<p>I would suggest to remove version 1.33.1 of <code>azureml-train<\/code> such that it still can be installed.  <br \/>\nOtherwise, I'm curious why this situation is the case.  <\/p>",
        "Challenge_closed_time":1629981340732,
        "Challenge_comment_count":0,
        "Challenge_created_time":1629973035930,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/528959\/(bug)-azureml-train-python-package-deprecated-but",
        "Challenge_link_count":4,
        "Challenge_participation_count":1,
        "Challenge_readability":11.8,
        "Challenge_reading_time":13.57,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":11,
        "Challenge_solved_time":2.3068894444,
        "Challenge_title":"[Bug] azureml-train Python package deprecated but did receive an update which is not in line with azureml-train-core",
        "Challenge_topic":"Environment Installation",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":null,
        "Challenge_word_count":106,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=b3ae76bb-30c9-45f0-9c89-d61eac6d87f6\">@SjoerdGn  <\/a> Yes, this is a bug in the release cycle that was pushed to pypi, This also caused other packages to get updated.    <\/p>\n<p><a href=\"https:\/\/pypi.org\/project\/azureml-train-automl-runtime\/1.33.1.post1\/\">https:\/\/pypi.org\/project\/azureml-train-automl-runtime\/1.33.1.post1\/<\/a>    <br \/>\n<a href=\"https:\/\/pypi.org\/project\/azureml-train-automl\/1.33.1\/\">https:\/\/pypi.org\/project\/azureml-train-automl\/1.33.1\/<\/a>    <\/p>\n<p><a href=\"https:\/\/pypi.org\/project\/azureml-sdk\/#history\">azureml-sdk 1.33.0.post1<\/a> is released now to ensure the correct versions are installed with the SDK. As you mentioned above azureml-train 1.33.1 is not required and can be removed.     <\/p>\n",
        "Solution_comment_count":1.0,
        "Solution_link_count":3.0,
        "Solution_readability":15.0,
        "Solution_reading_time":9.89,
        "Solution_score_count":1.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":62.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":90.4033952778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi Team,  <\/p>\n<p>I tried connecting to Azure table storage in Azure ML Studio. It shows connection successful after updating all credentials but after hitting run, import is landing to internal system error.  <br \/>\nBelow is the message :  <br \/>\n[Critical]     Error: Sorry, it seems that you have encountered an internal system error. Please contact amlforum@microsoft.com with the full URL in the browser and the time you experienced the failure. We can locate this error with your help and investigate further. Thank you.  <\/p>\n<p>Requesting you to please assist in this case.  <\/p>\n<p>Regards,  <br \/>\nSachin<\/p>",
        "Challenge_closed_time":1616395982956,
        "Challenge_comment_count":6,
        "Challenge_created_time":1616070530733,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/320696\/data-import-error-for-azure-table-storage-to-azure",
        "Challenge_link_count":0,
        "Challenge_participation_count":7,
        "Challenge_readability":7.9,
        "Challenge_reading_time":8.3,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":90.4033952778,
        "Challenge_title":"Data Import error for Azure table storage to Azure ML studio ?",
        "Challenge_topic":"Dataset Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":null,
        "Challenge_word_count":106,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello,    <\/p>\n<p>There is a known issue that Azure ML Studio only supports \u201chttp\u201d protocol when connecting with Azure Storage Account. You might hit this issue when using the Import Data module.    <\/p>\n<p>Here is a quick work around:    <br \/>\nPlease check the \u201cConfiguration\u201d of your Storage Account, and make sure the \u201cSecure transfer required\u201d is disabled (see the figure below).    <\/p>\n<p>If still encountering error after taking these steps, please double check and make sure the account key is correct.    <\/p>\n<p><a href=\"\/users\/na\/?userid=520e72bc-f33a-4fa2-84f8-4795fd5f44af\">@Sachin Gaikwad  <\/a> Please accept the answer if you feel the work around works. Thank you!    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/80028-image.png?platform=QnA\" alt=\"80028-image.png\" \/>    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":1.0,
        "Solution_readability":8.6,
        "Solution_reading_time":10.59,
        "Solution_score_count":0.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":108.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":0.6372222222,
        "Challenge_answer_count":1,
        "Challenge_body":"Hi,\n\nWhat parquet data loading logic is known to work well to train with SageMaker on parquet? ml-io? pyarrow? any examples? That would be to train a classifier, either logistic regression, XGBoost or custom TF.",
        "Challenge_closed_time":1588843302000,
        "Challenge_comment_count":1,
        "Challenge_created_time":1588841008000,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUCqvDUq4hSQqRT97tBUvE8Q\/training-a-classifier-on-parquet-with-sagemaker",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":8.8,
        "Challenge_reading_time":3.22,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":0.6372222222,
        "Challenge_title":"Training a classifier on parquet with SageMaker ?",
        "Challenge_topic":"Dataset Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":411.0,
        "Challenge_word_count":42,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":1.0,
        "Poster_isModerator":0.0,
        "Solution_body":"XGBoost as a framework container (v0.90+) can read parquet for training (see example [notebook][1]).  \nThe full list of valid content types are CSV, LIBSVM, PARQUET, RECORDIO_PROTOBUF (see [source][2]) \n\nAdditionally:  \n[Uber Petastorm][3] for reading parquet into Tensorflow, Pytorch, and PySpark inputs.   \nAs XGBoost accepts numpy, you can convert from PySpark to numpy\/pandas using the mentioned PyArrow.\n\n\n  [1]: https:\/\/github.com\/awslabs\/amazon-sagemaker-examples\/blob\/caf9363c0242d0da2de7f5765e7318fd843ce4c3\/introduction_to_amazon_algorithms\/xgboost_abalone\/xgboost_parquet_input_training.ipynb\n  [2]: https:\/\/github.com\/aws\/sagemaker-xgboost-container\/blob\/5e778770e009ce989e288e7bbc1255556129e75b\/src\/sagemaker_xgboost_container\/data_utils.py#L40\n  [3]: https:\/\/github.com\/uber\/petastorm",
        "Solution_comment_count":0.0,
        "Solution_link_count":3.0,
        "Solution_readability":19.1,
        "Solution_reading_time":10.59,
        "Solution_score_count":1.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":61.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":47.7326625,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>Hi Wandb Community!<\/p>\n<p>I have a laptop in my office that I am able to run <code>wandb local<\/code> on and sync my ML experiments to my account email address. My company gave me another laptop to work from on the road and I would like to set up <code>wandb local<\/code> on that laptop to streamline ML experiments I do in office and on the road.<\/p>\n<p>On my laptop, I have <code>wandb<\/code> and <code>docker<\/code> installed successfully. I can also run <code>wandb local<\/code> successfully. However, I\u2019m not sure if I need to copy the same api key and license over for the single account to work on both machines. Is there a smart way to do this?<\/p>\n<p>Thanks in advance!<\/p>\n<p>wand: 0.12.18<br>\nOS: Ubuntu 22.04<br>\ndocker: 20.10.17<\/p>",
        "Challenge_closed_time":1655499106272,
        "Challenge_comment_count":0,
        "Challenge_created_time":1655327268687,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/coordinate-wandb-local-across-two-laptops\/2620",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":6.3,
        "Challenge_reading_time":9.72,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":12,
        "Challenge_solved_time":47.7326625,
        "Challenge_title":"Coordinate wandb local across two laptops",
        "Challenge_topic":"Docker Configuration",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":167.0,
        "Challenge_word_count":130,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a class=\"mention\" href=\"\/u\/aclifton314\">@aclifton314<\/a> ,<\/p>\n<p>Thank you for writing in with your question. Local is explicitly an \u201con-device\u201d service.If you want to share data across devices,  you would want to host you instance on a server to be able to reach it from anywhere, otherwise your two laptops wont share data. You can however still use the individual machine to sync data back\/forth to W&amp;B cloud,  pull experiments\/runs\/metrics\/ ect. to the individual machines. If this is your intended approach then you can copy the same API and Local License key to both machines.  <a href=\"https:\/\/docs.wandb.ai\/guides\/self-hosted\/local#login\">Here<\/a> is a quick reference on how to switch between a private instance and the wandb cloud when you need to sync the data. Please let us know if you have additional questions.<\/p>\n<p>Regards,<\/p>\n<p>Mohammad<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":1.0,
        "Solution_readability":8.8,
        "Solution_reading_time":10.87,
        "Solution_score_count":null,
        "Solution_sentence_count":9.0,
        "Solution_word_count":128.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":25.1956663889,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Deploying my model to ACI takes forever and fails without any error message. In the ML workspace, the status of the deployed endpoint is unhealthy. I checked common errors while deployment but could not solve the problem. Pleas help. The deployment is never successful and it keeps running.<\/p>",
        "Challenge_closed_time":1649231254492,
        "Challenge_comment_count":0,
        "Challenge_created_time":1649140550093,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/800334\/issue-in-my-mlops-cd-pipeline",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":6.2,
        "Challenge_reading_time":4.05,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":25.1956663889,
        "Challenge_title":"Issue in my MLOPs CD pipeline.",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":53,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><em>anonymous user<\/em> Thanks for the question. Could you clarify the architecture of your model deployment? In particular, are you using a custom docker container for it?  Also, usually ACI would be used for testing, but I'd recommend investigating AKS for production model deployment.     <\/p>\n<p> I would deploy the container into a local machine\/VM with Docker to see the exact detail error message which you don't see via ACI deployment.<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":9.9,
        "Solution_reading_time":5.52,
        "Solution_score_count":1.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":70.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":1.7612627778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have trained and deployed a custom vision model via an Azure ML Notebook, following the guide: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/custom-vision-service\/quickstarts\/image-classification?tabs=visual-studio&amp;pivots=programming-language-python\">https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/custom-vision-service\/quickstarts\/image-classification?tabs=visual-studio&amp;pivots=programming-language-python<\/a>  <\/p>\n<p>I'm now trying to send images to the service via the SDK Notebook code: <\/p>\n<pre><code class=\"lang-python\">test_images_folder = '5point2\/frames'\noutput_images_folder = '5point2\/output'\n\n# Load the Arial font from the Matplotlib font library\nfont_path = fm.findfont(fm.FontProperties(family='Arial'))\n\n# Create a PIL ImageFont object using the Arial font\nfont_size = 16\nfont = ImageFont.truetype(font_path, font_size)\n\nfor filename in os.listdir(test_images_folder):\n    if filename.endswith(&quot;.jpg&quot;):\n        image_path = os.path.join(test_images_folder, filename)\n\n        with open(image_path, &quot;rb&quot;) as image_contents:\n            predictor1 = CustomVisionPredictionClient(end_point, pred_key)\n            headers = {'Prediction-Key': pred_key, 'Content-Type': 'application\/octet-stream'}\n            results = predictor1.classify_image(project.id, pub_iter_name, image_contents.read(), headers=headers)\n\n            # Load the image and create a drawing context.\n            im = Image.open(image_path)\n            draw = ImageDraw.Draw(im)\n\n            # Draw the class labels and their probabilities on the image.\n            for prediction in results.predictions:\n                label = prediction.tag_name + &quot;: {0:.2f}%&quot;.format(prediction.probability * 100)\n                draw.text((10, 10 + 20 * results.predictions.index(prediction)), label, fill=&quot;white&quot;, font=font)\n\n            # Save the output image.\n            output_image_path = os.path.join(output_images_folder, filename)\n            im.save(output_image_path)\n\n            # Print the predictions.\n            print(&quot;Predictions for&quot;, filename)\n            for prediction in results.predictions:\n                print(&quot;\\t&quot; + prediction.tag_name + &quot;: {0:.2f}%&quot;.format(prediction.probability * 100))\n\n        # Delay before sending the next image.\n        time.sleep(1)\n\n<\/code><\/pre>\n<p>But I get the following error: <\/p>\n<pre><code>AttributeError                            Traceback (most recent call last)\nInput In [114], in &lt;cell line: 18&gt;()\n     23 predictor1 = CustomVisionPredictionClient(end_point, pred_key)\n     24 headers = {'Prediction-Key': pred_key, 'Content-Type': 'application\/octet-stream'}\n---&gt; 25 results = predictor1.classify_image(project.id, pub_iter_name, image_contents.read(), headers=headers)\n     27 # Load the image and create a drawing context.\n     28 im = Image.open(image_path)\n\nFile \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/azure\/cognitiveservices\/vision\/customvision\/prediction\/operations\/_custom_vision_prediction_client_operations.py:73, in CustomVisionPredictionClientOperationsMixin.classify_image(self, project_id, published_name, image_data, application, custom_headers, raw, **operation_config)\n     71 # Construct and send request\n     72 request = self._client.post(url, query_parameters, header_parameters, form_content=form_data_content)\n---&gt; 73 response = self._client.send(request, stream=False, **operation_config)\n     75 if response.status_code not in [200]:\n     76     raise models.CustomVisionErrorException(self._deserialize, response)\n\nFile \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/msrest\/service_client.py:336, in ServiceClient.send(self, request, headers, content, **kwargs)\n    334 kwargs.setdefault('stream', True)\n    335 try:\n--&gt; 336     pipeline_response = self.config.pipeline.run(request, **kwargs)\n    337     # There is too much thing that expects this method to return a &quot;requests.Response&quot;\n    338     # to break it in a compatible release.\n    339     # Also, to be pragmatic in the &quot;sync&quot; world &quot;requests&quot; rules anyway.\n    340     # However, attach the Universal HTTP response\n    341     # to get the streaming generator.\n    342     response = pipeline_response.http_response.internal_response\n\nFile \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/msrest\/pipeline\/__init__.py:197, in Pipeline.run(self, request, **kwargs)\n    195 pipeline_request = Request(request, context)  # type: Request[HTTPRequestType]\n    196 first_node = self._impl_policies[0] if self._impl_policies else self._sender\n--&gt; 197 return first_node.send(pipeline_request, **kwargs)\n\nFile \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/msrest\/pipeline\/__init__.py:150, in _SansIOHTTPPolicyRunner.send(self, request, **kwargs)\n    148 self._policy.on_request(request, **kwargs)\n    149 try:\n--&gt; 150     response = self.next.send(request, **kwargs)\n    151 except Exception:\n    152     if not self._policy.on_exception(request, **kwargs):\n\nFile \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/msrest\/pipeline\/requests.py:65, in RequestsCredentialsPolicy.send(self, request, **kwargs)\n     63 session = request.context.session\n     64 try:\n---&gt; 65     self._creds.signed_session(session)\n     66 except TypeError: # Credentials does not support session injection\n     67     _LOGGER.warning(&quot;Your credentials class does not support session injection. Performance will not be at the maximum.&quot;)\n\nAttributeError: 'str' object has no attribute 'signed_session'\n<\/code><\/pre>\n<p>I have checked all my credentials and they are all correct.   <br \/>\nI am unable to use  azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionEndpoint as I am using Python.   <\/p>\n<p>I assume this is an SDK issue, please assist.   <\/p>\n<p>Thank you. <\/p>",
        "Challenge_closed_time":1680786974796,
        "Challenge_comment_count":3,
        "Challenge_created_time":1680780634250,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1199848\/attributeerror-str-object-has-no-attribute-signed",
        "Challenge_link_count":1,
        "Challenge_participation_count":4,
        "Challenge_readability":16.6,
        "Challenge_reading_time":74.8,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":66,
        "Challenge_solved_time":1.7612627778,
        "Challenge_title":"AttributeError: 'str' object has no attribute 'signed_session' for Python Notebook request to CV API.",
        "Challenge_topic":"Environment Installation",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":null,
        "Challenge_word_count":463,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=43306268-160b-4903-9156-e7ca00e7f352\">@Shane Dzartov  <\/a> I think this error is from the <code>msrest<\/code> package rather than the custom vision library. I see that you have not used or imported <code>ApiKeyCredentials<\/code> from <code>msrest<\/code> and instead the keys are directly passed to prediction client which seems to fail the request.<\/p>\n<p>Could you add the following in imports section:<\/p>\n<p><code>from msrest.authentication import ApiKeyCredentials<\/code><\/p>\n<p>And pass your key to <code>ApiKeyCredentials<\/code> and then to the prediction client?<\/p>\n<pre><code class=\"lang-python\">python prediction_credentials = ApiKeyCredentials(in_headers={&quot;Prediction-key&quot;: prediction_key})  \npredictor1 = CustomVisionPredictionClient(end_point, prediction_credentials) \n#Comment the headers declaration since SDK should take care of Content-Type header \nresults = predictor1.classify_image(project.id, pub_iter_name, image_contents.read()) \n\n<\/code><\/pre>\n<p>If this answers your query, do click <code>Accept Answer<\/code> and <code>Yes<\/code> for was this answer helpful. And, if you have any further query do let us know.<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":12.8,
        "Solution_reading_time":15.38,
        "Solution_score_count":1.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":123.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":27.2369069444,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have a output from previous step and want to use it as input to multiple steps.    <br \/>\nBut, when I run the experiment, the pipeline looks like this    <\/p>\n<p>Here is my code    <\/p>\n<pre><code>source_directory=&quot;.\/test&quot;  \ndesigner1_config = ScriptRunConfig(source_directory=source_directory,  \n                                 command=[&quot;python&quot;, &quot;designer1.py&quot;,   \n                                          &quot;--output_test1&quot;, output_test1], #   \n                                 compute_target=aml_compute,  \n                                 environment=env_py)  \n  \ndesigner1_step = CommandStep(name=&quot;designer_step&quot;,   \n                           inputs=[input_dept_fun_d],  \n                           outputs=[output_test1], #  \n                           runconfig=designer1_config,  \n                           allow_reuse=True)  \n\n\nsource_directory=&quot;.\/test&quot;  \ndesigner2_config = ScriptRunConfig(source_directory=source_directory,  \n                                 command=[&quot;python&quot;, &quot;designer2.py&quot;], #   \n                                 compute_target=aml_compute,  \n                                 environment=env_py)  \n  \ndesigner2_step = CommandStep(name=&quot;designer2_step&quot;,   \n                           inputs=[input_dept_fun_d, output_test1],  \n                           outputs=[], #  \n                           runconfig=designer2_config,  \n                           allow_reuse=True)  \n<\/code><\/pre>\n<p>Use 2 steps, it shows picture 1    <\/p>\n<pre><code>step_sequence = [designer1_step, designer2_step]  \n<\/code><\/pre>\n<p>Use 1 step, it shows picture 2    <\/p>\n<pre><code>step_sequence = [designer2_step]  \n  \n<\/code><\/pre>\n<p>Submit the experiement    <\/p>\n<pre><code>pipeline = Pipeline(workspace=ws, steps=step_sequence)  \npipeline_run = Experiment(workspace=ws, name='pipeline').submit(config=pipeline, regenerate_outputs=True)  \n<\/code><\/pre>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/190374-image.png?platform=QnA\" alt=\"190374-image.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/190373-image.png?platform=QnA\" alt=\"190373-image.png\" \/>    <\/p>\n<p>Here's what I want    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/190392-image.png?platform=QnA\" alt=\"190392-image.png\" \/>    <\/p>",
        "Challenge_closed_time":1649312364292,
        "Challenge_comment_count":2,
        "Challenge_created_time":1649214311427,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/801687\/azure-sdk-previous-step-output-to-multiple-steps-a",
        "Challenge_link_count":3,
        "Challenge_participation_count":3,
        "Challenge_readability":22.4,
        "Challenge_reading_time":25.81,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":10,
        "Challenge_solved_time":27.2369069444,
        "Challenge_title":"Azure SDK previous step output to multiple steps as input",
        "Challenge_topic":"Pipeline Configuration",
        "Challenge_topic_macro":"Lifecycle Management",
        "Challenge_view_count":null,
        "Challenge_word_count":126,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>@MiaZhangWHQWistron-2092 Based on the setup for designer2_step the inputs are the original input of step1 and the output of step1. The second screen shot seems appropriate and the designer has just replicated the original input dataset for step2. The connection that you are referring to is irrelevant because the same dataset is used, and designer only displays it for simplicity.    <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Solution_comment_count":3.0,
        "Solution_link_count":2.0,
        "Solution_readability":13.7,
        "Solution_reading_time":9.78,
        "Solution_score_count":1.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":87.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":455.8612047222,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>Hi,    <\/p>\n<p>I am doing the Challenge. <a href=\"https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/intro-to-azure-machine-learning-service\/\">https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/intro-to-azure-machine-learning-service\/<\/a>    <\/p>\n<p>Please see what I have installed:    <\/p>\n<blockquote>\n<p>pip install azureml-sdk    <\/p>\n<\/blockquote>\n<p>I am getting the following messages at the end:    <\/p>\n<blockquote>\n<p>ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.    <\/p>\n<p>We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.    <\/p>\n<p>jupyterlab 2.2.9 requires jupyterlab-server&lt;2.0,&gt;=1.1.5, which is not installed.    <br \/>\nSuccessfully installed applicationinsights-0.11.9 azure-identity-1.4.1 azureml-automl-core-1.19.0 azureml-dataprep-2.6.3 azureml-dataprep-native-26.0.0 azureml-dataprep-rslex-1.4.0 azureml-dataset-runtime-1.19.0.post1 azureml-pipeline-1.19.0 azureml-pipeline-core-1.19.0 azureml-pipeline-steps-1.19.0 azureml-sdk-1.19.0 azureml-telemetry-1.19.0 azureml-train-1.19.0 azureml-train-automl-client-1.19.0 azureml-train-core-1.19.0 azureml-train-restclients-hyperdrive-1.19.0 distro-1.5.0 dotnetcore2-2.1.20 fusepy-3.0.1 msal-1.8.0 msal-extensions-0.2.2 numpy-1.19.3 portalocker-1.7.1 pyarrow-1.0.1 pywin32-227    <\/p>\n<\/blockquote>\n<p>Now I am trying to start up and type the following in .py file in Visual Studio Code    <\/p>\n<blockquote>\n<p>from azureml.core import Workspace    <\/p>\n<\/blockquote>\n<p>This is the error message I am getting:    <\/p>\n<blockquote>\n<p> File &quot;c:\/Users\/User\/OneDrive\/Desktop\/New folder\/Build AI Solution\/automl_python.py&quot;, line 1, in &lt;module&gt;    <br \/>\n    from azureml.core import Workspace    <br \/>\nModuleNotFoundError: No module named 'azureml'    <\/p>\n<\/blockquote>\n<p>Please could you help me?    <\/p>\n<p>thanks,    <\/p>\n<p>Naveen<\/p>",
        "Challenge_closed_time":1610753174427,
        "Challenge_comment_count":0,
        "Challenge_created_time":1609112074090,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/211503\/modulenotfounderror-no-module-named-azureml",
        "Challenge_link_count":1,
        "Challenge_participation_count":2,
        "Challenge_readability":11.8,
        "Challenge_reading_time":26.75,
        "Challenge_score_count":4.0,
        "Challenge_sentence_count":15,
        "Challenge_solved_time":455.8612047222,
        "Challenge_title":"ModuleNotFoundError: No module named 'azureml'",
        "Challenge_topic":"Environment Installation",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":null,
        "Challenge_word_count":190,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>This is now solved. Thanks!<\/p>\n",
        "Solution_comment_count":1.0,
        "Solution_link_count":0.0,
        "Solution_readability":-1.9,
        "Solution_reading_time":0.44,
        "Solution_score_count":29.0,
        "Solution_sentence_count":1.0,
        "Solution_word_count":5.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":244.1759163889,
        "Challenge_answer_count":8,
        "Challenge_body":"<p>Hello, I ran a Unet on an other machine whithout internet and retrieved the offline Run. I am trying to sync it with wandb but, there are en issu that say:<\/p>\n<p>wandb: ERROR Uploading artifact file failed. Artifact won\u2019t be committed.<br>\nwandb: ERROR Error uploading [Path of the artefact on the other machine] : FileNotFoundError, [Errno 2] No such file or directory: [Path of the artefact on the other machine]<\/p>\n<p>When I searched for a solution, I couldn\u2019t find anything that realy helped and all the last topics had been finished whithout solution or answer from person who questions.<\/p>\n<p>I tryed this:<\/p>\n<ul>\n<li>\n<p>!wandb sync --project [the name] --entity [the name] [the path]<\/p>\n<\/li>\n<li>\n<p>!wandb sync  [the path]<\/p>\n<\/li>\n<li>\n<p>wandbId=wandb.util.generate_id()<br>\n!wandb sync [the path] --id wandbId<\/p>\n<\/li>\n<\/ul>\n<p>Thank you for your time, I hope you can help me<\/p>\n<p>Have a good day<\/p>",
        "Challenge_closed_time":1682337449096,
        "Challenge_comment_count":0,
        "Challenge_created_time":1681458415797,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/sync-offline-run-in-a-other-machine\/4218",
        "Challenge_link_count":0,
        "Challenge_participation_count":8,
        "Challenge_readability":7.5,
        "Challenge_reading_time":11.9,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":244.1759163889,
        "Challenge_title":"Sync offline Run in a other machine",
        "Challenge_topic":"YAML Configuration",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":139.0,
        "Challenge_word_count":151,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi <a class=\"mention\" href=\"\/u\/seirihiri\">@seirihiri<\/a>, thanks for the explanation! You can set the artifacts folder with the <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/environment-variables#optional-environment-variables\">env variable<\/a> <code>WANDB_CACHE_DIR <\/code> and point that to the folder you want. Regarding the artifacts created when running offline, it depends if you\u2019re creating them or not (they can be created not only when logging an <a href=\"https:\/\/docs.wandb.ai\/guides\/artifacts#how-it-works\">artifact<\/a> but also when logging tables for example). Let me know if this helps!<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":2.0,
        "Solution_readability":13.6,
        "Solution_reading_time":7.9,
        "Solution_score_count":null,
        "Solution_sentence_count":6.0,
        "Solution_word_count":68.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":1.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":2.7800052778,
        "Challenge_answer_count":1,
        "Challenge_body":"Hi! The following error happens while trying to create an endpoint from a successful trained model:\n\n* In the web console: \n> The customer:primary container for production variant AllTraffic did not pass the ping health check. Please check CloudWatch logs for this endpoint.\n * CloudWatch logs: \n> exec: \"serve\": executable file not found in $PATH\n\nIm deploying the model using a Lambda step, just as in this [notebook](https:\/\/github.com\/aws\/amazon-sagemaker-examples\/blob\/main\/sagemaker-pipelines\/tabular\/tensorflow2-california-housing-sagemaker-pipelines-deploy-endpoint\/tensorflow2-california-housing-sagemaker-pipelines-deploy-endpoint.ipynb). The Lambda step is successful, and I can see in the AWS web console that the model configuration is created with success. \n\nThe exact same error happens when I  create an endpoint for the registered model in the AWS web console, under Inference -> Models. In the console I can see that an inference container was created for the model, with the following characteristics:\n* Image: 763104351884.dkr.ecr.eu-west-3.amazonaws.com\/tensorflow-training:2.8-cpu-py39\n* Mode: single model\n* Environment variables (Key Value): \n> SAGEMAKER_CONTAINER_LOG_LEVEL\t20\n\n> SAGEMAKER_PROGRAM\tinference.py\n\n> SAGEMAKER_REGION\teu-west-3\n\n> SAGEMAKER_SUBMIT_DIRECTORY\t\/opt\/ml\/model\/code\n \nI absolutely have no clue what is wrong and I could not find anything relevant online about this problem. Is it necessary to provide an custom docker image for inference or something?\n\nFor more details, please find below the pipeline model steps code. Any help would be much appreciated!\n```\nmodel = Model(\n    image_uri=estimator.training_image_uri(),\n    model_data=step_training.properties.ModelArtifacts.S3ModelArtifacts,\n    sagemaker_session=sagemaker_session,\n    role=sagemaker_role,\n    source_dir='code',\n    entry_point='inference.py'\n)\nstep_model_create = ModelStep(\n        name=\"CreateModelStep\",\n        step_args=model.create(instance_type=\"ml.m5.large\")\n )\n\nregister_args = model.register(\n        content_types=[\"*\"],\n        response_types=[\"application\/json\"],\n        inference_instances=[\"ml.m5.large\"],\n        transform_instances=[\"ml.m5.large\"],\n        model_package_group_name=\"test\",\n        approval_status=\"Approved\"\n)\nstep_model_register = ModelStep(name=\"RegisterModelStep\", step_args=register_args)\n```",
        "Challenge_closed_time":1670290340636,
        "Challenge_comment_count":0,
        "Challenge_created_time":1670280332617,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QU0JgbfwUoS5m6VH4TvtZmkg\/error-creating-endpoint",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":17.4,
        "Challenge_reading_time":29.86,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":18,
        "Challenge_solved_time":2.7800052778,
        "Challenge_title":"Error Creating Endpoint",
        "Challenge_topic":"CloudWatch Monitoring",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":66.0,
        "Challenge_word_count":218,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"Hi, the problem here is that your inference model's container URI `763104351884.dkr.ecr.eu-west-3.amazonaws.com\/tensorflow-training:2.8-cpu-py39` is using a **training** image, not an **inference** image for TensorFlow. Because the images are each optimized for their own function, the serving executable is not available in the training container in this case.\n\nUsually, the framework-specific SDK classes will handle this lookup for you (for example `TensorFlowModel(...)` as used in the notebook you linked, or when calling `sagemaker.tensorflow.TensorFlow.deploy(...)` from the Estimator class.\n\nI see here though that you're using the generic `Model`, so guess you don't know (or don't want to commit to) the framework and version at the point the Lambda function runs?\n\nMy suggestions would be:\n\n- Can you use the Pipelines `ModelStep` to create your model before calling the Lambda deployment function? Similarly to how your linked notebook uses `CreateModelStep`. This would build your framework & version into the pipeline definition itself, but should mean that the selection of inference container image gets handled properly & automatically.\n- If you really need to be dynamic, I think you might need to find a way of looking up at least the *framework* from the training job. From my testing, you can use `estimator = sagemaker.tensorflow.TensorFlow.attach(\"training-job-name\")` and then `model = estimator.create_model(...)` to correctly infer the specific inference container *version* from a training job, but it still relies on knowing that TensorFlow is the correct framework. I'm not aware of a framework-agnostic equivalent? So could e.g. try describing the training job, manually inferring which framework it uses from that information, and then using the relevant framework estimator class' [attach()](https:\/\/sagemaker.readthedocs.io\/en\/stable\/api\/training\/estimators.html#sagemaker.estimator.EstimatorBase.attach) method to figure out the specifics and create your model.",
        "Solution_comment_count":1.0,
        "Solution_link_count":1.0,
        "Solution_readability":11.4,
        "Solution_reading_time":25.27,
        "Solution_score_count":1.0,
        "Solution_sentence_count":18.0,
        "Solution_word_count":266.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":131.5469241667,
        "Challenge_answer_count":10,
        "Challenge_body":"<p>Hi,<br>\nI\u2019m currently working on a self-supervised representation learning project, and to evaluate the quality of my models I train a linear classifier on the outputs of my (frozen) trained encoder and look at the downstream classification accuracy.<\/p>\n<p>This evaluation procedure is done separately from the training of the encoder, however is there still a way to add the metrics computed during this evaluation phase to the standard metrics I log during the training phase, in the same run panel?<\/p>\n<p>More generally, can I add metrics to a run that is already finished?<\/p>\n<p>Thanks a lot!<\/p>",
        "Challenge_closed_time":1674087539911,
        "Challenge_comment_count":0,
        "Challenge_created_time":1673613970984,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/log-custom-metrics-for-a-run-outside-of-the-training-loop\/3696",
        "Challenge_link_count":0,
        "Challenge_participation_count":10,
        "Challenge_readability":11.6,
        "Challenge_reading_time":8.21,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":131.5469241667,
        "Challenge_title":"Log custom metrics for a run outside of the training loop",
        "Challenge_topic":"Hyperparameter Tuning",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":234.0,
        "Challenge_word_count":106,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi <a class=\"mention\" href=\"\/u\/ari0u\">@ari0u<\/a> , appreciate your your additional feedback.<\/p>\n<p>This approach of first logging , <code>loss<\/code>, to a run, then revisiting\/resuming a run to log different metric, <code>accuracy<\/code>, starting from <strong>step zero<\/strong> again is not supported. The wandb logging step must be monotonically increasing in each call, otherwise the <code>step<\/code> value is ignored during your call to <code>log()<\/code>. Now if you are not interested in logging accuracy at step 0, you <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/advanced\/resuming#resuming-guidance\">could resume<\/a> the previously finished run using its un id and log additional metrics to the run. this however is problematic as the new metric is logged starting at the last known\/registered step for the run.<\/p>\n<p>One approach to get around the issue you are running into  is to assign each of the runs to a <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/advanced\/grouping\">specific group<\/a>. Example set <code>group = version_0<\/code> for any runs that logs metrics for this specific version of the model. You could then set grouping in the workspace to help with tracking  the different metrics for each experiment, <a href=\"https:\/\/wandb.ai\/mohammadbakir\/Group-Viz-Test\/groups\/L2\/workspace?workspace=user-mohammadbakir\">see this example workspace<\/a>.<\/p>\n<p>Hope this helps and please let us know if you have additional questions.<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":3.0,
        "Solution_readability":12.1,
        "Solution_reading_time":18.63,
        "Solution_score_count":null,
        "Solution_sentence_count":11.0,
        "Solution_word_count":183.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":0.1396913889,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi team,     <br \/>\nI am learning about the quota for machine learning service and I have a general doubt.    <\/p>\n<p>I can see that quotas for CPU cores is set at subscription level. Now, lets say my subscription level total CPU cores quota is 10.    <br \/>\nAnd i have 2 resource groups under that subscription. Can I assign 5 -5 cores each to both of the resource groups.     <\/p>\n<p>so that if all the cores are taken up by the resources under 1 resource group, the other resource_group (or the ML workspace under the other resource group) should not suffer.    <\/p>\n<p>I am able to find out  the-  get details query but this one doesnt give me details specific to each resource-group or the workspace.    <\/p>\n<p>HTTP query -&gt; <a href=\"https:\/\/management.azure.com\/subscriptions\/%7Bsubs_id%7D\/providers\/Microsoft.MachineLearningServices\/locations\/eastus\/usages?api-version=2022-10-01\">https:\/\/management.azure.com\/subscriptions\/{subs_id}\/providers\/Microsoft.MachineLearningServices\/locations\/eastus\/usages?api-version=2022-10-01<\/a><\/p>",
        "Challenge_closed_time":1667069947336,
        "Challenge_comment_count":0,
        "Challenge_created_time":1667069444447,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1067916\/how-to-set-quota-at-resource-group-level",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":10.4,
        "Challenge_reading_time":13.62,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":0.1396913889,
        "Challenge_title":"how to set Quota at resource group level?",
        "Challenge_topic":"Quota Management",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":null,
        "Challenge_word_count":138,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi <a href=\"\/users\/na\/?userid=7bafa6a3-9285-4b1c-a003-4490a74d05b5\">@JA  <\/a> ,    <\/p>\n<p>quotas can be set on Azure Subscription level only.    <br \/>\nThere is no option to apply quotas for different Azure Resource Groups.    <br \/>\nThere are 2 options I can see for your requirement:    <br \/>\nUse 2 Azure Subscriptions for each Resource Group    <br \/>\nUse the 2 Resource Groups in 2 different regions. There is a quota for vCPUs per region within the same Subscription.    <\/p>\n<p>----------    <\/p>\n<p>(If the reply was helpful please don't forget to <strong>upvote<\/strong> and\/or <strong>accept as answer<\/strong>, thank you)    <\/p>\n<p>Regards    <br \/>\n Andreas Baumgarten    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":8.2,
        "Solution_reading_time":8.26,
        "Solution_score_count":2.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":94.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":10.4670722222,
        "Challenge_answer_count":4,
        "Challenge_body":"<p>My current email id will be deactivated soon, so I need to change the email id associated with W&amp;B. Following the advice from this <a href=\"https:\/\/community.wandb.ai\/t\/possible-to-add-options-to-edit-profile\/123\/7\">thread<\/a>, I have created a new account. Can someone help me on this? (Had emailed someone from the Community team last week as well)<\/p>",
        "Challenge_closed_time":1636496146540,
        "Challenge_comment_count":0,
        "Challenge_created_time":1636458465080,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/transfer-my-account-email-change\/1247",
        "Challenge_link_count":1,
        "Challenge_participation_count":4,
        "Challenge_readability":9.1,
        "Challenge_reading_time":5.05,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":10.4670722222,
        "Challenge_title":"Transfer my account (email change)",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":329.0,
        "Challenge_word_count":53,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi <a class=\"mention\" href=\"\/u\/dsteam\">@dsteam<\/a>!<\/p>\n<p>I will be happy to help you move your projects to your new account. Could you email us at <a href=\"mailto:support@wandb.com\">support@wandb.com<\/a> about this with the details of the move? Specifically:<\/p>\n<ul>\n<li>The entity name of the account you want projects moved from<\/li>\n<li>The entity name of the account you want projects moved into<\/li>\n<li>Which projects you want moved (or if you want all)<\/li>\n<\/ul>\n<p>Thanks,<br>\nRamit<br>\nWeights and Biases support<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":7.9,
        "Solution_reading_time":6.74,
        "Solution_score_count":null,
        "Solution_sentence_count":5.0,
        "Solution_word_count":74.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":0.9765355556,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>When I connect the ML model endpoint with Power BI, it doesn't show me the model attributes that match the PBI dataset. Can you please help with the expected data format in Power BI.<\/p>",
        "Challenge_closed_time":1653287904968,
        "Challenge_comment_count":2,
        "Challenge_created_time":1653284389440,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/859568\/consuming-ml-models-on-power-bi",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":6.0,
        "Challenge_reading_time":2.69,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":0.9765355556,
        "Challenge_title":"Consuming ML models on Power BI",
        "Challenge_topic":"Dataset Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":null,
        "Challenge_word_count":39,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=78d653c4-ee0a-4cd3-b540-08c38c4bd217\">@Arjun  <\/a> Thanks, Can you try define the input schema and follow the below sample.    <\/p>\n<p> Here is the <a href=\"https:\/\/github.com\/WipadaChan\/pbi_demo_repo\/tree\/master\/03_DeployH2O_PBI\">sample<\/a> to Deploy trained model to Azure ML and use Power BI to score new data.    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":1.0,
        "Solution_readability":8.4,
        "Solution_reading_time":4.5,
        "Solution_score_count":0.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":39.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":0.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":144.7355655556,
        "Challenge_answer_count":1,
        "Challenge_body":"I want to enable data capture for a specific endpoint (so far, only via the console). The endpoint works fine and also logs & returns the desired results. However, no files are written to the specified S3 location.\n\n### Endpoint Configuration ###\n\nThe endpoint is based on a training job with a scikit learn classifier. It has only one variant which is a `ml.m4.xlarge` instance type. Data Capture is enabled with a sampling percentage of 100%. As data capture storage locations I tried `s3:\/\/<bucket-name>` as well as `s3:\/\/<bucket-name>\/<some-other-path>`. With the \"Capture content type\" I tried leaving everything blank, setting `text\/csv` in \"CSV\/Text\" and `application\/json` in \"JSON\".\n\n### Endpoint Invokation ###\n\nThe endpoint is invoked in a Lambda function with a client. Here's the call:\n```\nsagemaker_body_source = {\n            \"segments\": segments,\n            \"language\": language\n        }\npayload = json.dumps(sagemaker_body_source).encode()\nresponse = self.client.invoke_endpoint(EndpointName=endpoint_name,\n                                       Body=payload,\n                                       ContentType='application\/json',\n                                       Accept='application\/json')\nresult = json.loads(response['Body'].read().decode())\nreturn result[\"predictions\"]\n```\nInternally, the endpoint uses a Flask API with an `\/invocation` path that returns the result.\n\n### Logs ###\n\nThe endpoint itself works fine and the Flask API is logging input and output:\n```\nINFO:api:body: {'segments': [<strings...>], 'language': 'de'}\n```\n\n```\nINFO:api:output: {'predictions': [{'text': 'some text', 'label': 'some_label'}, ....]}\n```",
        "Challenge_closed_time":1660656368966,
        "Challenge_comment_count":0,
        "Challenge_created_time":1660135320930,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUKWPP4eXTTZe5qIUDJAXnsQ\/sagemaker-data-capture-does-not-write-files",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":9.9,
        "Challenge_reading_time":19.7,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":17,
        "Challenge_solved_time":144.7355655556,
        "Challenge_title":"Sagemaker Data Capture does not write files",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":74.0,
        "Challenge_word_count":183,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"So the issue seemed to be related to the IAM role. The default role (`ModelEndpoint-Role`) does not have access to write S3 files. It worked via the SDK since it uses another role in the sagemaker studio. I did not receive any error message about this.",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":5.4,
        "Solution_reading_time":3.04,
        "Solution_score_count":0.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":46.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":10.4716361111,
        "Challenge_answer_count":5,
        "Challenge_body":"<p>Hy, I\u2019m in love with wandb, but I have a problem\u2026<\/p>\n<p>I have a simple question\u2026<\/p>\n<p>How can I analyze hyperparameters\u2026As seen in this picture, without actually creating a sweep.<\/p>\n<p>In my own code\u2026<\/p>\n<p><img src=\"https:\/\/mail.google.com\/mail\/u\/0?ui=2&amp;ik=8824e8d63e&amp;attid=0.1&amp;permmsgid=msg-a:r-1242756300606160728&amp;th=181d7b1a169f2ed0&amp;view=fimg&amp;fur=ip&amp;sz=s0-l75-ft&amp;attbid=ANGjdJ9LbpPclu5VUg_KiYT_9MyY2AbgyxXn6tmqz8qoKH2kUghMnyxeJstBhkIK4wCOgqfFHueuZ6ul6juIl6zvWD3lcsPXIvZAnZatibVLxPjneVvO-xSUoWLyCpM&amp;disp=emb&amp;realattid=ii_l5aqmkag2\" alt=\"68747470733a2f2f692e696d6775722e636f6d2f5455333451465a2e706e67.png\" width=\"339\" height=\"205\"><\/p>\n<p>I\u2019m preforming learning and for every model i\u2019m sending config with hyperparams\u2026<\/p>\n<p>wandb.finish(quiet=True)<br>\nwandb.init(<br>\nentity=var.WANDB_ENTITY,<br>\nproject=f\u2019{var.version} | {var.INPUT_DATASET}',<br>\ndir=str(var.working_dir),<br>\nconfig=utils.keras.hyper_params(hp))<\/p>\n<p>But in dashboard I dont see hyperparameters dashboard\u2026 And this makes me really sad !<\/p>",
        "Challenge_closed_time":1657219039908,
        "Challenge_comment_count":0,
        "Challenge_created_time":1657181342018,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/analyzing-hyperparameters-without-actualy-performing-a-sweep\/2719",
        "Challenge_link_count":1,
        "Challenge_participation_count":5,
        "Challenge_readability":21.3,
        "Challenge_reading_time":15.42,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":10.4716361111,
        "Challenge_title":"Analyzing hyperparameters without actualy performing a sweep",
        "Challenge_topic":"Hyperparameter Tuning",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":130.0,
        "Challenge_word_count":79,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>I can\u2019t see the images above, but if you would like to create a <a href=\"https:\/\/docs.wandb.ai\/ref\/app\/features\/panels\/parallel-coordinates\">parallel coordinates plot<\/a>, you can do so using the UI by clicking \u201cadd panel\u201d in your workspace and choosing Parallel Coordinates.<\/p>\n<p>If you need to do this programmatically, one <em>very<\/em> recent feature would be to create a W&amp;B Report using our Api. You can programatically define what plots show up. It is a very new feature so it\u2019ll become better documented and more stable over time.<\/p>\n<p>Here\u2019s how you would create a Parallel Coordinates plot programmatically and save it in a report using Python.<\/p>\n<pre><code class=\"lang-auto\">import wandb\nimport wandb.apis.reports as wb\napi = wandb.Api()\nproject = 'pytorch-sweeps-demo'\nwandb.require('report-editing') # this is needed as of version 0.12.21 but will likely not be needed in future.\nreport = wb.Report(\n    project=project,\n    title='Sweep Results',\n    blocks=[\n            wb.PanelGrid(panels=[\n                 wb.ParallelCoordinatesPlot(\n                     columns=[wb.reports.PCColumn('batch_size'), wb.reports.PCColumn('epoch'), wb.reports.PCColumn('loss')])\n            ], runsets=[wb.RunSet(project=project)]),\n    ]\n)\nreport.save()\n<\/code><\/pre>\n<p>This will then show up in the Reports tab on your project.<br>\nAs this is a very fresh API, there may be issues or features that are not supported yet. I do apologise if that happens to you, I\u2019ll be happy to follow up and provide help.<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":1.0,
        "Solution_readability":10.5,
        "Solution_reading_time":18.39,
        "Solution_score_count":null,
        "Solution_sentence_count":15.0,
        "Solution_word_count":187.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":265.7839591667,
        "Challenge_answer_count":5,
        "Challenge_body":"<p>I recently started using the <code>wandb.Api()<\/code> in order not to manually download all the Charts in <code>.csv<\/code> format.<\/p>\n<p>The problem is that I cannot get consistent results, most of the times that I call the API  in a jupyter-notebook I get different results.<\/p>\n<p>I have made public one of my dashboards to tackle this issue. Here is a screenshot with a reproducible example:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/3bd006338d2541c672c4bf4c2f5e60aa6144e60c.png\" data-download-href=\"\/uploads\/short-url\/8x7Rm9lNkSyg4pi6edKG0wNOxgE.png?dl=1\" title=\"2022-05-16-165542_647x517_scrot\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/3bd006338d2541c672c4bf4c2f5e60aa6144e60c.png\" alt=\"2022-05-16-165542_647x517_scrot\" data-base62-sha1=\"8x7Rm9lNkSyg4pi6edKG0wNOxgE\" width=\"625\" height=\"500\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/3bd006338d2541c672c4bf4c2f5e60aa6144e60c_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">2022-05-16-165542_647x517_scrot<\/span><span class=\"informations\">647\u00d7517 50.3 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>In order to obtain the <code>csv_val_f1<\/code> variable one just needs to download the <code>Val F1<\/code> chart. Two things can be seen here:<\/p>\n<ol>\n<li>Multiple runs of the same code produce different results<\/li>\n<li>The maximum value obtained by the API differs from the maximum value obtained by manually downloading the <code>.csv<\/code> version of the Chart.<\/li>\n<\/ol>\n<p>Any ideas on what I\u2019m missing?<\/p>",
        "Challenge_closed_time":1653670051375,
        "Challenge_comment_count":0,
        "Challenge_created_time":1652713229122,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/run-history-returns-different-values-on-almost-each-call\/2431",
        "Challenge_link_count":3,
        "Challenge_participation_count":5,
        "Challenge_readability":14.1,
        "Challenge_reading_time":26.18,
        "Challenge_score_count":2.0,
        "Challenge_sentence_count":13,
        "Challenge_solved_time":265.7839591667,
        "Challenge_title":"Run.history() returns different values on almost each call",
        "Challenge_topic":"Environment Installation",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":832.0,
        "Challenge_word_count":165,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi <a class=\"mention\" href=\"\/u\/jaeheelee\">@jaeheelee<\/a> and <a class=\"mention\" href=\"\/u\/carloshernandezp\">@carloshernandezp<\/a>,<br>\nI believe you are seeing this because we sample the data points when you call <code>run.history()<\/code>. You can use <code>run.scan_history()<\/code> if you would like to have the entire history returned. <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/public-api-guide#sampling\">Here<\/a> is some more information on this.<\/p>\n<p>Let me know if this solves the issue for you.<\/p>\n<p>Thank you,<br>\nNate<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":1.0,
        "Solution_readability":9.5,
        "Solution_reading_time":7.07,
        "Solution_score_count":null,
        "Solution_sentence_count":6.0,
        "Solution_word_count":59.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":6.5106594444,
        "Challenge_answer_count":2,
        "Challenge_body":"based on the sample code provided here , https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/serverless-endpoints-create.html#serverless-endpoints-create-config\n\nI created a model via lambda, now when i try to create a serverless endpoint config (sample code below) , i keep getting -> parameter validation failed \nunknown parameter in` ProductVariants [ 0 ]:` \"ServerlessConfig\", must be one of : VairantName, ModelName, InitialInstanceCount , Instancetype...\n\n```\nresponse = client.create_endpoint_config(\n   EndpointConfigName=\"endpoint-new\",\n   ProductionVariants=[\n        {\n            \"ModelName\": \"MyModel\",\n            \"VariantName\": \"AllTraffic\",\n            \"ServerlessConfig\": {\n                \"MemorySizeInMB\": 2048,\n                \"MaxConcurrency\": 10\n            }\n        } \n    ]\n)\n```",
        "Challenge_closed_time":1645090644600,
        "Challenge_comment_count":0,
        "Challenge_created_time":1645067206226,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUfmAxh_aDQiS2nk0gbDicsg\/how-to-create-a-serverless-endpoint-configuration",
        "Challenge_link_count":1,
        "Challenge_participation_count":2,
        "Challenge_readability":20.3,
        "Challenge_reading_time":9.7,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":6.5106594444,
        "Challenge_title":"How to create a serverless endpoint configuration?",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":255.0,
        "Challenge_word_count":66,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"The cause might be that your SageMaker Python SDK is not updated to the latest version. Please make sure you update it to the latest version as well as the AWS SDK for Python (boto3). You can use pip:\n\n```\npip install --upgrade boto3\npip install --upgrade sagemaker\n```\n\n\nFor a sample notebook you can have a look [here](https:\/\/github.com\/aws\/amazon-sagemaker-examples\/blob\/main\/serverless-inference\/Serverless-Inference-Walkthrough.ipynb). More information on the documentation [page](https:\/\/sagemaker.readthedocs.io\/en\/stable\/overview.html#sagemaker-serverless-inference).",
        "Solution_comment_count":0.0,
        "Solution_link_count":2.0,
        "Solution_readability":14.2,
        "Solution_reading_time":7.48,
        "Solution_score_count":1.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":63.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":3.8833333333,
        "Challenge_answer_count":1,
        "Challenge_body":"Hi,\u00a0\n\nI'm stuck at following error message when I try to create vertex-ai endpoint from workbench notebook.\u00a0 I have enabled\u00a0aiplatform.googleapis.com.\n\nCommand:\ngcloud ai endpoints create \\\n--project=XXXXX\n--region=us-central1 \\\n--display-name=ld-test-resnet-classifier\n\nUsing endpoint [https:\/\/us-central1-aiplatform.googleapis.com\/]\nERROR: (gcloud.ai.endpoints.create) FAILED_PRECONDITION: Project XXXXXXXXXX is not active.\n\nPlease suggest what am I missing.",
        "Challenge_closed_time":1661575080000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1661561100000,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-create-endpoint-error-FAILED-PRECONDITION-Project\/td-p\/460565\/jump-to\/first-unread-message",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":11.1,
        "Challenge_reading_time":7.1,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":3.8833333333,
        "Challenge_title":"Vertex AI create endpoint error - FAILED_PRECONDITION: Project xxxxxxxx is not active.",
        "Challenge_topic":"Environment Installation",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":310.0,
        "Challenge_word_count":56,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"Hi,\nThe issue is resolved.\nAt least one model has to be uploaded first to model registry for this command to work.\nThe official documentation titled \"Deploy a model using the Vertex AI API\" - implies deploy a model uploaded to model registry\".\n\nThanks for the views.\n\nView solution in original post",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":7.3,
        "Solution_reading_time":3.6,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":51.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":0.4124352778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am using Azure ML for real-time machine learning. I have installed the Kafka server, but I am having a connection issue when trying to create a topic using the below line of code. I received the following warning: WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost\/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient). I appreciate your help.<\/p>\n<pre><code>!.\/kafka_2.13-3.3.2\/bin\/kafka-topics.sh --create --topic amids-train --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1\n<\/code><\/pre>",
        "Challenge_closed_time":1680844061480,
        "Challenge_comment_count":0,
        "Challenge_created_time":1680842576713,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1202024\/azure-ml-and-kafka-server-connection-issue",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":9.5,
        "Challenge_reading_time":8.31,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":8,
        "Challenge_solved_time":0.4124352778,
        "Challenge_title":"Azure ML and Kafka Server Connection Issue",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":78,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi Ghada,\nThe warning message you received suggests that the Kafka broker may not be available or is not running on the specified address and port.\nHere are some steps you can follow to troubleshoot the issue:<\/p>\n<ol>\n<li> Verify that the Kafka broker is running: You can check if the Kafka broker is running by using the following command in a new terminal window:\n    .\/kafka_2.13-3.3.2\/bin\/kafka-server-start.sh .\/kafka_2.13-3.3.2\/config\/server.properties<\/li>\n<li> Verify that the address and port are correct: Make sure that the address and port specified in the <strong><code>bootstrap-server<\/code><\/strong> parameter are correct and that there are no firewall or network configuration issues preventing you from connecting to the broker.<\/li>\n<li> Check the Kafka logs for errors: Check the Kafka logs to see if there are any error messages that could help identify the issue. You can find the Kafka logs in the <strong><code>logs<\/code><\/strong> directory of your Kafka installation.<\/li>\n<li> Try using a different topic name: It's possible that the topic name you're using is already in use or is invalid. Try using a different topic name to see if that resolves the issue.<\/li>\n<\/ol>\n<p>I hope these steps help you resolve the issue. Let me know if you have any further questions!<\/p>\n",
        "Solution_comment_count":5.0,
        "Solution_link_count":0.0,
        "Solution_readability":10.8,
        "Solution_reading_time":16.11,
        "Solution_score_count":1.0,
        "Solution_sentence_count":9.0,
        "Solution_word_count":200.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":31.5388561111,
        "Challenge_answer_count":3,
        "Challenge_body":"<p>I am finetuning multiple models using for loop as follows.<\/p>\n<pre><code class=\"lang-auto\">for file in os.listdir(args.data_dir):\n    finetune(args, file)\n<\/code><\/pre>\n<p>BUT <code>wandb<\/code> shows logs only for the first file in <code>data_dir<\/code> although it is training and saving models for other files. It feels very strange behavior.<\/p>\n<pre><code class=\"lang-auto\">wandb: Synced bertweet-base-finetuned-file1: https:\/\/wandb.ai\/***\/huggingface\/runs\/***\n<\/code><\/pre>\n<p>This is a small snippet of <strong>finetuning<\/strong> code with Huggingface:<\/p>\n<pre><code class=\"lang-auto\">def finetune(args, file):\n    training_args = TrainingArguments(\n        output_dir=f'{model_name}-finetuned-{file}',\n        overwrite_output_dir=True,\n        evaluation_strategy='no',\n        num_train_epochs=args.epochs,\n        learning_rate=args.lr,\n        weight_decay=args.decay,\n        per_device_train_batch_size=args.batch_size,\n        per_device_eval_batch_size=args.batch_size,\n        fp16=True, # mixed-precision training to boost speed\n        save_strategy='no',\n        seed=args.seed,\n        dataloader_num_workers=4,\n    )\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=tokenized_dataset['train'],\n        eval_dataset=None,\n        data_collator=data_collator,\n    )\n    trainer.train()\n    trainer.save_model()\n<\/code><\/pre>",
        "Challenge_closed_time":1650552651672,
        "Challenge_comment_count":0,
        "Challenge_created_time":1650439111790,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/wandb-for-huggingface-trainer-saves-only-first-model\/2270",
        "Challenge_link_count":1,
        "Challenge_participation_count":3,
        "Challenge_readability":17.1,
        "Challenge_reading_time":17.33,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":31.5388561111,
        "Challenge_title":"Wandb for Huggingface Trainer saves only first model",
        "Challenge_topic":"Model Persistence",
        "Challenge_topic_macro":"Model Management",
        "Challenge_view_count":200.0,
        "Challenge_word_count":100,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><code>wandb.init(reinit=True)<\/code> and <code>run.finish()<\/code> helped me to log the models <strong>separately<\/strong> on wandb website.<\/p>\n<p>The working code looks like below:<\/p>\n<pre><code class=\"lang-auto\">\nfor file in os.listdir(args.data_dir):\n    finetune(args, file)\n\nimport wandb\ndef finetune(args, file):\n    run = wandb.init(reinit=True)\n    ...\n    run.finish()\n<\/code><\/pre>\n<p>Reference: <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/launch#how-do-i-launch-multiple-runs-from-one-script\" class=\"inline-onebox\">Launch Experiments with wandb.init - Documentation<\/a><\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":1.0,
        "Solution_readability":14.4,
        "Solution_reading_time":7.73,
        "Solution_score_count":null,
        "Solution_sentence_count":6.0,
        "Solution_word_count":44.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":17.8672141667,
        "Challenge_answer_count":5,
        "Challenge_body":"<p>Hi, I created a sweep from existing runs, but the panel Parallel Coordinates are empty, is this an intended behaviour or a bug?<\/p>\n<p>Here is what I did:<\/p>\n<ul>\n<li>populate projects with many runs (using ray\u2019s wandb_mixin)<\/li>\n<li>create a sweep following <a href=\"https:\/\/docs.wandb.ai\/guides\/sweeps\/existing-project#seed-a-new-sweep-with-existing-runs\">https:\/\/docs.wandb.ai\/guides\/sweeps\/existing-project#seed-a-new-sweep-with-existing-runs<\/a>\n<\/li>\n<li>the panel at \u201cSweeps &gt; [2]\u201d contains only 1 run, should contains all 42 runs.<\/li>\n<\/ul>\n<p>The sweep is at <a href=\"https:\/\/wandb.ai\/inc\/try_ray_tune\/sweeps\/smh3d0wg\" class=\"inline-onebox\">Weights &amp; Biases<\/a>, if any one is interested.<\/p>",
        "Challenge_closed_time":1640309961152,
        "Challenge_comment_count":0,
        "Challenge_created_time":1640245639181,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/sweep-from-existing-runs-not-showing-up-in-parallel-coordinates-is-this-intended-or-a-bug\/1601",
        "Challenge_link_count":2,
        "Challenge_participation_count":5,
        "Challenge_readability":13.8,
        "Challenge_reading_time":10.55,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":17.8672141667,
        "Challenge_title":"Sweep from existing runs not showing up in parallel coordinates, is this intended or a bug?",
        "Challenge_topic":"Hyperparameter Tuning",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":254.0,
        "Challenge_word_count":89,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi <a class=\"mention\" href=\"\/u\/inc\">@inc<\/a>,<\/p>\n<p>You should be able to see all 42 runs on your parallel coordinates plot by ungrouping the runs. Grouping runs groups them for charts on your workspace as well.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":5.5,
        "Solution_reading_time":3.08,
        "Solution_score_count":null,
        "Solution_sentence_count":3.0,
        "Solution_word_count":35.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":55.7380611111,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>Our local wandb instance was taking up a lot of space, so we tried to free up it by deleting old underperforming runs. This included around half of all the runs we had.<\/p>\n<p>However, deleting them didn\u2019t result in any freed-up space (mysql tables ended up taking the same size as pre-deletion). Is there any way to delete associated entries in the database?<\/p>\n<p>Thanks for the help!<\/p>",
        "Challenge_closed_time":1675731253108,
        "Challenge_comment_count":0,
        "Challenge_created_time":1675530596088,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/deleting-runs-in-local-wandb-instance-doesnt-delete-associated-entries-in-the-database\/3821",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":6.1,
        "Challenge_reading_time":5.93,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":55.7380611111,
        "Challenge_title":"Deleting runs in local wandb instance doesn't delete associated entries in the database",
        "Challenge_topic":"Dataset Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":158.0,
        "Challenge_word_count":79,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi <a class=\"mention\" href=\"\/u\/oshapio\">@oshapio<\/a>, happy to help with. Today W&amp;B does not reclaim space for deleted runs in the database. Here\u2019s a <a href=\"https:\/\/gist.github.com\/vanpelt\/0c13c556fa82cabdecb70d5ef90a4ea9\" rel=\"noopener nofollow ugc\">SQL procedure<\/a> that will delete the metrics and logs from the sql database for any runs that have been deleted in the UI. We\u2019re planning to integrate this logic into our application soon, but this can be used from a mysql shell to clear up data in the mean time.<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":1.0,
        "Solution_readability":8.0,
        "Solution_reading_time":6.67,
        "Solution_score_count":null,
        "Solution_sentence_count":5.0,
        "Solution_word_count":76.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":57.5133555556,
        "Challenge_answer_count":2,
        "Challenge_body":"I've configured a model for async-inference, and its working correctly - I can submit a file via `invoke_endpoint_async` and download the output from s3.\n\nI'm now trying to configure auto-scaling. I'm trying experimentation with different options, but basically I want to configure 0-1 instances, have an instance created when`invoke_endpoint_async` is called, and have the instance shutdown shortly afterwards (along the lines of batch inference)\n\nI'm struggling to get it to work - I'm experiencing similar issues to https:\/\/github.com\/boto\/boto3\/issues\/2839\n\nFirst I think there's an issue with the `console` - if I  `aws register-scalable-target ...` it works but the console doesn't like the zero for `min-capacity`\n\n![Enter image description here](\/media\/postImages\/original\/IMWZdtU68ZSXSSvr46-_1nhw)\n\nI think this is just a UI nit though, I don't understand how the policy works - I have\n\n```json\n{\n    \"TargetValue\": 1.0,\n    \"CustomizedMetricSpecification\": {\n        \"MetricName\": \"ApproximateBacklogSizePerInstance\",\n        \"Namespace\": \"AWS\/SageMaker\",\n        \"Dimensions\": [{\"Name\": \"EndpointName\", \"Value\": \"***-test-endpoint-2023-03-24-04-28-06-341\"}],\n        \"Statistic\": \"Average\"\n    },\n    \"ScaleInCooldown\": 60,\n    \"ScaleOutCooldown\": 60\n}\n```\n\nThe first point of confusion was the console shows a built-in and custom policy. I was initially using the name of the built-in policy (SageMakerEndpointInvocationScalingPolicy) but `put-scaling-policy` doesn't appear to edit it - it creates a new policy with the same name.\n\nWhen I monitor the scaling activity ()\n\n```console\naws application-autoscaling describe-scaling-activities \\\n    --service-namespace sagemaker\n```\n\nI can initially see \"Successfully set desired instance count to 0. Change successfully fulfilled by sagemaker.\" \n\nBut when I involve the endpoint with \n\n```python\nresponse = sm_runtime.invoke_endpoint_async(\n    EndpointName=endpoint_name, \n    InputLocation=\"***\/input\/data.json\",\n    ContentType='application\/jsonlines',\n    Accept='application\/jsonlines')\n\noutput_location = response['OutputLocation']\n```\n\nI would expect to see the instance count increase to 1, then back to zero within a space of a few minutes. I have occasionally got it to do something but not reliably. I think the main issue is I don't understand the metric and how it interacts with the target.\n\nI've seen charts but I cannot figure out how to plot the \"ApproximateBacklogSizePerInstance\"? And how does it interact with \"TargetValue\"? What is the actual trigger for a scale in\/out?",
        "Challenge_closed_time":1679845259536,
        "Challenge_comment_count":0,
        "Challenge_created_time":1679638211456,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUT4xru2SdTSqtoNyt1XV3VA\/configuring-auto-scaling-for-sagemaker-async-inference",
        "Challenge_link_count":1,
        "Challenge_participation_count":2,
        "Challenge_readability":14.4,
        "Challenge_reading_time":32.16,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":19,
        "Challenge_solved_time":57.5133555556,
        "Challenge_title":"Configuring auto-scaling for sagemaker async-inference",
        "Challenge_topic":"CloudWatch Monitoring",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":162.0,
        "Challenge_word_count":310,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"A target tracking scaling policy will create 2 CloudWatch alarms (one for high and one for low usage), which you'll be able to see in the CloudWatch alarms console.  The high usage policy needs to have 3 consecutive 60 second breaching datapoints to trigger a scale-out; and the low alarm needs 15 consecutive 60 second breaching datapoints to scale-in\n\nYou may instead want to use step scaling policies, where you are able to create and control the alarms as well as the policy settings\nhttps:\/\/docs.aws.amazon.com\/autoscaling\/application\/userguide\/application-auto-scaling-step-scaling-policies.html",
        "Solution_comment_count":0.0,
        "Solution_link_count":1.0,
        "Solution_readability":21.0,
        "Solution_reading_time":7.57,
        "Solution_score_count":1.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":85.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":8.1582452778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am running this tutorial: <a href=\"https:\/\/learn.microsoft.com\/de-de\/azure\/machine-learning\/tutorial-first-experiment-automated-ml\">https:\/\/learn.microsoft.com\/de-de\/azure\/machine-learning\/tutorial-first-experiment-automated-ml<\/a>    <\/p>\n<p>and struggle under &quot;next steps&quot; to deploy this model to a browser user interface of some kind (where I can manually type in the input values and press &quot;predict&quot; to get the output value).     <\/p>\n<p>Background: I would like to present this for a seminar &quot;AI without any code&quot; and hence I will not call this REST-API in any other place but try to stay in the (Azure) web ecosystem. Any chance to get such a webinterface (functionality)?<\/p>",
        "Challenge_closed_time":1603319937640,
        "Challenge_comment_count":0,
        "Challenge_created_time":1603290567957,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/134024\/unable-to-deploy-a-automl-as-a-webservice-without",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":14.9,
        "Challenge_reading_time":10.36,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":8.1582452778,
        "Challenge_title":"Unable to deploy a autoML as a webservice without using C#, Go, Java, or Python (just a browser)",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":103,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Thanks for reaching out. Currently, Azure AutoML does not support consuming deployed web services via UI. You can create a client for the service, or use python to consume the web service via Azure ML Notebooks. Sorry for the inconvenience.<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":6.0,
        "Solution_reading_time":3.06,
        "Solution_score_count":0.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":40.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":25.5791947222,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>FLAML looks like it performs better than Azure AutoML for hyperparameter tuning (based on the benchmarking in the Arxiv paper): <a href=\"https:\/\/arxiv.org\/pdf\/1911.04706v1.pdf\">https:\/\/arxiv.org\/pdf\/1911.04706v1.pdf<\/a>  <\/p>\n<p>Is it now being used or is there a plan to integrate it for the hyperparameter tuning in Azure Machine Learning Services? If so, when is that expected to become available?<\/p>",
        "Challenge_closed_time":1623391032688,
        "Challenge_comment_count":1,
        "Challenge_created_time":1623298947587,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/429832\/does-azure-automl-use-(or-plan-to-use)-flaml-for-t",
        "Challenge_link_count":1,
        "Challenge_participation_count":2,
        "Challenge_readability":9.7,
        "Challenge_reading_time":6.13,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":25.5791947222,
        "Challenge_title":"Does Azure AutoML use (or plan to use) FLAML for the hyperparameter tuning?",
        "Challenge_topic":"Hyperparameter Tuning",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":null,
        "Challenge_word_count":66,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=44a7ffc5-e97c-4dec-95a0-445a9835aab3\">@Rainer Hillermann  <\/a> Thanks, We are not using the FLAML for Azure AutoML for the hyperparameter tuning, You can raise a user voice request <a href=\"https:\/\/feedback.azure.com\/forums\/257792-machine-learning\">here<\/a> so the community can vote and provide their feedback, the product team then checks this feedback and implements the feature in future releases.    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":1.0,
        "Solution_readability":15.6,
        "Solution_reading_time":5.66,
        "Solution_score_count":0.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":51.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":5.2697822222,
        "Challenge_answer_count":3,
        "Challenge_body":"<p>Hello. Can anyone help with this error? Can not execute Azure ML activity from ADF.  <br \/>\nEverything was ok, no changes was done but suddenly(two-three days ago) I got this error.  <\/p>\n<pre><code>Request sent to Azure ML Service for operation 'submitMLPipelineRun' failed with http status code 'Forbidden'. Error message from Azure ML Service: '{ &quot;error&quot;: { &quot;code&quot;: &quot;UserError&quot;, &quot;severity&quot;: null, &quot;message&quot;: &quot;Identity does not have permissions for Microsoft.MachineLearningServices\/workspaces\/experiments\/runs\/submit\/action, Microsoft.MachineLearningServices\/workspaces\/endpoints\/pipelines\/read actions.&quot;, &quot;messageFormat&quot;: null, &quot;messageParameters&quot;: null, &quot;referenceCode&quot;: null, &quot;detailsUri&quot;: null, &quot;target&quot;: null, &quot;details&quot;: [], &quot;innerError&quot;: { &quot;code&quot;: &quot;ForbiddenError&quot;, &quot;innerError&quot;: null } '.\n<\/code><\/pre>",
        "Challenge_closed_time":1621971357963,
        "Challenge_comment_count":3,
        "Challenge_created_time":1621952386747,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/408869\/auth-problems-with-machine-learning-execute-pipeli",
        "Challenge_link_count":0,
        "Challenge_participation_count":6,
        "Challenge_readability":15.5,
        "Challenge_reading_time":13.78,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":5.2697822222,
        "Challenge_title":"Auth Problems with Machine Learning Execute Pipeline Activity.",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":92,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=5cdf2b77-a1ae-4f5a-a9c6-d2178ac8e6db\">@Denis Bruk  <\/a>     <\/p>\n<p>We have identified the issue and a hot fix is rolling out. It will be fixed in all regions by end of today. Sorry for the experience.    <\/p>\n<p>Regards,    <br \/>\nYutong<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":5.6,
        "Solution_reading_time":3.31,
        "Solution_score_count":1.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":36.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":2.6107855556,
        "Challenge_answer_count":3,
        "Challenge_body":"<p>I have the following error while running <a href=\"http:\/\/wandb.me\/prompts-quickstart\" rel=\"noopener nofollow ugc\">W&amp;B_Prompts_Quickstart notebook<\/a> <div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/8\/88da9eb34b5ef62baf4fcd367d69c08d5579c825.png\" data-download-href=\"\/uploads\/short-url\/jwFkh0P5adLx7fGnRM3YtxxLn4p.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/8\/88da9eb34b5ef62baf4fcd367d69c08d5579c825.png\" alt=\"image\" data-base62-sha1=\"jwFkh0P5adLx7fGnRM3YtxxLn4p\" width=\"690\" height=\"289\" data-dominant-color=\"F4F4F4\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">774\u00d7325 8.32 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Challenge_closed_time":1684232017936,
        "Challenge_comment_count":0,
        "Challenge_created_time":1684222619108,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/error-in-w-b-prompts-quickstart-notebook\/4411",
        "Challenge_link_count":3,
        "Challenge_participation_count":3,
        "Challenge_readability":28.9,
        "Challenge_reading_time":15.06,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":2.6107855556,
        "Challenge_title":"Error in W&B_Prompts_Quickstart notebook",
        "Challenge_topic":"Environment Installation",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":24.0,
        "Challenge_word_count":50,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi <a class=\"mention\" href=\"\/u\/tinsae\">@tinsae<\/a> thanks for reporting this issue. There\u2019s a breaking change with newer LangChain version, and the Growth team is working on a fix.<\/p>\n<p>You could run the Prompts Quickstart notebook for now by pinning a previous LangChain version which I just tested and seems to be working fine. Could you please change the installation section as follows:<\/p>\n<pre><code class=\"lang-auto\">!pip install \"wandb&gt;=0.15.2\" -qqq\n!pip install \"langchain==v0.0.158\" openai\n<\/code><\/pre>\n<p>Would this work for you?<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":6.3,
        "Solution_reading_time":7.04,
        "Solution_score_count":null,
        "Solution_sentence_count":7.0,
        "Solution_word_count":75.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":70.62626,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>Hello to all, <\/p>\n<p>I am working on a machine learning project, I have trained my model on azure auto ml studio, I would like to import it in onnx format, but it is not in the download options, so I want to modify the resulting code directly in azure auto ml, in the script.py I have modified the recording format of the model but I can't find how to execute this script because it tells me that the script.py is not found, <\/p>\n<p>Could you help me please ? <\/p>\n<p>thank you <\/p>\n<p>Lysa<\/p>",
        "Challenge_closed_time":1680506244446,
        "Challenge_comment_count":0,
        "Challenge_created_time":1680251989910,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1195000\/how-to-modify-the-template-script-on-azure-auto-ml",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":7.8,
        "Challenge_reading_time":6.57,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":70.62626,
        "Challenge_title":"how to modify the template script on azure auto ml?",
        "Challenge_topic":"Model Persistence",
        "Challenge_topic_macro":"Model Management",
        "Challenge_view_count":null,
        "Challenge_word_count":103,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=2d96c782-8477-4987-b5a4-5ea497b49eb9\">AMROUN Lysa<\/a> I believe you are looking to create a model wihich is ONNX compatible with AutoML as per your previous thread. In this case in the automl config if you setup <code>enable_onnx_compatible_models<\/code> to true in the automl config the model should be available for download. Something similar to what is provided as guidance in this <a href=\"https:\/\/github.com\/Azure\/azureml-examples\/blob\/main\/v1\/python-sdk\/tutorials\/automl-with-azureml\/classification-bank-marketing-all-features\/auto-ml-classification-bank-marketing-all-features.ipynb\">notebook<\/a>.<\/p>\n<p>I would recommend running through this notebook and then change your experiment settings in a similar way to retrieve the best onnx format model. <\/p>\n<pre><code>automl_settings = {\n    &quot;experiment_timeout_hours&quot;: 0.3,\n    &quot;enable_early_stopping&quot;: True,\n    &quot;iteration_timeout_minutes&quot;: 5,\n    &quot;max_concurrent_iterations&quot;: 4,\n    &quot;max_cores_per_iteration&quot;: -1,\n    # &quot;n_cross_validations&quot;: 2,\n    &quot;primary_metric&quot;: &quot;AUC_weighted&quot;,\n    &quot;featurization&quot;: &quot;auto&quot;,\n    &quot;verbosity&quot;: logging.INFO,\n    &quot;enable_code_generation&quot;: True,\n}\n\nautoml_config = AutoMLConfig(\n    task=&quot;classification&quot;,\n    debug_log=&quot;automl_errors.log&quot;,\n    compute_target=compute_target,\n    experiment_exit_score=0.9984,\n    blocked_models=[&quot;KNN&quot;, &quot;LinearSVM&quot;],\n    enable_onnx_compatible_models=True,\n    training_data=train_data,\n    label_column_name=label,\n    validation_data=validation_dataset,\n    **automl_settings,\n)\n\n<\/code><\/pre>\n<p>If this answers your query, do click <code>Accept Answer<\/code> and <code>Yes<\/code> for was this answer helpful. And, if you have any further query do let us know.<\/p>\n",
        "Solution_comment_count":2.0,
        "Solution_link_count":2.0,
        "Solution_readability":20.8,
        "Solution_reading_time":24.75,
        "Solution_score_count":1.0,
        "Solution_sentence_count":10.0,
        "Solution_word_count":146.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":11.9617827778,
        "Challenge_answer_count":5,
        "Challenge_body":"<p>Hello,<br>\nthat\u2019s my first topic in the community, so I hope I am posting that in the correct category <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/wink.png?v=12\" title=\":wink:\" class=\"emoji\" alt=\":wink:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>\n<p>I started exploring sweeps last week for a university project, and it is incredible! As we also got a new PyTorch version with support for the new apple silicon, I wanted to try that on my M1 Pro. As this is not as powerful as, for example, using GoogleColab for a fraction of the time, I wanted to ask if it is somehow possible to stop bad runs after a few epochs.<\/p>\n<p>As you can see in the report linked below, the run hopeful-sweep-2 does not look promising. It would be nice to cancel that run and start a new one instead.<\/p>\n<p>Thanks,<br>\nMarkus<\/p>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https:\/\/wandb.ai\/markuskarner\/AILS-Challenge%203%20Microscopic%20Images\/reports\/Sweep-on-some-image-data--VmlldzoyMTI2MDA3?accessToken=9h1rd20e7e6smpxm2cvtm3plk3rrauhkbb39w2rs46fv0htwvf0tx9r4ixjhkolk\">\n  <header class=\"source\">\n      <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/18b592222b97bc09df3743831bb4929dec23611c.png\" class=\"site-icon\" width=\"32\" height=\"32\">\n\n      <a href=\"https:\/\/wandb.ai\/markuskarner\/AILS-Challenge%203%20Microscopic%20Images\/reports\/Sweep-on-some-image-data--VmlldzoyMTI2MDA3?accessToken=9h1rd20e7e6smpxm2cvtm3plk3rrauhkbb39w2rs46fv0htwvf0tx9r4ixjhkolk\" target=\"_blank\" rel=\"noopener\">W&amp;B<\/a>\n  <\/header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/cf9e1ba973281ce03a0112b895e3f727d93c3e20_2_500x500.jpeg\" class=\"thumbnail onebox-avatar\" width=\"500\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/cf9e1ba973281ce03a0112b895e3f727d93c3e20_2_500x500.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/cf9e1ba973281ce03a0112b895e3f727d93c3e20_2_750x750.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/cf9e1ba973281ce03a0112b895e3f727d93c3e20.jpeg 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/cf9e1ba973281ce03a0112b895e3f727d93c3e20_2_10x10.png\">\n\n<h3><a href=\"https:\/\/wandb.ai\/markuskarner\/AILS-Challenge%203%20Microscopic%20Images\/reports\/Sweep-on-some-image-data--VmlldzoyMTI2MDA3?accessToken=9h1rd20e7e6smpxm2cvtm3plk3rrauhkbb39w2rs46fv0htwvf0tx9r4ixjhkolk\" target=\"_blank\" rel=\"noopener\">Weights &amp; Biases<\/a><\/h3>\n\n  <p>Weights &amp; Biases, developer tools for machine learning<\/p>\n\n\n  <\/article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n",
        "Challenge_closed_time":1654627313182,
        "Challenge_comment_count":0,
        "Challenge_created_time":1654584250764,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/how-to-early-stop-bad-runs-in-sweeps-to-save-time\/2563",
        "Challenge_link_count":10,
        "Challenge_participation_count":5,
        "Challenge_readability":17.8,
        "Challenge_reading_time":37.81,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":15,
        "Challenge_solved_time":11.9617827778,
        "Challenge_title":"How to early stop bad runs in sweeps to save time",
        "Challenge_topic":"Hyperparameter Tuning",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":633.0,
        "Challenge_word_count":193,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi <a class=\"mention\" href=\"\/u\/markuskarner\">@markuskarner<\/a> ,<\/p>\n<p>Thank you for writing in with your question. We do support early termination of sweeps, this reference <a href=\"https:\/\/docs.wandb.ai\/guides\/sweeps\/configuration#early_terminate\">doc<\/a> covers this. When the early stopping is triggered, the agent stops the current run and gets the next set of hyperparameters to try. Here is a <a href=\"https:\/\/github.com\/wandb\/examples\/blob\/master\/examples\/keras\/keras-cnn-fashion\/sweep-bayes-hyperband.yaml\" rel=\"noopener nofollow ugc\">link<\/a> to an example sweep configuration for reference. If after setting up your configuration and your require review \/ feedback. Please do write back in this thread and we can review your work more closely.<\/p>\n<p>Regards,<\/p>\n<p>Mohammad<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":2.0,
        "Solution_readability":11.9,
        "Solution_reading_time":10.34,
        "Solution_score_count":null,
        "Solution_sentence_count":9.0,
        "Solution_word_count":90.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":92.1785794445,
        "Challenge_answer_count":3,
        "Challenge_body":"<p>The doc <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/public-api-guide\">Import &amp; Export Data<\/a> gives the way how to export data from cloud. Can I use api to export data from local run files? I tried use path to local run directory instread of <code>&lt;entity&gt;\/&lt;project&gt;\/&lt;run_id&gt;<\/code>, but it doesn\u2019t work.<\/p>",
        "Challenge_closed_time":1661211326167,
        "Challenge_comment_count":0,
        "Challenge_created_time":1660879483281,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/how-to-export-data-from-local-run-files\/2959",
        "Challenge_link_count":1,
        "Challenge_participation_count":3,
        "Challenge_readability":8.3,
        "Challenge_reading_time":4.8,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":92.1785794445,
        "Challenge_title":"How to export data from local run files?",
        "Challenge_topic":"Dataset Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":220.0,
        "Challenge_word_count":49,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi <a class=\"mention\" href=\"\/u\/geyao\">@geyao<\/a> , this is currently not an available option. This functionality will be revisited in the future for consideration. Our API only works with runs logged to the cloud.<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":7.3,
        "Solution_reading_time":2.78,
        "Solution_score_count":null,
        "Solution_sentence_count":3.0,
        "Solution_word_count":31.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":8.3581641667,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I have created and published a Azure ML pipeline. I want to trigger the ML pipeline from Azure Data Factory.  <\/p>\n<p>In ADF, i have chosen Machine learning execute pipeline and created the linked service to azure machine learning and able to choose the published pipeline endpoint. However while running, i am getting the below error. I couldn't find much information how to resolve the error.   <\/p>\n<p>&quot;Convert Failed. The value type 'System.String', in key 'azureCloudType' is not expected type 'Microsoft.DataTransfer.Common.Models.AzureCloudType&quot;<\/p>",
        "Challenge_closed_time":1645111953528,
        "Challenge_comment_count":10,
        "Challenge_created_time":1645081864137,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/739240\/trigger-azure-ml-pipeline-from-azure-data-factory",
        "Challenge_link_count":0,
        "Challenge_participation_count":12,
        "Challenge_readability":8.3,
        "Challenge_reading_time":7.77,
        "Challenge_score_count":5.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":8.3581641667,
        "Challenge_title":"Trigger Azure ML Pipeline from Azure Data Factory",
        "Challenge_topic":"Pipeline Configuration",
        "Challenge_topic_macro":"Lifecycle Management",
        "Challenge_view_count":null,
        "Challenge_word_count":88,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi <a href=\"\/users\/na\/?userid=0cab9490-181d-4799-9dfb-834a723c261c\">@Vinoth Kumar K  <\/a> ,    <br \/>\nWelcome to Microsoft Q&amp;A platform and thankyou for posting your query.     <br \/>\nAs per the details you have shared in the query, it looks like a product bug. I have raised this issue with the internal Product team. Once I hear back from them, I will keep everyone posted on this. Thanks for your patience!<\/p>\n",
        "Solution_comment_count":14.0,
        "Solution_link_count":0.0,
        "Solution_readability":4.9,
        "Solution_reading_time":5.11,
        "Solution_score_count":3.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":62.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":1.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":6.5138261111,
        "Challenge_answer_count":1,
        "Challenge_body":"We deployed a LighGBM Regression model and endpoint using Sagemaker Jumpstart.\nWe have attempted to configure this endpoint as 'asynchronous' via the console.\nReceiving Error: ValidationException-Network Isolation is not supported when specifying an AsyncInferenceConfig.\n\nLooking at the model's network details the model has Enable Network Isolation set as 'True'.\nThis was default output setting set by JumpStart.\n\nHow can we diasble Network Isolation to in order to make this endpoint asynchronous?",
        "Challenge_closed_time":1653023938004,
        "Challenge_comment_count":0,
        "Challenge_created_time":1653000488230,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUZNbZZQHhSl2RYUtLU8zpSQ\/sagemaker-asynchronous-endpoint-configuration",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":11.0,
        "Challenge_reading_time":6.93,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":6.5138261111,
        "Challenge_title":"Sagemaker Asynchronous Endpoint Configuration",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":120.0,
        "Challenge_word_count":74,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"Vanilla SageMaker \"Models\" (as opposed to versioned ModelPackages) are immutable in the API with no \"UpdateModel\" action... But I think you should be able to create a new Model copying the settings of the current one.\n\nI'd suggest to:\n\n1. Use [DescribeModel](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/APIReference\/API_DescribeModel.html) (via [boto3.client(\"sagemaker\").describe_model()](https:\/\/boto3.amazonaws.com\/v1\/documentation\/api\/latest\/reference\/services\/sagemaker.html#SageMaker.Client.describe_model), assuming you're using Python) to fetch all the parameters of the existing JumpStart model such as the S3 artifact location and other settings\n2. Use [CreateModel](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/APIReference\/API_CreateModel.html) ([create_model()](https:\/\/boto3.amazonaws.com\/v1\/documentation\/api\/latest\/reference\/services\/sagemaker.html#SageMaker.Client.create_model)) to create a new model with same configuration but network isolation disabled\n3. Use your new model to try and deploy an async endpoint\n\nProbably you'd find the low-level boto3 SDK more intuitive for this task than the high-level `sagemaker` SDK's [Model class](https:\/\/sagemaker.readthedocs.io\/en\/stable\/api\/inference\/model.html) - because the latter does some magic that makes typical build\/train\/deploy workflows easier but can be less natural for hacking around with existing model definitions. For example, creating an SMSDK `Model` object doesn't actually create a Model in the SageMaker API, because deployment instance type affects choice of container image so that gets deferred until a `.deploy()` call or similar later.",
        "Solution_comment_count":1.0,
        "Solution_link_count":5.0,
        "Solution_readability":18.3,
        "Solution_reading_time":21.3,
        "Solution_score_count":1.0,
        "Solution_sentence_count":10.0,
        "Solution_word_count":174.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":84.44475,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I've been working on a project for some months on AML Studio. I recently wanted to utilize the VSCode integration, so I opened my workspace via the extension. I had my notebook open in the vscode version, and ran a couple of cells. I shut down the compute, and left it there. <\/p>\n<p>Now I've come back to this and my notebook has been wiped. Completely, every cell. This is the case on the AML Studio proper, and on the vscode integration version. There doesn't seem to be any kind of backup tool I can use. I've looked in the filestore and there's no snapshot, no nothing. I looked at the last experiment run log, but it has no code. <\/p>\n<p>Ofc when I work elsewhere, I use git. But there's no git integration in AML studio, and the terminal is so unusably slow that I haven't touched it in a long time. <\/p>\n<p>I don't know what to do. This is literally months of work, wiped out. No idea what happened or how to rectify. <\/p>\n<p>Any help much appreciated. <\/p>",
        "Challenge_closed_time":1679893628340,
        "Challenge_comment_count":0,
        "Challenge_created_time":1679589627240,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1192605\/connecting-to-vscode-wiped-my-notebook-completely",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":4.1,
        "Challenge_reading_time":12.22,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":17,
        "Challenge_solved_time":84.44475,
        "Challenge_title":"Connecting to VSCode wiped my notebook, completely",
        "Challenge_topic":"Environment Installation",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":null,
        "Challenge_word_count":188,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=83376df1-3fe7-4f8e-aeae-798027e4c31b\">@Daniel Goldwater  <\/a>If you have your notebook setup under your user directory the files that are created and saved should be available in your default storage account i.e the storage account connected to your workspace under the fileshares of your storage account. For example, here is a screen shot of my notebooks under my username from the studio.<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/2e273099-db36-47d4-a82d-d1c43365bab9?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>By default, all these files are mounted to your compute instance when you start the instance, and this enables you to connect to git through terminal and use an external source control mechanism. Since you have not added this the files that are added previously should be available here even if you have deleted your compute. The files should be visible under your user account even when no compute is available. <\/p>\n<p>The file share that is mounted is from your storage account as seen in the screen shot below:<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/a149337f-0fb2-4873-99d6-337cf73a946d?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>This file share should be visible under your storage account file share tab and you should be able to download the data from storage explorer till the point the data was last saved. Ideally, notebook data is saved every 30seconds or whenever they are saved or when a checkpoint is created. Here is a screen shot of my storage account from storage browser to help you check the same on your account.<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/b527ad6a-403d-4aaa-b75b-d27131005d16?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>I hope this is helpful!! Thanks!!<\/p>\n",
        "Solution_comment_count":3.0,
        "Solution_link_count":3.0,
        "Solution_readability":10.5,
        "Solution_reading_time":23.31,
        "Solution_score_count":1.0,
        "Solution_sentence_count":13.0,
        "Solution_word_count":242.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":11.1486111111,
        "Challenge_answer_count":1,
        "Challenge_body":"Hi,  \n  \nI am new to SageMaker and I am trying to deploy my model to an endpoint but am getting the following error:  \n  \n**Failure reason**  \nUnable to locate at least 2 availability zone(s) with the requested instance type ml.t2.medium that overlap with SageMaker subnets  \n  \nI have tried using different instance types but always the same error  \n  \nI was under the impression that SageMaker will create the required instances for me and I do not need to create the instances first? I am using the EU-WEST-1 zone and using the console to setup the endpoint",
        "Challenge_closed_time":1553556696000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1553516561000,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUySs_fgNpSE6wuY-6W7MwqQ\/unable-to-create-endpoint",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":11.6,
        "Challenge_reading_time":6.87,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":11.1486111111,
        "Challenge_title":"Unable to create endpoint",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":657.0,
        "Challenge_word_count":97,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"Hello,  \n  \nSagemaker engineer here. I looked at the VpcConfig of your model and found only one subnet configured.   \n  \nThe error message \"Unable to locate at least 2 availability zone(s) with the requested instance type XYZ that overlap with SageMaker subnets\" usually indicates misconfigured VPCs. Sagemaker imposes mandatory requirement for at least 2 availability zones in your VPC subnets even if you only request one instance, to account for the potential use of auto-scaling in the future.   \n  \nIn order to create the endpoint, the number of subnets in your model needs to be at least 2 in distinct availability zones, and ideally as close to the total number of availability zones as possible in the region.   \n  \nHope it helps,   \nWenzhao",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":11.0,
        "Solution_reading_time":8.89,
        "Solution_score_count":0.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":119.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":10.5649966667,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>There is very less components compared to classical mode, how can I use prebuilt components in custom mode? Is that possible? How should I get it? <\/p>\n<p>Can I get some help here? Much appreciated.<\/p>",
        "Challenge_closed_time":1680082887128,
        "Challenge_comment_count":2,
        "Challenge_created_time":1680044853140,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1194061\/can-i-use-prebuilt-component-in-custom-pipeline-mo",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":5.5,
        "Challenge_reading_time":3.19,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":10.5649966667,
        "Challenge_title":"can I use prebuilt component in custom pipeline mode?",
        "Challenge_topic":"Pipeline Configuration",
        "Challenge_topic_macro":"Lifecycle Management",
        "Challenge_view_count":null,
        "Challenge_word_count":43,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello @merten<\/p>\n<p>Thanks for reaching out to us, as you know Designer supports two type of components, classic prebuilt components and custom components. These two types of components <strong>are not compatible. So a quick answer for your question is you can not use it together.<\/strong><\/p>\n<p>Classic prebuilt components provides prebuilt components majorly for data processing and traditional machine learning tasks like regression and classification. This type of component continues to be supported but will not have any new components added.<\/p>\n<p>Custom components allow you to provide your own code as a component. It supports sharing across workspaces and seamless authoring across Studio, CLI, and SDK interfaces.<\/p>\n<p>I am sorry for all inconveniences. If you can share more details about your scenario, we are happy to discuss with product team.<\/p>\n<p>Regards,<\/p>\n<p>Yutong<\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Solution_comment_count":1.0,
        "Solution_link_count":0.0,
        "Solution_readability":9.0,
        "Solution_reading_time":12.56,
        "Solution_score_count":2.0,
        "Solution_sentence_count":10.0,
        "Solution_word_count":147.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":48.2963777778,
        "Challenge_answer_count":1,
        "Challenge_body":"Hi there,\n\nIs it possible to use R model training and serving in SageMaker ML Pipelines? Looked in examples [here](https:\/\/github.com\/aws\/amazon-sagemaker-examples\/tree\/master\/r_examples).  And it doesn't look that R is fully supported currently by ML Pipelines.  Any examples and success stories are very welcome. \n\nThanks.",
        "Challenge_closed_time":1643404063708,
        "Challenge_comment_count":0,
        "Challenge_created_time":1643230196748,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QU17aS4s7uSRqmiLuveuchBw\/using-r-model-in-sagemaker-ml-pipelines",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":10.6,
        "Challenge_reading_time":4.58,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":48.2963777778,
        "Challenge_title":"Using R model in SageMaker ML pipelines",
        "Challenge_topic":"Pipeline Configuration",
        "Challenge_topic_macro":"Lifecycle Management",
        "Challenge_view_count":234.0,
        "Challenge_word_count":48,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"In general it is possible to use the SageMaker python SDK and boto3  using the reticulate package in R, However do not have direct examples of SageMaker Pipelines using R.\n\nIt is possible to orchestrate the production pipeline using the R Containers for training and serving and setting up the DAG can be done with reticulate and SageMaker Python SDK and can be achieved using the AWS Step Functions. Please refer to the following example for reference.\n\n\nhttps:\/\/github.com\/aws-samples\/reinvent2020-aim404-productionize-r-using-amazon-sagemaker\nhttps:\/\/www.youtube.com\/watch?v=Zpp0nfvqDCA",
        "Solution_comment_count":0.0,
        "Solution_link_count":2.0,
        "Solution_readability":15.9,
        "Solution_reading_time":7.45,
        "Solution_score_count":1.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":79.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":1.6406444445,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi, I manage to run a azure ml trainning pipeline in adf. Then I can see that I can create\/update a batch inference pipeline from the Designer. But can I update the batch inference pipeline from adf?  <\/p>\n<p>thanks<\/p>",
        "Challenge_closed_time":1619629995207,
        "Challenge_comment_count":0,
        "Challenge_created_time":1619624088887,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/375702\/how-to-update-azure-ml-model-from-adf",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":5.4,
        "Challenge_reading_time":3.16,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":1.6406444445,
        "Challenge_title":"how to update azure ml model from adf?",
        "Challenge_topic":"Pipeline Configuration",
        "Challenge_topic_macro":"Lifecycle Management",
        "Challenge_view_count":null,
        "Challenge_word_count":46,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi <a href=\"\/users\/na\/?userid=1b597528-b52c-41fc-932a-baf4d96cb15b\">@javier  <\/a>,    <\/p>\n<p>Thanks for using Microsoft Q&amp;A !!    <\/p>\n<p>Unfortunately this is not supported using Azure Data Factory and you can only update the scoring web service using <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/data-factory\/update-machine-learning-models\">Azure Machine Learning Studio (classic) update resource activity<\/a> Can you please provide your scenario\/use case in details so that I can check internally.  I also suggest you to please post this as a feedback at <a href=\"https:\/\/feedback.azure.com\/forums\/270578-data-factory\">ADDF UserVoice<\/a>. This will allow the community to upvote and for the product team to include into their plans    <\/p>\n<p>----------    <\/p>\n<p><em>Please do not forget to &quot;Accept the answer&quot; wherever the information provided helps you to help others in the community.<\/em>    <\/p>\n<p>Thanks    <br \/>\nSaurabh    <\/p>\n",
        "Solution_comment_count":2.0,
        "Solution_link_count":2.0,
        "Solution_readability":12.0,
        "Solution_reading_time":12.12,
        "Solution_score_count":0.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":114.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":1.51785,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>Hola a todos, perdon quiza sea muy basica mi pregunta, no se como importar un excel como Dataset. Solo puedo importar CSV, etc. Muchas gracias<\/p>",
        "Challenge_closed_time":1614974319960,
        "Challenge_comment_count":0,
        "Challenge_created_time":1614968855700,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/301247\/excel-en-microsoft-azure",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":8.1,
        "Challenge_reading_time":2.16,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":1.51785,
        "Challenge_title":"Excel en Microsoft Azure",
        "Challenge_topic":"Dataset Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":null,
        "Challenge_word_count":28,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi, thanks for reaching out. Excel is not a <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.tabulardataset?view=azure-ml-py\">supported format<\/a> for Azure ML Tabular datasets. I recommend that you convert your excel file to .csv file (save as .csv) before importing to Azure ML. Hope this helps!    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":1.0,
        "Solution_readability":6.7,
        "Solution_reading_time":4.36,
        "Solution_score_count":0.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":40.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":1.103265,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have tried to read the dataset from datastore. Also tried to create the dataset also.<\/p>\n<p>The code for reading the dataset is below<\/p>\n<pre><code>from azureml.core import Workspace\nws = Workspace.from_config()\ndatastore = Datastore.get(ws, 'qdataset')\n<\/code><\/pre>\n<p>It works fine still now.<\/p>\n<pre><code>from azureml.core.dataset import Dataset\nsix_dataset = Dataset.get_by_name(workspace=ws, name='combined_classifier')\n<\/code><\/pre>\n<p>Also i have tried from <code>azureml.core import Dataset<\/code><\/p>\n<p>It shows the following error:<\/p>\n<p>2021-04-29 11:56:47.284077 | ActivityCompleted: Activity=_dataflow, HowEnded=Failure, Duration=0.0 [ms], Info = {'activity_id': 'xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx', 'activity_name': '_dataflow', 'activity_type': 'InternalCall', 'app_name': 'dataset', 'source': 'azureml.dataset', 'version': '1.27.0', 'dataprepVersion': '2.14.2', 'subscription': '', 'run_id': '', 'resource_group': '', 'workspace_name': '', 'experiment_id': '', 'location': '', 'completionStatus': 'Failure', 'durationMs': 962.01}, Exception=AttributeError; module 'azureml.dataprep' has no attribute 'api'<\/p>\n<hr \/>\n<p>AttributeError Traceback (most recent call last)  <br \/>\n&lt;ipython-input-34-ac7a8d35da4d&gt; in &lt;module&gt;  <br \/>\n1 from azureml.core.dataset import Dataset  <br \/>\n----&gt; 2 six_dataset = Dataset.get_by_name(workspace=ws, name='combined_classifier')<\/p>\n<p>~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data_loggerfactory.py in wrapper(*args, **kwargs)  <br \/>\n127 with _LoggerFactory.track_activity(logger, func.<strong>name<\/strong>, activity_type, custom_dimensions) as al:  <br \/>\n128 try:  <br \/>\n--&gt; 129 return func(*args, **kwargs)  <br \/>\n130 except Exception as e:  <br \/>\n131 if hasattr(al, 'activity_info') and hasattr(e, 'error_code'):<\/p>\n<p>~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data\\abstract_dataset.py in get_by_name(workspace, name, version)  <br \/>\n87 :rtype: typing.Union[azureml.data.TabularDataset, azureml.data.FileDataset]  <br \/>\n88 &quot;&quot;&quot;  <br \/>\n---&gt; 89 dataset = AbstractDataset._get_by_name(workspace, name, version)  <br \/>\n90 AbstractDataset._track_lineage([dataset])  <br \/>\n91 return dataset<\/p>\n<p>~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data\\abstract_dataset.py in _get_by_name(workspace, name, version)  <br \/>\n652 if not success:  <br \/>\n653 raise result  <br \/>\n--&gt; 654 dataset = _dto_to_dataset(workspace, result)  <br \/>\n655 warn_deprecated_blocks(dataset)  <br \/>\n656 return dataset<\/p>\n<p>~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data_dataset_rest_helper.py in _dto_to_dataset(workspace, dto)  <br \/>\n93 registration=registration)  <br \/>\n94 if dto.dataset_type == _DATASET_TYPE_FILE:  <br \/>\n---&gt; 95 return FileDataset._create(  <br \/>\n96 definition=dataflow_json,  <br \/>\n97 properties=dto.latest.properties,<\/p>\n<p>~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data_loggerfactory.py in wrapper(*args, **kwargs)  <br \/>\n127 with _LoggerFactory.track_activity(logger, func.<strong>name<\/strong>, activity_type, custom_dimensions) as al:  <br \/>\n128 try:  <br \/>\n--&gt; 129 return func(*args, **kwargs)  <br \/>\n130 except Exception as e:  <br \/>\n131 if hasattr(al, 'activity_info') and hasattr(e, 'error_code'):<\/p>\n<p>~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data\\abstract_dataset.py in _create(cls, definition, properties, registration, telemetry_info)  <br \/>\n555 from azureml.data._partition_format import parse_partition_format  <br \/>\n556  <br \/>\n--&gt; 557 steps = dataset._dataflow._get_steps()  <br \/>\n558 partition_keys = []  <br \/>\n559 for step in steps:<\/p>\n<p>~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data_loggerfactory.py in wrapper(*args, **kwargs)  <br \/>\n127 with _LoggerFactory.track_activity(logger, func.<strong>name<\/strong>, activity_type, custom_dimensions) as al:  <br \/>\n128 try:  <br \/>\n--&gt; 129 return func(*args, **kwargs)  <br \/>\n130 except Exception as e:  <br \/>\n131 if hasattr(al, 'activity_info') and hasattr(e, 'error_code'):<\/p>\n<p>~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data\\abstract_dataset.py in _dataflow(self)  <br \/>\n215 raise UserErrorException('Dataset definition is missing. Please check how the dataset is created.')  <br \/>\n216 if self._registration and self._registration.workspace:  <br \/>\n--&gt; 217 dataprep().api._datastore_helper._set_auth_type(self._registration.workspace)  <br \/>\n218 if not isinstance(self._definition, dataprep().Dataflow):  <br \/>\n219 try:<\/p>\n<p>AttributeError: module 'azureml.dataprep' has no attribute 'api'<\/p>\n<p>Please give a solution to solve this<\/p>",
        "Challenge_closed_time":1619702571567,
        "Challenge_comment_count":0,
        "Challenge_created_time":1619698599813,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/377203\/error-while-accessing-the-dataset-from-a-datastore",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":13.8,
        "Challenge_reading_time":62.14,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":45,
        "Challenge_solved_time":1.103265,
        "Challenge_title":"Error while accessing the dataset from a datastore",
        "Challenge_topic":"Dataset Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":null,
        "Challenge_word_count":393,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>It now worked..   <br \/>\nWe need to install azure-ml-api-sdk using this command  <\/p>\n<p>pip install azure-ml-api-sdk  <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":5.4,
        "Solution_reading_time":1.54,
        "Solution_score_count":1.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":17.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":42.8398436111,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>What's the best way to preserve Azure ML workspace so that it can be restored at a later point? I was hoping to find some automatic way to take a snapshot of artifacts &amp; code and dump it into Azure storage, but haven't been able to find anything relevant in the online documentation. <\/p>",
        "Challenge_closed_time":1669596362440,
        "Challenge_comment_count":0,
        "Challenge_created_time":1669442139003,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1105130\/whats-the-best-way-to-preserve-azure-ml-workspace",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":9.8,
        "Challenge_reading_time":4.5,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":42.8398436111,
        "Challenge_title":"What's the best way to preserve Azure ML workspace so that it can be restored",
        "Challenge_topic":"Artifact Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":null,
        "Challenge_word_count":68,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>@VaraPrasad-1740 Thanks for the question. I would recommend you can have a git repository that backs your project.  For some details about this approach you can check <a href=\"https:\/\/santiagof.medium.com\/structure-your-machine-learning-project-source-code-like-a-pro-44815cac8652\">https:\/\/santiagof.medium.com\/structure-your-machine-learning-project-source-code-like-a-pro-44815cac8652<\/a><\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":1.0,
        "Solution_readability":17.7,
        "Solution_reading_time":5.41,
        "Solution_score_count":0.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":29.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":5.2104491667,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>According to <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/manage-azureml-service\/authentication-in-azureml\/authentication-in-azureml.ipynb\">this<\/a> notebook  <\/p>\n<blockquote>\n<p>Interactive Authentication  <br \/>\nInteractive authentication is the default mode when using Azure ML SDK.  <\/p>\n<p>When you connect to your workspace using workspace.from_config, you will get an interactive login dialog.  <\/p>\n<\/blockquote>\n<p>So, i ran <code>ws=Workspace.from_config()<\/code>  <br \/>\n and got the following error  <\/p>\n<pre><code>--------------------------------------------------------------------------\nUserErrorException                        Traceback (most recent call last)\n&lt;ipython-input-13-e469111f639c&gt; in &lt;module&gt;\n----&gt; 1 ws = Workspace.from_config()\n\n~\\Documents\\Softwares\\Anaconda3\\lib\\site-packages\\azureml\\core\\workspace.py in from_config(path, auth, _logger, _file_name)\n    276\n    277             if not found_path:\n--&gt; 278                 raise UserErrorException(\n    279                     'We could not find config.json in: {} or in its parent directories. '\n    280                     'Please provide the full path to the config file or ensure that '\n\nUserErrorException: UserErrorException:\n        Message: We could not find config.json in: C:\\Users\\qwewqd or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.\n        InnerException None\n        ErrorResponse\n{\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;message&quot;: &quot;We could not find config.json in: C:\\\\Users\\\\qwewqd or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.&quot;\n    }\n}\n<\/code><\/pre>",
        "Challenge_closed_time":1606116372007,
        "Challenge_comment_count":0,
        "Challenge_created_time":1606097614390,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/171577\/isnt-interactive-login-default-for-workspace-from",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":12.1,
        "Challenge_reading_time":23.15,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":17,
        "Challenge_solved_time":5.2104491667,
        "Challenge_title":"Isn't Interactive login, default for Workspace.from_config()?",
        "Challenge_topic":"Compute Management",
        "Challenge_topic_macro":"Computation Management",
        "Challenge_view_count":null,
        "Challenge_word_count":180,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=2c0f2a38-b74b-451f-85f1-6cc6fb702227\">@kalyan reddy  <\/a> A configuration file(JSON) is created when you run the configuration.ipynb file or notebook which can then be used to get the configuration using     <br \/>\n    ws = Workspace.from_config()  <\/p>\n<p>You can run this <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/setup-environment\/configuration.ipynb\">notebook<\/a> and create a new workspace if not available or use the existing workspace. For example, Set the workspace details as environment varibles.    <\/p>\n<pre><code>import os  \n  \nsubscription_id = os.getenv(&quot;SUBSCRIPTION_ID&quot;, default=&quot;&lt;my-subscription-id&gt;&quot;)  \nresource_group = os.getenv(&quot;RESOURCE_GROUP&quot;, default=&quot;&lt;my-resource-group&gt;&quot;)  \nworkspace_name = os.getenv(&quot;WORKSPACE_NAME&quot;, default=&quot;&lt;my-workspace-name&gt;&quot;)  \nworkspace_region = os.getenv(&quot;WORKSPACE_REGION&quot;, default=&quot;eastus2&quot;)  \n<\/code><\/pre>\n<p>Write then to config.json file    <\/p>\n<pre><code>from azureml.core import Workspace  \n  \ntry:  \n    ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)  \n    # write the details of the workspace to a configuration file to the notebook library  \n    ws.write_config()  \n    print(&quot;Workspace configuration succeeded. Skip the workspace creation steps below&quot;)  \nexcept:  \n    print(&quot;Workspace not accessible. Change your parameters or create a new workspace below&quot;)  \n<\/code><\/pre>\n<p>You can now access this config from other notebooks and need not specify the subscription or workspace details in every notebook file.    <\/p>\n",
        "Solution_comment_count":1.0,
        "Solution_link_count":1.0,
        "Solution_readability":13.2,
        "Solution_reading_time":21.98,
        "Solution_score_count":0.0,
        "Solution_sentence_count":15.0,
        "Solution_word_count":154.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":2.0391952778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi:  <\/p>\n<p>I wonder when will the classic Machine Learning Studio retire?  <\/p>\n<p>Also in order to save my data and file, any preparation or migration should be done to avoid any loss?  <\/p>\n<p>Thanks<\/p>",
        "Challenge_closed_time":1648423257900,
        "Challenge_comment_count":0,
        "Challenge_created_time":1648415916797,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/789066\/machine-learning-studio",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":6.9,
        "Challenge_reading_time":2.86,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":2.0391952778,
        "Challenge_title":"machine learning Studio",
        "Challenge_topic":"Dataset Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":null,
        "Challenge_word_count":37,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=3f0f48d2-f878-404d-bae7-0861ffefc027\">@dontbelazy  <\/a>     <\/p>\n<p>Thanks for reaching out to us, I think you are mentioning Azure Machine Learning Studio(classic). Machine Learning Studio (classic) will retire on 31 August 2024.     <\/p>\n<p>From now through 31 August 2024, you can continue to use the existing Machine Learning Studio (classic). Beginning 1 December 2021, you will not be able to create new Machine Learning Studio (classic) resources.    <\/p>\n<p>Required action to avoid loss:     <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-overview\">Follow these steps<\/a> to transition using Azure Machine Learning before 31 August 2024. Pricing may be subject to change, please view <a href=\"https:\/\/azure.microsoft.com\/en-us\/pricing\/details\/machine-learning\/#:%7E:text=Consumed%20Azure%20resources%20%28e.g.%20compute%2C%20storage%29%20%28No%20Azure,%24-%20%2B%20per%20vCPU%20hour%20Edition%3A%20Basic%20Enterprise\">pricing<\/a> here.    <\/p>\n<p>Hope this helps!    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p><em>-Please kindly accept the answer if you feel helpful, thanks!<\/em>    <\/p>\n",
        "Solution_comment_count":2.0,
        "Solution_link_count":2.0,
        "Solution_readability":10.2,
        "Solution_reading_time":15.01,
        "Solution_score_count":0.0,
        "Solution_sentence_count":10.0,
        "Solution_word_count":117.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":0.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":0.6476944444,
        "Challenge_answer_count":1,
        "Challenge_body":"Hi, \nI'm trying to run the SageMaker XGBoost Parquet example [linked here](https:\/\/sagemaker-examples.readthedocs.io\/en\/latest\/introduction_to_amazon_algorithms\/xgboost_abalone\/xgboost_parquet_input_training.html). I followed the exact same steps but using my own data. I uploaded my data, converted it to a pandas df. The train_df shape is (15279798, 32) while the test_df shape is (150848, 32). I then converted it to parquet files and uploaded it to an S3 bucket - per example instructions. \n\nMy error is as follows:\n\n```\nFailure reason\nAlgorithmError: framework error: Traceback (most recent call last): File \"\/miniconda3\/lib\/python3.7\/site-packages\/sagemaker_xgboost_container\/data_utils.py\", line 422, in _get_parquet_dmatrix_pipe_mode data = np.vstack(examples) File \"<__array_function__ internals>\", line 6, in vstack File \"\/miniconda3\/lib\/python3.7\/site-packages\/numpy\/core\/shape_base.py\", line 283, in vstack return _nx.concatenate(arrs, 0) File \"<__array_function__ internals>\", line 6, in concatenate ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 32 and the array at index 1 has size 9 During handling of the above exception, another exception occurred: Traceback (most recent call last): File \"\/miniconda3\/lib\/python3.7\/site-packages\/sagemaker_containers\/_trainer.py\", line 84, in train entrypoint() File \"\/miniconda3\/lib\/python3.7\/site-packages\/sagemaker_xgboost_container\/training.py\", line 94, in main train(framework.tr\n\n```\nBut I'm confused because the train and test are the same shape and I added no extra code. My code below:\n\n\n```\n# requires PyArrow installed\ntrain.to_parquet(\"Xgb_train.parquet\")\ntest.to_parquet(\"Xgb_test.parquet\")\n\n%%time\nsagemaker.Session().upload_data(\n    \"Xgb_train.parquet\", bucket=bucket, key_prefix=prefix + \"\/\" + \"Ptrain\"\n)\n\nsagemaker.Session().upload_data(\n    \"Xgb_test.parquet\", bucket=bucket, key_prefix=prefix + \"\/\" + \"Ptest\"\n)\n\ncontainer = sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.2-2\")\n\n%%time\nimport time\nfrom time import gmtime, strftime\n\njob_name = \"xgboost-parquet-example-training-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\nprint(\"Training job\", job_name)\n\n# Ensure that the training and validation data folders generated above are reflected in the \"InputDataConfig\" parameter below.\n\ncreate_training_params = {\n    \"AlgorithmSpecification\": {\"TrainingImage\": container, \"TrainingInputMode\": \"Pipe\"},\n    \"RoleArn\": role,\n    \"OutputDataConfig\": {\"S3OutputPath\": bucket_path + \"\/\" + prefix + \"\/single-xgboost\"},\n    \"ResourceConfig\": {\"InstanceCount\": 1, \"InstanceType\": \"ml.m5.2xlarge\", \"VolumeSizeInGB\": 20},\n    \"TrainingJobName\": job_name,\n    \"HyperParameters\": {\n        \"max_depth\": \"5\",\n        \"eta\": \"0.2\",\n        \"gamma\": \"4\",\n        \"min_child_weight\": \"6\",\n        \"subsample\": \"0.7\",\n        \"objective\": \"reg:linear\",\n        \"num_round\": \"10\",\n        \"verbosity\": \"2\",\n    },\n    \"StoppingCondition\": {\"MaxRuntimeInSeconds\": 3600},\n    \"InputDataConfig\": [\n        {\n            \"ChannelName\": \"train\",\n            \"DataSource\": {\n                \"S3DataSource\": {\n                    \"S3DataType\": \"S3Prefix\",\n                    \"S3Uri\": bucket_path + \"\/\" + prefix + \"\/Ptrain\",\n                    \"S3DataDistributionType\": \"FullyReplicated\",\n                }\n            },\n            \"ContentType\": \"application\/x-parquet\",\n            \"CompressionType\": \"None\",\n        },\n        {\n            \"ChannelName\": \"validation\",\n            \"DataSource\": {\n                \"S3DataSource\": {\n                    \"S3DataType\": \"S3Prefix\",\n                    \"S3Uri\": bucket_path + \"\/\" + prefix + \"\/Ptest\",\n                    \"S3DataDistributionType\": \"FullyReplicated\",\n                }\n            },\n            \"ContentType\": \"application\/x-parquet\",\n            \"CompressionType\": \"None\",\n        },\n    ],\n}\n\n\nclient = boto3.client(\"sagemaker\", region_name=region)\nclient.create_training_job(**create_training_params)\nprint(client)\nstatus = client.describe_training_job(TrainingJobName=job_name)[\"TrainingJobStatus\"]\nprint(status)\nwhile status != \"Completed\" and status != \"Failed\":\n    time.sleep(60)\n    status = client.describe_training_job(TrainingJobName=job_name)[\"TrainingJobStatus\"]\n    print(status)\n```",
        "Challenge_closed_time":1648149098276,
        "Challenge_comment_count":0,
        "Challenge_created_time":1648146766576,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUqqbIbodsT42efRxxi1FLzw\/sagemaker-xgboost-parquet-example-code-fails-and-errors-out-bug",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":16.2,
        "Challenge_reading_time":51.41,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":29,
        "Challenge_solved_time":0.6476944444,
        "Challenge_title":"SageMaker XGBoost Parquet Example Code Fails and Errors out. Bug?",
        "Challenge_topic":"Dataset Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":298.0,
        "Challenge_word_count":346,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"I just changed my bucket name and file names. It worked now.",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":-0.4,
        "Solution_reading_time":0.72,
        "Solution_score_count":0.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":12.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":26.9961138889,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>When ticking any boxes inside Azure Machine Learning Studio - or in the YAML templates by specifying it's enabled by a true or false value- you can't specify which Application Insights instance to use - it will use the default one connected to that Azure Machine Learning Studio only.    <\/p>\n<p>For using something like Azure Machine Learning Studio as a solutions provider, and that might have multiple customers models within it, the ability to be able to specify a Applications Insights connection string to an instance OUTSIDE of the default in-built one would be a great addition to functionality.     <\/p>\n<p>With the current set up we are forced to have a different AML Studio \/ Storage Account \/ ACR \/ App Insights \/ Key vault for each customer to allow Applications Insights data collection to make any sense per customer.    <\/p>\n<p>Thanks    <\/p>",
        "Challenge_closed_time":1671640414100,
        "Challenge_comment_count":0,
        "Challenge_created_time":1671543228090,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1135890\/integration-with-application-insights-should-allow",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":15.1,
        "Challenge_reading_time":11.62,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":26.9961138889,
        "Challenge_title":"Integration with Application Insights should allow you to specify a choice of which instance to use",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":152,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=0ec06fb6-513e-4f5c-9aff-281bc5e44e22\">@Neil McAlister  <\/a> Thanks for the feedback. I have forwarded to the product team to support near future to specify a Applications Insights connection string to an instance OUTSIDE of the default in-built.<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":11.1,
        "Solution_reading_time":3.6,
        "Solution_score_count":1.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":34.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":31.5833333333,
        "Challenge_answer_count":2,
        "Challenge_body":"Under the Vertex AI - a dataset failed to create due to a constraint applied to the organization. It does not allow for the deletion of the dataset, I attempted using python (Delete a dataset \u00a0|\u00a0 Vertex AI \u00a0|\u00a0 Google Cloud) and the response was -\u00a0\"...is in failure state and cannot be deleted. It will be deleted automatically after a few days.\"\u00a0\u00a0but it didn't delete. There is not a gcloud command to correct. Short of a support request..how can the dataset be removed as I foresee this occuring as others attempt experiments. I have addressed the issue with the constraint.",
        "Challenge_closed_time":1677681300000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1677567600000,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Deleting-a-failed-dataset\/td-p\/527077\/jump-to\/first-unread-message",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":4.9,
        "Challenge_reading_time":7.23,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":10,
        "Challenge_solved_time":31.5833333333,
        "Challenge_title":"Deleting a failed dataset",
        "Challenge_topic":"Dataset Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":86.0,
        "Challenge_word_count":101,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"I tried running the same\u00a0code you used and I was able to delete a dataset that was successfully created. I suspect in your case, the failure state of the dataset is the problem. Also, there is indeed no gcloud command to manually delete it. I would still suggest you file a\u00a0ticket here so\u00a0Google Cloud's engineering team can further investigate.\n\nView solution in original post",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":6.2,
        "Solution_reading_time":4.55,
        "Solution_score_count":1.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":67.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_isAwsEmployee":0.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":17.3883747222,
        "Challenge_answer_count":1,
        "Challenge_body":"Does Data Capture feature used for model monitor and analytics work with the multi model endpoint (one container).. we ran into an error.  See error \" An error occurred (ValidationException) when calling the CreateEndPointConfig operation: Data Capture Feature is not supported with MultiModel mode\"\nTheoretically, it should work because it is calling the DataCaptureConfig:\n\nfrom sagemaker.model_monitor import DataCaptureConfig\n\nendpoint_name = 'your-pred-model-monitor-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\nprint(\"EndpointName={}\".format(endpoint_name))\n\ndata_capture_config=DataCaptureConfig(\n                        enable_capture = True,\n                        sampling_percentage=100,\n                        destination_s3_uri=s3_capture_upload_path)",
        "Challenge_closed_time":1649857157628,
        "Challenge_comment_count":0,
        "Challenge_created_time":1649794559479,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUlAvpGSsISyqu0MyebgRJDA\/sagemaker-multi-model-endpoint-and-inference-data-capture-feature",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":20.0,
        "Challenge_reading_time":9.95,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":17.3883747222,
        "Challenge_title":"SageMaker Multi Model EndPoint and Inference Data Capture feature",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":403.0,
        "Challenge_word_count":75,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"SageMaker multi-model endpoints do not have support for SageMaker Model monitor as of writing this answer. So the error is pointing to exactly that. \n\nHowever, if you are looking to implement data drift using sagemaker model monitor then you can do that my mimicking data capture config functionality by capturing inference input and prediction output and storing it in the format supported by Model Monitor. And then setup a customer monitoring container using the instructions listed [https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/model-monitor-byoc-containers.html]()",
        "Solution_comment_count":1.0,
        "Solution_link_count":1.0,
        "Solution_readability":16.7,
        "Solution_reading_time":7.26,
        "Solution_score_count":0.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":77.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":75.2,
        "Challenge_answer_count":4,
        "Challenge_body":"Hi, I'm using Google Colab +pro and unfortunately I`m getting several Ram calls and have not been able to move forward or train some models\n\nWhich is the next tool that I should get in order to be able to run the Google Colab models without the Ram calls?\n\nShould I get a Google Compute Engine and try to connect the google colab files to it?\n\nShould I up load the model to vertex AI?\n\nWhat characteristics should I need to take into consideration before I select any of the different tools?",
        "Challenge_closed_time":1652442120000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1652171400000,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Next-Step-from-Google-Colab-Pro\/td-p\/421797\/jump-to\/first-unread-message",
        "Challenge_link_count":0,
        "Challenge_participation_count":4,
        "Challenge_readability":8.5,
        "Challenge_reading_time":6.23,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":75.2,
        "Challenge_title":"Next Step from Google Colab +Pro",
        "Challenge_topic":"GPU Acceleration",
        "Challenge_topic_macro":"Computation Management",
        "Challenge_view_count":373.0,
        "Challenge_word_count":97,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"Hello,\n\nI have provided a few links to help you through configuring your Google Colab Model.\n\nThis link below contains all Google Colab related questions on Stack Overflow:\n\nhttps:\/\/stackoverflow.com\/search?q=colab&s=7e8e7982-76a3-4765-8bad-63af4a9415fb\n\nThe following link explains how to double the Ram in Google Colab:\n\nhttps:\/\/towardsdatascience.com\/double-your-google-colab-ram-in-10-seconds-using-these-10-characters-...\n\nThe last link is a HOW-TO guide:\n\nhttps:\/\/neptune.ai\/blog\/how-to-use-google-colab-for-deep-learning-complete-tutorial#:~:text=Open%20a....\n\nRegards\n\nView solution in original post",
        "Solution_comment_count":null,
        "Solution_link_count":3.0,
        "Solution_readability":14.7,
        "Solution_reading_time":7.98,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":56.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":29.0333333333,
        "Challenge_answer_count":1,
        "Challenge_body":"Hi, could anyone share the python code on how to get\u00a0 natural language API to use version 2 classify text\u00a0 categories?\n\nI can get it working well with the default (version 1) categories but can't figure out where to adapt the standard code (as here: https:\/\/cloud.google.com\/natural-language\/docs\/samples\/language-classify-text-tutorial-classify?hl=e...)\u00a0 to\u00a0 use model version 2.\n\nMany thanks",
        "Challenge_closed_time":1667406420000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1667301900000,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Version-2-model-in-natural-language-API\/td-p\/484641\/jump-to\/first-unread-message",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":11.4,
        "Challenge_reading_time":5.42,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":29.0333333333,
        "Challenge_title":"Version 2 model in natural language API",
        "Challenge_topic":"Model Registry",
        "Challenge_topic_macro":"Model Management",
        "Challenge_view_count":173.0,
        "Challenge_word_count":59,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"From the Classifying Content guide, you can include classification_model_options\u00a0within the request\u00a0dictionary argument to the classify_text()\u00a0function. In these options, you can define the model and version to use for content categories.\n\n\/\/ ...\ncontent_categories_version = (\n        language_v1.ClassificationModelOptions.V2Model.ContentCategoriesVersion.V2) \/\/ Assigning the v2 model type\n    response = client.classify_text(request = {\n        \"document\": document,\n        \"classification_model_options\": {\n            \"v2_model\": {\n                \"content_categories_version\": content_categories_version\n            }\n        }\n    })\n\/\/ ...\n\n\nYou can also check ClassificationModelOptions\u00a0reference for available options.\n\nView solution in original post",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":20.3,
        "Solution_reading_time":8.84,
        "Solution_score_count":0.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":62.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_isAwsEmployee":0.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":6.0041666667,
        "Challenge_answer_count":1,
        "Challenge_body":"Hi, I see in this page of documentation https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/notebook-interface-endpoint.html that:\n>\"*You can connect to your notebook instance from your VPC through an interface endpoint in your Virtual Private Cloud (VPC) instead of connecting over the internet. When you use a VPC interface endpoint, communication between your VPC and the notebook instance is conducted entirely and securely within the AWS network.*\"\n\nHow would customer interact on their laptop with the UI of a notebook instance sitting in a VPC?",
        "Challenge_closed_time":1541516577000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1541494962000,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QU5z-7bQ9zQOi_NrVlHy_5oA\/which-connection-method-when-using-sagemaker-notebook-through-vpc-interface-endpoint",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":12.5,
        "Challenge_reading_time":8.01,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":6.0041666667,
        "Challenge_title":"Which connection method when using SageMaker Notebook through VPC Interface Endpoint?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":459.0,
        "Challenge_word_count":88,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":1.0,
        "Poster_isModerator":0.0,
        "Solution_body":"If you are trying to access from within VPC, you'll have a direct connection. Otherwise, you'll need a configuration in place, such as Amazon VPN or AWS Direct Connect, to connect to your notebooks. Here is the blog post where we tried to explain how to set up AWS PrivateLink for Amazon SageMaker notebooks: https:\/\/aws.amazon.com\/blogs\/machine-learning\/direct-access-to-amazon-sagemaker-notebooks-from-amazon-vpc-by-using-an-aws-privatelink-endpoint\/",
        "Solution_comment_count":0.0,
        "Solution_link_count":1.0,
        "Solution_readability":14.0,
        "Solution_reading_time":5.85,
        "Solution_score_count":0.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":55.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":1.2025963889,
        "Challenge_answer_count":1,
        "Challenge_body":"Hi all,\n\nI have raised a ticket for multiple issues we've been having with SageMaker lately, the ticket was created more than 36 hours  ago, and I have not had any response, in fact the ticket hasn't even been assigned yet.\n\nThe case ID is 10300240931.\n\nI thought AWS guarantee a response under 12 hours for \"system impaired\" issues, does anyone know what I can do to accelerate this?\n\nthank you!\nRuoy",
        "Challenge_closed_time":1656585271688,
        "Challenge_comment_count":0,
        "Challenge_created_time":1656580942341,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUFgnjt9J3T0iXhE0axG10vQ\/how-long-does-it-take-for-aws-tech-support-team-to-respond-to-a-system-impaired-issue",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":9.5,
        "Challenge_reading_time":5.85,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":1.2025963889,
        "Challenge_title":"How long does it take for AWS tech support team to respond to a \"system impaired\" issue?",
        "Challenge_topic":"Quota Management",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":125.0,
        "Challenge_word_count":88,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"Hi Ruoy!\nMy advice here is to scale this issue via your account team, they will have the mechanisms to scale this concern.\nIf you are on basic or developer support, you could look into upgrading to business support for a day and open a live chat with support!\nHope this helps",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":6.5,
        "Solution_reading_time":3.29,
        "Solution_score_count":0.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":52.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":1.1746825,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hello community,     <br \/>\nI'm facing a problem, my ACR in my resource group was deleted and I couldn't create any instance. I created again and now I can create instances but i'm having problems to run the dataset profile. It's failing to pull the image docker.    <\/p>\n<p>This is the output    <\/p>\n<pre><code>AzureMLCompute job failed.  \nFailedPullingImage: Unable to pull docker image  \n\timageName: 19acd0cdf57549bcace363c924cf045b.azurecr.io\/azureml\/azureml_e7e3dfebc6129c75c60868383ebc992f  \n\terror: Run docker command to pull public image failed with error: Error response from daemon: Get https:\/\/19acd0cdf57549bcace363c924cf045b.azurecr.io\/v2\/azureml\/azureml_e7e3dfebc6129c75c60868383ebc992f\/manifests\/latest: unauthorized: authentication required, visit https:\/\/aka.ms\/acr\/authorization for more information.  \n.  \n\tReason: Error response from daemon: Get https:\/\/19acd0cdf57549bcace363c924cf045b.azurecr.io\/v2\/azureml\/azureml_e7e3dfebc6129c75c60868383ebc992f\/manifests\/latest: unauthorized: authentication required, visit https:\/\/aka.ms\/acr\/authorization for more information.  \n  \n\tInfo: Failed to setup runtime for job execution: Job environment preparation failed on 10.0.0.5 with err exit status 1.  \n<\/code><\/pre>\n<p>The ML Studio has the following permissions on the ACR permissions    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/132698-unbenannt.png?platform=QnA\" alt=\"132698-unbenannt.png\" \/>    <\/p>\n<p>The docker image appears in the repositories of the ACR    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/132781-unbenannt2.png?platform=QnA\" alt=\"132781-unbenannt2.png\" \/>    <\/p>\n<p>Any hint how can i solve this problem?    <\/p>\n<p>Thanks in advance    <\/p>",
        "Challenge_closed_time":1631803071767,
        "Challenge_comment_count":0,
        "Challenge_created_time":1631798842910,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/555024\/not-able-to-pull-docker-image-from-container-regis",
        "Challenge_link_count":6,
        "Challenge_participation_count":1,
        "Challenge_readability":13.0,
        "Challenge_reading_time":23.03,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":18,
        "Challenge_solved_time":1.1746825,
        "Challenge_title":"Not able to pull docker image from Container Registry",
        "Challenge_topic":"Docker Configuration",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":null,
        "Challenge_word_count":175,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=5565f700-af3b-41a9-b47f-9b8a6276d8fd\">@Moresi, Marco  <\/a> Does this container registry have the admin account enabled? A requirement while creating a workspace with an <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-workspace-cli?tabs=bringexistingresources1%2Cvnetpleconfigurationsv1cli#create-a-workspace\">existing container registry<\/a> is to have the admin account enabled.     <\/p>\n<p>If you have already enabled it then a <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-workspace-cli?tabs=bringexistingresources1%2Cvnetpleconfigurationsv1cli#sync-keys-for-dependent-resources\">re-sync of keys<\/a> might be required for your workspace.    <\/p>\n<pre><code>az ml workspace sync-keys -w &lt;workspace-name&gt; -g &lt;resource-group-name&gt;  \n<\/code><\/pre>\n<p>Deleting the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-workspace?tabs=python#deleting-the-azure-container-registry\">default container registry<\/a> used by the workspace can also cause the workspace to break.    <\/p>\n",
        "Solution_comment_count":1.0,
        "Solution_link_count":3.0,
        "Solution_readability":18.3,
        "Solution_reading_time":14.97,
        "Solution_score_count":3.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":79.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":388.0879419444,
        "Challenge_answer_count":6,
        "Challenge_body":"<p>Thanks for your good product.<\/p>\n<p>It would be good to add an archive feature for runs.<\/p>\n<p>In a project, we may try many ideas. But most of them result in no outcomes. It would be good to archive those runs to keep the workspace clean.<\/p>\n<p>It is not a good option to delete them, because we may check them in future for some cases, such as ablation study.<\/p>",
        "Challenge_closed_time":1676670702464,
        "Challenge_comment_count":0,
        "Challenge_created_time":1675273585873,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/archive-runs\/3793",
        "Challenge_link_count":0,
        "Challenge_participation_count":6,
        "Challenge_readability":3.1,
        "Challenge_reading_time":4.64,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":388.0879419444,
        "Challenge_title":"Archive runs",
        "Challenge_topic":"Compute Management",
        "Challenge_topic_macro":"Computation Management",
        "Challenge_view_count":315.0,
        "Challenge_word_count":69,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>I believe currently wandb does support multiple selection. But not in the workspace view. In the table view I can select and tag multiple runs at once.<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":5.6,
        "Solution_reading_time":1.94,
        "Solution_score_count":null,
        "Solution_sentence_count":3.0,
        "Solution_word_count":27.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":11.6161658333,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I found that I can register the model using Mlflow, but I don't know how to register it in ONNX format.    <br \/>\nI found out that the model is registered using Mlflow.    <br \/>\nBut I don't know how to convert AutoML models to ONNX format and register them with Mlflow.    <\/p>\n<p>from azure.ai.ml import MLClient    <br \/>\nfrom azure.identity import DefaultAzureCredential    <br \/>\nfrom azureml.train.automl import AutoMLConfig    <br \/>\nfrom azureml.core import Workspace, Dataset    <br \/>\nfrom azureml.core.experiment import Experiment    <br \/>\nfrom azureml.core.model import Model    <br \/>\nfrom azureml.core.authentication import ServicePrincipalAuthentication    <br \/>\nfrom azureml.automl.runtime.onnx_convert import OnnxConverter    <br \/>\nfrom random import random    <br \/>\nfrom mlflow.tracking import MlflowClient    <br \/>\nimport mlflow    <br \/>\nimport mlflow.onnx    <br \/>\nimport os    <br \/>\nimport azureml.mlflow    <\/p>\n<p>auth = ServicePrincipalAuthentication(    <br \/>\n    tenant_id=&quot;&quot;,  <br \/>\n    service_principal_id=&quot;&quot;,  <br \/>\n    service_principal_password=&quot;&quot;)  <\/p>\n<p>subscription_id = ''    <br \/>\nresource_group = ''    <br \/>\nworkspace_name = ''    <\/p>\n<p>ml_client = MLClient(credential=auth,    <br \/>\n                    subscription_id=subscription_id,  <br \/>\n                    resource_group_name=resource_group)  <\/p>\n<p>azure_mlflow_uri = ml_client.workspaces.get(workspace_name).mlflow_tracking_uri    <br \/>\nmlflow.set_tracking_uri(azure_mlflow_uri)    <\/p>\n<p>ws = Workspace(subscription_id, resource_group, workspace_name, auth=auth)    <\/p>\n<p>train_data = Dataset.get_by_name(ws, name='iris')    <\/p>\n<p>label = &quot;class&quot;    <\/p>\n<p>automl_settings = {    <br \/>\n    &quot;primary_metric&quot;: 'AUC_weighted',  <br \/>\n    &quot;n_cross_validations&quot;: 2  <br \/>\n    }  <\/p>\n<p>automl_classifier = AutoMLConfig(    <br \/>\n    task='classification',  <br \/>\n    blocked_models=['XGBoostClassifier'],  <br \/>\n    enable_onnx_compatible_models=True,  <br \/>\n    experiment_timeout_minutes=30,  <br \/>\n    training_data=train_data,  <br \/>\n    label_column_name=label,  <br \/>\n    **automl_settings  <br \/>\n    )  <\/p>\n<p>experiment_name = 'experimetn_with_mlflow'    <br \/>\nmlflow.set_experiment(experiment_name)    <br \/>\nexperiment = Experiment(ws, experiment_name)    <\/p>\n<p>with mlflow.start_run() as mlflow_run:    <br \/>\n    mlflow.log_metric(&quot;iris_metric&quot;, random())  <\/p>\n<pre><code>mlflow_run = experiment.submit(automl_classifier, show_output=True)  \n\ndescription = 'iris_Description'  \n\nmodel = mlflow_run.register_model(description=description,  \n                               model_name='iris_Model')  \n\nbest_run, onnx_mdl = mlflow_run.get_output(return_onnx_model=True)  \nonnx_fl_path = &quot;.\/best_model.onnx&quot;  \nOnnxConverter.save_onnx_model(onnx_mdl, onnx_fl_path)  \n\nmodel = Model.register(workspace=ws,  \n                    description=description,  \n                    model_name='iris_onnx_model',  \n                    model_path=onnx_fl_path)  \n\nclient = MlflowClient()  \n\nfinished_mlflow_run = MlflowClient().get_run(mlflow_run.run_id)  \n\nmetrics = finished_mlflow_run.data.metrics  \ntags = finished_mlflow_run.data.tags  \nparams = finished_mlflow_run.data.params  \n\nmodel_path  = &quot;best_model&quot;  \nmodel_uri = 'runs:\/{}\/{}'.format(mlflow_run.run_id, model_path)  \nmlflow.register_model(model_uri, 'iris_onnx_mlflow_model')\n<\/code><\/pre>",
        "Challenge_closed_time":1664453127300,
        "Challenge_comment_count":0,
        "Challenge_created_time":1664411309103,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1027830\/i-want-to-register-the-model-learned-by-automl-in",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":17.0,
        "Challenge_reading_time":43.06,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":33,
        "Challenge_solved_time":11.6161658333,
        "Challenge_title":"I want to register the model learned by AutoML in Azure Machine learning in ONNX format and call it in Azure Synapse Analitics.",
        "Challenge_topic":"Model Persistence",
        "Challenge_topic_macro":"Model Management",
        "Challenge_view_count":null,
        "Challenge_word_count":258,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=cef675e6-0d34-4e7e-873a-aec3478f614f\">@\u4fdd\u53f2 \u7d30\u898b  <\/a> Thanks for the question.  Can you please share document\/sample that you are trying. In order to save trained model download (and score) as the ONNX model you have here a few code <a href=\"https:\/\/github.com\/CESARDELATORRE\/azureml-workshop-2019\/blob\/master\/2-training-inference\/2.3-automl-training\/local-compute\/binayclassification-employee-attrition-autoaml-local-compute.ipynb\">examples<\/a>.    <br \/>\nMLflow model registry will enable Synapse to run ONNX models is in preview.    <\/p>\n<p>Here is the ONNX prediction section in the sample <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/automated-machine-learning\/classification-bank-marketing-all-features\/auto-ml-classification-bank-marketing-all-features.ipynb\">notebook<\/a>.    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":2.0,
        "Solution_readability":21.3,
        "Solution_reading_time":11.52,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":65.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":19.6539680556,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi, I am new to Azure ML, and I have been trying to replicate the same structure presented in the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-train-models-with-aml\">MNIST tutorial<\/a>, but I don't understand how to adapt it to my case.     <\/p>\n<p>I am running a python file from the experiment, but I don't understand how I can access data that is currently in a folder in the cloud file system from the script running in the experiment.     <br \/>\nI have found many examples about accessing one single .csv file, but my data is made of many images.    <\/p>\n<p>From my understanding I should first load the folder to a datastore, then use Dataset.File.upload_directory to create a dataset containing my folder, and here is how I tried to do it:     <\/p>\n<pre><code># Create dataset from data directory  \ndatastore = Datastore.get(ws, 'workspaceblobstore')  \ndataset = Dataset.File.upload_directory(path_data, target, pattern=None, overwrite=False, show_progress=True)  \n  \nfile_dataset = dataset.register(workspace=ws, name='reduced_classification_dataset',  \n                                                 description='reduced_classification_dataset',  \n                                                 create_new_version=True)  \n<\/code><\/pre>\n<p>But then I don't understand if and how I can access this data like a normal file system from my python script, or I need further steps to be able to do that.     <\/p>",
        "Challenge_closed_time":1614833313088,
        "Challenge_comment_count":0,
        "Challenge_created_time":1614762558803,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/296661\/azureml-notebooks-how-to-access-data-from-an-exper",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":11.1,
        "Challenge_reading_time":17.42,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":11,
        "Challenge_solved_time":19.6539680556,
        "Challenge_title":"AzureML Notebooks: how to access data from an experiment",
        "Challenge_topic":"Dataset Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":null,
        "Challenge_word_count":187,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=bf39b622-b8af-42d8-809c-296225cdbb39\">@Matzof  <\/a> Thanks for the question. Please follow the below code for writing.    <\/p>\n<pre><code>   datastore = ## get your defined in Workspace as Datastore   \ndatastore.upload(src_dir='.\/files\/to\/copy\/...',  \n                 target_path='target\/directory',  \n                 overwrite=True)  \n<\/code><\/pre>\n<p>Datastore.upload only support blob and fileshare. For adlsgen2 upload, you can try our new dataset upload API:    <\/p>\n<pre><code>from azureml.core import Dataset, Datastore  \ndatastore = Datastore.get(workspace, 'mayadlsgen2')  \nDataset.File.upload_directory(src_dir='.\/data', target=(datastore,'data'))  \n<\/code><\/pre>\n<p>Pandas is integrated with fsspec which provides Pythonic implementation for filesystems including s3, gcs, and Azure. You can check the source for Azure here: <a href=\"https:\/\/github.com\/dask\/adlfs\">dask\/adlfs: fsspec-compatible Azure Datake and Azure Blob Storage access (github.com)<\/a>. With this you can use normal filesystem operations like ls, glob, info, etc.     <\/p>\n<p>You can find an example (for reading data) here: <a href=\"https:\/\/github.com\/Azure\/azureml-examples\/blob\/main\/tutorials\/using-dask\/1.intro-to-dask.ipynb\">azureml-examples\/1.intro-to-dask.ipynb at main \u00b7 Azure\/azureml-examples (github.com)<\/a>     <\/p>\n<p>Writing is essentially the same as reading, you need to switch the protocol to abfs (or az), slightly modify how you're accessing the data, and provide credentials unless your blob has public write access.     <\/p>\n<p>You can use the Azure ML Datastore to retrieve credentials like this (taken from example):     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/74112-2.png?platform=QnA\" alt=\"74112-2.png\" \/>    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":3.0,
        "Solution_readability":13.5,
        "Solution_reading_time":22.4,
        "Solution_score_count":0.0,
        "Solution_sentence_count":16.0,
        "Solution_word_count":177.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":154.0425902778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I'm trying to create a workspace in azure machine learning and receiving this error after 2 browser Windows open and I click log in.<\/p>\n<blockquote>\n<p>library(azuremlsdk)  <br \/>\nnew_ws &lt;- create_workspace(name = 'muffin',<\/p>\n<\/blockquote>\n<ul>\n<li>   subscription_id = 'XXXXXXXXXXXX',<\/li>\n<li>   resource_group = 'white',<\/li>\n<li>   location = 'eastus2',<\/li>\n<li>   create_resource_group = T)  <br \/>\n    Note, we have launched a browser for you to login. For old experience with device code, use &quot;az login --use-device-code&quot;  <br \/>\n    You have logged in. Now let us find all the subscriptions to which you have access...  <br \/>\n    Note, we have launched a browser for you to login. For old experience with device code, use &quot;az login --use-device-code&quot;  <br \/>\n    You have logged in. Now let us find all the subscriptions to which you have access...  <br \/>\n    Error in py_call_impl(callable, dots$args, dots$keywords) :  <br \/>\n    AuthenticationException: AuthenticationException:  <br \/>\n    Message: Could not retrieve user token. Please run 'az login'  <br \/>\n    InnerException It is required that you pass in a value for the &quot;algorithms&quot; argument when calling decode().  <br \/>\n    ErrorResponse  <br \/>\n    {  <br \/>\n    &quot;error&quot;: {  <br \/>\n    &quot;code&quot;: &quot;UserError&quot;,  <br \/>\n    &quot;inner_error&quot;: {  <br \/>\n    &quot;code&quot;: &quot;Authentication&quot;  <br \/>\n    },  <br \/>\n    &quot;message&quot;: &quot;Could not retrieve user token. Please run 'az login'&quot;  <br \/>\n    }  <br \/>\n    }<\/li>\n<\/ul>\n<p>how do I get passed this error?<\/p>",
        "Challenge_closed_time":1621844855832,
        "Challenge_comment_count":3,
        "Challenge_created_time":1621290302507,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/398420\/azuremlsdk-for-r-error-could-not-retrieve-user-tok",
        "Challenge_link_count":0,
        "Challenge_participation_count":4,
        "Challenge_readability":9.5,
        "Challenge_reading_time":20.26,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":13,
        "Challenge_solved_time":154.0425902778,
        "Challenge_title":"azuremlsdk for R error Could not retrieve user token. Please run 'az login'",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":207,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>You have to use this command to make it install the correct version of miniconda reticulate::py_install(&quot;PyJWT==1.7.1&quot;). If you don't do that it seems to install the wrong version. I also had to manually delete the r-miniconda folder in \\appdata\\local\\r-miniconda which got installed previously to get it to install the correct version. It's pretty outrageous they leave that out of the tutorial when it ain't going to work otherwise.<\/p>\n<p>If you try to do the accident.R tutorial for azuremlsdk-r next make sure you add the line<\/p>\n<p>interactive_auth &lt;- interactive_login_authentication(tenant_id=&quot;&lt;tenant id&gt;&quot;)<\/p>\n<p>to your code otherwise you'll get a permissions error and it won't work.<\/p>\n<p>Then to the create_workspace or get_workspace function you have to add auth = interactive_auth after a comma.<\/p>\n<p>It should look like this<\/p>\n<p>new_ws &lt;- get_workspace(name = &quot;&lt;workspace name&gt;&quot;,  <br \/>\nsubscription_id = &quot;&lt;subscription id&gt;&quot;,  <br \/>\nresource_group = &quot;&lt;resource name&gt;&quot;,  <br \/>\nauth = interactive_auth)<\/p>\n<p>To find the tenant ID I had to download the azure CLI and run the command az login. Not sure if there is another way to find a tenant ID or not.<\/p>\n<p>To leave out critical steps from a tutorial is gross incompetence on the part of Azure. How anyone who isn't a comp sci phd uses this service is a mystery to me.<\/p>\n",
        "Solution_comment_count":2.0,
        "Solution_link_count":0.0,
        "Solution_readability":10.5,
        "Solution_reading_time":17.95,
        "Solution_score_count":0.0,
        "Solution_sentence_count":11.0,
        "Solution_word_count":203.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":0.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":91.5201041667,
        "Challenge_answer_count":1,
        "Challenge_body":"I try to download image(.jpg, .png.) from S3 to Endpoint(made by Sagemaker) with s3url(s3:\/\/~~)\n\nBecause At the endpoint made by sagemaker, To send s3url is faster than to send image.\n\nI can download image at sagemaker notebook, from s3 to sagemaker local.\n\nbut I can't download image from s3 to sagemaker endpoint.\n\nThat local download code can not work.",
        "Challenge_closed_time":1661216110040,
        "Challenge_comment_count":0,
        "Challenge_created_time":1660886637665,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QULB64ZDsXSPuHBjqAWik3hQ\/solved-download-image-from-s3-to-endpoint-made-by-sagemaker-with-s3url-s3",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":6.5,
        "Challenge_reading_time":5.38,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":91.5201041667,
        "Challenge_title":"[Solved]download image from S3 to Endpoint(made by Sagemaker) with s3url(s3:\/\/~~)",
        "Challenge_topic":"Dataset Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":281.0,
        "Challenge_word_count":68,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"I solve this! I try to download image at endpoint.\nbut endpoint can not connect outside network except Lambda.\n1. I make request with s3url\n2. Download image from s3 to lambda\n3. Transmit image from lambda to endpoint",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":3.5,
        "Solution_reading_time":2.63,
        "Solution_score_count":0.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":39.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":6.1596858333,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am trying to log my model metrics and hyperparam space in the run metrics.     <br \/>\nI tried to also reduce the variable lengths throughout but still get consistently the following error:     <br \/>\ni find in the documentation that we can only have 15 columns for every row in the run metric.    <br \/>\n <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/resource-limits-quotas-capacity\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/resource-limits-quotas-capacity<\/a> . But is there a way to increase this capacity? Thanks    <\/p>\n<p> Is there a way to increase this capacity?     <\/p>\n<pre><code>RunHistory finalization failed: ServiceException:  \n Code: 400  \n Message: (UserError) A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.  \n Details:  \n A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.  \n A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.  \n A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.  \n A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.  \n A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.  \n A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.  \n A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.  \n A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.  \n A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.  \n A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.  \n A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.  \n A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.  \n A field of the entity is over the size limit. FieldName=MetricV2Value.Data\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.  \n A field of the entity is over the size limit. FieldName=MetricV2Value.Data\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.  \n A field of the entity is over the size limit. FieldName=MetricV2Value.Data\/Count, Limit=15, Size=16. See  \n  \n<\/code><\/pre>",
        "Challenge_closed_time":1643903062356,
        "Challenge_comment_count":0,
        "Challenge_created_time":1643880887487,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/721282\/runhistory-finalization-failed-serviceexception-co",
        "Challenge_link_count":16,
        "Challenge_participation_count":1,
        "Challenge_readability":12.1,
        "Challenge_reading_time":47.89,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":53,
        "Challenge_solved_time":6.1596858333,
        "Challenge_title":"RunHistory finalization failed: ServiceException: \tCode: 400",
        "Challenge_topic":"Metric Logging",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":null,
        "Challenge_word_count":390,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=2dc066be-691a-47bd-9f7a-67e426d994d9\">@Antara Das  <\/a> Some of the limits are soft limits which can be increased for a subscription or a workspace. Usually these limits can be increased by using a support case with appropriate usage scenario mentioned in the details of the case. Once the case is submitted it is reviewed by the service team and the limits are increased if it is possible to do so.     <\/p>\n<p>Please create a support case from Azure portal and use the following settings from the drop downs and mention the summary detail as &quot;Increase limit of columns per metric row&quot;    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/171018-image.png?platform=QnA\" alt=\"171018-image.png\" \/>    <\/p>\n<p>If you do not have a valid support subscription we could help you with a one time free support case that could help you to create one for this scenario.     <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":3.0,
        "Solution_readability":12.3,
        "Solution_reading_time":16.45,
        "Solution_score_count":0.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":160.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":258.9256763889,
        "Challenge_answer_count":4,
        "Challenge_body":"<p>We need to set a dataset folder in S3 as an artifact.  The folder has many sub-directories (only one layer though).<br>\nWhen I use the a <code>add_reference()<\/code> command it only stores the directory names of the top-level.<br>\nOf course, I could loop across it, but I\u2019m wondering if there is a command option to make the operation recursive?<\/p>\n<pre><code class=\"lang-auto\">run  = wandb.init(project=WB_PROJECT)\nart = wandb.Artifact(WB_ENTITY, type=WB_DATASET)\nart.add_reference(s3_full, max_objects=WB_MAX_OBJECTS_TO_UPLOAD)\nrun.log_artifact(art)\nwandb.finish()\n<\/code><\/pre>\n<p>EDIT 1: I conclude that the all files are not being added because the <code>Num Files<\/code> in the Artifact Overview shows only <code>5<\/code>.  If I click on the directories, it seems I can see the files, but I assume they are not actually there because of the <code>5<\/code> being reported for the number of files.<\/p>",
        "Challenge_closed_time":1663759922548,
        "Challenge_comment_count":0,
        "Challenge_created_time":1662827790113,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/add-reference-with-nested-folders\/3092",
        "Challenge_link_count":0,
        "Challenge_participation_count":4,
        "Challenge_readability":10.1,
        "Challenge_reading_time":11.96,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":11,
        "Challenge_solved_time":258.9256763889,
        "Challenge_title":"Add_reference() with nested folders",
        "Challenge_topic":"Artifact Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":443.0,
        "Challenge_word_count":127,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi Kevin,<\/p>\n<p>Thanks for the detailed explanation! I see your issue, I will create a request for this feature, thanks for reporting it! May I help you with any other issue?<\/p>\n<p>Best,<br>\nLuis<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":4.2,
        "Solution_reading_time":2.53,
        "Solution_score_count":null,
        "Solution_sentence_count":4.0,
        "Solution_word_count":33.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":66.2517636111,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi,    <\/p>\n<p>Is there a way to specify the disk storage type for Compute instances?     <br \/>\nBoth the Azure portal and ARM templates do not have an option to define the disk storage type, which defaults to the P10 disks (Premium SSD).     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/148883-azureml-compute.png?platform=QnA\" alt=\"148883-azureml-compute.png\" \/>Thanks    <\/p>",
        "Challenge_closed_time":1636952401092,
        "Challenge_comment_count":1,
        "Challenge_created_time":1636713894743,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/625035\/azure-machine-learning-specify-disk-storage-type",
        "Challenge_link_count":1,
        "Challenge_participation_count":2,
        "Challenge_readability":8.7,
        "Challenge_reading_time":5.74,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":66.2517636111,
        "Challenge_title":"Azure Machine Learning - Specify disk storage type",
        "Challenge_topic":"Compute Management",
        "Challenge_topic_macro":"Computation Management",
        "Challenge_view_count":null,
        "Challenge_word_count":54,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=41b4924d-c8f5-4ca4-9844-0c0af46eb5d5\">@Simon Magrin  <\/a>  Thanks, Currently There's no way to change the disk storage type for CIs or compute clusters. We have added this to our product backlog item to support in the near future.    <\/p>\n<p>------------------------------    <\/p>\n<ul>\n<li> Please don't forget to click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/25904\/accepted-answers.html\">how<\/a>    <\/li>\n<li> Want a reminder to come back and check responses? Here is how to subscribe to a <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/67444\/email-notifications.html\">notification<\/a>    <\/li>\n<li> If you are interested in joining the VM program and help shape the future of Q&amp;A: Here is how you can be part of <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/543261\/index.html\">Q&amp;A Volunteer Moderators<\/a>    <\/li>\n<\/ul>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":5.0,
        "Solution_readability":13.8,
        "Solution_reading_time":17.16,
        "Solution_score_count":0.0,
        "Solution_sentence_count":11.0,
        "Solution_word_count":130.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":162.2120102778,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I've created an Azure ML Endpoint Pipeline with a single 'Execute Python Script'.  From the script, I am looking for a way to access the input 'ParameterAssignments' that I POST to the endpoint to trigger the pipeline.  I expected to see them somewhere in Run.get_context(), but I haven't had any luck.  I simply need a way to POST arbitrary values that my Python scripts can access.  Thank you!<\/p>",
        "Challenge_closed_time":1603069686240,
        "Challenge_comment_count":2,
        "Challenge_created_time":1602485723003,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/123204\/how-do-i-access-an-input-parameter-in-azure-machin",
        "Challenge_link_count":0,
        "Challenge_participation_count":4,
        "Challenge_readability":7.3,
        "Challenge_reading_time":5.76,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":162.2120102778,
        "Challenge_title":"How do I access an input parameter in Azure Machine Learning endpoints?",
        "Challenge_topic":"Pipeline Configuration",
        "Challenge_topic_macro":"Lifecycle Management",
        "Challenge_view_count":null,
        "Challenge_word_count":79,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>I just confirmed with our engineer that you cannot set up a pipeline parameter and use it without tying it with any of the module parameter. So the workaround is  - make the pipeline parameter as one of the inputs (i.e. dataset) to &quot;Execute Python Script&quot; module and set it as pipeline parameter. Then you can change it every time when calling the pipeline.<\/p>\n",
        "Solution_comment_count":3.0,
        "Solution_link_count":0.0,
        "Solution_readability":8.3,
        "Solution_reading_time":4.55,
        "Solution_score_count":1.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":63.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":504.6333333333,
        "Challenge_answer_count":20,
        "Challenge_body":"My request to join the Bard preview was recently accepted and I've begun evaluating it. So far it looks amazing and I'm anxious to begin working with it as a developer. I asked Bard if there was an API that I can start to use and it responded with the information below. I cannot seem to find the API waitlist sign-up page in the Bard website, nor can I enable the API from my Cloud Account (https:\/\/cloud.google.com\/),\n\nIs there any additional action I should take to request to join the wait list for access to the Bard API? Perhaps I am too anxious and just need to wait.\u00a0\ud83d\ude00\n\nThanks in advance for any advice.\n\nResponse from Bard itself:\n\nYes, there is an API for Google Bard. It is currently in beta and is available to a limited number of users. You can sign up for the waitlist on the Google AI website.\n\nThe Google Bard API allows you to access the power of Google's large language models to generate text, translate languages, write different kinds of creative content, and answer your questions in an informative way.\n\nYou can use the Google Bard API to create a variety of applications, including:\n\nChatbots that can hold conversations with users\nGenerators that can create content for websites and social media\nTranslators that can translate text from one language to another\nAnswerers that can answer questions about a variety of topics\n\nTo use the Google Bard API, you will need to create a Google Cloud Platform project and enable the Google Bard API. You will then need to create a service account and download the JSON key file.\n\nOnce you have done this, you can start using the Google Bard API in your applications. You can find more information about the Google Bard API on the Google AI website.",
        "Challenge_closed_time":1681909860000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1680093180000,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Bard-API\/td-p\/538517\/jump-to\/first-unread-message",
        "Challenge_link_count":1,
        "Challenge_participation_count":20,
        "Challenge_readability":8.4,
        "Challenge_reading_time":20.76,
        "Challenge_score_count":11.0,
        "Challenge_sentence_count":16,
        "Challenge_solved_time":504.6333333333,
        "Challenge_title":"Google Bard API",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":0.0,
        "Challenge_word_count":307,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"Hi\u00a0@DeanS - thank you for your patience! We are excited to hear that you are ready to begin working with Google LLM API's as a developer.\u00a0\ud83d\ude0e Check out the information below:\u00a0\n\nEnterprise customers can sign up to Vertex AI LLM Trusted Testers program here:\u00a0https:\/\/cloud.google.com\/ai\/earlyaccess\/join?hl=en\nIndependent developers can sign up the MakerSuite and PalmAPI waitlist here:\u00a0https:\/\/makersuite.google.com\/waitlist.\n\u00a0\n\ud83d\ude80Register for the Google Cloud Innovators Program to stay informed on the latest updates and roadmap sessions.\n\u00a0\nI hope this helps. Thanks!\n\nView solution in original post",
        "Solution_comment_count":null,
        "Solution_link_count":2.0,
        "Solution_readability":8.0,
        "Solution_reading_time":7.4,
        "Solution_score_count":10.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":84.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":11.0410916667,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am encountering an issue of error 0138, while training the data, at the end it shows memory has been exhausted exception  <\/p>\n<p>I do not think my data has exceed the limit of azure ML studio, is there any way to solve this?<\/p>",
        "Challenge_closed_time":1653942581987,
        "Challenge_comment_count":0,
        "Challenge_created_time":1653902834057,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/869594\/memory-outage-while-running-module",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":11.5,
        "Challenge_reading_time":3.25,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":2,
        "Challenge_solved_time":11.0410916667,
        "Challenge_title":"memory outage while running module",
        "Challenge_topic":"Compute Management",
        "Challenge_topic_macro":"Computation Management",
        "Challenge_view_count":null,
        "Challenge_word_count":48,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=d4454683-c6fe-4103-a1a8-d167ab8d04de\">@darya  <\/a>     <\/p>\n<p>Thanks for reaching out to us. This issue seldoms happen.  Could you please share your structure to us and how is your dataset size? Based on the error info, too many steps in your experiment may cause that.     <\/p>\n<p>I would suggest you try to remove some unnecessary one to try and see. If you believe your structure is reasonable, please share it to us. But it should be fine if you have not put too much.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer to help the community if you feel helpful, thanks.    <\/p>\n",
        "Solution_comment_count":1.0,
        "Solution_link_count":0.0,
        "Solution_readability":4.2,
        "Solution_reading_time":7.71,
        "Solution_score_count":0.0,
        "Solution_sentence_count":9.0,
        "Solution_word_count":102.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":0.7565502778,
        "Challenge_answer_count":1,
        "Challenge_body":"I'm trying to deploy my own GreengrassV2 components. It's a SageMaker ML model (optimized with SageMakerNeo and packaged as a Greengrass component) and the according inference app. I was trying to deploy it to my core device with SageMaker Edge Manager component. But it is always stuck in the status \"In progress\".\n\nMy logs show this error:\ncom.aws.greengrass.tes.CredentialRequestHandler: Error in retrieving AwsCredentials from TES. {iotCredentialsPath=\/role-aliases\/edgedevicerolealias\/credentials, credentialData=TES responded with status code: 403. Caching response. {\"message\":\"Access Denied\"}}\n\nBut how do I know which policies are missing?",
        "Challenge_closed_time":1682713832572,
        "Challenge_comment_count":0,
        "Challenge_created_time":1682711108991,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUlDu9VAj4Qx-O7cbAXDz28w\/greengrass-own-component-deployment-stuck-in-progress",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":9.6,
        "Challenge_reading_time":9.0,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":0.7565502778,
        "Challenge_title":"Greengrass own component deployment stuck \"in progress\"",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":61.0,
        "Challenge_word_count":90,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"Hello, please refer to https:\/\/docs.aws.amazon.com\/greengrass\/v2\/developerguide\/troubleshooting.html#token-exchange-service-credentials-http-403 for troubleshooting,  you'll need `iot:AssumeRoleWithCertificate` permissions on your core device's AWS IoT role alias",
        "Solution_comment_count":0.0,
        "Solution_link_count":1.0,
        "Solution_readability":21.2,
        "Solution_reading_time":3.58,
        "Solution_score_count":2.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":19.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":0.1277777778,
        "Challenge_answer_count":0,
        "Challenge_body":"From slack\n\nHi, I\u2019m trying to deploy Polyaxon CE with helm\/argocd and the polyaxon-api keeps logging in loop:\n\nSystem check identified some issues:\n\nPreparing...\n\n\nand the pod never becomes ready.\nAny idea what could cause that?\n\nMore\n\nIt seems the polyaxon helm chart installation always fails with the message:\n\nError: timed out waiting for the condition\nThis is what I see:\n\npolyaxon-polyaxon-api-d8d7c8b5f-spsb2           1\/1     Running   0          3d5h\npolyaxon-polyaxon-api-dbb84b79c-6jqm9           0\/1     Running   2          13m\n\n\nThe polyaxon api pods take a long time to become ready. It fails liveness probe:\n\nEvents:\n  Type     Reason     Age                   From               Message\n  ----     ------     ----                  ----               -------\n  Normal   Scheduled  15m                   default-scheduler  Successfully assigned polyaxon\/polyaxon-polyaxon-api-dbb84b79c-6jqm9 to ip-192-168-165-30.us-east-2.compute.internal\n  Normal   Pulling    14m                   kubelet            Pulling image \"polyaxon\/polyaxon-api:xx\"\n  Normal   Pulled     14m                   kubelet            Successfully pulled image \"polyaxon\/polyaxon-api:xx\" in 33.387487209s\n  Normal   Created    14m                   kubelet            Created container polyaxon-api\n  Normal   Started    14m                   kubelet            Started container polyaxon-api\n  Normal   Killing    8m49s                 kubelet            Container polyaxon-api failed liveness probe, will be restarted\n  Warning  Unhealthy  8m37s (x10 over 13m)  kubelet            Readiness probe failed: Get \"[http:\/\/192.168.184.124:80\/healthz\/](http:\/\/192.168.184.124\/healthz\/)\": dial tcp 192.168.184.124:80: connect: connection refused\n  Normal   Pulled     8m19s                 kubelet            Container image \"polyaxon\/polyaxon-api:1.9.5\" already present on machine\n  Warning  Unhealthy  4m49s (x16 over 13m)  kubelet            Liveness probe failed: Get \"[http:\/\/192.168.184.124:80\/healthz\/](http:\/\/192.168.184.124\/healthz\/)\": dial tcp 192.168.184.124:80: connect: connection refused",
        "Challenge_closed_time":1649329378000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1649328918000,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1473",
        "Challenge_link_count":2,
        "Challenge_participation_count":0,
        "Challenge_readability":10.4,
        "Challenge_reading_time":22.21,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":13,
        "Challenge_solved_time":0.1277777778,
        "Challenge_title":"Polyaxon CE fresh deployment never finishes",
        "Challenge_topic":"Kubernetes Configuration",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":null,
        "Challenge_word_count":196,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"The firts step is to cehck if you are using the --wait flag with Helm, if yes the deployment will not pass because there's helm hook.\n\nThe reason of the deadlock: helm waits forever for API to be healthy and the API is waiting for the hook to initialize the database.\n\nMore info about the helm deadlock issue: helm\/helm#5118\n\nFor ArgoCD, the flag is set to true automatically: argoproj\/argo-cd#6880\n\nFor the Terraform provider for helm release, the flag is set to true by default: https:\/\/registry.terraform.io\/providers\/hashicorp\/helm\/latest\/docs\/resources\/release#wait and should be set it to false.",
        "Solution_comment_count":0.0,
        "Solution_link_count":1.0,
        "Solution_readability":11.1,
        "Solution_reading_time":7.43,
        "Solution_score_count":1.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":92.0,
        "Tool":"Polyaxon"
    },
    {
        "Answerer_isAwsEmployee":0.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":4.1845747222,
        "Challenge_answer_count":1,
        "Challenge_body":"Hi,\nCan I use serverless inference as a pricing model for selling a SageMaker Model Package on the AWS Marketplace?",
        "Challenge_closed_time":1673186904128,
        "Challenge_comment_count":0,
        "Challenge_created_time":1673171839659,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUcZwxBuy-SROI7OF3-NFslA\/sagemaker-serverless-on-aws-marketplace",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":10.3,
        "Challenge_reading_time":1.95,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":2,
        "Challenge_solved_time":4.1845747222,
        "Challenge_title":"SageMaker Serverless on AWS Marketplace?",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":55.0,
        "Challenge_word_count":24,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"No, quoting from SageMaker documentation:\n\n\n```\n\u2026features currently available for SageMaker Real-time Inference are not supported for Serverless Inference, including GPUs, AWS marketplace model packages\u2026\n```\n\nReference: https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/serverless-endpoints.html#serverless-endpoints-how-it-works-exclusions",
        "Solution_comment_count":0.0,
        "Solution_link_count":1.0,
        "Solution_readability":28.8,
        "Solution_reading_time":4.52,
        "Solution_score_count":0.0,
        "Solution_sentence_count":1.0,
        "Solution_word_count":26.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":0.0900975,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hello,<\/p>\n<p>I created a batch endpoint, deployment and now creating deployment job in Machine Learning Workspace. I am providing the input data via datastore to read data from an external data storage. I followed the following tutorial <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data-batch-endpoints-jobs?view=azureml-api-2&amp;tabs=sdk\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data-batch-endpoints-jobs?view=azureml-api-2&amp;tabs=sdk<\/a> and under the title <strong>Security considerations when reading data<\/strong> within the table, in the second row, identity of the job should be enough. But I am still getting authorization error when I try to read the data. Is it because I want to read from an external storage account, meaning that compute cluster should be authenticated by the external storage account as well? <\/p>\n<p>Thank you for your time and help.<\/p>",
        "Challenge_closed_time":1684230604864,
        "Challenge_comment_count":0,
        "Challenge_created_time":1684230280513,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1285828\/ml-batch-endpoint-using-datastore-to-access-an-ext",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":12.7,
        "Challenge_reading_time":13.1,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":8,
        "Challenge_solved_time":0.0900975,
        "Challenge_title":"ML Batch Endpoint, using datastore to access an external data storage",
        "Challenge_topic":"Dataset Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":null,
        "Challenge_word_count":120,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Yes, you are correct. In order to read data from an external storage account, the compute cluster must be authenticated by the external storage account as well. This is because the compute cluster needs to have permission to access the data in the external storage account.<\/p>\n<p>There are a few ways to authenticate the compute cluster with the external storage account. One way is to use a service principal. A service principal is an identity that can be used to access Azure resources. To create a service principal, you can use the Azure portal or the Azure CLI.<\/p>\n<p>Once you have created a service principal, you need to grant it access to the external storage account. You can do this by assigning the service principal a role in the external storage account. The role that you assign will determine what level of access the service principal has to the external storage account.<\/p>\n<p>Once you have granted the service principal access to the external storage account, you need to configure the compute cluster to use the service principal. You can do this by setting the <code>AZURE_STORAGE_ACCOUNT_CONNECTION_STRING<\/code> environment variable on the compute cluster. The value of this environment variable should be the connection string for the external storage account.<\/p>\n<p>Once you have configured the compute cluster to use the service principal, you should be able to read data from the external storage account. If you are still getting an authorization error, you can try the following:<\/p>\n<ul>\n<li> Make sure that the service principal has the correct permissions to access the external storage account.<\/li>\n<li> Make sure that the <code>AZURE_STORAGE_ACCOUNT_CONNECTION_STRING<\/code> environment variable is set correctly on the compute cluster.<\/li>\n<li> Restart the compute cluster.<\/li>\n<\/ul>\n<p>If you are still having trouble, you can contact Azure support for help.<\/p>\n<p>Please don't forget to click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/><\/p>\n<p>and upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/><\/p>\n<p>button if you find this helpful.<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":2.0,
        "Solution_readability":10.4,
        "Solution_reading_time":28.38,
        "Solution_score_count":0.0,
        "Solution_sentence_count":21.0,
        "Solution_word_count":318.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":1.0094444444,
        "Challenge_answer_count":1,
        "Challenge_body":"Hi, does SageMaker PyTorch Hosting 1.6 works only with artifacts named model.pth ?\nI'm trying [this sample with 1.6][1] and the deployment fails with error\n\n    FileNotFoundError: [Errno 2] No such file or directory: '\/opt\/ml\/model\/model.pth'\n\nthe documentation doesn't mention such a constraint\n\n  [1]: https:\/\/github.com\/aws-samples\/amazon-sagemaker-bert-classify-pytorch",
        "Challenge_closed_time":1610121735000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1610118101000,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUn-IyC9nySDKKibLL3Lvw3A\/sagemaker-pytorch-hosting-1-6-works-only-with-artifacts-named-model-pth",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":9.7,
        "Challenge_reading_time":5.67,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":1.0094444444,
        "Challenge_title":"SageMaker PyTorch Hosting 1.6 works only with artifacts named model.pth ?",
        "Challenge_topic":"Model Persistence",
        "Challenge_topic_macro":"Model Management",
        "Challenge_view_count":330.0,
        "Challenge_word_count":52,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":1.0,
        "Poster_isModerator":0.0,
        "Solution_body":"Yes - from the thread on this open issue: https:\/\/github.com\/aws\/sagemaker-pytorch-inference-toolkit\/issues\/86\n\nIn the issue thread they note that the new Pytorch 1.6 image requires that the model filename is `model.pth`, linking to the relevant code where this default is set: https:\/\/github.com\/aws\/sagemaker-pytorch-inference-toolkit\/blob\/9a6869e\/src\/sagemaker_pytorch_serving_container\/torchserve.py#L121\n\nAlso noted in the thread is that users have successfully adapted their code to use torchserve in Pytorch 1.6 by changing it to save their model in a file named `model.pth`. Once renamed, they were still able to use custom inference scripts to load their model by defining a custom `model_fn`: https:\/\/github.com\/data-science-on-aws\/workshop\/blob\/374329adf15bf1810bfc4a9e73501ee5d3b4e0f5\/09_deploy\/wip\/pytorch\/code\/inference.py",
        "Solution_comment_count":1.0,
        "Solution_link_count":3.0,
        "Solution_readability":11.9,
        "Solution_reading_time":10.91,
        "Solution_score_count":1.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":91.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":28.1985233334,
        "Challenge_answer_count":3,
        "Challenge_body":"<p>I\u2019m trying to train a model, but I keep receiving an error that tells me \u201ctrain.py: error: unrecognized arguments: --save_period 1.\u201d<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/3ad842158d3fe6c02426800cceb90f785a60b755.png\" data-download-href=\"\/uploads\/short-url\/8oz1v5B3P0W95o6FWMDht4yfVLD.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/3ad842158d3fe6c02426800cceb90f785a60b755_2_690x337.png\" alt=\"image\" data-base62-sha1=\"8oz1v5B3P0W95o6FWMDht4yfVLD\" width=\"690\" height=\"337\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/3ad842158d3fe6c02426800cceb90f785a60b755_2_690x337.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/3ad842158d3fe6c02426800cceb90f785a60b755_2_1035x505.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/3ad842158d3fe6c02426800cceb90f785a60b755.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/3ad842158d3fe6c02426800cceb90f785a60b755_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1326\u00d7648 66 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><br>\nWhat issue do I have here?  Thanks in advance.<\/p>",
        "Challenge_closed_time":1636785650863,
        "Challenge_comment_count":0,
        "Challenge_created_time":1636684136179,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/save-period-not-working\/1264",
        "Challenge_link_count":6,
        "Challenge_participation_count":3,
        "Challenge_readability":28.8,
        "Challenge_reading_time":22.56,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":28.1985233334,
        "Challenge_title":"Save_period Not Working",
        "Challenge_topic":"Model Persistence",
        "Challenge_topic_macro":"Model Management",
        "Challenge_view_count":259.0,
        "Challenge_word_count":71,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>I think you have  a typo. According to the usage info, the argument name is <code>--save-period<\/code>  , not <code>--save_period<\/code><\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":9.2,
        "Solution_reading_time":1.81,
        "Solution_score_count":null,
        "Solution_sentence_count":2.0,
        "Solution_word_count":18.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":8.8905811111,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi community,   <br \/>\nI'm interested in what Azure Form Recogniser or another tool can do for us in terms of screening the correctness of uploaded applications. Think of applications for funding grants.  I haven't built any models yet, just wondering how feasible the below is.  A solution doesn't have to involve AI at all, but must be able to 'read' the uploaded documents.  <\/p>\n<p>A client uploads a set of standard documents (usually scanned PDF's)  using a file upload in our .net application.    <br \/>\nCan we:  <\/p>\n<ol>\n<li> Use form recogniser to extract key value pairs, after training a custom model.  <\/li>\n<li> Run a loop over these pairs to find missing information e.g. they forgot to add their date of birth, or didn't enter their income.  <\/li>\n<li> Report back to the user the missing information so they can correct the document and reupload them?  <br \/>\nPreferably in real time?  So they hit submit on the webpage, it extracts, analyses and provides a result in a few seconds?  <\/li>\n<\/ol>",
        "Challenge_closed_time":1647513011952,
        "Challenge_comment_count":0,
        "Challenge_created_time":1647481005860,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/775440\/form-recognizer-to-report-on-missing-information-i",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":8.0,
        "Challenge_reading_time":13.02,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":12,
        "Challenge_solved_time":8.8905811111,
        "Challenge_title":"Form recognizer to report on missing information in (near) real-time",
        "Challenge_topic":"Metric Logging",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":null,
        "Challenge_word_count":181,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=d4ec46af-03e5-46ab-ace4-d0dd3b8d93ba\">@Andrew Robertson  <\/a> Yes, you can use Azure form recognizer to analyze a document that is passed to the API and use the result of the analyze operation to report any missing fields in the form back to the user. This is the most widely used use case by most of the customers.     <\/p>\n<p>Form recognizer comes with a set of prebuilt APIs where it can extract common information from invoices, business cards, receipts etc. If you have a form that does not conform to the prebuilt API standards you need to create a custom model to extract the text in the form of a tags and their key:value pairs. The custom models require some basic training with some test forms and if all the forms that need extraction follow the same layout or guidelines the extraction results will be good.     <\/p>\n<p>In the case of custom forms the results are provided in almost real time where the form is submitted or <a href=\"https:\/\/westus.dev.cognitive.microsoft.com\/docs\/services\/form-recognizer-api-v3-0-preview-2\/operations\/AnalyzeDocument\">POST<\/a> request is sent to the API and an operation id is returned to retrieve the results using <a href=\"https:\/\/westus.dev.cognitive.microsoft.com\/docs\/services\/form-recognizer-api-v3-0-preview-2\/operations\/GetAnalyzeDocumentResult\">GET<\/a>.  Depending on your pricing tier of your resource if you intend to perform these actions synchronously you might have to limit the rate of requests sent to the API to avoid any TPS errors. If you are using async operations with a slight delay to fetch the results then you can design an application that can take large number of documents and provide results to the users within a short span of time.     <\/p>\n<p>I hope the above information is helpful.    <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Solution_comment_count":1.0,
        "Solution_link_count":4.0,
        "Solution_readability":14.4,
        "Solution_reading_time":27.25,
        "Solution_score_count":0.0,
        "Solution_sentence_count":13.0,
        "Solution_word_count":292.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":0.0377777778,
        "Challenge_answer_count":0,
        "Challenge_body":"From slack\n\nHi, I have a quick question, is it possible to filter all jobs that requested\/accessed a specific connection?\n\nTo explain my use-case, we detected an issue with some data, and we would like to assess how many jobs and how far in the past that data was used in our training jobs.",
        "Challenge_closed_time":1649676909000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1649676773000,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1487",
        "Challenge_link_count":0,
        "Challenge_participation_count":0,
        "Challenge_readability":9.6,
        "Challenge_reading_time":4.39,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":0.0377777778,
        "Challenge_title":"How to filter all jobs that accessed a connection, a dataset, or an artifact",
        "Challenge_topic":"CloudWatch Monitoring",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":null,
        "Challenge_word_count":67,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"V1.18 the following filters, or any combination, will be possible:\n\nBy connection name connections.name: CONNECTION1 | CONNECTION2\nBy connection tag connections.tags: TAG1 | TAG2\nBy connection kind connections.kind: git or connections.kind: KIND1 | KIND2\nBy artifact name artifacts.name: LINEAGE1 | LINEAGE2\nBy artifact kind artifacts.kind: model or artifacts.kind: KIND1 | KIND2\nBy artifact path artifacts.path: foo\/bar\nBy artifact state artifacts.state: STATE",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":10.4,
        "Solution_reading_time":5.88,
        "Solution_score_count":1.0,
        "Solution_sentence_count":9.0,
        "Solution_word_count":56.0,
        "Tool":"Polyaxon"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":3.3121319444,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi,  <\/p>\n<p>Please will you tell me how to cancel a dataset upload?  <\/p>\n<p>I tried to upload a small (321kb) CSV to Azure Machine Learning Studio.  The upload has been running for more than 1 hour, but it still says uploading.  <\/p>\n<p>I tried to upload other files (different names), and they are hanging too....same symptoms.  <\/p>\n<p>It seems the first problem is blocking all subsequent upload attempts.  <\/p>\n<p>Until today uploads worked perfectly.....multiple file types, multiple sizes, multiple dates, were all OK.  <\/p>\n<p>I have plenty of space left in my environment.  <\/p>\n<p>I tried closing and restarting my browser....same problem.  I accessed my AMLS via a different computer...same problem.  <\/p>\n<p>Thanks in advance for any advice you can give.  <\/p>",
        "Challenge_closed_time":1592933611232,
        "Challenge_comment_count":2,
        "Challenge_created_time":1592921687557,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/39201\/how-to-cancel-upload-azure-machine-learning-studio",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":4.8,
        "Challenge_reading_time":10.12,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":13,
        "Challenge_solved_time":3.3121319444,
        "Challenge_title":"How to Cancel Upload? - Azure Machine Learning Studio",
        "Challenge_topic":"Compute Management",
        "Challenge_topic_macro":"Computation Management",
        "Challenge_view_count":null,
        "Challenge_word_count":130,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Well, I don't know if you (<a href=\"\/users\/na\/?userid=d67fe4ea-5ec6-4e6b-b93c-404092429abd\">@GiftA-MSFT  <\/a>) did something to help, but it's solved!  Thanks if you did take that initiative, I appreciate it.  :-)    <\/p>\n<p>...or it could be that after 4-5 hours the upload just completed.  My internet connection was fine (it's a 40Mb line), so I'm not sure what the solution was.  Perhaps patience alone is the answer.    <\/p>\n<p>Anyway, thanks for taking an interest in my problem either way.      <\/p>\n<p>Best wishes.  :-)<\/p>\n",
        "Solution_comment_count":1.0,
        "Solution_link_count":0.0,
        "Solution_readability":4.8,
        "Solution_reading_time":6.45,
        "Solution_score_count":0.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":78.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":18.2845952778,
        "Challenge_answer_count":4,
        "Challenge_body":"<p>I am trying to run the demo code from <a href=\"https:\/\/colab.research.google.com\/gist\/sayakpaul\/5b31ed03725cc6ae2af41848d4acee45\/demo_tensorboard.ipynb\" rel=\"noopener nofollow ugc\">Demo_tensorboard.ipynb<\/a> so that I can learn more about the use of Tensorboard in combination with W&amp;B. Unfortunately this code throws this warning:<\/p>\n<p>WARNING When using several event log directories, please call <code>wandb.tensorboard.patch(root_logdir=\"...\")<\/code> before <code>wandb.init<\/code><\/p>\n<p>When I implement the suggested change with:<\/p>\n<p><code>wandb.tensorboard.patch(root_logdir=\".\/logs\/debug\")<\/code><\/p>\n<p>I get the following warning:<br>\nFound log directory outside of given root_logdir, dropping given root_logdir for event file in i:\\tinyml\\tiny_cnn\\wandb\\run-20221016_205607-22b9tlzf\\files\\train<\/p>\n<p>So my questions is: What is a suitable root_logdir for Tensorboard?<\/p>\n<p>Thanks for your support.<\/p>",
        "Challenge_closed_time":1666012581990,
        "Challenge_comment_count":0,
        "Challenge_created_time":1665946757447,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/logging-with-tensorboard\/3265",
        "Challenge_link_count":1,
        "Challenge_participation_count":4,
        "Challenge_readability":10.8,
        "Challenge_reading_time":12.68,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":18.2845952778,
        "Challenge_title":"Logging with Tensorboard",
        "Challenge_topic":"TensorBoard Logging",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":201.0,
        "Challenge_word_count":92,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi Susanne,<\/p>\n<p>Thanks for writing in! The <code>root_logdir<\/code>argument is the path to the root of all tfevent files, so you can use the wandb project folder (in this case I think it is <code>I:\/tinyml\/tiny_cnn<\/code>). Could you try if setting this solves the issue?<\/p>\n<p>Best,<br>\nLuis<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":4.2,
        "Solution_reading_time":3.8,
        "Solution_score_count":null,
        "Solution_sentence_count":4.0,
        "Solution_word_count":45.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":11.6668433334,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi :  <\/p>\n<p>I am planing to use k-means to form algorithm to do project. However, I am aware that there are certain shortcomings to find the optimal groups using k-means.  <\/p>\n<p>Could you please tell the limitation and provide me with a detailed example?  <\/p>\n<p>Thanks<\/p>",
        "Challenge_closed_time":1647898847903,
        "Challenge_comment_count":1,
        "Challenge_created_time":1647856847267,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/780362\/machine-learning-algorithms-questions",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":6.9,
        "Challenge_reading_time":3.92,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":11.6668433334,
        "Challenge_title":"machine learning algorithms questions",
        "Challenge_topic":"Hyperparameter Tuning",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":null,
        "Challenge_word_count":49,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello @hideonbush again,  <\/p>\n<p>Generally to think about k-means, please refer to below cons and pros. If you can provide more details and how you want to develop your project, I can share more:  <\/p>\n<p>Pros:  <\/p>\n<ul>\n<li> K-means is very simple, highly flexible, and efficient.   <\/li>\n<li> Easy to adjust and interpret the clustering results. Easy to explain the results in contrast to Neural Networks.  <\/li>\n<li> The efficiency of k-means implies that the algorithm is good at segmenting a dataset.  <\/li>\n<li> An instance can change cluster (move to another cluster) when the centroids are recomputed  <\/li>\n<\/ul>\n<p>Cons  <\/p>\n<ul>\n<li> It does not allow to develop the most optimal set of clusters and the number of clusters must be decided before the analysis. How many clusters to include is left at the discretion of the researcher. This involves a combination of common sense, domain knowledge, and statistical tools. Too many clusters tell you nothing because of the groups becoming very small and there are too many of them.   <\/li>\n<li> When doing the analysis, the k-means algorithm will randomly select several different places from which to develop clusters. This can be good or bad depending on where the algorithm chooses to begin at. From there, the center of the clusters is recalculated until an adequate &quot;center'' is found for the number of clusters requested.  <\/li>\n<li> The order of the data input has an impact on the final results.  <\/li>\n<\/ul>\n<p>Hope this helps!  <\/p>\n<p>Regards,  <br \/>\nYutong  <\/p>\n<p><em>-Please kindly accept the answer if you feel helpful, thanks.<\/em>  <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":9.0,
        "Solution_reading_time":19.71,
        "Solution_score_count":0.0,
        "Solution_sentence_count":15.0,
        "Solution_word_count":265.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":201.2384813889,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>Hi,<br>\nI am tuning hyper-params with wandb.sweep(). As I know the params are defined in sweep_id and insert into wandb.sweep() like this:<\/p>\n<pre><code class=\"lang-auto\">    sweep_configuration = {\n    'method': 'bayes',\n    'name': 'I dont believe that I can not just give you a name!',\n    'metric': {'goal': 'minimize', 'name': 'Valid\/final_ber'},\n    'parameters':\n    {\n        'batch_size': {'distribution': 'int_uniform','min': 10,'max': 12},\n        'lr': {'distribution': 'int_uniform','max': -3,'min': -4}\n    }\n    }\n    sweep_id = wandb.sweep(sweep=sweep_configuration, project=args.project, entity=args.entity)\n<\/code><\/pre>\n<p>Now I what I want to do is to extract the params <strong>batch_size<\/strong> and <strong>lr<\/strong> from each sweep into the name of <code>wand.init()<\/code>, because I need these information in name of each run to identify them.<br>\nBut in wandb frame, I cannot get access to the params in <code>wandb.config<\/code> before <code>wandb.init()<\/code>. As a result I cannot define argument <strong>name<\/strong>  in <code>wandb.init()<\/code> with params which are given during each sweep.<\/p>\n<pre><code class=\"lang-auto\">......\nwandb.init(name=f'{wandb.config.lr}_{wandb.config.batch_size}')\n......\n\nRun wnb56ush errored: Error('You must call wandb.init() before wandb.config.lr')\nwandb: ERROR Run wnb56ush errored: Error('You must call wandb.init() before wandb.config.lr')\n<\/code><\/pre>\n<p>Is there a way to get the params given by <code>wandb.sweep()<\/code> before wandb.init()?<br>\nThanks at advance<\/p>",
        "Challenge_closed_time":1680815891260,
        "Challenge_comment_count":0,
        "Challenge_created_time":1680091432727,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/how-can-i-extract-params-from-sweep-and-add-them-into-name-of-wandb-init\/4146",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":9.4,
        "Challenge_reading_time":20.36,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":19,
        "Challenge_solved_time":201.2384813889,
        "Challenge_title":"How can I extract params from sweep and add them into name of wandb.init()",
        "Challenge_topic":"Hyperparameter Tuning",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":88.0,
        "Challenge_word_count":183,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi <a class=\"mention\" href=\"\/u\/1060111768\">@1060111768<\/a> , it\u2019s not possible to get the sweep parameters before calling <code>wandb.init()<\/code>.<\/p>\n<p>When you run <code>wandb.sweep()<\/code> to define a hyperparameter sweep, it generates a unique sweep ID that is used to link the sweep to the subsequent runs that are generated by the sweep. This sweep ID is used to retrieve the sweep parameters when you initialize WandB by calling <code>wandb.init()<\/code>. The <code>wandb.init()<\/code> function retrieves the sweep parameters from the WandB servers using the sweep ID, and uses them to configure the run. Once you have called <code>wandb.init()<\/code>, you can access the sweep parameters using the <code>config<\/code> object.<\/p>\n<p>Instead of specifying a name in wandb init, rename the run immediately after initializing the run.<br>\nExample:<\/p>\n<pre><code class=\"lang-auto\">run =  wandb.init(config=config)\nrun.name=f\"{wandb.config.lr}_{wandb.config.batch_size}\"\n<\/code><\/pre>",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":11.0,
        "Solution_reading_time":12.78,
        "Solution_score_count":null,
        "Solution_sentence_count":9.0,
        "Solution_word_count":123.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":1.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":29.82268,
        "Challenge_answer_count":3,
        "Challenge_body":"The SageMaker Data Wrangler UI in SageMaker Studio doesn't seem to support all the features that the API does.  When will the UI support:\n* Loading all s3 objects under a prefix?  https:\/\/aws-data-wrangler.readthedocs.io\/en\/stable\/stubs\/awswrangler.s3.read_csv.html#awswrangler.s3.read_csv\n* Loading JSON objects in addition to CSV and Parquet files?  https:\/\/aws-data-wrangler.readthedocs.io\/en\/stable\/stubs\/awswrangler.s3.read_json.html#awswrangler.s3.read_json",
        "Challenge_closed_time":1642051347464,
        "Challenge_comment_count":1,
        "Challenge_created_time":1641943985816,
        "Challenge_favorite_count":1.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUcsIt78jnSTW8Ta9__kUm-w\/sagemaker-data-wrangler-ui-features",
        "Challenge_link_count":2,
        "Challenge_participation_count":4,
        "Challenge_readability":16.2,
        "Challenge_reading_time":6.58,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":29.82268,
        "Challenge_title":"SageMaker Data Wrangler UI Features",
        "Challenge_topic":"Batch Transformation",
        "Challenge_topic_macro":"Computation Management",
        "Challenge_view_count":122.0,
        "Challenge_word_count":47,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"As mentioned by Tulio Alberto in comments, Amazon SageMaker Data Wrangler (the graphical data preparation feature inside Amazon SageMaker) is separate from AWS Data Wrangler (an open-source data prep utility published by AWS Labs): The two tools are based on different technologies and don't necessarily aim for full feature parity - they just happen to share similar names.\n\nTo my knowledge there's no committed timeline we can share at the moment for when these particular features will make it to SageMaker Data Wrangler, but I think as feature requests they make sense and the reasoning for both is pretty clear: I'm aware that both have been discussed to some extent internally already, and I'd personally like to see them launch too!\n\nThanks for sharing the feedback, and apologies for the naming confusion!",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":20.3,
        "Solution_reading_time":9.99,
        "Solution_score_count":2.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":131.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":16.8847241667,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>How to mount the dataset in ML Studio using python sdk ?    <br \/>\nWhat are the different ways and which is the right one ?    <\/p>\n<p>Can we create dataset pointing to two different stores ?    <\/p>\n<p>Also where can I learn more about azure machine learning ?<\/p>",
        "Challenge_closed_time":1661469512520,
        "Challenge_comment_count":0,
        "Challenge_created_time":1661408727513,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/981126\/mounting-the-dataset-in-ml-workspace",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":2.5,
        "Challenge_reading_time":3.57,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":16.8847241667,
        "Challenge_title":"Mounting the dataset in ML Workspace",
        "Challenge_topic":"Dataset Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":null,
        "Challenge_word_count":50,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=b2d28b4e-27a0-4d31-9f64-5723bfe88382\">@V JEEVA  <\/a>     <\/p>\n<p>Thanks for using Microsoft Q&amp;A platform. Let me answer your questions one by one.    <\/p>\n<p><em>where can I learn more about azure machine learning<\/em>    <br \/>\nThe best way to learn Azure Machine Learning is the documentation, please refer to - <a href=\"https:\/\/azure.microsoft.com\/en-us\/services\/machine-learning\/#documentation\">https:\/\/azure.microsoft.com\/en-us\/services\/machine-learning\/#documentation<\/a>    <\/p>\n<p><em>How to mount the dataset in ML Studio using python sdk ?<\/em>    <br \/>\nGenerally there are two ways to work with data in Azure Machine Learning -    <br \/>\nUse datastores - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-datastore?tabs=cli-identity-based-access%2Ccli-adls-identity-based-access%2Ccli-azfiles-account-key%2Ccli-adlsgen1-identity-based-access\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-datastore?tabs=cli-identity-based-access%2Ccli-adls-identity-based-access%2Ccli-azfiles-account-key%2Ccli-adlsgen1-identity-based-access<\/a>    <br \/>\nUse data assets - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-datastore?tabs=cli-identity-based-access%2Ccli-adls-identity-based-access%2Ccli-azfiles-account-key%2Ccli-adlsgen1-identity-based-access\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-datastore?tabs=cli-identity-based-access%2Ccli-adls-identity-based-access%2Ccli-azfiles-account-key%2Ccli-adlsgen1-identity-based-access<\/a>    <\/p>\n<p><em>What are the different ways and which is the right one ?<\/em>    <br \/>\nIt depends on your need. Compared to data assets and datastore, the benefits of creating data assets are:    <br \/>\nYou can share and reuse data with other members of the team such that they do not need to remember file locations.    <br \/>\nYou can seamlessly access data during model training (on any supported compute type) without worrying about connection strings or data paths.    <br \/>\nYou can version the data.    <\/p>\n<p><em>Can we create dataset pointing to two different stores ?<\/em>    <br \/>\nIf you need to assembly data, you may want to consider data assets. By creating a data asset, you create a reference to the data source location, along with a copy of its metadata. Because the data remains in its existing location, you incur no extra storage cost, and don't risk the integrity of your data sources. You can create Data from datastores, Azure Storage, public URLs, and local files.    <\/p>\n<p>I hope this helps!    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":3.0,
        "Solution_readability":14.9,
        "Solution_reading_time":35.07,
        "Solution_score_count":2.0,
        "Solution_sentence_count":19.0,
        "Solution_word_count":277.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":1.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":39.9922386111,
        "Challenge_answer_count":1,
        "Challenge_body":"i have a async inference on SageMaker, with BYOC.  The job may take about 20 minutes and more. And i already set InvocationTimeoutSeconds to 3600 seconds.    \nthe problem is, when i start a new inference request, from CloudWatch i know the job is in progress,  and there is not \/ping request log in CloudWatch. but the after about 10 minute ,  \/ping log in CloudWatch show up again with error, which says service unavailable.  \n then after 6 minute, i found a new log stream in CloudWatch, and the older one is down.  \nhere is the log in CloudWatch:\n\n```\n...(\/ping log, until i send a request)\n\n2023-05-17T16:12:15.761+08:00\ttask type:file ( my job start)\n2023-05-17T16:22:58.223+08:00.     [error] 31#31: *389 connect() to unix:\/tmp\/gunicorn.sock failed (11: Resource temporarily unavailable) while connecting to upstream, client: 169.254.178.2, server: , request: \"GET \/ping HTTP\/1.1\", upstream: \"http:\/\/unix:\/tmp\/gunicorn.sock:\/ping\", host: \"169.254.180.2:8080\"\n2023-05-17T16:23:02.761+08:00\t169.254.178.2 - - [17\/May\/2023:08:22:58 +0000] \"GET \/ping HTTP\/1.1\" 502 166 \"-\" \"AHC\/2.0\"\n\n...(the error and \/ping repeat for 6 minute)\n\n2023-05-17T16:28:58.133+08:00    [error] 31#31: *449 connect() to unix:\/tmp\/gunicorn.sock failed (11: Resource temporarily unavailable) while connecting to upstream, client: 169.254.178.2, server: , request: \"GET \/ping HTTP\/1.1\", upstream: \"http:\/\/unix:\/tmp\/gunicorn.sock:\/ping\", host: \"169.254.180.2:8080\"\n```\n\nhow can i fix it?",
        "Challenge_closed_time":1684462461646,
        "Challenge_comment_count":0,
        "Challenge_created_time":1684318489587,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUInjgvtuaRNi54eIpETzQ-Q\/async-inference-docker-restart-after-less-than-20-minutes-not-helpful-log-found",
        "Challenge_link_count":2,
        "Challenge_participation_count":1,
        "Challenge_readability":4.2,
        "Challenge_reading_time":19.26,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":24,
        "Challenge_solved_time":39.9922386111,
        "Challenge_title":"async inference docker restart after less than 20 minutes, not helpful log found",
        "Challenge_topic":"CloudWatch Monitoring",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":49.0,
        "Challenge_word_count":199,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"If I understand your log snippets correctly, it looks like your container is failing to respond to any `\/ping`s while processing the long-running request? Failing to respond to ping for an extended period indicates your endpoint is unhealthy so will signal SageMaker to restart the container.\n\nA likely reason for not responding might be if your request handling uses multi-processing in a way that maxes out all CPUs on the instance? This would leave no cores\/threads available to handle to incoming pings while the data is getting processed. In that case, the fix would be to identify what component(s) of your request handling might be using all available system cores at once, and re-configuring them to use `int(os.environ[\"SM_NUM_CPUS\"]) - 1` instead.\n\nA similar but less likely reason is if for some reason you're using a fully-custom serving stack or have explicitly re-configured the default one to have only one worker thread: In which case your main request handling might be blocking the server with no threads available to pick up concurrent pings (even though there are CPU resources)?",
        "Solution_comment_count":1.0,
        "Solution_link_count":0.0,
        "Solution_readability":12.0,
        "Solution_reading_time":13.51,
        "Solution_score_count":0.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":177.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":1.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":0.5291666667,
        "Challenge_answer_count":1,
        "Challenge_body":"Did the SageMaker PyTorch deployment process change?\n\nIt use to be the case that people needed to have a model.tar.gz in s3, and an inference script locally or in git. Now, it seems that the inference script must also be part of the model.tar.gz. This is new, right?\n\nFrom the docs,  https:\/\/sagemaker.readthedocs.io\/en\/stable\/frameworks\/pytorch\/using_pytorch.html#for-versions-1-2-and-higher:\n\n*For PyTorch versions 1.2 and higher, the contents of model.tar.gz should be organized as follows:\n - Model files in the top-level directory\n - Inference script (and any other source files) in a directory named code\/ (for more about the inference script, see The SageMaker PyTorch Model Server)\n - Optional requirements file located at code\/requirements.txt (for more about requirements files, see Using third-party libraries)*\n\nThis may be confusing, because this new mode of deployment means that people creating the model artifact need to know in advanced how the inference is going to look like. The previous design, with separation of artifact and inference code, was more agile.",
        "Challenge_closed_time":1594981418000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1594979513000,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUFIru4hJ2TcWLi7CYt3mnuw\/did-the-sagemaker-pytorch-deployment-process-change",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":9.7,
        "Challenge_reading_time":14.12,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":12,
        "Challenge_solved_time":0.5291666667,
        "Challenge_title":"Did the SageMaker PyTorch deployment process change?",
        "Challenge_topic":"Model Persistence",
        "Challenge_topic_macro":"Model Management",
        "Challenge_view_count":307.0,
        "Challenge_word_count":161,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":1.0,
        "Poster_isModerator":0.0,
        "Solution_body":"When [AWS Sample - BERT sample using torch 1.4](https:\/\/github.com\/aws-samples\/amazon-sagemaker-bert-classify-pytorch) was published, advance knowledge of the inference seems to be necessary.  If you use the PyTorch SageMaker SDK to create or deploy the model after it is trained, it automatically **re-packages** the model.tar.gz to include the code files and the inference files. As an example, when you use the following script, the model.tar.gz is repackaged so the contents of the src directory is automatically added to the code directory model.tar.gz, which initially only contains model files. You don't need to know the inference code in advance.\n\n```python\nfrom sagemaker.pytorch import PyTorchModel\nfrom sagemaker import get_execution_role\nrole = get_execution_role()\n\nmodel_uri = estimator.model_data\n\nmodel = PyTorchModel(model_data=model_uri,\n                     role=role,\n                     framework_version='1.4.0',\n                     entry_point='serve.py',\n                     source_dir='src')\n\npredictor = model.deploy(initial_instance_count=1, instance_type='ml.p3.2xlarge')\n```\n\nFor the older versions, you couldn't include additional files \/dependencies during inference unless you built a custom container.  The source.tar.gz was only used during training.",
        "Solution_comment_count":0.0,
        "Solution_link_count":1.0,
        "Solution_readability":11.9,
        "Solution_reading_time":15.44,
        "Solution_score_count":0.0,
        "Solution_sentence_count":14.0,
        "Solution_word_count":141.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":525.8622483334,
        "Challenge_answer_count":7,
        "Challenge_body":"<p>I have a guild operation <code>main<\/code> that runs 3 steps which are other operations: <code>impute<\/code>, <code>evaluate<\/code>, and <code>predict<\/code>. The latter two require on the <code>impute<\/code> operation (specifically a model checkpoint and some data output).<br>\n(<a href=\"https:\/\/github.com\/davzaman\/autopopulus\/blob\/dev\/guild.yml\" rel=\"noopener nofollow ugc\">guild.yml<\/a> file for reference)<\/p>\n<ol>\n<li>When one of the steps fails (e.g. <code>evaluate<\/code>), the <code>main<\/code> op shows error and so does <code>evaluate<\/code>. If I fix the error in the code and restart the run with something like <code>for hash in $(guild select --operation evaluate --error --all); do guild run -y --background --restart $hash --force-sourcecode; done<\/code>,  then the <code>evaluate<\/code> op fixes to completed, but the <code>main<\/code> operation does not. It doesn\u2019t seem very possible to update it, but it is slightly unclean and annoying to keep track of what broke and what is fixed. I end up with something like:<\/li>\n<\/ol>\n<pre><code class=\"lang-plaintext\">[71:ec03c916]   evaluate  2023-02-20 14:43:57  completed  dvae myexperiment\n[72:957ecb30]   evaluate  2023-02-20 14:43:56  completed  dvae myexperiment\n[73:19493e6b]   evaluate  2023-02-20 14:43:56  completed  dvae myexperiment\n...\n[127:fe72a7ff]  predict   2023-02-18 20:58:56  completed  dvae \n[128:617bc8fd]  impute    2023-02-18 20:26:16  completed  dvae myexperiment\n[129:2b155ff0]  main      2023-02-18 20:26:14  error      dvae \n[130:39125144]  predict   2023-02-18 20:21:08  completed  dvae \n[131:5c4ed46a]  impute    2023-02-18 19:45:25  completed  dvae myexperiment\n[132:c542fcbe]  main      2023-02-18 19:45:24  error      dvae \n<\/code><\/pre>\n<p>It said <code>error<\/code> for <code>main<\/code> but it\u2019s really been fixed sine the <code>evaluate<\/code> op was fixed.<br>\nAnother issue is also what files are stored under each op which leads me to the next point, where ill use <code>run 132<\/code> as an example:<\/p>\n<ol start=\"2\">\n<li>If I look at what is stored under the <code>main<\/code> op I see:<\/li>\n<\/ol>\n<pre><code class=\"lang-shell\">me@machine:~\/mambaforge\/envs\/ap\/.guild\/runs\/c542fcbe24ab4a86b1ea0e33fabd839a$ ls\nevaluate  impute  options.yml  predict\n<\/code><\/pre>\n<p>If I drill into the directories I see:<\/p>\n<pre><code class=\"lang-plaintext\">me@machine:~\/mambaforge\/envs\/ap\/.guild\/runs\/c542fcbe24ab4a86b1ea0e33fabd839a$ cd evaluate\nme@machine:~\/mambaforge\/envs\/ap\/.guild\/runs\/c542fcbe24ab4a86b1ea0e33fabd839a\/evaluate$ ls\nF.O.  options.yml  serialized_models\n<\/code><\/pre>\n<p>If <code>evaluate<\/code> fails and I rerun it, does that mean that the <code>evaluate<\/code>folder will be updated too (is it a symlink)? There seems to be some redundancy too which leads me to:<\/p>\n<ol start=\"3\">\n<li>If I look at the output of the substeps <code>impute<\/code> and <code>predict<\/code> I see:<\/li>\n<\/ol>\n<pre><code class=\"lang-plaintext\"># impute op\nme@machine:~\/mambaforge\/envs\/ap\/.guild\/runs\/5c4ed46a12e145158b2351621ee81345\/serialized_models$ ls\nAEDitto_STATIC.pt  imputed_data.pkl  STATIC_test_dataloader.pt\n# predict op\nme@machine:~\/mambaforge\/envs\/ap\/.guild\/runs\/391251446fe041048d93d80deda6ac8a\/serialized_models$ ls\nAEDitto_STATIC.pt  imputed_data.pkl  STATIC_test_dataloader.pt\n<\/code><\/pre>\n<p>I also see<\/p>\n<pre><code class=\"lang-plaintext\"># impute op\nme@machine:~\/mambaforge\/envs\/ap\/.guild\/runs\/5c4ed46a12e145158b2351621ee81345$ ls F.O.\/0.33\/MNAR\\(G\\)\/dvae\/lightning_logs\/version_0\/\nevents.out.tfevents.1676780435.lambda2.6521.0\nevents.out.tfevents.1676780445.lambda2.6521.1\nevents.out.tfevents.1676780453.lambda2.6521.2\nhparams.yaml\n# predict op\nme@machine:~\/mambaforge\/envs\/ap\/.guild\/runs\/391251446fe041048d93d80deda6ac8a$ ls F.O.\/0.33\/MNAR\\(G\\)\/dvae\/lightning_logs\/version_0\/\nevents.out.tfevents.1676780435.lambda2.6521.0\nevents.out.tfevents.1676780445.lambda2.6521.1\nevents.out.tfevents.1676780453.lambda2.6521.2\nhparams.yaml\n<\/code><\/pre>\n<p>It looks like it copies over everything from the <code>impute<\/code> op top the parents: <code>main<\/code>, and dependent steps: <code>predict<\/code>, and <code>evaluate<\/code>. This is a lot of redundancy especially for expensive\/large models and artifacts. This is making me run out of space on my machine.<\/p>\n<p>My questions are<br>\na) How do I avoid redundancy in stored artifacts between parent and child steps like <code>main<\/code> having substeps.<br>\nb) How do I avoid redundancy amongst sibling runs where one may be dependent on another? While <code>evaluate<\/code> relies on the artifacts from <code>impute<\/code> I don\u2019t want it to store all the artifacts all over again (including the model checkpoints, data, and the logging files), I just want <code>evaluate<\/code> to use the checkpointed data and model. <a href=\"https:\/\/my.guild.ai\/t\/guild-file-cheatsheet\/192#required-operation-files-14\">I know there\u2019s a <code>select:<\/code> option<\/a> but it seems to be regex, making it complicated to select the checkpointed model AND data. Also even if that solves excluding the logged files, I don\u2019t want to copy over the files it relies on to the final logged artifacts.<\/p>",
        "Challenge_closed_time":1678831800198,
        "Challenge_comment_count":0,
        "Challenge_created_time":1676938696104,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/my.guild.ai\/t\/confusion-on-multistep-operations-restarting-substeps-and-copied-files\/998",
        "Challenge_link_count":2,
        "Challenge_participation_count":7,
        "Challenge_readability":13.3,
        "Challenge_reading_time":67.5,
        "Challenge_score_count":3.0,
        "Challenge_sentence_count":33,
        "Challenge_solved_time":525.8622483334,
        "Challenge_title":"Confusion on multistep operations, restarting substeps, and copied files?",
        "Challenge_topic":"Pipeline Configuration",
        "Challenge_topic_macro":"Lifecycle Management",
        "Challenge_view_count":126.0,
        "Challenge_word_count":550,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a class=\"mention\" href=\"\/u\/davzaman\">@davzaman<\/a> It looks like there was a regression and Guild is indeed <em>copying<\/em> resolved operation dependency files. This is not the intended behavior and we\u2019ll fix that ASAP.<\/p>\n<p>As a workaround, avoid copying files by adding <code>target-type<\/code> to your dependency def like this:<\/p>\n<pre><code class=\"lang-yaml\">upstream: {}\n\ndownstream:\n  requires:\n    - operation: upstream\n      target-type: link  # tells Guild to link to the resolved files, not copy\n<\/code><\/pre>\n<p>The <code>downstream<\/code> operation is any operation that requires an upstream run.<\/p>\n<p>Sorry about that! This will make a big difference in disk space for you. We\u2019ll post here when the fix is applied, after which you can remove the explicit <code>target-type<\/code> in your dependencies.<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":11.5,
        "Solution_reading_time":10.34,
        "Solution_score_count":null,
        "Solution_sentence_count":6.0,
        "Solution_word_count":108.0,
        "Tool":"Guild AI"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":18.2166666667,
        "Challenge_answer_count":1,
        "Challenge_body":"Hi,\n\nI am carrying out the OAuth verification in Google Cloud Platform, I received an email that said:\n\"Thanks for your patience while we reviewed your project.\n\nYour project pc-api-XXXXXXXXXXXXXXX-XX has multiple unique domains in the redirect URI and origin URLs, many of which have\u00a0unrelated applications. This is in direct violation of the\u00a0Google API Services: User Data Policy, which requires that projects accurately represent their identity and intent to Google and to our users when they request access to Google user data.\n\nPlease follow the instructions on the\u00a0Google API Console\u00a0to:\n\nCreate new projects\nMigrate your redirect URIs with distinct brands to different projects, and\/or\nEnsure that these projects accurately represent their true identity to Google users\n\nYou can find more information in the\u00a0OAuth Application Verification FAQ. \u00a0To make sure we don't miss your messages, respond directly to this email to continue with the verification process.\"\n\n\n\nI have a web server, which checks the validity (domain-1.com) in-app purchases, and I also have a site with a different domain containing: privacy-policy and terms-of-service (domain-2.com).\n\nMy settings are as follows:\n\nOAuth consent screen:\n- Home page application:\u00a0https:\/\/www.domain-2.com\/\n- Privacy Policy:\u00a0https:\/\/www.domain-2.com\/privacy-policy\/\n- Terms of Service:\u00a0https:\/\/www.domain-2.com\/terms-of-service\/\n\nAuthorized domains:\n- domain-2.com\n- domain-1.com\n\nID client OAuth 2.0 -> Authorized Redirect URIs:\n-\u00a0https:\/\/game.domain-1.com:8443\n\nI have a working service account.\nI have successfully verified all 2 domains.\n\n\nWhere is the mistake?",
        "Challenge_closed_time":1649106480000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1649040900000,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Action-Needed-OAuth-Google-Cloud-platform-multiple-unique\/td-p\/410024\/jump-to\/first-unread-message",
        "Challenge_link_count":4,
        "Challenge_participation_count":1,
        "Challenge_readability":9.8,
        "Challenge_reading_time":21.11,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":17,
        "Challenge_solved_time":18.2166666667,
        "Challenge_title":"Action Needed | OAuth Google Cloud platform | multiple unique domains",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":118.0,
        "Challenge_word_count":233,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"I have found the solution:\n\nI had 2 Google Cloud Platform projects for the same application.\n\nI deleted a Google Cloud Platform.\nI implemented all the configurations of the deleted project in the other project, and it worked!\n\nView solution in original post",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":6.3,
        "Solution_reading_time":3.11,
        "Solution_score_count":3.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":43.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":9.4488722223,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hello, I've set up an Azure endpoint and I'm trying to communicate with it using some old software that can only read decimal notation. The scientific notation the endpoint occasionally delivers is breaking it. Is there a way to configure the endpoint to return only decimal notation? Ideally just with the correct header like &quot;application\/jsonlegacy&quot; or something?<\/p>",
        "Challenge_closed_time":1639637934830,
        "Challenge_comment_count":0,
        "Challenge_created_time":1639603918890,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/665285\/azure-endpoint-in-decimal-notation",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":11.6,
        "Challenge_reading_time":5.24,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":9.4488722223,
        "Challenge_title":"Azure endpoint in decimal notation",
        "Challenge_topic":"Lambda Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":61,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=f32931a2-cf4c-4d9d-bf15-d0fd70f7b4aa\">@Jonathan Horton  <\/a> Returning a decimal value from an endpoint should be possible. I think this depends on the training of the experiment if the ML studio is used. I have an <a href=\"https:\/\/learn.microsoft.com\/en-us\/learn\/modules\/create-clustering-model-azure-machine-learning-designer\/\">experiment<\/a> which returns decimals. You can use a similar setup with Apply transformation module or Apply Math operation if using the newer version of the studio.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/158096-image.png?platform=QnA\" alt=\"158096-image.png\" \/>    <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Solution_comment_count":1.0,
        "Solution_link_count":4.0,
        "Solution_readability":16.7,
        "Solution_reading_time":13.68,
        "Solution_score_count":1.0,
        "Solution_sentence_count":9.0,
        "Solution_word_count":91.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":39.018835,
        "Challenge_answer_count":3,
        "Challenge_body":"<p>I run several agents in one sweep.<br>\nI want to stop a specific agent among them, but I don\u2019t know how to stop it.<\/p>",
        "Challenge_closed_time":1658470957452,
        "Challenge_comment_count":0,
        "Challenge_created_time":1658330489646,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/how-to-kill-a-specific-agent-using-a-command-in-terminal\/2782",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":4.2,
        "Challenge_reading_time":2.16,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":39.018835,
        "Challenge_title":"How to kill a specific agent using a command in terminal?",
        "Challenge_topic":"Hyperparameter Tuning",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":161.0,
        "Challenge_word_count":34,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi <a class=\"mention\" href=\"\/u\/jeongwhanchoi\">@jeongwhanchoi<\/a> , please see this <a href=\"https:\/\/community.wandb.ai\/t\/hp-sweep-correct-way-to-stop-a-specific-agent-and-not-the-entire-sweep\/1173\">post<\/a> for stopping agents. Please let me know if you have additional questions.<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":1.0,
        "Solution_readability":19.0,
        "Solution_reading_time":3.91,
        "Solution_score_count":null,
        "Solution_sentence_count":3.0,
        "Solution_word_count":21.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":85.8609441667,
        "Challenge_answer_count":4,
        "Challenge_body":"<p>See screenshots below. Each model has been trained for 3 epochs so far. They all started from 0, and the info panel shows that the most recent epoch was 2 and \u201cbest\u201d is 0. Looking at the plots though, it looks like all the plots cover epochs 2 through 4.<\/p>\n<p>I\u2019m calling keras <code>model.fit<\/code> with <code>from_epoch=0<\/code>. I\u2019m running inside a <code>ray<\/code> worker so maybe that\u2019s causing some problems?<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/6\/674f340076209ecba401fa6747a6418e31e1f2fe.png\" data-download-href=\"\/uploads\/short-url\/eJUS1BdlLEVdGhqEUtHrBXnO9Q2.png?dl=1\" title=\"Screenshot 2022-12-24 at 8.45.46 am\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/6\/674f340076209ecba401fa6747a6418e31e1f2fe_2_690x288.png\" alt=\"Screenshot 2022-12-24 at 8.45.46 am\" data-base62-sha1=\"eJUS1BdlLEVdGhqEUtHrBXnO9Q2\" width=\"690\" height=\"288\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/6\/674f340076209ecba401fa6747a6418e31e1f2fe_2_690x288.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/6\/674f340076209ecba401fa6747a6418e31e1f2fe.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/6\/674f340076209ecba401fa6747a6418e31e1f2fe.png 2x\" data-dominant-color=\"202121\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshot 2022-12-24 at 8.45.46 am<\/span><span class=\"informations\">788\u00d7329 16.3 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><br>\n<img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/b\/b82b054b707b56a829f444969855ec256c85aee5.png\" alt=\"Screenshot 2022-12-24 at 8.44.29 am\" data-base62-sha1=\"qhe1BKuwPFD8WbPpt39n8Mz0TKR\" width=\"456\" height=\"269\"><\/p>",
        "Challenge_closed_time":1672141317164,
        "Challenge_comment_count":0,
        "Challenge_created_time":1671832217765,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/all-my-plots-start-at-epoch-2\/3593",
        "Challenge_link_count":6,
        "Challenge_participation_count":4,
        "Challenge_readability":14.5,
        "Challenge_reading_time":28.29,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":18,
        "Challenge_solved_time":85.8609441667,
        "Challenge_title":"All my plots start at epoch 2",
        "Challenge_topic":"Metric Logging",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":330.0,
        "Challenge_word_count":135,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi Tom,<\/p>\n<p>Thanks for writing in! So the step is calculated every time there is a call to <code>wandb.log(<\/code>, you can see more details in our docs. If you click on the Edit panel button (a pencil) in the top right corner of the chart, you can select the epoch as X axis. I just checked in your project and it starts in 0. Please let me know if I can help you in any other way!<\/p>\n<p>Best,<br>\nLuis<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":3.0,
        "Solution_reading_time":4.94,
        "Solution_score_count":null,
        "Solution_sentence_count":7.0,
        "Solution_word_count":79.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":0.4231186111,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi,<\/p>\n<p>I want to create a compute cluster in Azure ML that has one vGPU and can scale its vCPU's within the specified min and max. Is this possible? And can someone explain how this can be done or point me to a tutorial?<\/p>\n<p>Thanks in advance!<\/p>",
        "Challenge_closed_time":1680518356223,
        "Challenge_comment_count":0,
        "Challenge_created_time":1680516832996,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1195654\/custom-compute-cluster",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":4.8,
        "Challenge_reading_time":3.41,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":0.4231186111,
        "Challenge_title":"Custom Compute Cluster",
        "Challenge_topic":"Compute Management",
        "Challenge_topic_macro":"Computation Management",
        "Challenge_view_count":null,
        "Challenge_word_count":49,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Unfortunately, you cannot create a compute cluster with a single vGPU that can scale its vCPUs independently in Azure ML. The available VM sizes in Azure are predefined with a fixed ratio of vCPUs, memory, and GPU resources. However, you can create a compute cluster with different VM sizes that can scale within a specified range of nodes, depending on your requirements<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-workspace#create-a-workspace\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-workspace#create-a-workspace<\/a><\/p>\n",
        "Solution_comment_count":2.0,
        "Solution_link_count":1.0,
        "Solution_readability":16.3,
        "Solution_reading_time":7.84,
        "Solution_score_count":1.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":64.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":7.2653166667,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have 2 experiments A and B in Azure MLS classic. I need the web service output of experiment A as one of the web service inputs for experiment B.  Please let me know if it is possible and if yes, how I can do it.<\/p>",
        "Challenge_closed_time":1592433417623,
        "Challenge_comment_count":2,
        "Challenge_created_time":1592407262483,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/37128\/connect-2-separate-experiments-via-webservice-azur",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":7.4,
        "Challenge_reading_time":3.41,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":7.2653166667,
        "Challenge_title":"Connect 2 separate experiments via webservice - Azure MLS Classic",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":54,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>I used export module in experiment A and import module in experiment B to transfer the output of A as input of B.<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":12.3,
        "Solution_reading_time":1.44,
        "Solution_score_count":0.0,
        "Solution_sentence_count":1.0,
        "Solution_word_count":23.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":1.0104277778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I'd like to use GPT-3 for my application.  I understand MS has licensed GPT-3 from OpenAI, and that there is pricing too.  So how do I get to use GPT-3?  <\/p>\n<p>Chris Powell<\/p>",
        "Challenge_closed_time":1605182707940,
        "Challenge_comment_count":0,
        "Challenge_created_time":1605179070400,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/160489\/gpt-3-access",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":4.2,
        "Challenge_reading_time":2.32,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":1.0104277778,
        "Challenge_title":"GPT-3 access",
        "Challenge_topic":"GPU Acceleration",
        "Challenge_topic_macro":"Computation Management",
        "Challenge_view_count":null,
        "Challenge_word_count":34,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=912f72cd-88e9-416f-bbe1-5a7356385053\">@Crispy  <\/a> Thanks for the question, Innovations from our GPT-3 workstreams will be incorporated in later versions of Azure. In the meantime, If you are interested in participation in the OpenAI GPT-3 and Azure Service partnership please fill out this <a href=\"https:\/\/forms.office.com\/Pages\/ResponsePage.aspx?id=v4j5cvGGr0GRqy180BHbRyj5DlT4gqZKgEsfbkRQK5xUQVlSVlJITkxDQkRaOVdESjJGN0dONkQzNy4u\">form<\/a> to submit a request.    <\/p>\n<p>Ignite blog announcement: <a href=\"https:\/\/blogs.microsoft.com\/ai-for-business\/ai-at-scale-ignite\/\">https:\/\/blogs.microsoft.com\/ai-for-business\/ai-at-scale-ignite\/<\/a>    <\/p>\n",
        "Solution_comment_count":2.0,
        "Solution_link_count":2.0,
        "Solution_readability":18.0,
        "Solution_reading_time":9.12,
        "Solution_score_count":0.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":54.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":1.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":8.3539691667,
        "Challenge_answer_count":1,
        "Challenge_body":"I am currently utilizing an ml.c4.2xlarge instance type for a DeepAR use case to run an Automated Model Tuning job. The data consists of 7157 time series with 152 timesteps in the training set and 52 timesteps in the test set respectively. I estimate the run time for the tuning job on this specific instance type to take about 4-5 days. Looking to find out if DeepAR is engineered to take advantage of GPU computing for training and if it would be advisable to use a 'p' or 'g' compute instance instead for faster results. Also would be great for recommendations as to which Accelerated Computing instance would be optimal for this scenario.",
        "Challenge_closed_time":1644892187263,
        "Challenge_comment_count":0,
        "Challenge_created_time":1644862112974,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUnYV-WoO2R3KY4sNEq-Dshw\/optimal-notebook-instance-type-for-deepar-in-aws-sagemaker",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":8.9,
        "Challenge_reading_time":8.53,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":8.3539691667,
        "Challenge_title":"Optimal notebook instance type for DeepAR in AWS Sagemaker",
        "Challenge_topic":"GPU Acceleration",
        "Challenge_topic_macro":"Computation Management",
        "Challenge_view_count":218.0,
        "Challenge_word_count":121,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"(As detailed further on the [algorithm details page](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/deepar.html#deepar-instances)), **yes**, the SageMaker DeepAR algorithm implementation is able to train on GPU-accelerated instances to speed up more challenging jobs. There's also a handy [reference table here](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/common-info-all-im-models.html) listing all the SageMaker built-in algorithms and whether they're likely to be accelerated with GPU.\n\n**However**, to be clear, it shouldn't be the *notebook* instance type that affects this... Typically when training models on SageMaker, the notebook would provide your interactive compute environment but you'd run training in *training jobs* - for example using the [SageMaker Python SDK](https:\/\/sagemaker.readthedocs.io\/en\/stable\/) `Estimator` class as shown in the sample notebooks for DeepAR [electricity](https:\/\/github.com\/aws\/amazon-sagemaker-examples\/blob\/main\/introduction_to_amazon_algorithms\/deepar_electricity\/DeepAR-Electricity.ipynb) and [synthetic](https:\/\/github.com\/aws\/amazon-sagemaker-examples\/blob\/main\/introduction_to_amazon_algorithms\/deepar_synthetic\/deepar_synthetic.ipynb). The instance type you select for training is independent of the instance type you use for your notebook - for example in the electricity notebook it's set as follows:\n\n```python\nestimator = sagemaker.estimator.Estimator(\n    image_uri=image_name,\n    sagemaker_session=sagemaker_session,\n    role=role,\n    train_instance_count=1,  # <-- Setting training instance count\n    train_instance_type=\"ml.c4.2xlarge\",  # <-- Setting training instance type\n    base_job_name=\"deepar-electricity-demo\",\n    output_path=s3_output_path,\n)\n```\n\nSo normally I wouldn't expect you to need to change your *notebook* instance type to speed up training - just edit the configuration of your training job from within the notebook.\n\nSuggesting a particular type is tricky because [DeepAR hyperparameters](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/deepar_hyperparameters.html) like `context_length`, `embedding_dimension`, and `mini_batch_size` will affect how much GPU capacity is needed for a particular run. Since you're coming from CPU-only baseline, I'd maybe suggest to start small with trying out single-GPU `g4dn.xlarge`, `g5.xlarge` or `p3.2xlarge` instances, perhaps starting with the lowest cost-per-hour? You can keep  an eye on your jobs' GPUUtilization and GPUMemoryUtilization metrics to check whether utilization is low on instances like p3 with \"bigger\" GPUs. Increasing `mini_batch_size` should help fill extra capacity on these and complete your job faster, but it will probably affect model convergence - so may need to tune other parameters like `learning_rate` to try and compensate. So considering all of this, you may find trade-offs between speed and total cost, or speed and accuracy, for good hyperparameter combinations on your dataset. Of course you could also scale up to multi-GPU instance types if you'd like to accelerate further.\n\nIf I understood right you're also using SageMaker Automatic Hyperparameter Tuning to search these parameters, something like [this XGBoost notebook](https:\/\/github.com\/aws\/amazon-sagemaker-examples\/blob\/main\/hyperparameter_tuning\/xgboost_random_log\/hpo_xgboost_random_log.ipynb) with the `HyperparameterTuner` class?\n\nIn that case would also mention:\n- Increasing the `max_parallel_jobs` parameter may accelerate the overall run time (by running more of the individual training jobs in parallel) - with a trade-off on how much information is available when each training job in the budget is kicked off.\n- If you're planning to run this training regularly on a dataset which evolves over time, you probably don't need to run HPO each time: Will likely see good results using your previously-optimized hyperparameters, unless something materially changes in the nature of the data and patterns.",
        "Solution_comment_count":0.0,
        "Solution_link_count":7.0,
        "Solution_readability":16.5,
        "Solution_reading_time":50.55,
        "Solution_score_count":1.0,
        "Solution_sentence_count":24.0,
        "Solution_word_count":448.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":20.4316775,
        "Challenge_answer_count":4,
        "Challenge_body":"<p>Hello,  <\/p>\n<p>I understand there was a process how to connect to on-prem sql db from Azure ML studio, but with the transition to the new UI, I don't see the option to connect to the gateway. I have it successfully installed and registered in MS Azure, but from Studio it simply does not offer it as a dataset type when using the Import Data module.  <br \/>\nI can't find any documentation regarding the new UI nor any useful guides for this.  <\/p>\n<p>Would anybody know whether this function is still available in the new studio and if so how can an on-prem gateway be connected?  <\/p>\n<p>Thank you,  <br \/>\nVS<\/p>",
        "Challenge_closed_time":1638351388392,
        "Challenge_comment_count":0,
        "Challenge_created_time":1638277834353,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/646058\/new-azure-ml-vs-on-prem-sql",
        "Challenge_link_count":0,
        "Challenge_participation_count":4,
        "Challenge_readability":7.3,
        "Challenge_reading_time":7.7,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":20.4316775,
        "Challenge_title":"NEW Azure ML vs On-Prem SQL",
        "Challenge_topic":"Dataset Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":null,
        "Challenge_word_count":116,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=63e55afc-7396-4eb1-8eec-945a013b20aa\">@sorcrow  <\/a>     <\/p>\n<p>Thanks for reaching out to us. I just got confirmation from the pm of AML, on-prem SQL is not supported in AML yet, but it's now on our plan.     <\/p>\n<p>I will forward your feedback to product team as well.    <\/p>\n<p>Hope this will help. Please let us know if any further queries.    <\/p>\n<p>------------------------------    <\/p>\n<ul>\n<li> Please don't forget to click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/25904\/accepted-answers.html\">how<\/a>    <\/li>\n<li> Want a reminder to come back and check responses? Here is how to subscribe to a <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/67444\/email-notifications.html\">notification<\/a>    <\/li>\n<li> If you are interested in joining the VM program and help shape the future of Q&amp;A: Here is how you can be part of <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/543261\/index.html\">Q&amp;A Volunteer Moderators<\/a>    <\/li>\n<\/ul>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":5.0,
        "Solution_readability":11.1,
        "Solution_reading_time":18.41,
        "Solution_score_count":0.0,
        "Solution_sentence_count":14.0,
        "Solution_word_count":152.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":135.3537413889,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi all,     <\/p>\n<p>I am following the steps on this tutorial:     <br \/>\nTutorial: Score machine learning models with PREDICT in serverless Apache Spark pools <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/synapse-analytics\/machine-learning\/tutorial-score-model-predict-spark-pool\">https:\/\/learn.microsoft.com\/en-us\/azure\/synapse-analytics\/machine-learning\/tutorial-score-model-predict-spark-pool<\/a>      <\/p>\n<p>I don't know what is the AML_MODEL_URI. I thought it was the REST endpoint or the Swagger URI from the endpoint.     <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/150362-image.png?platform=QnA\" alt=\"150362-image.png\" \/>    <\/p>\n<p>But it is not working. I am getting this error on Synapse: &quot;RuntimeError: Load model failed    <br \/>\nTraceback (most recent call last):&quot;    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/150308-image.png?platform=QnA\" alt=\"150308-image.png\" \/>    <\/p>\n<p>I appreciate you help.    <\/p>\n<p>Kind regards,     <br \/>\nAnaid     <\/p>",
        "Challenge_closed_time":1637667545272,
        "Challenge_comment_count":2,
        "Challenge_created_time":1637180271803,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/631200\/what-is-aml-model-uri-predict-in-serverless-apache",
        "Challenge_link_count":3,
        "Challenge_participation_count":3,
        "Challenge_readability":14.8,
        "Challenge_reading_time":14.6,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":135.3537413889,
        "Challenge_title":"What is AML_MODEL_URI - PREDICT in serverless Apache Spark pools (Synapse & Azure Machine learning AML)",
        "Challenge_topic":"Spark Configuration",
        "Challenge_topic_macro":"Computation Management",
        "Challenge_view_count":null,
        "Challenge_word_count":103,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=4bb27b25-616e-491c-b986-136b5bf96f77\">@Anaid  <\/a>,    <\/p>\n<p>Thanks for the question and using MS Q&amp;A platform.    <\/p>\n<blockquote>\n<p>AML_MODEL_URL is the same name of the model in the ML workspace with (follow the format of <code>aml:\/\/<\/code> + Name of the Model).    <\/p>\n<\/blockquote>\n<p>Example: <code>aml:\/\/sklearn_regression_model:1<\/code> (follow the format of <code>aml:\/\/<\/code> + Name of the Model).    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/153599-image.png?platform=QnA\" alt=\"153599-image.png\" \/>    <\/p>\n<p>Hope this will help. Please let us know if any further queries.    <\/p>\n<p>------------------------------    <\/p>\n<ul>\n<li> Please don't forget to click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/25904\/accepted-answers.html\">how<\/a>    <\/li>\n<li> Want a reminder to come back and check responses? Here is how to subscribe to a <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/67444\/email-notifications.html\">notification<\/a>    <\/li>\n<li> If you are interested in joining the VM program and help shape the future of Q&amp;A: Here is how you can be part of <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/543261\/index.html\">Q&amp;A Volunteer Moderators<\/a>    <\/li>\n<\/ul>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":6.0,
        "Solution_readability":13.2,
        "Solution_reading_time":22.33,
        "Solution_score_count":1.0,
        "Solution_sentence_count":16.0,
        "Solution_word_count":163.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":214.2541211111,
        "Challenge_answer_count":3,
        "Challenge_body":"<p>May I have some samples about anomaly detector with azure machine learning studio? <\/p>",
        "Challenge_closed_time":1665356587116,
        "Challenge_comment_count":0,
        "Challenge_created_time":1664585272280,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1031454\/anomaly-detector-with-azure",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":6.6,
        "Challenge_reading_time":1.5,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":2,
        "Challenge_solved_time":214.2541211111,
        "Challenge_title":"anomaly detector with azure",
        "Challenge_topic":"Hyperparameter Tuning",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":null,
        "Challenge_word_count":17,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=033f3419-75e1-402b-b1ac-8869dd655829\">@minhoo lee  <\/a>     <\/p>\n<p>Sorry about the late response, I think what you are looking for is Anomaly detection in time series analytic. I find some resource you may want to have a look -     <br \/>\n<a href=\"https:\/\/www.youtube.com\/watch?v=Ra8HhBLdzHE\">https:\/\/www.youtube.com\/watch?v=Ra8HhBLdzHE<\/a>    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/archive\/msdn-magazine\/2017\/november\/machine-learning-azure-machine-learning-time-series-analysis-for-anomaly-detection\">https:\/\/learn.microsoft.com\/en-us\/archive\/msdn-magazine\/2017\/november\/machine-learning-azure-machine-learning-time-series-analysis-for-anomaly-detection<\/a>    <\/p>\n<p>Above resource are a little bit old, it is how to achieve the target in Azure Machine Learning.     <\/p>\n<p>Please let me know if you have more questions.    <\/p>\n<p>I hope this helps.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful, thanks a lot.<\/p>\n",
        "Solution_comment_count":1.0,
        "Solution_link_count":2.0,
        "Solution_readability":11.4,
        "Solution_reading_time":13.16,
        "Solution_score_count":0.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":93.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":3.1353469444,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi,     <\/p>\n<p>I am trying to runt the following R Script in an 'Execute R Script' module in Machine Learning Studio.    <\/p>\n<p>data.set &lt;- data.frame(installed.packages())    <br \/>\nmaml.mapOutputPort(&quot;data.set&quot;)    <\/p>\n<p>This script is taken from the 'Get started with Machine Learning Studio (classic)' in R page (<a href=\"https:\/\/learn.microsoft.com\/en-au\/azure\/machine-learning\/classic\/r-get-started#timeseries\">https:\/\/learn.microsoft.com\/en-au\/azure\/machine-learning\/classic\/r-get-started#timeseries<\/a>)    <\/p>\n<p>Whilst it works in ML (classic) I receive the following error when running it in Machine Learning Studio;    <\/p>\n<p>Error in maml.mapOutputPort(&quot;data.set&quot;): could not find function &quot;maml.mapOutputPort&quot;    <\/p>\n<p>What additional config settings are needed to enable R scripts in ML Studio?    <\/p>\n<p>Thank you.    <\/p>",
        "Challenge_closed_time":1627028470716,
        "Challenge_comment_count":0,
        "Challenge_created_time":1627017183467,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/486775\/execute-r-script-in-ml-studio",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":11.0,
        "Challenge_reading_time":11.58,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":3.1353469444,
        "Challenge_title":"Execute R Script in ML Studio",
        "Challenge_topic":"Docker Configuration",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":null,
        "Challenge_word_count":97,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=0c543906-17a1-488d-870d-1c2f45290746\">@Graham Benson  <\/a> For the designer version of the Azure ML studio you could follow the steps in this <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/execute-r-script\">document<\/a> to install the packages and run any R scripts. Unlike the classic version you need to select or create compute for your experiment before the experiment can be submitted.     <\/p>\n<p>Example for installing a package:    <\/p>\n<pre><code>azureml_main &lt;- function(dataframe1, dataframe2){  \n  print(&quot;R script run.&quot;)  \n    \n  if(!require(zoo)) install.packages(&quot;zoo&quot;,repos = &quot;http:\/\/cran.us.r-project.org&quot;)  \n  library(zoo)  \n  # Return datasets as a Named List  \n  return(list(dataset1=dataframe1, dataset2=dataframe2))  \n}  \n<\/code><\/pre>\n",
        "Solution_comment_count":1.0,
        "Solution_link_count":2.0,
        "Solution_readability":14.1,
        "Solution_reading_time":10.99,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":78.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":4.1436111111,
        "Challenge_answer_count":1,
        "Challenge_body":"Is there official documentation showing the **regions** in which **SageMaker AutoPilot** is supported? From my understanding, it should work with the SDK wherever SageMaker is supported, while in the no-code mode only where SageMaker Studio is available. Is this true?  \n\nThanks!",
        "Challenge_closed_time":1596635055000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1596620138000,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QU_7jk19ozQSeyjTAR_D_hEA\/sagemaker-autopilot-regions",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":9.9,
        "Challenge_reading_time":3.85,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":4.1436111111,
        "Challenge_title":"SageMaker AutoPilot Regions",
        "Challenge_topic":"Compute Management",
        "Challenge_topic_macro":"Computation Management",
        "Challenge_view_count":87.0,
        "Challenge_word_count":43,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"SageMaker Autopilot works in all the regions where Amazon SageMaker is available today as noted in this blog post \"[Amazon SageMaker Autopilot \u2013 Automatically Create High-Quality Machine Learning Models With Full Control And Visibility][1]\".  In addition, Autopilot is also integrated with Amazon SageMaker Studio, which is available in us-east-1, us-east-2, us-west-2 and eu-west-1. For a current list of available regions, please check the [AWS Regional Services List](https:\/\/aws.amazon.com\/about-aws\/global-infrastructure\/regional-product-services\/).\n\n\n  [1]: https:\/\/aws.amazon.com\/fr\/blogs\/aws\/amazon-sagemaker-autopilot-fully-managed-automatic-machine-learning\/",
        "Solution_comment_count":0.0,
        "Solution_link_count":2.0,
        "Solution_readability":21.6,
        "Solution_reading_time":8.74,
        "Solution_score_count":0.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":68.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":8.2721991667,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am considering using Personalizer for project and have found limited third party metrics for this service. This one article indicates needing TENS of thousands of hits to get good results.  <\/p>\n<p><a href=\"https:\/\/medium.com\/@EnefitIT\/we-tested-azure-personalizer-heres-what-you-can-expect-8c5ec074a28e\">https:\/\/medium.com\/@EnefitIT\/we-tested-azure-personalizer-heres-what-you-can-expect-8c5ec074a28e<\/a>  <\/p>\n<p>Can any one provide any other data?   <\/p>\n<p>Obviously, over time it will get better, but does it have to get to 10K+ to get good?<\/p>",
        "Challenge_closed_time":1606893531207,
        "Challenge_comment_count":0,
        "Challenge_created_time":1606863751290,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/182318\/training-personalizer",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":12.8,
        "Challenge_reading_time":7.52,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":8.2721991667,
        "Challenge_title":"Training Personalizer",
        "Challenge_topic":"Quota Management",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":null,
        "Challenge_word_count":62,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=bac6bba0-0ba2-419e-b1dd-254f191be319\">@Gregorio Rojas  <\/a> The minimum requirements to have an effective recommendation is to have a minimum of ~1k\/day content-related events. Higher rate of events do help you to provide faster and better recommendations. All the requirements are documented in the official documentation <a href=\"https:\/\/learn.microsoft.com\/en-in\/azure\/cognitive-services\/personalizer\/what-is-personalizer#content-requirements\">page<\/a> of the service. The samples <a href=\"https:\/\/github.com\/Azure-Samples\/cognitive-services-personalizer-samples\">repo<\/a> provides some data along with the quickstart's from the documentation to get started. The service now provides an E0 tier or apprentice mode that helps you test the service and gain confidence to move to a higher tier with production level recommendations.     <\/p>\n",
        "Solution_comment_count":2.0,
        "Solution_link_count":2.0,
        "Solution_readability":14.5,
        "Solution_reading_time":11.34,
        "Solution_score_count":0.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":95.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":4.8515066667,
        "Challenge_answer_count":1,
        "Challenge_body":"This is my code.\n\n```python\nfrom datetime import datetime\nfrom sagemaker.multidatamodel import MultiDataModel\nmme = MultiDataModel(\n    name=\"LV-multi-\" + datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\"),\n    model_data_prefix=model_dir, # 2\uc5d0\uc11c \uad6c\ud55c \ubaa8\ub378\uc774 \ubaa8\uc5ec\uc788\ub294 \ud3f4\ub354(\uacbd\ub85c)!!,\n    model=sagemaker_model,  # \ubaa8\ub378 \uac1d\uccb4 1\uac1c \uc6b0\uc120 \ub123\uae30\n    sagemaker_session=sess\n)\n\npredictor = mme.deploy(\n    initial_instance_count=1,\n    instance_type=\"ml.g4dn.xlarge\"\n)\n```\n\nAnd error message.\nHow can I find Ecr Image(within multi-models=true)?\n```\nClientError: An error occurred (ValidationException) when calling the CreateModel operation: Your Ecr Image 763104351884.dkr.ecr.ap-northeast-2.amazonaws.com\/pytorch-inference:1.8.1-gpu-py3 does not contain required com.amazonaws.sagemaker.capabilities.multi-models=true Docker label(s).\n```",
        "Challenge_closed_time":1660139833476,
        "Challenge_comment_count":0,
        "Challenge_created_time":1660122368052,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUJQBp6A_dSQm1RJ3f8AYMmg\/how-can-make-multi-model-endpoint-with-sagemaker",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":17.4,
        "Challenge_reading_time":10.87,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":12,
        "Challenge_solved_time":4.8515066667,
        "Challenge_title":"How can make multi model endpoint with SageMaker?",
        "Challenge_topic":"Docker Configuration",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":80.0,
        "Challenge_word_count":72,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"Hi there - thanks for opening this thread. Multi-model endpoints are not supported on GPU instance types, see here: https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/multi-model-endpoints.html#multi-model-endpoint-instance\n\nIn order to host a multi-model endpoint, choose a CPU instance type instead. The ECR image for CPUs will contain the required  `com.amazonaws.sagemaker.capabilities.multi-models=true` label, see here: https:\/\/github.com\/aws\/deep-learning-containers\/blob\/master\/pytorch\/inference\/docker\/1.8\/py3\/Dockerfile.cpu",
        "Solution_comment_count":1.0,
        "Solution_link_count":2.0,
        "Solution_readability":19.9,
        "Solution_reading_time":7.08,
        "Solution_score_count":1.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":46.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":4.8680555556,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Can I train models in parallel? Is is possible to train model in parallel on like hyperdrive?<\/p>",
        "Challenge_closed_time":1653922130807,
        "Challenge_comment_count":0,
        "Challenge_created_time":1653904605807,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/869619\/parallel-training",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":9.2,
        "Challenge_reading_time":1.48,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":2,
        "Challenge_solved_time":4.8680555556,
        "Challenge_title":"Parallel training",
        "Challenge_topic":"Hyperparameter Tuning",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":null,
        "Challenge_word_count":18,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=3d6a9d61-6cf9-45d8-870d-2fbbf147f56d\">@Chungsun  <\/a>  Thanks for the question. The max number of parallel tasks is limited by number of cores in the cluster (excluding master node).    <br \/>\nThe demand for parallelism comes from two sources: 1. The cross validation which address multiple combination of train-val datasets &amp; parameters 2. The training algorithm itself which can be parallelized.    <\/p>\n<p>\u2022\tYou can run multiple runs in a distributed fashion across AML clusters, meaning that each cluster node can be running a run in parallel to other nodes running other runs. For instance, that\u2019s what we also do with Pipeline steps, HyperParameter Tunning child runs and for Azure AutoML child runs.    <\/p>\n<p> <a href=\"https:\/\/github.com\/microsoft\/solution-accelerator-many-models\"> https:\/\/aka.ms\/many-models<\/a> is a solution accelerator that will help you walk through to run many models.     <br \/>\nIn the HyperDriveConfig there is AMLcompute max_concurrent_runs map to maximum number of nodes that will be used to run  a hyperparameter tuning run. So there would be 1 execution per node.    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-train-core\/azureml.train.hyperdrive.hyperdriveconfig?view=azure-ml-py\">https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-train-core\/azureml.train.hyperdrive.hyperdriveconfig?view=azure-ml-py<\/a>    <\/p>\n",
        "Solution_comment_count":1.0,
        "Solution_link_count":3.0,
        "Solution_readability":12.1,
        "Solution_reading_time":18.04,
        "Solution_score_count":0.0,
        "Solution_sentence_count":12.0,
        "Solution_word_count":163.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":420.1906525,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Please see the screenshots below. Once it said terminated but without reason:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/140829-screenshot-2021-10-13-221133.png?platform=QnA\" alt=\"140829-screenshot-2021-10-13-221133.png\" \/>    <br \/>\nThe other time there was nothing just stopped:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/140846-screenshot-2021-10-13-215523.png?platform=QnA\" alt=\"140846-screenshot-2021-10-13-215523.png\" \/>    <\/p>",
        "Challenge_closed_time":1635818701492,
        "Challenge_comment_count":2,
        "Challenge_created_time":1634306015143,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/592153\/my-script-stops-running-without-any-message-explai",
        "Challenge_link_count":2,
        "Challenge_participation_count":3,
        "Challenge_readability":16.6,
        "Challenge_reading_time":7.52,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":420.1906525,
        "Challenge_title":"my script stops running without any message explaining the reason",
        "Challenge_topic":"Compute Management",
        "Challenge_topic_macro":"Computation Management",
        "Challenge_view_count":null,
        "Challenge_word_count":39,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello,  <\/p>\n<p>Hope you have solved this issue and we are sorry not seeing your response. Since this issue happened without any error details, support ticket would be the best way to debug that. Please let me know if you still need that. Thanks.  <\/p>\n<p>Regards,  <br \/>\nYutong<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":4.4,
        "Solution_reading_time":3.45,
        "Solution_score_count":0.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":48.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":150.3343644444,
        "Challenge_answer_count":11,
        "Challenge_body":"<p>I can't use ml real-time inference endpoint becouse it's stuck on transitioning status (more than 20 hours). Could you help me with that?<\/p>",
        "Challenge_closed_time":1600780351532,
        "Challenge_comment_count":0,
        "Challenge_created_time":1600239147820,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/96645\/azure-ml-real-time-inference-endpoint-deloyment-st",
        "Challenge_link_count":0,
        "Challenge_participation_count":11,
        "Challenge_readability":8.6,
        "Challenge_reading_time":2.81,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":150.3343644444,
        "Challenge_title":"Azure ML real-time inference endpoint deloyment stuck on transitioning status",
        "Challenge_topic":"Kubernetes Configuration",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":null,
        "Challenge_word_count":32,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>I've chacked in on some different algorithms and the issue appears when i'm using n-grams block for getting features. When i'm using feature hashing for example it looks like working well.<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":8.2,
        "Solution_reading_time":2.42,
        "Solution_score_count":0.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":31.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":26.8941822222,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi All    <\/p>\n<p>I have been working with Azure Machine Learning Studio (Classic) and have always found its integration with Excel super mega useful.    <\/p>\n<p>All I had to do was to get the URI and the API_Key of my web service and paste them on the Azure Machine Learning Add-In, that I had downloaded. Easy and useful.    <\/p>\n<p>However, with the new Azure Machine Learning studio that does not seem possible any more.     <\/p>\n<p>Under the new Azure Machine Learning studio when I deploy a model I get a REST endpoint and that's it? !? I cannot find anywhere the API_key for my web service. I cannot even find a web service section  as such.     <\/p>\n<ol>\n<li> How do I get the API_Key for the web service I need?    <\/li>\n<li> If I get the API_Key could I use it on the Excel Azure Machine Learning add-in. It looks as if this is no longer an option and we need to start using Power BI instead.    <\/li>\n<li>  I have read this interesting post where someone mentions a work around that consist of creating an Excel macro. Is this the best option? <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/236781\/consume-scoreing-api-in-excel.html\">https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/236781\/consume-scoreing-api-in-excel.html<\/a>     <\/li>\n<\/ol>\n<p>Thank you    <\/p>",
        "Challenge_closed_time":1651319301696,
        "Challenge_comment_count":0,
        "Challenge_created_time":1651222482640,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/831512\/new-azure-machine-learning-excel",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":7.8,
        "Challenge_reading_time":16.07,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":14,
        "Challenge_solved_time":26.8941822222,
        "Challenge_title":"New Azure Machine Learning & Excel",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":204,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi, thanks for reaching out. The new AzureML integration with Excel isn't supported at this time. More details are provided on this <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/778717\/replacement-for-azure-ml-classic-excel-add-in.html\">thread<\/a>. The alternative approach would be to use a Client or PowerBI to <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service?tabs=python\">consume<\/a> the model. For future reference, you can find your webservice endpoint and keys under Studio &gt; Endpoints &gt; Endpoint &gt; Consume.    <\/p>\n<p>--please don't forget to <code>Accept Answer<\/code> if the reply is helpful. Thanks.--<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":2.0,
        "Solution_readability":10.8,
        "Solution_reading_time":8.99,
        "Solution_score_count":0.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":72.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":1.8990052778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi, I just started a Pay-As-You-Go account for the Azure Machine Learning training, when I tried to create a budget, I get the error that says &quot;Cost Management budgets is not supported for this account. Please change to another scope.&quot; <\/p>\n<p>I do not know what means or how to go about it.<\/p>\n<p>Please assist me<\/p>\n<p>Jonathan<\/p>",
        "Challenge_closed_time":1674963239872,
        "Challenge_comment_count":0,
        "Challenge_created_time":1674956403453,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1165089\/cost-management-budgets-is-not-supported-for-this",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":5.5,
        "Challenge_reading_time":5.44,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":1.8990052778,
        "Challenge_title":"Cost Management budgets is not supported for this account. Please change to another scope.",
        "Challenge_topic":"Quota Management",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":null,
        "Challenge_word_count":70,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi Jonathan,<\/p>\n<p>Are you able to open Cost Management and set the scope to your Pay-As-You-Go subscription?   For example, open Cost Management Budgets using link below, then click on Scope and set the scope to be the correct subscription:<\/p>\n<p><a href=\"https:\/\/portal.azure.com\/#view\/Microsoft_Azure_CostManagement\/Menu\/%7E\/budgets\/openedBy\/AzurePortal\">https:\/\/portal.azure.com\/#view\/Microsoft_Azure_CostManagement\/Menu\/~\/budgets\/openedBy\/AzurePortal<\/a><\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/af6ac92e-9bab-46c3-ab9e-1c03e404897e?platform=QnA\" alt=\"azure budget scope\" \/><\/p>\n<p>If the above is useful please click Accept Answer.<\/p>\n<p>Thanks.<\/p>\n<p>-TP<\/p>\n",
        "Solution_comment_count":1.0,
        "Solution_link_count":2.0,
        "Solution_readability":16.0,
        "Solution_reading_time":9.46,
        "Solution_score_count":1.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":58.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":39.1253477778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>While opening ml studio (classic) , shows a pop up message like it will retire on 31 August 2024 . Couldn't close the message<\/p>",
        "Challenge_closed_time":1650491049672,
        "Challenge_comment_count":1,
        "Challenge_created_time":1650350198420,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/817073\/cant-open-machine-learning-studio-(classic)",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":5.6,
        "Challenge_reading_time":2.19,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":39.1253477778,
        "Challenge_title":"Can't open Machine learning studio (classic)",
        "Challenge_topic":"Compute Management",
        "Challenge_topic_macro":"Computation Management",
        "Challenge_view_count":null,
        "Challenge_word_count":27,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=065b67d4-0031-46e3-b16b-02416c45d955\">@Asheekha  <\/a>     <\/p>\n<p>Sorry about your experience again, I checked internally about the issue and my colleague confirmed that this is a known issue of Chrome browser, which can be fixed by cleaning the cookie.     <\/p>\n<p>Please try to clean the cookies and I hope this helps! Please let me know if you are still blocked by this issue.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p><em>-Please kindly accept the answer to help the community, thanks a lot.<\/em>    <\/p>\n",
        "Solution_comment_count":3.0,
        "Solution_link_count":0.0,
        "Solution_readability":7.1,
        "Solution_reading_time":6.61,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":79.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":1.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":26.0827755556,
        "Challenge_answer_count":1,
        "Challenge_body":"We are in a process to move all of our IAM users to aws SSO \nwe used to have this policy for sagemaker :\n\n\n\"\n\n```\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"VisualEditor0\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"sagemaker:ListTags\",\n                \"sagemaker:DeleteNotebookInstance\",\n                \"sagemaker:StopNotebookInstance\",\n                \"sagemaker:CreatePresignedNotebookInstanceUrl\",\n                \"sagemaker:DescribeNotebookInstance\",\n                \"sagemaker:StartNotebookInstance\",\n                \"sagemaker:UpdateNotebookInstance\"\n            ],\n            \"Resource\": \"arn:aws:sagemaker:::notebook-instance\/${aws:username}*\"\n        },\n        {\n            \"Sid\": \"VisualEditor1\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"sagemaker:ListNotebookInstanceLifecycleConfigs\",\n                \"sagemaker:ListNotebookInstances\",\n                \"sagemaker:ListCodeRepositories\"\n            ],\n            \"Resource\": \"*\"\n        }\n    ]\n}\n```\n\n\"\n\n\nthis would give access to each user to use his\\hers own notebook\nnow on the new SSO permission set i gave this \n\n\n\n```\n\"\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"glue:CreateScript\",\n                \"secretsmanager:*\"\n            ],\n            \"Resource\": \"*\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"sagemaker:ListTags\",\n                \"sagemaker:DeleteNotebookInstance\",\n                \"sagemaker:StopNotebookInstance\",\n                \"sagemaker:CreatePresignedNotebookInstanceUrl\",\n                \"sagemaker:Describe*\",\n                \"sagemaker:StartNotebookInstance\",\n                \"sagemaker:UpdateNotebookInstance\",\n                \"sagemaker:CreatePresignedDomainUrl\",\n                \"sagemaker:*\"\n            ],\n            \"Resource\": \"arn:aws:sagemaker:::notebook-instance\/*\",\n            \"Condition\": {\n                \"StringEquals\": {\n                    \"aws:ResourceTag\/Owner\": \"${identitystore:UserId}\"\n                }\n            }\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"sagemaker:ListTags\",\n                \"sagemaker:Describe*\",\n                \"sagemaker:StartNotebookInstance\"\n            ],\n            \"Resource\": \"*\"\n        }\n    ]\n}\n\"\n```\n\n\n\n\nthis is what i tried but i cant make it work \nplease assist?",
        "Challenge_closed_time":1658148377804,
        "Challenge_comment_count":0,
        "Challenge_created_time":1658054479812,
        "Challenge_favorite_count":2.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUruheXJHaQVu_S9LIzUyDAw\/policy-that-allows-only-one-sso-user-to-access-a-resource",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":38.9,
        "Challenge_reading_time":22.75,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":2,
        "Challenge_solved_time":26.0827755556,
        "Challenge_title":"Policy that allows only one SSO user to access a resource",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":160.0,
        "Challenge_word_count":128,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"Hello, \n\nI understand that you are currently trying to restrict access to Sagemaker notebook using SSO identity's UserID. \n\nCurrently, I leveraged your provided SSO Permission set and tweaked it out as you can see below, and finally tested it out on AWS SageMaker Console by logging in as an AWS SSO User, and was able to see successful start\/stop\/describing of the SageMaker notebook (with Tags - Owner:UserId) corresponding to the SSO UserId.\n\n```\n{\n\t\"Version\": \"2012-10-17\",\n\t\"Statement\": [\n\t\t{\n\t\t\t\"Effect\": \"Allow\",\n\t\t\t\"Action\": [\n\t\t\t\t\"glue:CreateScript\",\n\t\t\t\t\"secretsmanager:*\"\n\t\t\t],\n\t\t\t\"Resource\": \"*\"\n\t\t},\n\t\t{\n\t\t\t\"Effect\": \"Allow\",\n\t\t\t\"Action\": [\n\t\t\t\t\"sagemaker:ListTags\",\n\t\t\t\t\"sagemaker:DeleteNotebookInstance\",\n\t\t\t\t\"sagemaker:StopNotebookInstance\",\n\t\t\t\t\"sagemaker:CreatePresignedNotebookInstanceUrl\",\n\t\t\t\t\"sagemaker:Describe*\",\n\t\t\t\t\"sagemaker:StartNotebookInstance\",\n\t\t\t\t\"sagemaker:UpdateNotebookInstance\",\n\t\t\t\t\"sagemaker:CreatePresignedDomainUrl\"\n\t\t\t],\n\t\t\t\"Resource\": \"arn:aws:sagemaker:us-east-1:7XXXXXXXXX:notebook-instance\/*\",\n\t\t\t\"Condition\": {\n\t\t\t\t\"StringEquals\": {\n\t\t\t\t\t\"sagemaker:ResourceTag\/Owner\": \"${identitystore:UserId}\"\n\t\t\t\t}\n\t\t\t}\n\t\t},\n\t\t{\n\t\t\t\"Sid\": \"VisualEditor1\",\n\t\t\t\"Effect\": \"Allow\",\n\t\t\t\"Action\": [\n\t\t\t\t\"sagemaker:ListNotebookInstanceLifecycleConfigs\",\n\t\t\t\t\"sagemaker:ListNotebookInstances\",\n\t\t\t\t\"sagemaker:ListCodeRepositories\"\n\t\t\t],\n\t\t\t\"Resource\": \"*\"\n\t\t}\n\t]\n}\n```\n________________________________\n\nHowever, in case if this SSO User tried to stop any other Sagemaker notebooks, which didn't have the tags corresponding to their UserId, then the following errors were observed as expected behavior -\n\n```\nUser: arn:aws:sts::7XXXXXXXXX:assumed-role\/AWSReservedSSO_SageMXXXXXXXXXbe\/test1 is not authorized to perform: sagemaker:StopNotebookInstance on resource: arn:aws:sagemaker:us-east-1:7XXXXXXXXX:notebook-instance\/userachecking because no identity-based policy allows the sagemaker:StopNotebookInstance action\n\nor \n\nUser: arn:aws:sts::7XXXXXXXXX:assumed-role\/AWSReservedSSO_SageMXXXXXXXXXbe\/test1 is not authorized to perform: sagemaker:DescribeNotebookInstance on resource: arn:aws:sagemaker:us-east-1:7XXXXXXXXX:notebook-instance\/Test1Check because no identity-based policy allows the sagemaker:DescribeNotebookInstance action\n```\n\nAlso, please note that unlike your provided IAM policy, your SSO permission set policy was missing the action - `sagemaker:ListNotebookInstances` which also raised an error for not being able to list out the notebook instances on AWS SageMaker Console in my testing. Hence, I had added the appropriate Sagemaker list actions to your permission set as well. \n\n**Additional Information** - \n\na. ${identitystore:UserId} -> Each user in the AWS SSO identity store is assigned a unique UserId. You can view the UserId for your users by using the AWS SSO console and navigating to each user or by using the DescribeUser API action. [1]\n\nb. ListNotebookInstances -> Returns a list of the SageMaker notebook instances in the requester's account in an AWS Region. [2]\n\nc. ResourceTag -> You can use the ResourceTag\/key-name condition key to determine whether to allow access to the resource based on the tags that are attached to the resource. [3][4]\n\nd. sagemaker:ResourceTag\/ -> Filters access by the preface string for a tag key and value pair attached to a resource [5]\n\ne. sagemaker:ResourceTag\/${TagKey} -> Filters access by a tag key and value pair [5]\n____________________________________\nI hope the shared information is insightful to your query. In case, if you have any other queries or concerns regarding AWS SSO or Sagemaker services or any account specific configuration that you would like to discuss, then please feel free to reach out to our team directly by creating a support case with our premium support team. \n\nHave a wonderful day ahead and stay safe. \n____________________________________\nReferences: \n\n[1] https:\/\/docs.aws.amazon.com\/singlesignon\/latest\/userguide\/using-predefined-attributes.html\n\n[2] https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/APIReference\/API_ListNotebookInstances.html\n\n[3] https:\/\/docs.aws.amazon.com\/IAM\/latest\/UserGuide\/access_tags.html\n\n[4] https:\/\/aws.amazon.com\/blogs\/security\/simplify-granting-access-to-your-aws-resources-by-using-tags-on-aws-iam-users-and-roles\/\n\n[5] https:\/\/docs.aws.amazon.com\/service-authorization\/latest\/reference\/list_amazonsagemaker.html#amazonsagemaker-policy-keys",
        "Solution_comment_count":1.0,
        "Solution_link_count":5.0,
        "Solution_readability":18.7,
        "Solution_reading_time":55.47,
        "Solution_score_count":1.0,
        "Solution_sentence_count":18.0,
        "Solution_word_count":437.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":0.5089333333,
        "Challenge_answer_count":7,
        "Challenge_body":"<p>When I finished the training with the offline mode, I use  the following command to upload the trained results to the cloud service.<\/p>\n<pre><code class=\"lang-auto\">wandb  sync   MY_RUN_DIRECTORY\n<\/code><\/pre>\n<p>But I got the KeyError: \u2018run_url\u2019<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/a\/ae1f879a48417b9728aa910bc9e8bb757627f044.jpeg\" data-download-href=\"\/uploads\/short-url\/oQmDb7gGEFmjb7DrMnTKtSiKweM.jpeg?dl=1\" title=\"Screenshot 2023-04-24 202643\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/a\/ae1f879a48417b9728aa910bc9e8bb757627f044_2_690x240.jpeg\" alt=\"Screenshot 2023-04-24 202643\" data-base62-sha1=\"oQmDb7gGEFmjb7DrMnTKtSiKweM\" width=\"690\" height=\"240\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/a\/ae1f879a48417b9728aa910bc9e8bb757627f044_2_690x240.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/a\/ae1f879a48417b9728aa910bc9e8bb757627f044_2_1035x360.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/a\/ae1f879a48417b9728aa910bc9e8bb757627f044_2_1380x480.jpeg 2x\" data-dominant-color=\"181818\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshot 2023-04-24 202643<\/span><span class=\"informations\">1396\u00d7487 192 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>How to solve this question?<\/p>",
        "Challenge_closed_time":1682341145608,
        "Challenge_comment_count":0,
        "Challenge_created_time":1682339313448,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/sync-error\/4267",
        "Challenge_link_count":5,
        "Challenge_participation_count":7,
        "Challenge_readability":27.6,
        "Challenge_reading_time":23.17,
        "Challenge_score_count":3.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":0.5089333333,
        "Challenge_title":"Sync error",
        "Challenge_topic":"Compute Management",
        "Challenge_topic_macro":"Computation Management",
        "Challenge_view_count":93.0,
        "Challenge_word_count":85,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi <a class=\"mention\" href=\"\/u\/lee086824\">@lee086824<\/a> thanks for reporting this issue. There was a regression in wandb <code>v0.14.1<\/code> that would throw this <code>KeyError: 'run_url'<\/code>. Is this your current version, and if so could you please upgrade to our most recent client\/SDK version and try to sync your runs again? Would it work for you?<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":5.0,
        "Solution_reading_time":4.6,
        "Solution_score_count":null,
        "Solution_sentence_count":5.0,
        "Solution_word_count":52.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":0.7837736111,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Would like to upload Jupyter notebooks from different sources like GitHub into my workspace either directly or through my local machine (download locally first and then upload) but I would like to do it programmatically. Either with the AzureML SDK or azure cli  <\/p>",
        "Challenge_closed_time":1651104442392,
        "Challenge_comment_count":0,
        "Challenge_created_time":1651101620807,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/829311\/how-could-i-upload-notebooks-to-my-azureml-workspa",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":9.0,
        "Challenge_reading_time":4.2,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":0.7837736111,
        "Challenge_title":"How could I upload notebooks to my AzureML workspace programatically",
        "Challenge_topic":"Environment Installation",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":null,
        "Challenge_word_count":53,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi, thanks for reaching out. You can use compute instance <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-terminal\">terminal<\/a> in AML notebooks to <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/samples-notebooks#get-samples-on-azure-machine-learning-compute-instance\">clone<\/a> the GitHub repo. There's currently no option to upload notebooks to your workspace programmatically using sdk or cli.<\/p>\n<p>--- *Kindly <em><strong>Accept Answer<\/strong><\/em> if the information helps. Thanks.*<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":2.0,
        "Solution_readability":14.5,
        "Solution_reading_time":7.42,
        "Solution_score_count":0.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":45.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":7.8330322222,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi,   <br \/>\nour team is using AzureML for company's Machine Learning project.  <\/p>\n<p><strong>My question is this:<\/strong>  <\/p>\n<blockquote>\n<p>What's the <strong>price difference<\/strong> between <strong>AzureML<\/strong> and <strong>AzureVM<\/strong> when executing python script?  <\/p>\n<\/blockquote>\n<p>if we use AzureVM, we may use Azure Registry together, i think.    <\/p>\n<p>Because our team is newbie in Azure, we are unfamiliar with this price policy  <\/p>\n<p>thanks.  <\/p>",
        "Challenge_closed_time":1625239530936,
        "Challenge_comment_count":0,
        "Challenge_created_time":1625211332020,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/460862\/price-difference-between-azure-ml-vs-azure-vm",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":7.6,
        "Challenge_reading_time":6.64,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":7.8330322222,
        "Challenge_title":"Price Difference between Azure ML vs Azure VM",
        "Challenge_topic":"Quota Management",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":null,
        "Challenge_word_count":70,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=2088fd6d-27cc-47a6-9fa7-93bb2a8db8a2\">@\ubc15\uc601\ubbfc(Park Young Min)\/\ube44\uc804)DX\ud300  <\/a> Thank you for your query!!!    <\/p>\n<p>Depending upon your requirement there are different possibilities.    <\/p>\n<p>Now as per your statement you want to understand cost associated with Azure ML and Azure VM for running Python Script.    <\/p>\n<p>Now as such for Machine Learning on Azure the Machine Learning surcharges are free and you are only charged for series of VM you use.    <\/p>\n<p>It has been best described in example <a href=\"https:\/\/azure.microsoft.com\/en-in\/pricing\/details\/machine-learning\/#purchase-options\">here<\/a>:    <\/p>\n<p>You will be billed daily. For billing purposes, a day commences at midnight UTC. Bills are generated monthly.    <\/p>\n<p>Training:    <br \/>\nAs a specific example, let\u2019s say you train a model for 100 hours using 10 DS14 v2 VMs on an Basic workspace in US West 2. For a billing month of 30 days, your bill will be as follows:    <\/p>\n<p>Azure VM Charge: (10 machines * $1.196 per machine) * 100 hours = $1,196    <\/p>\n<p>Azure Machine Learning Charge: (10 machines * 16 cores * $0 per core) * 100 hours = $0    <\/p>\n<p>Total: $1,196 + $0 = $1,196    <\/p>\n<p>Inferencing:    <br \/>\nAs a specific example, let\u2019s say you deploy a model for inferencing all day for a 30-day billing month using 10 DS14 v2 VMs in Basic in US West 2. For a billing month of 30 days, your bill will be as follows:    <\/p>\n<p>Azure VM Charge: (10 machines * $1.196 per machine) * (24 hours * 30 days) = $8,611.20    <\/p>\n<p>Azure Machine Learning Charge: (10 machines * 16 cores * $0 per core) * (24 hours * 30 days) = $0    <\/p>\n<p>Total: $8,611.20 + $0 = $8,611.20    <\/p>\n<p>This already includes the use of VM.    <\/p>\n<p>Now the other scenario you are talking about is around deployment of Python App where you might need to make use of containers and the cost associated with them which is a seperate topic.    <\/p>\n<p>Now let us come to your basic question where I do assume that you might want to explore the options available to you for running Python Script in Azure.    <\/p>\n<p>Both Azure Automation and Azure Functions support running Python scripts and do not require the creation of any VM's for same.    <\/p>\n<p>For Azure Function you can refer to <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/azure-functions\/functions-reference-python?tabs=application-level\">this<\/a>. and for cost you can refer to <a href=\"https:\/\/azure.microsoft.com\/en-in\/pricing\/details\/functions\/\">this<\/a>.    <\/p>\n<p>For Azure Automation you can refer to <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/automation\/learn\/automation-tutorial-runbook-textual-python2\">this<\/a>. For cost incurred for automation you can refer to <a href=\"https:\/\/azure.microsoft.com\/en-in\/pricing\/details\/automation\/\">this<\/a> which mostly depends upon the Job you create.    <\/p>\n<p>Now if you check both the option they are not billed particularly for Python script you are running but more around resources being used for what time which you can have a rough estimation from Pricing calculator links mentioned in above links.    <\/p>\n<p>Further now if you want to deploy or run your Python App in Azure there are mainly 4 ways as mentioned <a href=\"https:\/\/azure.microsoft.com\/en-in\/get-started\/python\/\">here<\/a>:    <\/p>\n<ul>\n<li> <a href=\"https:\/\/learn.microsoft.com\/en-in\/azure\/azure-functions\/create-first-function-vs-code-python\">Create a simple Python web app on Azure<\/a>    <\/li>\n<li> <a href=\"https:\/\/learn.microsoft.com\/en-in\/azure\/azure-functions\/tutorial-vs-code-serverless-python\">Build and deploy a serverless Python app<\/a>    <\/li>\n<li> <a href=\"https:\/\/learn.microsoft.com\/en-in\/azure\/notebooks\/use-machine-learning-services-jupyter-notebooks?toc=%2Fpython%2Fazure%2FTOC.json\">Try Azure Machine Learning scenarios in a preconfigured environment<\/a>    <\/li>\n<li> <a href=\"https:\/\/learn.microsoft.com\/en-in\/python\/azure\/?view=azure-python\">See more ways to use Python on Azure<\/a>    <\/li>\n<\/ul>\n<p>You don't need to worry about the Python script incurring you charges but you can check the price of associated resource you are using basically any Azure resource here on <a href=\"https:\/\/azure.microsoft.com\/en-in\/pricing\/calculator\/\">Pricing Calculator<\/a> as well.    <\/p>\n<p>Hope it helps :) !!!    <\/p>\n<p>Please <strong>&quot;Accept as Answer&quot;<\/strong> if it helped so it can help others in community looking for help on similar topics.    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":11.0,
        "Solution_readability":9.8,
        "Solution_reading_time":55.56,
        "Solution_score_count":1.0,
        "Solution_sentence_count":34.0,
        "Solution_word_count":570.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":43.8208166667,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>for a project we are doing azure ml assisted labeling (object detection). we also want to check the model for false positives\/negatives, by receiving the results of the camera and performing manual labeling on it. then we want to take the results from the check and put those in the original dataset that we created using azure labeling. is there a built in function for this or do we need to create this ourselfs?<\/p>",
        "Challenge_closed_time":1676534037760,
        "Challenge_comment_count":1,
        "Challenge_created_time":1676376282820,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1180554\/feedback-loop-azure-ml-possibilities",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":9.4,
        "Challenge_reading_time":5.61,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":43.8208166667,
        "Challenge_title":"feedback loop azure ml possibilities?",
        "Challenge_topic":"Data Labeling",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":null,
        "Challenge_word_count":78,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=6ab37d97-2a03-49e5-8bb2-90417150ab68\">Hamza Outa<\/a> Are you looking to add new labels after some feedback for your systems? <\/p>\n<p>I think there is an option to add new labels to a project by pausing it and then you have the following options:<\/p>\n<ul>\n<li> Start over, removing all existing labels. Choose this option if you want to start labeling from the beginning with the new full set of labels.<\/li>\n<li> Start over, keeping all existing labels. Choose this option to mark all data as unlabeled, but keep the existing labels as a default tag for images that were previously labeled.<\/li>\n<li> Continue, keeping all existing labels. Choose this option to keep all data already labeled as is, and start using the new label for data not yet labeled.<\/li>\n<\/ul>\n<p>Is this what you are looking for? I think the second option might work for you to add new labels if the default tags need to be changed. As per <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-image-labeling-projects#add-new-labels-to-a-project\">documentation <\/a>you can start using the new labels for labeling and the ML assisted labeling will start after a certain threshold is reached or you can manually start an ML assisted training run. I hope this helps!!<\/p>\n",
        "Solution_comment_count":4.0,
        "Solution_link_count":2.0,
        "Solution_readability":9.6,
        "Solution_reading_time":16.69,
        "Solution_score_count":1.0,
        "Solution_sentence_count":12.0,
        "Solution_word_count":195.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":4.2104608333,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hello,  <br \/>\nI am using the example provided in the Machine Learning Studio Docs for extracting Health Entities from a given string.  <br \/>\nThe code is shown below.  <\/p>\n<p>My question is: what is the easiest way to <strong>convert the output result into JSON format<\/strong>?  <\/p>\n<pre><code>from azure.core.credentials import AzureKeyCredential\nfrom azure.ai.textanalytics import TextAnalyticsClient\nimport json\n\ncredential = AzureKeyCredential(&quot;**********************************&quot;)\nendpoint=&quot;https:\/\/eastus.api.cognitive.microsoft.com\/&quot;\n\ntext_analytics_client = TextAnalyticsClient(endpoint, credential)\n\ndocuments = [&quot;Subject is taking 100mg of ibuprofen twice daily&quot;]\n\npoller = text_analytics_client.begin_analyze_healthcare_entities(documents)\nresult = poller.result()\n\ndocs = [doc for doc in result if not doc.is_error]\n\nprint(&quot;Results of Healthcare Entities Analysis:&quot;)\nfor idx, doc in enumerate(docs):\n    for entity in doc.entities:\n        print(&quot;Entity: {}&quot;.format(entity.text))\n        print(&quot;...Normalized Text: {}&quot;.format(entity.normalized_text))\n        print(&quot;...Category: {}&quot;.format(entity.category))\n        print(&quot;...Subcategory: {}&quot;.format(entity.subcategory))\n        print(&quot;...Offset: {}&quot;.format(entity.offset))\n        print(&quot;...Confidence score: {}&quot;.format(entity.confidence_score))\n        if entity.data_sources is not None:\n            print(&quot;...Data Sources:&quot;)\n            for data_source in entity.data_sources:\n                print(&quot;......Entity ID: {}&quot;.format(data_source.entity_id))\n                print(&quot;......Name: {}&quot;.format(data_source.name))\n        if entity.assertion is not None:\n            print(&quot;...Assertion:&quot;)\n            print(&quot;......Conditionality: {}&quot;.format(entity.assertion.conditionality))\n            print(&quot;......Certainty: {}&quot;.format(entity.assertion.certainty))\n            print(&quot;......Association: {}&quot;.format(entity.assertion.association))\n        for relation in doc.entity_relations:\n            print(&quot;Relation of type: {} has the following roles&quot;.format(relation.relation_type))\n        for role in relation.roles:\n            print(&quot;...Role '{}' with entity '{}'&quot;.format(role.name, role.entity.text))\n    print(&quot;------------------------------------------&quot;)\n<\/code><\/pre>",
        "Challenge_closed_time":1650982690652,
        "Challenge_comment_count":2,
        "Challenge_created_time":1650967532993,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/826603\/converting-textanalytics-result-to-json-format",
        "Challenge_link_count":1,
        "Challenge_participation_count":3,
        "Challenge_readability":21.2,
        "Challenge_reading_time":30.67,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":25,
        "Challenge_solved_time":4.2104608333,
        "Challenge_title":"Converting textanalytics result to JSON Format",
        "Challenge_topic":"Batch Transformation",
        "Challenge_topic_macro":"Computation Management",
        "Challenge_view_count":null,
        "Challenge_word_count":167,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=c7e28bb4-3bff-4f66-9bdf-9c63a80436b1\">@Kamran Ali  <\/a> The result does not seem to be directly serializable to JSON. I found a library <a href=\"https:\/\/pypi.org\/project\/jsons\/\">JSONS<\/a> that can do the heavy lifting if you are using python 3.5 or higher.     <\/p>\n<p>Install jsons    <\/p>\n<pre><code>pip install jsons  \n<\/code><\/pre>\n<p>Import JSONS and using jsons.dump() on docs object.    <\/p>\n<pre><code>import jsons #import in the import section  \nprint(jsons.dump(docs)) #Printing the json after docs is created  \n<\/code><\/pre>\n<p>This should give a file of this format in this case. Uploaded the file in .txt format since JSON files cannot be uploaded on Q&amp;A, download the file and rename it to .json     <br \/>\nI hope this helps!!    <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n<p><a href=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/196624-health.txt?platform=QnA\">196624-health.txt<\/a>    <\/p>\n",
        "Solution_comment_count":1.0,
        "Solution_link_count":4.0,
        "Solution_readability":10.4,
        "Solution_reading_time":16.32,
        "Solution_score_count":0.0,
        "Solution_sentence_count":15.0,
        "Solution_word_count":136.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":3.9835497222,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>According to the adoption plan, we need to rebuild everything, there is no quick way to push <a href=\"https:\/\/github.com\/Azure\/Azure-Machine-Learning-Adoption-Framework\">https:\/\/github.com\/Azure\/Azure-Machine-Learning-Adoption-Framework<\/a>    <\/p>\n<p>Am I correct?     <\/p>\n<p>It\u2019s not user friendly if I am not wrong.<\/p>",
        "Challenge_closed_time":1656630131776,
        "Challenge_comment_count":0,
        "Challenge_created_time":1656615790997,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/909961\/azure-machine-learning-adoption-framework",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":12.3,
        "Challenge_reading_time":4.83,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":3.9835497222,
        "Challenge_title":"Azure-Machine-Learning-Adoption-Framework",
        "Challenge_topic":"CloudWatch Monitoring",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":null,
        "Challenge_word_count":33,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=ce84de18-8973-44f3-8101-f191f9216b1f\">@Alexandre  <\/a>    <\/p>\n<p>Thanks for reaching out to us, I have answered this question as well in your other post. I think you are talking about move from Studio classc to Designer, please refer to below document:    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-overview\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-overview<\/a>    <\/p>\n<p>Basically yes for your other thread, you need to rebuild the whole pipeline since we can not copy - paste your orignal structure to Designer.    <\/p>\n<p>I am sorry for the inconveniences since the new studio has a disfferent structure to make this migration not that easy. Please let me know if you have any question during this process, we will provide help.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Solution_comment_count":1.0,
        "Solution_link_count":1.0,
        "Solution_readability":10.3,
        "Solution_reading_time":12.15,
        "Solution_score_count":0.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":126.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":51.3298138889,
        "Challenge_answer_count":4,
        "Challenge_body":"<p>Is it possible to log tables to WANDB from a list \/sequence of dicts where the keys are the column names and the values wandb.Images (for example)?<\/p>\n<p>Once the my tables are logged to WANDB, if they share a column, can I join them in the WANDB web GUI?<\/p>\n<p>Thanks  beforehand!<\/p>",
        "Challenge_closed_time":1657222685552,
        "Challenge_comment_count":0,
        "Challenge_created_time":1657037898222,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/logging-a-table-from-a-list-of-python-dicts\/2701",
        "Challenge_link_count":0,
        "Challenge_participation_count":4,
        "Challenge_readability":4.4,
        "Challenge_reading_time":4.04,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":51.3298138889,
        "Challenge_title":"Logging a table from a list of python dicts",
        "Challenge_topic":"Dataset Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":176.0,
        "Challenge_word_count":59,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a class=\"mention\" href=\"\/u\/fisikillo\">@fisikillo<\/a> ,<\/p>\n<p>Thanks for writing in. We support logging tables using list\/nested listed  with multiple images, see <a href=\"https:\/\/docs.wandb.ai\/guides\/data-vis\/log-tables#create-tables\">here.<\/a> You can also join tables directly from the web GUI.<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":1.0,
        "Solution_readability":12.0,
        "Solution_reading_time":4.03,
        "Solution_score_count":null,
        "Solution_sentence_count":3.0,
        "Solution_word_count":31.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":3.1917047222,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am using model versioning and would like to have different model versions accessible via the same endpoint. Any best practices to access the multiple models from the same endpoint.<\/p>",
        "Challenge_closed_time":1653550999480,
        "Challenge_comment_count":1,
        "Challenge_created_time":1653539509343,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/864579\/accessing-different-model-versions-from-same-endpo",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":9.2,
        "Challenge_reading_time":3.06,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":3.1917047222,
        "Challenge_title":"Accessing different model versions from same endpoint",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":36,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=71c0cf97-895c-43f1-ac54-98e1e9833ae4\">@A-4824  <\/a> Thanks, You may deploy \u201clocally\u201d to a Azure Machine Learning compute instance, by specifying different port # for each version. They are converted to a URL according to the format https:\/\/&lt;compute instance\u2019s name&gt;-port.region.instances.azureml.ms\/score    <\/p>\n<p>Model v1: service_url = <a href=\"https:\/\/azure-ml-compute-instance-name-8001.westeurope.instances.azureml.ms\/score\">https:\/\/azure-ml-compute-instance-name-8001.westeurope.instances.azureml.ms\/score<\/a>    <br \/>\nModel v2: service_url = https:\/\/ azure-ml-compute-instance-name-8002.westeurope.instances.azureml.ms\/score    <\/p>\n<p>There\u2019s sample code in <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-local-container-notebook-vm\">documentation<\/a>. You can specify port to deploy with the following parameter.    <br \/>\ndeployment_config = LocalWebservice.deploy_configuration(port=8001)    <\/p>\n<p>We recommend using the new ML Endpoints (Preview) <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-endpoints\">What are endpoints (preview) - Azure Machine Learning | Microsoft Learn<\/a>.    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":4.0,
        "Solution_readability":18.9,
        "Solution_reading_time":16.0,
        "Solution_score_count":0.0,
        "Solution_sentence_count":9.0,
        "Solution_word_count":87.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":0.0,
        "Answerer_isCse":1.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":37.6475466667,
        "Challenge_answer_count":1,
        "Challenge_body":"Hi,\n\nI have created a simple notebook on SageMaker Studio using the Image \"Tensorflow 2.6 Python 3.8 GPU optimized\". But when I try to run simple statement viz. \"import tensorflow\", I am getting the error \"no module named 'tensorflow'\".\n\nI tried to install 'tensorflow' package using pip from the terminal attached to the image. But it shows the message \"requirement already satisfied\".\n\nAm I missing anything here? Please help.\n\nThanks in advance, \nPraveen",
        "Challenge_closed_time":1640721332675,
        "Challenge_comment_count":0,
        "Challenge_created_time":1640585801507,
        "Challenge_favorite_count":2.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUN63fjMWsT5uVUNn2AIsmhw\/sagemaker-studio-notebook-no-module-named-tensorflow-when-chosen-image-type-tensorflow-2-6-python-3-8-gpu-optimized",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":6.2,
        "Challenge_reading_time":7.12,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":12,
        "Challenge_solved_time":37.6475466667,
        "Challenge_title":"Sagemaker Studio notebook - no module named 'tensorflow' when chosen image type \"Tensorflow 2.6 Python 3.8 GPU optimized\"",
        "Challenge_topic":"TensorBoard Logging",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":343.0,
        "Challenge_word_count":89,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"From the question, I understand that you are trying to use a TensorFlow 2.6 Python 3.8 kernel in SageMaker Studio, but you are unable to import tensorflow.\n\nThe service team are aware of this issue and are actively working on a fix.\n\nMitigation Option\n\nA)  If your use case is version flexible, version other than 2.6 should work.\n \nB) If not, you can try the following as workaround \n\n1. Open a notebook using a Tensorflow 2.6 Python 3.8 kernel\n2. Execute the following line in a notebook cell:\n!sed -i 's|^ *\"python\",|  \"\/usr\/local\/bin\/python\",|g' \/usr\/local\/share\/jupyter\/kernels\/python3\/kernel.json\n3. Stop the kernel\n4. Re-attach the kernel to your notebook.\n\nHope it helps!",
        "Solution_comment_count":2.0,
        "Solution_link_count":0.0,
        "Solution_readability":4.9,
        "Solution_reading_time":8.26,
        "Solution_score_count":1.0,
        "Solution_sentence_count":15.0,
        "Solution_word_count":108.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":10.8978944445,
        "Challenge_answer_count":3,
        "Challenge_body":"<p>Is there any way to return a custom HTTP status code from R Web Service in Azure ML?  <\/p>\n<p>All the examples of entry scripts in documentation return the response body from the scoring function. In Python Web Service, it is possible to return a HTTP response object with a custom status code. However, R's httr library does not seem to have any function to create response objects directly (only via HTTP method objects such as POST, which call a given URL).  <\/p>\n<p>I would like to implement a custom exception handling scheme in R Web Service. Is there any way to return a custom HTTP code from the entry script?  <\/p>\n<p>EDIT: Found this idea on the feedback forum, which suggests that the option is not available in Python Web Service either:  <br \/>\n<a href=\"https:\/\/feedback.azure.com\/forums\/257792-machine-learning\/suggestions\/40122838-make-http-status-codes-controllable-from-your-scor\">https:\/\/feedback.azure.com\/forums\/257792-machine-learning\/suggestions\/40122838-make-http-status-codes-controllable-from-your-scor<\/a>  <\/p>",
        "Challenge_closed_time":1612394092687,
        "Challenge_comment_count":0,
        "Challenge_created_time":1612354860267,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/257156\/how-to-specify-http-response-status-code-in-aml-r",
        "Challenge_link_count":1,
        "Challenge_participation_count":3,
        "Challenge_readability":12.9,
        "Challenge_reading_time":13.94,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":8,
        "Challenge_solved_time":10.8978944445,
        "Challenge_title":"How to specify HTTP response status code in AML R Web Service",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":148,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello Lauri,  <\/p>\n<p>Thanks for the feedback. Yes, we have this product idea in our backlog. I will help to bump up this idea to product group again. ^^  <\/p>\n<p>Regards,  <br \/>\nYutong<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":2.9,
        "Solution_reading_time":2.31,
        "Solution_score_count":0.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":32.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":28.9666666667,
        "Challenge_answer_count":2,
        "Challenge_body":"In our project we use 21 custom trained models to translate from EN to target_language.\n\nLast week 30% of all our requests finishes with timeout! What is the problem?!\n\nHow can you\/we fix it?",
        "Challenge_closed_time":1680180000000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1680075720000,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/AutoML-Translation-30-of-all-our-requests-finishes-with-timeout\/td-p\/538365\/jump-to\/first-unread-message",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":4.3,
        "Challenge_reading_time":3.13,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":28.9666666667,
        "Challenge_title":"AutoML Translation: 30% of all our requests finishes with timeout",
        "Challenge_topic":"Model Persistence",
        "Challenge_topic_macro":"Model Management",
        "Challenge_view_count":88.0,
        "Challenge_word_count":43,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"Hi\u00a0@ochkarik\u00a0\n\nWelcome back to Google Cloud Community.\n\nSetting request timeout (services)\nFor Cloud Run services, the request timeout setting specifies the time within which a response must be returned by services deployed to Cloud Run. If a response isn't returned within the time specified, the request ends and error 504 is returned.\n\nThe timeout is set by default to 5 minutes and can be extended up to 60 minutes.\n\nHere are some articles that might help you:\nhttps:\/\/cloud.google.com\/run\/docs\/configuring\/request-timeout\n\nhttps:\/\/cloud.google.com\/python\/docs\/reference\/storage\/1.39.0\/retry_timeout?_ga=2.21056062.-48059091...\n\nhttps:\/\/cloud.google.com\/translate\/docs\/reference\/rpc\/google.longrunning?_ga=2.25258296.-480590913.1...\n\nView solution in original post",
        "Solution_comment_count":null,
        "Solution_link_count":3.0,
        "Solution_readability":12.4,
        "Solution_reading_time":9.92,
        "Solution_score_count":1.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":86.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":3.1427777778,
        "Challenge_answer_count":1,
        "Challenge_body":"A customer is trying to setup Sagemaker studio. He is following our published instructions to set up using IAM: https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/onboard-iam.html\n\nBut is getting an error: User:  arn:aws:iam:xxxx:user\/user1 is not authorized to perform: sagemaker:CreateDomain on resource: arn:aws:sagemaker: us-east-2:xxxx:domain\/yyyy\n\nHe has admin priviledges on the account and AmazonSageMakerFullAccess. We noticed that the AmazonSageMakerFullAccess policy actually has a limitation. You can perform all sagemaker actions, but not on a resource with arn \u201carn:aws:sagemaker:*:*:domain\/*\u201d. \nWe confirmed there are no other domains in that region with the CLI as you are only allowed one \u2013 so that isn\u2019t blocking.\nAnd aws sagemaker list-user-profiles returns no user profiles. \n\nHas anyone seen that error before or know the workaround? Should he create a custom policy to enable creating domains or would there be any implications of that? Are there specific permissions he should have so as to onboard using IAM?",
        "Challenge_closed_time":1586807470000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1586796156000,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUyWQfPusnSHG6Ujfzx27o1w\/sagemaker-studio-create-domain-error",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":12.0,
        "Challenge_reading_time":13.44,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":11,
        "Challenge_solved_time":3.1427777778,
        "Challenge_title":"Sagemaker Studio - create domain error",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":1584.0,
        "Challenge_word_count":146,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"A user with admin privileges would have access to `\"iam:CreateServiceLinkedRole\"` and `\"sagemaker:CreateDomain\"` actions, unless SCPs or permissions boundaries are involved. However, for the purpose of onboarding Amazon SageMaker Studio with limited permissions, I would grant the user [least privilege](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/security_iam_id-based-policy-examples.html#security_iam_service-with-iam-policy-best-practices) by reviewing [Control Access to the Amazon SageMaker API by Using Identity-based Policies](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/security_iam_id-based-policy-examples.html#api-access-policy) and [Actions, Resources, and Condition Keys for Amazon SageMaker](https:\/\/docs.aws.amazon.com\/IAM\/latest\/UserGuide\/list_amazonsagemaker.html) documentation:\n\n    {\n        \"Effect\": \"Allow\",\n        \"Action\": \"sagemaker:CreateDomain\",\n        \"Resource\": \"arn:aws:sagemaker:<REGION>:<ACCOUNT-ID>:domain\/*\"\n    }\n\nNOTE: An AWS account is limited to one Domain, per region, see [CreateDomain](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/APIReference\/API_CreateDomain.html).\n\n    {\n        \"Effect\": \"Allow\",\n        \"Action\": \"iam:CreateServiceLinkedRole\",\n        \"Resource\": \"*\",\n        \"Condition\": {\n            \"StringEquals\": {\n                \"iam:AWSServiceName\": \"sagemaker.amazonaws.com\"\n            }\n        }\n    }\n\nCheers!",
        "Solution_comment_count":0.0,
        "Solution_link_count":4.0,
        "Solution_readability":28.1,
        "Solution_reading_time":17.07,
        "Solution_score_count":1.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":91.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":10.7709561111,
        "Challenge_answer_count":1,
        "Challenge_body":"Hi all,\n\nI am asking if it's possible to use `framework processor` inside a `sagemaker pipeline`.\n\nI am asking because the to submit the source_dir for the framework processor, we have to do so when calling the .run() method, when wrapping the processor inside a `sagemaker.workflow.steps.ProcessingStep`, there isn't an available argument to specify the `source_dir`.\n\nThank you!\nBest,\nRuoy",
        "Challenge_closed_time":1652383066859,
        "Challenge_comment_count":0,
        "Challenge_created_time":1652344291417,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUbY_u2lSORnmomHzZsGOZAA\/sagemaker-framework-processor-compatibility-with-sagemaker-pipelines",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":10.7,
        "Challenge_reading_time":5.77,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":10.7709561111,
        "Challenge_title":"SageMaker framework processor compatibility with sagemaker pipelines",
        "Challenge_topic":"Pipeline Configuration",
        "Challenge_topic_macro":"Lifecycle Management",
        "Challenge_view_count":379.0,
        "Challenge_word_count":65,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"You can do this with the latest version of the sagemaker sdk 2.89.0\n\n```\nfrom sagemaker.workflow.pipeline_context import PipelineSession\n\nsession = PipelineSession()\n\ninputs = [\n    ProcessingInput(\n    source=\"s3:\/\/my-bucket\/sourcefile\", \n    destination=\"\/opt\/ml\/processing\/inputs\/\",),\n]\n\nprocessor = FrameworkProcessor(...)\n\nstep_args = processor.run(inputs=inputs, source_dir=\"...\")\n\nstep_sklearn = ProcessingStep(\n    name=\"MyProcessingStep\",\n    step_args=step_args,\n)\n```",
        "Solution_comment_count":1.0,
        "Solution_link_count":0.0,
        "Solution_readability":18.2,
        "Solution_reading_time":6.02,
        "Solution_score_count":0.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":32.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":8.9666666667,
        "Challenge_answer_count":1,
        "Challenge_body":"Hi everyone I have a step in vertex ai pipelines that looks like this:\n\ntranscribe_task = transcribe_audios(audio_files=download_task.output)\ntranscribe_task.set_cpu_limit(\"2\").set_memory_limit(\n\"8G\"\n).add_node_selector_constraint(\"NVIDIA_TESLA_T4\").set_gpu_limit(\"1\")\n\nyet that task is not executed due to:\n\ncom.google.cloud.ai.platform.common.errors.AiPlatformException: code=RESOURCE_EXHAUSTED, message=The following quota metrics exceed quota limits:\u00a0aiplatform.googleapis.com\/custom_model_training_nvidia_t4_gpus, cause=null; Failed to create custom job for the task.\n\nBut that quota is not listed anywhere in the quota manager, how can I enable GPU in Vertex AI pipelines?",
        "Challenge_closed_time":1675667340000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1675635060000,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Quota-not-listed-in-Vertex-AI-pipelines\/td-p\/518466\/jump-to\/first-unread-message",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":15.1,
        "Challenge_reading_time":9.45,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":8.9666666667,
        "Challenge_title":"Quota not listed in Vertex AI pipelines?",
        "Challenge_topic":"Quota Management",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":167.0,
        "Challenge_word_count":72,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"I solved it, it is quite not easy to find:\n\nSo for anyone with the same problem, go to Quotas and use the following filters:\n\n\n\nHope it can help anyone\n\nView solution in original post",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":13.4,
        "Solution_reading_time":2.12,
        "Solution_score_count":1.0,
        "Solution_sentence_count":1.0,
        "Solution_word_count":35.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_isAwsEmployee":0.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":7.3261111111,
        "Challenge_answer_count":2,
        "Challenge_body":"Hi,  \n  \nI've tried following a tutorial to use AWS sagemaker in script mode from my local linux VM, but I can't even get the basics working.  \n  \nSteps:  \n- \u279c  ~> python3 --version  \nPython 3.6.9  \n  \n- \u279c  ~> pip3 install sagemaker  \n...  \nSuccessfully installed boto3-1.14.42 botocore-1.17.42 importlib-metadata-1.7.0 packaging-20.4 protobuf3-to  \n-dict-0.1.5 s3transfer-0.3.3 sagemaker-2.3.0 smdebug-rulesconfig-0.1.4 zipp-3.1.0  \n  \n\u279c  ~> cat sagemaker.py  \nimport sagemaker  \nimport boto3  \n  \nsess = sagemaker.Session()  \n  \n\u279c  ~> python3 sagemaker.py  \nTraceback (most recent call last):  \n  File \"sagemaker.py\", line 1, in <module>  \n    import sagemaker  \n  File \"~\/sagemaker.py\", line 4, in <module>  \n    sess = sagemaker.Session()  \nAttributeError: module 'sagemaker' has no attribute 'Session'  \n  \nI also have the aws cli (version 2) installed, and configured using IAM credentials that have full rights, so that's not related.  \n  \nWhat is the problem with my python sdk install? TIA",
        "Challenge_closed_time":1597425118000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1597398744000,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUZe9xubsHTuyRPCUGXvi40Q\/sagemaker-python-sdk-installation-troubles",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":9.0,
        "Challenge_reading_time":12.15,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":14,
        "Challenge_solved_time":7.3261111111,
        "Challenge_title":"Sagemaker python sdk installation troubles",
        "Challenge_topic":"Environment Installation",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":283.0,
        "Challenge_word_count":120,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"You should name your script something else than sagemaker.py, since python will look in the current directory first for a module when doing an import, so the import sagemaker will not import the Sagemaker SDK, but your script.",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":8.3,
        "Solution_reading_time":2.78,
        "Solution_score_count":0.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":38.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":30.8515688889,
        "Challenge_answer_count":1,
        "Challenge_body":"I want to train and build the model in Sagemaker studio and then be able to export the model as a container image to ECR, so I can use the model in external platform by sharing the ECR image to another account where I Can create container with the image  from ECR",
        "Challenge_closed_time":1663369533112,
        "Challenge_comment_count":0,
        "Challenge_created_time":1663258467464,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUZHWz5-hpSc-80dEIkuxwQw\/how-to-export-tresained-models-to-ecr-as-container-image",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":14.0,
        "Challenge_reading_time":3.8,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":2,
        "Challenge_solved_time":30.8515688889,
        "Challenge_title":"How to export tresained models to ECR as container image",
        "Challenge_topic":"Model Persistence",
        "Challenge_topic_macro":"Model Management",
        "Challenge_view_count":68.0,
        "Challenge_word_count":61,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"The models you train in SageMaker are stored in S3 as .tar.gz files that you can use to deploy to an endpoint, or even test locally (extracting the model file from the tar file). \nIf you are using a built-in algorithm, you can share the .tar.gz file to the second account and deploy the model in the second account, since built-in algorithm containers can be accessed from any AWS account. \n\nIf you are using a custom training image ([docs here](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/adapt-training-container.html)), you can push this image to ECR and allow a [second account to pull the image](https:\/\/aws.amazon.com\/premiumsupport\/knowledge-center\/secondary-account-access-ecr\/) and then use the image with the model that you have trained. However, note that Studio at this time does not support building Docker images out of the box. You can use [SageMaker Notebook Instances](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/nbi.html) instead.\n\nI would recommend keeping the model (.tar.gz) and the image (Docker) separate, since you can easily retrain and deploy the newer versions of models without updating the image every single time.",
        "Solution_comment_count":1.0,
        "Solution_link_count":3.0,
        "Solution_readability":10.2,
        "Solution_reading_time":14.47,
        "Solution_score_count":0.0,
        "Solution_sentence_count":11.0,
        "Solution_word_count":163.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":1.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":1.9680911111,
        "Challenge_answer_count":1,
        "Challenge_body":"Hello, I'd like to deploy SageMaker's built-in algorithm, BlazingText model on Fargate instead of Sagemaker endpoint. So, I tried to make an ECS task using BlazingText docker path. Here is my CDK code for it.\n\nconst loadBalancedFargateService = new ecsPatterns.ApplicationLoadBalancedFargateService(this, 'Service', {\n            memoryLimitMiB: 1024,\n            desiredCount: 1,\n            cpu: 512,\n            taskImageOptions: {\n              image: ecs.ContainerImage.fromRegistry(\"811284229777.dkr.ecr.us-east-1.amazonaws.com\/blazingtext:1\"),\n            },\n          });\n\nHowever, I got an error: \nCannotPullContainerError: inspect image has been retried 1 time(s): failed to resolve ref \"811284229777.dkr.ecr.us-east-1.amazonaws.com\/blazingtext:1\": pulling from host 811284229777.dkr.ecr.us-east-1.amazonaws.com failed with status code [manifests 1]...\n\nIs it impossible to pull docker container of sagemaker built-in algorithm from ECS?",
        "Challenge_closed_time":1651328900608,
        "Challenge_comment_count":0,
        "Challenge_created_time":1651321815480,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUCbp7XzQSSPSH200r45m4Uw\/ecs-load-container-image-from-sagemaker-built-in-algorithm-docker-path",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":14.2,
        "Challenge_reading_time":12.15,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":10,
        "Challenge_solved_time":1.9680911111,
        "Challenge_title":"ECS load container image from sagemaker built-in algorithm docker path",
        "Challenge_topic":"Docker Configuration",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":254.0,
        "Challenge_word_count":99,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"To my knowledge, no - it's not generally possible to pull the [built-in algorithm](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/algos.html) containers outside SageMaker: Your easiest route would probably just be to deploy the model on SageMaker and integrate your other containerized tasks to call the SageMaker endpoint.\n\nIt's maybe worth mentioning that the [framework containers](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/docker-containers-prebuilt.html) for custom\/script-mode modelling (e.g. the [AWS DLCs](https:\/\/github.com\/aws\/deep-learning-containers) for PyTorch\/HuggingFace\/etc) are not subject to this restriction (can check you should even be able to pull them locally): So if you were to use those to implement a customized text processing model I think you should be able to deploy it on ECS if needed. Of course this'd mean a more initial build and later maintenance effort though.",
        "Solution_comment_count":1.0,
        "Solution_link_count":3.0,
        "Solution_readability":13.2,
        "Solution_reading_time":11.62,
        "Solution_score_count":1.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":114.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":15.0818666667,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi all;    <\/p>\n<p>Is there an Azure ML resource\/program that can be fed a transcript of a meeting and from it can:    <\/p>\n<ol>\n<li> Create a written summary of the meeting.    <\/li>\n<li> Create a list of action items promised in the meeting.    <\/li>\n<li> Create a list of conclusions reached in the meeting.    <\/li>\n<\/ol>\n<p>The service <a href=\"https:\/\/otter.ai\/\">Otter<\/a> does a lot (all?) of this. <a href=\"https:\/\/www.fiercehealthcare.com\/tech\/microsoft-and-nuance-developing-ambient-ai-technologies-to-tackle-doctors-administrative-tasks\">Microsoft\/Nuance<\/a> has something similar too.    <\/p>\n<p>thanks - dave    <\/p>",
        "Challenge_closed_time":1671619392127,
        "Challenge_comment_count":2,
        "Challenge_created_time":1671565097407,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1136479\/does-the-azure-ml-stack-have-functionality-to-summ",
        "Challenge_link_count":2,
        "Challenge_participation_count":3,
        "Challenge_readability":8.7,
        "Challenge_reading_time":8.68,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":8,
        "Challenge_solved_time":15.0818666667,
        "Challenge_title":"Does the Azure ML stack have functionality to summarize meetings?",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":86,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=2e000d14-7fa3-4e41-9299-8306855b228f\">@David Thielen  <\/a>     <\/p>\n<p>I have checked with the document and pm, there is a preview feature I think is very suitable for your senario - document and conversation summarization (preview) from Azure Language Service.    <\/p>\n<p><strong>Summarization<\/strong> is one of the features offered by Azure Cognitive Service for Language, a collection of <strong>machine learning and AI algorithms<\/strong> in the cloud for developing intelligent applications that involve written language. Conversation summarization supports the following features:    <\/p>\n<ol>\n<li> Issue\/resolution summarization: A call center specific feature that gives a summary of issues and resolutions in conversations between customer-service agents and your customers.    <\/li>\n<li> Chapter title summarization: Gives suggested chapter titles of the input conversation.    <\/li>\n<li> <strong>Narrative summarization: Gives call notes, meeting notes or chat summaries of the input conversation.<\/strong>    <\/li>\n<\/ol>\n<p>I think the <strong>narrative summarization<\/strong> is what you are looking for. Please check on below document to see if that is what you are looking for -    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/language-service\/summarization\/overview?tabs=conversation-summarization\">https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/language-service\/summarization\/overview?tabs=conversation-summarization<\/a>    <\/p>\n<p>This is the quickstart session for you, but since this feature is new and under preview, you need to send a request for the access -     <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/language-service\/summarization\/quickstart?pivots=rest-api&amp;tabs=conversation-summarization\">https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/language-service\/summarization\/quickstart?pivots=rest-api&amp;tabs=conversation-summarization<\/a>    <\/p>\n<p>I hope this helps.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support our community, thanks a lot.    <\/p>\n",
        "Solution_comment_count":1.0,
        "Solution_link_count":2.0,
        "Solution_readability":18.1,
        "Solution_reading_time":27.96,
        "Solution_score_count":0.0,
        "Solution_sentence_count":11.0,
        "Solution_word_count":217.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":15.64844,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I came across <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-with-datasets#mount-vs-download\">this page<\/a> which describes how to work with AML datasets. I'm specifically interested in mounting. It states that &quot;Mounting is supported for Linux-based computes&quot;. Is there no way to do this on Windows?    <\/p>\n<p>Thanks,    <br \/>\nYordan    <\/p>",
        "Challenge_closed_time":1653382797127,
        "Challenge_comment_count":0,
        "Challenge_created_time":1653326462743,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/860774\/mount-aml-dataset-on-windows",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":7.0,
        "Challenge_reading_time":5.32,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":15.64844,
        "Challenge_title":"Mount AML dataset on Windows",
        "Challenge_topic":"Dataset Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":null,
        "Challenge_word_count":46,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>@YordanZaykov-7763 Yes, currently this is only supported for linux based computes for Azure ML. Windows only supports download option.    <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":2.0,
        "Solution_readability":16.3,
        "Solution_reading_time":6.76,
        "Solution_score_count":1.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":46.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":56.2932952778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have an Azure Data factory that receives data from a service bus and then I want to classify my data with an ML model.  <\/p>\n<p>Is there any solution to save and load the ML model on the Azure Data Factory pipeline?  <\/p>\n<p>For your information, I want to use cloud base solution. I don't use the PICKLE library. <\/p>",
        "Challenge_closed_time":1623860467256,
        "Challenge_comment_count":0,
        "Challenge_created_time":1623657811393,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/434449\/how-to-save-and-load-ml-model-with-azure-data-fact",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":6.5,
        "Challenge_reading_time":4.48,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":56.2932952778,
        "Challenge_title":"How to save and load ML model with Azure Data Factory",
        "Challenge_topic":"Model Persistence",
        "Challenge_topic_macro":"Model Management",
        "Challenge_view_count":null,
        "Challenge_word_count":71,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=b5c4f434-7ffe-0003-0000-000000000000\">@Mohsen Akhavan  <\/a>,    <br \/>\nThanks for the ask and using the Microsoft Q&amp;A platform  .    <\/p>\n<p>I think you can use the machine learning activity . Read and watch the video <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/data-factory\/transform-data-machine-learning-service\">here<\/a> .    <\/p>\n<p>The challenge in your case is the data is in EH and at this time ADF cannot read EH data . I suggest you to use a Azure stream analytics jobs and read the data from EH and write it to SQL or blob . Once the data is in any of these two sources ADF can be used to read the data .    <\/p>\n<p>Please do let me know how it goes .    <br \/>\nThanks     <br \/>\nHimanshu    <br \/>\nPlease do consider clicking on <strong>&quot;Accept Answer&quot;<\/strong> and <strong>&quot;Up-vote&quot;<\/strong> on the post that helps you, as it can be beneficial to other community members    <\/p>\n",
        "Solution_comment_count":2.0,
        "Solution_link_count":1.0,
        "Solution_readability":7.9,
        "Solution_reading_time":11.53,
        "Solution_score_count":0.0,
        "Solution_sentence_count":9.0,
        "Solution_word_count":134.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":12.4379594444,
        "Challenge_answer_count":3,
        "Challenge_body":"<p>Hello Microsoft Q&amp;A,\nwhen running azure ml pipelines I got the following error:\n&quot; permission denied when access stream. Reason: Some(This request is not authorized to perform this operation using this permission.) &quot;\nWhen I checked the data assets for the pipeline, I got the follwoing error:<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/37d53c8a-2bec-4fa5-b769-3d57010a96f7?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>The Azure machine learning workspace is inside a vnet and I'm using a service principal for the data store authentification:\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/aa1dd74a-f306-4ddc-a8ef-97b8fc6ae98a?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>I allready granted the workspace managed identity AND the service principal the reader role for ALL private endpointes. Moreover I checked all other permissions, for example that the workspace managed identiy has the blob storage reader role for the adls gen2 storage.\nDoes this has something to do with these changes:\n &quot;Azure Machine Learning Network Isolation Changes with Compute Instance and Compute Cluster&quot;<\/p>\n<p>Could you please help me.<\/p>",
        "Challenge_closed_time":1681272887700,
        "Challenge_comment_count":0,
        "Challenge_created_time":1681228111046,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1220935\/azure-ml-workspace-unable-to-get-access-token-for",
        "Challenge_link_count":2,
        "Challenge_participation_count":3,
        "Challenge_readability":13.2,
        "Challenge_reading_time":16.0,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":8,
        "Challenge_solved_time":12.4379594444,
        "Challenge_title":"Azure ML Workspace - Unable to get access token for ADLS Gen2",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":154,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello @Lukas\nThanks for reaching out to us. I haven't seen the same error, but based on some researches and my personal experience, the error message you're seeing indicates that the user or service principal running the Azure ML pipeline does not have sufficient permissions to access the data assets required by the pipeline. It's possible that the recent changes to Azure Machine Learning Network Isolation could be a factor in this issue.<\/p>\n<p>Here are some steps you can take to further troubleshoot the issue:<\/p>\n<p>Check the credentials being used to access the data assets: Verify that the credentials being used to access the data assets are correct and have sufficient permissions to read the data. You can check this by attempting to manually access the data assets using the same credentials and seeing if you encounter any issues.<\/p>\n<p>Verify RBAC permissions: Make sure that the user or service principal running the pipeline has the necessary RBAC permissions to access the data assets. You can check this by reviewing the access policies and roles associated with the data assets, and making sure that the user or service principal is included in the appropriate role(s) with sufficient access.<\/p>\n<p>Check firewall and network settings: If the data assets are hosted in a private network, make sure that the firewall and network settings allow the pipeline to access the data. You may need to configure virtual network peering or VPN connections to enable access.<\/p>\n<p>Review pipeline configuration: Double-check the pipeline configuration to ensure that the correct data asset paths and permissions are specified. You can also try re-creating the pipeline from scratch to see if that resolves the issue.<\/p>\n<p>Review the Network Isolation changes: Review the recent Azure Machine Learning Network Isolation changes and ensure that they are not impacting your pipeline. You may need to update your pipeline configuration to account for any changes in network isolation.<\/p>\n<p>If none of the above steps resolve the issue, you can contact Microsoft support for further assistance. Please raise a support ticket if you have a support plan, please let us know if you have tried all above items but nothing works, I am happy to enable you a free ticket for this issue. <\/p>\n<p>I hope this helps! Let me know if you have any further questions.<\/p>\n<p>Regards,\nYutong<\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":12.0,
        "Solution_reading_time":30.78,
        "Solution_score_count":0.0,
        "Solution_sentence_count":18.0,
        "Solution_word_count":401.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":0.7333333333,
        "Challenge_answer_count":1,
        "Challenge_body":"Customer wants to configure the SageMaker Ground Truth interface seen by the workers such that the labeler can navigate to previous or next tasks. For example, if one is labelling images, they could skip the current image, label the next one, and then return to the skipped image. The Ground Truth interface does not seem to have this capability. Is there an option for it that I missed? I could not find anything about it here: https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/sms-data-labeling.html.",
        "Challenge_closed_time":1596058119000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1596055479000,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QU_S8ylg4UQdKh76o3zp3dWQ\/sagemaker-groundtruth-interface-option-to-skip-a-task-and-then-return",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":8.9,
        "Challenge_reading_time":7.12,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":0.7333333333,
        "Challenge_title":"SageMaker GroundTruth Interface - option to skip a task and then return",
        "Challenge_topic":"Data Labeling",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":137.0,
        "Challenge_word_count":87,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":1.0,
        "Poster_isModerator":0.0,
        "Solution_body":"Currently, there is no functionality to skip a task and go back to it later. However, you could add a field like\n\n `[ ] this task was skipped` \n\nwhere the annotator could check the box for those items to be reviewed and processed at another time. ",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":9.5,
        "Solution_reading_time":2.89,
        "Solution_score_count":0.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":44.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":17.2132430556,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>Hey, I am trying to build ML pipelines using the python-sdk. I am wondering if I can use those pre-defined modules from Designer when building pipelines using the python-sdk?<\/p>",
        "Challenge_closed_time":1636079210008,
        "Challenge_comment_count":0,
        "Challenge_created_time":1636017242333,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/615328\/is-it-possible-to-use-pre-defined-designer-modules",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":9.8,
        "Challenge_reading_time":3.44,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":17.2132430556,
        "Challenge_title":"Is it possible to use pre-defined designer modules when building pipelines using python-sdk?",
        "Challenge_topic":"Pipeline Configuration",
        "Challenge_topic_macro":"Lifecycle Management",
        "Challenge_view_count":null,
        "Challenge_word_count":41,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=e1f49cb3-80a0-42db-98e1-dae1d9419473\">@Chris-2395  <\/a>     <\/p>\n<p>Thanks for reaching out to us. But this currently is under development and we have no exact ETA for it.    <\/p>\n<p>Hope this will help. Please let us know if any further queries.    <\/p>\n<p>------------------------------    <\/p>\n<ul>\n<li> Please don't forget to click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/25904\/accepted-answers.html\">how<\/a>    <\/li>\n<li> Want a reminder to come back and check responses? Here is how to subscribe to a <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/67444\/email-notifications.html\">notification<\/a>    <\/li>\n<li> If you are interested in joining the VM program and help shape the future of Q&amp;A: Here is how you can be part of <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/543261\/index.html\">Q&amp;A Volunteer Moderators<\/a>    <\/li>\n<\/ul>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":5.0,
        "Solution_readability":11.7,
        "Solution_reading_time":17.35,
        "Solution_score_count":1.0,
        "Solution_sentence_count":14.0,
        "Solution_word_count":133.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":1.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":1.8288888889,
        "Challenge_answer_count":1,
        "Challenge_body":"Per the [SageMaker Environment Variables][1] doc, algorithms should save model artifacts to the folder prescribed by `SM_MODEL_DIR`.\n\nThe [SageMaker Containers doc][2] describes additional environment variables, including `SM_OUTPUT_DATA_DIR` to write non-model training artifacts.\n\n...But how should the algorithm determine if checkpointing has been requested?\n\nThe [Using Checkpoints in Amazon SageMaker][3] doc only specifies a default local path to save them to, and I can't see any environment variables that would indicate whether or not to checkpoint. I've seen one piece of code checking for the **existence** of that default local path, but not convinced anybody's actually checked to see whether it works (is present when checkpointing is requested and absent when not).\n\nIt's good to parameterize Checkpointing to avoid wasting EBS space (and precious seconds of IO) in jobs when it's not needed; and by the conventions for other I\/O like model and data folders I would assume SageMaker to have a specific mechanism to pass this instruction, rather than just defining an algo hyperparameter?\n\n  [1]: https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/docker-container-environmental-variables-user-scripts.html\n  [2]: https:\/\/github.com\/aws\/sagemaker-containers\n  [3]: https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/model-checkpoints.html",
        "Challenge_closed_time":1576730886000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1576724302000,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUmOFbuaH9RPSY4kH2t1dFcQ\/how-should-a-custom-sagemaker-algorithm-determine-if-checkpoints-are-enabled",
        "Challenge_link_count":3,
        "Challenge_participation_count":1,
        "Challenge_readability":14.6,
        "Challenge_reading_time":18.13,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":1.8288888889,
        "Challenge_title":"How should a custom SageMaker algorithm determine if checkpoints are enabled?",
        "Challenge_topic":"Model Persistence",
        "Challenge_topic_macro":"Model Management",
        "Challenge_view_count":159.0,
        "Challenge_word_count":180,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":1.0,
        "Poster_isModerator":0.0,
        "Solution_body":"Hi,\n\nFor custom Sagemaker containers or  deep learning frameworks, I tend to do this..and it works\n\n\nThis example is for pytorch I have tried\n\n-  entry point file: \n   \n   ```python\n   # 1. Define a custom argument, say checkpointdir\n    parser.add_argument(\"--checkpointdir\", help=\"The checkpoint dir\", type=str,\n                        default=None)\n   # 2. You can additional params for checkpoint frequency etc\n\n   # 3. Code for checkpointing\n   if checkpointdir is not None:\n      #TODO: save mode\n    \n   ```\n\n-   Sagemaker estimator in Jupyter notebook, for. e.g.\n\n```python\n# 1. Define local and remote variables for checkpoints\ncheckpoint_s3 = \"s3:\/\/{}\/{}t\/\".format(bucket, \"checkpoints\")\nlocalcheckpoint_dir=\"\/opt\/ml\/checkpoints\/\"\n\nhyperparameters = {\n\n    \"batchsize\": \"8\",\n    \"epochs\" : \"1000\",\n    \"learning_rate\":.0001,\n    \"weight_decay\":5e-5,\n    \"momentum\":.9,\n    \"patience\": 20,\n    \"log-level\" : \"INFO\",\n    \"commit_id\":commit_id,\n    \"model\" :\"FasterRcnnFactory\",\n    \"accumulation_steps\": 8,\n# 2.  define hp for checkpoint dir\n    \"checkpointdir\": localcheckpoint_dir\n}\n\n# In the Sagemaker estimator fit, specify the local and remote path\nfrom sagemaker.pytorch import PyTorch\n\nestimator = PyTorch(\n     entry_point='experiment_train.py',\n                    source_dir = 'src',\n                    dependencies =['src\/datasets', 'src\/evaluators', 'src\/models'],\n                    role=role,\n                    framework_version =\"1.0.0\",\n                    py_version='py3',\n                    git_config= git_config,\n                    image_name= docker_repo,\n                    train_instance_count=1,\n                    train_instance_type=instance_type,\n# 3. The entrypoint file will pick up the checkpoint location from here\n                    hyperparameters =hyperparameters,\n                    output_path=s3_output_path,\n                    metric_definitions=metric_definitions,\n                    train_use_spot_instances = use_spot,\n                    train_max_run =  train_max_run_secs,\n                    train_max_wait = max_wait_time_secs,   \n                    base_job_name =\"object-detection\",\n# 4. Sagemaker knows that the checkpoints will need to be periodically copied from the localcheckpoint_dir to s3 pointed to by checkpoint_s3\n                    checkpoint_s3_uri=checkpoint_s3,\n                    checkpoint_local_path=localcheckpoint_dir)\n```",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":13.8,
        "Solution_reading_time":25.15,
        "Solution_score_count":0.0,
        "Solution_sentence_count":16.0,
        "Solution_word_count":188.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":0.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":279.3938888889,
        "Challenge_answer_count":2,
        "Challenge_body":"The parameters of a big neural network model can be huge. But the largest storage size of a host instance is only 30G, according to https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/host-instance-storage.html. Is there a way to increase the storage volume? I have a model (embeddings) that is very close to 30G and caused a no space error when deploying.   \n  \nThanks!",
        "Challenge_closed_time":1577746997000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1576741179000,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUeVh4VvD6R-eIhRYY6K8dsw\/how-to-increase-the-storage-of-host-instance",
        "Challenge_link_count":1,
        "Challenge_participation_count":2,
        "Challenge_readability":8.1,
        "Challenge_reading_time":5.05,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":279.3938888889,
        "Challenge_title":"how to increase the storage of host instance",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":747.0,
        "Challenge_word_count":62,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"The disk size is currently not configurable for SageMaker Endpoints with EBS backed volumes. As a workaround, please use instances with ephemeral storage for your SageMaker endpoint.  \n  \nExample instance types with ephemeral storage:  \n- m5d instances: https:\/\/aws.amazon.com\/ec2\/instance-types\/m5\/  \n- c5d instances: https:\/\/aws.amazon.com\/ec2\/instance-types\/c5\/  \n- r5d instances: https:\/\/aws.amazon.com\/ec2\/instance-types\/r5\/  \n  \nThe full list of Amazon SageMaker instance types can be accessed here: https:\/\/aws.amazon.com\/sagemaker\/pricing\/instance-types\/",
        "Solution_comment_count":0.0,
        "Solution_link_count":4.0,
        "Solution_readability":12.8,
        "Solution_reading_time":7.18,
        "Solution_score_count":0.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":55.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":0.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":169.8337822222,
        "Challenge_answer_count":1,
        "Challenge_body":"I have setup the pdf labelling task in Sagemaker groud truth following this link - https:\/\/github.com\/aws-samples\/amazon-comprehend-semi-structured-documents-annotation-tools\n\nAfter sometime, the job is failed saying  \"**Complete with labeling errors**\". I found the below log in cloudwatch logs\n\n```\n{\n    \"event-name\": \"HUMAN_TASK_FAILED\",\n    \"event-log-message\": \"ERROR: Human task failed for line 694.\",\n    \"labeling-job-name\": \"resume-labeling-job-20221201T182336\"\n}\n```\n\nNot sure what happened. Does anyone have any way to identify the root cause behind this failure ?",
        "Challenge_closed_time":1671877894556,
        "Challenge_comment_count":0,
        "Challenge_created_time":1670920092769,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUirlDbmZPS8SCqnmC2RFA6A\/human-task-failed-sagemaker-ground-truth-labelling-jobs",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":10.2,
        "Challenge_reading_time":7.96,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":266.0560519444,
        "Challenge_title":"Human Task Failed - Sagemaker ground truth labelling jobs",
        "Challenge_topic":"Data Labeling",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":81.0,
        "Challenge_word_count":70,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"Since I didn't get answer here, I reached out to tech support to seek guidance. It looks like the job duration is elapsed. \n\n\"failure-reason\": \"ClientError: Annotation tasks expired. \n\nReasons are TaskAvailabilityLifetimeInSeconds parameter is too small. \n\nYou can validate this configuration by running the following AWS CLI command from your environment:\naws sagemaker describe-labeling-job --labeling-job-name resume-labeling-job-20221212T094103\n\n\u2014References\u2014\n[1] https:\/\/docs.aws.amazon.com\/sagemaker\/\/latest\/APIReference\/API_HumanTaskConfig.html#API_HumanTaskConfig_Contents",
        "Solution_comment_count":0.0,
        "Solution_link_count":1.0,
        "Solution_readability":14.9,
        "Solution_reading_time":7.57,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":58.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":16.75,
        "Challenge_answer_count":3,
        "Challenge_body":"Does anyone know which locations can be used to set the variable \"location\" in the following code snippet from a .js program designed to use Google Cloud Translation (Advanced) to translate asynchronously a .docx file stored in the subdirectory of a bucket into another supported language?\n\n\u00a0\n\n\/\/ Set your project ID, location and bucket name here\nconst projectId = ....\nconst location = ....\nconst bucketName\u00a0 = ....\n\nMy VM instance is located in \"europe-north1-a\", but is it possible to also use this as a valid region\/zone to set the \"const location\" variable to? I don't\u00a0 see anything about this in the documentation.",
        "Challenge_closed_time":1681397820000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1681337520000,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/location-variable-setting-for-the-Google-Cloud-Translation-API\/td-p\/543332\/jump-to\/first-unread-message",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":9.1,
        "Challenge_reading_time":8.48,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":16.75,
        "Challenge_title":"location variable setting for the Google Cloud Translation API (Advanced)",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":74.0,
        "Challenge_word_count":105,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"Hi\u00a0@legrandtimonier,\u00a0\n\nWelcome back to Google Cloud Support,\n\nThe area \"europe-north1-a\" is a valid location, You may able to generate resources like buckets and VM instances there, you may use it as the location value for the location variable in the code snippet you gave.\n\nThe location parameter of the Google Cloud Translation API indicates the region in which the Translation API service is hosted. The following locations are listed as being accessible for the API service in the official documentation:\n\nasia-east1\neurope-west2\nus-central1\n\nTo reduce latency and increase speed while using services, You may pick the area that is either closest to your users or where your resources are located.\n\nHere are some references that might help you:\nhttps:\/\/cloud.google.com\/compute\/docs\/regions-zones?_ga=2.183424358.-1392753435.1676655686\n\nhttps:\/\/cloud.google.com\/translate\n\nView solution in original post",
        "Solution_comment_count":null,
        "Solution_link_count":2.0,
        "Solution_readability":14.3,
        "Solution_reading_time":11.37,
        "Solution_score_count":1.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":126.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":2.4724386111,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I would like to know if there is any problem in terms of license if enterprise companies use Anaconda that is preinstalled in Azure Data Science Virtual Machine. In another inquiry, I saw an answer that Anaconda included in Azure Machine Learning service has no problem in terms of the license but I would like to confirm whether DSVM also has a problem or not. <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/165312\/anaconda-commercial-use-on-azure-machine-learning.html\">https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/165312\/anaconda-commercial-use-on-azure-machine-learning.html<\/a><\/p>",
        "Challenge_closed_time":1614766234916,
        "Challenge_comment_count":0,
        "Challenge_created_time":1614757334137,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/296502\/anaconda-commercial-use-on-azure-data-science-virt",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":17.8,
        "Challenge_reading_time":8.78,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":2.4724386111,
        "Challenge_title":"Anaconda commercial use on Azure Data Science Virtual Machine",
        "Challenge_topic":"Environment Installation",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":null,
        "Challenge_word_count":75,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=6672f5df-879d-4960-a974-87ca328f8861\">@Kenta  <\/a> The thread referenced by a user was in a different context who wanted to check if they had to subscribe to commercial license to use Azure ML. In the case of DSVM where anaconda packages are installed they are still configured to use open source packages irrespective of the subscription that spins them up. So, you can definitely use the DSVM for your purposes and configure any license's that were acquired to enhance your usage experience with the tools that have been pre-installed. Thanks!!<\/p>\n",
        "Solution_comment_count":3.0,
        "Solution_link_count":0.0,
        "Solution_readability":13.4,
        "Solution_reading_time":7.24,
        "Solution_score_count":0.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":87.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":74.4278163889,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>Hi, getting this error when i run an azureml experiment with custom_docker_image (basegpu image of mcr) - can anybody help me understand this? Have tested this in local compute and it works, not sure why this does not work on a training cluster vm?<\/p>\n<pre><code>   azureml._restclient.exceptions.ServiceException: ServiceException:\n        Code: 400\n        Message: (UserError) Error when parsing request; unable to deserialize request body\n        Details:\n\n        Headers: {\n            &quot;Date&quot;: &quot;Mon, 08 Jun 2020 11:03:52 GMT&quot;,\n            &quot;Content-Type&quot;: &quot;application\/json; charset=utf-8&quot;,\n            &quot;Transfer-Encoding&quot;: &quot;chunked&quot;,\n            &quot;Connection&quot;: &quot;keep-alive&quot;,\n            &quot;Request-Context&quot;: &quot;appId=cid-v1:6a27ce65-5555-41a3-85f7-b7a1ce31fd6b&quot;,\n            &quot;x-ms-response-type&quot;: &quot;error&quot;,\n            &quot;Strict-Transport-Security&quot;: &quot;max-age=15724800; includeSubDomains; preload&quot;\n        }\n        InnerException: {\n        &quot;additional_properties&quot;: {},\n        &quot;error&quot;: {\n            &quot;additional_properties&quot;: {},\n            &quot;code&quot;: &quot;UserError&quot;,\n            &quot;message&quot;: &quot;Error when parsing request; unable to deserialize request body&quot;,\n            &quot;details_uri&quot;: null,\n            &quot;target&quot;: null,\n            &quot;details&quot;: [],\n            &quot;inner_error&quot;: null,\n            &quot;debug_info&quot;: null,\n            &quot;message_format&quot;: null,\n            &quot;message_parameters&quot;: null,\n            &quot;reference_code&quot;: null\n        },\n        &quot;correlation&quot;: {\n            &quot;operation&quot;: &quot;e96d6285280f5849a4a5e3f172d65d36&quot;,\n            &quot;request&quot;: &quot;1beee8ecb7180147&quot;\n        },\n        &quot;environment&quot;: &quot;westeurope&quot;,\n        &quot;location&quot;: &quot;westeurope&quot;,\n        &quot;time&quot;: {}\n    }\n<\/code><\/pre>",
        "Challenge_closed_time":1591884305636,
        "Challenge_comment_count":0,
        "Challenge_created_time":1591616365497,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/33313\/(usererror)-error-when-parsing-request-unable-to-d",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":24.4,
        "Challenge_reading_time":24.05,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":74.4278163889,
        "Challenge_title":"(UserError) Error when parsing request; unable to deserialize request body",
        "Challenge_topic":"Docker Configuration",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":null,
        "Challenge_word_count":134,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>My bad, after giving it some days and looking at the code, I noticed i had forgotten to add the parameters for the estimator configuration. Here is the estimator configuration that works for me:   <\/p>\n<pre><code>estimator = Estimator(source_directory=experiment_folder,\n                      compute_target=compute_target,\n                      script_params=script_params,\n                      entry_script='rps_efn_b0.py',\n                      node_count=1,        \n                      conda_packages=['ipykernel'],\n                      pip_packages = ['azureml-sdk',\n                                      'pyarrow',\n                                      'pyspark',\n                                      'azureml-mlflow',\n                                      'joblib',\n                                      'matplotlib',\n                                      'Pillow',\n                                      'tensorflow==2.2',\n                                      'tensorflow-datasets',\n                                      'tensorflow-hub',\n                                      'azureml-defaults',\n                                      'azureml-dataprep[fuse,pandas]'],\n                      custom_docker_image='mcr.microsoft.com\/azureml\/base-gpu:openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04')\n<\/code><\/pre>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":23.0,
        "Solution_reading_time":9.97,
        "Solution_score_count":1.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":57.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":157.0440930556,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi there, I'm trying to register a ML model to the mlflow model registry to be served from an Azure web app. I'm wondering if the databricks networking configuration will apply to the model api endpoint, as in, calls to the api from outside the VNET which the databricks is deployed to with private endpoints and disabled public access will be rejected and the call from within the vnet integrated web app will be successful?    <\/p>\n<p>Thank you!<\/p>",
        "Challenge_closed_time":1663046075632,
        "Challenge_comment_count":4,
        "Challenge_created_time":1662480716897,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/996163\/databricks-mlflow-model-serving-networking",
        "Challenge_link_count":0,
        "Challenge_participation_count":5,
        "Challenge_readability":10.1,
        "Challenge_reading_time":6.07,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":157.0440930556,
        "Challenge_title":"Databricks mlflow model serving networking",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":82,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=72c1697f-78db-46b7-813e-f61c7171cb88\">@Chammie Ho  <\/a>,    <\/p>\n<p>Thanks for the question and using MS Q&amp;A platform.    <\/p>\n<blockquote>\n<p>I'm wondering if the databricks networking configuration will apply to the model api endpoint    <\/p>\n<\/blockquote>\n<p>Yes, it will. The single node cluster on which the model is hosted (classic), is deployed in data plane and will have a private IP.     <\/p>\n<blockquote>\n<p>I should be able to call the model with the url &lt;databricks-instance&gt;\/model\/&lt;registered-model-name&gt;\/&lt;model-version&gt;\/invocations, my question is whether this url will have the same restrictions as the databricks where it resides    <\/p>\n<\/blockquote>\n<p>I believe, this should work as long as you have not defined any IP access list. The PAT will let you authenticate.    <\/p>\n<blockquote>\n<p>but I can't find information for IP restrictions    <\/p>\n<\/blockquote>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/databricks\/security\/network\/ip-access-list\">IP access lists - Azure Databricks | Microsoft Learn<\/a>    <\/p>\n<p>Hope this will help. Please let us know if any further queries.    <\/p>\n<p>------------------------------    <\/p>\n<ul>\n<li> Please don't forget to click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.pngsfe?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.pngjust?platform=QnA\" alt=\"130671-image.png\" \/> button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/25904\/accepted-answers.html\">how<\/a>    <\/li>\n<li> Want a reminder to come back and check responses? Here is how to subscribe to a <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/67444\/email-notifications.htmlstr\">notification<\/a>    <\/li>\n<li> If you are interested in joining the VM program and help shape the future of Q&amp;A: Here is jhow you can be part of <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/support\/community-champions-program\">Q&amp;A Volunteer Moderators<\/a>    <\/li>\n<\/ul>\n",
        "Solution_comment_count":1.0,
        "Solution_link_count":6.0,
        "Solution_readability":12.1,
        "Solution_reading_time":28.75,
        "Solution_score_count":1.0,
        "Solution_sentence_count":18.0,
        "Solution_word_count":241.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":0.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":513.8669444444,
        "Challenge_answer_count":1,
        "Challenge_body":"Hi,\n\nI'm trying this nice SageMaker Autopilot demo https:\/\/github.com\/awslabs\/amazon-sagemaker-examples\/blob\/master\/autopilot\/autopilot_customer_churn_high_level_with_evaluation.ipynb\n\nAt the beginning of the job, the status is \"InProgress - AnalyzingData\" for several minutes. This is long enough that I'd like to know more about it: what is Autopilot doing when at that status?",
        "Challenge_closed_time":1597886708000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1596036787000,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QU8QUiTTSMQ2W2uOgHXC7lqA\/what-is-sagemaker-autopilot-doing-when-in-state-inprogress-analyzingdata",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":14.4,
        "Challenge_reading_time":5.91,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":513.8669444444,
        "Challenge_title":"What is SageMaker Autopilot doing when in state \"InProgress - AnalyzingData\" ?",
        "Challenge_topic":"Hyperparameter Tuning",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":49.0,
        "Challenge_word_count":53,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":1.0,
        "Poster_isModerator":0.0,
        "Solution_body":"There are some metrics begin collected in this stage. To understanding what is doing is the same as what happens when you're using tensorflow autoML.  There's a deep explanation what is does in our Science page https:\/\/www.amazon.science\/publications\/amazon-sagemaker-autopilot-a-white-box-automl-solution-at-scale",
        "Solution_comment_count":0.0,
        "Solution_link_count":1.0,
        "Solution_readability":14.0,
        "Solution_reading_time":4.07,
        "Solution_score_count":0.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":37.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":6.4760219444,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>Hi,  <br \/>\nI have stored some ml model in my ADLS and I want to register the model to Azure ML using databricks.  <br \/>\nTried to use the following codes to register my ml model but keep encountering an error that the path cannot be found.<\/p>\n<p>import urllib.request  <br \/>\nfrom azureml.core.model import Model<\/p>\n<h1 id=\"register-a-model\">Register a model<\/h1>\n<p>model = Model.register(model_path = 'dbfs:\/mnt\/machinelearning\/classifier.joblib',  <br \/>\nmodel_name = &quot;pretrained-classifier&quot;,  <br \/>\ndescription = &quot;Pretrained Classifier&quot;,  <br \/>\nworkspace=ws)<\/p>",
        "Challenge_closed_time":1642438310976,
        "Challenge_comment_count":0,
        "Challenge_created_time":1642414997297,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/697789\/import-ml-model-from-adls-to-azure-ml-using-databr",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":11.2,
        "Challenge_reading_time":8.17,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":6.4760219444,
        "Challenge_title":"Import ML Model from ADLS to Azure ML using Databricks",
        "Challenge_topic":"Model Registry",
        "Challenge_topic_macro":"Model Management",
        "Challenge_view_count":null,
        "Challenge_word_count":78,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=ad14abdc-d75c-4489-859e-28e2aba507a8\">@Yuzu  <\/a> Using the databricks file path for registering a model is not supported. When using the <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.model?view=azure-ml-py#azureml-core-model-model-register\">model.register()<\/a> you need to download the model locally and then use the path of the model or the folder in which the model is present to register the same.     <\/p>\n<blockquote>\n<p>model_path    <\/p>\n<p>The path on the local file system where the model assets are located. This can be a direct pointer to a single file or folder. If pointing to a folder, the child_paths parameter can be used to specify individual files to bundle together as the Model object, as opposed to using the entire contents of the folder.    <\/p>\n<\/blockquote>\n<p>This sample <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/deployment\/deploy-to-cloud\/model-register-and-deploy.ipynb\">notebook<\/a> should help you with using the method.    <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":4.0,
        "Solution_readability":14.5,
        "Solution_reading_time":18.8,
        "Solution_score_count":1.0,
        "Solution_sentence_count":11.0,
        "Solution_word_count":149.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":77.8924658334,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I deployed my Training pipeline and my Real-time inference pipeline.  <br \/>\nWith the REST-Api of my training pipeline I'm able to retrain my ML model. Is it possible to use that retrained model automated in my real inference pipeline?  <br \/>\nWhen i trigger the pipeline in ML studio I have to update my real inference pipeline manually. Since I want to trigger my retraining external that is not possible.  <br \/>\nThanks in advance.<\/p>",
        "Challenge_closed_time":1615579149187,
        "Challenge_comment_count":0,
        "Challenge_created_time":1615298736310,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/305899\/update-real-interference-pipeline",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":7.5,
        "Challenge_reading_time":5.79,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":77.8924658334,
        "Challenge_title":"update real interference pipeline",
        "Challenge_topic":"Pipeline Configuration",
        "Challenge_topic_macro":"Lifecycle Management",
        "Challenge_view_count":null,
        "Challenge_word_count":76,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi, here's a reference on which <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-ml-pipelines#which-azure-pipeline-technology-should-i-use\">technology<\/a> to use based on a given scenario. For your scenario, you should be able to create an Azure Machine Learning pipeline using the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-trigger-published-pipeline\">SDK to trigger a pipeline<\/a> based on a <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-trigger-published-pipeline#create-a-schedule\">time\/change based schedule<\/a> and then <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-update-web-service\">update the web service<\/a> accordingly. Depending on the complexity of your triggers or data prep needs, you can leverage other technologies such as <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-trigger-published-pipeline#use-azure-logic-apps-for-complex-triggers\">Logic Apps<\/a> or <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-trigger-published-pipeline#call-machine-learning-pipelines-from-azure-data-factory-pipelines\">Azure Data Factory<\/a> to trigger your Azure Machine Learning pipeline. Currently, you can only use the Azure Machine Learning SDK to automatically update the web service. Hope this helps.    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":6.0,
        "Solution_readability":17.6,
        "Solution_reading_time":18.76,
        "Solution_score_count":0.0,
        "Solution_sentence_count":11.0,
        "Solution_word_count":105.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":77.7987138889,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I got this error when running a job in Azure Machine Learning Studio. Any ideas about how to fix it?<\/p>\n<pre><code>Error Code: ScriptExecution.StreamAccess.Unexpected\nNative Error: error in streaming from input data sources\n\tStreamError(Unknown(&quot;unsuccessful status code 409 Conflict, body &quot;, None))\n=&gt; unsuccessful status code 409 Conflict, body \n\tUnknown(&quot;unsuccessful status code 409 Conflict, body &quot;, None)\nError Message: Got unexpected error: unsuccessful status code 409 Conflict, body . | session_id=96032e2f-c1e6-423c-8225-c1c460b3192f\n<\/code><\/pre>",
        "Challenge_closed_time":1676870036790,
        "Challenge_comment_count":0,
        "Challenge_created_time":1676589961420,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1181563\/error-code-scriptexecution-streamaccess-unexpected",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":13.0,
        "Challenge_reading_time":8.7,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":77.7987138889,
        "Challenge_title":"Error Code: ScriptExecution.StreamAccess.Unexpected when running a job in AzureML Studio",
        "Challenge_topic":"Pipeline Configuration",
        "Challenge_topic_macro":"Lifecycle Management",
        "Challenge_view_count":null,
        "Challenge_word_count":77,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=2506b2a8-0b14-4610-bdd6-41ac619af16a\">@Maria Rivera Araya  <\/a>The error message &quot;unsuccessful status code 409 Conflict, body&quot; suggests that there is a conflict with the input data sources. This error can occur when the input data sources are being modified while the job is running.&lt;sup&gt;<a href=\"https:\/\/github.com\/MicrosoftDocs\/azure-docs\/blob\/main\/articles\/machine-learning\/component-reference\/designer-error-codes.md\">[2]<\/a>&lt;\/sup&gt;<\/p>\n<p>You can try the following steps to resolve the issue: Wait for the input data sources to finish being modified.<\/p>\n<ol>\n<li> If the input data sources are not being modified, try restarting the job.<\/li>\n<li> If the issue persists, try using a different input data source.<\/li>\n<\/ol>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":1.0,
        "Solution_readability":13.9,
        "Solution_reading_time":10.12,
        "Solution_score_count":1.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":90.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":75.75,
        "Challenge_answer_count":3,
        "Challenge_body":"Hi,\n\u00a0\nIs there a way to download my Google AutoML Transation model and use it offline once it's trained?\n\u00a0\nAnd in what format can the model be exported?\u00a0\n\u00a0\nThank you",
        "Challenge_closed_time":1664553420000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1664280720000,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/exporting-a-google-autoML-translate-model\/td-p\/471646\/jump-to\/first-unread-message",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":6.7,
        "Challenge_reading_time":2.44,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":75.75,
        "Challenge_title":"exporting a google autoML translate model",
        "Challenge_topic":"Model Persistence",
        "Challenge_topic_macro":"Model Management",
        "Challenge_view_count":135.0,
        "Challenge_word_count":35,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"1.- No.\n\n2.- You can create a Feature Request at\u00a0Issue Tracker\u00a0and\u00a0add a description about the feature you want(Export Translation Models), and the engineer team will look at it. You can see here how it is more likely that the team prioritize the work of the Feature Request\/Issues.\n\nView solution in original post",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":9.2,
        "Solution_reading_time":3.79,
        "Solution_score_count":0.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":55.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":1.8364655556,
        "Challenge_answer_count":1,
        "Challenge_body":"Which Sagemaker Domain is used when using Redshift ML CREATE MODEL",
        "Challenge_closed_time":1683298611292,
        "Challenge_comment_count":0,
        "Challenge_created_time":1683292000016,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUHf0f_0SuS5KOSSctyn37xA\/redshift-ml-sagemaker-domain",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":9.6,
        "Challenge_reading_time":1.2,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":2,
        "Challenge_solved_time":1.8364655556,
        "Challenge_title":"Redshift ML SageMaker Domain",
        "Challenge_topic":"Dataset Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":44.0,
        "Challenge_word_count":14,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"Hi @jkrice, Redshift ML does not use SageMaker Studio (domains). When you run a CREATE MODEL statement, it calls SageMaker to create an Autopilot job (https:\/\/aws.amazon.com\/sagemaker\/autopilot\/) to train a model. Autopilot usually does preprocessing, and trains on a variety of suitable models for your use case and finally returns the best model, that's then deployed for inference in Redshift. You can see more information here - https:\/\/docs.aws.amazon.com\/redshift\/latest\/dg\/machine_learning.html",
        "Solution_comment_count":0.0,
        "Solution_link_count":2.0,
        "Solution_readability":10.8,
        "Solution_reading_time":6.39,
        "Solution_score_count":1.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":66.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":8.7637902778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Assume a data scientist who is coding inside a Synapse notebook, aims to submit his AutoML job to Azure ML. Also assume that we already created the Azure ML workspace, and linked it to Synapse, and also gave Synapse workspace the contributor access to Azure ML workspace. Also the data scientist has the Azure reader role at the synapse workspace level. Data scientist run the following code according to this link (<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/synapse-analytics\/spark\/apache-spark-azure-machine-learning-tutorial\">https:\/\/learn.microsoft.com\/en-us\/azure\/synapse-analytics\/spark\/apache-spark-azure-machine-learning-tutorial<\/a>)    <\/p>\n<p>from azureml.core import Workspace    <\/p>\n<p>subscription_id = &quot;xxxxxx&quot; #you should be owner or contributor    <br \/>\nresource_group = &quot;xxxxx&quot; #you should be owner or contributor    <br \/>\nworkspace_name = &quot;xxxxx&quot; #your workspace name    <br \/>\nworkspace_region = &quot;xxxxx&quot; #your region    <\/p>\n<p>ws = Workspace(workspace_name = workspace_name,    <br \/>\n               subscription_id = subscription_id,  <br \/>\n               resource_group = resource_group)  <\/p>\n<p>However, he receives an error that says he does not have the required contributor\/owner roles at the subscription and resource group level. But we (as the synapse administrators) we don't want to give him the contributor\/owner role at the subscription and resource group name    <\/p>\n<p>Question: How the data scientist can submit his job without letting him to have the required contributor\/owner role. Can he use the managed identity of the Synapse workspace to connect to the Azure ML workspace?    <\/p>\n<p>Thank you<\/p>",
        "Challenge_closed_time":1648620290572,
        "Challenge_comment_count":0,
        "Challenge_created_time":1648588740927,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/792681\/submitting-a-job-to-azure-ml-from-synapse-workspac",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":12.6,
        "Challenge_reading_time":21.56,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":10,
        "Challenge_solved_time":8.7637902778,
        "Challenge_title":"Submitting a job to Azure ML from Synapse workspace",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":209,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello <em>anonymous user<\/em>,    <\/p>\n<p>Thanks for the question and using MS Q&amp;A platform.    <\/p>\n<blockquote>\n<p>Make sure your <code>Service principal<\/code> or <code>Managed Service Identity (MSI)<\/code> must have &quot;<strong>Contributor<\/strong>&quot; access to the AML workspace.    <\/p>\n<\/blockquote>\n<p> If the model is registered in Azure Machine Learning, then you can choose either of the following two supported ways of authentication.    <\/p>\n<ul>\n<li> <strong>Through service principal:<\/strong> You can use service principal client ID and secret directly to authenticate to AML workspace. Service principal must have &quot;Contributor&quot; access to the AML workspace.    <\/li>\n<li> <strong>Through linked service:<\/strong> You can use linked service to authenticate to AML workspace. Linked service can use &quot;service principal&quot; or Synapse workspace's &quot;Managed Service Identity (MSI)&quot; for authentication. &quot;Service principal&quot; or &quot;Managed Service Identity (MSI)&quot; must have &quot;Contributor&quot; access to the AML workspace.    <\/li>\n<\/ul>\n<p>Here is the complete walkthrough of authenticating AML workspace with Azure Synapse Analytics:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/188130-synapse-aml-predict.gif?platform=QnA\" alt=\"188130-synapse-aml-predict.gif\" \/>      <\/p>\n<p>For more details, refer to <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/synapse-analytics\/machine-learning\/tutorial-score-model-predict-spark-pool\">Tutorial: Score machine learning models with PREDICT in serverless Apache Spark pools<\/a>.    <\/p>\n<p>Hope this will help. Please let us know if any further queries.    <\/p>\n<p>------------------------------    <\/p>\n<ul>\n<li> Please don't forget to click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/25904\/accepted-answers.html\">how<\/a>    <\/li>\n<li> Want a reminder to come back and check responses? Here is how to subscribe to a <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/67444\/email-notifications.html\">notification<\/a>    <\/li>\n<li> If you are interested in joining the VM program and help shape the future of Q&amp;A: Here is how you can be part of <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/support\/community-champions-program\">Q&amp;A Volunteer Moderators<\/a>    <\/li>\n<\/ul>\n",
        "Solution_comment_count":1.0,
        "Solution_link_count":7.0,
        "Solution_readability":13.0,
        "Solution_reading_time":35.73,
        "Solution_score_count":1.0,
        "Solution_sentence_count":22.0,
        "Solution_word_count":280.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":13.0572022222,
        "Challenge_answer_count":4,
        "Challenge_body":"<p>I need to import MatPlotLib images into WandB.  On the surface, this seems simple, since the documentation clearly shows how to ingest a <code>plt<\/code> or <code>fig<\/code> object.  However, WandB is making a mess of the plots and I don\u2019t want to recode them in plotly.<br>\nSo I next want to use MatPlotLib to save a PNG and ingest that.  Again seems easy, but I would prefer to do it using an in-memory buffer object (this avoids messing with local paths and temp directories on various instances).  Apparently I\u2019m not the first one to do this either (<a href=\"https:\/\/stackoverflow.com\/questions\/35999020\/convert-pyplot-figure-into-wand-image-image\" rel=\"noopener nofollow ugc\">link<\/a>). The instructions are clear and show someone has already done this.  But it fails when I try it:<\/p>\n<pre><code class=\"lang-auto\">fig, (ax1, ax2) = plt.subplots(2, 1, dpi=300, figsize=(10, 5))\n...\nbuf = io.BytesIO()\nplt.savefig(buf, format='png')\nbuf.seek(0)\nwandb.log(({\"chart\": wandb.Image(file=buf)}))\n<\/code><\/pre>\n<p>The error seems to be with <code>wandb.Image()<\/code>.  It returns:<br>\n<code>{TypeError}__init__() got an unexpected keyword argument 'file'<\/code><\/p>\n<p>I can remove the <code>file=<\/code> parameter so that the command is:<\/p>\n<pre><code class=\"lang-auto\">wandb.Image(buf)\n<\/code><\/pre>\n<p>And I get: <code>{AttributeError}'_io.BytesIO' object has no attribute 'ndim'<\/code><\/p>\n<p>Any recommendations?<\/p>",
        "Challenge_closed_time":1664817995860,
        "Challenge_comment_count":0,
        "Challenge_created_time":1664770989932,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/matplotlib-into-wandb\/3212",
        "Challenge_link_count":1,
        "Challenge_participation_count":4,
        "Challenge_readability":10.0,
        "Challenge_reading_time":18.51,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":16,
        "Challenge_solved_time":13.0572022222,
        "Challenge_title":"MatPlotLib into WandB",
        "Challenge_topic":"Metric Logging",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":790.0,
        "Challenge_word_count":179,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi <a class=\"mention\" href=\"\/u\/kevinashaw\">@kevinashaw<\/a>!<\/p>\n<p>The <code>BytesIO<\/code> type is not supported by <code>wandb.Image<\/code> which is why you are running into this issue. Here are a few options that would work instead:<\/p>\n<ul>\n<li><code>wandb.log({ 'chart' : wandb.Image(Image.open(buf)) })<\/code><\/li>\n<li><code>wandb.log({ 'chart' : wandb.Image(fig) })<\/code><\/li>\n<li>\n<code>wandb.log({ 'chart' : fig })<\/code> (Please note that this does not actually save an image but an interactable Plotly chart on your workspace<\/li>\n<\/ul>\n<p>Thanks,<br>\nRamit<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":6.1,
        "Solution_reading_time":7.48,
        "Solution_score_count":null,
        "Solution_sentence_count":9.0,
        "Solution_word_count":65.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":10.6412836111,
        "Challenge_answer_count":1,
        "Challenge_body":"Can Sagemaker Git Repositories use ssh secrets (no name and password)?",
        "Challenge_closed_time":1649828878883,
        "Challenge_comment_count":0,
        "Challenge_created_time":1649790570262,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QU-P1Hlk4OR6K6kAug-wHT_g\/can-sagemaker-git-repositories-use-ssh-secrets-no-name-and-password",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":8.6,
        "Challenge_reading_time":1.78,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":2,
        "Challenge_solved_time":10.6412836111,
        "Challenge_title":"Can Sagemaker Git Repositories use ssh secrets (no name and password)?",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":1647.0,
        "Challenge_word_count":21,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"Yes, Sagemaker can use SSH for private repos. There are multiple options on how to connect to a repo in Sagemaker.\n\n** Option 1**: Using SSH to work with a private repo\nYou can follow the same steps you do in your local machine to connect to a private repo through SSH, steps to follow:\n    \n1. Open `Terminal` and type `ssh-keygen` to create an SSH key in your Amazon Sagemaker instance. \n2. Add the public key to your Git account (Github or Gitlab)\n3. Get the SSH url of your repo and git clone\n\n**Option 2**: Using AWS Secret Manager \nYou can follow the steps in AWS official documentation [here](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/nbi-git-resource.html). \n\n\n**Option 3**: Using GitHub with Personal Access Tokens **Recommended**\n\nLet\u2019s assume you have already generated an Access Tokens through the GitHub\u2019s Settings \/ Developer Settings \/ Personal Access Tokens page.\n\nYou can just simply go ahead and clone the repository using Studio UI. When it asks your username and password, you can provide your GitHub username and the Personal Access Token. If you want to cache your credentials avoiding to type it every time when you\u2019re interacting with the GitHub server, you can cache or store it on your home folder with the following command issued in the Terminal:\n\n``` $ git config --global git credential.helper [cache|store] ```\n\nIf you choose to store your credentials, it will be written to the `~\/.git-credentials` file located in your home folder. The \u201ccache\u201d helper stores the credential in-memory only and never lands on disk. It also accepts the --timeout <seconds> option, which changes the amount of time its daemon is kept running (the default is \u201c900\u201d, or 15 minutes)\n\nBefore you make your first commit, you still need to configure the git client to use your identity when we\u2019re checking in some new code into the repository. You need to run the following two commands from the terminal:\n```\n$ git config --global user.email \u201cuser@email.com\u201d\n$ git config --global user.name \u201cUser Name\u201d\n```\n\nSagemaker Studio is fully integrated with git and you can do it through the UI.",
        "Solution_comment_count":0.0,
        "Solution_link_count":1.0,
        "Solution_readability":9.8,
        "Solution_reading_time":25.53,
        "Solution_score_count":0.0,
        "Solution_sentence_count":17.0,
        "Solution_word_count":335.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":8.6992033333,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>&quot;We want  the model  to automatically register model every time there is a new model. we created the model in the process and write it out to a pipeline data set.To persist it then we upload and read it for registration.    <\/p>\n<p>We are using .\/output to send the file to output. The issue is that it cannot find it in the file path . How can we validate its existence?  &quot;  <\/p>\n<p>[Note: As we migrate from MSDN, this question has been posted by an\u202fAzure Cloud Engineer\u202fas a frequently asked question] Source: <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/en-US\/1369621f-ebc2-4e79-abe9-9f1165aea6c6\/model-file-is-not-found-for-registration-of-model-in-training-pipeline?forum=MachineLearning\">MSDN<\/a>  <\/p>",
        "Challenge_closed_time":1589360659692,
        "Challenge_comment_count":0,
        "Challenge_created_time":1589329342560,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/26470\/model-file-is-not-found-for-registration-of-model",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":9.2,
        "Challenge_reading_time":10.03,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":8.6992033333,
        "Challenge_title":"Model file is not found for Registration of model in training Pipeline.",
        "Challenge_topic":"Pipeline Configuration",
        "Challenge_topic_macro":"Lifecycle Management",
        "Challenge_view_count":null,
        "Challenge_word_count":108,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Can you verify that the script that is actually writing the model file to the location you expect:<\/p>\n<pre><code>with open(model_name, 'wb') as file:\n       joblib.dump(value = model, filename = os.path.join('.\/outputs\/', model_name))\n<\/code><\/pre>\n<p>Inside in your train python script, you just need to do something like this:<\/p>\n<h1 id=\"persist-the-model-to-the-local-machine\">persist the model to the local machine<\/h1>\n<pre><code>tf.saved_model.save(model,'.\/outputs\/model\/')\n<\/code><\/pre>\n<h1 id=\"register-the-model-with-run-object\">register the model with run object<\/h1>\n<pre><code>run.register_model(model_name,'.\/outputs\/model\/')\n<\/code><\/pre>\n<p>Source: <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/en-US\/1369621f-ebc2-4e79-abe9-9f1165aea6c6\/model-file-is-not-found-for-registration-of-model-in-training-pipeline?forum=MachineLearning\">MSDN<\/a><\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":1.0,
        "Solution_readability":21.3,
        "Solution_reading_time":11.69,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":65.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":0.6764758334,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I only have a few components. What\u2019s wrong with my workspace? I have removed all filters but not working. Can I get some guidance from it?<\/p>",
        "Challenge_closed_time":1677513365643,
        "Challenge_comment_count":1,
        "Challenge_created_time":1677510930330,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1184712\/components-disappear",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":3.6,
        "Challenge_reading_time":2.06,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":0.6764758334,
        "Challenge_title":"Components disappear",
        "Challenge_topic":"Compute Management",
        "Challenge_topic_macro":"Computation Management",
        "Challenge_view_count":null,
        "Challenge_word_count":27,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello <a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=d55db955-94bc-459c-9988-f19bdf6adaee\">sona sathe<\/a>, <\/p>\n<p>Thanks you for reaching out to us here. I just did some researches and I found there is a reason may cause your issue. Could you please confirm if you are in the classic prebuild pipeline so that you have the component you want? If you are not, please try the Classic prebuilt pipeline. <\/p>\n<p>If you are in but you can not  find the component you want, please share the name to me and the screenshot, I will forward it to product team. <\/p>\n<p>I hope this helps! <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/dfae8944-0259-492d-bd74-d6393214c5c9?platform=QnA\" alt=\"User's image\" \/><\/p>\n<p>Regards,<\/p>\n<p>Yutong<\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Solution_comment_count":1.0,
        "Solution_link_count":2.0,
        "Solution_readability":7.2,
        "Solution_reading_time":11.12,
        "Solution_score_count":0.0,
        "Solution_sentence_count":9.0,
        "Solution_word_count":118.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":0.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":2.5986111111,
        "Challenge_answer_count":1,
        "Challenge_body":"Hi,\n\nI want to use `awswrangler` package in my Jupyter Notebook instance of SageMaker.\n\nI understand that we have to use **Lifecycle configuration**. I tried to do it using the following script:\n\n    #!\/bin\/bash\n    \n    pip install awswrangler==0.2.2\n\nBut when I import that package into my Notebook:\n\n    import boto3                                      # For executing native S3 APIs\n    import pandas as pd                               # For munging tabulara data\n    import numpy as np                                # For doing some calculation\n    import awswrangler as wr\n    import io\n    from io import StringIO\n\nI still get the following error:\n\n    ---------------------------------------------------------------------------\n    ModuleNotFoundError                       Traceback (most recent call last)\n    <ipython-input-1-f3d85c7dd0f6> in <module>()\n          2 import pandas as pd                               # For munging tabulara data\n          3 import numpy as np                                # For doing some calculation\n    ----> 4 import awswrangler as wr\n          5 import io\n          6 from io import StringIO\n    \n    ModuleNotFoundError: No module named 'awswrangler'\n\nAny documentation or reference on how to install certain package for Jupyter Notebook in SageMaker?",
        "Challenge_closed_time":1592832724000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1592823369000,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QU4pvReJNZS6eDLxhd4pK-tQ\/how-to-install-phyton-package-in-jupyter-notebook-instance-in-sagemaker",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":13.3,
        "Challenge_reading_time":13.6,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":2.5986111111,
        "Challenge_title":"How to install Phyton package in Jupyter Notebook instance in SageMaker?",
        "Challenge_topic":"Environment Installation",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":1262.0,
        "Challenge_word_count":154,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"Hi,\n\n example how to use lifecycle config to install python package in one environment : https:\/\/github.com\/aws-samples\/amazon-sagemaker-notebook-instance-lifecycle-config-samples\/blob\/master\/scripts\/install-pip-package-single-environment\/on-start.sh\n\nand to all conda env - https:\/\/github.com\/aws-samples\/amazon-sagemaker-notebook-instance-lifecycle-config-samples\/blob\/master\/scripts\/install-pip-package-all-environments\/on-start.sh",
        "Solution_comment_count":0.0,
        "Solution_link_count":2.0,
        "Solution_readability":40.4,
        "Solution_reading_time":6.01,
        "Solution_score_count":0.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":21.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":1.0001155556,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>As the document     <br \/>\nA composed model is created by taking a collection of custom models and assigning them to a single model ID. You can assign up to 100 trained custom models to a single composed model ID. When a document is submitted to a composed model, the service performs a classification step to decide which custom model accurately represents the form presented for analysis.     <\/p>\n<p>What\u2019s the price for the classification step? <\/p>",
        "Challenge_closed_time":1669044705523,
        "Challenge_comment_count":0,
        "Challenge_created_time":1669041105107,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1098169\/compose-model",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":11.9,
        "Challenge_reading_time":5.67,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":1.0001155556,
        "Challenge_title":"Compose model",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":76,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=08dc8e09-5319-4bd7-9cf8-cce17f133981\">@KenSmith  <\/a>     <\/p>\n<p>Thanks for reaching out to us and sorry for the confusion of the document.     <\/p>\n<p>There is <strong>no extra fee<\/strong> for the classification you mentioned in the document. You only pay for the custom model you finally run for your document.    <\/p>\n<p>I will raise a ticket to fix the document, thanks a lot for pointing out it.    <\/p>\n<p>I hope this helps!    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks! <\/p>\n",
        "Solution_comment_count":1.0,
        "Solution_link_count":0.0,
        "Solution_readability":7.0,
        "Solution_reading_time":7.29,
        "Solution_score_count":0.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":88.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":0.1138888889,
        "Challenge_answer_count":0,
        "Challenge_body":"From slack\n\nI'm trying to run a training job and make it resume automatically whenever it is preempted or it encounters an issue.\nI'm using for this the \"termination\" and \"maxRetries\" field to restart the job.\nAfter a problem happens, the job is restarted automatically starting from where the problem has happened if I look at the logs. However, nothing is being saved to the artifacts and any call to tracking.log_metric doesn't seem to have an effect. If I look at the logs, the job then continues until it reaches the end. However instead of just ending, it just keeps restarting (from the point where the problem occurred) until all the \"maxRetries\" are used and fails with the warning \"Underlying job has an issue\" at the status page.\nAny idea what could cause such a problem and if there is anything I could do to avoid it?",
        "Challenge_closed_time":1649329911000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1649329501000,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1474",
        "Challenge_link_count":0,
        "Challenge_participation_count":0,
        "Challenge_readability":7.6,
        "Challenge_reading_time":10.72,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":0.1138888889,
        "Challenge_title":"Auto-resume for deep learning training is not working",
        "Challenge_topic":"Metric Logging",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":null,
        "Challenge_word_count":154,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"Polyaxon provides several strategies to restart, restrat with copy mode, and resumes jobs. The auto-resume behavior is enabled by default\n\nNote that resuming a job can only work if your code supports loading the last checkpoint.\n\nHere's a quick debugging logic to check that the resuming process works as expected:\n\nmain.py\ndef main():\n    tracking.init()\n    checkpoint_path = tracking.get_outputs_path(\"checkpoint.json\")\n    checkpoint_path_exists = os.path.exists(checkpoint_path)\n    print(\"[CHECKPOINT] path found: {}\".format(checkpoint_path_exists))\n    if checkpoint_path_exists:\n        with open(checkpoint_path, \"r\") as checkpoint_file:\n            checkpoint = json.loads(checkpoint_file.read())\n            print(\"[CHECKPOINT] last content: {}\".format(checkpoint))\n    else:\n      print(\"[CHECKPOINT] init ...\")\n      checkpoint = {\n        \"last_time\": time.time(),\n        \"last_index\": 0,\n        \"array\": [],\n      }\n    for i in range(checkpoint[\"last_index\"] + 1, 300):\n      print(\"[CHECKPOINT] step {}\".format(i))\n      tracking.log_progress((i + 1)\/300)\n      tracking.log_metric(name=\"index\", value=i, step=i)\n      checkpoint[\"array\"].append(i)\n      checkpoint[\"last_index\"] = i\n      checkpoint[\"last_time\"] = time.time()\n      if i in [10, 50]:\n        print(\"[CHECKPOINT] Saving last content ...\")\n        with open(checkpoint_path, \"w\") as checkpoint_file:\n          checkpoint_file.write(json.dumps(checkpoint))\n        raise ValueError(\"Error was raised at {}\".format(i))\n      time.sleep(1)\npolyaxonfile.yaml\nversion: 1.1\nkind: component\ntermination:\n  maxRetries: 3\nrun:\n  kind: job\n  container:\n    image: polyaxon\/polyaxon-examples:artifacts\n    workingDir: \"{{ globals.run_artifacts_path }}\/uploads\"\n    command: [\"\/bin\/bash\", -c]\n    args: [\"pip install -U polyaxon --no-cache && python3 main.py\"]\nLogged a dummy metric that resumes from last checkpoint and (apart from the warning regression that I mentioned) the job succeeds after after two failures (you can see the first chart where the x-axis is the time that there's gap time)",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":9.1,
        "Solution_reading_time":24.27,
        "Solution_score_count":1.0,
        "Solution_sentence_count":22.0,
        "Solution_word_count":194.0,
        "Tool":"Polyaxon"
    },
    {
        "Answerer_isAwsEmployee":0.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":0.1483333333,
        "Challenge_answer_count":1,
        "Challenge_body":"I read somewhere that some Amazon SageMaker's built-in algorithms can *only* be trained using GPU, whereas some can use either GPU or CPU, and some can only be used on CPU.\n\nIs there any official documentation explicitly stating which algorithms can only use GPU or both? ",
        "Challenge_closed_time":1597251737000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1597251203000,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUdTLbPM2STGelSj1g3TIjpA\/which-amazon-sagemaker-algorithms-can-only-use-gpu-for-training",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":10.4,
        "Challenge_reading_time":4.13,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":0.1483333333,
        "Challenge_title":"Which Amazon SageMaker algorithms can only use GPU for training?",
        "Challenge_topic":"GPU Acceleration",
        "Challenge_topic_macro":"Computation Management",
        "Challenge_view_count":269.0,
        "Challenge_word_count":55,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":1.0,
        "Solution_body":"Documentation for [Amazon SageMaker built-in algorithms][1]  provides recommendations around choice of Amazon EC2 instances and whether given algorithm supports GPU or CPU devices.\n\nLet's take [Image Classification][2] as an example. Here is a excerpt from online documentation:\n\n> For image classification, we support the following GPU instances for\n> training: ml.p2.xlarge, ml.p2.8xlarge, ml.p2.16xlarge, ml.p3.2xlarge,\n> ml.p3.8xlargeand ml.p3.16xlarge. We recommend using GPU instances with\n> more memory for training with large batch sizes. However, both CPU\n> (such as C4) and GPU (such as P2 and P3) instances can be used for the\n> inference. You can also run the algorithm on multi-GPU and\n> multi-machine settings for distributed training.\n\nFor more complex scenarios, such as [Script or BYO Container][3] modes, customers have flexibility to choose which device (GPU or CPU) to utilize for which operation. This is configured as part of their training scripts.\n\n\n  [1]: https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/algos.html\n  [2]: https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/image-classification.html\n  [3]: https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/your-algorithms.html",
        "Solution_comment_count":0.0,
        "Solution_link_count":3.0,
        "Solution_readability":12.4,
        "Solution_reading_time":15.2,
        "Solution_score_count":0.0,
        "Solution_sentence_count":10.0,
        "Solution_word_count":143.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":117.0207547222,
        "Challenge_answer_count":3,
        "Challenge_body":"<p>Because of network problem. The local <code>debug-internal.log<\/code> files of some runs are too large (more than 500MB). To save the disk space, is there any way to avoid the generation of these log files?<\/p>",
        "Challenge_closed_time":1672190667020,
        "Challenge_comment_count":0,
        "Challenge_created_time":1671769392303,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/the-debug-internal-log-file-is-too-large-500mb\/3589",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":5.2,
        "Challenge_reading_time":3.29,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":117.0207547222,
        "Challenge_title":"The debug-internal.log file is too large (>500MB)",
        "Challenge_topic":"Metric Logging",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":211.0,
        "Challenge_word_count":40,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi <a class=\"mention\" href=\"\/u\/geyao\">@geyao<\/a> , thank you for writing in and happy to look into this for you.  <code>debug-internal.log<\/code> files are automatically generated and cannot be disabled by the user.  Please see this github issue thread that was raised about this issue were a user provided <a href=\"https:\/\/github.com\/wandb\/wandb\/issues\/4223#issuecomment-1236304565\" rel=\"noopener nofollow ugc\">workaround<\/a> solution to address this . Do let me know if this reference helps.<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":1.0,
        "Solution_readability":10.5,
        "Solution_reading_time":6.39,
        "Solution_score_count":null,
        "Solution_sentence_count":5.0,
        "Solution_word_count":62.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":9.2260158334,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I'd like to deploy a machine learning service using AzureML on AKS. I also need to add some OpenAPI specification for it.    <\/p>\n<p>Features in <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-azure-kubernetes-service?tabs=python\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-azure-kubernetes-service?tabs=python<\/a> are neat, but that of having API docs\/swagger for the webservice seems missing.    <\/p>\n<p>Having some documentation is useful especially if the model takes in input several features of different type.    <\/p>\n<p>To overcome this, I currently get models trained in AzureML and include them in Docker containers that use the python FastAPI library to build the API and OpenAPI\/Swagger specs, and those are deployed on some host.     <\/p>\n<p>Can I do something equivalent to this with AKS in AzureML instead? If so, how?<\/p>",
        "Challenge_closed_time":1600930445547,
        "Challenge_comment_count":0,
        "Challenge_created_time":1600897231890,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/105437\/can-i-add-openapi-specification-to-a-webservice-de",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":9.8,
        "Challenge_reading_time":12.38,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":9.2260158334,
        "Challenge_title":"Can I add OpenAPI specification to a webservice deployed with AzureML in AKS?",
        "Challenge_topic":"Docker Configuration",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":null,
        "Challenge_word_count":123,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=9ced4628-b03a-4169-99b4-e42b0955c045\">@Davide Fiocco  <\/a> The deployments of Azure ML provide a swagger specification URI that can be used directly. The documentation of this is available <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.webservice.akswebservice?view=azure-ml-py\">here<\/a>. You can print your <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service\">swagger_uri<\/a> of the web service and check if it confirms with the specifications you are creating currently.     <\/p>\n<p>If the above response helps, please accept the response as answer. Thanks!!    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":2.0,
        "Solution_readability":12.9,
        "Solution_reading_time":8.84,
        "Solution_score_count":2.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":63.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":67.9020225,
        "Challenge_answer_count":4,
        "Challenge_body":"<p>We can use <code>wandb.watch(model, criterion, ...)<\/code> in order to log a model + a loss function.<br>\nBut my loss function is not something simple like: <code>criterion = nn.CrossEntropyLoss()<\/code>.<\/p>\n<p>Rather, here\u2019s how I calculate my loss:<\/p>\n<pre><code class=\"lang-auto\">            # `set_to_none=True` boosts performance\n            optimizer.zero_grad(set_to_none=True)\n            masks_pred = model(imgs)\n\n            probs = F.softmax(masks_pred, dim=1).float()\n            ground_truth = F.one_hot(masks, model.n_classes).permute(0, 3, 1, 2).float()\n\n            loss = criterion(masks_pred, masks) + dice_loss(probs, ground_truth)\n            loss.backward()\n            optimizer.step()\n<\/code><\/pre>\n<p>As you can see, the loss is a composition of 2 functions: the criterion and the <code>dice_loss<\/code> function.<br>\nWhat should I pass to <code>wandb.watch<\/code> for the <code>criterion<\/code> argument?<\/p>",
        "Challenge_closed_time":1657306434860,
        "Challenge_comment_count":0,
        "Challenge_created_time":1657061987579,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/how-to-log-custom-criterion-function\/2703",
        "Challenge_link_count":0,
        "Challenge_participation_count":4,
        "Challenge_readability":9.8,
        "Challenge_reading_time":11.47,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":12,
        "Challenge_solved_time":67.9020225,
        "Challenge_title":"How to log custom criterion function?",
        "Challenge_topic":"Metric Logging",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":111.0,
        "Challenge_word_count":91,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi <a class=\"mention\" href=\"\/u\/vroomerify\">@vroomerify<\/a>,<\/p>\n<p>Thanks for reaching out. <code>wandb.watch<\/code> expects a torch function as a criterion parameter. You can set up a custom criterion function by subclassing <code>torch.nn.Module<\/code>.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":12.1,
        "Solution_reading_time":3.79,
        "Solution_score_count":null,
        "Solution_sentence_count":4.0,
        "Solution_word_count":30.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":10.316325,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>Hi, I am training my models via Azure Machine Learning.<\/p>\n<p>On other day, my training is running with GPU support, however today I found my training is running on a CPU.  <br \/>\nI'm not modified training environment, only training script was modified.  <br \/>\nMy computing cluster is NC6v3 - have a GPU.<\/p>\n<p>I investigate a situation, and I found training script is running on PyTorch 1.6.0.  <br \/>\nOn other day, it ran on Pytorch 1.8.1.  <br \/>\nI think my &quot;don't use GPU&quot; problem is caused by the situation that CUDA toolkit version is not suitable for Pytorch version.<\/p>\n<p>Then, I output a installed package to the log.  <br \/>\nThe log says 'Pytorch 1.8.1 was installed, however uses 1.6.0'.  <br \/>\nI confused by this weird circumstances.  <br \/>\nCan someone tell me the solution?<\/p>\n<p>&lt;My code snippet&gt;  <br \/>\n&lt;&lt;conda_dependencies.yaml&gt;&gt;<\/p>\n<p>channels:  <\/p>\n<ul>\n<li> conda-forge  <\/li>\n<li> pytorch  <\/li>\n<li> nvidia  <br \/>\ndependencies:  <\/li>\n<li> python=3.8.10  <\/li>\n<li> mesa-libgl-cos6-x86_64  <\/li>\n<li> cudatoolkit=11.1  <\/li>\n<li> pytorch==1.8.1  <\/li>\n<li> torchvision==0.9.1  <\/li>\n<li> tqdm  <\/li>\n<li> scikit-learn  <\/li>\n<li> matplotlib  <\/li>\n<li> pandas  <\/li>\n<li> pip &lt; 20.3  <\/li>\n<li> pip:  <\/li>\n<li> azureml-defaults  <\/li>\n<li> opencv-python-headless  <\/li>\n<li> pillow==8.2.0<\/li>\n<\/ul>\n<p>&lt;&lt;Environment definition&gt;&gt;  <br \/>\nenvironment_definition_file = experiment_dir \/ 'conda_dependencies.yaml'  <br \/>\nenvironment_name = 'pytorch-1.8.1-gpu'  <br \/>\nbase_image_name = 'mcr.microsoft.com\/azureml\/openmpi4.1.0-cuda11.0.3-cudnn8-ubuntu18.04'  <br \/>\nenvironment = Environment.from_docker_image(environment_name, base_image_name, conda_specification = environment_definition_file)  <br \/>\ndocker_run_config = DockerConfiguration(use_docker=True)<\/p>\n<p>script_run_config = ScriptRunConfig(  <br \/>\nsource_directory = experiment_dir,  <br \/>\nscript = SCRIPT_FILE_NAME,  <br \/>\narguments = arguments,  <br \/>\ncompute_target = compute_target,  <br \/>\ndocker_runtime_config = docker_run_config,  <br \/>\nenvironment = environment)<\/p>\n<p>&lt;&lt;Output a log in the training script&gt;&gt;  <br \/>\nimport torch  <br \/>\nimport pip<\/p>\n<p>pip.main(['list'])  <br \/>\nprint(f'PyTorch version: {torch.<strong>version<\/strong>}')<\/p>\n<p>&lt;My logs&gt;  <br \/>\nPackage Version<\/p>\n<hr \/>\n<p>adal 1.2.7  <br \/>\napplicationinsights 0.11.10  <br \/>\n(omission)  <br \/>\ntorch 1.8.1  <br \/>\ntorchvision 0.9.0a0  <br \/>\n(omission)<\/p>\n<p>PyTorch version: 1.6.0<\/p>",
        "Challenge_closed_time":1629156299363,
        "Challenge_comment_count":0,
        "Challenge_created_time":1629119160593,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/515579\/azure-machine-learning-uses-invalid-pytorch-versio",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":10.4,
        "Challenge_reading_time":32.76,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":31,
        "Challenge_solved_time":10.316325,
        "Challenge_title":"Azure Machine Learning - Uses invalid Pytorch version when training",
        "Challenge_topic":"GPU Acceleration",
        "Challenge_topic_macro":"Computation Management",
        "Challenge_view_count":null,
        "Challenge_word_count":285,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi, thanks for reaching out. These are the <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-train-core\/azureml.train.dnn.pytorch?view=azure-ml-py\">supported versions<\/a> for PyTorch. Please refer to this document for creating a <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-pytorch#create-a-custom-environment\">custom environment<\/a>. As shown, you'll need to use versions &lt;= 1.6.0. Hope this helps.    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":2.0,
        "Solution_readability":14.0,
        "Solution_reading_time":6.17,
        "Solution_score_count":0.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":37.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":15.2782375,
        "Challenge_answer_count":1,
        "Challenge_body":"So as mentioned in my [other recent post](https:\/\/repost.aws\/questions\/QUAL9Vn9abQ6KKCs2ASwwmzg\/adjusting-sagemaker-xgboost-project-to-tensorflow-or-even-just-different-folder-name), I'm trying to modify the sagemaker example abalone xgboost template to use tensorfow.\n\nMy current problem is that running the pipeline I get a failure and in the logs I see:\n\n```\nModuleNotFoundError: No module named 'transformers'\n```\n\nNOTE: I am importing 'transformers' in `preprocess.py` not in `pipeline.py`\n\nNow I have 'transformers' listed in various places as a dependency including:\n\n* `setup.py` - `required_packages = [\"sagemaker==2.93.0\", \"sklearn\", \"transformers\", \"openpyxl\"]`\n* `pipelines.egg-info\/requires.txt` - `transformers` (auto-generated from setup.py?)\n\nbut so I'm keen to understand, how can I ensure that additional dependencies are available in the pipline itself?\n\nMany thanks in advance\n\n------------\n------------\n------------\nADDITIONAL DETAILS ON HOW I ENCOUNTERED THE ERROR\n\nFrom one particular notebook (see [previous post](https:\/\/repost.aws\/questions\/QUAL9Vn9abQ6KKCs2ASwwmzg\/adjusting-sagemaker-xgboost-project-to-tensorflow-or-even-just-different-folder-name) for more details)  I have succesfully constructed the new topic\/tensorflow pipeline and run the following steps:\n\n```\npipeline.upsert(role_arn=role)\nexecution = pipeline.start()\nexecution.describe()\n```\n\nthe `describe()` method gives this output:\n\n```\n{'PipelineArn': 'arn:aws:sagemaker:eu-west-1:398371982844:pipeline\/topicpipeline-example',\n 'PipelineExecutionArn': 'arn:aws:sagemaker:eu-west-1:398371982844:pipeline\/topicpipeline-example\/execution\/0aiczulkjoaw',\n 'PipelineExecutionDisplayName': 'execution-1664394415255',\n 'PipelineExecutionStatus': 'Executing',\n 'PipelineExperimentConfig': {'ExperimentName': 'topicpipeline-example',\n  'TrialName': '0aiczulkjoaw'},\n 'CreationTime': datetime.datetime(2022, 9, 28, 19, 46, 55, 147000, tzinfo=tzlocal()),\n 'LastModifiedTime': datetime.datetime(2022, 9, 28, 19, 46, 55, 147000, tzinfo=tzlocal()),\n 'CreatedBy': {'UserProfileArn': 'arn:aws:sagemaker:eu-west-1:398371982844:user-profile\/d-5qgy6ubxlbdq\/sjoseph-reg-genome-com-273',\n  'UserProfileName': 'sjoseph-reg-genome-com-273',\n  'DomainId': 'd-5qgy6ubxlbdq'},\n 'LastModifiedBy': {'UserProfileArn': 'arn:aws:sagemaker:eu-west-1:398371982844:user-profile\/d-5qgy6ubxlbdq\/sjoseph-reg-genome-com-273',\n  'UserProfileName': 'sjoseph-reg-genome-com-273',\n  'DomainId': 'd-5qgy6ubxlbdq'},\n 'ResponseMetadata': {'RequestId': 'f949d6f4-1865-4a01-b7a2-a96c42304071',\n  'HTTPStatusCode': 200,\n  'HTTPHeaders': {'x-amzn-requestid': 'f949d6f4-1865-4a01-b7a2-a96c42304071',\n   'content-type': 'application\/x-amz-json-1.1',\n   'content-length': '882',\n   'date': 'Wed, 28 Sep 2022 19:47:02 GMT'},\n  'RetryAttempts': 0}}\n```\nWaiting for the execution I get:\n\n```\n---------------------------------------------------------------------------\nWaiterError                               Traceback (most recent call last)\n<ipython-input-14-72be0c8b7085> in <module>\n----> 1 execution.wait()\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/sagemaker\/workflow\/pipeline.py in wait(self, delay, max_attempts)\n    581             waiter_id, model, self.sagemaker_session.sagemaker_client\n    582         )\n--> 583         waiter.wait(PipelineExecutionArn=self.arn)\n    584 \n    585 \n\n\/opt\/conda\/lib\/python3.7\/site-packages\/botocore\/waiter.py in wait(self, **kwargs)\n     53     # method.\n     54     def wait(self, **kwargs):\n---> 55         Waiter.wait(self, **kwargs)\n     56 \n     57     wait.__doc__ = WaiterDocstring(\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/botocore\/waiter.py in wait(self, **kwargs)\n    376                     name=self.name,\n    377                     reason=reason,\n--> 378                     last_response=response,\n    379                 )\n    380             if num_attempts >= max_attempts:\n\nWaiterError: Waiter PipelineExecutionComplete failed: Waiter encountered a terminal failure state: For expression \"PipelineExecutionStatus\" we matched expected path: \"Failed\"\n```\nWhich I assume is corresponding to the failure I see in the logs:\n\n![buildl pipeline error message on preprocessing step](\/media\/postImages\/original\/IMMpF6LeI6TgWxp20TnPZbUw)\n\nI did also run `python setup.py build` to ensure my build directory was up to date ... here's the terminal output of that command:\n\n```\nsagemaker-user@studio$ python setup.py build\n\/opt\/conda\/lib\/python3.9\/site-packages\/setuptools\/dist.py:771: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n  warnings.warn(\n\/opt\/conda\/lib\/python3.9\/site-packages\/setuptools\/config\/setupcfg.py:508: SetuptoolsDeprecationWarning: The license_file parameter is deprecated, use license_files instead.\n  warnings.warn(msg, warning_class)\nrunning build\nrunning build_py\ncopying pipelines\/topic\/pipeline.py -> build\/lib\/pipelines\/topic\nrunning egg_info\nwriting pipelines.egg-info\/PKG-INFO\nwriting dependency_links to pipelines.egg-info\/dependency_links.txt\nwriting entry points to pipelines.egg-info\/entry_points.txt\nwriting requirements to pipelines.egg-info\/requires.txt\nwriting top-level names to pipelines.egg-info\/top_level.txt\nreading manifest file 'pipelines.egg-info\/SOURCES.txt'\nadding license file 'LICENSE'\nwriting manifest file 'pipelines.egg-info\/SOURCES.txt'\n```\nIt seems like the dependencies are being written to `pipelines.egg-info\/requires.txt` but are these not being picked up by the pipeline?",
        "Challenge_closed_time":1664451755510,
        "Challenge_comment_count":0,
        "Challenge_created_time":1664396753855,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUdd2zOBY0Q4CEG1ZdbgNsgA\/using-transformers-module-with-sagemaker-studio-project-modulenotfounderror-no-module-named-transformers",
        "Challenge_link_count":2,
        "Challenge_participation_count":1,
        "Challenge_readability":16.7,
        "Challenge_reading_time":71.76,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":43,
        "Challenge_solved_time":15.2782375,
        "Challenge_title":"using transformers module with sagemaker studio project: ModuleNotFoundError: No module named 'transformers'",
        "Challenge_topic":"Pipeline Configuration",
        "Challenge_topic_macro":"Lifecycle Management",
        "Challenge_view_count":132.0,
        "Challenge_word_count":440,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"Hi! There are two places where you need to install the dependencies \/ requirements:\n\n1. In your environment where you execute `pipeline.start()` \u2013 can be Amazon SageMaker Studio, your local machine or CI\/CD pipeline executor, e. g. AWS CodeBuild. These dependencies are installed in `setup.py`.\n2. Inside the SageMaker processing and training jobs as well as in inference endpoints. This is usually done via `requirements.txt` file that you submit as part of your `source_dir`.\n\nIn your example, I recommend you to use the `TensorFlowProcessor`. The way how to install dependencies into it is described [in the corresponding section of the documentation](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/processing-job-frameworks-tensorflow.html), in particular:\n> SageMaker Processing installs the dependencies in `requirements.txt` in the container for you.\n\nSame applies to your model training and to the `TensorFlow` estimator. See the section [Use third-party libraries](https:\/\/sagemaker.readthedocs.io\/en\/stable\/frameworks\/tensorflow\/using_tf.html#use-third-party-libraries) in the TensorFlow documentation of the SageMaker Python SDK, in particular:\n> If there are other packages you want to use with your script, you can use a `requirements.txt` to install other dependencies at runtime. \n\nHope it helps!",
        "Solution_comment_count":14.0,
        "Solution_link_count":2.0,
        "Solution_readability":10.9,
        "Solution_reading_time":16.7,
        "Solution_score_count":1.0,
        "Solution_sentence_count":16.0,
        "Solution_word_count":167.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":11.7354919444,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi, I'm using Azure ML Designer to run a pipeline. The pipeline performs a few steps and then it cancels the work throwing an error message with no further details.  <\/p>\n<p>If I re-submit the pipeline it completes the previously failed step but fails on the next step. If I re-submit the same thing happens (completes previously failed step to then fail the next step)... until it gets stuck in a specific sql transform step (see log below)  <\/p>\n<p>Here is a sequence of  run ids related with the issue:  <br \/>\nd33d23a2-2e60-4198-a6b6-f47e6e27ef4e  <br \/>\n57e04c1e-73e8-4ddf-91a8-c407cd1ad5ef  <br \/>\nad7dc826-6549-4eb3-9536-9a801d8e8c0b  <br \/>\ne6623f6f-b7b9-4f19-9501-c8c28f53ab23  <\/p>\n<p>It may be due to the way my pipeline is built but seems like JOIN, SQL Transform and SELECT Column operations tend to fail the most.  <\/p>\n<p>Would much appreciate any help on this.  <\/p>\n<pre><code>2021\/05\/11 01:57:24 Starting App Insight Logger for task:  runTaskLet\n2021\/05\/11 01:57:24 Attempt 1 of http call to http:\/\/10.0.0.6:16384\/sendlogstoartifacts\/info\n2021\/05\/11 01:57:24 Attempt 1 of http call to http:\/\/10.0.0.6:16384\/sendlogstoartifacts\/status\n[2021-05-11T01:57:24.912444] Entering context manager injector.\n[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['urldecode_invoker.py', 'python', '-m', 'azureml.designer.modules.datatransform.invoker', 'ApplySqlTransModule', '--dataset', 'DatasetOutputConfig:Result_dataset', '--t1=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpmflqzlpr', '--t2=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpl9h5snzy', '--t3=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpuhf3n5ji', '--sqlquery=%22select+b.*%2cc.*%0d%0afrom+(%0d%0a++++select+a.customer_id%2c+a.sku_id%0d%0a++++from+(%0d%0a++++++++select+*+from+t1+cross+join+t2%0d%0a++++)+a%0d%0a++++where+exists+(%0d%0a++++++++select+t3.top_skus%0d%0a++++++++from+t3%0d%0a++++++++where+t3.sku_id+%3d+a.sku_id%0d%0a++++)%0d%0a)+b%0d%0ainner+join+(%0d%0a++++select+distinct+sku_id%2c+top_skus%0d%0a++++from+t3%0d%0a)+c%0d%0aon+c.sku_id+%3d+b.sku_id%22'])\nScript type = None\n[2021-05-11T01:57:26.142183] Entering Run History Context Manager.\n[2021-05-11T01:57:26.734197] Current directory: \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/mounts\/workspaceblobstore\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\n[2021-05-11T01:57:26.734493] Preparing to call script [urldecode_invoker.py] with arguments:['python', '-m', 'azureml.designer.modules.datatransform.invoker', 'ApplySqlTransModule', '--dataset', '$Result_dataset', '--t1=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpmflqzlpr', '--t2=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpl9h5snzy', '--t3=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpuhf3n5ji', '--sqlquery=%22select+b.*%2cc.*%0d%0afrom+(%0d%0a++++select+a.customer_id%2c+a.sku_id%0d%0a++++from+(%0d%0a++++++++select+*+from+t1+cross+join+t2%0d%0a++++)+a%0d%0a++++where+exists+(%0d%0a++++++++select+t3.top_skus%0d%0a++++++++from+t3%0d%0a++++++++where+t3.sku_id+%3d+a.sku_id%0d%0a++++)%0d%0a)+b%0d%0ainner+join+(%0d%0a++++select+distinct+sku_id%2c+top_skus%0d%0a++++from+t3%0d%0a)+c%0d%0aon+c.sku_id+%3d+b.sku_id%22']\n[2021-05-11T01:57:26.734551] After variable expansion, calling script [urldecode_invoker.py] with arguments:['python', '-m', 'azureml.designer.modules.datatransform.invoker', 'ApplySqlTransModule', '--dataset', '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpnbybe4mu', '--t1=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpmflqzlpr', '--t2=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpl9h5snzy', '--t3=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpuhf3n5ji', '--sqlquery=%22select+b.*%2cc.*%0d%0afrom+(%0d%0a++++select+a.customer_id%2c+a.sku_id%0d%0a++++from+(%0d%0a++++++++select+*+from+t1+cross+join+t2%0d%0a++++)+a%0d%0a++++where+exists+(%0d%0a++++++++select+t3.top_skus%0d%0a++++++++from+t3%0d%0a++++++++where+t3.sku_id+%3d+a.sku_id%0d%0a++++)%0d%0a)+b%0d%0ainner+join+(%0d%0a++++select+distinct+sku_id%2c+top_skus%0d%0a++++from+t3%0d%0a)+c%0d%0aon+c.sku_id+%3d+b.sku_id%22']\n\nSession_id = 4b5b4c29-cfda-4ab6-a715-47fee287c468\nInvoking module by urldecode_invoker 0.0.8.\n\nModule type: custom module.\n\nUsing runpy to invoke module 'azureml.designer.modules.datatransform.invoker'.\n\n\/azureml-envs\/azureml_7c975cabc8bb1dc19c3de94457d707fd\/lib\/python3.6\/site-packages\/azureml\/designer\/modules\/datatransform\/tools\/dataframe_utils.py:2: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n  from pandas.util.testing import assert_frame_equal\n2021-05-11 01:57:27,324 [             invoker] [    INFO] .[main] Start custom modules\n2021-05-11 01:57:27,337 [             invoker] [    INFO] .[main] Module version: 0.0.74\n2021-05-11 01:57:27,344 [             invoker] [    INFO] .[main] args: azureml.designer.modules.datatransform.invoker, ApplySqlTransModule, --dataset, \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpnbybe4mu, --t1=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpmflqzlpr, --t2=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpl9h5snzy, --t3=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpuhf3n5ji, --sqlquery=select b.*,c.*\nfrom (\n    select a.customer_id, a.sku_id\n    from (\n        select * from t1 cross join t2\n    ) a\n    where exists (\n        select t3.top_skus\n        from t3\n        where t3.sku_id = a.sku_id\n    )\n) b\ninner join (\n    select distinct sku_id, top_skus\n    from t3\n) c\non c.sku_id = b.sku_id\n2021-05-11 01:57:27,352 [             invoker] [    INFO] .[main] &quot;transform_module_class_name&quot;: ApplySqlTransModule\n2021-05-11 01:57:27,444 [         module_base] [    INFO] ...[get_arg_parser] Construct arg parser\n2021-05-11 01:57:27,460 [         module_base] [    INFO] ...[get_arg_parser] arg: t1\n2021-05-11 01:57:27,468 [         module_base] [    INFO] ...[get_arg_parser] arg: t2\n2021-05-11 01:57:27,476 [         module_base] [    INFO] ...[get_arg_parser] arg: t3\n2021-05-11 01:57:27,484 [         module_base] [    INFO] ...[get_arg_parser] arg: dataset\n2021-05-11 01:57:27,492 [         module_base] [    INFO] ...[get_arg_parser] arg: sqlquery\n2021-05-11 01:57:27,500 [         module_base] [    INFO] ..[parse_and_insert_args] invoker args:\n module_classname = ApplySqlTransModule\n t1 = \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpmflqzlpr\n t2 = \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpl9h5snzy\n t3 = \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpuhf3n5ji\n dataset = \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpnbybe4mu\n sqlquery = select b.*,c.*\nfrom (\n    select a.customer_id, a.sku_id\n    from (\n        select * from t1 cross join t2\n    ) a\n    where exists (\n        select t3.top_skus\n        from t3\n        where t3.sku_id = a.sku_id\n    )\n) b\ninner join (\n    select distinct sku_id, top_skus\n    from t3\n) c\non c.sku_id = b.sku_id\n\n2021-05-11 01:57:27,508 [             invoker] [    INFO] .[main] start to run custom module: ApplySqlTransModule\n2021-05-11 01:57:27,516 [apply_sql_trans_module] [    INFO] ...[run] Construct SQLite Server\n2021-05-11 01:57:27,530 [    module_parameter] [    INFO] ......[data] Read data from \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpmflqzlpr\n2021-05-11 01:57:29,215 [apply_sql_trans_module] [    INFO] ....[_transform_df_to_sql] Insert t1 with only column names\n2021-05-11 01:57:29,227 [    module_parameter] [    INFO] ......[data] Read data from \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpl9h5snzy\n2021\/05\/11 01:57:29 Not exporting to RunHistory as the exporter is either stopped or there is no data.\nStopped: false\nOriginalData: 1\nFilteredData: 0.\n2021-05-11 01:57:30,093 [apply_sql_trans_module] [    INFO] ....[_transform_df_to_sql] Insert t2 with only column names\n2021-05-11 01:57:30,106 [    module_parameter] [    INFO] ......[data] Read data from \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpuhf3n5ji\n2021-05-11 01:57:30,876 [apply_sql_trans_module] [    INFO] ....[_transform_df_to_sql] Insert t3 with only column names\n2021-05-11 01:57:30,888 [apply_sql_trans_module] [    INFO] ...[run] Read SQL script query\n2021-05-11 01:57:30,895 [apply_sql_trans_module] [    INFO] ...[run] Validate SQL script query\n2021-05-11 01:57:30,912 [apply_sql_trans_module] [    INFO] ...[run] Insert data to SQLite Server\n2021-05-11 01:57:30,919 [apply_sql_trans_module] [    INFO] ....[_transform_df_to_sql] Insert t1\n2021-05-11 01:57:30,930 [apply_sql_trans_module] [    INFO] ....[_transform_df_to_sql] Insert t2\n2021-05-11 01:57:30,970 [apply_sql_trans_module] [    INFO] ....[_transform_df_to_sql] Insert t3\n2021-05-11 01:57:31,053 [apply_sql_trans_module] [    INFO] ...[run] Generate SQL query result from SQLite Server\n<\/code><\/pre>",
        "Challenge_closed_time":1620739797128,
        "Challenge_comment_count":2,
        "Challenge_created_time":1620697549357,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/390003\/azure-ml-pipeline-fails-at-sql-transform-task",
        "Challenge_link_count":2,
        "Challenge_participation_count":3,
        "Challenge_readability":17.3,
        "Challenge_reading_time":130.61,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":69,
        "Challenge_solved_time":11.7354919444,
        "Challenge_title":"azure ml pipeline fails at sql transform task",
        "Challenge_topic":"Pipeline Configuration",
        "Challenge_topic_macro":"Lifecycle Management",
        "Challenge_view_count":null,
        "Challenge_word_count":609,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Found the problem.   <\/p>\n<p>There was a task failing but due to the size of the canvas I wasn't able to spot it at first (working late hours didn't help also).   <\/p>\n<p>However it certainly didn't help the fact that the error message didn't provide any info regarding which task failed, so maybe the AML team would like to add more descriptive messages in cases like this one.  <\/p>\n<p>thanks<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":8.8,
        "Solution_reading_time":4.8,
        "Solution_score_count":1.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":70.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":1.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":4.5602777778,
        "Challenge_answer_count":1,
        "Challenge_body":"Is there a way to attach a custom image to just the user (not the domain) in SageMaker Studio. \n\nDocumentation states 'To make a custom SageMaker image available to all users within a domain, you attach the image to the domain. To make an image available to a single user, you attach the image to the user's profile.'\nhttps:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/studio-byoi.html \n\nWhen I 'edit user', I dont see a way to attach a custom image. Is there a way to do this?",
        "Challenge_closed_time":1607593010000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1607576593000,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUhP1jmxpAQi6X0eDIUI2JKA\/attaching-custom-image-to-user-not-domain-in-sagemaker-studio",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":9.1,
        "Challenge_reading_time":6.55,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":4.5602777778,
        "Challenge_title":"Attaching custom image to user (not domain) in SageMaker Studio",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":328.0,
        "Challenge_word_count":89,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"You can attach custom images to user profiles via the APIs to create\/update user profiles.\n\nMore info:\n\nhttps:\/\/docs.aws.amazon.com\/sagemaker\/latest\/APIReference\/API_CreateUserProfile.html\nhttps:\/\/docs.aws.amazon.com\/sagemaker\/latest\/APIReference\/API_UpdateUserProfile.html",
        "Solution_comment_count":0.0,
        "Solution_link_count":2.0,
        "Solution_readability":27.1,
        "Solution_reading_time":3.72,
        "Solution_score_count":1.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":19.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":14.0508991667,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hello,  <\/p>\n<p>we have also found this example of using <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/intro-to-pipelines\/aml-pipelines-use-databricks-as-compute-target.ipynb\">Databricks as a Compute Target for an Azure Machine Learning Pipeline<\/a>.  <\/p>\n<p>However, we want to use an existing Databricks Cluster as compute target within Azure Machine Learning Studio for our Azure Machine Learning Pipeline.  <br \/>\nCould you help us in accomplishing this, please?  <\/p>\n<p>With best regards  <br \/>\nAlex  <\/p>",
        "Challenge_closed_time":1654664851167,
        "Challenge_comment_count":0,
        "Challenge_created_time":1654614267930,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/880189\/connecting-to-an-existing-databricks-cluster-in-am",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":12.5,
        "Challenge_reading_time":8.29,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":14.0508991667,
        "Challenge_title":"Connecting to an existing Databricks Cluster in AMLS",
        "Challenge_topic":"Pipeline Configuration",
        "Challenge_topic_macro":"Lifecycle Management",
        "Challenge_view_count":null,
        "Challenge_word_count":69,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>@AlexanderPakakis-0994 Are you looking at adding the cluster from the UI of ML studio rather than using the SDK as mentioned in the notebook you referenced?    <br \/>\nIf Yes, you need to add the same attached compute.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/209283-image.png?platform=QnA\" alt=\"209283-image.png\" \/>    <\/p>\n<p>Once you select Azure Databricks the following option to add the existing databricks workspace is seen.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/209260-image.png?platform=QnA\" alt=\"209260-image.png\" \/>    <\/p>\n<p>I hope this helps!!    <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Solution_comment_count":10.0,
        "Solution_link_count":4.0,
        "Solution_readability":13.2,
        "Solution_reading_time":13.06,
        "Solution_score_count":0.0,
        "Solution_sentence_count":9.0,
        "Solution_word_count":94.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":12.3472294445,
        "Challenge_answer_count":1,
        "Challenge_body":"![Studio encountered an error when creating your project](https:\/\/repost.aws\/media\/postImages\/original\/IMWYkHCNADT7ihgQuoRgh7nQ)\nI trying tutorial on \"MLOps template for model building, training, and deployment with third-party Git repositories using CodePipeline\". But I am getting  error as shown in image",
        "Challenge_closed_time":1658994240283,
        "Challenge_comment_count":0,
        "Challenge_created_time":1658949790257,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUOCKdskABQumCC7OnzBZR4g\/sagemaker-studio-encountered-an-error-when-creating-your-project-github-and-codepipeline-template",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":14.9,
        "Challenge_reading_time":5.29,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":12.3472294445,
        "Challenge_title":"Sagemaker Studio encountered an error when creating your project(github and codepipeline template)",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":165.0,
        "Challenge_word_count":46,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"Hello. It seems like you are having permission problems according to the snapshot you provided. \nIf you head to the Cloudformation service, you will probably get a better understanding of where the tamplate is failing. \nMake sure to have followed the prerequisites and check out this [section](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/sagemaker-projects-templates-sm.html#sagemaker-projects-templates-update).",
        "Solution_comment_count":1.0,
        "Solution_link_count":1.0,
        "Solution_readability":15.3,
        "Solution_reading_time":5.41,
        "Solution_score_count":1.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":47.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":22.6043166667,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I'm following a tutorial (<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python<\/a>) on how to deploy a model to Azure, and I had a few questions that have had confused a bit. I had a ready model that I trained using a notebook in Azure ML and have saved the model in a folder (as .h5) in my compute directory (Users\/username\/projectname\/models).    <\/p>\n<p>1- Can I deploy from the Azure ML Notebook section? So I create a .py file (or can I do it in a .ipynb notebook?), connect to my workspace, and register the model through there? I have my model stored in the models folder, so can I just reference that from an <code>azureml.core.Run<\/code> object?    <\/p>\n<p>2- When I create my entry scripts and inference and deployment configurations, do they have to be in separate files or does that not matter? Same for the code to deploy the model.    <\/p>\n<p>3- What model extensions are supported? Is .h5 fine?    <\/p>\n<p>4- When I deploy successfully, do I get an endpoint or uri I can connect to from anywhere?    <\/p>\n<p>I know this is a bit all over the place, but any clarifications would be appreciated. <\/p>",
        "Challenge_closed_time":1633027344787,
        "Challenge_comment_count":0,
        "Challenge_created_time":1632945969247,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/571518\/deploying-model-in-azure-ml-confusion",
        "Challenge_link_count":1,
        "Challenge_participation_count":2,
        "Challenge_readability":8.4,
        "Challenge_reading_time":15.97,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":15,
        "Challenge_solved_time":22.6043166667,
        "Challenge_title":"Deploying model in Azure ML confusion",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":196,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi, thanks for reaching out. Here's the workflow for deploying a model:    <\/p>\n<ol>\n<li> Register the model    <\/li>\n<li> Prepare an entry script    <\/li>\n<li> Prepare an inference configuration    <\/li>\n<li> Deploy the model locally to ensure everything works    <\/li>\n<li> Choose a compute target    <\/li>\n<li> Re-deploy the model to the cloud    <\/li>\n<li> Test the resulting web service    <\/li>\n<\/ol>\n<p>You can perform the above steps through AML notebooks. However, you <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python#define-a-dummy-entry-script\">entry script<\/a> and <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python#define-an-inference-configuration\">deployment configuration<\/a> need to be in separate files. After <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python#deploy-your-machine-learning-model\">deployment<\/a>, you obtain an endpoint for <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service?tabs=python\">calling the webservice<\/a>. Model with extension .h5 is supported.    <\/p>\n<p>You can create new or reference an existing environment in your config, here's information on how to <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-environments\">create\/use software environments<\/a>. Also, here's another <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/ml-frameworks\/tensorflow\/train-hyperparameter-tune-deploy-with-tensorflow\/train-hyperparameter-tune-deploy-with-tensorflow.ipynb\">example<\/a> (Deploy the model in ACI section) of how to create a scoring script. Please review the following <a href=\"https:\/\/www.tensorflow.org\/guide\/keras\/save_and_serialize\">document<\/a> for details on how to save and load Keras models.    <\/p>\n<pre><code>%%writefile score.py  \nimport json  \nimport numpy as np  \nimport os  \nimport tensorflow as tf  \n  \nfrom azureml.core.model import Model  \n  \ndef init():  \n    global tf_model  \n    model_root = os.getenv('AZUREML_MODEL_DIR')  \n    # the name of the folder in which to look for tensorflow model files  \n    tf_model_folder = 'model'  \n      \n    tf_model = tf.saved_model.load(os.path.join(model_root, tf_model_folder))  \n  \ndef run(raw_data):  \n    data = np.array(json.loads(raw_data)['data'], dtype=np.float32)  \n      \n    # make prediction  \n    out = tf_model(data)  \n    y_hat = np.argmax(out, axis=1)  \n  \n    return y_hat.tolist()  \n<\/code><\/pre>\n",
        "Solution_comment_count":2.0,
        "Solution_link_count":7.0,
        "Solution_readability":16.4,
        "Solution_reading_time":32.7,
        "Solution_score_count":1.0,
        "Solution_sentence_count":23.0,
        "Solution_word_count":219.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":161.8254016667,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>Hei, I'm trying to build a pipeline including a HyperdriveStep to tuen the hyperparameters.  <br \/>\nThe pipeline should later on run automatically and be tuned at each pipeline run.<\/p>\n<p>The pipeline consists of three steps: a preparation step resulting in a PipelineData Object, the HyperdriveStep and a final PythonRegisterStep, where the best model should be registered.<\/p>\n<p>However, when creating the pipeline object I'm getting an error I can not relate to.<\/p>\n<p>Traceback (most recent call last):<\/p>\n<pre><code>      File &quot;\/Users\/xxx\/Desktop\/azure_test\/pipeline-folder\/azure_pipeline_wrapper1.py&quot;, line 168, in &lt;module&gt;\n        pipeline = Pipeline(workspace=ws, steps=pipeline_steps, description=&quot;Pipeline for hyperparameter tuning&quot;)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/core\/_experiment_method.py&quot;, line 104, in wrapper\n        return init_func(self, *args, **kwargs)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/pipeline.py&quot;, line 177, in __init__\n        self._graph = self._graph_builder.build(self._name, steps, finalize=False)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/builder.py&quot;, line 1481, in build\n        graph = self.construct(name, steps)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/builder.py&quot;, line 1503, in construct\n        self.process_collection(steps)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/builder.py&quot;, line 1539, in process_collection\n        builder.process_collection(collection)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/builder.py&quot;, line 1830, in process_collection\n        self._base_builder.process_collection(item)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/builder.py&quot;, line 1533, in process_collection\n        return self.process_step(collection)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/builder.py&quot;, line 1577, in process_step\n        node = step.create_node(self._graph, self._default_datastore, self._context)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/steps\/hyper_drive_step.py&quot;, line 270, in create_node\n        hyperdrive_config, reuse_hashable_config = self._get_hyperdrive_config(context._workspace,\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/steps\/hyper_drive_step.py&quot;, line 346, in _get_hyperdrive_config\n        hyperdrive_dto = _search._create_experiment_dto(self._hyperdrive_config, workspace,\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/train\/hyperdrive\/_search.py&quot;, line 38, in _create_experiment_dto\n        platform_config = hyperdrive_config._get_platform_config(workspace, experiment_name, **kwargs)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/train\/hyperdrive\/runconfig.py&quot;, line 672, in _get_platform_config\n        platform_config.update(self._get_platform_config_data_from_run_config(workspace))\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/train\/hyperdrive\/runconfig.py&quot;, line 686, in _get_platform_config_data_from_run_config\n        run_config = get_run_config_from_script_run(self.run_config)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/core\/script_run_config.py&quot;, line 84, in get_run_config_from_script_run\n        run_config.arguments = deepcopy(script_run_config.arguments)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py&quot;, line 146, in deepcopy\n        y = copier(x, memo)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py&quot;, line 205, in _deepcopy_list\n        append(deepcopy(a, memo))\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py&quot;, line 172, in deepcopy\n        y = _reconstruct(x, memo, *rv)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py&quot;, line 270, in _reconstruct\n        state = deepcopy(state, memo)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py&quot;, line 146, in deepcopy\n        y = copier(x, memo)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py&quot;, line 230, in _deepcopy_dict\n        y[deepcopy(key, memo)] = deepcopy(value, memo)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py&quot;, line 172, in deepcopy\n        y = _reconstruct(x, memo, *rv)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py&quot;, line 270, in _reconstruct\n        state = deepcopy(state, memo)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py&quot;, line 146, in deepcopy\n        y = copier(x, memo)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py&quot;, line 230, in _deepcopy_dict\n        y[deepcopy(key, memo)] = deepcopy(value, memo)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py&quot;, line 172, in deepcopy\n        y = _reconstruct(x, memo, *rv)\n\n      File &quot;\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py&quot;, line 264, in _reconstruct\n        y = func(*args)\n\n      File &quot;\/Users\/xxxr\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copyreg.py&quot;, line 91, in __newobj__\n        return cls.__new__(cls, *args)\n\n    TypeError: __new__() missing 2 required positional arguments: 'workspace' and 'name'\n<\/code><\/pre>\n<p>My Code:<\/p>\n<pre><code># Connect to workspace \nws = Workspace.from_config()\nprint(ws.name, &quot;loaded&quot;)\n\n# Set compute target\ncluster_name = &quot;compcluster234&quot;\npipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n\n# Create new environment\nsklearn_env = Environment(&quot;sklearn_env&quot;)\n# Adds dependencies to PythonSection of sklaern_env\nenv_packages = CondaDependencies.create(conda_packages=['scikit-learn'])\nsklearn_env.docker.enabled = True\nsklearn_env.python.conda_dependencies = env_packages\n# Register the environment\nsklearn_env.register(workspace=ws)\n\n# =============================================================================\n# Run Configuration\n# =============================================================================\n\n# Create Run configuration \n# Pipeline_folder\npipeline_folder = path + '\/pipeline-folder'\n# Create a new runconfig object for the pipeline\npipeline_run_config = RunConfiguration()\n# Use the compute you created above. \npipeline_run_config.target = pipeline_cluster\n# Assign the environment to the run configuration\n# In comparison to the ScriptRunCnfig object, the RunConfig is more generous\npipeline_run_config.environment = sklearn_env\nprint (&quot;Run configuration created.&quot;)\n\n# =============================================================================\n# DataPath\n# =============================================================================\n\n# Get the default datastore\ndefault_ds = ws.get_default_datastore()\n# Create a DataPath object \ndatapath = DataPath(datastore = default_ds,\n                     path_on_datastore = 'cancer-data')\n# Make the datapath a PipelineParameter\ndatapath_pipeline_param = PipelineParameter(name='input-data',   \n                                            default_value=datapath)\ndatapath_input = (datapath_pipeline_param, \n                   DataPathComputeBinding(mode = 'mount'))\n\n# =============================================================================\n# PipelineData\n# =============================================================================\n\n# Create a PipelineData (temporary Data Reference) for the preppared data folder\nprepped_data_folder = PipelineData(name=&quot;prepped_data_folder&quot;,\n                                   datastore=ws.get_default_datastore())\n\n# Create PipelineData objects for the Metrics and the saved model\nmetrics_output_name = 'metrics_output'\nmetrics_data = PipelineData(name='metrics_data',\n                            datastore=default_ds,\n                            pipeline_output_name=metrics_output_name,\n                            training_output=TrainingOutput(&quot;Metrics&quot;))\n\nmodel_output_name = 'model_output'\nsaved_model = PipelineData(name='saved_model',\n                           datastore=default_ds,\n                           pipeline_output_name=model_output_name,\n                           training_output=TrainingOutput(&quot;Model&quot;,\n                                                          model_file=&quot;outputs\/model\/cancer_model.pkl&quot;))\n\n# =============================================================================\n# Pipeline Steps\n# =============================================================================\n\n# Step 1, Run the data prep script\nprep_step = PythonScriptStep(name = &quot;prepare_data&quot;,\n                                source_directory = pipeline_folder,\n                                script_name = &quot;cancer_pipeline_preprocessing.py&quot;,\n                                arguments = ['--input-data', datapath_input,\n                                             '--prepped-data', prepped_data_folder],\n                                inputs=[datapath_input],\n                                outputs=[prepped_data_folder],\n                                compute_target = pipeline_cluster,\n                                runconfig = pipeline_run_config,\n                                allow_reuse = False)\n\n# Define the search strategy and parameter space for hyperparameter tuning\nps = GridParameterSampling({ '--max_depth': choice(1,2,3)})\n# Define a early stopping criteria\nearly_termination_policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)\n# Define a ScriptRunConfig for the Training script\n# The ScriptRunConfig is based on the RunConfig of the Pipeline\nscript_run_config = ScriptRunConfig(script=&quot;cancer_pipeline_tuning.py&quot;,\n                                    source_directory=pipeline_folder,\n                                    # Add non-hyperparameter arguments -in this case, the training dataset\n                                    arguments = ['--training_folder', prepped_data_folder],\n                                    run_config=pipeline_run_config)\n# Define a HyperDriveConfiguration\n# The primary_metric_name must be completely idential to the metric name logged during training (inside the training script)\nhd_config = HyperDriveConfig(run_config=script_run_config, \n                             hyperparameter_sampling=ps,\n                             policy=early_termination_policy,\n                             primary_metric_name='Accuracy', \n                             primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n                             max_total_runs=3,\n                             max_concurrent_runs=2)\n\n# Step 2b, define a HyperDriveStep\n# HyperDriveStep can be used to run HyperDrive job as a step in pipeline.\n# No arguments need to be set as they are already set inside the ScriptRunConfig\nhyperdrive_step = HyperDriveStep(name=&quot;tune_hyperparameters&quot;,\n                                 hyperdrive_config=hd_config,\n                                 inputs=[prepped_data_folder],\n                                 outputs=[metrics_data, saved_model])\n\nhyperdrive_step.run_after(prep_step)    \n\n# Step 3, Run the model registration step\nregister_step = PythonScriptStep(name=&quot;register_model&quot;,\n                                       script_name='cancer_pipeline_register1.py',\n                                       source_directory = pipeline_folder,\n                                       arguments=[&quot;--saved_model&quot;, saved_model],\n                                       inputs=[saved_model],\n                                       compute_target = pipeline_cluster,\n                                       runconfig=pipeline_run_config,\n                                       allow_reuse = False)\n\nregister_step.run_after(hyperdrive_step)    \nprint(&quot;Pipeline steps defined&quot;)\n\n\n# Construct the pipeline\npipeline_steps = [prep_step, hyperdrive_step, register_step]\npipeline = Pipeline(workspace=ws, steps=pipeline_steps, description=&quot;Pipeline for hyperparameter tuning&quot;)\nprint(&quot;Pipeline is built.&quot;)\n<\/code><\/pre>",
        "Challenge_closed_time":1622098105463,
        "Challenge_comment_count":2,
        "Challenge_created_time":1621515534017,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/403018\/pipeline-can-not-be-built-using-a-hyperdrivestep-i",
        "Challenge_link_count":0,
        "Challenge_participation_count":4,
        "Challenge_readability":22.8,
        "Challenge_reading_time":150.93,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":66,
        "Challenge_solved_time":161.8254016667,
        "Challenge_title":"Pipeline can not be built using a HyperdriveStep inside a Pipeline",
        "Challenge_topic":"Pipeline Configuration",
        "Challenge_topic_macro":"Lifecycle Management",
        "Challenge_view_count":null,
        "Challenge_word_count":701,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Solved the issue!  <\/p>\n<p>Had to remove the <strong>arguments<\/strong>  argument of the ScriptRunConfig and instead set the values to the Hyperdrive Steps <strong>estimator_entry_script_arguments<\/strong> argument.  <\/p>\n<pre><code># Step 1, Run the data prep script\nprep_step = PythonScriptStep(name = &quot;prepare_data&quot;,\n                                source_directory = pipeline_folder,\n                                script_name = &quot;cancer_pipeline_preprocessing.py&quot;,\n                                arguments = ['--input-data', datapath_input,\n                                             '--prepped-data', prepped_data_folder],\n                                inputs=[datapath_input],\n                                outputs=[prepped_data_folder],\n                                compute_target = pipeline_cluster,\n                                runconfig = pipeline_run_config,\n                                allow_reuse=False)\n\n# Define the search strategy and parameter space for hyperparameter tuning\nps = GridParameterSampling({'--max_depth': choice(1,2,3),\n                            '--n_estimators': choice(100,300)})\n# Define a early stopping criteria\nearly_termination_policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)\n# Define a ScriptRunConfig for the Training script\n# The ScriptRunConfig is based on the RunConfig of the Pipeline\nscript_run_config = ScriptRunConfig(script=&quot;cancer_pipeline_tuning.py&quot;,\n                                    source_directory=pipeline_folder,\n                                    run_config=pipeline_run_config)\n# Define a HyperDriveConfiguration\n# The primary_metric_name must be completely idential to the metric name logged during training (inside the training script)\nhd_config = HyperDriveConfig(run_config=script_run_config, \n                             hyperparameter_sampling=ps,\n                             policy=None,\n                             primary_metric_name=&quot;Accuracy&quot;, \n                             primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n                             max_total_runs=6,\n                             max_concurrent_runs=2)\n\n# Step 2b, define a HyperDriveStep\n# HyperDriveStep can be used to run HyperDrive job as a step in pipeline.\n# No arguments need to be set as they are already set inside the ScriptRunConfig\nhyperdrive_step = HyperDriveStep(name=&quot;tune_hyperparameters&quot;,\n                                 hyperdrive_config=hd_config,\n                                 # Add non-hyperparameter arguments -in this case, the training dataset\n                                 # IMPORTANT: Don't add them already in the ScriptRunConfig\n                                 estimator_entry_script_arguments=['--training_folder', prepped_data_folder],\n                                 inputs=[prepped_data_folder],\n                                 outputs=[metrics_data, saved_model],\n                                 allow_reuse=False)\n<\/code><\/pre>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":25.2,
        "Solution_reading_time":29.16,
        "Solution_score_count":5.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":183.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":26.85,
        "Challenge_answer_count":2,
        "Challenge_body":"Hi all,\n\nI've got a compute instance that cannot access the documentai processor.\u00a0 The compute engine is in the same project as the processor, and I've given the service account the roles\n\n\"Document AI API User\" and\n\"Document AI Viewer\"\u00a0\n\nThe error I receive is\n\n\"7 PERMISSION_DENIED: Request had insufficient authentication scopes.\"\u00a0\n\nwhich feels like an Oauth issue, but my reading leads me to believe that documentAI uses Application Default Credentials, and that my compute instance should use the service account for the request.\u00a0\u00a0\n\nthanks in advance for any insight.",
        "Challenge_closed_time":1675190760000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1675094100000,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/cannot-access-documentai-api-from-compute\/td-p\/515739\/jump-to\/first-unread-message",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":11.9,
        "Challenge_reading_time":7.48,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":26.85,
        "Challenge_title":"cannot access documentai api from compute",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":87.0,
        "Challenge_word_count":95,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"Hi,\n\nthanks, I had tried adding scopes, but the solution was to add a key to the service account\u00a0 add the json config to the file system and add the environment variable\u00a0\n\nGOOGLE_APPLICATION_CREDENTIALS\n\nas per\u00a0\n\nhttps:\/\/stackoverflow.com\/questions\/65703339\/fixedcredentialsprovider-gives-unauthorized-exception-w...\n\n\u00a0\n\n\u00a0\n\nView solution in original post",
        "Solution_comment_count":null,
        "Solution_link_count":1.0,
        "Solution_readability":14.8,
        "Solution_reading_time":4.41,
        "Solution_score_count":0.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":41.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":0.0275,
        "Challenge_answer_count":0,
        "Challenge_body":"We are trying to save a model using log_model_ref and add a name to it, i.e. best_auc. Then we want to be able to retrieve this model from the latest run.\nHowever, if we use RunClient.client.runs_v1.get_runs_artifacts_lineage this returns all the artifacts ever generated for that project. And if we use RunClient.get_artifacts_tree, we do have more control about which run we are looking at, but we lose the name information we set when using log_model_ref?",
        "Challenge_closed_time":1649410238000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1649410139000,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1485",
        "Challenge_link_count":0,
        "Challenge_participation_count":0,
        "Challenge_readability":7.9,
        "Challenge_reading_time":6.32,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":0.0275,
        "Challenge_title":"How to get model references logged by a specific run?",
        "Challenge_topic":"Metric Logging",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":null,
        "Challenge_word_count":83,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"To get the logged model refs:\n\nfrom polyaxon.client import RunClient\n\nrun_client = RunClient(project=\"PROJECT_NAME\", run_uuid=\"RUN_UUID\")\n\n# Query the lineage information\nlineages = run_client.get_artifacts_lineage(query=\"kind: model\").results\n\n# Download the lineage assets\nfor lineage in lineages:\n    run_client.download_artifact_for_lineage(lineage=lineage)\n\nYou can restrict the ref to specific lineage by filtering further by name:\n\nlineages = run_client.get_artifacts_lineage(query=\"kind: model, name: best_auc\").results",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":17.6,
        "Solution_reading_time":6.85,
        "Solution_score_count":1.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":47.0,
        "Tool":"Polyaxon"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":13.0756255556,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>We have developed and deployed machine learning models in AML Studio. The models were deployed using ACI and we have REST endpoints that we can make calls to successfully. Next thing that I need to do is to secure the endpoints using TLS. I am going through the following article:    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-secure-web-service#enable\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-secure-web-service#enable<\/a>    <\/p>\n<p>The article suggests that I need to get a domain and then update our DNS point to the IP address of scoring endpoint. I have a subdomain  ready to use but as for the IP address, I can't work out where I would get the IP address of the scoring endpoint and how I would even be able to map this to the endpoint as the current endpoint do not contain and IP address and look nothing like the example in the article.    <\/p>\n<p>URIs currently look like the following:    <br \/>\n<a href=\"http:\/\/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxx.northeurope.azurecontainer.io\/score\">http:\/\/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxx.northeurope.azurecontainer.io\/score<\/a>    <\/p>\n<p>Anyone able to help with this one please as it's a little confusing and I can't find any guidance online anywhere?<\/p>",
        "Challenge_closed_time":1616038303612,
        "Challenge_comment_count":0,
        "Challenge_created_time":1615991231360,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/318807\/secure-azure-machine-learning-rest-endpoints-(depl",
        "Challenge_link_count":2,
        "Challenge_participation_count":1,
        "Challenge_readability":11.1,
        "Challenge_reading_time":16.92,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":13.0756255556,
        "Challenge_title":"Secure Azure Machine Learning REST Endpoints (deployed in ACI) with TLS",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":179,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello,<\/p>\n<p>You can do it according to DNS.<\/p>\n<p>A \u201cURL\u201d is a full specification to a page. For example:<\/p>\n<p><a href=\"http:\/\/example.com\/this_is_example.html\">http:\/\/example.com\/this_is_example.html<\/a> is a URL. It has three parts:<\/p>\n<p>The protocol specifier: http:<\/p>\n<p>The domain name: example.com<\/p>\n<p>The page location: \/this_is_example.html<\/p>\n<p>The protocol specifies the port that will be used. http, for example, is  <br \/>\nport 80. ftp uses ports 20 and 21. SMTP, the mail sending protocol, is usually  <br \/>\non port 25. You can actually find the full list of \u201cofficial\u201d ports here.<\/p>\n<p>It\u2019s only the domain name that has an IP address associated with it. So that\u2019s what you would be looking up.<\/p>\n<p>My approach is to use the \u201cping\u201d command in a Windows command prompt. For  <br \/>\nexample:<\/p>\n<p>C:\\&gt;ping example.com<\/p>\n<p>Then you can get it.<\/p>\n<p>Regards,  <br \/>\nYutong<\/p>\n",
        "Solution_comment_count":2.0,
        "Solution_link_count":2.0,
        "Solution_readability":6.3,
        "Solution_reading_time":11.49,
        "Solution_score_count":0.0,
        "Solution_sentence_count":17.0,
        "Solution_word_count":131.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":0.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":1.6278808333,
        "Challenge_answer_count":1,
        "Challenge_body":"[This is a duplicate of a question I asked on stack overflow](https:\/\/stackoverflow.com\/questions\/75043118\/sagemaker-batch-transform-job-upstream-prematurely-closed-connection-when-surp)\n\nI am serving a sagemaker model through a custom docker container using [the guide that AWS provides](https:\/\/sagemaker-examples.readthedocs.io\/en\/latest\/advanced_functionality\/scikit_bring_your_own\/scikit_bring_your_own.html#When-should-I-build-my-own-algorithm-container%3F). This is a docker container that runs a simple nginx->gunicorn\/wsgi->flask server\n\nI am facing an issue where my transform requests time out around 30 minutes in all instances, despite should being able to continue to 60 minutes. I need requests to be able to go to sagemaker maximum of 60 minutes due to data intense nature of request.\n\n\n----------\n\n\nThrough experience working with this setup for some months, I know that there are 3 factors that should affect the time my server has to respond to requests:\n\n 1. Sagemaker itself will cap invocations requests according to the\n    `InvocationsTimeoutInSeconds` paremeter set when [creating the batch\n    transform\n    job](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/APIReference\/API_ModelClientConfig.html#sagemaker-Type-ModelClientConfig-InvocationsTimeoutInSeconds).\n 2. The `nginx.conf` file must be configured such that `keepalive_timeout`, `proxy_read_timeout`, `proxy_send_timeout`, and `proxy_connect_timeout` are all equal or greater than maximum timeout\n 3. gunicorn server must its timeout configured to be equal or greater than maximum timeout\n\n\n----------\n\n\nI have verified that when I create my batch transform job `InvocationsTimeoutInSeconds` is set to 3600 (1 hour)\n\nMy nginx.conf looks like this:\n\n    worker_processes 1;\n    daemon off; # Prevent forking\n    \n    \n    pid \/tmp\/nginx.pid;\n    error_log \/var\/log\/nginx\/error.log;\n    \n    events {\n      # defaults\n    }\n    \n    http {\n      include \/etc\/nginx\/mime.types;\n      default_type application\/octet-stream;\n      access_log \/var\/log\/nginx\/access.log combined;\n    \n      sendfile        on;\n      client_max_body_size 30M;\n      keepalive_timeout  3920s;\n      \n      upstream gunicorn {\n        server unix:\/tmp\/gunicorn.sock;\n      }\n    \n      server {\n        listen 8080 deferred;\n        client_max_body_size 80m;\n    \n        keepalive_timeout 3920s;\n        proxy_read_timeout 3920s;\n        proxy_send_timeout 3920s;\n        proxy_connect_timeout 3920s;\n        send_timeout 3920s;\n    \n        location ~ ^\/(ping|invocations) {\n          proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n          proxy_set_header Host $http_host;\n          proxy_redirect off;\n          proxy_pass http:\/\/gunicorn;\n        }\n    \n        location \/ {\n          return 404 \"{}\";\n        }\n      }\n    }`\n\nI start the gunicorn server like this:\n\n    def start_server():\n        print('Starting the inference server with {} workers.'.format(model_server_workers))\n        print('Model server timeout {}.'.format(model_server_timeout))\n    \n        # link the log streams to stdout\/err so they will be logged to the container logs\n        subprocess.check_call(['ln', '-sf', '\/dev\/stdout', '\/var\/log\/nginx\/access.log'])\n        subprocess.check_call(['ln', '-sf', '\/dev\/stderr', '\/var\/log\/nginx\/error.log'])\n    \n        nginx = subprocess.Popen(['nginx', '-c', '\/opt\/program\/nginx.conf'])\n        gunicorn = subprocess.Popen(['gunicorn',\n                                     '--timeout', str(3600),\n                                     '-k', 'sync',\n                                     '-b', 'unix:\/tmp\/gunicorn.sock',\n                                     '--log-level', 'debug',\n                                     '-w', str(1),\n                                     'wsgi:app'])\n    \n        signal.signal(signal.SIGTERM, lambda a, b: sigterm_handler(nginx.pid, gunicorn.pid))\n    \n        # If either subprocess exits, so do we.\n        pids = set([nginx.pid, gunicorn.pid])\n        while True:\n            pid, _ = os.wait()\n            if pid in pids:\n                break\n    \n        sigterm_handler(nginx.pid, gunicorn.pid)\n        print('Inference server exiting')\n\nDespite all this, whenever a transform job takes longer than approx 30 minutes I will see this message in my logs and the transform job status becomes failed: \n\n    2023\/01\/07 08:23:14 [error] 11#11: *4 upstream prematurely closed connection while reading response header from upstream, client: 169.254.255.130, server: , request: \"POST \/invocations HTTP\/1.1\", upstream: \"http:\/\/unix:\/tmp\/gunicorn.sock:\/invocations\", host: \"169.254.255.131:8080\"\n\nI am close to thinking there is a bug in AWS batch transform, but perhaps I am missing some other variable (perhaps in the nginx.conf) that could lead to premature upstream termination of my request.",
        "Challenge_closed_time":1673126209340,
        "Challenge_comment_count":0,
        "Challenge_created_time":1673120348969,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUbey_TyxSRrSsZ0XG99jnDQ\/sagemaker-batch-transform-upstream-prematurely-closed-connection-unable-to-serve-requests-that-take-longer-than-30-minutes",
        "Challenge_link_count":5,
        "Challenge_participation_count":1,
        "Challenge_readability":14.3,
        "Challenge_reading_time":54.91,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":34,
        "Challenge_solved_time":1.6278808333,
        "Challenge_title":"Sagemaker Batch Transform - \"upstream prematurely closed connection\" - Unable to serve requests that take longer than 30 minutes",
        "Challenge_topic":"CloudWatch Monitoring",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":67.0,
        "Challenge_word_count":450,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"By looking at hardware metrics was able to determine that the upstream termination only happens when the server was near its memory limit. So my guess is that the OS was killing the gunicorn worker and the 30 minute mark was just a coincidence that happened on my long running test cases.\n\nMy solution was to increase the memory available on the server",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":10.3,
        "Solution_reading_time":4.25,
        "Solution_score_count":0.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":63.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":36.4333333333,
        "Challenge_answer_count":1,
        "Challenge_body":"Have installed Google Cloud via pip and CLI installer, yet programs cannot seem to see import statements from Google.cloud, returning the following error:\n\nline 9, in <module>\nfrom google.cloud import vision\nModuleNotFoundError: No module named 'google.cloud'\n\nPlease advise and thank you for your time.",
        "Challenge_closed_time":1672393260000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1672262100000,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Simple-but-frustrating-error-Google-cloud-module-not-found\/td-p\/504285\/jump-to\/first-unread-message",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":6.6,
        "Challenge_reading_time":4.57,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":36.4333333333,
        "Challenge_title":"Simple but frustrating error: Google.cloud module not found",
        "Challenge_topic":"Environment Installation",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":130.0,
        "Challenge_word_count":51,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"Have you tried installing google cloud vision? You can also check what python version you are using, this package is only supported in python versions 3.7 and up.\n\nView solution in original post",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":4.2,
        "Solution_reading_time":2.37,
        "Solution_score_count":1.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":33.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":159.9731416667,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hello :)     <\/p>\n<p>Do you have any kind of idea when Azure Machine Learning Python SDK V2 could support parallel computing? We are testing things out with the machine learning studio and we are in a bit confusing stage that should we go with the SDK V1 or V2, but seemingly the V2 is not yet supporting multiple nodes in compute clusters.    <\/p>\n<p>Best regards,    <br \/>\nTuomas<\/p>",
        "Challenge_closed_time":1657774403743,
        "Challenge_comment_count":2,
        "Challenge_created_time":1657198500433,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/918129\/parallel-computing-with-python-sdk-v2",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":7.9,
        "Challenge_reading_time":5.07,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":159.9731416667,
        "Challenge_title":"Parallel computing with Python SDK V2",
        "Challenge_topic":"Pipeline Configuration",
        "Challenge_topic_macro":"Lifecycle Management",
        "Challenge_view_count":null,
        "Challenge_word_count":71,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=618a88ea-c762-4907-9a08-ae41864a250e\">@Tuomas Partanen  <\/a>     <\/p>\n<p>I have a good news for you, we are testing Parallel Run Step NOW in private preview of V2.     <\/p>\n<p>For your scenario, v1 is stable and serving all production customers. v2 (through DPv2) is still in private preview, and there are some dependency on new dataset\/mltable implementation. So if you want to seriously put some production traffic, I suggest guide to v1; but if you just want to have some prototypes, v2 may be better, as v2 is growing but v1 will not. Also, V2 will have the feature you want - Parallel.     <\/p>\n<p>The estimate time is not confirmed but should be around October.    <\/p>\n<p>I hope this helps.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p><em>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/em>    <\/p>\n",
        "Solution_comment_count":1.0,
        "Solution_link_count":0.0,
        "Solution_readability":6.9,
        "Solution_reading_time":10.65,
        "Solution_score_count":0.0,
        "Solution_sentence_count":9.0,
        "Solution_word_count":138.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":267.3833333333,
        "Challenge_answer_count":3,
        "Challenge_body":"Hi,\n\nI would like to use Google Translate API in plain javascript.\n\nAs far as I understand from this guide, the supported languages are :\u00a0\n\nGo\nJava\nNode.js\nPython\n\n... and some additional languages :\n\nC#\nPhp\nRuby\n\nDoes translate API is supported for Javascript as well? If so, where is the guide?\n\nThanks in advance.",
        "Challenge_closed_time":1641823740000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1640861160000,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Translate-API\/td-p\/181620\/jump-to\/first-unread-message",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":3.3,
        "Challenge_reading_time":4.0,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":267.3833333333,
        "Challenge_title":"Google Translate API",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":347.0,
        "Challenge_word_count":55,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"Here is a third-party solution you may find useful [1].\u00a0You may also report it to the Public Issue Tracker (PIT) [2]\u00a0 as well as feature request.\n\n[1]\u00a0 https:\/\/github.com\/topics\/javascript-translate\n\n[2]\u00a0https:\/\/cloud.google.com\/support\/docs\/issue-trackers\n\nView solution in original post",
        "Solution_comment_count":null,
        "Solution_link_count":2.0,
        "Solution_readability":10.3,
        "Solution_reading_time":3.64,
        "Solution_score_count":0.0,
        "Solution_sentence_count":4.0,
        "Solution_word_count":36.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":20.7202602778,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>Hello, I am using Azure machine learning studio, which has been changed since last year.    <\/p>\n<p>Previously, the Azure Machine Learning designer function of the Classic version could be applied to Excel by importing the App function to Excel and downloading it. Like the picture below!    <\/p>\n<p>Has the function that can be linked to Excel be lost in this Azure Machine Learning Studio? it's very difficult....    <\/p>\n<p>If there is a function, can you tell me how to do it?    <\/p>\n<p>And I wonder if there are any lectures that explain the new azure machine learning designer features.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/178194-azure2.png?platform=QnA\" alt=\"178194-azure2.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/178202-azure1.png?platform=QnA\" alt=\"178202-azure1.png\" \/>    <\/p>",
        "Challenge_closed_time":1646044643350,
        "Challenge_comment_count":0,
        "Challenge_created_time":1645970050413,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/752248\/azure-machine-learning-studio-for-designer-functio",
        "Challenge_link_count":2,
        "Challenge_participation_count":2,
        "Challenge_readability":9.0,
        "Challenge_reading_time":11.88,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":10,
        "Challenge_solved_time":20.7202602778,
        "Challenge_title":"Azure machine learning studio for designer function connected with excel?",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":117,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=3b41fd96-f090-42a6-b421-e5af3d214f5f\">@Robin Jang  <\/a> The designer studio does not have an add-in for excel. This is only available with the classic version of Azure Machine Learning.     <br \/>\nIf you are new to Azure machine learning designer I would recommend to start with the tutorials from Microsoft Learn available <a href=\"https:\/\/learn.microsoft.com\/en-us\/learn\/browse\/?filter-products=machine&amp;products=azure-machine-learning\">here<\/a>.    <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":3.0,
        "Solution_readability":14.2,
        "Solution_reading_time":11.27,
        "Solution_score_count":0.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":77.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":788.5729277778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi Team,     <\/p>\n<p>When I Submit the Batch Inference Pipeline. It is working.     <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/158498-1-image-designer.png?platform=QnA\" alt=\"158498-1-image-designer.png\" \/>    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/158597-2-image-designer.png?platform=QnA\" alt=\"158597-2-image-designer.png\" \/>    <\/p>\n<p>After submitting, I can see the file:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/158519-3-image-designer.png?platform=QnA\" alt=\"158519-3-image-designer.png\" \/>    <\/p>\n<p>Then when I Publish, the file is not in the Datastore. The file is not generated again. I didn't get an error.    <\/p>\n<p>Kind regards,     <br \/>\nAnaid    <\/p>",
        "Challenge_closed_time":1642583796710,
        "Challenge_comment_count":2,
        "Challenge_created_time":1639744934170,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/667479\/problem-aml-designer-batch-inference-pipeline",
        "Challenge_link_count":3,
        "Challenge_participation_count":3,
        "Challenge_readability":14.2,
        "Challenge_reading_time":10.44,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":10,
        "Challenge_solved_time":788.5729277778,
        "Challenge_title":"Problem: AML Designer - Batch Inference Pipeline",
        "Challenge_topic":"Pipeline Configuration",
        "Challenge_topic_macro":"Lifecycle Management",
        "Challenge_view_count":null,
        "Challenge_word_count":67,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=4bb27b25-616e-491c-b986-136b5bf96f77\">@Anaid  <\/a>     <\/p>\n<p>Hi,    <\/p>\n<p>I\u2019ve enabled one-time Free Technical Support for you.  To create the support request, please do the following:     <\/p>\n<p>\u2022            Go to the Health Advisory section within the Azure Portal: <a href=\"https:\/\/aka.ms\/healthadvisories\">https:\/\/aka.ms\/healthadvisories<\/a>      <br \/>\n\u2022            Select the Issue Name &quot;You have been enabled for one-time Free Technical Support&quot;     <br \/>\n\u2022            Details will populate below in the Summary Tab within the reading pane and you can click on the link &quot;Create a Support Request&quot; to the right of the message    <\/p>\n<p>Let me know what your support request number is so that I can keep track of your case. If you run into any issues, feel free to let me know.    <\/p>\n<p>Regards,    <br \/>\nYutong<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":1.0,
        "Solution_readability":11.2,
        "Solution_reading_time":10.22,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":116.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":0.1111111111,
        "Challenge_answer_count":1,
        "Challenge_body":"A wants to manage Sagemaker resources (such as models and endpoints) via CloudFormation. As part of their model deployment pipeline, they'd like to be able to create or update existing Sagemaker Endpoint with new model data. Customers wants to re-use the same endpoint name for a given workload. \n\n**Question:**\n\nHow to express in CF a following logic:\n1. If Sagemaker endpoint with name \"XYZ\" doesn't exist in customer account, then create a new endpoint;\n2. If Sagemaker endpoint with name \"XYZ\" already exist, then update existing endpoint with new model data.",
        "Challenge_closed_time":1607357193000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1607356793000,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUXiLSnlxkQHKzQVFj6GKT7w\/create-or-update-sagemaker-endpoint-via-cloudformation",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":8.7,
        "Challenge_reading_time":7.62,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":0.1111111111,
        "Challenge_title":"Create or update Sagemaker Endpoint via CloudFormation",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":425.0,
        "Challenge_word_count":97,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"This functionality of \"UPSERT\" type does not exist in CFn natively. You would need to use a Custom Resource to handle this logic.\nOne alternative that is not exactly what you asked for but might be a decent compromise is to use a Parameter to supply the endpoint if it does exist. Then use a condition to check the value. If the paramter is blank then create an endpoint if not use the value supplied.\nI know this is not what you asked for but it allows you to avoid the custom resource solution.\n\nSample of similiar UPSERT example for a VPC:\n\n```\nParameters :\n\n  Vpc:\n    Type: AWS::EC2::VPC::Id\n\nConditions:\n\n  VpcNotSupplied: !Equals [!Ref Vpc, '']\n\nResources:\n\n  NewVpc:\n    Type: AWS::EC2::VPC\n    Condition: VpcNotSupplied\n    Properties:\n      CidrBlock: 10.0.0.0\/16\n\n  SecurityGroup:\n    Type: AWS::EC2::SecurityGroup\n    Properties:\n      GroupDescription: Sample\n      GroupName: Sample\n      VpcId: !If [VpcNotSupplied, !Ref NewVpc, !Ref Vpc ]\n```\n\nHere the `Vpc` input parameter can be supplied if the VPC you wish to use already exists, left blank if you want to create a new one. The NewVPC resource uses the `Condition` to only create if the supplied Vpc parameter value is blank. The Security group then uses the same condition to decide whetehr to use and existing Vpc or the newly created one.\n\nHope this makes sense.",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":9.4,
        "Solution_reading_time":15.59,
        "Solution_score_count":0.0,
        "Solution_sentence_count":13.0,
        "Solution_word_count":204.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":0.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":2183.8986427778,
        "Challenge_answer_count":2,
        "Challenge_body":"We have a gitlab repo within a private VPN and would like to setup Studio to clone that repo and to push and pull updates. Is that possible yet from within Studio?",
        "Challenge_closed_time":1650994900956,
        "Challenge_comment_count":1,
        "Challenge_created_time":1643132865842,
        "Challenge_favorite_count":1.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QURGs7VOVlTzKCG7H2AFLWww\/how-can-we-connect-a-sagemaker-studio-user-to-a-gitlab-repo-within-a-private-vpn",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":8.2,
        "Challenge_reading_time":2.92,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":2183.8986427778,
        "Challenge_title":"How can we connect a Sagemaker Studio user to a gitlab repo within a private VPN?",
        "Challenge_topic":"Git Version Control",
        "Challenge_topic_macro":"Code Management",
        "Challenge_view_count":367.0,
        "Challenge_word_count":47,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"Thank you for your response. For those looking to do the same thing, according to AWS Support AWS SageMakers does NOT support GitLab yet and there is no ETA for that feature.",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":6.0,
        "Solution_reading_time":2.1,
        "Solution_score_count":0.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":32.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":0.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":0.5526797223,
        "Challenge_answer_count":1,
        "Challenge_body":"According to the doc ( https:\/\/sagemaker.readthedocs.io\/en\/stable\/api\/training\/smd_model_parallel_general.html ), there are different parameters depending on the version of `smdistributed-modelparallel` module \/ package. However, I am unable to find a way to check the version (e.g. via sagemaker python SDK) or just from the training container documentation (e.g. https:\/\/github.com\/aws\/deep-learning-containers\/blob\/master\/available_images.md#huggingface-training-containers ).\n\nAny idea?\n\nThanks!",
        "Challenge_closed_time":1660807962126,
        "Challenge_comment_count":0,
        "Challenge_created_time":1660805972479,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUsfpWY8CuRsiyHg_x7qyJzw\/how-to-check-smdistributed-modelparallel-version",
        "Challenge_link_count":2,
        "Challenge_participation_count":1,
        "Challenge_readability":20.2,
        "Challenge_reading_time":7.26,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":0.5526797223,
        "Challenge_title":"How to check smdistributed-modelparallel version?",
        "Challenge_topic":"Environment Installation",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":105.0,
        "Challenge_word_count":50,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"Have not yet found a programmatic way to check the version.\n\nHowever, for each DLC (Deep Learning Container) available at \nhttps:\/\/github.com\/aws\/deep-learning-containers\/blob\/master\/available_images.md , we can look at the corresponding docker build files.\n\nE.g. for `PyTorch 1.10.2 with HuggingFace transformers` DLC, the corresponding dockerfile is here: https:\/\/github.com\/aws\/deep-learning-containers\/blob\/master\/huggingface\/pytorch\/training\/docker\/1.10\/py3\/cu113\/Dockerfile.gpu\n\nAnd we can see that the version: `smdistributed_modelparallel-1.8.1-cp38-cp38-linux_x86_64.whl`.",
        "Solution_comment_count":0.0,
        "Solution_link_count":2.0,
        "Solution_readability":16.1,
        "Solution_reading_time":7.71,
        "Solution_score_count":0.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":52.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":29.4160616667,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi ,   <\/p>\n<p>I have a have a dataset from the labelled data using the  ML Data Labeling tool , my question is how can use the dataset to train a model ? , I tried Automated ML but I cannot make ant connection with the dataset .  <\/p>\n<p>Thanks for your help.<\/p>",
        "Challenge_closed_time":1623240266352,
        "Challenge_comment_count":4,
        "Challenge_created_time":1623134368530,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/426209\/machine-learning-studio-data-labeling-dataset",
        "Challenge_link_count":0,
        "Challenge_participation_count":5,
        "Challenge_readability":6.1,
        "Challenge_reading_time":3.7,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":29.4160616667,
        "Challenge_title":"Machine Learning studio Data Labeling Dataset",
        "Challenge_topic":"Data Labeling",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":null,
        "Challenge_word_count":53,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=4eb02c39-e084-433a-9d5e-4fce46999081\">@hernandoZ  <\/a> I can confirm that using labeling data in the designer is currently not supported. This is however part of the roadmap in the future releases of designer. You can consume the data with the SDK as mentioned above.<\/p>\n",
        "Solution_comment_count":4.0,
        "Solution_link_count":0.0,
        "Solution_readability":9.8,
        "Solution_reading_time":3.82,
        "Solution_score_count":0.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":41.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":7.809835,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hello experts, we are working on a medium size solution for our company and we are exploring basic estimate for SDK or studio decision. How I can know? <\/p>",
        "Challenge_closed_time":1658757422623,
        "Challenge_comment_count":0,
        "Challenge_created_time":1658729307217,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/940045\/estimate-the-cost-for-machine-learning-sdk-or-ui-p",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":8.2,
        "Challenge_reading_time":2.61,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":7.809835,
        "Challenge_title":"Estimate the cost for Machine learning SDK or UI portal",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":38,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=ce84de18-8973-44f3-8101-f191f9216b1f\">@Alexandre  <\/a>     <\/p>\n<p>Thanks for reachin out to us, the Azure Machine Learnng pricing mainly is consist of CPU pricing and compute pricing, to get a better estimate pricing, a good way to calculate is using the calculator - <a href=\"https:\/\/azure.microsoft.com\/en-us\/pricing\/calculator\/\">https:\/\/azure.microsoft.com\/en-us\/pricing\/calculator\/<\/a>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/224435-image.png?platform=QnA\" alt=\"224435-image.png\" \/>    <\/p>\n<p>You can add your details into it and you will have a general idea about that.    <\/p>\n<p>I hope this helps, thank you.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":2.0,
        "Solution_readability":11.6,
        "Solution_reading_time":10.55,
        "Solution_score_count":0.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":92.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":16.2021597222,
        "Challenge_answer_count":13,
        "Challenge_body":"<p>Dear Sir or Madam,<\/p>\n<p>Sorry for bothering you, I think there is an error in one of my wandb projects and the records of all runs were lost. The account is nbower0707, email 1155156871@link.cuhk.edu.hk, and the project name is ocp22.<\/p>\n<p>Everything worked fine before today, and I did a lot of experiments on this project. I\u2019m uploading records of my metric around every 5000 steps, and the result validation metric plot should be something like  figure 1 shows(continuous lines of records, with multiple data points) I\u2019m uploading the corresponding metrics every 2500 steps, and wandb displayed all results fine yesterday (either undergoing or finished runs)<\/p>\n<p>However, when I check the plot today, the record of metric in all runs were (completely or partly) lost, except for some small isolated data points left (as figure 2 and 3 shows).<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/a14c097f39437a5f49c44e628d5d3e3d92490c4d.jpeg\" data-download-href=\"\/uploads\/short-url\/n0TMrYL9SyvpaH1YKsBmceDhhRb.jpeg?dl=1\" title=\"Picture 1\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/a14c097f39437a5f49c44e628d5d3e3d92490c4d_2_414x500.jpeg\" alt=\"Picture 1\" data-base62-sha1=\"n0TMrYL9SyvpaH1YKsBmceDhhRb\" width=\"414\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/a14c097f39437a5f49c44e628d5d3e3d92490c4d_2_414x500.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/a14c097f39437a5f49c44e628d5d3e3d92490c4d_2_621x750.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/a14c097f39437a5f49c44e628d5d3e3d92490c4d_2_828x1000.jpeg 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/a14c097f39437a5f49c44e628d5d3e3d92490c4d_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Picture 1<\/span><span class=\"informations\">2337\u00d72818 348 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>I tried to use <strong>wandb sync<\/strong> from the local file, and upload the runs to a new project, the result is still the same.<\/p>\n<p>I didn\u2019t do any specific operations regarding wandb logging process or on the website. The project consist of runs uploaded from different machines, therefore it wouldn\u2019t be mistakenly deletion\/ false operation offline. And the phenomenon of lost of data also occurs on old runs that finished weeks ago.<\/p>\n<p>Please let me know if you have any suggestions on this error, and if the records could be recovered.<\/p>\n<p>Your time and patience are sincerely appreciated.<\/p>\n<p>Bowen Wang<\/p>",
        "Challenge_closed_time":1661461646292,
        "Challenge_comment_count":0,
        "Challenge_created_time":1661403318517,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/all-records-are-lost-in-a-project-without-any-action\/2993",
        "Challenge_link_count":6,
        "Challenge_participation_count":13,
        "Challenge_readability":13.5,
        "Challenge_reading_time":39.24,
        "Challenge_score_count":5.0,
        "Challenge_sentence_count":17,
        "Challenge_solved_time":16.2021597222,
        "Challenge_title":"All records are lost in a project without any action",
        "Challenge_topic":"Compute Management",
        "Challenge_topic_macro":"Computation Management",
        "Challenge_view_count":273.0,
        "Challenge_word_count":289,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hey all,<\/p>\n<p>Our engineering team looked into this and rolled back some changes, everything should be working fine now.<\/p>\n<p>Please let us know if this issue persists.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":4.7,
        "Solution_reading_time":2.59,
        "Solution_score_count":null,
        "Solution_sentence_count":3.0,
        "Solution_word_count":29.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":99.2333333333,
        "Challenge_answer_count":3,
        "Challenge_body":"I have exported my trained tflite model. But I noticed the order of the labels in the txt file matters. I'm using image classification models. The ones with only two labels, it's an easy fix. I just switch the two. But when I have more than two labels, I notice the predictions are way off. Does it say in Vertex AI or is there a general rule to what label should go first, second, third..etc in the txt file that we create on our own?",
        "Challenge_closed_time":1666711620000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1666354380000,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/What-s-the-order-for-the-labels-in-txt-file-after-I-have\/td-p\/480804\/jump-to\/first-unread-message",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":4.2,
        "Challenge_reading_time":6.32,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":99.2333333333,
        "Challenge_title":"What's the order for the labels in txt file after I have exported my tflite model from Vertex AI",
        "Challenge_topic":"Data Labeling",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":380.0,
        "Challenge_word_count":103,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"After reviewing more about Export AutoML Edge models, you can see the following TensorFlow documentation to learn more about extracting this information.\n\nTensorFlow Lite inference with metadata\nGenerate model interfaces with TensorFlow Lite code generator\nAdding metadata to TensorFlow Lite models\n\nThe documentation that might help more for your question is the last one \u201cAdding metadata to TensorFlow Lite Models\u201d.\n\nBut what I can suggest to you is to send an email to tensorflow-enterprise-support@google.com with your question, and hopefully they can give you a direct solution to your concerns.\n\nAdditionally, I found this Stack Overflow question to create labels.txt manually.\n\nView solution in original post",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":12.5,
        "Solution_reading_time":8.9,
        "Solution_score_count":0.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":105.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":20.56922,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>Bunch of secrets being automatically created in key vault that is integrated into Azure ML workspace(s). These secrets seem to be generated by the ML resource\/service itself and continues to generate new secrets.<\/p>\n<p>\u00a0Can you please help with the document for these secrets?<\/p>",
        "Challenge_closed_time":1682931416008,
        "Challenge_comment_count":1,
        "Challenge_created_time":1682857366816,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1270782\/secrets-automatically-created-in-key-vault",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":10.4,
        "Challenge_reading_time":4.1,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":20.56922,
        "Challenge_title":"Secrets automatically created in key vault",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":49,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>@<a href=\"https:\/\/learn.microsoft.com\/en-us\/users\/na\/?userid=dfa9d536-725c-462d-87c8-47fbafb1a2bc\">D-0887<\/a> Thanks, When you perform operations in Azure ML that require secret values to be stored like creating connections, datastores, or workspace management operations, the key vault instance associated to the workspace is used to store those secrets.<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":1.0,
        "Solution_readability":22.0,
        "Solution_reading_time":4.76,
        "Solution_score_count":0.0,
        "Solution_sentence_count":1.0,
        "Solution_word_count":39.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":0.2683527778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I have imported packages:    <\/p>\n<p>library(dplyr)    <\/p>\n<p>Uploaded my dataset:    <\/p>\n<p>bike &lt;- readRDS(&quot;bike.rds&quot;)    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/16798-image.png?platform=QnA\" alt=\"16798-image.png\" \/>    <\/p>\n<p>But when I try simple &quot;filter&quot; it is not working:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/16867-image.png?platform=QnA\" alt=\"16867-image.png\" \/>    <\/p>",
        "Challenge_closed_time":1597097170387,
        "Challenge_comment_count":0,
        "Challenge_created_time":1597096204317,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/63901\/simple-filter-is-not-working-in-azure-notebook-for",
        "Challenge_link_count":2,
        "Challenge_participation_count":1,
        "Challenge_readability":16.9,
        "Challenge_reading_time":6.86,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":0.2683527778,
        "Challenge_title":"Simple filter is not working in Azure notebook for R",
        "Challenge_topic":"Dataset Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":null,
        "Challenge_word_count":43,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Fixed.  <\/p>\n<p>It looks azure notebook clean the session after some period of inactivity, there the package dplyr was not loaded after some time<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":11.5,
        "Solution_reading_time":1.88,
        "Solution_score_count":1.0,
        "Solution_sentence_count":1.0,
        "Solution_word_count":24.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":4.3046052778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am newly starting in machine learning field with basic training now.  <br \/>\nI am not sure about the difference and whichever should be used for beginner <\/p>",
        "Challenge_closed_time":1653921374096,
        "Challenge_comment_count":0,
        "Challenge_created_time":1653905877517,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/869589\/azure-ml-and-ml-net-which-is-better",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":4.2,
        "Challenge_reading_time":2.41,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":4.3046052778,
        "Challenge_title":"Azure ML and ML.net which is better",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":34,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=9836544a-a7dc-4344-a8ac-804ab892757e\">@Joel  <\/a>  Thanks for the question. Azure ML is a cloud service where you pay for the compute power that you &quot;burn&quot; whereas ML.NET is a Toolkit for . net that you can run anywhere. You don't pay anything for using ML.NET itself.     <\/p>\n<p>Azure ML Empower data scientists and developers to build, deploy, and manage high-quality models faster and with confidence. Here is the <a href=\"https:\/\/azure.microsoft.com\/en-in\/services\/machine-learning\/#product-overview\">document<\/a> for Azure ML.    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":1.0,
        "Solution_readability":7.9,
        "Solution_reading_time":7.35,
        "Solution_score_count":0.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":71.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":0.8001691667,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I can\u2019t find some of the basic modules from this week. Any significant change about Designer? <\/p>",
        "Challenge_closed_time":1660841903856,
        "Challenge_comment_count":0,
        "Challenge_created_time":1660839023247,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/972775\/change-in-machine-learning-designer",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":6.0,
        "Challenge_reading_time":1.72,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":0.8001691667,
        "Challenge_title":"Change in Machine Learning Designer",
        "Challenge_topic":"Pipeline Configuration",
        "Challenge_topic_macro":"Lifecycle Management",
        "Challenge_view_count":null,
        "Challenge_word_count":21,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=2ce87912-8dda-483a-8ead-0e2912a6e6ef\">@Mofoch  <\/a>     <\/p>\n<p>Thanks for using Microsoft Q&amp;A platform, there is no surprising change in Azure Machine Learning Designer.    <\/p>\n<p>Based on my experience, you may use the filter so you can not see some of the modules as below screenshot.     <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/232490-image.png?platform=QnA\" alt=\"232490-image.png\" \/>    <\/p>\n<p>If this is not your case, could you please share which module you have lost? Thanks.     <\/p>\n<p>I hope this helps.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":1.0,
        "Solution_readability":8.4,
        "Solution_reading_time":9.0,
        "Solution_score_count":0.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":91.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":14.6736786111,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hello,    <\/p>\n<p>In my MLStudio my notebook files window has disappeared so I can not access any of my data (as seen on the image) and I do not know what to do.    <\/p>\n<p>Please your help to solve this as soon as poosible.    <\/p>\n<p>Thank you.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/203167-image.png?platform=QnA\" alt=\"203167-image.png\" \/>    <\/p>",
        "Challenge_closed_time":1652928385600,
        "Challenge_comment_count":1,
        "Challenge_created_time":1652875560357,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/854288\/notebook-files-have-disaperred",
        "Challenge_link_count":1,
        "Challenge_participation_count":2,
        "Challenge_readability":7.6,
        "Challenge_reading_time":5.16,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":14.6736786111,
        "Challenge_title":"Notebook files have disaperred",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":55,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello,    <\/p>\n<p>Thanks for reaching out to us. Could you please check the access of Storage?  <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/storage\/blobs\/assign-azure-role-data-access?tabs=portal#assign-an-azure-role\">https:\/\/learn.microsoft.com\/en-us\/azure\/storage\/blobs\/assign-azure-role-data-access?tabs=portal#assign-an-azure-role<\/a>    <\/p>\n<p>To access these storage services, you must have at least Storage Blob Data Reader access to the storage account. Only storage account owners can change your access level via the Azure portal.    <\/p>\n<p>Or, your admin put the data storage behind V-Net and you can not get access to it- <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-identity-based-data-access#work-with-virtual-networks\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-identity-based-data-access#work-with-virtual-networks<\/a>    <br \/>\nIn this situation, you need to ask permission from your admin.    <\/p>\n<p>Could you please share which situation you are in?     <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n",
        "Solution_comment_count":2.0,
        "Solution_link_count":2.0,
        "Solution_readability":14.0,
        "Solution_reading_time":13.94,
        "Solution_score_count":0.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":98.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":1.9663888889,
        "Challenge_answer_count":1,
        "Challenge_body":"What is value and use case for Deep Learning AMI (DLAMI)?\n\nIt seems that customers often pack ML dependencies at the docker level (themselves, or with DL containers or with SageMaker containers), instead of the AMI level. So what is the value and use-case of DL AMI ?",
        "Challenge_closed_time":1594216705000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1594209626000,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUQInSlgeCS6mIe4DJv3KwnQ\/what-is-value-and-use-case-for-deep-learning-ami-dlami",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":6.5,
        "Challenge_reading_time":3.92,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":1.9663888889,
        "Challenge_title":"What is value and use case for Deep Learning AMI (DLAMI)?",
        "Challenge_topic":"Docker Configuration",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":179.0,
        "Challenge_word_count":57,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":1.0,
        "Poster_isModerator":0.0,
        "Solution_body":"The value of the DLAMI (https:\/\/docs.aws.amazon.com\/dlami\/latest\/devguide\/what-is-dlami.html) is ease of use and saving time to get up to speed in a development environment.  If you are developing code for ML there is a huge variety of frameworks and software that you might need to install. The DLAMI includes the more popular ones, so you may quickly deploy a machine complete with common dependencies. This results in a reduction of the time needed for installing and configuring things. It speeds up experimentation and evaluation. If you want to try a new framework, it is already there.\n\nThe second reason is that AWS keeps the AMI up to date, so you may just deploy a new AMI periodically rather than having to patch.  Again, this saves you time and lets you concentrate on the underlying development and business activities.\n\nAll that said, for running in production and at volume you might want to use a different tool, I would imagine that for most cases creating docker images to your specific requirements would make a lot of sense. No need to go over the good and bad points of containers here.",
        "Solution_comment_count":0.0,
        "Solution_link_count":1.0,
        "Solution_readability":8.7,
        "Solution_reading_time":13.47,
        "Solution_score_count":0.0,
        "Solution_sentence_count":11.0,
        "Solution_word_count":187.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":70.6300730556,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi,  <\/p>\n<p>I have made deployment of the model from the AutoML experiment, due to the issue in the resources associated. Deployment has failed.  <\/p>\n<p>But the real-time endpoint has been in the transition state for few hours,  I can't delete it and the model registered along with it due to this. How can I force delete in this case. Please provide a solution.   <\/p>\n<p>Thanks  <\/p>",
        "Challenge_closed_time":1629112596936,
        "Challenge_comment_count":1,
        "Challenge_created_time":1628858328673,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/513012\/how-to-delete-azure-ml-real-time-endpoints-which-i",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":5.3,
        "Challenge_reading_time":5.57,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":70.6300730556,
        "Challenge_title":"how to delete Azure ML real-time endpoints which is in transition state",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":78,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Thank you for the response <a href=\"\/users\/na\/?userid=bc467a93-95da-4dea-bc82-06951da4cfad\">@romungi-MSFT  <\/a>. I have left the feedback to the team.<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":8.8,
        "Solution_reading_time":2.07,
        "Solution_score_count":0.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":16.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":24.4168155556,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi, there was a website for machine learning studio. You can publish your pipelines and you can also get others publish. But it not works for designer. Is there any plan for the platform migration? <\/p>",
        "Challenge_closed_time":1669854634263,
        "Challenge_comment_count":1,
        "Challenge_created_time":1669766733727,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1109523\/ai-gallery-for-designer",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":4.0,
        "Challenge_reading_time":2.81,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":24.4168155556,
        "Challenge_title":"AI gallery for Designer",
        "Challenge_topic":"Pipeline Configuration",
        "Challenge_topic_macro":"Lifecycle Management",
        "Challenge_view_count":null,
        "Challenge_word_count":39,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=662ea9f1-8d5c-4484-9ff1-c27d48858639\">@Markswift  <\/a>     <\/p>\n<p>I am sorry the AI gallery currently is not supporting Azure Machine Learning Service Designer at this moment, but I do see there are some sample shared by offcial product team. Currently you can refer to it for general style project.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/265941-image.png?platform=QnA\" alt=\"265941-image.png\" \/>    <\/p>\n<p>I will bring this feedback to product team, but at this moment we still need to wait for the next step plan. I hope this helps.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to suppor the community, thanks a lot.    <\/p>\n",
        "Solution_comment_count":1.0,
        "Solution_link_count":1.0,
        "Solution_readability":8.8,
        "Solution_reading_time":9.3,
        "Solution_score_count":0.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":99.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":0.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":9.6287383334,
        "Challenge_answer_count":1,
        "Challenge_body":"Hello. I created a Notebook Job Definition, scheduled to run every hour. According to the status it is \"Active\". Whenever I manually trigger the job with the \"Run Job\" button, it creates a new Notebook Job and runs successfully. However, the notebook never runs on the schedule. It should execute every hour, but instead only executes when manually triggered.\n\nIs there anything I need to do for the notebook to obey the schedule? Thanks,",
        "Challenge_closed_time":1675405386807,
        "Challenge_comment_count":0,
        "Challenge_created_time":1675370723349,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUjxD8Cf8lTc2Tknbt4MAzFQ\/sagemaker-notebook-doesn-t-run-on-job-schedule",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":7.7,
        "Challenge_reading_time":5.95,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":9.6287383334,
        "Challenge_title":"Sagemaker notebook doesn't run on Job schedule",
        "Challenge_topic":"Compute Management",
        "Challenge_topic_macro":"Computation Management",
        "Challenge_view_count":74.0,
        "Challenge_word_count":80,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"Are there any problems with IAM role settings, etc.?\n\nPlease check this document for reference only.\nhttps:\/\/aws.amazon.com\/jp\/blogs\/machine-learning\/operationalize-your-amazon-sagemaker-studio-notebooks-as-scheduled-notebook-jobs\/",
        "Solution_comment_count":1.0,
        "Solution_link_count":1.0,
        "Solution_readability":21.9,
        "Solution_reading_time":3.14,
        "Solution_score_count":1.0,
        "Solution_sentence_count":2.0,
        "Solution_word_count":17.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":6.5462247223,
        "Challenge_answer_count":6,
        "Challenge_body":"<p>Hi,<br>\nI am using Sweeps to run through different configuration models and I was told by the wandb chat support that to run the best model configuration off sweeps is to create a new sweep with the best performing parameter set and running off it.<\/p>\n<p>But this is lot of tedious work, is there any other elegant way of quering wandb project for the best model configuration and running off it?<\/p>\n<p>tldr: I run a sweep with different configuration, would like to run predictions off a specific set of parameters (or best performing set of parameters). How  to do it with the sweep API?<\/p>",
        "Challenge_closed_time":1652695869278,
        "Challenge_comment_count":0,
        "Challenge_created_time":1652672302869,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/run-best-model-off-sweep\/2423",
        "Challenge_link_count":0,
        "Challenge_participation_count":6,
        "Challenge_readability":10.5,
        "Challenge_reading_time":7.58,
        "Challenge_score_count":2.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":6.5462247223,
        "Challenge_title":"Run best model off sweep?",
        "Challenge_topic":"Hyperparameter Tuning",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":580.0,
        "Challenge_word_count":108,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi <a class=\"mention\" href=\"\/u\/cyrilw\">@cyrilw<\/a><\/p>\n<p>Thanks for persisting with this and posting it here, here is how you do it with the Api.<\/p>\n<pre><code class=\"lang-auto\">import wandb\n\napi = wandb.Api()\nsweep = api.sweep(f\"_scott\/project-name\/sweeps\/qwbwbwbz\")\n\n# Get best run parameters\nbest_run = sweep.best_run(order='validation\/accuracy')\nbest_parameters = best_run.config\nprint(best_parameters)\n<\/code><\/pre>\n<p>Hope this helps <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/magic_wand.png?v=12\" title=\":magic_wand:\" class=\"emoji\" alt=\":magic_wand:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":1.0,
        "Solution_readability":13.1,
        "Solution_reading_time":8.17,
        "Solution_score_count":null,
        "Solution_sentence_count":7.0,
        "Solution_word_count":50.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":0.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":4.27,
        "Challenge_answer_count":1,
        "Challenge_body":"Which Amazon SageMaker built-in algorithms support checkpointing? In the [documentation][1] it says that:\n\n> SageMaker built-in algorithms and marketplace algorithms that do not checkpoint are currently limited to a `MaxWaitTimeInSeconds` of 3600 seconds (60 minutes).\n\nHowever, in the algorithms I don't find any pointer to \"checkpoint\" or \"spot\". Can you help me out?\n\n  [1]: https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/model-managed-spot-training.html",
        "Challenge_closed_time":1593611388000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1593596016000,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QURbWeXcwDT8i4dvXKE4HZXg\/amazon-sagemaker-built-in-algorithms-and-spot-checkpointing",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":12.7,
        "Challenge_reading_time":6.65,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":4.27,
        "Challenge_title":"Amazon SageMaker Built-in algorithms and Spot checkpointing",
        "Challenge_topic":"Model Persistence",
        "Challenge_topic_macro":"Model Management",
        "Challenge_view_count":55.0,
        "Challenge_word_count":60,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"This is the best resource that I've found to clarify this:\n\nhttps:\/\/aws.amazon.com\/blogs\/aws\/managed-spot-training-save-up-to-90-on-your-amazon-sagemaker-training-jobs\/\n\n> Built-in algorithms: computer vision algorithms support checkpointing (Object Detection, Semantic Segmentation, and very soon Image Classification). As they tend to train on large data sets and run for longer than other algorithms, they have a higher likelihood of being interrupted. Other built-in algorithms do not support checkpointing for now.\n\nAlso:\n\n> Please note that TensorFlow uses checkpoints by default. For other frameworks, you\u2019ll find examples in our sample notebooks and in the documentation.",
        "Solution_comment_count":0.0,
        "Solution_link_count":1.0,
        "Solution_readability":12.3,
        "Solution_reading_time":8.67,
        "Solution_score_count":0.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":84.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":12.4729783333,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>I am able to find the pricing the page for SDK or designer, are they pricing the same?<\/p>",
        "Challenge_closed_time":1654080178612,
        "Challenge_comment_count":0,
        "Challenge_created_time":1654035275890,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/872161\/is-machine-learning-sdk-and-designer-pricing-the-s",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":4.8,
        "Challenge_reading_time":1.79,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":2,
        "Challenge_solved_time":12.4729783333,
        "Challenge_title":"Is machine learning SDK and designer pricing the same",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":26,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=fd7f30ec-b4f1-4575-a425-a49ca6a1a14e\">@ben wu  <\/a> Adding to <a href=\"\/users\/na\/?userid=8005b94c-3fff-0003-0000-000000000000\">@Dave Patrick  <\/a> response, Since you have used the tag azure-machine-learning tag I think you are using the latest version of Azure Machine Learning rather than classic studio. In the case of the new Azure Machine Learning studio and the SDK there will be no charge for using the service. You will only be charged for the compute used for your experiments and other Azure services consumed, including but not limited to Azure Blob Storage, Azure Key Vault, Azure Container Registry and Azure Application Insights. Please check the details of pricing for compute for Azure ML on this <a href=\"https:\/\/azure.microsoft.com\/en-in\/pricing\/details\/machine-learning\/\">page<\/a>.    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":1.0,
        "Solution_readability":10.5,
        "Solution_reading_time":10.66,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":108.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":1.4038472222,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hallo, i would like make an appointment for Exam AI-900: Microsoft Azure AI Fundamentals.     <br \/>\nHowever this exam is currently not available at Pearson vue or Certiport. When can i expect this again? Is there an alternative ?<\/p>",
        "Challenge_closed_time":1662210933980,
        "Challenge_comment_count":0,
        "Challenge_created_time":1662205880130,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/992629\/certification-test-for-ai-900-microsoft-azure-ai-f",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":8.1,
        "Challenge_reading_time":3.86,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":5,
        "Challenge_solved_time":1.4038472222,
        "Challenge_title":"certification test for AI-900: Microsoft Azure AI Fundamentals not available",
        "Challenge_topic":"Role Management",
        "Challenge_topic_macro":"Identity Management",
        "Challenge_view_count":null,
        "Challenge_word_count":47,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi Jurian,    <\/p>\n<p>This is available in PearsonVue check this.  <a href=\"https:\/\/learn.microsoft.com\/en-us\/certifications\/exams\/ai-900\">ai-900<\/a>    <\/p>\n<p>Any specific region you are trying from?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/237503-image.png?platform=QnA\" alt=\"237503-image.png\" \/>    <\/p>\n<p>==    <br \/>\nPlease &quot;Accept the answer&quot; if the information helped you. This will help us and others in the community as well.    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":2.0,
        "Solution_readability":11.8,
        "Solution_reading_time":6.23,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":48.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":93.5734752778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>In Azure Machine learning Studio, I have imported a dataset from a locally stored spreadsheet. In the designer, I drag the dataset into the workspace, right click, and select 'Visualize. I get the following error:   <\/p>\n<p>&quot;Unable to visualize this dataset. This might be because your data is stored behind a virtual network or your data does not support profile&quot;. I've searched for hours for a remedy, but find nothing.   <\/p>\n<p>What do I do to fix this error?<\/p>",
        "Challenge_closed_time":1603128837008,
        "Challenge_comment_count":5,
        "Challenge_created_time":1602791972497,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/127980\/error-when-visualizing-dataset-in-microsoft-azure",
        "Challenge_link_count":0,
        "Challenge_participation_count":6,
        "Challenge_readability":7.0,
        "Challenge_reading_time":6.8,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":93.5734752778,
        "Challenge_title":"Error when Visualizing Dataset in Microsoft Azure Machine Learning Studio",
        "Challenge_topic":"Dataset Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":null,
        "Challenge_word_count":88,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=ab00ff52-eb99-4909-97c6-13620f09e957\">@Dana Shields  <\/a> I have tried this scenario with my workspace and i was able to replicate the message you have seen. It looks like you are using the Dataset type as File while creating the dataset which is causing the issue. Please register the dataset as Tabular type and then use the dataset in designer. This should show you the preview of the data. Here is a screen shot from my workspace of the designer.    <\/p>\n<p><img src=\"\/answers\/storage\/temp\/33346-image.png\" alt=\"33346-image.png\" \/>    <\/p>\n",
        "Solution_comment_count":2.0,
        "Solution_link_count":0.0,
        "Solution_readability":6.3,
        "Solution_reading_time":7.11,
        "Solution_score_count":0.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":82.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":0.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":2159.1657988889,
        "Challenge_answer_count":2,
        "Challenge_body":"Is there a link that shows how much GPU memory is available on the following GPU instances on AWS?\n\n1. g4-series instances (NVidia T4)\n2. g5-series instances (NVidia A10)\n3. p3d-series instances (NVidia V100)\n4. p4d-series instances (NVidia A100)\n\nUpdate: the information is available for the [p3d series](https:\/\/aws.amazon.com\/ec2\/instance-types\/p3\/) and [g5 series](https:\/\/aws.amazon.com\/ec2\/instance-types\/g5\/), though not for the [g4 series](https:\/\/aws.amazon.com\/ec2\/instance-types\/g4\/) or the [p4 series](https:\/\/aws.amazon.com\/ec2\/instance-types\/p4\/) instances. Is it possible to retrieve the information for the latter two instances anywhere (without having to launch the instances)?",
        "Challenge_closed_time":1676386194668,
        "Challenge_comment_count":0,
        "Challenge_created_time":1643029354176,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUvPdBv2rwTEiYKKHDPLUTWA\/how-much-gpu-memory-are-available-on-the-g4-g5-p3d-and-p4d-series-instances",
        "Challenge_link_count":4,
        "Challenge_participation_count":2,
        "Challenge_readability":8.2,
        "Challenge_reading_time":9.96,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":10,
        "Challenge_solved_time":9265.7890255556,
        "Challenge_title":"How much GPU memory are available on the g4, g5, p3d, and p4d series instances?",
        "Challenge_topic":"GPU Acceleration",
        "Challenge_topic_macro":"Computation Management",
        "Challenge_view_count":2027.0,
        "Challenge_word_count":95,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"This link has a table that compares instances' GPU memory\nhttps:\/\/docs.amazonaws.cn\/en_us\/AmazonECS\/latest\/developerguide\/ecs-gpu.html",
        "Solution_comment_count":0.0,
        "Solution_link_count":1.0,
        "Solution_readability":24.1,
        "Solution_reading_time":1.82,
        "Solution_score_count":1.0,
        "Solution_sentence_count":1.0,
        "Solution_word_count":11.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":1.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":29.7170177778,
        "Challenge_answer_count":1,
        "Challenge_body":"I have been using Sagemaker Studio Notebook and suddenly it started hanging.\nWhen this happens, the notebook freezes completely. Than I have to wait some seconds (the delay duration is not constant and is common to reach about 30 seconds) and then it just freezes again, making its usage impossible.\nI was using a temporary account provided by Udacity and after trying different approaches to find and solve the problem, I switched to a personal account but the problem persists.\nApproaches I have tried so far:\n- Shutdow and start kernel\n- Restart kernel\n- Restart kernel and clear outputs\n- Log out and Login (from Sagemaker)\n- Log out and Login (from AWS)\n- Change region\n- Trying a different browser (I tried Chrome and Firefox)\n- Trying using other account (personal)\n\nI also checked CloudWatch logs but didn't find anything that seemed unusual.",
        "Challenge_closed_time":1657857148680,
        "Challenge_comment_count":0,
        "Challenge_created_time":1657750167416,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUbUkR0L2-Q1CcAHtTbLYJmg\/sagemaker-notebook-keeps-hanging-freezing",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":12.4,
        "Challenge_reading_time":10.93,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":6,
        "Challenge_solved_time":29.7170177778,
        "Challenge_title":"Sagemaker Notebook keeps hanging\/freezing",
        "Challenge_topic":"Environment Installation",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":81.0,
        "Challenge_word_count":140,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"The most likely cause of this from my experience is a **(very) large number of active git changes**.\n\nGiven your \"current\" working folder (the one you're navigated to in the folder sidebar menu), the jupyterlab-git integration regularly checks if you're inside a git repository and polls for changes in that repository if so.\n\nWhen this list is very large, I've sometimes seen it cause significant slowdowns in the overall UI because of the way the underlying (open-source) extension works. This has been discussed before for example [in this GitHub issue](https:\/\/github.com\/jupyterlab\/jupyterlab-git\/issues\/667) - which is now marked closed but I've still seen it happening.\n\nFor example, maybe you (like me \ud83d\ude05) forgot to [gitignore](https:\/\/git-scm.com\/docs\/gitignore) a data folder or node_modules and generated thousands of untracked files there: You might see a significant slowdown whenever you're navigated to a folder within the scope of that git repo.\n\nSuggested solution would be:\n\n- Use the folder sidebar to navigate anywhere other than the affected git repository (e.g. to your root folder?), and you should see the slowdown resolve pretty much immediately if this is the underlying cause\n- Now the tricky task of finding and clearing up the problemmatic folder(s) without navigating to them in the folder GUI:\n    - You could use a System Terminal, `cd` to the affected folder and run `git status` to see where the many changes are hiding, if you're not sure already\n    - Add a `.gitignore` file (or modify your existing one) to make git ignore those changes. Because it starts with a dot, `.gitignore` is hidden by default in the JupyterLab file browser anyway. I usually use a system terminal to e.g. `cp myrepo\/.gitignore gitignore.txt` to create a visible copy (somewhere other than the repository folder which you're trying to avoid navigating to!) and then `mv gitignore.txt myrepo\/.gitignore` to overwrite with my edited version\n\nAlternatively (if e.g. it's a folder full of new files that you no longer care about like `node_modules`) you could just slog through the slowness to delete the problemmatic folder in the UI - but of course the problem would return if you re-created them later without `.gitignore`.",
        "Solution_comment_count":1.0,
        "Solution_link_count":2.0,
        "Solution_readability":10.8,
        "Solution_reading_time":27.44,
        "Solution_score_count":1.0,
        "Solution_sentence_count":18.0,
        "Solution_word_count":346.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":0.5953230556,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hello, my endpoint seems be throttled so I want to know what is the default limitation. I did some research but found nothing in the official docs, please help me point the obvious data. <\/p>",
        "Challenge_closed_time":1672328170423,
        "Challenge_comment_count":0,
        "Challenge_created_time":1672326027260,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1145811\/is-there-a-limit-for-endpoint-bandwidth-quota",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":6.4,
        "Challenge_reading_time":2.92,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":0.5953230556,
        "Challenge_title":"Is there a limit for endpoint bandwidth quota",
        "Challenge_topic":"Quota Management",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":null,
        "Challenge_word_count":42,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=80951d13-b803-4a3c-a513-64b99f671835\">@jim jones  <\/a>     <\/p>\n<p>Thanks for reaching out to us for this issue. Mirroring traffic uses your endpoint bandwidth quota <strong>(default 5 MBPS)<\/strong>. Your endpoint bandwidth will be throttled if you exceed the allocated quota. For information on monitoring bandwidth throttling, see Monitor managed online endpoints.    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-quotas#azure-machine-learning-managed-online-endpoints\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-quotas#azure-machine-learning-managed-online-endpoints<\/a>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/274868-image.png?platform=QnA\" alt=\"274868-image.png\" \/>    <\/p>\n<p>I hope this helps!    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.    <\/p>\n",
        "Solution_comment_count":1.0,
        "Solution_link_count":2.0,
        "Solution_readability":15.1,
        "Solution_reading_time":12.97,
        "Solution_score_count":0.0,
        "Solution_sentence_count":9.0,
        "Solution_word_count":82.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":32.65,
        "Challenge_answer_count":2,
        "Challenge_body":"Hello, I have an Databricks account on Azure, and the goal is to compare different image tagging services from GCP and other providers via corresponding API calls, with Python notebook. I have problems with GCP vision API calls, specifically with credentials: as far as I understand, the one necessary step is to set 'GOOGLE_APPLICATION_CREDENTIALS' environment variable in my databricks notebook with something like\u00a0\n\nos.environ['GOOGLE_APPLICATION_CREDENTIALS'] ='\/folder1\/credentials.json'\u00a0\n\nwhere '\/folder1\/credentials.json' is the place my notebook looks for json file with credentials (notebook is in the same folder,\u00a0\/folder1\/notebook_api_test).\n\nI am getting this path by looking into\u00a0Workspace->\u00a0Copy file path\u00a0in the Databricks web page.\n\nBut this approach doesn't work, when cell is executed, I am getting this error:\u00a0\n\nDefaultCredentialsError: File \/folder1\/credentials.json was not found.\u00a0\n\nWhat is the right way to deal with credentials to access google vision API from Databricks notebook?",
        "Challenge_closed_time":1682007420000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1681889880000,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/What-is-the-best-way-to-use-credentials-for-API-calls-from\/td-p\/545303\/jump-to\/first-unread-message",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":9.9,
        "Challenge_reading_time":13.56,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":9,
        "Challenge_solved_time":32.65,
        "Challenge_title":"What is the best way to use credentials for API calls from databricks notebook?",
        "Challenge_topic":"Environment Installation",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":140.0,
        "Challenge_word_count":152,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"Ok, here is a trick: in my case, the file with GCP credentials is stored in notebook workspace storage, which is not visible to os.environ() command. So solution is to read a content of this file, and save it to the cluster storage attached to the notebook, which is created with the cluster and is erased when cluster is gone (so we need to repeat this procedure every time the cluster is re-created). According to this doc, we can read the content of the credentials json file stored in notebook workspace with\n\n\u00a0 \u00a0 \u00a0 \u00a0 with open('\/Workspace\/folder1\/cred.json'): #note that I need a full path here, for some reason\n\u00a0 \u00a0 \u00a0 \u00a0 content = f.read()\n\nand then according to this doc, we need to save it on another place in a new file (with the same name in my case, cred.json), namely on cluster storage attached to the notebook (which is visible to os-related functions, like os.environ()), with\n\n\u00a0 \u00a0 \u00a0 \u00a0 fd = os.open(\"cred.json\", os.O_RDWR|os.O_CREAT)\n\u00a0 \u00a0 \u00a0 \u00a0 ret = os.write(fd,content.encode())\n\u00a0 \u00a0 \u00a0 \u00a0 #need to add .encode(), or will get TypeError: a bytes-like object is required, not 'str'\n\u00a0 \u00a0 \u00a0 \u00a0 os.close(fd)\n\nOnly after that we can continue with setting an environment variable, required for GCP authentication:\n\n\u00a0 \u00a0 \u00a0 \u00a0 os.environ['GOOGLE_APPLICATION_CREDENTIALS'] ='.\/cred.json'\n\nand then API calls should work fine, without DefaultCredentialsError.\n\nView solution in original post",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":9.3,
        "Solution_reading_time":16.42,
        "Solution_score_count":0.0,
        "Solution_sentence_count":13.0,
        "Solution_word_count":202.0,
        "Tool":"Vertex AI"
    },
    {
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":57.5032686111,
        "Challenge_answer_count":2,
        "Challenge_body":"When calculating the cost of SageMaker Studio Notebooks in [the AWS Pricing Calculator](https:\/\/calculator.aws\/#\/addService\/SageMaker), it asks you for the \"Number of Studio Notebook instances per data scientist per month.\"\n\nHow do you reason about this? What would be the use case for having multiple instances for one data scientist? Would that happen if an individual is working on multiple projects, which have different kernels and library dependencies?\n\nI imagine most of the time it will be 1 Studio Notebook instance per data scientist per month, instead of 2 or more instances per data scientist?",
        "Challenge_closed_time":1670809472327,
        "Challenge_comment_count":0,
        "Challenge_created_time":1670602460560,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QU5kNZTb_yRR6VUo1Reg6lxg\/how-do-you-choose-the-number-of-studio-notebook-instances-per-data-scientist",
        "Challenge_link_count":1,
        "Challenge_participation_count":2,
        "Challenge_readability":10.3,
        "Challenge_reading_time":8.48,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":57.5032686111,
        "Challenge_title":"How do you choose the number of Studio Notebook Instances per Data Scientist?",
        "Challenge_topic":"Quota Management",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":214.0,
        "Challenge_word_count":105,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"Hi @yann_stoneman, you're right. Up to 4 apps can run on the same instances, so different kernels could still be run on the same instance. For example, a data scientist could be working on a tabular use case, and an image processing use case - so they might have a CPU and GPU instance running. Or they might use a larger instance for data processing or data wrangler feature. \n\nDepending on your data scientists' projects and use cases, I'd account for at most 2 instances per data scientist running concurrently. If your users already use SageMaker Notebook Instances, you can use the commonly used resource type as the Studio instance resource type for estimates - that way you can get a closer estimate to the actual costs. \n\nIf you're allowing for shared spaces (real time collaboration), include additional instances in your estimate - the users will now be able to use a private space through their user profile (unique to one user) and a shared space (this instance can be accessed across profiles). \n\nI'd also recommend using a plugin to shut down idle instances as a best practice when your teams are onboarded to Studio, so these instances are shut down if there are no notebooks actively running (ref: https:\/\/aws.amazon.com\/blogs\/machine-learning\/save-costs-by-automatically-shutting-down-idle-resources-within-amazon-sagemaker-studio\/)",
        "Solution_comment_count":2.0,
        "Solution_link_count":1.0,
        "Solution_readability":13.4,
        "Solution_reading_time":16.66,
        "Solution_score_count":1.0,
        "Solution_sentence_count":8.0,
        "Solution_word_count":207.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":39.0607519444,
        "Challenge_answer_count":5,
        "Challenge_body":"<p>We are running long data preparation run (30+ hours) to pre-build source files for training.  However, part of the dataset was not ready and was excluding from the current run (which is 20+ hours into the run).  I would like to process the remaining data and ADD it to this current artifact.<br>\nI note that whenever I run this code is creates a new version of the artifact.<br>\nHow can I append new data to an existing artifact?<\/p>\n<p>Second question: Can I add new data in-parallel with the original job.  That is, can two different processes add data to the same artifact at the same time?<\/p>",
        "Challenge_closed_time":1664566326300,
        "Challenge_comment_count":0,
        "Challenge_created_time":1664425707593,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/continuing-an-artifact\/3198",
        "Challenge_link_count":0,
        "Challenge_participation_count":5,
        "Challenge_readability":7.4,
        "Challenge_reading_time":7.54,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":8,
        "Challenge_solved_time":39.0607519444,
        "Challenge_title":"Continuing an artifact",
        "Challenge_topic":"Dataset Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":787.0,
        "Challenge_word_count":108,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi <a class=\"mention\" href=\"\/u\/kevinashaw\">@kevinashaw<\/a><\/p>\n<p>After speaking with the the team, you have options via our wandb artifact upsert calls to append to a non-finalized artifact as output of a run, see <a href=\"https:\/\/docs.wandb.ai\/ref\/python\/run#upsert_artifact\">here<\/a>.However, we highly recommend you utilize S3 URI reference instead as it would be the more straightforward approach. Add all data to the S3 bucket <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/track-external-files#amazon-s3-gcs-references\">then setup reference URI<\/a> to generate the new artifact with all your processed data. If you run into any issues, please let me know.<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":2.0,
        "Solution_readability":12.0,
        "Solution_reading_time":8.59,
        "Solution_score_count":null,
        "Solution_sentence_count":5.0,
        "Solution_word_count":82.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":3.8464063889,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>When using explanations for AutoML models or standalone model, the explanation dashboard has 2 tabs which displays same information.    <\/p>\n<p>I am using azureml-interpret to explain the models that are executed under azure context  and upload the explanations into Azure ML studio.    <br \/>\nI use global_explanation and local_explanation to explain the overall model performance and local model performance.    <\/p>\n<p>I guess this is creating 2 tabs if I am correct, but both of them seems to have same or duplicate information. I don't understand what is the need for that?    <\/p>\n<p>This seem to the case when I use AutoML models also, there is 2 tabs which has same information. Note, here I am not uploading anything,  it is by default uploading the model explanations and I am using azure-python-sdk-v1.    <\/p>\n<p>I have provided the accompanying screenshots with the information, please let me know if there is gap in my understanding or it is problem with the azure explanation?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/264609-first-tab-information.png?platform=QnA\" alt=\"264609-first-tab-information.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/264610-second-tab-information.png?platform=QnA\" alt=\"264610-second-tab-information.png\" \/>    <\/p>",
        "Challenge_closed_time":1669634696120,
        "Challenge_comment_count":0,
        "Challenge_created_time":1669620849057,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1106407\/why-explanation-dashboard-is-showing-2-tabs-with-d",
        "Challenge_link_count":2,
        "Challenge_participation_count":1,
        "Challenge_readability":13.3,
        "Challenge_reading_time":17.86,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":11,
        "Challenge_solved_time":3.8464063889,
        "Challenge_title":"Why explanation dashboard is showing 2 tabs with duplicate information in Azure ML Studio?",
        "Challenge_topic":"Dataset Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":null,
        "Challenge_word_count":181,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=b3da8189-5298-4acf-8e9a-e4e5f7b30c14\">@Bharath Kumar Loganathan  <\/a> I think the explanation ids are based on the raw and engineered datasets. Raw explanations are based on the features from the original dataset and engineered explanations are based on the features from the dataset with feature engineering applied. The documentation from these links provides a bit more information about the different explanation ids. If you expand the menu on the left this should confirm the same.    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-automated-ml-for-ml-models#model-explanations-preview\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-automated-ml-for-ml-models#model-explanations-preview<\/a>    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-machine-learning-interpretability-aml#visualizations\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-machine-learning-interpretability-aml#visualizations<\/a>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/264729-image.png?platform=QnA\" alt=\"264729-image.png\" \/>    <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Solution_comment_count":5.0,
        "Solution_link_count":5.0,
        "Solution_readability":21.7,
        "Solution_reading_time":20.92,
        "Solution_score_count":1.0,
        "Solution_sentence_count":10.0,
        "Solution_word_count":109.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":5.3284266667,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>I am able to run the notebook in studio, but can I export the studio as notebook and import it in another place?<\/p>",
        "Challenge_closed_time":1667268149163,
        "Challenge_comment_count":1,
        "Challenge_created_time":1667248966827,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1069926\/can-i-build-my-ml-pipeline-experiment-in-ml-studio",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":10.1,
        "Challenge_reading_time":2.76,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":2,
        "Challenge_solved_time":5.3284266667,
        "Challenge_title":"can I build my ML pipeline\/experiment in ML studio designer, and export it as a python and jupyter notebook?",
        "Challenge_topic":"Environment Installation",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":null,
        "Challenge_word_count":41,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello <a href=\"\/users\/na\/?userid=a7efa3c2-0ff5-4cc8-8b14-63a031eb0713\">@usui gina  <\/a>     <\/p>\n<p>Thanks for using Microsoft Q&amp;A. Sorry, this is not support at this moment. But Azure Machine Learning Studio already has Notebook function just for your reference.     <\/p>\n<p>I will forward your feedback to product team and at the same time, I would highly recommend you provide your feedback in Azure Machine Learning portal to raise more visability - top right side as below screenshot    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/255817-image.png?platform=QnA\" alt=\"255817-image.png\" \/>    <\/p>\n<p>I hope this helps!    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":1.0,
        "Solution_readability":10.0,
        "Solution_reading_time":9.96,
        "Solution_score_count":0.0,
        "Solution_sentence_count":7.0,
        "Solution_word_count":100.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":3.7982433333,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>Is there any way to integrate MS Dynamics Customer Insights with Azure Machine Learning (designer)?I know there is an integration between CI and Azure Machine Learning studio (classic). Please help to integrate these two services.<\/p>",
        "Challenge_closed_time":1656632594976,
        "Challenge_comment_count":1,
        "Challenge_created_time":1656618921300,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/909965\/azure-machine-learning",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":6.9,
        "Challenge_reading_time":3.29,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":3.7982433333,
        "Challenge_title":"Azure machine learning",
        "Challenge_topic":"Web Service Deployment",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":37,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hello @Yasuo-9899     <\/p>\n<p>Thanks for reaching out to us for this question. Are you looking for this document? <a href=\"https:\/\/learn.microsoft.com\/en-us\/dynamics365\/customer-insights\/azure-machine-learning-experiments\">https:\/\/learn.microsoft.com\/en-us\/dynamics365\/customer-insights\/azure-machine-learning-experiments<\/a>    <\/p>\n<p>I have found one pic which is described the structure well:    <br \/>\n<img src=\"https:\/\/github.com\/ArtisConsulting\/customer-insights-azure-data-workshop\/raw\/main\/images\/workshop-playbook\/media\/image2.png\" alt=\"image2.png\" \/>    <\/p>\n<p>And also a repo you may want to refer to: <a href=\"https:\/\/github.com\/ArtisConsulting\/customer-insights-azure-data-workshop\/blob\/main\/README.md\">https:\/\/github.com\/ArtisConsulting\/customer-insights-azure-data-workshop\/blob\/main\/README.md<\/a>    <\/p>\n<p>Please let us know more details you are interested in so that we can help. Thanks.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":3.0,
        "Solution_readability":20.9,
        "Solution_reading_time":12.6,
        "Solution_score_count":0.0,
        "Solution_sentence_count":6.0,
        "Solution_word_count":71.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":1.8825055556,
        "Challenge_answer_count":3,
        "Challenge_body":"<p>Hey,<br>\nI\u2019m trying to get the version of an artifact directly after logging my model (encoder) as an artifact to WandB.<\/p>\n<p><strong>Code:<\/strong><\/p>\n<pre><code class=\"lang-auto\">artifact = wandb.Artifact('my_artifact_name', type='model')\nartifact.add_file('\/home\/dezzardhd\/encoder.pth')\nwandb.log_artifact(artifact)\nversion = artifact.version\n<\/code><\/pre>\n<p>Logging works so far, but\u2026<br>\nwhen trying to access the version of the artifact I get an error.<br>\n<strong>Error:<\/strong><\/p>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"\/home\/moritz\/PycharmProjects\/bachelorarbeit\/main.py\", line 48, in &lt;module&gt;\n    train_setups.start_training_sessions(project=project)\n  File \"\/home\/moritz\/PycharmProjects\/bachelorarbeit\/train_setups.py\", line 18, in start_training_sessions\n    model_pipeline(config, project=project)\n  File \"\/home\/moritz\/PycharmProjects\/bachelorarbeit\/learning.py\", line 84, in model_pipeline\n    save_model(model_ae=model, model_encoder=model_encoder, model_decoder=model_decoder)\n  File \"\/home\/moritz\/PycharmProjects\/bachelorarbeit\/learning.py\", line 124, in save_model\n    version = artifact_enc.version\n  File \"\/home\/moritz\/anaconda3\/envs\/bachelorarbeit\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_artifacts.py\", line 191, in version\n    return self._logged_artifact.version\n  File \"\/home\/moritz\/anaconda3\/envs\/bachelorarbeit\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_run.py\", line 2899, in version\n    return self._assert_instance().version\n  File \"\/home\/moritz\/anaconda3\/envs\/bachelorarbeit\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_run.py\", line 2871, in _assert_instance\n    raise ValueError(\nValueError: Must call wait() before accessing logged artifact properties\n<\/code><\/pre>\n<p>What should I do now?<\/p>\n<p>For context:<br>\nI want to print out the version number with some other parameters so that I can easier start my evaluation process for certain runs.<\/p>\n<p>Best regards<br>\nDezzardHD<\/p>",
        "Challenge_closed_time":1646696888232,
        "Challenge_comment_count":0,
        "Challenge_created_time":1646690111212,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/how-do-i-get-the-version-of-an-artifact\/2035",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":18.3,
        "Challenge_reading_time":26.49,
        "Challenge_score_count":2.0,
        "Challenge_sentence_count":20,
        "Challenge_solved_time":1.8825055556,
        "Challenge_title":"How do I get the version of an artifact?",
        "Challenge_topic":"Artifact Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":400.0,
        "Challenge_word_count":164,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi <a class=\"mention\" href=\"\/u\/dezzardhd\">@dezzardhd<\/a>,<\/p>\n<p>Could you try running your code as the following?<\/p>\n<pre><code class=\"lang-python\">artifact = wandb.Artifact('my_artifact_name', type='model')\nartifact.add_file('\/home\/dezzardhd\/encoder.pth')\nwandb.log_artifact(artifact).wait()\nversion = artifact.version\n<\/code><\/pre>\n<p>Calling <code>wait()<\/code> after <code>log_artifact()<\/code> should resolve this for you.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":19.6,
        "Solution_reading_time":6.27,
        "Solution_score_count":null,
        "Solution_sentence_count":6.0,
        "Solution_word_count":33.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":0.0,
        "Answerer_isCse":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isModerator":0.0,
        "Challenge_adjusted_solved_time":66.3502777778,
        "Challenge_answer_count":1,
        "Challenge_body":"My customer's 220 Gb of training data took 54 minutes for Sagemaker to download. This is a rate of only 70 MB\/s, which is unexpectedly slow. He is accessing the data in S3 from his p3.8xlarge instance through a private VPC endpoint, so the theoretical maximum bandwidth is 25 Gbps. Is there anything that can be done to speed up the download? \n\nHe started the Sagemaker training with the following function:\n\nestimator = Estimator(image_name, role=role, output_path=output_location,\n                      train_instance_count=1, train_instance_type='ml.p3.8xlarge',\n                     train_volume_size=300, train_max_run = 5*24*60*60 ,\n                     security_group_ids='sg-00f1529adc4076841')\n\nThe output was:\n2018-10-18 23:27:15 Starting - Starting the training job...\nLaunching requested ML instances......\nPreparing the instances for training...\n2018-10-18 23:29:15 Downloading - Downloading input data............\n....................................................................\n....................................................................\n....................................................................\n2018-10-19 00:23:50 Training - Downloading the training image..\n \nDataset download took ~54mins",
        "Challenge_closed_time":1540622900000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1540384039000,
        "Challenge_favorite_count":0.0,
        "Challenge_link":"https:\/\/repost.aws\/questions\/QUPpqUS0ckRXCHW0BXgxV5wQ\/sagemaker-taking-an-unexpectedly-long-time-to-download-training-data",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":9.4,
        "Challenge_reading_time":16.09,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":13,
        "Challenge_solved_time":66.3502777778,
        "Challenge_title":"Sagemaker taking an unexpectedly long time to download training data",
        "Challenge_topic":"Dataset Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":1104.0,
        "Challenge_word_count":126,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":1.0,
        "Poster_isCse":0.0,
        "Poster_isExpert":0.0,
        "Poster_isModerator":0.0,
        "Solution_body":"How are they connect to S3? are they using a VPC endpoint \/ NAT?\nIf they are using a VPC endpoint, My recommendation will be the open a support ticket, it's possible that support will be able to look at the network logs.\n\nAnother option for the customer is to use [pipe input](https:\/\/aws.amazon.com\/blogs\/machine-learning\/using-pipe-input-mode-for-amazon-sagemaker-algorithms\/), pipe mode is recommended for large datasets, and it'll shorter their startup time because the data is being streamed instead of being downloaded to your training instances.",
        "Solution_comment_count":0.0,
        "Solution_link_count":1.0,
        "Solution_readability":10.6,
        "Solution_reading_time":6.93,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":79.0,
        "Tool":"Amazon SageMaker"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":2.4997222222,
        "Challenge_answer_count":0,
        "Challenge_body":"I have setup a community self-hosted polyaxon, and the config abourt ui is\n\nui:\n  enabled: true\n  offline: false\n  adminEnabled: true\n\n\naccording to the documentation, if I set adminEnabled to true, there should be an admin dashboard. But I did not find it, there is no difference to turn it on\/off",
        "Challenge_closed_time":1648196727000,
        "Challenge_comment_count":0,
        "Challenge_created_time":1648187728000,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1460",
        "Challenge_link_count":0,
        "Challenge_participation_count":0,
        "Challenge_readability":10.4,
        "Challenge_reading_time":4.03,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":3,
        "Challenge_solved_time":2.4997222222,
        "Challenge_title":"Does Community UI has Admin dashboard?",
        "Challenge_topic":"Metric Logging",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":null,
        "Challenge_word_count":55,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"The admin page is under http:\/\/localhost:8000\/_admin\/",
        "Solution_comment_count":0.0,
        "Solution_link_count":1.0,
        "Solution_readability":8.0,
        "Solution_reading_time":0.71,
        "Solution_score_count":1.0,
        "Solution_sentence_count":1.0,
        "Solution_word_count":6.0,
        "Tool":"Polyaxon"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":2.2800663889,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Next to the Normalized root mean squared error value, select View all other metrics to see values of other possible evaluation metrics for a regression model.    <\/p>\n<p>Select the Metrics tab and select the residuals and predicted_true charts if they are not already selected. Then review the charts, which show the performance of the model by comparing the predicted values against the true values, and by showing the residuals (differences between predicted and actual values) as a histogram.    <\/p>\n<p>As per the above lines, I am not able to find the Metrics tab and not able to see the predicted true charts.<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/106017-screenshot-26.png?platform=QnA\" alt=\"106017-screenshot-26.png\" \/>    <\/p>",
        "Challenge_closed_time":1623824430656,
        "Challenge_comment_count":0,
        "Challenge_created_time":1623816222417,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/437991\/metrics-tab",
        "Challenge_link_count":1,
        "Challenge_participation_count":1,
        "Challenge_readability":14.8,
        "Challenge_reading_time":9.71,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":2.2800663889,
        "Challenge_title":"Metrics tab.",
        "Challenge_topic":"Metric Logging",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":null,
        "Challenge_word_count":106,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=470817e2-2a8d-42d2-9da4-00253723c5ca\">@A Sashank Sainath Reddy  <\/a> You will have to first click on the algorithm name from the screen shot first.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/105969-image.png?platform=QnA\" alt=\"105969-image.png\" \/>    <\/p>\n<p>Then you will see the metrics tab and the charts.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/106101-image.png?platform=QnA\" alt=\"106101-image.png\" \/>    <\/p>\n<p>Please feel free to accept the answer if it helped. Thanks.    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":2.0,
        "Solution_readability":11.0,
        "Solution_reading_time":7.54,
        "Solution_score_count":0.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":53.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":7.6244272222,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>Sorry if this is covered by docs  couldn\u2019t understand something about wandb jobs (wandb launch);<\/p>\n<p>Basically, does the Dockerfile itself must have an <code>Entrypoint<\/code> attr, which runs a program? Or is it enough to have a docker image which has WANDB_DOCKER, wandb_api_key env variable set, having a python directory codebase which can start wandb runs?? (can\u2019t create a job this way though\u2026), if possible without logging the code.<\/p>",
        "Challenge_closed_time":1679692322111,
        "Challenge_comment_count":0,
        "Challenge_created_time":1679664874173,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/community.wandb.ai\/t\/confused-about-wandb-launch-usage-with-docker\/4119",
        "Challenge_link_count":0,
        "Challenge_participation_count":2,
        "Challenge_readability":9.3,
        "Challenge_reading_time":6.18,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":7.6244272222,
        "Challenge_title":"Confused about wandb launch usage with docker",
        "Challenge_topic":"Docker Configuration",
        "Challenge_topic_macro":"Infrastructure Management",
        "Challenge_view_count":103.0,
        "Challenge_word_count":74,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Cleared:<br>\nYeah, the Dockerfile should be complete end to end such that just running the docker file should run the program, it must have <code>Entrypoint<\/code> attr in the Dockerfile, which actually can be changed from the overrides when we pass it to queue.<\/p>",
        "Solution_comment_count":null,
        "Solution_link_count":0.0,
        "Solution_readability":17.7,
        "Solution_reading_time":3.33,
        "Solution_score_count":null,
        "Solution_sentence_count":1.0,
        "Solution_word_count":43.0,
        "Tool":"Weights & Biases"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":8.4330788889,
        "Challenge_answer_count":3,
        "Challenge_body":"<p>Hello MS team,  <\/p>\n<p>I have registered an ML model in the AML workspace using an Azure Machine learning pipeline and triggered the main control script of the pipeline by linking the repo present in Azure DevOps to the AML workspace(using Service principal).   <\/p>\n<p>How do I download the latest version of the model from the AML workspace to the <em>&quot;Artifacts&quot;<\/em> folder in Azure DevOPs?  <\/p>\n<p>Any help is appreciated please.  <\/p>",
        "Challenge_closed_time":1643933985587,
        "Challenge_comment_count":0,
        "Challenge_created_time":1643903626503,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/721792\/how-to-get-model-id-of-the-latest-version-register",
        "Challenge_link_count":0,
        "Challenge_participation_count":3,
        "Challenge_readability":11.1,
        "Challenge_reading_time":7.02,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":4,
        "Challenge_solved_time":8.4330788889,
        "Challenge_title":"How to get Model ID of the Latest Version registered in Azure Machine Learning Service Model Registry using az ml cli?",
        "Challenge_topic":"Model Registry",
        "Challenge_topic_macro":"Model Management",
        "Challenge_view_count":null,
        "Challenge_word_count":92,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p><a href=\"\/users\/na\/?userid=6755dac2-30f1-48a2-9d0d-4d2c96edc5d4\">@Shivapriya Katta  <\/a>     <\/p>\n<p>I think you are mentioning how to get the latest version of model and download the model in az ml.    <\/p>\n<p>There are 2 steps, one is list the model to get the model ID you want, two is download the model.    <\/p>\n<p><strong>az ml model list<\/strong>    <br \/>\nList models in the workspace.    <\/p>\n<pre><code>az ml model list [--dataset-id]  \n                 [--latest]  \n                 [--model-name]  \n                 [--path]  \n                 [--property]  \n                 [--resource-group]  \n                 [--run-id]  \n                 [--subscription-id]  \n                 [--tag]  \n                 [--workspace-name]  \n                 [-v]  \n<\/code><\/pre>\n<p>Optional Parameters    <br \/>\n--dataset-id    <br \/>\nIf provided, will only show models with the specified dataset ID.    <\/p>\n<p>--latest -l    <br \/>\nIf provided, will only return models with the latest version.    <\/p>\n<p>--model-name -n    <br \/>\nAn optional model name to filter the list by.    <\/p>\n<p>--path    <br \/>\nPath to a project folder. Default: current directory.    <\/p>\n<p>--property    <br \/>\nKey\/value property to add (e.g. key=value ). Multiple properties can be specified with multiple --property options.    <\/p>\n<p>--resource-group -g    <br \/>\nResource group corresponding to the provided workspace.    <\/p>\n<p>--run-id    <br \/>\nIf provided, will only show models with the specified Run ID.    <\/p>\n<p>--subscription-id    <br \/>\nSpecifies the subscription Id.    <\/p>\n<p>--tag    <br \/>\nKey\/value tag to add (e.g. key=value ). Multiple tags can be specified with multiple --tag options.    <\/p>\n<p>--workspace-name -w    <br \/>\nName of the workspace containing models to list.    <\/p>\n<p>-v    <br \/>\nVerbosity flag.    <\/p>\n<p><strong>az ml model download<\/strong>    <br \/>\nDownload a model from the workspace.    <\/p>\n<pre><code>az ml model download --model-id  \n                     --target-dir  \n                     [--overwrite]  \n                     [--path]  \n                     [--resource-group]  \n                     [--subscription-id]  \n                     [--workspace-name]  \n                     [-v]  \n<\/code><\/pre>\n<p>Required Parameters    <br \/>\n--model-id -i    <br \/>\nID of model.    <\/p>\n<p>--target-dir -t    <br \/>\nTarget directory to download the model file to.    <\/p>\n<p>Optional Parameters    <br \/>\n--overwrite    <br \/>\nOverwrite if the same name file exists in target directory.    <\/p>\n<p>--path    <br \/>\nPath to a project folder. Default: current directory.    <\/p>\n<p>--resource-group -g    <br \/>\nResource group corresponding to the provided workspace.    <\/p>\n<p>--subscription-id    <br \/>\nSpecifies the subscription Id.    <\/p>\n<p>--workspace-name -w    <br \/>\nName of the workspace containing model to show.    <\/p>\n<p>-v    <br \/>\nVerbosity flag.    <\/p>\n<p>Hope this helps!     <\/p>\n<p><em>Please kindly accept the answer if you feel helpful, thank you!<\/em>    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":0.0,
        "Solution_readability":7.8,
        "Solution_reading_time":32.05,
        "Solution_score_count":0.0,
        "Solution_sentence_count":30.0,
        "Solution_word_count":344.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":8.0685027778,
        "Challenge_answer_count":1,
        "Challenge_body":"<p>Hi;  <\/p>\n<p>First off, where can I find the costs for all the different things I can run in Azure ML? Not just a compute, but editing a notebook, connecting to a datastore, splitting a datastore, etc. Basically where is the price list?  <\/p>\n<p>Second, where can I find what I will be charged for things I ran in the last hour? I want to see what I'm spending before a month is up and the charge is then 100x what I expected (and can afford).  <\/p>\n<p>thanks - dave<\/p>",
        "Challenge_closed_time":1634347958867,
        "Challenge_comment_count":0,
        "Challenge_created_time":1634318912257,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/592299\/cost-of-running-a-compute-other-tasks",
        "Challenge_link_count":0,
        "Challenge_participation_count":1,
        "Challenge_readability":5.1,
        "Challenge_reading_time":6.08,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":7,
        "Challenge_solved_time":8.0685027778,
        "Challenge_title":"Cost of running a compute, other tasks",
        "Challenge_topic":"Dataset Management",
        "Challenge_topic_macro":"Data Management",
        "Challenge_view_count":null,
        "Challenge_word_count":95,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi, you can use <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cost-management-billing\/cost-management-billing-overview\">Azure Cost Management<\/a> to manage Azure costs, please review the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cost-management-billing\/costs\/quick-acm-cost-analysis\">quickstart<\/a> document. Also, the following document provides detailed information on how to <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/concept-plan-manage-cost\">plan and manage cost for AML<\/a>.<\/p>\n<p>--- *Kindly <em><strong>Accept Answer<\/strong><\/em> if the information helps. Thanks.*<\/p>\n",
        "Solution_comment_count":0.0,
        "Solution_link_count":3.0,
        "Solution_readability":19.7,
        "Solution_reading_time":8.39,
        "Solution_score_count":2.0,
        "Solution_sentence_count":5.0,
        "Solution_word_count":44.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":5.2082036111,
        "Challenge_answer_count":4,
        "Challenge_body":"<p>I have loaded <a href=\"https:\/\/automlsamplenotebookdata.blob.core.windows.net\/automl-sample-notebook-data\/bankmarketing_train.csv\">bankmarketing_train.csv<\/a> to get a dataset and auto generated a model to predict &quot;y&quot; field value with AutoML.    <br \/>\nVoting Ensemble model was generated as the best model and tested its behavior after deployed to the endpoint.    <\/p>\n<p>Schema is generated like this for the endpoint.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/113929-schema-2021-07-13-124905.png?platform=QnA\" alt=\"113929-schema-2021-07-13-124905.png\" \/>    <\/p>\n<p>Tried with the endpoint test feature in ML Studio. It worked and responded an expected output (left side in the fig below).    <br \/>\nBut my python REST call fails with 502 Bad Gateway(right side)    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/114082-screenshot-2021-07-12-232443.png?platform=QnA\" alt=\"114082-screenshot-2021-07-12-232443.png\" \/>    <\/p>\n<p>Using the REST plug-in for VSCode, I have requested as below. This also failed with the same response status code.    <\/p>\n<pre><code>POST http:\/\/d8e9f6ad-4112-4417-97c0-01b4246b284a.japaneast.azurecontainer.io\/score  \nContent-Type: application\/json  \nAuthorization: Bearer === My correct key here ===  \n  \n{&quot;data&quot;: [{&quot;age&quot;: 87, &quot;campaign&quot;: 1, &quot;cons.conf.idx&quot;: -46.2, &quot;cons.price.idx&quot;: 92.893, &quot;contact&quot;: &quot;cellular&quot;, &quot;day_of_week&quot;: &quot;mon&quot;, &quot;default&quot;: &quot;no&quot;, &quot;duration&quot;: 471, &quot;education&quot;: &quot;university.degree&quot;, &quot;emp.var.rate&quot;: -1.8, &quot;euribor3m&quot;: 1.299, &quot;housing&quot;: &quot;yes&quot;, &quot;job&quot;: &quot;blue-collar&quot;, &quot;loan&quot;: &quot;yes&quot;, &quot;marital&quot;: &quot;married&quot;, &quot;month&quot;: &quot;may&quot;, &quot;nr.employed&quot;: 5099.1, &quot;pdays&quot;: 999, &quot;poutcome&quot;: &quot;failure&quot;, &quot;previous&quot;: 1}]}  \n<\/code><\/pre>\n<p>Investigated in the App Insight and queried the exceptions.    <br \/>\nI found this end point tries to convert 'yes' to int value. Of course it fails.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/114083-%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88-2021-07-13-003243.png?platform=QnA\" alt=\"114083-%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88-2021-07-13-003243.png\" \/>    <\/p>\n<p>The value 'yes' is set to 'loan' and 'housing&quot;. Both are defined string value in the swagger.json for this endpoint.    <\/p>\n<p>What do you think?    <br \/>\nAm I missing something?    <br \/>\nIs this a bug with the endpoint?    <\/p>",
        "Challenge_closed_time":1626168091356,
        "Challenge_comment_count":3,
        "Challenge_created_time":1626149341823,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/473223\/endpoint-fails-with-the-model-generated-by-automat",
        "Challenge_link_count":5,
        "Challenge_participation_count":7,
        "Challenge_readability":11.7,
        "Challenge_reading_time":36.89,
        "Challenge_score_count":0.0,
        "Challenge_sentence_count":26,
        "Challenge_solved_time":5.2082036111,
        "Challenge_title":"Endpoint fails with the model generated by Automated ML",
        "Challenge_topic":"Model Endpoint",
        "Challenge_topic_macro":"Service Management",
        "Challenge_view_count":null,
        "Challenge_word_count":244,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Yes, I tried that. Following is the code coming from the consume, the values are set accordingly.    <\/p>\n<pre><code>import urllib.request  \nimport json  \nimport os  \nimport ssl  \n  \ndef allowSelfSignedHttps(allowed):  \n    # bypass the server certificate verification on client side  \n    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):  \n        ssl._create_default_https_context = ssl._create_unverified_context  \n  \nallowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.  \n  \n# Request data goes here  \n  \ndata = {&quot;data&quot;:  \n        [  \n          {  \n            &quot;age&quot;: &quot;17&quot;,  \n            &quot;campaign&quot;: &quot;1&quot;,  \n            &quot;cons.conf.idx&quot;: &quot;-46.2&quot;,  \n            &quot;cons.price.idx&quot;: &quot;92.893&quot;,  \n            &quot;contact&quot;: &quot;cellular&quot;,  \n            &quot;day_of_week&quot;: &quot;mon&quot;,  \n            &quot;default&quot;: &quot;no&quot;,  \n            &quot;duration&quot;: &quot;971&quot;,  \n            &quot;education&quot;: &quot;university.degree&quot;,  \n            &quot;emp.var.rate&quot;: &quot;-1.8&quot;,  \n            &quot;euribor3m&quot;: &quot;1.299&quot;,  \n            &quot;housing&quot;: &quot;yes&quot;,  \n            &quot;job&quot;: &quot;blue-collar&quot;,  \n            &quot;loan&quot;: &quot;yes&quot;,  \n            &quot;marital&quot;: &quot;married&quot;,  \n            &quot;month&quot;: &quot;may&quot;,  \n            &quot;nr.employed&quot;: &quot;5099.1&quot;,  \n            &quot;pdays&quot;: &quot;999&quot;,  \n            &quot;poutcome&quot;: &quot;failure&quot;,  \n            &quot;previous&quot;: &quot;1&quot;  \n          }  \n      ]  \n    }  \n  \n  \nbody = str.encode(json.dumps(data))  \n  \nurl = 'http:\/\/d8e9f6ad-4112-4417-97c0-01b4246b284a.japaneast.azurecontainer.io\/score'  \napi_key = '&lt;key&gt;' # Replace this with the API key for the web service  \nheaders = {'Content-Type':'application\/json', 'Authorization':('Bearer '+ api_key)}  \n  \nreq = urllib.request.Request(url, body, headers)  \n  \ntry:  \n    response = urllib.request.urlopen(req)  \n  \n    result = response.read()  \n    print(result)  \nexcept urllib.error.HTTPError as error:  \n    print(&quot;The request failed with status code: &quot; + str(error.code))  \n  \n    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure  \n    print(error.info())  \n    print(json.loads(error.read().decode(&quot;utf8&quot;, 'ignore')))  \n  \n<\/code><\/pre>\n<p>The result was the same. 'yes' was tried to cast to int and failed.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/114222-consume-2021-07-13-175924.png?platform=QnA\" alt=\"114222-consume-2021-07-13-175924.png\" \/>    <\/p>\n<p>In the deployment log, following exception observed. Something is happening inside the server call, which I cannot see.    <\/p>\n<pre><code>2021-07-13 08:56:49,684 | root | ERROR | Encountered Exception: Traceback (most recent call last):  \n  File &quot;\/var\/azureml-server\/synchronous\/routes.py&quot;, line 64, in run_scoring  \n    response = invoke_user_with_timer(service_input, request_headers)  \n  File &quot;\/var\/azureml-server\/synchronous\/routes.py&quot;, line 97, in invoke_user_with_timer  \n    result = user_main.run(**params)  \n  File &quot;\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/wrapt\/wrappers.py&quot;, line 567, in __call__  \n    args, kwargs)  \n  File &quot;\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/inference_schema\/schema_decorators.py&quot;, line 57, in decorator_input  \n    kwargs[param_name] = _deserialize_input_argument(kwargs[param_name], param_type, param_name)  \n  File &quot;\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/inference_schema\/schema_decorators.py&quot;, line 285, in _deserialize_input_argument  \n    input_data = param_type.deserialize_input(input_data)  \n  File &quot;\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/inference_schema\/parameter_types\/pandas_parameter_type.py&quot;, line 79, in deserialize_input  \n    data_frame = data_frame.astype(dtype=converted_types)  \n  File &quot;\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/pandas\/core\/generic.py&quot;, line 5865, in astype  \n    dtype=dtype[col_name], copy=copy, errors=errors, **kwargs  \n  File &quot;\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/pandas\/core\/generic.py&quot;, line 5882, in astype  \n    dtype=dtype, copy=copy, errors=errors, **kwargs  \n  File &quot;\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/pandas\/core\/internals\/managers.py&quot;, line 581, in astype  \n    return self.apply(&quot;astype&quot;, dtype=dtype, **kwargs)  \n  File &quot;\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/pandas\/core\/internals\/managers.py&quot;, line 438, in apply  \n    applied = getattr(b, f)(**kwargs)  \n  File &quot;\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/pandas\/core\/internals\/blocks.py&quot;, line 559, in astype  \n    return self._astype(dtype, copy=copy, errors=errors, values=values, **kwargs)  \n  File &quot;\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/pandas\/core\/internals\/blocks.py&quot;, line 643, in _astype  \n    values = astype_nansafe(vals1d, dtype, copy=True, **kwargs)  \n  File &quot;\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/pandas\/core\/dtypes\/cast.py&quot;, line 707, in astype_nansafe  \n    return lib.astype_intsafe(arr.ravel(), dtype).reshape(arr.shape)  \n  File &quot;pandas\/_libs\/lib.pyx&quot;, line 547, in pandas._libs.lib.astype_intsafe  \nValueError: invalid literal for int() with base 10: 'yes'  \n  \nDuring handling of the above exception, another exception occurred:  \n  \nTraceback (most recent call last):  \n  File &quot;\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/flask\/app.py&quot;, line 1832, in full_dispatch_request  \n    rv = self.dispatch_request()  \n  File &quot;\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/flask\/app.py&quot;, line 1818, in dispatch_request  \n    return self.view_functions[rule.endpoint](**req.view_args)  \n  File &quot;\/var\/azureml-server\/synchronous\/routes.py&quot;, line 43, in score_realtime  \n    return run_scoring(service_input, request.headers, request.environ.get('REQUEST_ID', '00000000-0000-0000-0000-000000000000'))  \n  File &quot;\/var\/azureml-server\/synchronous\/routes.py&quot;, line 77, in run_scoring  \n    raise RunFunctionException(str(exc))  \nrun_function_exception.RunFunctionException  \n<\/code><\/pre>\n",
        "Solution_comment_count":1.0,
        "Solution_link_count":2.0,
        "Solution_readability":18.1,
        "Solution_reading_time":86.29,
        "Solution_score_count":0.0,
        "Solution_sentence_count":52.0,
        "Solution_word_count":408.0,
        "Tool":"Azure Machine Learning"
    },
    {
        "Answerer_isAwsEmployee":null,
        "Answerer_isCse":null,
        "Answerer_isExpert":null,
        "Answerer_isModerator":null,
        "Challenge_adjusted_solved_time":3.0937622222,
        "Challenge_answer_count":2,
        "Challenge_body":"<p>Hello,    <\/p>\n<p>I've created an azure for students account wiht $100 free credit and started using Azure Notebooks to train some ML models. I've created a GPU instance which costs $1.20\/hr. I've been using it for at least 1.5h now and what's weird is that no usage is being shown on my dashboard, and on the sponsorship page it's showing that it is not active and that I haven't used any of my credit:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/239817-image.png?platform=QnA\" alt=\"239817-image.png\" \/>    <\/p>\n<p>On the other hand when I go to my subscriptions it says it's active:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/239809-image.png?platform=QnA\" alt=\"239809-image.png\" \/>    <\/p>\n<p>Is something wrong or does it take a while to see usage statistics\/credit spending?    <\/p>\n<p>Thanks in advance.    <\/p>",
        "Challenge_closed_time":1662904704207,
        "Challenge_comment_count":0,
        "Challenge_created_time":1662893566663,
        "Challenge_favorite_count":null,
        "Challenge_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1002201\/azure-for-students-showing-no-usage-despite-using",
        "Challenge_link_count":2,
        "Challenge_participation_count":2,
        "Challenge_readability":9.4,
        "Challenge_reading_time":11.62,
        "Challenge_score_count":1.0,
        "Challenge_sentence_count":8,
        "Challenge_solved_time":3.0937622222,
        "Challenge_title":"Azure for students showing no usage despite using it",
        "Challenge_topic":"Quota Management",
        "Challenge_topic_macro":"Performance Management",
        "Challenge_view_count":null,
        "Challenge_word_count":125,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isCse":null,
        "Poster_isExpert":null,
        "Poster_isModerator":null,
        "Solution_body":"<p>Hi,    <\/p>\n<p>Usually it is every 4 hours the data\/cost is updated so check after sometime, you can check and download the data by using and following the steps over here - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cost-management-billing\/understand\/download-azure-daily-usage\">download-azure-daily-usage<\/a>    <\/p>\n<p>==    <br \/>\nPlease &quot;Accept the answer&quot; if the information helped you. This will help us and others in the community as well.    <\/p>\n",
        "Solution_comment_count":1.0,
        "Solution_link_count":1.0,
        "Solution_readability":13.1,
        "Solution_reading_time":5.93,
        "Solution_score_count":0.0,
        "Solution_sentence_count":3.0,
        "Solution_word_count":57.0,
        "Tool":"Azure Machine Learning"
    }
]