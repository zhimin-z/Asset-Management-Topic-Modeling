[
    {
        "Issue_link":"https:\/\/github.com\/awsdocs\/amazon-sagemaker-developer-guide\/issues\/70",
        "Issue_title":"ResourceLimitExceeded for ml.m4.xlarge when running SageMaker studio demo in a new AWS account",
        "Issue_created_time":1585108798000,
        "Issue_closed_time":1600123381000,
        "Issue_body":"When walking through the SageMaker Studio tour :\r\n\r\nhttps:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/gs-studio-end-to-end.html\r\n\r\nfor the first time in a new AWS account, the usual service limit issue is hit when running code cell [17] to create an endpoint to host the model.\r\n\r\n`ResourceLimitExceeded: An error occurred (ResourceLimitExceeded) when calling the CreateEndpoint operation: The account-level service limit 'ml.m4.xlarge for endpoint usage' is 0 Instances, with current utilization of 0 Instances and a request delta of 1 Instances. Please contact AWS support to request an increase for this limit.`\r\n\r\nSuggestions:\r\n\r\n- The \"Prerequistes\" section could address this proactively, with a link to the service limit increase page, or...\r\n-  the notebook could be changed to use an instance type for the endpoint that does not have a default service limit of `0`\r\n\r\nPlease LMK which is preferable and I will submit a PR\r\n\r\n",
        "Issue_answer_count":3,
        "Issue_self_closed":0.0,
        "Answer_body":"same with code cell [12]\r\nit calls for 5 child weights to be tried:\r\n\r\n`min_child_weights = [1, 2, 4, 8, 10]`\r\n\r\nbut the default number of instances across all training jobs in a new account is 4, and needs to be increased for the tour to work without errors.\r\n\r\nSuggestion:\r\n- add this to prerequsites section\r\n- change the notebook to only try 4 values for `min_child_weights`\r\n\r\n\r\n`ResourceLimitExceeded: An error occurred (ResourceLimitExceeded) when calling the CreateTrainingJob operation: The account-level service limit 'Number of instances across all training jobs' is 4 Instances, with current utilization of 4 Instances and a request delta of 1 Instances. Please contact AWS support to request an increase for this limit.` Neither of these are doc issues. The notebook itself needs to be updated. https:\/\/docs.aws.amazon.com\/general\/latest\/gr\/sagemaker.html states that the default limit for ml.m4.xlarge is 20, so in a typical account, you should be able to run the notebook without failure. Your administrator could have changed this though. You can contact support for a limit increase to fix your account to be able to run this notebook.",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"resourcelimitexceed xlarg run studio demo new aw account walk studio tour http doc aw amazon com latest studio end end html time new aw account usual servic limit issu hit run code cell creat endpoint host model resourcelimitexceed error occur resourcelimitexceed call createendpoint oper account level servic limit xlarg endpoint usag instanc current util instanc request delta instanc contact aw support request increas limit suggest prerequist section address proactiv link servic limit increas page notebook chang us instanc type endpoint default servic limit lmk prefer submit",
        "Issue_preprocessed_content":"studio demo new aw walk studio tour time new aw usual servic limit hit code creat endpoint host model prerequist section proactiv link servic limit increas page chang us instanc type endpoint default servic limit lmk prefer submit",
        "Issue_gpt_summary_original":"The user encountered a ResourceLimitExceeded error when running code cell [17] to create an endpoint to host the model while walking through the SageMaker Studio tour for the first time in a new AWS account. The error occurred due to the account-level service limit 'ml.m4.xlarge for endpoint usage' being 0 Instances. The user suggests that the Prerequisites section could address this proactively with a link to the service limit increase page or the notebook could be changed to use an instance type for the endpoint that does not have a default service limit of 0.",
        "Issue_gpt_summary":"user encount resourcelimitexceed error run code cell creat endpoint host model walk studio tour time new aw account error occur account level servic limit xlarg endpoint usag instanc user suggest prerequisit section address proactiv link servic limit increas page notebook chang us instanc type endpoint default servic limit",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/awsdocs\/amazon-sagemaker-developer-guide\/issues\/69",
        "Issue_title":"sagemaker studio tour missing\/out of order steps",
        "Issue_created_time":1585107785000,
        "Issue_closed_time":1593275392000,
        "Issue_body":"regarding this section:\r\nhttps:\/\/github.com\/awsdocs\/amazon-sagemaker-developer-guide\/blob\/master\/doc_source\/gs-studio-end-to-end.md#keep-track-of-machine-learning-experiments\r\n\r\n- step 1 \"Run the following cell...\" refers to the 8th code cell in the notebook.  The previous 7 code cells need to be run first for the notebook to work, but are never referenced in the tour walkthrough doc.  The doc  goes from having the user clone the repo:\r\n\r\n`git clone https:\/\/github.com\/awslabs\/amazon-sagemaker-examples.git`\r\n\r\nstraight to having the user run the 8th code cell in the notebook, skipping the first 7 code cells.\r\n\r\n-  step 2 \"Create trials and associate....\" refers to code cell 11 in the notebook, but again jumps straight from cell 8 without ever running cells 9, or 10\r\n\r\n\r\n\r\n",
        "Issue_answer_count":2,
        "Issue_self_closed":0.0,
        "Answer_body":"@juliensimon @eslesar-aws \r\nif you want to briefly outline what you _want_ the tour\/walkthrough to look like here, I will submit a PR to fix Updated in latest commit.",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"studio tour miss order step section http github com awsdoc amazon develop guid blob master doc sourc studio end end track machin learn experi step run follow cell refer code cell notebook previou code cell need run notebook work referenc tour walkthrough doc doc goe have user clone repo git clone http github com awslab amazon exampl git straight have user run code cell notebook skip code cell step creat trial associ refer code cell notebook jump straight cell run cell",
        "Issue_preprocessed_content":"studio tour order step section step run refer code previou code run work referenc tour walkthrough doc doc goe have user clone repo straight have user run code code step creat trial refer code jump straight",
        "Issue_gpt_summary_original":"The user is encountering an error while setting up a MME on sagemaker using an existing container image. The model is not loading and the user is receiving a connection error. The expected behavior is for the model to load and return predictions. The model files are stored in S3 and are in the correct directory structure with a version number.",
        "Issue_gpt_summary":"user encount error set mme exist contain imag model load user receiv connect error expect behavior model load return predict model file store correct directori structur version number",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws\/sagemaker-tensorflow-serving-container\/issues\/170",
        "Issue_title":"[bug] : Model not loading while using existing container image to setup MME on sagemaker",
        "Issue_created_time":1602135852000,
        "Issue_closed_time":null,
        "Issue_body":"Checklist\r\n- [x] I've prepended issue tag with type of change: [bug]\r\n- [ ] (If applicable) I've attached the script to reproduce the bug\r\n- [x] (If applicable) I've documented below the DLC image\/dockerfile this relates to\r\n- [ ] (If applicable) I've documented below the tests I've run on the DLC image\r\n- [x] I'm using an existing DLC image listed here: https:\/\/docs.aws.amazon.com\/deep-learning-containers\/latest\/devguide\/deep-learning-containers-images.html\r\n- [ ] I've built my own container based off DLC (and I've attached the code used to build my own image)\r\n\r\n*Concise Description:*\r\nGetting this error, when invoking a MME on sagemaker setup using `763104351884.dkr.ecr.us-east-1.amazonaws.com\/tensorflow-inference:2.3.0-cpu-py37-ubuntu18.04` container image.\r\n\r\nurllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=14448): Max retries exceeded with url: \/v1\/models\/d2295a7526f9df36354b8a2c4adc4f63 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f70966dba50>: Failed to establish a new connection: [Errno 111] Connection refused'))\r\nTraceback (most recent call last):\r\n  File \"\/sagemaker\/python_service.py\", line 157, in _handle_load_model_post\r\n    self._wait_for_model(model_name)\r\n  File \"\/sagemaker\/python_service.py\", line 247, in _wait_for_model\r\n    response = session.get(url)\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/requests\/sessions.py\", line 546, in get\r\n    return self.request('GET', url, **kwargs)\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/requests\/sessions.py\", line 533, in request\r\n    resp = self.send(prep, **send_kwargs)\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/requests\/sessions.py\", line 646, in send\r\n    r = adapter.send(request, **kwargs)\r\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/requests\/adapters.py\", line 516, in send\r\n    raise ConnectionError(e, request=request)\r\n\r\n*DLC image\/dockerfile:*\r\n763104351884.dkr.ecr.us-east-1.amazonaws.com\/tensorflow-inference:2.3.0-cpu-py37-ubuntu18.04\r\n*Current behavior:*\r\n\r\n*Expected behavior:*\r\nModel should load up and return prediction\r\n*Additional context:*\r\nI have setup a MME using the above mentioned container and invoking the endpoint using a lambda. The model files are in placed in S3 and are in the correct directory structure with a version number. ",
        "Issue_answer_count":1,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"bug model load exist contain imag setup mme checklist prepend issu tag type chang bug applic attach script reproduc bug applic document dlc imag dockerfil relat applic document test run dlc imag exist dlc imag list http doc aw amazon com deep learn contain latest devguid deep learn contain imag html built contain base dlc attach code build imag concis descript get error invok mme setup dkr ecr east amazonaw com tensorflow infer cpu ubuntu contain imag urllib except maxretryerror httpconnectionpool host localhost port max retri exceed url model dafdfbacadcf caus newconnectionerror fail establish new connect errno connect refus traceback recent file python servic line handl load model post self wait model model file python servic line wait model respons session url file usr local lib python site packag request session line return self request url kwarg file usr local lib python site packag request session line request resp self send prep send kwarg file usr local lib python site packag request session line send adapt send request kwarg file usr local lib python site packag request adapt line send rais connectionerror request request dlc imag dockerfil dkr ecr east amazonaw com tensorflow infer cpu ubuntu current behavior expect behavior model load return predict addit context setup mme mention contain invok endpoint lambda model file place correct directori structur version number",
        "Issue_preprocessed_content":"model load exist contain imag setup checklist prepend tag type chang script reproduc bug document dlc relat document test run dlc imag exist dlc imag list built contain base dlc concis descript invok setup contain imag max retri url traceback file line file line respons file line return url kwarg file line request resp file line send kwarg file line send rais dlc behavior expect behavior model load return predict context setup mention contain invok endpoint lambda model file place directori structur version number",
        "Issue_gpt_summary_original":"The user is facing an issue while deploying a custom TensorFlow model on Amazon SageMaker for inference. The model has three inputs and five outputs. The user has successfully created the model endpoint on SageMaker, but when trying to hit the request for the results, they are getting an error message stating \"Missing 'inputs' or 'instances' key\". The user has created a model.tar.gz file with the required structure and has implemented input_handler and output_handler functions in inference.py. The issue seems to be related to the input data not being passed correctly to the model.",
        "Issue_gpt_summary":"user face issu deploi custom tensorflow model infer model input output user successfulli creat model endpoint try hit request result get error messag state miss input instanc kei user creat model tar file requir structur implement input handler output handler function infer issu relat input data pass correctli model",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws\/sagemaker-tensorflow-serving-container\/issues\/73",
        "Issue_title":"Error in giving inputs to the tensorflow serving model on sagemaker. {'error': \"Missing 'inputs' or 'instances' key\"}",
        "Issue_created_time":1567172491000,
        "Issue_closed_time":1571957138000,
        "Issue_body":"I have a custom model built-in TensorFlow. I am trying to deploy this model on amazon sagemaker for inference. The model takes three inputs and gives five outputs.\r\nThe name of the inputs are:\r\n1. `input_image` \r\n2. `input_image_meta` \r\n3. `input_anchors` \r\n\r\n\r\nand the name of outputs are:\r\n1.  `output_detections`\r\n2.  `output_mrcnn_class`\r\n3.  `output_mrcnn_bbox`\r\n4.  `output_mrcnn_mask`\r\n5.  `output_rois`\r\n\r\nI have successfully created the model endpoint on sagemaker and when I am trying to hit the request for the results, I am getting `{'error': \"Missing 'inputs' or 'instances' key\"}` in return.\r\n \r\nI have made a model.tar.gz file which has the following structure:\r\n\r\n    mymodel\r\n        |__1\r\n            |__variables\r\n            |__saved_model.pb\r\n\r\n    code\r\n        |__inference.py\r\n        |__requirements.txt\r\n\r\nAs specified in the documentation, inference.py has input_handler and output handler functions. From the client-side, I pass the S3 link of the image which then transforms to the three inputs for the model. \r\n\r\nThe structure of input_handler is as follows:\r\n\r\n```\r\ndef input_handler(data, context):\r\n     input_data = json.loads(data.read().decode('utf-8'))\r\n\r\n    obj = bucket.Object(input_data['img_link'])\r\n    tmp = tempfile.NamedTemporaryFile()\r\n    \r\n    # download image from AWS S3\r\n    with open(tmp.name, 'wb') as f:\r\n        obj.download_fileobj(f)\r\n        image=mpimg.imread(tmp.name)\r\n    \r\n    # make preprocessing\r\n    image = Image.fromarray(image)\r\n     \r\n     ...... # some more transformations \r\n     return = {\"input_image\": Python list for image,\r\n                    \"input_image_meta: Python list for input image meta,\r\n                    \"input_anchors\": Python list for input anchors}\r\n\r\n```\r\nThe deifinition of output_handler is as follows:\r\n\r\n```\r\ndef output_handler(data, context):\r\n      output_string = data.content.decode('unicode-escape')\r\n      return output_string, context.accept_header\r\n```\r\n\r\nThe sagemaker endpoint gets created and the tensorflow server also starts(as shown in CloudWatch logs).\r\nOn the client side, I call the predictor using follwoing code:\r\n\r\n```\r\nrequest = {}\r\nrequest[\"img_link\"] = \"image.jpg\"\r\nresult = predictor.predict(request)\r\n```\r\n\r\nBut when I print the result the following gets printed out, `{'error': \"Missing 'inputs' or 'instances' key\"}`\r\nAll the bucket connections for loading the image are in inference.py\r\n      ",
        "Issue_answer_count":2,
        "Issue_self_closed":0.0,
        "Answer_body":"Hello @janismdhanbad,\r\n\r\nI believe your inference requests will have to follow the TensorFlow serving REST API specifications defined here: https:\/\/www.tensorflow.org\/tfx\/serving\/api_rest#request_format_2\r\n\r\n```\r\nThe request body for predict API must be JSON object formatted as follows:\r\n\r\n{\r\n  \/\/ (Optional) Serving signature to use.\r\n  \/\/ If unspecifed default serving signature is used.\r\n  \"signature_name\": <string>,\r\n\r\n  \/\/ Input Tensors in row (\"instances\") or columnar (\"inputs\") format.\r\n  \/\/ A request can have either of them but NOT both.\r\n  \"instances\": <value>|<(nested)list>|<list-of-objects>\r\n  \"inputs\": <value>|<(nested)list>|<object>\r\n}\r\n``` closing due to inactivity. feel free to reopen if necessary.",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"error give input tensorflow serv model error miss input instanc kei custom model built tensorflow try deploi model infer model take input give output input input imag input imag meta input anchor output output detect output mrcnn class output mrcnn bbox output mrcnn mask output roi successfulli creat model endpoint try hit request result get error miss input instanc kei return model tar file follow structur mymodel variabl save model code infer requir txt specifi document infer input handler output handler function client pass link imag transform input model structur input handler follow def input handler data context input data json load data read decod utf obj bucket object input data img link tmp tempfil namedtemporaryfil download imag aw open tmp obj download fileobj imag mpimg imread tmp preprocess imag imag fromarrai imag transform return input imag python list imag input imag meta python list input imag meta input anchor python list input anchor deifinit output handler follow def output handler data context output string data content decod unicod escap return output string context accept header endpoint get creat tensorflow server start shown cloudwatch log client predictor follwo code request request img link imag jpg result predictor predict request print result follow get print error miss input instanc kei bucket connect load imag infer",
        "Issue_preprocessed_content":"give input tensorflow serv model custom model tensorflow try deploi model infer model take input give output input output creat model endpoint try hit request result return file structur mymodel code specifi document output handler function link imag transform input model structur deifinit endpoint get creat tensorflow server start client predictor code print result get print bucket load imag",
        "Issue_gpt_summary_original":"The user encountered an error message stating that no kind \"TrainingJob\" is registered for version \"sagemaker.aws.amazon.com\/v1\" in scheme \"k8s.io\/kubectl\/pkg\/scheme\/scheme.go:28\".",
        "Issue_gpt_summary":"user encount error messag state kind trainingjob regist version aw amazon com scheme kubectl pkg scheme scheme",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws\/amazon-sagemaker-operator-for-k8s\/issues\/175",
        "Issue_title":"error: no kind \"TrainingJob\" is registered for version \"sagemaker.aws.amazon.com\/v1\" in scheme \"k8s.io\/kubectl\/pkg\/scheme\/scheme.go:28\"",
        "Issue_created_time":1615292895000,
        "Issue_closed_time":1615314058000,
        "Issue_body":"",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"Closing in favour of #174 ",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"error kind trainingjob regist version aw amazon com scheme kubectl pkg scheme scheme ",
        "Issue_preprocessed_content":"kind trainingjob regist version scheme ",
        "Issue_gpt_summary_original":"The user encountered an error message stating that no kind \"TrainingJob\" is registered for version \"sagemaker.aws.amazon.com\/v1\" in scheme \"k8s.io\/kubectl\/pkg\/scheme\/scheme.go:28\".",
        "Issue_gpt_summary":"user encount error messag state kind trainingjob regist version aw amazon com scheme kubectl pkg scheme scheme",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws\/amazon-sagemaker-operator-for-k8s\/issues\/174",
        "Issue_title":"error: no kind \"TrainingJob\" is registered for version \"sagemaker.aws.amazon.com\/v1\" in scheme \"k8s.io\/kubectl\/pkg\/scheme\/scheme.go:28\"",
        "Issue_created_time":1615292808000,
        "Issue_closed_time":1632465008000,
        "Issue_body":"error: no kind \"TrainingJob\" is registered for version \"sagemaker.aws.amazon.com\/v1\" in scheme \"k8s.io\/kubectl\/pkg\/scheme\/scheme.go:28\"",
        "Issue_answer_count":3,
        "Issue_self_closed":0.0,
        "Answer_body":"Thanks for using amazon-sagemaker-operator-for-k8s. Please help us with the steps to replicate the issue, especially the installation\r\n\r\nOfficial documentation for reference: https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/amazon-sagemaker-operators-for-kubernetes.html I ran into this issue while myself and was resolved by making sure the SageMaker operator was applied and running by verifying with kubectl -n sagemaker-k8s-operator-system get pods Closing since there has been no activity in 90+ days",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"error kind trainingjob regist version aw amazon com scheme kubectl pkg scheme scheme error kind trainingjob regist version aw amazon com scheme kubectl pkg scheme scheme",
        "Issue_preprocessed_content":"kind trainingjob regist version scheme kind trainingjob regist version scheme",
        "Issue_gpt_summary_original":"The SageMaker Operator Types fail the KubeBuilder V2 custom CRD definition validation check due to unescaped regex patterns. The user expected KubeBuilder to generate a CRD specification that includes AWS SageMaker Operator Types. The issue can be resolved by escaping the regex pattern with quotes.",
        "Issue_gpt_summary":"oper type fail kubebuild custom crd definit valid check unescap regex pattern user expect kubebuild gener crd specif includ oper type issu resolv escap regex pattern quot",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws\/amazon-sagemaker-operator-for-k8s\/issues\/125",
        "Issue_title":"SageMaker Operator Types fails KubeBuilder Pattern validation check",
        "Issue_created_time":1595360580000,
        "Issue_closed_time":1596827786000,
        "Issue_body":"<!-- Please use this template while reporting a bug and provide as much info as possible. Not doing so may result in your bug not being addressed in a timely manner. Thanks!\r\n\r\nIf you would like to report a vulnerability or have a security concern regarding AWS cloud services, please email aws-security@amazon.com\r\n-->\r\n\r\n\r\n**What happened**:\r\nSageMaker Operator Types, when included as part of KubeBuilder V2 custom CRD definition fail due to validation errors of unescaped regex patterns. \r\n\r\n```\r\n\/go\/bin\/controller-gen \"crd:trivialVersions=true\" rbac:roleName=manager-role webhook paths=\".\/...\" output:crd:artifacts:config=config\/crd\/bases\r\n\/go\/pkg\/mod\/github.com\/aws\/amazon-sagemaker-operator-for-k8s@v1.0.1-0.20200410212604-780c48ecb21a\/api\/v1\/common\/sagemaker_api.go:488:2: extra arguments provided: \":\/\/([^\/]+)\/?(.*)$\" (at <input>:1:12)\r\n\/go\/pkg\/mod\/github.com\/aws\/amazon-sagemaker-operator-for-k8s@v1.0.1-0.20200410212604-780c48ecb21a\/api\/v1\/common\/sagemaker_api.go:110:2: extra arguments provided: \":\/\/([^\/]+)\/?(.*)$\" (at <input>:1:12)\r\n\/go\/pkg\/mod\/github.com\/aws\/amazon-sagemaker-operator-for-k8s@v1.0.1-0.20200410212604-780c48ecb21a\/api\/v1\/common\/sagemaker_api.go:82:2: extra arguments provided: \":\/\/([^\/]+)\/?(.*)$\" (at <input>:1:12)\r\n\/go\/pkg\/mod\/github.com\/aws\/amazon-sagemaker-operator-for-k8s@v1.0.1-0.20200410212604-780c48ecb21a\/api\/v1\/common\/sagemaker_api.go:103:2: extra arguments provided: \":\/\/([^\/]+)\/?(.*)$\" (at <input>:1:12)\r\n\/go\/pkg\/mod\/github.com\/aws\/amazon-sagemaker-operator-for-k8s@v1.0.1-0.20200410212604-780c48ecb21a\/api\/v1\/common\/sagemaker_api.go:466:2: extra arguments provided: \":\/\/([^\/]+)\/?(.*)$\" (at <input>:1:12)\r\n\/go\/pkg\/mod\/github.com\/aws\/amazon-sagemaker-operator-for-k8s@v1.0.1-0.20200410212604-780c48ecb21a\/api\/v1\/common\/sagemaker_api.go:450:2: extra arguments provided: \":\/\/([^\/]+)\/?(.*)$\" (at <input>:1:12)\r\n\/go\/pkg\/mod\/github.com\/aws\/amazon-sagemaker-operator-for-k8s@v1.0.1-0.20200410212604-780c48ecb21a\/api\/v1\/common\/sagemaker_api.go:500:2: extra arguments provided: \":\/\/([^\/]+)\/?(.*)$\" (at <input>:1:12)\r\n\/go\/pkg\/mod\/github.com\/aws\/amazon-sagemaker-operator-for-k8s@v1.0.1-0.20200410212604-780c48ecb21a\/api\/v1\/common\/sagemaker_api.go:515:2: extra arguments provided: \":\/\/([^\/]+)\/?(.*)$\" (at <input>:1:12)\r\n\/go\/pkg\/mod\/github.com\/aws\/amazon-sagemaker-operator-for-k8s@v1.0.1-0.20200410212604-780c48ecb21a\/api\/v1\/common\/sagemaker_api.go:500:2: extra arguments provided: \":\/\/([^\/]+)\/?(.*)$\" (at <input>:1:12)\r\n\/go\/pkg\/mod\/github.com\/aws\/amazon-sagemaker-operator-for-k8s@v1.0.1-0.20200410212604-780c48ecb21a\/api\/v1\/common\/sagemaker_api.go:450:2: extra arguments provided: \":\/\/([^\/]+)\/?(.*)$\" (at <input>:1:12)\r\n\/go\/pkg\/mod\/github.com\/aws\/amazon-sagemaker-operator-for-k8s@v1.0.1-0.20200410212604-780c48ecb21a\/api\/v1\/common\/sagemaker_api.go:82:2: extra arguments provided: \":\/\/([^\/]+)\/?(.*)$\" (at <input>:1:12)\r\n\/go\/pkg\/mod\/github.com\/aws\/amazon-sagemaker-operator-for-k8s@v1.0.1-0.20200410212604-780c48ecb21a\/api\/v1\/common\/sagemaker_api.go:466:2: extra arguments provided: \":\/\/([^\/]+)\/?(.*)$\" (at <input>:1:12)\r\n\/go\/pkg\/mod\/github.com\/aws\/amazon-sagemaker-operator-for-k8s@v1.0.1-0.20200410212604-780c48ecb21a\/api\/v1\/common\/sagemaker_api.go:103:2: extra arguments provided: \":\/\/([^\/]+)\/?(.*)$\" (at <input>:1:12)\r\n\/go\/pkg\/mod\/github.com\/aws\/amazon-sagemaker-operator-for-k8s@v1.0.1-0.20200410212604-780c48ecb21a\/api\/v1\/common\/sagemaker_api.go:488:2: extra arguments provided: \":\/\/([^\/]+)\/?(.*)$\" (at <input>:1:12)\r\n\/go\/pkg\/mod\/github.com\/aws\/amazon-sagemaker-operator-for-k8s@v1.0.1-0.20200410212604-780c48ecb21a\/api\/v1\/common\/sagemaker_api.go:515:2: extra arguments provided: \":\/\/([^\/]+)\/?(.*)$\" (at <input>:1:12)\r\n\/go\/pkg\/mod\/github.com\/aws\/amazon-sagemaker-operator-for-k8s@v1.0.1-0.20200410212604-780c48ecb21a\/api\/v1\/common\/sagemaker_api.go:110:2: extra arguments provided: \":\/\/([^\/]+)\/?(.*)$\" (at <input>:1:12)\r\n```\r\n\r\n**What you expected to happen**:\r\nKubeBuilder should generate CRD specification which includes AWS SageMaker Operator Types\r\n\r\n**How to reproduce it (as minimally and precisely as possible)**:\r\n```\r\nimport (\r\n\tcommonv1 \"github.com\/aws\/amazon-sagemaker-operator-for-k8s\/api\/v1\/common\"\r\n\tmetav1 \"k8s.io\/apimachinery\/pkg\/apis\/meta\/v1\"\r\n)\r\n\r\n\/\/ GuestbookSpec defines the desired state of Guestbook\r\ntype GuestbookSpec struct {\r\n\t\/\/ INSERT ADDITIONAL SPEC FIELDS - desired state of cluster\r\n\t\/\/ Important: Run \"make\" to regenerate code after modifying this file\r\n\r\n\tAlgorithmSpecification *commonv1.AlgorithmSpecification `json:\"algorithmSpecification\"`\r\n\r\n\tEnableInterContainerTrafficEncryption *bool `json:\"enableInterContainerTrafficEncryption,omitempty\"`\r\n\r\n\tEnableNetworkIsolation *bool `json:\"enableNetworkIsolation,omitempty\"`\r\n...\r\n\/\/Run make install with above  types in custom operator\r\nmake install \r\n```\r\n\r\n**Anything else we need to know?**:\r\nTried copying the above types and escaped the regex pattern with quotes (``\/\/ +kubebuilder:validation:Pattern='^(https|s3):\/\/([^\/]+)\/?(.*)$'``) and everything worked\r\n\r\n**Environment**:\r\n- Kubernetes version (use `kubectl version`):Version: version.Version{KubeBuilderVersion:\"2.3.1\", KubernetesVendor:\"1.16.4\", GitCommit:\"8b53abeb4280186e494b726edf8f54ca7aa64a49\", BuildDate:\"2020-03-26T16:42:00Z\", GoOs:\"unknown\", GoArch:\"unknown\"}\r\n- Operator version (controller image tag):\tgithub.com\/aws\/amazon-sagemaker-operator-for-k8s v1.0.1-0.20200410212604-780c48ecb21a\r\n- OS (e.g: `cat \/etc\/os-release`):\r\n- Kernel (e.g. `uname -a`):\r\n- Installation method:\r\n- Others:\r\n",
        "Issue_answer_count":2,
        "Issue_self_closed":0.0,
        "Answer_body":"Hi Nagaraj, I'll contact you directly to discuss this. It appears as though you are attempting to build your project with a newer version of `controller-gen` than we have supported in our CRDs. We are using an older version [`v0.2.0-beta.2`](https:\/\/github.com\/aws\/amazon-sagemaker-operator-for-k8s\/blob\/283886dd7c66adfd8c491bf452796fea698ceab8\/Makefile#L98) for our builds. We will need to update our CRDs (and maybe some controller logic) and our build scripts to support the newest version ([`v0.3.0`](https:\/\/github.com\/kubernetes-sigs\/controller-tools\/releases\/tag\/v0.3.0)). ",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"oper type fail kubebuild pattern valid check happen oper type includ kubebuild custom crd definit fail valid error unescap regex pattern bin control gen crd trivialvers true rbac rolenam manag role webhook path output crd artifact config config crd base pkg mod github com aw amazon oper cecba api common api extra argument provid pkg mod github com aw amazon oper cecba api common api extra argument provid pkg mod github com aw amazon oper cecba api common api extra argument provid pkg mod github com aw amazon oper cecba api common api extra argument provid pkg mod github com aw amazon oper cecba api common api extra argument provid pkg mod github com aw amazon oper cecba api common api extra argument provid pkg mod github com aw amazon oper cecba api common api extra argument provid pkg mod github com aw amazon oper cecba api common api extra argument provid pkg mod github com aw amazon oper cecba api common api extra argument provid pkg mod github com aw amazon oper cecba api common api extra argument provid pkg mod github com aw amazon oper cecba api common api extra argument provid pkg mod github com aw amazon oper cecba api common api extra argument provid pkg mod github com aw amazon oper cecba api common api extra argument provid pkg mod github com aw amazon oper cecba api common api extra argument provid pkg mod github com aw amazon oper cecba api common api extra argument provid pkg mod github com aw amazon oper cecba api common api extra argument provid expect happen kubebuild gener crd specif includ oper type reproduc minim precis possibl import commonv github com aw amazon oper api common metav apimachineri pkg api meta guestbookspec defin desir state guestbook type guestbookspec struct insert addit spec field desir state cluster import run regener code modifi file algorithmspecif commonv algorithmspecif json algorithmspecif enableintercontainertrafficencrypt bool json enableintercontainertrafficencrypt omitempti enablenetworkisol bool json enablenetworkisol omitempti run instal type custom oper instal need know tri copi type escap regex pattern quot kubebuild valid pattern http work environ kubernet version us kubectl version version version version kubebuildervers kubernetesvendor gitcommit babebebedffcaaaa builddat goo unknown goarch unknown oper version control imag tag github com aw amazon oper cecba cat releas kernel unam instal method",
        "Issue_preprocessed_content":"oper type fail kubebuild valid check oper type includ kubebuild custom crd definit fail valid unescap regex expect kubebuild gener crd specif includ oper type reproduc know tri copi type escap regex quot work environ kubernet version version abeb edf unknown goarch unknown oper version kernel method",
        "Issue_gpt_summary_original":"The user encountered an error while building SageMaker types due to missing types in common\/manual_deepcopy. The packaged types refer to types in zz_generated_deepcopy which are missing, causing the import of sagemaker types in Go Client to fail the build. The error occurred while using Kubernetes version, v1.1.0 operator version, and the Go programming language.",
        "Issue_gpt_summary":"user encount error build type miss type common manual deepcopi packag type refer type gener deepcopi miss caus import type client fail build error occur kubernet version oper version program languag",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws\/amazon-sagemaker-operator-for-k8s\/issues\/122",
        "Issue_title":"Error Building SageMaker Types due to missing types in common\/manual_deepcopy",
        "Issue_created_time":1592335014000,
        "Issue_closed_time":1599678360000,
        "Issue_body":"<!-- Please use this template while reporting a bug and provide as much info as possible. Not doing so may result in your bug not being addressed in a timely manner. Thanks!\r\n\r\nIf you would like to report a vulnerability or have a security concern regarding AWS cloud services, please email aws-security@amazon.com\r\n-->\r\n\r\n\r\n**What happened**:\r\nError Building SageMaker Types due to missing types in common\/manual_deepcopy\r\n(base) afccd2:example nj$ make all\r\ngo: creating new go.mod: module tmp\r\ngo: found sigs.k8s.io\/controller-tools\/cmd\/controller-gen in sigs.k8s.io\/controller-tools v0.2.5\r\n\/devel\/projects\/go_tutorial\/bin\/controller-gen object:headerFile=\"hack\/boilerplate.go.txt\" paths=\".\/...\"\r\ngo fmt .\/...\r\ncontrollers\/guestbook_controller.go\r\ngo vet .\/...\r\ngithub.com\/aws\/amazon-sagemaker-operator-for-k8s\/api\/v1\/common\r\n..\/..\/..\/go_tutorial\/pkg\/mod\/github.com\/aws\/amazon-sagemaker-operator-for-**k8s@v1.1.0\/api\/v1\/common\/manual_deepcopy.go:28:19: tag.DeepCopy undefined (type Tag has no field or method DeepCopy)\r\nmake: *** [vet] Error 2**\r\n\r\n**What you expected to happen**:\r\nPackaged types refer to types in zz_generated_deepcopy which are missing\r\n\r\n**How to reproduce it (as minimally and precisely as possible)**:\r\n\r\n\r\nImport of sagemaker types in Go Client fails build\r\n\r\nimport (\r\n\ttrainingjobv1 \"github.com\/aws\/amazon-sagemaker-operator-for-k8s\/api\/v1\/trainingjob\"\r\n)\r\n\r\n\r\n**Anything else we need to know?**:\r\n\r\n**Environment**:\r\n- Kubernetes version (use `kubectl version`): \r\n- Operator version (controller image tag): v1.1.0\r\n- OS (e.g: `cat \/etc\/os-release`):\r\n- Kernel (e.g. `uname -a`):\r\n- Installation method:\r\n- Others:\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"I believe this may be caused due to the generated deepcopy code not being checked in to the v1.1.0 branch. I attempted to backport this code previously but I don't think the go modules ever picked this up for some reason. I might suggest attempting this pinning to the `master` branch rather than `v1.1.0`. The APIs are backwardly compatible (while `master` is still pointed at a `v1.X`).",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"error build type miss type common manual deepcopi happen error build type miss type common manual deepcopi base afccd exampl creat new mod modul tmp sig control tool cmd control gen sig control tool devel project tutori bin control gen object headerfil hack boilerpl txt path fmt control guestbook control vet github com aw amazon oper api common tutori pkg mod github com aw amazon oper api common manual deepcopi tag deepcopi undefin type tag field method deepcopi vet error expect happen packag type refer type gener deepcopi miss reproduc minim precis possibl import type client fail build import trainingjobv github com aw amazon oper api trainingjob need know environ kubernet version us kubectl version oper version control imag tag cat releas kernel unam instal method",
        "Issue_preprocessed_content":"build type type build type type base exampl creat new modul tmp fmt vet undefin expect packag type refer type reproduc import type client fail build import know environ kubernet version oper version kernel method",
        "Issue_gpt_summary_original":"The user is unable to kick off the SageMaker job for the deployed sample mnist training job. The job is not getting invoked on the SageMaker. The kubectl describe TrainingJob command output is provided in the post.",
        "Issue_gpt_summary":"user unabl kick job deploi sampl mnist train job job get invok kubectl trainingjob command output provid post",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws\/amazon-sagemaker-operator-for-k8s\/issues\/99",
        "Issue_title":"unable to kick off the sagemaker job",
        "Issue_created_time":1583773133000,
        "Issue_closed_time":1599677796000,
        "Issue_body":"\r\nDeployed the sample mnist training job but seems its not getting invoked on the SageMaker\r\n\r\n```\r\nkubectl describe TrainingJob            \r\nName:         xgboost-mnist\r\nNamespace:    default\r\nLabels:       <none>\r\nAnnotations:  kubectl.kubernetes.io\/last-applied-configuration:\r\n                {\"apiVersion\":\"sagemaker.aws.amazon.com\/v1\",\"kind\":\"TrainingJob\",\"metadata\":{\"annotations\":{},\"name\":\"xgboost-mnist\",\"namespace\":\"default\"...\r\nAPI Version:  sagemaker.aws.amazon.com\/v1\r\nKind:         TrainingJob\r\nMetadata:\r\n  Creation Timestamp:  2020-03-09T06:58:17Z\r\n  Generation:          1\r\n  Resource Version:    117181\r\n  Self Link:           \/apis\/sagemaker.aws.amazon.com\/v1\/namespaces\/default\/trainingjobs\/xgboost-mnist\r\n  UID:                 5a907178-61d3-11ea-b461-02efd6507006\r\nSpec:\r\n  Algorithm Specification:\r\n    Training Image:       825641698319.dkr.ecr.us-east-2.amazonaws.com\/xgboost:latest\r\n    Training Input Mode:  File\r\n  Hyper Parameters:\r\n    Name:   max_depth\r\n    Value:  5\r\n    Name:   eta\r\n    Value:  0.2\r\n    Name:   gamma\r\n    Value:  4\r\n    Name:   min_child_weight\r\n    Value:  6\r\n    Name:   silent\r\n    Value:  0\r\n    Name:   objective\r\n    Value:  multi:softmax\r\n    Name:   num_class\r\n    Value:  10\r\n    Name:   num_round\r\n    Value:  10\r\n  Input Data Config:\r\n    Channel Name:      train\r\n    Compression Type:  None\r\n    Content Type:      text\/csv\r\n    Data Source:\r\n      S 3 Data Source:\r\n        S 3 Data Distribution Type:  FullyReplicated\r\n        S 3 Data Type:               S3Prefix\r\n        S 3 Uri:                     s3:\/\/<MY-BUCKET>\/xgboost-mnist\/train\/\r\n    Channel Name:                    validation\r\n    Compression Type:                None\r\n    Content Type:                    text\/csv\r\n    Data Source:\r\n      S 3 Data Source:\r\n        S 3 Data Distribution Type:  FullyReplicated\r\n        S 3 Data Type:               S3Prefix\r\n        S 3 Uri:                     s3:\/\/<MY-BUCKET>\/xgboost-mnist\/validation\/\r\n  Output Data Config:\r\n    S 3 Output Path:  s3:\/\/<MY-BUCKET>\/xgboost-mnist\/models\/\r\n  Region:             us-east-2\r\n  Resource Config:\r\n    Instance Count:     1\r\n    Instance Type:      ml.m4.xlarge\r\n    Volume Size In GB:  5\r\n  Role Arn:             arn:aws:iam::<ACCOUNT>:role\/sagemaker_execution_role\r\n  Stopping Condition:\r\n    Max Runtime In Seconds:  86400```\r\n",
        "Issue_answer_count":15,
        "Issue_self_closed":0.0,
        "Answer_body":"@charlesa101  Thanks for trying out. I am assuming you have replaced input, output buckets and role Arn. \r\n\r\nWould you please run the following command provide the output ?\r\n\r\n```\r\nkubectl  get trainingjobs xgboost-mnist\r\nkubectl describe trainingjob xgboost-mnist\r\n``` @gautamkmr, here you go thank you! yeah i have my own bucket and sagemaker executor role\r\n\r\n```kubectl get trainingjobs\r\nNAME            STATUS   SECONDARY-STATUS   CREATION-TIME          SAGEMAKER-JOB-NAME\r\nxgboost-mnist                               2020-03-09T16:51:08Z ```\r\n\r\n```kubectl describe TrainingJob            \r\nName:         xgboost-mnist\r\nNamespace:    default\r\nLabels:       <none>\r\nAnnotations:  kubectl.kubernetes.io\/last-applied-configuration:\r\n                {\"apiVersion\":\"sagemaker.aws.amazon.com\/v1\",\"kind\":\"TrainingJob\",\"metadata\":{\"annotations\":{},\"name\":\"xgboost-mnist\",\"namespace\":\"default\"...\r\nAPI Version:  sagemaker.aws.amazon.com\/v1\r\nKind:         TrainingJob\r\nMetadata:\r\n  Creation Timestamp:  2020-03-09T06:58:17Z\r\n  Generation:          1\r\n  Resource Version:    117181\r\n  Self Link:           \/apis\/sagemaker.aws.amazon.com\/v1\/namespaces\/default\/trainingjobs\/xgboost-mnist\r\n  UID:                 5a907178-61d3-11ea-b461-02efd6507006\r\nSpec:\r\n  Algorithm Specification:\r\n    Training Image:       825641698319.dkr.ecr.us-east-2.amazonaws.com\/xgboost:latest\r\n    Training Input Mode:  File\r\n  Hyper Parameters:\r\n    Name:   max_depth\r\n    Value:  5\r\n    Name:   eta\r\n    Value:  0.2\r\n    Name:   gamma\r\n    Value:  4\r\n    Name:   min_child_weight\r\n    Value:  6\r\n    Name:   silent\r\n    Value:  0\r\n    Name:   objective\r\n    Value:  multi:softmax\r\n    Name:   num_class\r\n    Value:  10\r\n    Name:   num_round\r\n    Value:  10\r\n  Input Data Config:\r\n    Channel Name:      train\r\n    Compression Type:  None\r\n    Content Type:      text\/csv\r\n    Data Source:\r\n      S 3 Data Source:\r\n        S 3 Data Distribution Type:  FullyReplicated\r\n        S 3 Data Type:               S3Prefix\r\n        S 3 Uri:                     s3:\/\/<MY-BUCKET>\/xgboost-mnist\/train\/\r\n    Channel Name:                    validation\r\n    Compression Type:                None\r\n    Content Type:                    text\/csv\r\n    Data Source:\r\n      S 3 Data Source:\r\n        S 3 Data Distribution Type:  FullyReplicated\r\n        S 3 Data Type:               S3Prefix\r\n        S 3 Uri:                     s3:\/\/<MY-BUCKET>\/xgboost-mnist\/validation\/\r\n  Output Data Config:\r\n    S 3 Output Path:  s3:\/\/<MY-BUCKET>\/xgboost-mnist\/models\/\r\n  Region:             us-east-2\r\n  Resource Config:\r\n    Instance Count:     1\r\n    Instance Type:      ml.m4.xlarge\r\n    Volume Size In GB:  5\r\n  Role Arn:             arn:aws:iam::<ACCOUNT>:role\/sagemaker_execution_role\r\n  Stopping Condition:\r\n    Max Runtime In Seconds:  86400``` @charlesa101  Thanks for providing the output. It appears that operator is not running successfully on your k8s cluster.  you can verify that \r\n\r\n```\r\n kubectl get pods -A | grep -i sagemaker\r\n```\r\n\r\nYou can follow steps from [here](https:\/\/sagemaker.readthedocs.io\/en\/stable\/amazon_sagemaker_operators_for_kubernetes.html#setup-and-operator-deployment) to install the operator, let us know if you face any issue. yeah that's what i noticed as well now\r\n\r\n```kubectl get pods -n sagemaker-k8s-operator-system\r\nNAME                                                         READY   STATUS    RESTARTS   AGE\r\nsagemaker-k8s-operator-controller-manager-5858fd7b8d-h89s8   0\/2     Pending   0          24h``` ```kubectl describe pod  -n sagemaker-k8s-operator-system                                             \r\nName:               sagemaker-k8s-operator-controller-manager-5858fd7b8d-h89s8\r\nNamespace:          sagemaker-k8s-operator-system\r\nPriority:           0\r\nPriorityClassName:  <none>\r\nNode:               <none>\r\nLabels:             control-plane=controller-manager\r\n                    pod-template-hash=5858fd7b8d\r\nAnnotations:        kubernetes.io\/psp: eks.privileged\r\nStatus:             Pending\r\nIP:                 \r\nControlled By:      ReplicaSet\/sagemaker-k8s-operator-controller-manager-5858fd7b8d\r\nContainers:\r\n  kube-rbac-proxy:\r\n    Image:      gcr.io\/kubebuilder\/kube-rbac-proxy:v0.4.0\r\n    Port:       8443\/TCP\r\n    Host Port:  0\/TCP\r\n    Args:\r\n      --secure-listen-address=0.0.0.0:8443\r\n      --upstream=http:\/\/127.0.0.1:8080\/\r\n      --logtostderr=true\r\n      --v=10\r\n    Environment:\r\n      AWS_ROLE_ARN:                 arn:aws:iam::123456789012:role\/DELETE_ME\r\n      AWS_WEB_IDENTITY_TOKEN_FILE:  \/var\/run\/secrets\/eks.amazonaws.com\/serviceaccount\/token\r\n    Mounts:\r\n      \/var\/run\/secrets\/eks.amazonaws.com\/serviceaccount from aws-iam-token (ro)\r\n      \/var\/run\/secrets\/kubernetes.io\/serviceaccount from sagemaker-k8s-operator-default-token-rwdkn (ro)\r\n  manager:\r\n    Image:      957583890962.dkr.ecr.us-east-1.amazonaws.com\/amazon-sagemaker-operator-for-k8s:v1\r\n    Port:       <none>\r\n    Host Port:  <none>\r\n    Command:\r\n      \/manager\r\n    Args:\r\n      --metrics-addr=127.0.0.1:8080\r\n    Limits:\r\n      cpu:     100m\r\n      memory:  30Mi\r\n    Requests:\r\n      cpu:     100m\r\n      memory:  20Mi\r\n    Environment:\r\n      AWS_DEFAULT_SAGEMAKER_ENDPOINT:  \r\n      AWS_ROLE_ARN:                    arn:aws:iam::123456789012:role\/DELETE_ME\r\n      AWS_WEB_IDENTITY_TOKEN_FILE:     \/var\/run\/secrets\/eks.amazonaws.com\/serviceaccount\/token\r\n    Mounts:\r\n      \/var\/run\/secrets\/eks.amazonaws.com\/serviceaccount from aws-iam-token (ro)\r\n      \/var\/run\/secrets\/kubernetes.io\/serviceaccount from sagemaker-k8s-operator-default-token-rwdkn (ro)\r\nConditions:\r\n  Type           Status\r\n  PodScheduled   False \r\nVolumes:\r\n  aws-iam-token:\r\n    Type:                    Projected (a volume that contains injected data from multiple sources)\r\n    TokenExpirationSeconds:  86400\r\n  sagemaker-k8s-operator-default-token-rwdkn:\r\n    Type:        Secret (a volume populated by a Secret)\r\n    SecretName:  sagemaker-k8s-operator-default-token-rwdkn\r\n    Optional:    false\r\nQoS Class:       Burstable\r\nNode-Selectors:  <none>\r\nTolerations:     node.kubernetes.io\/not-ready:NoExecute for 300s\r\n                 node.kubernetes.io\/unreachable:NoExecute for 300s\r\nEvents:\r\n  Type     Reason            Age                   From               Message\r\n  ----     ------            ----                  ----               -------\r\n  Warning  FailedScheduling  64s (x1378 over 34h)  default-scheduler  no nodes available to schedule pods\r\n my eks\/ecr is on us-east2, but it seems all the crd artifacts are coming from us-east1 could that be the issue?\r\n EKS can pull the image from other region too. I think in your case it seems that you don't have any worker node associated to cluster?  At least thats what below message says.\r\n```\r\n  Warning  FailedScheduling  64s (x1378 over 34h)  default-scheduler  no nodes available to schedule pods\r\n```\r\n\r\nCan you run ?  \r\n```\r\nkubectl get node\r\n``` @charlesa101  did you get chance to review it again? ``` kubectl get nodes\r\nNAME                                           STATUS   ROLES    AGE     VERSION\r\nip-172-16-116-51.us-east-2.compute.internal    Ready    <none>   5h47m   v1.14.8-eks-b8860f\r\nip-172-16-121-255.us-east-2.compute.internal   Ready    <none>   5h47m   v1.14.8-eks-b8860f\r\nip-172-16-137-197.us-east-2.compute.internal   Ready    <none>   5h47m   v1.14.8-eks-b8860f\r\n yeah i did, recreated the cluster again but still the same issue\r\n @charlesa101   In previous describe output of `pod` it appears that cluster did not have any worker nodes available `(no nodes available to schedule pods)`.\r\n\r\nBut based on recent output it appears that you have three worker nodes available. \r\n\r\n> NAME                                           STATUS   ROLES    AGE     VERSION\r\n> ip-172-16-116-51.us-east-2.compute.internal    Ready    <none>   5h47m   v1.14.8-eks-b8860f\r\n> ip-172-16-121-255.us-east-2.compute.internal   Ready    <none>   5h47m   v1.14.8-eks-b8860f\r\n> ip-172-16-137-197.us-east-2.compute.internal   Ready    <none>   5h47m   v1.14.8-eks-b8860f\r\n\r\n\r\nCould you please describe each of these nodes and operator pod ?\r\n\r\n```\r\n# Describe nodes , assuming the names of nodes are same as you mentioned in previous comment.\r\nkubectl describe node ip-172-16-116-51.us-east-2.compute.internal \r\nkubectl describe node ip-172-16-121-255.us-east-2.compute.internal \r\nkubectl describe node ip-172-16-137-197.us-east-2.compute.internal \r\n```\r\n\r\n\r\n```\r\n#Get the operator pod name \r\nkubectl get pods -A | grep -i sagemaker\r\nkubectl describe pod <put the pod name here>  -n sagemaker-k8s-operator-system\r\n```\r\n\r\n\r\nIf operator has been deployed successfully and if trainingjob is still not yet running please attach the out put of describe trainingjob as well ? \r\n```\r\nkubectl describe trainingjob xgboost-mnist\r\n\r\n```\r\n\r\n i tried to look checked the operator pod, here is  the log @gautamkmr \r\n\r\n```\r\nkubectl logs -f sagemaker-k8s-operator-controller-manager-5858fd7b8d-2dk5c  -n sagemaker-k8s-operator-system manager\r\n2020-03-15T18:09:13.864Z        INFO    controller-runtime.metrics      metrics server is starting to listen    {\"addr\": \"127.0.0.1:8080\"}\r\n2020-03-15T18:09:13.865Z        INFO    controller-runtime.controller   Starting EventSource    {\"controller\": \"trainingjob\", \"source\": \"kind source: \/, Kind=\"}\r\n2020-03-15T18:09:13.865Z        INFO    controller-runtime.controller   Starting EventSource    {\"controller\": \"hyperparametertuningjob\", \"source\": \"kind source: \/, Kind=\"}\r\n2020-03-15T18:09:13.865Z        INFO    controller-runtime.controller   Starting EventSource    {\"controller\": \"hostingdeployment\", \"source\": \"kind source: \/, Kind=\"}\r\n2020-03-15T18:09:13.866Z        INFO    controller-runtime.controller   Starting EventSource    {\"controller\": \"model\", \"source\": \"kind source: \/, Kind=\"}\r\n2020-03-15T18:09:13.866Z        INFO    controller-runtime.controller   Starting EventSource    {\"controller\": \"endpointconfig\", \"source\": \"kind source: \/, Kind=\"}\r\n2020-03-15T18:09:13.866Z        INFO    controller-runtime.controller   Starting EventSource    {\"controller\": \"batchtransformjob\", \"source\": \"kind source: \/, Kind=\"}\r\n2020-03-15T18:09:13.866Z        INFO    setup   starting manager\r\n2020-03-15T18:09:13.866Z        INFO    controller-runtime.manager      starting metrics server {\"path\": \"\/metrics\"}\r\n2020-03-15T18:09:14.066Z        INFO    controller-runtime.controller   Starting Controller     {\"controller\": \"trainingjob\"}\r\n2020-03-15T18:09:14.066Z        INFO    controller-runtime.controller   Starting Controller     {\"controller\": \"model\"}\r\n2020-03-15T18:09:14.067Z        INFO    controller-runtime.controller   Starting Controller     {\"controller\": \"batchtransformjob\"}\r\n2020-03-15T18:09:14.067Z        INFO    controller-runtime.controller   Starting Controller     {\"controller\": \"hostingdeployment\"}\r\n2020-03-15T18:09:14.066Z        INFO    controller-runtime.controller   Starting Controller     {\"controller\": \"endpointconfig\"}\r\n2020-03-15T18:09:14.067Z        INFO    controller-runtime.controller   Starting Controller     {\"controller\": \"hyperparametertuningjob\"}\r\n2020-03-15T18:09:14.167Z        INFO    controller-runtime.controller   Starting workers        {\"controller\": \"trainingjob\", \"worker count\": 1}\r\n2020-03-15T18:09:14.167Z        INFO    controller-runtime.controller   Starting workers        {\"controller\": \"model\", \"worker count\": 1}\r\n2020-03-15T18:09:14.167Z        INFO    controller-runtime.controller   Starting workers        {\"controller\": \"endpointconfig\", \"worker count\": 1}\r\n2020-03-15T18:09:14.167Z        INFO    controller-runtime.controller   Starting workers        {\"controller\": \"batchtransformjob\", \"worker count\": 1}\r\n2020-03-15T18:09:14.167Z        INFO    controller-runtime.controller   Starting workers        {\"controller\": \"hostingdeployment\", \"worker count\": 1}\r\n2020-03-15T18:09:14.167Z        INFO    controller-runtime.controller   Starting workers        {\"controller\": \"hyperparametertuningjob\", \"worker count\": 1}\r\n2020-03-15T19:09:19.962Z        INFO    controllers.TrainingJob Getting resource        {\"trainingjob\": \"default\/xgboost-mnist\"}\r\n2020-03-15T19:09:19.962Z        INFO    controllers.TrainingJob Job status is empty, setting to intermediate status     {\"trainingjob\": \"default\/xgboost-mnist\", \"status\": \"SynchronizingK8sJobWithSageMaker\"}\r\n2020-03-15T19:09:19.963Z        INFO    controllers.TrainingJob Updating job status     {\"trainingjob\": \"default\/xgboost-mnist\", \"new-status\": {\"trainingJobStatus\":\"SynchronizingK8sJobWithSageMaker\",\"lastCheckTime\":\"2020-03-15T19:09:19Z\"}}\r\n2020-03-15T19:09:19.976Z        INFO    controllers.TrainingJob Getting resource        {\"trainingjob\": \"default\/xgboost-mnist\"}\r\n2020-03-15T19:09:19.976Z        INFO    controllers.TrainingJob Adding generated name to spec   {\"trainingjob\": \"default\/xgboost-mnist\", \"new-name\": \"xgboost-mnist-792eb47166f011ea88d202c3652bf444\"}\r\n2020-03-15T19:09:19.982Z        DEBUG   controller-runtime.controller   Successfully Reconciled {\"controller\": \"trainingjob\", \"request\": \"default\/xgboost-mnist\"}\r\n2020-03-15T19:09:19.983Z        INFO    controllers.TrainingJob Getting resource        {\"trainingjob\": \"default\/xgboost-mnist\"}\r\n2020-03-15T19:09:19.983Z        INFO    controllers.TrainingJob Loaded AWS config       {\"trainingjob\": \"default\/xgboost-mnist\", \"training-job-name\": \"xgboost-mnist-792eb47166f011ea88d202c3652bf444\", \"aws-region\": \"us-east-2\"}\r\n2020-03-15T19:09:19.983Z        INFO    controllers.TrainingJob Calling SM API DescribeTrainingJob      {\"trainingjob\": \"default\/xgboost-mnist\", \"training-job-name\": \"xgboost-mnist-792eb47166f011ea88d202c3652bf444\", \"aws-region\": \"us-east-2\"}\r\n2020-03-15T19:09:20.916Z        ERROR   controllers.TrainingJob.handleSageMakerApiError Handling unrecoverable sagemaker API error      {\"trainingjob\": \"default\/xgboost-mnist\", \"training-job-name\": \"xgboost-mnist-792eb47166f011ea88d202c3652bf444\", \"aws-region\": \"us-east-2\", \"error\": \"UnrecognizedClientException: The security token included in the request is invalid.\\n\\tstatus code: 400, request id: 01ea5be5-6bd5-4bae-b79e-2bc8d86338ee\"}\r\ngithub.com\/go-logr\/zapr.(*zapLogger).Error\r\n        \/go\/pkg\/mod\/github.com\/go-logr\/zapr@v0.1.0\/zapr.go:128\r\ngo.amzn.com\/sagemaker\/sagemaker-k8s-operator\/controllers\/trainingjob.(*TrainingJobReconciler).handleSageMakerApiError\r\n        \/workspace\/controllers\/trainingjob\/trainingjob_controller.go:396\r\ngo.amzn.com\/sagemaker\/sagemaker-k8s-operator\/controllers\/trainingjob.(*TrainingJobReconciler).Reconcile\r\n        \/workspace\/controllers\/trainingjob\/trainingjob_controller.go:172\r\nsigs.k8s.io\/controller-runtime\/pkg\/internal\/controller.(*Controller).reconcileHandler\r\n        \/go\/pkg\/mod\/sigs.k8s.io\/controller-runtime@v0.2.0\/pkg\/internal\/controller\/controller.go:216\r\nsigs.k8s.io\/controller-runtime\/pkg\/internal\/controller.(*Controller).processNextWorkItem\r\n        \/go\/pkg\/mod\/sigs.k8s.io\/controller-runtime@v0.2.0\/pkg\/internal\/controller\/controller.go:192\r\nsigs.k8s.io\/controller-runtime\/pkg\/internal\/controller.(*Controller).worker\r\n        \/go\/pkg\/mod\/sigs.k8s.io\/controller-runtime@v0.2.0\/pkg\/internal\/controller\/controller.go:171\r\nk8s.io\/apimachinery\/pkg\/util\/wait.JitterUntil.func1\r\n        \/go\/pkg\/mod\/k8s.io\/apimachinery@v0.0.0-20190404173353-6a84e37a896d\/pkg\/util\/wait\/wait.go:152\r\nk8s.io\/apimachinery\/pkg\/util\/wait.JitterUntil\r\n        \/go\/pkg\/mod\/k8s.io\/apimachinery@v0.0.0-20190404173353-6a84e37a896d\/pkg\/util\/wait\/wait.go:153\r\nk8s.io\/apimachinery\/pkg\/util\/wait.Until\r\n        \/go\/pkg\/mod\/k8s.io\/apimachinery@v0.0.0-20190404173353-6a84e37a896d\/pkg\/util\/wait\/wait.go:88\r\n2020-03-15T19:09:20.916Z        INFO    controllers.TrainingJob.handleSageMakerApiError Updating job status     {\"trainingjob\": \"default\/xgboost-mnist\", \"training-job-name\": \"xgboost-mnist-792eb47166f011ea88d202c3652bf444\", \"aws-region\": \"us-east-2\", \"new-status\": {\"trainingJobStatus\":\"Failed\",\"additional\":\"UnrecognizedClientException: The security token included in the request is invalid.\\n\\tstatus code: 400, request id: 01ea5be5-6bd5-4bae-b79e-2bc8d86338ee\",\"lastCheckTime\":\"2020-03-15T19:09:20Z\",\"cloudWatchLogUrl\":\"https:\/\/us-east-2.console.aws.amazon.com\/cloudwatch\/home?region=us-east-2#logStream:group=\/aws\/sagemaker\/TrainingJobs;prefix=xgboost-mnist-792eb47166f011ea88d202c3652bf444;streamFilter=typeLogStreamPrefix\",\"sageMakerTrainingJobName\":\"xgboost-mnist-792eb47166f011ea88d202c3652bf444\"}}\r\n2020-03-15T19:09:20.924Z        DEBUG   controller-runtime.controller   Successfully Reconciled {\"controller\": \"trainingjob\", \"request\": \"default\/xgboost-mnist\"}\r\n2020-03-15T19:11:41.623Z        INFO    controllers.TrainingJob Getting resource        {\"trainingjob\": \"default\/xgboost-mnist\"}\r\n2020-03-15T19:11:41.623Z        INFO    controllers.TrainingJob Loaded AWS config       {\"trainingjob\": \"default\/xgboost-mnist\", \"training-job-name\": \"xgboost-mnist-792eb47166f011ea88d202c3652bf444\", \"aws-region\": \"us-east-2\"}\r\n2020-03-15T19:11:41.623Z        INFO    controllers.TrainingJob Calling SM API DescribeTrainingJob      {\"trainingjob\": \"default\/xgboost-mnist\", \"training-job-name\": \"xgboost-mnist-792eb47166f011ea88d202c3652bf444\", \"aws-region\": \"us-east-2\"}\r\n2020-03-15T19:11:42.150Z        ERROR   controllers.TrainingJob.handleSageMakerApiError Handling unrecoverable sagemaker API error      {\"trainingjob\": \"default\/xgboost-mnist\", \"training-job-name\": \"xgboost-mnist-792eb47166f011ea88d202c3652bf444\", \"aws-region\": \"us-east-2\", \"error\": \"UnrecognizedClientException: The security token included in the request is invalid.\\n\\tstatus code: 400, request id: 7145c885-b685-4663-8dd3-6c212ce574b2\"}\r\ngithub.com\/go-logr\/zapr.(*zapLogger).Error\r\n        \/go\/pkg\/mod\/github.com\/go-logr\/zapr@v0.1.0\/zapr.go:128\r\ngo.amzn.com\/sagemaker\/sagemaker-k8s-operator\/controllers\/trainingjob.(*TrainingJobReconciler).handleSageMakerApiError\r\n        \/workspace\/controllers\/trainingjob\/trainingjob_controller.go:396\r\ngo.amzn.com\/sagemaker\/sagemaker-k8s-operator\/controllers\/trainingjob.(*TrainingJobReconciler).Reconcile\r\n        \/workspace\/controllers\/trainingjob\/trainingjob_controller.go:172\r\nsigs.k8s.io\/controller-runtime\/pkg\/internal\/controller.(*Controller).reconcileHandler\r\n        \/go\/pkg\/mod\/sigs.k8s.io\/controller-runtime@v0.2.0\/pkg\/internal\/controller\/controller.go:216\r\nsigs.k8s.io\/controller-runtime\/pkg\/internal\/controller.(*Controller).processNextWorkItem\r\n        \/go\/pkg\/mod\/sigs.k8s.io\/controller-runtime@v0.2.0\/pkg\/internal\/controller\/controller.go:192\r\nsigs.k8s.io\/controller-runtime\/pkg\/internal\/controller.(*Controller).worker\r\n        \/go\/pkg\/mod\/sigs.k8s.io\/controller-runtime@v0.2.0\/pkg\/internal\/controller\/controller.go:171\r\nk8s.io\/apimachinery\/pkg\/util\/wait.JitterUntil.func1\r\n        \/go\/pkg\/mod\/k8s.io\/apimachinery@v0.0.0-20190404173353-6a84e37a896d\/pkg\/util\/wait\/wait.go:152\r\nk8s.io\/apimachinery\/pkg\/util\/wait.JitterUntil\r\n        \/go\/pkg\/mod\/k8s.io\/apimachinery@v0.0.0-20190404173353-6a84e37a896d\/pkg\/util\/wait\/wait.go:153\r\nk8s.io\/apimachinery\/pkg\/util\/wait.Until\r\n        \/go\/pkg\/mod\/k8s.io\/apimachinery@v0.0.0-20190404173353-6a84e37a896d\/pkg\/util\/wait\/wait.go:88\r\n2020-03-15T19:11:42.150Z        INFO    controllers.TrainingJob.handleSageMakerApiError Updating job status     {\"trainingjob\": \"default\/xgboost-mnist\", \"training-job-name\": \"xgboost-mnist-792eb47166f011ea88d202c3652bf444\", \"aws-region\": \"us-east-2\", \"new-status\": {\"trainingJobStatus\":\"Failed\",\"additional\":\"UnrecognizedClientException: The security token included in the request is invalid.\\n\\tstatus code: 400, request id: 7145c885-b685-4663-8dd3-6c212ce574b2\",\"lastCheckTime\":\"2020-03-15T19:11:42Z\",\"cloudWatchLogUrl\":\"https:\/\/us-east-2.console.aws.amazon.com\/cloudwatch\/home?region=us-east-2#logStream:group=\/aws\/sagemaker\/TrainingJobs;prefix=xgboost-mnist-792eb47166f011ea88d202c3652bf444;streamFilter=typeLogStreamPrefix\",\"sageMakerTrainingJobName\":\"xgboost-mnist-792eb47166f011ea88d202c3652bf444\"}}\r\n2020-03-15T19:11:42.159Z        DEBUG   controller-runtime.controller   Successfully Reconciled {\"controller\": \"trainingjob\", \"request\": \"default\/xgboost-mnist\"}\r\n```\r\n @charlesa101  Thanks for sharing the log. You are on right track. I think the issue now is operator pod is unable to retrieve credentials from IAM service to talk to sagemaker. \r\n\r\n`\"error\": \"UnrecognizedClientException: The security token included in the request is invalid.\\n`\r\n\r\nCould you please check your [trust.json](https:\/\/sagemaker.readthedocs.io\/en\/stable\/amazon_sagemaker_operators_for_kubernetes.html#create-an-iam-role) basically **trust policy have three places to update cluster region and OIDC ID and one place to add your AWS account number.** Hi @charlesa101\r\n\r\nClosing this issue since there has been no activity in 90 days. Please re-open if you still need help\r\n\r\nThanks Hi, I'm having the exact same issue except that my pod is running fine. I setup my k8s cluster using terraform with 1 master node and 1 worker node. When I submit the trainingjob, there is no status or job name or anything else. I tried all the commands above and it looks like the scheduler was able to assign the pods to the worker node. Any help would be appreciated! Please see outputs for commands below:\r\n\r\n```\r\nubuntu@ip-172-31-35-229:\/imvaria\/repos\/model-training$ kubectl get pods -A                                                                                                                                                                                                                                                    \r\nNAMESPACE        NAME                                                         READY   STATUS    RESTARTS   AGE                                                                                                                                                                                                                \r\nkube-system      aws-node-67tgx                                               1\/1     Running   0          2d18h\r\nkube-system      aws-node-k2q7z                                               1\/1     Running   0          2d18h\r\nkube-system      coredns-85d5b4454c-cwfvj                                     1\/1     Running   0          2d18h\r\nkube-system      coredns-85d5b4454c-x5ld9                                     1\/1     Running   0          2d18h\r\nkube-system      kube-proxy-54vm5                                             1\/1     Running   0          2d18h\r\nkube-system      kube-proxy-r8j7j                                             1\/1     Running   0          2d18h\r\nkube-system      metrics-server-64cf6869bd-6nppx                              1\/1     Running   0          2d18h\r\nsagemaker-jobs   sagemaker-k8s-operator-controller-manager-855f498957-fhkvv   2\/2     Running   0          2d18h\r\nubuntu@ip-172-31-35-229:\/imvaria\/repos\/model-training$ kubectl describe pod sagemaker-k8s-operator-controller-manager-855f498957-fhkvv -n sagemaker-jobs\r\nName:         sagemaker-k8s-operator-controller-manager-855f498957-fhkvv\r\nNamespace:    sagemaker-jobs\r\nPriority:     0\r\nNode:         ip-10-0-1-245.us-west-2.compute.internal\/10.0.1.245\r\nStart Time:   Fri, 24 Jun 2022 22:26:03 +0000\r\nLabels:       control-plane=controller-manager\r\n              pod-template-hash=855f498957\r\nAnnotations:  kubernetes.io\/psp: eks.privileged\r\nStatus:       Running\r\nIP:           10.0.1.144\r\nIPs:\r\n  IP:           10.0.1.144\r\nControlled By:  ReplicaSet\/sagemaker-k8s-operator-controller-manager-855f498957\r\nContainers:\r\n  manager:\r\n    Container ID:  docker:\/\/d8fc52b3e20a050999d3f24ab914f1d865a84a168a8b038f3fa81ce59cccbced\r\n    Image:         957583890962.dkr.ecr.us-east-1.amazonaws.com\/amazon-sagemaker-operator-for-k8s:v1\r\n    Image ID:      docker-pullable:\/\/957583890962.dkr.ecr.us-east-1.amazonaws.com\/amazon-sagemaker-operator-for-k8s@sha256:94ffbba68954249b1724fdb43f1e8ab13547114555b4a217849687d566191e23\r\n    Port:          <none>\r\n    Host Port:     <none>\r\n    Command:\r\n      \/manager\r\n    Args:\r\n      --metrics-addr=127.0.0.1:8080\r\n      --namespace=sagemaker-jobs\r\n    State:          Running\r\n      Started:      Fri, 24 Jun 2022 22:26:09 +0000\r\n    Ready:          True\r\n    Restart Count:  0\r\n    Limits:\r\n      cpu:     100m\r\n      memory:  30Mi\r\n    Requests:\r\n      cpu:     100m\r\n      memory:  20Mi\r\n    Environment:\r\n      AWS_DEFAULT_SAGEMAKER_ENDPOINT:\r\n      AWS_DEFAULT_REGION:              us-west-2\r\n      AWS_REGION:                      us-west-2\r\n      AWS_ROLE_ARN:                    arn:aws:iam::438029713005:role\/model-training-sagemaker-role20220624222338450100000009\r\n      AWS_WEB_IDENTITY_TOKEN_FILE:     \/var\/run\/secrets\/eks.amazonaws.com\/serviceaccount\/token\r\n    Mounts:\r\n      \/var\/run\/secrets\/eks.amazonaws.com\/serviceaccount from aws-iam-token (ro)\r\n      \/var\/run\/secrets\/kubernetes.io\/serviceaccount from kube-api-access-6j8rt (ro)\r\nkube-rbac-proxy:\r\n    Container ID:  docker:\/\/4ecdaa395fdc70d5cead609465dbf21f6e11771a80ad5db0a6125053ab08b9d3\r\n    Image:         gcr.io\/kubebuilder\/kube-rbac-proxy:v0.4.0\r\n    Image ID:      docker-pullable:\/\/gcr.io\/kubebuilder\/kube-rbac-proxy@sha256:297896d96b827bbcb1abd696da1b2d81cab88359ac34cce0e8281f266b4e08de\r\n    Port:          8443\/TCP\r\n    Host Port:     0\/TCP\r\n    Args:\r\n      --secure-listen-address=0.0.0.0:8443\r\n      --upstream=http:\/\/127.0.0.1:8080\/\r\n      --logtostderr=true\r\n      --v=10\r\n    State:          Running\r\n      Started:      Fri, 24 Jun 2022 22:26:11 +0000\r\n    Ready:          True\r\n    Restart Count:  0\r\n    Environment:\r\n      AWS_DEFAULT_REGION:           us-west-2\r\n      AWS_REGION:                   us-west-2\r\n      AWS_ROLE_ARN:                 arn:aws:iam::438029713005:role\/model-training-sagemaker-role20220624222338450100000009\r\n      AWS_WEB_IDENTITY_TOKEN_FILE:  \/var\/run\/secrets\/eks.amazonaws.com\/serviceaccount\/token\r\n    Mounts:\r\n      \/var\/run\/secrets\/eks.amazonaws.com\/serviceaccount from aws-iam-token (ro)\r\n      \/var\/run\/secrets\/kubernetes.io\/serviceaccount from kube-api-access-6j8rt (ro)\r\nConditions:\r\n  Type              Status\r\n  Initialized       True\r\n  Ready             True\r\n  ContainersReady   True\r\n  PodScheduled      True\r\nVolumes:\r\n  aws-iam-token:\r\n    Type:                    Projected (a volume that contains injected data from multiple sources)\r\n    TokenExpirationSeconds:  86400\r\n  kube-api-access-6j8rt:\r\n    Type:                    Projected (a volume that contains injected data from multiple sources)\r\n    TokenExpirationSeconds:  3607\r\n    ConfigMapName:           kube-root-ca.crt\r\n    ConfigMapOptional:       <nil>\r\n    DownwardAPI:             true\r\nQoS Class:                   Burstable\r\nNode-Selectors:              <none>\r\nTolerations:                 node.kubernetes.io\/not-ready:NoExecute op=Exists for 300s\r\n                             node.kubernetes.io\/unreachable:NoExecute op=Exists for 300s\r\nEvents:                      <none>\r\n```\r\n\r\n```\r\nubuntu@ip-172-31-35-229:\/imvaria\/repos\/model-training$ kubectl logs sagemaker-k8s-operator-controller-manager-855f498957-fhkvv manager -n sagemaker-jobs\r\nI0624 22:26:11.339445       1 request.go:621] Throttling request took 1.046981399s, request: GET:https:\/\/172.20.0.1:443\/apis\/extensions\/v1beta1?timeout=32s\r\n2022-06-24T22:26:12.443Z        INFO    controller-runtime.metrics      metrics server is starting to listen    {\"addr\": \"127.0.0.1:8080\"}\r\n2022-06-24T22:26:12.443Z        INFO    Starting manager in the namespace:      sagemaker-jobs\r\n2022-06-24T22:26:12.443Z        INFO    setup   starting manager\r\n2022-06-24T22:26:12.444Z        INFO    controller-runtime.manager      starting metrics server {\"path\": \"\/metrics\"}\r\n2022-06-24T22:26:12.444Z        INFO    controller      Starting EventSource    {\"reconcilerGroup\": \"sagemaker.aws.amazon.com\", \"reconcilerKind\": \"EndpointConfig\", \"controller\": \"endpointconfig\", \"source\": \"kind source: \/, Kind=\"}\r\n2022-06-24T22:26:12.444Z        INFO    controller      Starting EventSource    {\"reconcilerGroup\": \"sagemaker.aws.amazon.com\", \"reconcilerKind\": \"BatchTransformJob\", \"controller\": \"batchtransformjob\", \"source\": \"kind source: \/, Kind=\"}\r\n2022-06-24T22:26:12.445Z        INFO    controller      Starting EventSource    {\"reconcilerGroup\": \"sagemaker.aws.amazon.com\", \"reconcilerKind\": \"HostingAutoscalingPolicy\", \"controller\": \"hostingautoscalingpolicy\", \"source\": \"kind source: \/, Kind=\"}\r\n2022-06-24T22:26:12.444Z        INFO    controller      Starting EventSource    {\"reconcilerGroup\": \"sagemaker.aws.amazon.com\", \"reconcilerKind\": \"Model\", \"controller\": \"model\", \"source\": \"kind source: \/, Kind=\"}\r\n2022-06-24T22:26:12.444Z        INFO    controller      Starting EventSource    {\"reconcilerGroup\": \"sagemaker.aws.amazon.com\", \"reconcilerKind\": \"TrainingJob\", \"controller\": \"trainingjob\", \"source\": \"kind source: \/, Kind=\"}\r\n2022-06-24T22:26:12.445Z        INFO    controller      Starting EventSource    {\"reconcilerGroup\": \"sagemaker.aws.amazon.com\", \"reconcilerKind\": \"ProcessingJob\", \"controller\": \"processingjob\", \"source\": \"kind source: \/, Kind=\"}\r\n2022-06-24T22:26:12.446Z        INFO    controller      Starting EventSource    {\"reconcilerGroup\": \"sagemaker.aws.amazon.com\", \"reconcilerKind\": \"HyperparameterTuningJob\", \"controller\": \"hyperparametertuningjob\", \"source\": \"kind source: \/, Kind=\"}\r\n2022-06-24T22:26:12.446Z        INFO    controller      Starting EventSource    {\"reconcilerGroup\": \"sagemaker.aws.amazon.com\", \"reconcilerKind\": \"HostingDeployment\", \"controller\": \"hostingdeployment\", \"source\": \"kind source: \/, Kind=\"}\r\n2022-06-24T22:26:12.665Z        INFO    controller      Starting Controller     {\"reconcilerGroup\": \"sagemaker.aws.amazon.com\", \"reconcilerKind\": \"Model\", \"controller\": \"model\"}\r\n2022-06-24T22:26:12.666Z        INFO    controller      Starting Controller     {\"reconcilerGroup\": \"sagemaker.aws.amazon.com\", \"reconcilerKind\": \"HostingAutoscalingPolicy\", \"controller\": \"hostingautoscalingpolicy\"}\r\n2022-06-24T22:26:12.666Z        INFO    controller      Starting Controller     {\"reconcilerGroup\": \"sagemaker.aws.amazon.com\", \"reconcilerKind\": \"EndpointConfig\", \"controller\": \"endpointconfig\"}\r\n2022-06-24T22:26:12.666Z        INFO    controller      Starting Controller     {\"reconcilerGroup\": \"sagemaker.aws.amazon.com\", \"reconcilerKind\": \"BatchTransformJob\", \"controller\": \"batchtransformjob\"}\r\n2022-06-24T22:26:12.666Z        INFO    controller      Starting Controller     {\"reconcilerGroup\": \"sagemaker.aws.amazon.com\", \"reconcilerKind\": \"ProcessingJob\", \"controller\": \"processingjob\"}\r\n2022-06-24T22:26:12.666Z        INFO    controller      Starting Controller     {\"reconcilerGroup\": \"sagemaker.aws.amazon.com\", \"reconcilerKind\": \"HyperparameterTuningJob\", \"controller\": \"hyperparametertuningjob\"}\r\n2022-06-24T22:26:12.666Z        INFO    controller      Starting Controller     {\"reconcilerGroup\": \"sagemaker.aws.amazon.com\", \"reconcilerKind\": \"TrainingJob\", \"controller\": \"trainingjob\"}\r\n2022-06-24T22:26:12.746Z        INFO    controller      Starting Controller     {\"reconcilerGroup\": \"sagemaker.aws.amazon.com\", \"reconcilerKind\": \"HostingDeployment\", \"controller\": \"hostingdeployment\"}\r\n2022-06-24T22:26:12.747Z        INFO    controller      Starting workers        {\"reconcilerGroup\": \"sagemaker.aws.amazon.com\", \"reconcilerKind\": \"HostingDeployment\", \"controller\": \"hostingdeployment\", \"worker count\": 1}\r\n2022-06-24T22:26:12.766Z        INFO    controller      Starting workers        {\"reconcilerGroup\": \"sagemaker.aws.amazon.com\", \"reconcilerKind\": \"Model\", \"controller\": \"model\", \"worker count\": 1}\r\n2022-06-24T22:26:12.766Z        INFO    controller      Starting workers        {\"reconcilerGroup\": \"sagemaker.aws.amazon.com\", \"reconcilerKind\": \"EndpointConfig\", \"controller\": \"endpointconfig\", \"worker count\": 1}\r\n2022-06-24T22:26:12.766Z        INFO    controller      Starting workers        {\"reconcilerGroup\": \"sagemaker.aws.amazon.com\", \"reconcilerKind\": \"HostingAutoscalingPolicy\", \"controller\": \"hostingautoscalingpolicy\", \"worker count\": 1}\r\n2022-06-24T22:26:12.766Z        INFO    controller      Starting workers        {\"reconcilerGroup\": \"sagemaker.aws.amazon.com\", \"reconcilerKind\": \"ProcessingJob\", \"controller\": \"processingjob\", \"worker count\": 1}\r\n2022-06-24T22:26:12.766Z        INFO    controller      Starting workers        {\"reconcilerGroup\": \"sagemaker.aws.amazon.com\", \"reconcilerKind\": \"BatchTransformJob\", \"controller\": \"batchtransformjob\", \"worker count\": 1}\r\n2022-06-24T22:26:12.766Z        INFO    controller      Starting workers        {\"reconcilerGroup\": \"sagemaker.aws.amazon.com\", \"reconcilerKind\": \"TrainingJob\", \"controller\": \"trainingjob\", \"worker count\": 1}\r\n2022-06-24T22:26:12.766Z        INFO    controller      Starting workers        {\"reconcilerGroup\": \"sagemaker.aws.amazon.com\", \"reconcilerKind\": \"HyperparameterTuningJob\", \"controller\": \"hyperparametertuningjob\", \"worker count\": 1}\r\n```\r\n\r\n```\r\nubuntu@ip-172-31-35-229:\/imvaria\/repos\/model-training$ kubectl get trainingjobs\r\nNAME            STATUS   SECONDARY-STATUS   CREATION-TIME          SAGEMAKER-JOB-NAME\r\nosic-test-run                               2022-06-24T22:38:13Z  \r\n```\r\n\r\n```\r\nubuntu@ip-172-31-35-229:\/imvaria\/repos\/model-training$ kubectl describe trainingjob osic-test-run                                                                                                                                                                                                                             \r\nName:         osic-test-run                                                                                                                                                                                                                                                                                                   \r\nNamespace:    default                                                                                                                                                                                                                                                                                                         \r\nLabels:       <none>                                                                                                                                                                                                                                                                                                          \r\nAnnotations:  <none>                                                                                                                                                                                                                                                                                                          \r\nAPI Version:  sagemaker.aws.amazon.com\/v1                                                                                                                                                                                                                                                                                     \r\nKind:         TrainingJob                                                                                                                                                                                                                                                                                                     \r\nMetadata:                                                                                                                                                                                                                                                                                                                     \r\n  Creation Timestamp:  2022-06-24T22:38:13Z                                                                                                                                                                                                                                                                                   \r\n  Generation:          1                                                                                                                                                                                                                                                                                                      \r\n  Managed Fields:\r\n    API Version:  sagemaker.aws.amazon.com\/v1\r\n    Fields Type:  FieldsV1\r\n    fieldsV1:\r\n      f:metadata:\r\n        f:annotations:\r\n          .:\r\n          f:kubectl.kubernetes.io\/last-applied-configuration:\r\n      f:spec:\r\n        .:\r\n        f:algorithmSpecification:\r\n          .:\r\n          f:trainingImage:\r\n          f:trainingInputMode:\r\n        f:inputDataConfig:\r\n        f:outputDataConfig:\r\n          .:\r\n          f:s3OutputPath:\r\n        f:region:\r\n        f:resourceConfig:\r\n          .:\r\n          f:instanceCount:\r\n          f:instanceType:\r\n          f:volumeSizeInGB:\r\n        f:roleArn:\r\n        f:stoppingCondition:\r\n          .:\r\n          f:maxRuntimeInSeconds:\r\n        f:trainingJobName:\r\n    Manager:         kubectl-client-side-apply\r\n    Operation:       Update\r\n    Time:            2022-06-24T22:38:13Z\r\n  Resource Version:  3182\r\n  UID:               0a0880c0-baf9-4f1a-8aa3-37480520c3e2\r\nSpec:\r\n  Algorithm Specification:\r\nTraining Image:       438029713005.dkr.ecr.us-west-2.amazonaws.com\/model-training:latest\r\n    Training Input Mode:  File\r\n  Input Data Config:\r\n    Channel Name:      train\r\n    Compression Type:  None\r\n    Data Source:\r\n      s3DataSource:\r\n        s3DataDistributionType:  FullyReplicated\r\n        s3DataType:              S3Prefix\r\n        s3Uri:                   s3:\/\/osic-full-including-override\r\n  Output Data Config:\r\n    s3OutputPath:  s3:\/\/osic-full-including-override\/experiments\r\n  Region:          us-west-2\r\n  Resource Config:\r\n    Instance Count:     1\r\n    Instance Type:      ml.p3.2xlarge\r\n    Volume Size In GB:  500\r\n  Role Arn:             arn:aws:iam::438029713005:role\/model-training-sagemaker-role20220624222338450100000009\r\n  Stopping Condition:\r\n    Max Runtime In Seconds:  900\r\n  Training Job Name:         osic-test-run\r\nEvents:                      <none>\r\n```\r\n\r\nplease let me know if you need to see anything else!",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"unabl kick job deploi sampl mnist train job get invok kubectl trainingjob xgboost mnist namespac default label annot kubectl kubernet appli configur apivers aw amazon com kind trainingjob metadata annot xgboost mnist namespac default api version aw amazon com kind trainingjob metadata creation timestamp gener resourc version self link api aw amazon com namespac default trainingjob xgboost mnist uid efd spec algorithm specif train imag dkr ecr east amazonaw com xgboost latest train input mode file hyper paramet max depth valu eta valu gamma valu min child weight valu silent valu object valu multi softmax num class valu num round valu input data config channel train compress type content type text csv data sourc data sourc data distribut type fullyrepl data type sprefix uri xgboost mnist train channel valid compress type content type text csv data sourc data sourc data distribut type fullyrepl data type sprefix uri xgboost mnist valid output data config output path xgboost mnist model region east resourc config instanc count instanc type xlarg volum size role arn arn aw iam role execut role stop condit max runtim second",
        "Issue_preprocessed_content":"unabl kick job deploi sampl mnist train job invok",
        "Issue_gpt_summary_original":"The user encountered an issue while trying to install AWS stepfunctions using pip install in SageMaker Studio Notebook. The error message shows that the metadata generation failed due to an AttributeError, and the user received a CryptographyDeprecationWarning. The user expected to be able to install AWS stepfunctions, but the installation failed. The environment used was AWS Step Functions Data Science Python SDK version 2.3.0 and Python version 3.7.",
        "Issue_gpt_summary":"user encount issu try instal aw stepfunct pip instal studio notebook error messag show metadata gener fail attributeerror user receiv cryptographydeprecationwarn user expect abl instal aw stepfunct instal fail environ aw step function data scienc python sdk version python version",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws\/aws-step-functions-data-science-sdk-python\/issues\/188",
        "Issue_title":"pip install stepfunctions fails in SageMaker Studio Notebook",
        "Issue_created_time":1651588352000,
        "Issue_closed_time":null,
        "Issue_body":"### What did you do?\r\n\r\n<!--\r\n-->pip install stepfunctions fails in SageMaker Studio Notebook\r\n\r\nNotebook is using the Python3 (Data Science) kernel.\r\n\r\n\r\n\r\n\r\n### Reproduction Steps\r\n\r\n<!--\r\n--> pip install stepfunctions\r\n\r\n### What did you expect to happen?\r\n\r\n<!--\r\n-->I expected to be able to install AWS stepfunctions.\r\n\r\n### What actually happened?\r\n\r\n<!--\r\n-->\/opt\/conda\/lib\/python3.7\/site-packages\/secretstorage\/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\r\n  from cryptography.utils import int_from_bytes\r\n\/opt\/conda\/lib\/python3.7\/site-packages\/secretstorage\/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\r\n  from cryptography.utils import int_from_bytes\r\nCollecting stepfunctions\r\n  Using cached stepfunctions-2.3.0.tar.gz (67 kB)\r\n  Preparing metadata (setup.py) ... error\r\n  error: subprocess-exited-with-error\r\n  \r\n  \u00d7 python setup.py egg_info did not run successfully.\r\n  \u2502 exit code: 1\r\n  \u2570\u2500> [22 lines of output]\r\n      \/opt\/conda\/lib\/python3.7\/site-packages\/setuptools\/dist.py:760: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\r\n        % (opt, underscore_opt)\r\n      Traceback (most recent call last):\r\n        File \"<string>\", line 36, in <module>\r\n        File \"<pip-setuptools-caller>\", line 34, in <module>\r\n        File \"\/tmp\/pip-install-a9sl8pu9\/stepfunctions_fec8ededb6d5452993a38c0c5620f20d\/setup.py\", line 70, in <module>\r\n          \"IPython\",\r\n        File \"\/opt\/conda\/lib\/python3.7\/site-packages\/setuptools\/__init__.py\", line 87, in setup\r\n          return distutils.core.setup(**attrs)\r\n        File \"\/opt\/conda\/lib\/python3.7\/site-packages\/setuptools\/_distutils\/core.py\", line 109, in setup\r\n          _setup_distribution = dist = klass(attrs)\r\n        File \"\/opt\/conda\/lib\/python3.7\/site-packages\/setuptools\/dist.py\", line 466, in __init__\r\n          for k, v in attrs.items()\r\n        File \"\/opt\/conda\/lib\/python3.7\/site-packages\/setuptools\/_distutils\/dist.py\", line 293, in __init__\r\n          self.finalize_options()\r\n        File \"\/opt\/conda\/lib\/python3.7\/site-packages\/setuptools\/dist.py\", line 885, in finalize_options\r\n          for ep in sorted(loaded, key=by_order):\r\n        File \"\/opt\/conda\/lib\/python3.7\/site-packages\/setuptools\/dist.py\", line 884, in <lambda>\r\n          loaded = map(lambda e: e.load(), filtered)\r\n        File \"\/opt\/conda\/lib\/python3.7\/site-packages\/setuptools\/_vendor\/importlib_metadata\/__init__.py\", line 196, in load\r\n          return functools.reduce(getattr, attrs, module)\r\n      AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\r\n      [end of output]\r\n  \r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\nerror: metadata-generation-failed\r\n\r\n\u00d7 Encountered error while generating package metadata.\r\n\u2570\u2500> See above for output.\r\n\r\nnote: This is an issue with the package mentioned above, not pip.\r\nhint: See above for details.\r\n\r\n\r\n### Environment\r\n\r\n  - **AWS Step Functions Data Science Python SDK version  : 2.3.0\r\n  - **Python Version:** <!-- Version of Python (run the command `python3 --version`) --> 3.7\r\n\r\n### Other\r\n\r\n<!-- e.g. detailed explanation, stack-traces, related issues, suggestions on how to fix, links for us to have context, eg. associated pull-request, stackoverflow, slack, etc -->\r\n\r\n\r\n\r\n\r\n--- \r\n\r\nThis is :bug: Bug Report",
        "Issue_answer_count":0,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"pip instal stepfunct fail studio notebook pip instal stepfunct fail studio notebook notebook python data scienc kernel reproduct step pip instal stepfunct expect happen expect abl instal aw stepfunct actual happen opt conda lib python site packag secretstorag dhcrypto cryptographydeprecationwarn int byte deprec us int byte instead cryptographi util import int byte opt conda lib python site packag secretstorag util cryptographydeprecationwarn int byte deprec us int byte instead cryptographi util import int byte collect stepfunct cach stepfunct tar prepar metadata setup error error subprocess exit error python setup egg info run successfulli exit code line output opt conda lib python site packag setuptool dist userwarn usag dash separ descript file support futur version us underscor descript file instead opt underscor opt traceback recent file line file line file tmp pip instal aslpu stepfunct fecededbdaccfd setup line ipython file opt conda lib python site packag setuptool init line setup return distutil core setup attr file opt conda lib python site packag setuptool distutil core line setup setup distribut dist klass attr file opt conda lib python site packag setuptool dist line init attr item file opt conda lib python site packag setuptool distutil dist line init self final option file opt conda lib python site packag setuptool dist line final option sort load kei order file opt conda lib python site packag setuptool dist line load map lambda load filter file opt conda lib python site packag setuptool vendor importlib metadata init line load return functool reduc getattr attr modul attributeerror type object distribut attribut final featur opt end output note error origin subprocess like problem pip error metadata gener fail encount error gener packag metadata output note issu packag mention pip hint detail environ aw step function data scienc python sdk version python version bug bug report",
        "Issue_preprocessed_content":"pip stepfunct fail studio pip stepfunct fail studio python kernel reproduct step pip stepfunct expect expect abl aw stepfunct cryptographydeprecationwarn deprec us instead import cryptographydeprecationwarn deprec us instead import stepfunct cach prepar metadata python run exit code userwarn usag futur version us underscor instead traceback file string line file line file line ipython file line setup return file line setup dist file line item file line file line sort file line load map filter file line load return reduc type object distribut note origin like problem pip encount gener packag metadata output note packag mention pip hint detail environ aw step function data scienc python sdk version python version detail explan relat fix link context request stackoverflow slack bug bug report",
        "Issue_gpt_summary_original":"The user is facing a challenge in updating the TrainingPipeline to support the new `sagemaker.tensorflow.serving.Model` from the Tensorflow package. They have raised the issue on GitHub for support.",
        "Issue_gpt_summary":"user face challeng updat trainingpipelin support new tensorflow serv model tensorflow packag rais issu github support",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws\/aws-step-functions-data-science-sdk-python\/issues\/17",
        "Issue_title":"Support Tensorflow with the new sagemaker.tensorflow.serving.Model",
        "Issue_created_time":1578691549000,
        "Issue_closed_time":1579559963000,
        "Issue_body":"TrainingPipeline needs to be updated to accommodate the `sagemaker.tensorflow.serving.Model` from Tensorflow package.\r\n\r\nRelated Thread: https:\/\/github.com\/aws\/sagemaker-python-sdk\/issues\/1201",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"This PR https:\/\/github.com\/aws\/sagemaker-python-sdk\/pull\/1252 fixes the issue.",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"support tensorflow new tensorflow serv model trainingpipelin need updat accommod tensorflow serv model tensorflow packag relat thread http github com aw python sdk issu",
        "Issue_preprocessed_content":"tensorflow new trainingpipelin updat tensorflow packag relat thread",
        "Issue_gpt_summary_original":"The user is unable to reimage their SageMaker Studio Lab instance to regain the initial 30GB of space after running out of space while trying to create a Conda environment using mlu-tab.yml. Even after deleting all files from the home folder, the user still has 95% of space used up. The user is seeking help to either reimage the instance or uninstall all libraries installed by creating the Conda environment.",
        "Issue_gpt_summary":"user unabl reimag studio lab instanc regain initi space run space try creat conda environ mlu tab yml delet file home folder user space user seek help reimag instanc uninstal librari instal creat conda environ",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws\/studio-lab-examples\/issues\/167",
        "Issue_title":"inability to reimage SageMaker Studio Lab instance to get the space back",
        "Issue_created_time":1668737794000,
        "Issue_closed_time":1668738306000,
        "Issue_body":"Hello,\r\n\r\nAfter I tried to build a Conda environment using mlu-tab.yml I was ran out of space with no environment created. After I deleted all files from my home folder I still had 95% of my space used. There is no way to \"reimage\" my Studio Lab instance and get back the initial 30Gb of space.\r\n\r\nI followed the AWS Machine Learning University course and cloned the examples for Tabular data course: [(https:\/\/github.com\/aws-samples\/aws-machine-learning-university-accelerated-tab)]\r\n\r\nAfter that I was stupid enough to try creating the Conda environment using the mlu-tab.yml file. the environment creation ate all my space available and creation was failed.\r\nCurrently I have 95% space usage of my \/home\/studio-lab-user folder with no files in it.\r\n\r\nHow can I reimage SageMaker Studio Lab instance to get the space back or uninstall all libraries installed by creating the Conda environment?\r\n\r\nOS: Windows 10\r\nBrowser: Chrome 107.0.5304.107\r\n\r\n![space issue1](https:\/\/user-images.githubusercontent.com\/12427856\/202601233-b7378b40-17d6-4ea3-8e8c-c96bebde0010.png)\r\n![space issue2](https:\/\/user-images.githubusercontent.com\/12427856\/202601236-c6fe41d5-0171-4539-8d82-3eaf0577f427.png)\r\n",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"inabl reimag studio lab instanc space hello tri build conda environ mlu tab yml ran space environ creat delet file home folder space wai reimag studio lab instanc initi space follow aw machin learn univers cours clone exampl tabular data cours http github com aw sampl aw machin learn univers acceler tab stupid try creat conda environ mlu tab yml file environ creation at space avail creation fail current space usag home studio lab user folder file reimag studio lab instanc space uninstal librari instal creat conda environ window browser chrome space issu http user imag githubusercont com cbebd png space issu http user imag githubusercont com cfed eaff png",
        "Issue_preprocessed_content":"inabl reimag studio lab instanc space tri build conda environ ran space environ creat delet file home folder space wai reimag studio lab instanc initi space aw machin learn univers cours clone exampl tabular data cours stupid try creat conda environ file environ creation at space avail creation fail space usag folder file reimag studio lab instanc space librari creat conda environ window browser chrome",
        "Issue_gpt_summary_original":"SageMaker Studio Lab is experiencing elevated errors starting runtimes since November 16, 2022, at 04:00 PM PST. Users are unable to open projects and are receiving an ERR_EMPTY_RESPONSE error in the browser. The SageMaker Studio Lab team is working to restore the service, and users are advised to try again later.",
        "Issue_gpt_summary":"studio lab experienc elev error start runtim novemb pst user unabl open project receiv err respons error browser studio lab team work restor servic user advis try later",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws\/studio-lab-examples\/issues\/166",
        "Issue_title":"Starting 16th Nov 2022 04:00 PM PST, we are experiencing elevated error starting runtimes. The SageMaker Studio Lab team is working to restore the service. We apologize for any inconvenience.",
        "Issue_created_time":1668650514000,
        "Issue_closed_time":1668731619000,
        "Issue_body":"**Describe the bug**\r\nThe banner message is shown on the top page of Studio Lab.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to Studio Lab Top Page\r\n2. The message is shown.\r\n\r\n**Expected behavior**\r\nWe can use the Studio Lab as usual.\r\n\r\nI confirmed the following error.\r\n\r\n* We can start runtime but when clicking \"Open Project\", `ERR_EMPTY_RESPONSE` occurs in the browser.\r\n* When we click the start runtime, \"There was a problem when loading your project. This should be resolved shortly. Please try again later.\" occurred.\r\n\r\n**Screenshots**\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/544269\/202335625-de4d1505-97a7-4748-93d5-f0d6b0f5c597.png)\r\n\r\n**Desktop (please complete the following information):**\r\n - OS: Windows\r\n - Browser Chrome\r\n\r\n**Additional context**\r\n\r\nAs the message suggests, we are working to restore the service. We apologize for any inconvenience.\r\nI'll announce after the service is back. \r\n",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"start nov pst experienc elev error start runtim studio lab team work restor servic apolog inconveni bug banner messag shown page studio lab reproduc step reproduc behavior studio lab page messag shown expect behavior us studio lab usual confirm follow error start runtim click open project err respons occur browser click start runtim problem load project resolv shortli try later occur screenshot imag http user imag githubusercont com ded fdbfc png desktop complet follow inform window browser chrome addit context messag suggest work restor servic apolog inconveni announc servic",
        "Issue_preprocessed_content":"start nov pst experienc elev start runtim studio lab team work restor servic apolog inconveni bug shown page studio lab reproduc step reproduc behavior studio lab page shown expect behavior us studio lab usual confirm start runtim click open project browser click start runtim problem load project resolv shortli try desktop window browser chrome context work restor servic apolog inconveni servic",
        "Issue_gpt_summary_original":"The user is experiencing an elevated fault rate in the start runtime API of SageMaker Studio Lab for more than three days. They are unable to run CPU or GPU runtimes and are seeking information on how long it will take to resolve the issue.",
        "Issue_gpt_summary":"user experienc elev fault rate start runtim api studio lab dai unabl run cpu gpu runtim seek inform long resolv issu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws\/studio-lab-examples\/issues\/155",
        "Issue_title":"we are experiencing elevated fault rate in start runtime API. The SageMaker Studio Lab team is working to restore the service.",
        "Issue_created_time":1667438077000,
        "Issue_closed_time":1667627477000,
        "Issue_body":"its been more than 3 days and im still getting this issue, i cant run cpu or even gpu runtimes in sagemaker\r\nhow long is this going to even take man",
        "Issue_answer_count":4,
        "Issue_self_closed":0.0,
        "Answer_body":"up Ah finally btw, I can run the CPU but not GPU today\r\n @saleemmalik10835 Sorry for the long inconvenience of Studio Lab. As you know, the service was back and we confirmed that we can say it to you. I will close this issue because the mentioned problem is solved.\r\n\r\nBut as @aozorahime said, the GPU instance is sometime unavailable because of another instance allocation issue. Of course, we deal with this problem now. ",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"experienc elev fault rate start runtim api studio lab team work restor servic dai get issu run cpu gpu runtim long go man",
        "Issue_preprocessed_content":"experienc elev fault rate start runtim api studio lab team work restor servic dai run cpu gpu runtim long go man",
        "Issue_gpt_summary_original":"The user is trying to install libraries in SageMaker Studio Lab that require root privileges, but they are not able to access root user. They have tried running `whoami` and `sudo` commands, but the latter is not found. They have also tried to install `sudo` by following a link, but they are prompted for a password which they do not have. The user is seeking help to gain root access or install libraries that require root access.",
        "Issue_gpt_summary":"user try instal librari studio lab requir root privileg abl access root user tri run whoami sudo command tri instal sudo follow link prompt password user seek help gain root access instal librari requir root access",
        "Issue_score_count":1
    },
    {
        "Issue_link":"https:\/\/github.com\/aws\/studio-lab-examples\/issues\/118",
        "Issue_title":"How to get root access in SageMaker Studio Lab",
        "Issue_created_time":1654778335000,
        "Issue_closed_time":1655933766000,
        "Issue_body":"Hi, I am trying to install some libraries in Studio Lab which requires root privileges. \r\n\r\nBelow I have run `whoami` to check if I am root user. (I am not as it should print 'root' in case of root user)\r\n![whoami_image](https:\/\/user-images.githubusercontent.com\/91401599\/172846069-ae664262-ae25-4cf0-9a60-ed5bf657029f.png)\r\n\r\nBelow you can see the error on running sudo: ->  `bash: sudo: command not found`\r\n![sudo_cmd](https:\/\/user-images.githubusercontent.com\/91401599\/172847142-57fb5a9f-720b-41af-989a-93740c29805c.png)\r\n\r\nI followed [this ](https:\/\/stackoverflow.com\/questions\/44443228\/sudo-command-not-found-when-i-ssh-into-server)link to install sudo. \r\nOn running `su -` , It asks for the password, but we don't have any password for Studio Lab. \r\n![password](https:\/\/user-images.githubusercontent.com\/91401599\/172847894-34da1cd8-f59c-4f65-9500-c870b50095c6.png)\r\n\r\nCan anyone tell how to get root access or a way to install libraries which require root access\/(or packages which installs using sudo). \r\nPlease let me know if my query is not clear. ",
        "Issue_answer_count":5,
        "Issue_self_closed":1.0,
        "Answer_body":"Thank you for trying Studio Lab. Now Studio Lab does not allow `sudo` (similar issue: https:\/\/github.com\/aws\/studio-lab-examples\/issues\/40#issuecomment-1005305538). We can use `pip` and `conda` instead. Please refer the following issue.\r\n\r\nWhat software do you try to install? Some libraries will be available in `conda-forge` . Here is the sample of search.\r\n\r\nhttps:\/\/anaconda.org\/search?q=gym Thanks for the reply, I will try to explain the issue.\r\n I am trying to run bipedal robot from Open-ai gym. \r\n```\r\n!pip install gym\r\n!apt-get update\r\n!apt-get -qq -y install xvfb freeglut3-dev ffmpeg> \/dev\/null\r\n!apt-get install xvfb\r\n!pip install pyvirtualdisplay \r\n!pip -q install pyglet\r\n!pip -q install pyopengl\r\n!apt-get install swig\r\n!pip install box2d box2d-kengz\r\n!pip install pybullet\r\n```\r\nThese are the libraries which I need to install for the code to work. \r\nIt works fine on google-colab: (screenshot below)\r\n![colab_gym_ss](https:\/\/user-images.githubusercontent.com\/91401599\/173034039-1973ee00-6c0b-4f49-adad-9bb324c59b8c.png)\r\n\r\nBut it throws error when I run it on SageMaker Studio Lab: (screenshot below)\r\n![sagemaker1](https:\/\/user-images.githubusercontent.com\/91401599\/173034679-f49340dc-de46-42bb-be1b-7c7e3616dac4.png)\r\n\r\nError Log (I have made gym_install.sh file which installs everything described above, I am running it below.): \r\n```\r\n(AKR_env) studio-lab-user@default:~\/sagemaker-studiolab-notebooks\/GM_\/ARS_src$ sh gym_install.sh\r\nRequirement already satisfied: gym in \/home\/studio-lab-user\/.conda\/envs\/AKR_env\/lib\/python3.10\/site-packages (0.24.1)\r\nRequirement already satisfied: gym-notices>=0.0.4 in \/home\/studio-lab-user\/.conda\/envs\/AKR_env\/lib\/python3.10\/site-packages (from gym) (0.0.7)\r\nRequirement already satisfied: numpy>=1.18.0 in \/home\/studio-lab-user\/.conda\/envs\/AKR_env\/lib\/python3.10\/site-packages (from gym) (1.22.4)\r\nRequirement already satisfied: cloudpickle>=1.2.0 in \/home\/studio-lab-user\/.conda\/envs\/AKR_env\/lib\/python3.10\/site-packages (from gym) (2.1.0)\r\nReading package lists... Done\r\nE: List directory \/var\/lib\/apt\/lists\/partial is missing. - Acquire (13: Permission denied)\r\nE: Could not open lock file \/var\/lib\/dpkg\/lock-frontend - open (13: Permission denied)\r\nE: Unable to acquire the dpkg frontend lock (\/var\/lib\/dpkg\/lock-frontend), are you root?\r\nE: Could not open lock file \/var\/lib\/dpkg\/lock-frontend - open (13: Permission denied)\r\nE: Unable to acquire the dpkg frontend lock (\/var\/lib\/dpkg\/lock-frontend), are you root?\r\nRequirement already satisfied: pyvirtualdisplay in \/home\/studio-lab-user\/.conda\/envs\/AKR_env\/lib\/python3.10\/site-packages (3.0)\r\nE: Could not open lock file \/var\/lib\/dpkg\/lock-frontend - open (13: Permission denied)\r\nE: Unable to acquire the dpkg frontend lock (\/var\/lib\/dpkg\/lock-frontend), are you root?\r\nCollecting box2d\r\n  Using cached Box2D-2.3.2.tar.gz (427 kB)\r\n  Preparing metadata (setup.py) ... done\r\nCollecting box2d-kengz\r\n  Using cached Box2D-kengz-2.3.3.tar.gz (425 kB)\r\n  Preparing metadata (setup.py) ... done\r\nBuilding wheels for collected packages: box2d, box2d-kengz\r\n  Building wheel for box2d (setup.py) ... error\r\n  error: subprocess-exited-with-error\r\n  \r\n  \u00d7 python setup.py bdist_wheel did not run successfully.\r\n  \u2502 exit code: 1\r\n  \u2570\u2500> [16 lines of output]\r\n      Using setuptools (version 62.3.3).\r\n      running bdist_wheel\r\n      running build\r\n      running build_py\r\n      creating build\r\n      creating build\/lib.linux-x86_64-cpython-310\r\n      creating build\/lib.linux-x86_64-cpython-310\/Box2D\r\n      copying library\/Box2D\/Box2D.py -> build\/lib.linux-x86_64-cpython-310\/Box2D\r\n      copying library\/Box2D\/__init__.py -> build\/lib.linux-x86_64-cpython-310\/Box2D\r\n      creating build\/lib.linux-x86_64-cpython-310\/Box2D\/b2\r\n      copying library\/Box2D\/b2\/__init__.py -> build\/lib.linux-x86_64-cpython-310\/Box2D\/b2\r\n      running build_ext\r\n      building 'Box2D._Box2D' extension\r\n      swigging Box2D\/Box2D.i to Box2D\/Box2D_wrap.cpp\r\n      swig -python -c++ -IBox2D -small -O -includeall -ignoremissing -w201 -globals b2Globals -outdir library\/Box2D -keyword -w511 -D_SWIG_KWARGS -o Box2D\/Box2D_wrap.cpp Box2D\/Box2D.i\r\n      error: command 'swig' failed: No such file or directory\r\n      [end of output]\r\n  \r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\n  ERROR: Failed building wheel for box2d\r\n  Running setup.py clean for box2d\r\n  Building wheel for box2d-kengz (setup.py) ... error\r\n  error: subprocess-exited-with-error\r\n  \r\n  \u00d7 python setup.py bdist_wheel did not run successfully.\r\n  \u2502 exit code: 1\r\n  \u2570\u2500> [16 lines of output]\r\n      Using setuptools (version 62.3.3).\r\n      running bdist_wheel\r\n      running build\r\n      running build_py\r\n      creating build\r\n      creating build\/lib.linux-x86_64-cpython-310\r\n      creating build\/lib.linux-x86_64-cpython-310\/Box2D\r\n      copying library\/Box2D\/__init__.py -> build\/lib.linux-x86_64-cpython-310\/Box2D\r\n      copying library\/Box2D\/Box2D.py -> build\/lib.linux-x86_64-cpython-310\/Box2D\r\n      creating build\/lib.linux-x86_64-cpython-310\/Box2D\/b2\r\n      copying library\/Box2D\/b2\/__init__.py -> build\/lib.linux-x86_64-cpython-310\/Box2D\/b2\r\n      running build_ext\r\n      building 'Box2D._Box2D' extension\r\n      swigging Box2D\/Box2D.i to Box2D\/Box2D_wrap.cpp\r\n      swig -python -c++ -IBox2D -small -O -includeall -ignoremissing -w201 -globals b2Globals -outdir library\/Box2D -keyword -w511 -D_SWIG_KWARGS -o Box2D\/Box2D_wrap.cpp Box2D\/Box2D.i\r\n      error: command 'swig' failed: No such file or directory\r\n      [end of output]\r\n  \r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\n  ERROR: Failed building wheel for box2d-kengz\r\n  Running setup.py clean for box2d-kengz\r\nFailed to build box2d box2d-kengz\r\nInstalling collected packages: box2d-kengz, box2d\r\n  Running setup.py install for box2d-kengz ... error\r\n  error: subprocess-exited-with-error\r\n  \r\n  \u00d7 Running setup.py install for box2d-kengz did not run successfully.\r\n  \u2502 exit code: 1\r\n  \u2570\u2500> [18 lines of output]\r\n      Using setuptools (version 62.3.3).\r\n      running install\r\n      \/home\/studio-lab-user\/.conda\/envs\/AKR_env\/lib\/python3.10\/site-packages\/setuptools\/command\/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\r\n        warnings.warn(\r\n      running build\r\n      running build_py\r\n      creating build\r\n      creating build\/lib.linux-x86_64-cpython-310\r\n      creating build\/lib.linux-x86_64-cpython-310\/Box2D\r\n      copying library\/Box2D\/__init__.py -> build\/lib.linux-x86_64-cpython-310\/Box2D\r\n      copying library\/Box2D\/Box2D.py -> build\/lib.linux-x86_64-cpython-310\/Box2D\r\n      creating build\/lib.linux-x86_64-cpython-310\/Box2D\/b2\r\n      copying library\/Box2D\/b2\/__init__.py -> build\/lib.linux-x86_64-cpython-310\/Box2D\/b2\r\n      running build_ext\r\n      building 'Box2D._Box2D' extension\r\n      swigging Box2D\/Box2D.i to Box2D\/Box2D_wrap.cpp\r\n      swig -python -c++ -IBox2D -small -O -includeall -ignoremissing -w201 -globals b2Globals -outdir library\/Box2D -keyword -w511 -D_SWIG_KWARGS -o Box2D\/Box2D_wrap.cpp Box2D\/Box2D.i\r\n      error: command 'swig' failed: No such file or directory\r\n      [end of output]\r\n  \r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\nerror: legacy-install-failure\r\n\r\n\u00d7 Encountered error while trying to install package.\r\n\u2570\u2500> box2d-kengz\r\n\r\nnote: This is an issue with the package mentioned above, not pip.\r\nhint: See above for output from the failure.\r\nRequirement already satisfied: pybullet in \/home\/studio-lab-user\/.conda\/envs\/AKR_env\/lib\/python3.10\/site-packages (3.2.5)\r\n(AKR_env) studio-lab-user@default:~\/sagemaker-studiolab-notebooks\/GM_\/ARS_src$ \r\n```\r\n### To be specific I am getting error in this line:\r\n```\r\n(AKR_env) studio-lab-user@default:~\/sagemaker-studiolab-notebooks\/GM_\/ARS_src$ apt-get install xvfb\r\nE: Could not open lock file \/var\/lib\/dpkg\/lock-frontend - open (13: Permission denied)\r\nE: Unable to acquire the dpkg frontend lock (\/var\/lib\/dpkg\/lock-frontend), are you root?\r\n```\r\nSo as mentioned by you I tried to find xvfb in conda-forge, but couldn't find it. \r\nThere are some wrapper xvfb on conda-forge but installing them didn't help with the error. \r\n```\r\n(AKR_env) studio-lab-user@default:~\/sagemaker-studiolab-notebooks\/GM_\/ARS_src$ python check.py\r\nTraceback (most recent call last):\r\n  File \"\/home\/studio-lab-user\/sagemaker-studiolab-notebooks\/GM_\/ARS_src\/check.py\", line 9, in <module>\r\n    display = Display(visible=0, size=(1024, 768))\r\n  File \"\/home\/studio-lab-user\/.conda\/envs\/AKR_env\/lib\/python3.10\/site-packages\/pyvirtualdisplay\/display.py\", line 54, in __init__\r\n    self._obj = cls(\r\n  File \"\/home\/studio-lab-user\/.conda\/envs\/AKR_env\/lib\/python3.10\/site-packages\/pyvirtualdisplay\/xvfb.py\", line 44, in __init__\r\n    AbstractDisplay.__init__(\r\n  File \"\/home\/studio-lab-user\/.conda\/envs\/AKR_env\/lib\/python3.10\/site-packages\/pyvirtualdisplay\/abstractdisplay.py\", line 85, in __init__\r\n    helptext = get_helptext(program)\r\n  File \"\/home\/studio-lab-user\/.conda\/envs\/AKR_env\/lib\/python3.10\/site-packages\/pyvirtualdisplay\/util.py\", line 13, in get_helptext\r\n    p = subprocess.Popen(\r\n  File \"\/home\/studio-lab-user\/.conda\/envs\/AKR_env\/lib\/python3.10\/subprocess.py\", line 966, in __init__\r\n    self._execute_child(args, executable, preexec_fn, close_fds,\r\n  File \"\/home\/studio-lab-user\/.conda\/envs\/AKR_env\/lib\/python3.10\/subprocess.py\", line 1842, in _execute_child\r\n    raise child_exception_type(errno_num, err_msg, err_filename)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'Xvfb'\r\n(AKR_env) studio-lab-user@default:~\/sagemaker-studiolab-notebooks\/GM_\/ARS_src$ \r\n```\r\nTo reproduce above error run below code (check.py) :->\r\n```\r\nimport os\r\nimport numpy as np\r\nimport gym\r\nfrom gym import wrappers\r\nimport pyvirtualdisplay\r\nfrom pyvirtualdisplay import Display\r\n\r\nif __name__ == \"__main__\":\r\n    display = Display(visible=0, size=(1024, 768))\r\n```\r\n Thank you for sharing the error message. Studio Lab does not allow `apt install` so that the `gym_install.sh` does not work straightly. We have to prepare the environment by `conda` and `pip`.\r\n\r\nAt first we can install `swig` from `conda`. We can not install `xvfb` from `conda`, is this necessary to run the code?  Basically I have to capture the video output using `Display` of `pyvirtualdisplay` library. Everything else works. \r\nAs you can see `display = Display(visible=0, size=(1024, 768))` this line throws error  `FileNotFoundError: [Errno 2] No such file or directory: 'Xvfb'` , so I am trying to install `Xvfb`.\r\n\r\nThanks, @ar8372 Sorry for the late reply. I raised the #124 to work OpenAI Gym in Studio Lab. Please comment to #124 if you have additional information. We need your insight to solve the issue. If you do not mind, please close this issue to suppress the duplication of issues.",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"root access studio lab try instal librari studio lab requir root privileg run whoami check root user print root case root user whoami imag http user imag githubusercont com edbff png error run sudo bash sudo command sudo cmd http user imag githubusercont com fbaf png follow http stackoverflow com question sudo command ssh server link instal sudo run ask password password studio lab password http user imag githubusercont com dacd cbc png tell root access wai instal librari requir root access packag instal sudo let know queri clear",
        "Issue_preprocessed_content":"studio lab try librari studio lab requir privileg run check user sudo link sudo ask studio lab wai librari requir let know queri clear",
        "Issue_gpt_summary_original":"The user is unable to open a database file and is encountering an unexpected error while saving a file. They have deleted some unwanted notebooks from the studio lab's files and are now unable to install libraries with pip, create new files, or start the kernel.",
        "Issue_gpt_summary":"user unabl open databas file encount unexpect error save file delet unwant notebook studio lab file unabl instal librari pip creat new file start kernel",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws\/studio-lab-examples\/issues\/94",
        "Issue_title":"Unable to open database file, Unexpected error while saving file: d2l-pytorch-sagemaker-studio-lab\/dash\/Untitled.ipynb unable to open database file",
        "Issue_created_time":1647978773000,
        "Issue_closed_time":1655626980000,
        "Issue_body":"**Describe the bug**\r\n![image](https:\/\/user-images.githubusercontent.com\/42097653\/159563812-a9471c23-ad6a-4354-9e30-ef001df04352.png)\r\n\r\n**To Reproduce**\r\nI've deleted some of the unwanted notebooks from studio lab's files and now I am getting this error. \r\ncannot install libraries with pip, cannot create new files, cannot even start kernel ",
        "Issue_answer_count":9,
        "Issue_self_closed":1.0,
        "Answer_body":"Hey there, I\u2019m not one of the devs sorry\r\n\r\nBut i wanna ask if you can start up a GPU runtime? Kindly Try and let me know thanks @lorazabora  while launching the GPU instance I am getting this as there is no runtime environment available available right now \r\n![image](https:\/\/user-images.githubusercontent.com\/42097653\/159628994-38b1c339-ac43-4f6a-8ac7-56f32a8174f9.png)\r\n So then indeed everyone is experiencing the same issue\r\n\r\nIt\u2019s been over a week now and not yet fixed, CPU runtimes aren\u2019t enough for my workloads neither that they even make much sense since there\u2019s already many free cloud CPU options out there\r\n\r\nI hope they see and fix this soon @someshfengde Thank you for reporting the problem. Would you please tell us how did you delete the notebooks? Because only delete the specific files does not affect the behavior of Jupyter Lab. We need to know the procedure to reproduce your problem.\r\n\r\nIf you need the Studio Lab as soon as possible, recreate the account is one of the option.\r\n Yes I tried to delete all notebooks from directory maybe because of that\n\nHow can I recreate account?\n\n\nOn Thu, Mar 24, 2022, 13:48 Takahiro Kubo ***@***.***> wrote:\n\n> @someshfengde <https:\/\/github.com\/someshfengde> Thank you for reporting\n> the problem. Would you please tell us how did you delete the notebooks?\n> Because only delete the specific files does not affect the behavior of\n> Jupyter Lab. We need to know the procedure to reproduce your problem.\n>\n> If you need the Studio Lab as soon as possible, recreate the account is\n> one of the option.\n>\n> \u2014\n> Reply to this email directly, view it on GitHub\n> <https:\/\/github.com\/aws\/studio-lab-examples\/issues\/94#issuecomment-1077354727>,\n> or unsubscribe\n> <https:\/\/github.com\/notifications\/unsubscribe-auth\/AKBFX5JUOPOEUHKEZGXZF53VBQQN3ANCNFSM5RL44VJA>\n> .\n> You are receiving this because you were mentioned.Message ID:\n> ***@***.***>\n>\n @someshfengde You can delete the account from here.\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/544269\/160840123-5f628318-f158-4e40-abba-29524ceb4248.png)\r\n Dear @someshfengde , to delete the account was worked for you? If you still have problem, please let us know. If you already solved the problem, please let us know by closing the this issue. Hi @icoxfog417  I resolved the issue by deleting and opening the account again .\r\n Thanks for your response :smile:  closing issue now :)  You are welcome! We are very glad if Studio Lab supports your data science learning.\r\n",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"unabl open databas file unexpect error save file pytorch studio lab dash untitl ipynb unabl open databas file bug imag http user imag githubusercont com ada efdf png reproduc delet unwant notebook studio lab file get error instal librari pip creat new file start kernel",
        "Issue_preprocessed_content":"unabl open databas file unexpect save file unabl open databas file bug reproduc delet unwant studio lab file librari pip creat new file start kernel",
        "Issue_gpt_summary_original":"The user is unable to open their project on Amazon Sagemaker, as the 'open project' button keeps loading indefinitely. The user has tried various solutions such as restarting the project, browser, laptop, clearing cache, and changing the environment from GPU to CPU, but nothing has worked. The user has attached a screenshot and requested assistance in resolving the issue.",
        "Issue_gpt_summary":"user unabl open project open project button keep load indefinit user tri solut restart project browser laptop clear cach chang environ gpu cpu work user attach screenshot request assist resolv issu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws\/studio-lab-examples\/issues\/72",
        "Issue_title":"Can't open project on amazon sagemaker",
        "Issue_created_time":1645584371000,
        "Issue_closed_time":1668499115000,
        "Issue_body":"Hello, I can't open my project on amazon sagemaker. When I am clicking the 'open project' button, it is loading indefinitely, and I can't do anything with the files. I have restarted my project, browser, laptop, cleared cache, tried from other browsers, changed the env from GPU to CPU but nothing did work. Can you please take a look into my account and resolve the issue? A screenshot is attached here to understand better. Thanks!\r\n<img width=\"1363\" alt=\"Screen Shot 2022-02-22 at 9 45 35 PM\" src=\"https:\/\/user-images.githubusercontent.com\/12325889\/155253679-bc27e42d-0a34-4e8d-8a08-7c1ad5fde9a8.png\">\r\n\r\n",
        "Issue_answer_count":5,
        "Issue_self_closed":0.0,
        "Answer_body":"Not sure if your issue has been resolved or not.\r\nA quick fix is to delete your account and recreate. You will by pass the approval process if you use the same email that has already been approved. @bsaha205 do you still have the problem to open the project? Please let us know about your situation. I'll close the issue. If you have the trouble. please try @MicheleMonclova solution.  Hi @icoxfog417, yes the issue is resolved. Thanks. I am glad to hear that. Please enjoy your ML journey!",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"open project hello open project click open project button load indefinit file restart project browser laptop clear cach tri browser chang env gpu cpu work look account resolv issu screenshot attach understand better thank",
        "Issue_preprocessed_content":"open project open project click open project load indefinit file restart project browser laptop clear cach tri browser chang env gpu cpu work resolv understand thank img width alt shot",
        "Issue_gpt_summary_original":"The user is encountering a bug when attempting to clone a single notebook using the \"Open In in Sagemaker Studio Lab\" button. The error message \"Unable to copy notebook to project\" appears when the user selects \"Copy Notebook Only\" in the modal. Cloning the whole repository works without any issues. The expected behavior is for the notebook to open and appear as it would with cloning a directory. The user is using Windows 11 and Chrome version 97.0.4692.71.",
        "Issue_gpt_summary":"user encount bug attempt clone singl notebook open studio lab button error messag unabl copi notebook project appear user select copi notebook modal clone repositori work issu expect behavior notebook open appear clone directori user window chrome version",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws\/studio-lab-examples\/issues\/54",
        "Issue_title":"[BUG] \"Open In in Sagemaker Studio Lab\" button process fails when attempting to \"Copy Notebooks Only\"",
        "Issue_created_time":1643305784000,
        "Issue_closed_time":1643319424000,
        "Issue_body":"**Describe the bug**\r\nCloning a single notebook using the \"Open In in Sagemaker Studio Lab\" fails.  Cloning the whole repo works.  \r\n\r\nUsing sagemaker's sample, https:\/\/github.com\/aws\/studio-lab-examples\/tree\/main\/open-in-studio-lab, I get this error:\r\n```\r\nUnable to copy notebook to project.\r\nThe link to this notebook is broken or blocked. If this is a private GitHub notebook, sign in to GitHub before copying the notebook.aws\/studio-lab-examples\/blob\/main\/natural-language-processing\/NLP_Disaster_Recovery_Translation.ipynb\r\n```\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. create MD cell with `[![Open in SageMaker Studio Lab](https:\/\/studiolab.sagemaker.aws\/studiolab.svg)](https:\/\/studiolab.sagemaker.aws\/import\/github\/aws\/studio-lab-examples\/blob\/main\/natural-language-processing\/NLP_Disaster_Recovery_Translation.ipynb)`  and run it\r\n2. Click on the button that appears once you run the cell.  Will open new tab in browser\r\n3. In the new pop up tab, click \"Copy to Project\".  Will open new tab in browser\r\n4. In the new pop up tab's modal, select \"Copy Notebook Only\"\r\n5. Error will now appear\r\n\r\n**Expected behavior**\r\nMy notebook will open and appear, just as it would with cloning a directory\r\n\r\n**Screenshots**\r\n![image](https:\/\/user-images.githubusercontent.com\/46935140\/151415892-7d033f97-f98c-4ac8-9c50-99223253b1ee.png)\r\n\r\n**Desktop (please complete the following information):**\r\n - OS: [Windows 11]\r\n - Browser [Chrome]\r\n - Version [97.0.4692.71]\r\n\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"Interesting - this works fine on my end, but I'm using a Mac. I'll create a ticket for you. ",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"bug open studio lab button process fail attempt copi notebook bug clone singl notebook open studio lab fail clone repo work sampl http github com aw studio lab exampl tree main open studio lab error unabl copi notebook project link notebook broken block privat github notebook sign github copi notebook aw studio lab exampl blob main natur languag process nlp disast recoveri translat ipynb reproduc step reproduc behavior creat cell open studio lab http studiolab aw studiolab svg http studiolab aw import github aw studio lab exampl blob main natur languag process nlp disast recoveri translat ipynb run click button appear run cell open new tab browser new pop tab click copi project open new tab browser new pop tab modal select copi notebook error appear expect behavior notebook open appear clone directori screenshot imag http user imag githubusercont com bee png desktop complet follow inform window browser chrome version",
        "Issue_preprocessed_content":"open studio lab fail copi bug clone singl open studio lab fail clone repo work sampl reproduc step reproduc behavior creat run click run open new tab browser new pop tab click copi project open new tab browser new pop tab modal select copi expect behavior open clone directori desktop browser version",
        "Issue_gpt_summary_original":"The user is unable to open Jupyter notebook on Amazon Sagemaker studio lab as it is stuck at \"Preparing project run time\" and shows an error message stating \"There was a problem when starting the project runtime. This should be resolved shortly.\" The issue has been persisting for almost a week, even after trying to shift the runtime from CPU to GPU.",
        "Issue_gpt_summary":"user unabl open jupyt notebook studio lab stuck prepar project run time show error messag state problem start project runtim resolv shortli issu persist week try shift runtim cpu gpu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws\/studio-lab-examples\/issues\/52",
        "Issue_title":"couldn't open Project on amazon sagemaker studio lab",
        "Issue_created_time":1642548428000,
        "Issue_closed_time":1643050102000,
        "Issue_body":"**Describe the bug**\r\nAmazon Sagemaker studio lab is not opening jupyter notebook. It is loading indefinitely at Preparing project run time after that i am getting `There was a problem when starting the project runtime. This should be resolved shortly.` Please try again later. It's been almost a week and it still hasn't been resolved. Even though I tried shifting the runtime from CPU to GPU but issue still persists. Any help would be appreciated.\r\n\r\n**The error i am getting is**\r\n![image](https:\/\/user-images.githubusercontent.com\/81302966\/150034710-378eabbc-13fa-4820-adea-f2ebc8d66431.png)\r\n\r\n\r\n\r\n\r\n\r\n",
        "Issue_answer_count":5,
        "Issue_self_closed":0.0,
        "Answer_body":"Hi - sorry you're running into this issue, we're taking a look.  I have also encountered this problem, which still exists at present.\r\n![image](https:\/\/user-images.githubusercontent.com\/37031974\/150719178-b4b46fa6-d912-44e3-a412-f605435d664c.png)\r\n I deleted my account and re-created it, which took around 5 minutes for them to accept my request for the second time. If need instance then this is the only approach I could find. I had not received any updates from this issue after a week, so I recreated my instance.\r\n I see - really sorry you're running into that. I've created a ticket with the team, but I'll close this issue for now since there is a known workaround.  Hello, I can't open project on amazon sagemaker. When I am clicking the 'open project' button, it is loading indefinitely, and I can't do anything with the files. I have restarted my project, browser, laptop, cleared cache, tried from other browsers, changed the env from GPU to CPU but nothing did work. Can you please take a look into my account and resolve the issue? Thanks!",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"couldn open project studio lab bug studio lab open jupyt notebook load indefinit prepar project run time get problem start project runtim resolv shortli try later week hasn resolv tri shift runtim cpu gpu issu persist help appreci error get imag http user imag githubusercont com eabbc adea febcd png",
        "Issue_preprocessed_content":"couldn open project studio lab bug studio lab open jupyt load indefinit prepar project run time try later hasn resolv tri shift runtim cpu gpu persist help",
        "Issue_gpt_summary_original":"The user is wondering if it is possible to initialize their Sagemaker Studio lab.",
        "Issue_gpt_summary":"user wonder possibl initi studio lab",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws\/studio-lab-examples\/issues\/38",
        "Issue_title":"I just wonder if i can initialize my sagemaker studio lab? ",
        "Issue_created_time":1641220236000,
        "Issue_closed_time":1641229646000,
        "Issue_body":"as the title suggests\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"Hello - if you have any specific technical issues please use our issue template here to describe it in detail. \r\n\r\nhttps:\/\/github.com\/aws\/studio-lab-examples\/issues\/new?assignees=&labels=bug&template=bug-report-for-sagemaker-studio-lab.md&title=\r\n",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"wonder initi studio lab titl suggest",
        "Issue_preprocessed_content":"wonder initi studio lab titl",
        "Issue_gpt_summary_original":"The user is unable to configure their profile with AWS CLI for using AWS Built-in sagemaker algorithms. They are encountering a ValueError that requires them to set up local AWS configuration with a region supported by SageMaker. The user is unsure if it is possible to link access AWS resources in Studiolab.",
        "Issue_gpt_summary":"user unabl configur profil aw cli aw built algorithm encount valueerror requir set local aw configur region support user unsur possibl link access aw resourc studiolab",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws\/studio-lab-examples\/issues\/30",
        "Issue_title":"Can't configure profile with AWS CLI for using AWS Built-in sagemaker algorithms ",
        "Issue_created_time":1639662702000,
        "Issue_closed_time":1639666969000,
        "Issue_body":"Hi everybody,\r\n\r\nI am trying to use AWS built-in algorithms in Sagemaker Studio Lab. For that I need an execution role and region etc. \r\nWhen I try to run my code it outputs\r\n\r\nValueError: Must setup local AWS configuration with a region supported by SageMaker.\r\n\r\nIs it even possible to link access AWS resources in Studiolab?\r\n\r\nMany thanks in advance!\r\n\r\n\r\n",
        "Issue_answer_count":4,
        "Issue_self_closed":0.0,
        "Answer_body":"Hi! The use case you are describing is exactly why we have this example notebook:\r\n- https:\/\/github.com\/aws\/studio-lab-examples\/blob\/main\/connect-to-aws\/Access_AWS_from_Studio_Lab.ipynb \r\n\r\nYour net net is:\r\n1\/ Ensure you have proper training and authorization to use your AWS access and secret keys. If you are an AWS account admin, you can find this in your IAM console. If you are not, work with your admin to determine if this pattern is appropriate for you. \r\n\r\n2\/ If you are qualified to manage your AWS keys, create a new file called `~\/.aws\/credentials`. There, copy and paste in your access and secret keys.\r\n\r\n3\/ Remove any cells you ran in a notebook to create or verify those files.\r\n\r\n4\/ Create a SageMaker execution role. The easiest way to do this is via the console - you can create a new SageMaker execution role when create a notebook instance or a Studio user profile. Once this is done, paste in the arn (Amazon Resource Name), for this execution role.\r\n\r\n5\/ Go forth and scale up on SageMaker! After that,  once you are using the SageMaker Python SDK, you should be able to use all code-based features within SageMaker, such as training, hosting, tuning, autopilot, pipelines, etc.   Hi @EmilyWebber. Might you also have an example that doesn't require AWS account information yet avoids \"ValueError: Must setup local AWS configuration with a region supported by SageMaker\" in the code below for \"role\"?\r\n\r\n```\r\n# create Hugging Face Model Class\r\nhuggingface_model = HuggingFaceModel(\r\n\ttransformers_version='4.6.1',\r\n\tpytorch_version='1.7.1',\r\n\tpy_version='py36',\r\n\tenv=hub,\r\n\trole=role, \r\n)\r\n```\r\nCode source: https:\/\/huggingface.co\/distilbert-base-uncased-finetuned-sst-2-english, where Deploy is Amazon SageMaker rather than Accelerated Inference \u2014 the latter [currently returns an error](https:\/\/discuss.huggingface.co\/t\/distilbert-accelerated-inference-error\/15027) with or without SageMaker\r\n\r\nSince the SageMaker Studio Lab website emphasizes no costs and no need to sign up for an AWS account, a team and I are exploring whether to have students try. Thank you in advance. Hi @derekschan - thanks for the comment. This is actually expected behavior right now - Studio Lab defaults to not having access to any AWS API's unless explicitly granted. To date, that is solved only by the pattern mentioned above in this issue, explicitly installing AWS key permissions to utilize them. \r\n\r\nShould that ever change in the future we will be sure to let you know! I'll mark your comment as a feature enhancement.  Thank you, @EmilyWebber.",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"configur profil aw cli aw built algorithm everybodi try us aw built algorithm studio lab need execut role region try run code output valueerror setup local aw configur region support possibl link access aw resourc studiolab thank advanc",
        "Issue_preprocessed_content":"configur profil aw cli aw algorithm everybodi try us aw algorithm studio lab execut role region try run code output setup local aw configur region link aw resourc studiolab thank advanc",
        "Issue_gpt_summary_original":"The user is encountering an issue with Pytorch images where all prints in stderr are not being caught and are being ignored. The user has provided a code snippet and logs to demonstrate the issue. The stdout is being printed, but the stderr is being ignored. The issue persists even in distant mode.",
        "Issue_gpt_summary":"user encount issu pytorch imag print stderr caught ignor user provid code snippet log demonstr issu stdout print stderr ignor issu persist distant mode",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws\/sagemaker-training-toolkit\/issues\/37",
        "Issue_title":"Pytorch Sagemaker Container STDERR output",
        "Issue_created_time":1571735353000,
        "Issue_closed_time":null,
        "Issue_body":"In Pytorch images all the prints in stderr are not catched and are ignored:\r\n\r\n\r\n### Describe the problem\r\n\r\n### Minimal repro \/ logs\r\nEntrypoint.py:\r\n\r\n```\r\nif __name__ == '__main__':\r\n    import sys\r\n    sys.stderr.write('Coucou stderr')\r\n    sys.stdout.write('Coucou stdout')\r\n```\r\n\r\n```\r\nfrom sagemaker.pytorch import PyTorch\r\nestimator = PyTorch(entry_point='entrypoint.py',\r\n                    role=role,\r\n                    framework_version='1.1.0',\r\n                    train_instance_count=1,\r\n                    train_instance_type='local',\r\n                )\r\nestimator.fit({'config': 's3:\/\/sagemaker-eu-*************\/config\/test_sagemaker_1.json'})\r\n```\r\n\r\n<details><summary>LOGS<\/summary>\r\n<p>\r\n\r\nCreating tmpqp7i_4w3_algo-1-8gd7b_1 ... \r\nAttaching to tmpqp7i_4w3_algo-1-8gd7b_12mdone\r\nalgo-1-8gd7b_1  | 2019-10-22 09:06:21,345 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\r\nalgo-1-8gd7b_1  | 2019-10-22 09:06:21,349 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\r\nalgo-1-8gd7b_1  | 2019-10-22 09:06:21,363 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\r\nalgo-1-8gd7b_1  | 2019-10-22 09:06:21,365 sagemaker_pytorch_container.training INFO     Invoking user training script.\r\nalgo-1-8gd7b_1  | 2019-10-22 09:06:21,489 sagemaker-containers INFO     Module entrypoint does not provide a setup.py. \r\nalgo-1-8gd7b_1  | Generating setup.py\r\nalgo-1-8gd7b_1  | 2019-10-22 09:06:21,489 sagemaker-containers INFO     Generating setup.cfg\r\nalgo-1-8gd7b_1  | 2019-10-22 09:06:21,489 sagemaker-containers INFO     Generating MANIFEST.in\r\nalgo-1-8gd7b_1  | 2019-10-22 09:06:21,490 sagemaker-containers INFO     Installing module with the following command:\r\nalgo-1-8gd7b_1  | \/usr\/bin\/python -m pip install . \r\nalgo-1-8gd7b_1  | Processing \/opt\/ml\/code\r\nalgo-1-8gd7b_1  | Building wheels for collected packages: entrypoint\r\nalgo-1-8gd7b_1  |   Running setup.py bdist_wheel for entrypoint ... done\r\nalgo-1-8gd7b_1  |   Stored in directory: \/tmp\/pip-ephem-wheel-cache-44kbrxy0\/wheels\/35\/24\/16\/37574d11bf9bde50616c******356bc7164af8ca3\r\nalgo-1-8gd7b_1  | Successfully built entrypoint\r\nalgo-1-8gd7b_1  | Installing collected packages: entrypoint\r\nalgo-1-8gd7b_1  | Successfully installed entrypoint-1.0.0\r\nalgo-1-8gd7b_1  | You are using pip version 18.1, however version 19.3.1 is available.\r\nalgo-1-8gd7b_1  | You should consider upgrading via the 'pip install --upgrade pip' command.\r\nalgo-1-8gd7b_1  | 2019-10-22 09:06:23,054 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\r\nalgo-1-8gd7b_1  | 2019-10-22 09:06:23,069 sagemaker-containers INFO     Invoking user script\r\nalgo-1-8gd7b_1  | \r\nalgo-1-8gd7b_1  | Training Env:\r\nalgo-1-8gd7b_1  | \r\nalgo-1-8gd7b_1  | {\r\nalgo-1-8gd7b_1  |     \"additional_framework_parameters\": {},\r\nalgo-1-8gd7b_1  |     \"channel_input_dirs\": {\r\nalgo-1-8gd7b_1  |         \"config\": \"\/opt\/ml\/input\/data\/config\"\r\nalgo-1-8gd7b_1  |     },\r\nalgo-1-8gd7b_1  |     \"current_host\": \"algo-1-8gd7b\",\r\nalgo-1-8gd7b_1  |     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\r\nalgo-1-8gd7b_1  |     \"hosts\": [\r\nalgo-1-8gd7b_1  |         \"algo-1-8gd7b\"\r\nalgo-1-8gd7b_1  |     ],\r\nalgo-1-8gd7b_1  |     \"hyperparameters\": {},\r\nalgo-1-8gd7b_1  |     \"input_config_dir\": \"\/opt\/ml\/input\/config\",\r\nalgo-1-8gd7b_1  |     \"input_data_config\": {\r\nalgo-1-8gd7b_1  |         \"config\": {\r\nalgo-1-8gd7b_1  |             \"TrainingInputMode\": \"File\"\r\nalgo-1-8gd7b_1  |         }\r\nalgo-1-8gd7b_1  |     },\r\nalgo-1-8gd7b_1  |     \"input_dir\": \"\/opt\/ml\/input\",\r\nalgo-1-8gd7b_1  |     \"is_master\": true,\r\nalgo-1-8gd7b_1  |     \"job_name\": \"sagemaker-pytorch-2019-10-22-09-06-18-353\",\r\nalgo-1-8gd7b_1  |     \"log_level\": 20,\r\nalgo-1-8gd7b_1  |     \"master_hostname\": \"algo-1-8gd7b\",\r\nalgo-1-8gd7b_1  |     \"model_dir\": \"\/opt\/ml\/model\",\r\nalgo-1-8gd7b_1  |     \"module_dir\": \"s3:\/\/sagemaker-eu-west-1-*********\/sagemaker-pytorch-2019-10-22-09-06-18-353\/source\/sourcedir.tar.gz\",\r\nalgo-1-8gd7b_1  |     \"module_name\": \"entrypoint\",\r\nalgo-1-8gd7b_1  |     \"network_interface_name\": \"eth0\",\r\nalgo-1-8gd7b_1  |     \"num_cpus\": 2,\r\nalgo-1-8gd7b_1  |     \"num_gpus\": 0,\r\nalgo-1-8gd7b_1  |     \"output_data_dir\": \"\/opt\/ml\/output\/data\",\r\nalgo-1-8gd7b_1  |     \"output_dir\": \"\/opt\/ml\/output\",\r\nalgo-1-8gd7b_1  |     \"output_intermediate_dir\": \"\/opt\/ml\/output\/intermediate\",\r\nalgo-1-8gd7b_1  |     \"resource_config\": {\r\nalgo-1-8gd7b_1  |         \"current_host\": \"algo-1-8gd7b\",\r\nalgo-1-8gd7b_1  |         \"hosts\": [\r\nalgo-1-8gd7b_1  |             \"algo-1-8gd7b\"\r\nalgo-1-8gd7b_1  |         ]\r\nalgo-1-8gd7b_1  |     },\r\nalgo-1-8gd7b_1  |     \"user_entry_point\": \"entrypoint.py\"\r\nalgo-1-8gd7b_1  | }\r\nalgo-1-8gd7b_1  | \r\nalgo-1-8gd7b_1  | Environment variables:\r\nalgo-1-8gd7b_1  | \r\nalgo-1-8gd7b_1  | SM_HOSTS=[\"algo-1-8gd7b\"]\r\nalgo-1-8gd7b_1  | SM_NETWORK_INTERFACE_NAME=eth0\r\nalgo-1-8gd7b_1  | SM_HPS={}\r\nalgo-1-8gd7b_1  | SM_USER_ENTRY_POINT=entrypoint.py\r\nalgo-1-8gd7b_1  | SM_FRAMEWORK_PARAMS={}\r\nalgo-1-8gd7b_1  | SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-8gd7b\",\"hosts\":[\"algo-1-8gd7b\"]}\r\nalgo-1-8gd7b_1  | SM_INPUT_DATA_CONFIG={\"config\":{\"TrainingInputMode\":\"File\"}}\r\nalgo-1-8gd7b_1  | SM_OUTPUT_DATA_DIR=\/opt\/ml\/output\/data\r\nalgo-1-8gd7b_1  | SM_CHANNELS=[\"config\"]\r\nalgo-1-8gd7b_1  | SM_CURRENT_HOST=algo-1-8gd7b\r\nalgo-1-8gd7b_1  | SM_MODULE_NAME=entrypoint\r\nalgo-1-8gd7b_1  | SM_LOG_LEVEL=20\r\nalgo-1-8gd7b_1  | SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\r\nalgo-1-8gd7b_1  | SM_INPUT_DIR=\/opt\/ml\/input\r\nalgo-1-8gd7b_1  | SM_INPUT_CONFIG_DIR=\/opt\/ml\/input\/config\r\nalgo-1-8gd7b_1  | SM_OUTPUT_DIR=\/opt\/ml\/output\r\nalgo-1-8gd7b_1  | SM_NUM_CPUS=2\r\nalgo-1-8gd7b_1  | SM_NUM_GPUS=0\r\nalgo-1-8gd7b_1  | SM_MODEL_DIR=\/opt\/ml\/model\r\nalgo-1-8gd7b_1  | SM_MODULE_DIR=s3:\/\/sagemaker-eu-west-1-***********\/sagemaker-pytorch-2019-10-22-09-06-18-353\/source\/sourcedir.tar.gz\r\nalgo-1-8gd7b_1  | SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"config\":\"\/opt\/ml\/input\/data\/config\"},\"current_host\":\"algo-1-8gd7b\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-8gd7b\"],\"hyperparameters\":{},\"input_config_dir\":\"\/opt\/ml\/input\/config\",\"input_data_config\":{\"config\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"\/opt\/ml\/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-2019-10-22-09-06-18-353\",\"log_level\":20,\"master_hostname\":\"algo-1-8gd7b\",\"model_dir\":\"\/opt\/ml\/model\",\"module_dir\":\"s3:\/\/sagemaker-eu-west-1-**********\/sagemaker-pytorch-2019-10-22-09-06-18-353\/source\/sourcedir.tar.gz\",\"module_name\":\"entrypoint\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"\/opt\/ml\/output\/data\",\"output_dir\":\"\/opt\/ml\/output\",\"output_intermediate_dir\":\"\/opt\/ml\/output\/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-8gd7b\",\"hosts\":[\"algo-1-8gd7b\"]},\"user_entry_point\":\"entrypoint.py\"}\r\nalgo-1-8gd7b_1  | SM_USER_ARGS=[]\r\nalgo-1-8gd7b_1  | SM_OUTPUT_INTERMEDIATE_DIR=\/opt\/ml\/output\/intermediate\r\nalgo-1-8gd7b_1  | SM_CHANNEL_CONFIG=\/opt\/ml\/input\/data\/config\r\nalgo-1-8gd7b_1  | PYTHONPATH=\/usr\/local\/bin:\/usr\/lib\/python36.zip:\/usr\/lib\/python3.6:\/usr\/lib\/python3.6\/lib-dynload:\/usr\/local\/lib\/python3.6\/dist-packages:\/usr\/lib\/python3\/dist-packages\r\nalgo-1-8gd7b_1  | \r\nalgo-1-8gd7b_1  | Invoking script with the following command:\r\nalgo-1-8gd7b_1  | \r\nalgo-1-8gd7b_1  | \/usr\/bin\/python -m entrypoint\r\nalgo-1-8gd7b_1  | \r\nalgo-1-8gd7b_1  | \r\nalgo-1-8gd7b_1  | Coucou stdout2019-10-22 09:06:23,102 sagemaker-containers INFO     Reporting training SUCCESS\r\ntmpqp7i_4w3_algo-1-8gd7b_1 exited with code 0\r\nAborting on container exit...\r\n===== Job Complete =====\r\n<\/p>\r\n<\/details>\r\n\r\nAs you see the coucou stdout has been printed, stderr has been ignored. In distant mode same result.\r\n\r\n\r\n",
        "Issue_answer_count":5,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"pytorch contain stderr output pytorch imag print stderr catch ignor problem minim repro log entrypoint main import sy sy stderr write coucou stderr sy stdout write coucou stdout pytorch import pytorch estim pytorch entri point entrypoint role role framework version train instanc count train instanc type local estim fit config config test json log creat tmpqpi algo gdb attach tmpqpi algo gdb mdone algo gdb contain info import framework pytorch contain train algo gdb contain info gpu detect normal gpu instal algo gdb pytorch contain train info block host dn lookup succe algo gdb pytorch contain train info invok user train script algo gdb contain info modul entrypoint provid setup algo gdb gener setup algo gdb contain info gener setup cfg algo gdb contain info gener manifest algo gdb contain info instal modul follow command algo gdb usr bin python pip instal algo gdb process opt code algo gdb build wheel collect packag entrypoint algo gdb run setup bdist wheel entrypoint algo gdb store directori tmp pip ephem wheel cach kbrxy wheel dbfbdec bcafca algo gdb successfulli built entrypoint algo gdb instal collect packag entrypoint algo gdb successfulli instal entrypoint algo gdb pip version version avail algo gdb consid upgrad pip instal upgrad pip command algo gdb contain info gpu detect normal gpu instal algo gdb contain info invok user script algo gdb algo gdb train env algo gdb algo gdb algo gdb addit framework paramet algo gdb channel input dir algo gdb config opt input data config algo gdb algo gdb current host algo gdb algo gdb framework modul pytorch contain train main algo gdb host algo gdb algo gdb algo gdb algo gdb hyperparamet algo gdb input config dir opt input config algo gdb input data config algo gdb config algo gdb traininginputmod file algo gdb algo gdb algo gdb input dir opt input algo gdb master true algo gdb job pytorch algo gdb log level algo gdb master hostnam algo gdb algo gdb model dir opt model algo gdb modul dir west pytorch sourc sourcedir tar algo gdb modul entrypoint algo gdb network interfac eth algo gdb num cpu algo gdb num gpu algo gdb output data dir opt output data algo gdb output dir opt output algo gdb output intermedi dir opt output intermedi algo gdb resourc config algo gdb current host algo gdb algo gdb host algo gdb algo gdb algo gdb algo gdb algo gdb user entri point entrypoint algo gdb algo gdb algo gdb environ variabl algo gdb algo gdb host algo gdb algo gdb network interfac eth algo gdb hp algo gdb user entri point entrypoint algo gdb framework param algo gdb resourc config current host algo gdb host algo gdb algo gdb input data config config traininginputmod file algo gdb output data dir opt output data algo gdb channel config algo gdb current host algo gdb algo gdb modul entrypoint algo gdb log level algo gdb framework modul pytorch contain train main algo gdb input dir opt input algo gdb input config dir opt input config algo gdb output dir opt output algo gdb num cpu algo gdb num gpu algo gdb model dir opt model algo gdb modul dir west pytorch sourc sourcedir tar algo gdb train env addit framework paramet channel input dir config opt input data config current host algo gdb framework modul pytorch contain train main host algo gdb hyperparamet input config dir opt input config input data config config traininginputmod file input dir opt input master true job pytorch log level master hostnam algo gdb model dir opt model modul dir west pytorch sourc sourcedir tar modul entrypoint network interfac eth num cpu num gpu output data dir opt output data output dir opt output output intermedi dir opt output intermedi resourc config current host algo gdb host algo gdb user entri point entrypoint algo gdb user arg algo gdb output intermedi dir opt output intermedi algo gdb channel config opt input data config algo gdb pythonpath usr local bin usr lib python zip usr lib python usr lib python lib dynload usr local lib python dist packag usr lib python dist packag algo gdb algo gdb invok script follow command algo gdb algo gdb usr bin python entrypoint algo gdb algo gdb algo gdb coucou stdout contain info report train success tmpqpi algo gdb exit code abort contain exit job complet coucou stdout print stderr ignor distant mode result",
        "Issue_preprocessed_content":"pytorch contain output pytorch imag print catch ignor problem minim repro log creat contain info import framework contain info gpu detect info block host dn info invok user train script contain info modul entrypoint provid gener contain info gener contain info gener contain info modul pip build packag entrypoint entrypoint store directori built entrypoint packag entrypoint pip version version avail consid upgrad pip pip contain info gpu detect contain info invok user script train env host hyperparamet true entrypoint eth environ variabl invok script entrypoint coucou contain info report train exit code abort contain job complet detail coucou stdout print ignor distant mode result",
        "Issue_gpt_summary_original":"The renaming of `mxnet-model-server` to `multi-model-server` in the `sagemaker-inference` package version 1.5.3 is causing the entrypoint with command `serve` to fail. This issue is encountered when using the `ENTRYPOINT` with `serve` as a build arg. The error message indicates that the `multi-model-server` file cannot be found. This issue affects all versions of the toolkit and framework and both CPU and GPU.",
        "Issue_gpt_summary":"renam mxnet model server multi model server infer packag version caus entrypoint command serv fail issu encount entrypoint serv build arg error messag indic multi model server file issu affect version toolkit framework cpu gpu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws\/sagemaker-pytorch-inference-toolkit\/issues\/88",
        "Issue_title":"renaming of mxnet-model-server in sagemaker-inference package 1.5.3 causing entrypoint with command `serve` to fail",
        "Issue_created_time":1607044885000,
        "Issue_closed_time":null,
        "Issue_body":"**Describe the bug**\r\n`sagemaker-inference` recently (10\/15) released v1.5.3, which included [this commit](https:\/\/github.com\/aws\/sagemaker-inference-toolkit\/commit\/8efb1672798d747cd623e5dd2eb7919af87a1b80) updating the name of the model server artifact and command from `mxnet-model-server` to `multi-model-server`.\r\n\r\nall containers defined in this repository install `sagemaker-inference` as a dependency of this repo itself, on lines\r\n\r\n```dockerfile\r\nRUN pip install --no-cache-dir \"sagemaker-pytorch-inference<2\"\r\n```\r\n\r\nand this repo's `setup.py` has an `install_requires` which includes `sagemaker-inference>=1.3.1`. as a result, `sagemaker-inference=1.5.3` installed.\r\n\r\nso while the `Dockerfile`'s `CMD` value (which calls `mxnet-model-server` directly) will succeed, attempts to use the `ENTRYPOINT` with `serve` as a build arg will fail with message:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"\/usr\/local\/bin\/dockerd-entrypoint.py\", line 22, in <module>\r\n    serving.main()\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/sagemaker_pytorch_serving_container\/serving.py\", line 39, in main\r\n    _start_model_server()\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/retrying.py\", line 49, in wrapped_f\r\n    return Retrying(*dargs, **dkw).call(f, *args, **kw)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/retrying.py\", line 206, in call\r\n    return attempt.get(self._wrap_exception)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/retrying.py\", line 247, in get\r\n    six.reraise(self.value[0], self.value[1], self.value[2])\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/retrying.py\", line 200, in call\r\n    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/sagemaker_pytorch_serving_container\/serving.py\", line 35, in _start_model_server\r\n    model_server.start_model_server(handler_service=HANDLER_SERVICE)\r\n  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/sagemaker_inference\/model_server.py\", line 94, in start_model_server\r\n    subprocess.Popen(multi_model_server_cmd)\r\n  File \"\/opt\/conda\/lib\/python3.6\/subprocess.py\", line 709, in __init__\r\n    restore_signals, start_new_session)\r\n  File \"\/opt\/conda\/lib\/python3.6\/subprocess.py\", line 1344, in _execute_child\r\n    raise child_exception_type(errno_num, err_msg, err_filename)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'multi-model-server': 'multi-model-server'\r\n\r\n```\r\n\r\n**To reproduce**\r\n1. build any container\r\n1. mount a model and `inference.py` (e.g. `half_plus_three`) into `\/opt\/ml\/model`\r\n1. `docker run [tag name] serve`\r\n\r\n**Expected behavior**\r\ntensorflow serving serves the mounted model \/ `inference.py`\r\n\r\n**System information**\r\nA description of your system. Please provide:\r\n- **Toolkit version**: 2.0.5, but should apply to all versions\r\n- **Framework version**: 1.4, but should apply to all versions\r\n- **Python version**: 3.7\r\n- **CPU or GPU**: cpu, but should apply to both\r\n- **Custom Docker image (Y\/N)**: N",
        "Issue_answer_count":0,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"renam mxnet model server infer packag caus entrypoint command serv fail bug infer recent releas includ commit http github com aw infer toolkit commit efbdcdeddebafab updat model server artifact command mxnet model server multi model server contain defin repositori instal infer depend repo line dockerfil run pip instal cach dir pytorch infer result infer instal dockerfil cmd valu call mxnet model server directli succe attempt us entrypoint serv build arg fail messag traceback recent file usr local bin dockerd entrypoint line serv main file opt conda lib python site packag pytorch serv contain serv line main start model server file opt conda lib python site packag retri line wrap return retri darg dkw arg file opt conda lib python site packag retri line return attempt self wrap except file opt conda lib python site packag retri line rerais self valu self valu self valu file opt conda lib python site packag line rerais rais valu file opt conda lib python site packag retri line attempt attempt arg kwarg attempt number fals file opt conda lib python site packag pytorch serv contain serv line start model server model server start model server handler servic handler servic file opt conda lib python site packag infer model server line start model server subprocess popen multi model server cmd file opt conda lib python subprocess line init restor signal start new session file opt conda lib python subprocess line execut child rais child except type errno num err msg err filenam filenotfounderror errno file directori multi model server multi model server reproduc build contain mount model infer half plu opt model docker run tag serv expect behavior tensorflow serv serv mount model infer inform descript provid toolkit version appli version framework version appli version python version cpu gpu cpu appli custom docker imag",
        "Issue_preprocessed_content":"renam infer packag caus entrypoint fail bug recent releas includ updat model server artifact contain defin repositori depend repo line repo includ result valu us build arg fail reproduc build contain mount model expect behavior tensorflow serv serv mount model inform descript provid version version framework version version python version cpu gpu cpu custom docker imag",
        "Issue_gpt_summary_original":"The user has encountered a bug while importing a Sagemaker workspace. The screenshot of the workspace should highlight the \"instance type\" field, but it is not highlighted. Additionally, the \"AutoStopIdleTimeInMinutes\" field is also required. The user has provided steps to reproduce the behavior and has requested the expected behavior. The user has also provided the release version installed and additional context about the problem.",
        "Issue_gpt_summary":"user encount bug import workspac screenshot workspac highlight instanc type field highlight addition autostopidletimeinminut field requir user provid step reproduc behavior request expect behavior user provid releas version instal addit context problem",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/awslabs\/service-workbench-on-aws-cn\/issues\/70",
        "Issue_title":"[Bug] highlight incorrect field in screenshot of importing Sagemaker workspace",
        "Issue_created_time":1659604135000,
        "Issue_closed_time":1662449543000,
        "Issue_body":"**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\nshould highlight `instance type` field\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/843303\/182809305-2d25c565-18f8-4da0-ad9e-847c28cc62b0.png)\r\n\r\nthe field `AutoStopIdleTimeInMinutes` also is required.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Versions (please complete the following information):**\r\n - Release Version installed [e.g. v1.0.3]\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"Already fixed",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"bug highlight incorrect field screenshot import workspac bug clear concis descript bug highlight instanc type field imag http user imag githubusercont com ad cccb png field autostopidletimeinminut requir reproduc step reproduc behavior click scroll error expect behavior clear concis descript expect happen screenshot applic add screenshot help explain problem version complet follow inform releas version instal addit context add context problem",
        "Issue_preprocessed_content":"highlight field import workspac bug clear concis descript bug highlight field field requir reproduc step reproduc behavior click expect behavior clear concis descript expect help explain problem version releas version context context problem",
        "Issue_gpt_summary_original":"The user encountered a bug in the Hong Kong region where after manually stopping a Sagemaker workspace, the web console shows an \"UNKNOWN\" status.",
        "Issue_gpt_summary":"user encount bug hong kong region manual stop workspac web consol show unknown statu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/awslabs\/service-workbench-on-aws-cn\/issues\/45",
        "Issue_title":"[Bug] In HongKong region, After user stop sagemaker workspace manually, web console show \"UNKNOWN\" status",
        "Issue_created_time":1657604472000,
        "Issue_closed_time":1659958133000,
        "Issue_body":"**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Deploy SWB in hongkong reigon\r\n2. Create a Sagemaker workspace\r\n3. Click \"Stop\" button.\r\n5. workspace status show \"UNKNOWN\"\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"Fixed, refer [commit](https:\/\/github.com\/awslabs\/service-workbench-on-aws-cn\/commit\/cd99bd2a4f39291e3149b0abbc78ab5b3d650454)",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"bug hongkong region user stop workspac manual web consol unknown statu bug clear concis descript bug reproduc step reproduc behavior deploi swb hongkong reigon creat workspac click stop button workspac statu unknown",
        "Issue_preprocessed_content":"hongkong region user stop workspac web consol unknown statu bug clear concis descript bug reproduc step reproduc behavior deploi swb hongkong reigon creat workspac click stop workspac statu unknown",
        "Issue_gpt_summary_original":"The user has encountered a bug in Sagemaker template where the workspace environment status is not updated after it is automatically stopped due to the AutoStopIdleTimeInMinutes configuration. The expected behavior is for the workspace status to be \"STOPPED\" but it remains \"AVAILABLE\".",
        "Issue_gpt_summary":"user encount bug templat workspac environ statu updat automat stop autostopidletimeinminut configur expect behavior workspac statu stop remain avail",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/awslabs\/service-workbench-on-aws-cn\/issues\/44",
        "Issue_title":"[Bug] Sagemaker template, after auto stoped, workspace env status is not updated",
        "Issue_created_time":1657451336000,
        "Issue_closed_time":1657702977000,
        "Issue_body":"**Describe the bug**\r\nAfter Sagemaker workspace stopped automatically, workspace env status is not updated.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Set sagemaker workspace config's AutoStopIdleTimeInMinutes as 10 minutes\r\n2. Create sagemaker workspace and wait for more than 10 minutes,\r\n3. Check sagemaker notebook instances to confirm the instance status is Stopped\r\n4. Check Service Workbench workspace status, it is still \"AVAILABLE\"\r\n\r\n**Expected behavior**\r\n1. Above step 4, workspace status should be \"STOPPED\"\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Versions (please complete the following information):**\r\n - Release Version installed [e.g. v1.0.3]\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"Fixed, refer [commit](https:\/\/github.com\/awslabs\/service-workbench-on-aws-cn\/commit\/2339efe78d0f4705ef0cd6d2b1c5f06a810e6730) ",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"bug templat auto stope workspac env statu updat bug workspac stop automat workspac env statu updat reproduc step reproduc behavior set workspac config autostopidletimeinminut minut creat workspac wait minut check notebook instanc confirm instanc statu stop check servic workbench workspac statu avail expect behavior step workspac statu stop screenshot applic add screenshot help explain problem version complet follow inform releas version instal addit context add context problem",
        "Issue_preprocessed_content":"templat auto stope workspac env statu updat bug workspac workspac env statu updat reproduc step reproduc behavior set workspac config autostopidletimeinminut minut creat workspac wait minut check instanc confirm instanc statu check servic workbench workspac statu avail expect behavior step workspac statu help explain problem version releas version context context problem",
        "Issue_gpt_summary_original":"The user is requesting to add three dependencies to the Sagemaker section, which are urllib3, PyYAML, and ipython, to train a Deepracer model locally with GPU support.",
        "Issue_gpt_summary":"user request add depend section urllib pyyaml ipython train deeprac model local gpu support",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws-deepracer-community\/deepracer-core\/issues\/36",
        "Issue_title":"Sagemaker dependencies",
        "Issue_created_time":1563873801000,
        "Issue_closed_time":1564216116000,
        "Issue_body":"Hi,\r\n\r\nGood day.\r\n\r\nCould you add to the Sagemaker section?:\r\n```\r\npip install urllib3==1.24.3\r\npip install PyYAML==3.13\r\npip install ipython\r\n```\r\nFrom https:\/\/medium.com\/@jonathantse\/train-deepracer-model-locally-with-gpu-support-29cce0bdb0f9. \r\n\r\nKeep up the good work!",
        "Issue_answer_count":3,
        "Issue_self_closed":0.0,
        "Answer_body":"I know ipython used to be used because of a couple lines in the python launch file, however it's been removed. Are you able to launch it without ipython?\n\nI'll double check the other two as they should come in through other dependencies. They used to be there but threw errors because of other dependencies requiring different versions What I did was go through your steps line by line on a fresh Ubuntu 18 install. And try and run sagemaker. Might be environment specific to Ubuntu? I\u2019m not too clued up on python and pip. But for sure I had to install those to get it to run.\n\n\n________________________________\nFrom: Chris Rhodes <notifications@github.com>\nSent: Wednesday, July 24, 2019 3:42 AM\nTo: crr0004\/deepracer\nCc: jarrett jordaan; Author\nSubject: Re: [crr0004\/deepracer] Sagemaker dependencies (#36)\n\n\nI know ipython used to be used because of a couple lines in the python launch file, however it's been removed. Are you able to launch it without ipython?\n\nI'll double check the other two as they should come in through other dependencies. They used to be there but threw errors because of other dependencies requiring different versions\n\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub<https:\/\/github.com\/crr0004\/deepracer\/issues\/36?email_source=notifications&email_token=AAF52S6N33S3XYV4OLVLAR3QA6XRLA5CNFSM4IGB77KKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD2U47FQ#issuecomment-514445206>, or mute the thread<https:\/\/github.com\/notifications\/unsubscribe-auth\/AAF52S3V6KVWPFHAOM5ODA3QA6XRLANCNFSM4IGB77KA>.\n I have updated sagemaker python sdk setup.py file for the dependencies. The errors won't actually do any harm. Just some conflicting version constraints.",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"depend good dai add section pip instal urllib pip instal pyyaml pip instal ipython http medium com jonathants train deeprac model local gpu support ccebdbf good work",
        "Issue_preprocessed_content":"depend dai section work",
        "Issue_gpt_summary_original":"The user encountered an issue with SageMaker falling into an infinite silent loop when a pretrained model was not found. The issue was caused by the model being placed outside the model subfolder, resulting in an exception being caught silently and a sleep being called to retry the exact behavior. The user added logging to make it verbose but has not yet fixed the issue and plans to upload a patch.",
        "Issue_gpt_summary":"user encount issu fall infinit silent loop pretrain model issu caus model place outsid model subfold result except caught silent sleep call retri exact behavior user ad log verbos fix issu plan upload patch",
        "Issue_score_count":1
    },
    {
        "Issue_link":"https:\/\/github.com\/aws-deepracer-community\/deepracer-core\/issues\/21",
        "Issue_title":"When pretrained model is not found, sagemaker falls into an infinite silent loop",
        "Issue_created_time":1561357678000,
        "Issue_closed_time":1562359564000,
        "Issue_body":"I mistakenly put my model in pretrained folder but outside the model subfolder. In such case an exception is caught silently and then a sleep is called only to retry the exact behaviour.\r\nWhile I did not fix the issue, I added logging to make it verbose. I will try to upload a patch.",
        "Issue_answer_count":4,
        "Issue_self_closed":1.0,
        "Answer_body":"```\r\nIndex: rl_coach\/src\/markov\/s3_client.py\r\nIDEA additional info:\r\nSubsystem: com.intellij.openapi.diff.impl.patch.CharsetEP\r\n<+>UTF-8\r\n===================================================================\r\n--- rl_coach\/src\/markov\/s3_client.py\t(revision 789d7553bdfda74d10dcfbcc0c0286fdb0b5b57f)\r\n+++ rl_coach\/src\/markov\/s3_client.py\t(date 1561357411000)\r\n@@ -60,10 +60,12 @@\r\n \r\n     def download_model(self, checkpoint_dir):\r\n         s3_client = self.get_client()\r\n+        logger.info(\"Downloading pretrained model from %s\/%s %s\" % (self.bucket, self.model_checkpoints_prefix, checkpoint_dir))\r\n         filename = \"None\"\r\n         try:\r\n             filename = os.path.abspath(os.path.join(checkpoint_dir, \"checkpoint\"))\r\n             if not os.path.exists(checkpoint_dir):\r\n+                logger.info(\"Model folder %s does not exist, creating\" % filename)\r\n                 os.makedirs(checkpoint_dir)\r\n \r\n             while True:\r\n@@ -73,13 +75,17 @@\r\n                 if \"Contents\" not in response:\r\n                     # If no lock is found, try getting the checkpoint\r\n                     try:\r\n+                        key = self._get_s3_key(\"checkpoint\")\r\n+                        logger.info(\"Downloading %s\" % key)\r\n                         s3_client.download_file(Bucket=self.bucket,\r\n-                                                Key=self._get_s3_key(\"checkpoint\"),\r\n+                                                Key=key,\r\n                                                 Filename=filename)\r\n                     except Exception as e:\r\n+                        logger.info(\"Something went wrong, will retry in 2 seconds %s\" % e)\r\n                         time.sleep(2)\r\n                         continue\r\n                 else:\r\n+                    logger.info(\"Found a lock file, waiting\")\r\n                     time.sleep(2)\r\n                     continue\r\n \r\n@@ -98,6 +104,8 @@\r\n                             filename = os.path.abspath(os.path.join(checkpoint_dir,\r\n                                                                     obj[\"Key\"].replace(self.model_checkpoints_prefix,\r\n                                                                                        \"\")))\r\n+\r\n+                            logger.info(\"Downloading model file %s\" % filename)\r\n                             s3_client.download_file(Bucket=self.bucket,\r\n                                                     Key=obj[\"Key\"],\r\n                                                     Filename=filename)\r\n\r\n``` Sadly, no file upload is available in issues You can open a pull request if you like, do you need help in doing so? It's definitely an issue and I've encountered it myself. It also happens when the checkpoint file references files that don't exist. Thank you @bhannebipro , I lost track :)",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"pretrain model fall infinit silent loop mistakenli model pretrain folder outsid model subfold case except caught silent sleep call retri exact behaviour fix issu ad log verbos try upload patch",
        "Issue_preprocessed_content":"pretrain model infinit silent mistakenli model pretrain folder outsid model subfold case except caught silent retri exact behaviour fix verbos try upload patch",
        "Issue_gpt_summary_original":"The user encountered an error when trying to run a nvidia image for sagemaker. The expected result was for the GPU to be detected and training to begin, but instead, the user received a \"No module named 'tensorflow'\" error. The user's system information is Ubuntu 18.04.2 LTS.",
        "Issue_gpt_summary":"user encount error try run nvidia imag expect result gpu detect train begin instead user receiv modul name tensorflow error user inform ubuntu lt",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws-deepracer-community\/deepracer-core\/issues\/18",
        "Issue_title":"No tensorflow reported when trying to run nvidia image for sagemaker",
        "Issue_created_time":1560810377000,
        "Issue_closed_time":1564215404000,
        "Issue_body":"Steps to reproduce:\r\nI followed instructions in the readme, but instead of `docker pull nabcrr\/sagemaker-rl-tensorflow:console` I did `docker pull nabcrr\/sagemaker-rl-tensorflow:nvidia` and then tagged it as instructed. Before running `(cd rl_coach; ipython rl_deepracer_coach_robomaker.py)` I went to that file and commented out the line that Lonon mentioned in #17 \r\n\r\nExpected result:\r\nWhen running `(cd rl_coach; ipython rl_deepracer_coach_robomaker.py)` my gpu is detected and training begins\r\n\r\nActual result:\r\n```\r\nalgo-1-vrm2i_1  | ERROR: ld.so: object '\/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\r\nalgo-1-vrm2i_1  | Reporting training FAILURE\r\nalgo-1-vrm2i_1  | framework error:\r\nalgo-1-vrm2i_1  | Traceback (most recent call last):\r\nalgo-1-vrm2i_1  |   File \"\/usr\/local\/lib\/python3.6\/dist-packages\/sagemaker_containers\/_trainer.py\", line 60, in train\r\nalgo-1-vrm2i_1  |     framework = importlib.import_module(framework_name)\r\nalgo-1-vrm2i_1  |   File \"\/usr\/lib\/python3.6\/importlib\/__init__.py\", line 126, in import_module\r\nalgo-1-vrm2i_1  |     return _bootstrap._gcd_import(name[level:], package, level)\r\nalgo-1-vrm2i_1  |   File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\nalgo-1-vrm2i_1  |   File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\nalgo-1-vrm2i_1  |   File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\nalgo-1-vrm2i_1  |   File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\r\nalgo-1-vrm2i_1  |   File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\r\nalgo-1-vrm2i_1  |   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nalgo-1-vrm2i_1  |   File \"\/usr\/local\/lib\/python3.6\/dist-packages\/sagemaker_tensorflow_container\/training.py\", line 24, in <module>\r\nalgo-1-vrm2i_1  |     import tensorflow as tf\r\nalgo-1-vrm2i_1  | ModuleNotFoundError: No module named 'tensorflow'\r\nalgo-1-vrm2i_1  |\r\nalgo-1-vrm2i_1  | No module named 'tensorflow'\r\n```\r\n\r\nSystem info:\r\nUbuntu 18.04.2 LTS\r\n\r\n```\r\n$ docker run --runtime=nvidia --rm nvidia\/cuda:10.1-base nvidia-smi\r\nMon Jun 17 22:24:56 2019       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 418.56       Driver Version: 418.56       CUDA Version: 10.1     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage\/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 660M    Off  | 00000000:01:00.0 N\/A |                  N\/A |\r\n| N\/A   46C    P8    N\/A \/  N\/A |    266MiB \/  1999MiB |     N\/A      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0                    Not Supported                                       |\r\n+-----------------------------------------------------------------------------+\r\n```",
        "Issue_answer_count":2,
        "Issue_self_closed":0.0,
        "Answer_body":"Note: adding tensorflow-gpu==1.11.0 and rebuilding the image solves the issue Image has been updated for this",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"tensorflow report try run nvidia imag step reproduc follow instruct readm instead docker pull nabcrr tensorflow consol docker pull nabcrr tensorflow nvidia tag instruct run coach ipython deeprac coach robomak went file comment line lonon mention expect result run coach ipython deeprac coach robomak gpu detect train begin actual result algo vrmi error object libchangehostnam preload preload open share object file ignor algo vrmi report train failur algo vrmi framework error algo vrmi traceback recent algo vrmi file usr local lib python dist packag contain trainer line train algo vrmi framework importlib import modul framework algo vrmi file usr lib python importlib init line import modul algo vrmi return bootstrap gcd import level packag level algo vrmi file line gcd import algo vrmi file line load algo vrmi file line load unlock algo vrmi file line load unlock algo vrmi file line exec modul algo vrmi file line frame remov algo vrmi file usr local lib python dist packag tensorflow contain train line algo vrmi import tensorflow algo vrmi modulenotfounderror modul name tensorflow algo vrmi algo vrmi modul name tensorflow info ubuntu lt docker run runtim nvidia nvidia cuda base nvidia smi mon jun nvidia smi driver version cuda version gpu persist bu disp volatil uncorr ecc fan temp perf pwr usag cap memori usag gpu util comput geforc gtx mib mib default process gpu memori gpu pid type process usag support",
        "Issue_preprocessed_content":"tensorflow report try run nvidia imag step reproduc instruct readm instead instruct went file line lonon mention expect result gpu detect train begin actual result info ubuntu lt",
        "Issue_gpt_summary_original":"The user encountered a pipeline compile error while trying to run a Kubeflow\/SageMaker notebook in their workshop.",
        "Issue_gpt_summary":"user encount pipelin compil error try run kubeflow notebook workshop",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws-samples\/eks-kubeflow-workshop\/issues\/1",
        "Issue_title":"Can not compile SageMaker examples",
        "Issue_created_time":1571075742000,
        "Issue_closed_time":1586730089000,
        "Issue_body":"Trying our your Kubeflow\/SageMaker notebook in your workshop and received a pipeline compile error.  \r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/4739316\/66772250-1e628900-ee71-11e9-92f0-afceb992313a.png)\r\n",
        "Issue_answer_count":6,
        "Issue_self_closed":0.0,
        "Answer_body":"This is reported by user and the problem is kubeflow pipeline has some breaking changes on parameters but we always install latest KFP pipeline which is not compatible. \r\n\r\nShort term. use lower kfp version\r\n```\r\n!pip install https:\/\/storage.googleapis.com\/ml-pipeline\/release\/0.1.29\/kfp.tar.gz --upgrade\r\n```\r\n\r\nLong term, update examples and make sure it leverages latest features of KFP.  Will check on the [SageMaker example](https:\/\/github.com\/aws-samples\/eks-kubeflow-workshop\/blob\/01438d181f502504056eac89bfc0eb091733e9a8\/notebooks\/05_Kubeflow_Pipeline\/05_04_Pipeline_SageMaker.ipynb) and file a PR to make it leverage the latest features of KFP. And the master example of [SageMaker Kubeflow Pipeline](https:\/\/github.com\/kubeflow\/pipelines\/tree\/master\/samples\/contrib\/aws-samples\/mnist-kmeans-sagemaker), will try to use [master yaml file](https:\/\/github.com\/kubeflow\/pipelines\/tree\/master\/components\/aws\/sagemaker). After so, will try to use latest version 2.05 of kfp to make it compatible. Potential SageMaker example issues with users: [1st](https:\/\/github.com\/kubeflow\/pipelines\/issues\/1401) and [2nd](https:\/\/github.com\/kubeflow\/pipelines\/issues\/1642). But the issue description is not that informative. Will talk with users if necessary. Let's not put time on this one. I will ask SM team to fix Op issue and we can concentrate on others. Since the updated SageMaker example has been merged, let's close this issue.",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"compil exampl try kubeflow notebook workshop receiv pipelin compil error imag http user imag githubusercont com afceba png",
        "Issue_preprocessed_content":"compil exampl try kubeflow workshop receiv pipelin compil",
        "Issue_gpt_summary_original":"The user encountered an error while using PyTorch MNIST Notebook with SageMaker Studio. They had to add two commands to the notebook, but even after that, SageMaker local mode still showed some errors.",
        "Issue_gpt_summary":"user encount error pytorch mnist notebook studio add command notebook local mode show error",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws-samples\/amazon-sagemaker-examples-jp\/issues\/32",
        "Issue_title":"Error in PyTorch MNIST Notebook with SageMaker Studio ",
        "Issue_created_time":1590122594000,
        "Issue_closed_time":null,
        "Issue_body":"https:\/\/github.com\/aws-samples\/amazon-sagemaker-examples-jp\/blob\/master\/hpo_pytorch_mnist\/hpo_pytorch_mnist.ipynb\r\n\r\nNeed to add \r\n```\r\n!pip install ipywidgets\r\n!jupyter nbextension enable --py widgetsnbextension\r\n```\r\n\r\nWith the command below, SageMaker local mode still show some errors: \r\n```\r\n!pip install docker-compose\r\n```",
        "Issue_answer_count":1,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"error pytorch mnist notebook studio http github com aw sampl amazon exampl blob master hpo pytorch mnist hpo pytorch mnist ipynb need add pip instal ipywidget jupyt nbextens enabl widgetsnbextens command local mode error pip instal docker compos",
        "Issue_preprocessed_content":"pytorch mnist studio local mode",
        "Issue_gpt_summary_original":"The user encountered an error while using Autopilot Notebook with SageMaker Studio and was able to resolve it by adding `!apt-get install unzip -y` to the code.",
        "Issue_gpt_summary":"user encount error autopilot notebook studio abl resolv ad apt instal unzip code",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws-samples\/amazon-sagemaker-examples-jp\/issues\/31",
        "Issue_title":"Error in Autopilot Notebook with SageMaker Studio ",
        "Issue_created_time":1590122435000,
        "Issue_closed_time":null,
        "Issue_body":"https:\/\/github.com\/aws-samples\/amazon-sagemaker-examples-jp\/blob\/master\/autopilot\/autopilot_customer_churn.ipynb\r\n\r\nResolve by adding `!apt-get install unzip -y`\r\n",
        "Issue_answer_count":0,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"error autopilot notebook studio http github com aw sampl amazon exampl blob master autopilot autopilot custom churn ipynb resolv ad apt instal unzip",
        "Issue_preprocessed_content":"autopilot studio resolv",
        "Issue_gpt_summary_original":"The user encountered an error related to numpy in the lambda of \"createModel\" when running the pipeline from scratch in the natural deployment of the framework. This prevented the user from creating a sagemaker model for both the batch and realtime pipelines. The user tried to fix the numpy versions issue by re-creating the `sagemaker_layer` layer, but there were conflicts with other modified libraries at the time of `pip install numpy`. The user had to modify the code by adding the default AWS library that comes with numpy \"AWSLambda-Python38-SciPy1x-v29\" to stop the error. The user suggests checking if this error still exists in the new versions of the mlops-framework solution.",
        "Issue_gpt_summary":"user encount error relat numpi lambda createmodel run pipelin scratch natur deploy framework prevent user creat model batch realtim pipelin user tri fix numpi version issu creat layer layer conflict modifi librari time pip instal numpi user modifi code ad default aw librari come numpi awslambda python scipyx stop error user suggest check error exist new version mlop framework solut",
        "Issue_score_count":1
    },
    {
        "Issue_link":"https:\/\/github.com\/aws-solutions\/mlops-workload-orchestrator\/issues\/6",
        "Issue_title":"Error with sagemaker_layer in lambda \"create_sagemakermodel\"",
        "Issue_created_time":1620397656000,
        "Issue_closed_time":1620839615000,
        "Issue_body":"**Describe the bug**\r\nWhen making the natural deployment of the framework, and deploying the framework, there is an error related to numpy in the lambda of \"createModel\" when I run the pipeline from scratch. The error is:\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/21212412\/117463159-5e8ad000-af1d-11eb-9568-90380ee83ef3.png)\r\n\r\n**To Reproduce**\r\nThe only steps I took was to unfold it as it naturally comes. This bug prevented me from creating a sagemaker model for both the batch and realtime pipelines.\r\n\r\n**Expected behavior**\r\nThe ideal and expected behavior is that this error does not occur and you can create the model.\r\n\r\n**Solution to that moment**\r\nTry to fix the numpy versions issue by re-creating the `sagemaker_layer` layer, via pip installation of the libraries. However, there were conflicts with other modified libraries at the time of `pip install numpy`. For this reason, I had to choose to use the default AWS library that comes with numpy \"AWSLambda-Python38-SciPy1x-v29\". For this, I had to modify the code as follows:\r\n\r\nin deploy_actions.py \/ create_sagemaker_model - I add the layer:\r\n\"arn:aws:lambda:us-east-1:668099181075:layer:AWSLambda-Python38-SciPy1x:29\u201d\r\n\r\nWith this, I stop throwing that error at me. I think it is likely that due to library or version incompatibility issues, this error is by default in the mlops-framework solution. Please check if it still exists in the new versions.\r\n\r\n**Please complete the following information about the solution:**\r\n- [ ] Version: [e.g. v1.1.0]\r\n\r\n\r\nTo get the version of the solution, you can look at the description of the created CloudFormation stack. For example, \"(SO0136) - AWS MLOps Framework. Version v1.1.0\".\r\n\r\n- [ ] Region: [e.g. us-east-1]\r\n- [ ] Was the solution modified from the version published on this repository? No\r\n- [ ] If the answer to the previous question was yes, are the changes available on GitHub? -\r\n- [ ] Have you checked your [service quotas](https:\/\/docs.aws.amazon.com\/general\/latest\/gr\/aws_service_limits.html) for the sevices this solution uses?\r\n- [ ] Were there any errors in the CloudWatch Logs? Yes\r\n\r\n**Additional context**\r\nI am a Solution Architect of an advanced AWS partner company, and we are running a proof of concept with a real client.",
        "Issue_answer_count":4,
        "Issue_self_closed":1.0,
        "Answer_body":"Please mention if this continues to support you in correcting this error with a pull request. Also to know if it is something from my environment or if it is really a bug in the layer. Greetings to all! Hi @CthompsonCL , thank you for raising this issue. In the newly released version (v1.2.0), the createmodel lambda does not exist anymore. The model is created within a CloudFromation template. So, this issue is resolved in the new release. We will investigate\/fix the build of the sagemaker layer in the previous release.     @CthompsonCL, one more note. if you build the solution locally (i.e, custom build), the sagemaker layer must be built using an Amazon Linux image. Otherwise, you will have the reported error. Perfect! thanks for all. ",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"error layer lambda creat model bug make natur deploy framework deploi framework error relat numpi lambda createmodel run pipelin scratch error imag http user imag githubusercont com ead afd eeef png reproduc step took unfold natur come bug prevent creat model batch realtim pipelin expect behavior ideal expect behavior error occur creat model solut moment try fix numpi version issu creat layer layer pip instal librari conflict modifi librari time pip instal numpi reason choos us default aw librari come numpi awslambda python scipyx modifi code follow deploi action creat model add layer arn aw lambda east layer awslambda python scipyx stop throw error think like librari version incompat issu error default mlop framework solut check exist new version complet follow inform solut version version solut look descript creat cloudform stack exampl aw mlop framework version region east solut modifi version publish repositori answer previou question ye chang avail github check servic quota http doc aw amazon com gener latest aw servic limit html sevic solut us error cloudwatch log ye addit context solut architect advanc aw partner compani run proof concept real client",
        "Issue_preprocessed_content":"lambda bug make natur deploy framework deploi framework relat numpi lambda createmodel run pipelin scratch reproduc step unfold come bug prevent creat model batch realtim pipelin expect behavior ideal expect behavior creat model solut moment try fix numpi version layer pip librari conflict modifi librari time reason us default aw librari come numpi modifi code layer stop throw think like librari version incompat default solut check exist new version complet inform solut version version solut descript creat cloudform stack exampl aw mlop framework version region solut modifi version publish repositori answer previou question ye chang avail github check sevic solut us cloudwatch log ye context solut architect advanc aw partner compani concept real client",
        "Issue_gpt_summary_original":"The user encountered an error while using the \"sagemaker.pytorch.PyTorch\" with \"sagemaker 2.31.1\" and had to specify both \"framework_version\" and \"py_version\" to fix the issue. The error was caused by the absence of either \"framework_version\" or \"py_version\" while \"image_uri\" was also absent.",
        "Issue_gpt_summary":"user encount error pytorch pytorch specifi framework version version fix issu error caus absenc framework version version imag uri absent",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/udacity\/ML_SageMaker_Studies\/issues\/15",
        "Issue_title":"With \"sagemaker 2.31.1\", \"sagemaker.pytorch.PyTorch\" needs to specify both \"framework_version\" and \"py_version\"",
        "Issue_created_time":1619388470000,
        "Issue_closed_time":1623053107000,
        "Issue_body":"In **Moon_Classification_Solution.ipynb**, the original code below would cause an error `ValueError: framework_version or py_version was None, yet image_uri was also None. Either specify both framework_version and py_version, or specify image_uri.` So I specified `py_version='py3'`, cause the framework version only supports `py2` and `py3`, which fixed the problem. Or I guess just add `!pip install sagemaker==1.72.0` like notebooks in another [**repo**](https:\/\/github.com\/udacity\/sagemaker-deployment\/blob\/master\/Mini-Projects\/IMDB%20Sentiment%20Analysis%20-%20XGBoost%20(Batch%20Transform)%20-%20Solution.ipynb) would also solve the issue.\r\n\r\n```\r\n# import a PyTorch wrapper\r\nfrom sagemaker.pytorch import PyTorch\r\n\r\n# specify an output path\r\n# prefix is specified above\r\noutput_path = 's3:\/\/{}\/{}'.format(bucket, prefix)\r\n\r\n# instantiate a pytorch estimator\r\nestimator = PyTorch(entry_point='train.py',\r\n                    source_dir='source_solution', # this should be just \"source\" for your code\r\n                    role=role,\r\n                    framework_version='1.0',\r\n                    py_version='py3', ### <------------------------ added a line here\r\n                    train_instance_count=1,\r\n                    train_instance_type='ml.c4.xlarge',\r\n                    output_path=output_path,\r\n                    sagemaker_session=sagemaker_session,\r\n                    hyperparameters={\r\n                        'input_dim': 2,  # num of features\r\n                        'hidden_dim': 20,\r\n                        'output_dim': 1,\r\n                        'epochs': 80 # could change to higher\r\n                    })\r\n```",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"Resolved by fixing Sagemaker's version to 1.72.0.",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"pytorch pytorch need specifi framework version version moon classif solut ipynb origin code caus error valueerror framework version version imag uri specifi framework version version specifi imag uri specifi version caus framework version support fix problem guess add pip instal like notebook repo http github com udac deploy blob master mini project imdb sentiment analysi xgboost batch transform solut ipynb solv issu import pytorch wrapper pytorch import pytorch specifi output path prefix specifi output path format bucket prefix instanti pytorch estim estim pytorch entri point train sourc dir sourc solut sourc code role role framework version version ad line train instanc count train instanc type xlarg output path output path session session hyperparamet input dim num featur hidden dim output dim epoch chang higher",
        "Issue_preprocessed_content":"specifi origin code caus specifi caus framework version fix problem like solv",
        "Issue_gpt_summary_original":"The user encountered a bug in the Kubeflow pipeline Sagemaker component where if a node scales up or down, the component tries to create the same job which fails because Sagemaker does not allow the creation of the same name job. The user expected the job to resume from the previous state, but instead, it hangs or fails. The component controller should be able to detect this and resume the job from the existing state. The environment used was kfp-1.6.",
        "Issue_gpt_summary":"user encount bug kubeflow pipelin compon node scale compon tri creat job fail allow creation job user expect job resum previou state instead hang fail compon control abl detect resum job exist state environ kfp",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/kubeflow\/pipelines\/issues\/7040",
        "Issue_title":"[bug] Idempotency in kubeflow pipeline sagemaker component. ",
        "Issue_created_time":1639174458000,
        "Issue_closed_time":null,
        "Issue_body":"### What steps did you take\r\n\r\nIf node scales\/up down, the sagemaker component tries to create the same job which fails. Since sagemaker does not let create the same name job. Component controller should be able to detect this and resume the job from existing state. \r\n\r\n### What happened:\r\nthe job hangs\/fail \r\n\r\n### What did you expect to happen:\r\nI expect the job to resume from previous state. \r\n\r\n### Environment:\r\nkfp-1.6\r\n\r\n<!-- Don't delete message below to encourage users to support your issue! -->\r\nImpacted by this bug? Give it a \ud83d\udc4d. We prioritise the issues with the most \ud83d\udc4d.\r\n",
        "Issue_answer_count":4,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"bug idempot kubeflow pipelin compon step node scale compon tri creat job fail let creat job compon control abl detect resum job exist state happen job hang fail expect happen expect job resum previou state environ kfp impact bug prioritis issu",
        "Issue_preprocessed_content":"idempot kubeflow pipelin compon step node compon tri creat job fail let creat job compon abl detect resum job exist state job expect expect job resum previou state environ delet encourag user impact bug prioritis",
        "Issue_gpt_summary_original":"The user encountered a bug where their code gets stuck in an infinite loop if the SageMaker training job status is marked as 'Stopped'. The code only caters for training job status 'Completed' or 'Failed', causing an issue with unhandled use cases. The user expected the training job status 'stopped' to be catered for.",
        "Issue_gpt_summary":"user encount bug code get stuck infinit loop train job statu mark stop code cater train job statu complet fail caus issu unhandl us case user expect train job statu stop cater",
        "Issue_score_count":1
    },
    {
        "Issue_link":"https:\/\/github.com\/kubeflow\/pipelines\/issues\/6465",
        "Issue_title":"[bug] Unhandled SageMaker training job status 'stopped' causing infinite loop",
        "Issue_created_time":1630204381000,
        "Issue_closed_time":null,
        "Issue_body":"### What steps did you take\r\n\r\nCode gets stuck in infinite loop is SageMaker training job gets stopped (unhandled use case)\r\n\r\n### What happened:\r\n\r\nhttps:\/\/github.com\/kubeflow\/pipelines\/blob\/master\/components\/aws\/sagemaker\/train\/src\/sagemaker_training_component.py#L57-L66\r\n\r\nAbove code only caters for training job status `Completed` or `Failed`, so if the training job status is marked as `Stopped`, it causes an infinite loop in below code\r\n\r\nhttps:\/\/github.com\/kubeflow\/pipelines\/blob\/d9c019641ef9ebd78db60cdb78ea29b0d9933008\/components\/aws\/sagemaker\/common\/sagemaker_component.py#L197-L201\r\n\r\n### What did you expect to happen:\r\n\r\nTraining job status `stopped` to be catered for\r\n\r\n### Environment:\r\n\r\n### Anything else you would like to add:\r\n\r\n\r\n### Labels\r\n<!-- Please include labels below by uncommenting them to help us better triage issues -->\r\n\r\n<!-- \/area frontend -->\r\n<!-- \/area backend -->\r\n<!-- \/area sdk -->\r\n<!-- \/area testing -->\r\n<!-- \/area samples -->\r\n<!-- \/area components -->\r\n\r\n\r\n---\r\n\r\n<!-- Don't delete message below to encourage users to support your issue! -->\r\nImpacted by this bug? Give it a \ud83d\udc4d. We prioritise the issues with the most \ud83d\udc4d.\r\n",
        "Issue_answer_count":6,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"bug unhandl train job statu stop caus infinit loop step code get stuck infinit loop train job get stop unhandl us case happen http github com kubeflow pipelin blob master compon aw train src train compon code cater train job statu complet fail train job statu mark stop caus infinit loop code http github com kubeflow pipelin blob dcefebddbcdbeabd compon aw common compon expect happen train job statu stop cater environ like add label impact bug prioritis issu",
        "Issue_preprocessed_content":"unhandl train job statu caus infinit step code get stuck infinit train job get code cater train job statu train job statu mark caus infinit code expect train job statu cater environ like label includ label help triag area frontend area backend area sdk area test area sampl area compon delet encourag user impact bug prioritis",
        "Issue_gpt_summary_original":"The user is encountering a TypeError while trying to update an endpoint using Sagemaker Components for building Kubeflow pipelines. The error message indicates that the Sagemaker - Deploy Model() function received an unexpected keyword argument 'update_endpoint'. The user is using kfp 1.1.2 and sagemaker 2.1.0. The user expects to update the endpoint without any issue.",
        "Issue_gpt_summary":"user encount typeerror try updat endpoint compon build kubeflow pipelin error messag indic deploi model function receiv unexpect keyword argument updat endpoint user kfp user expect updat endpoint issu",
        "Issue_score_count":1
    },
    {
        "Issue_link":"https:\/\/github.com\/kubeflow\/pipelines\/issues\/4888",
        "Issue_title":"TypeError: Sagemaker - Deploy Model() got an unexpected keyword argument 'update_endpoint'",
        "Issue_created_time":1607683045000,
        "Issue_closed_time":1611093472000,
        "Issue_body":"### What steps did you take:\r\n[A clear and concise description of what the bug is.]\r\n\r\nI am use the re usable Sagemaker Components for building kubeflow pipelines.\r\n\r\nsagemaker_train_op = components.load_component_from_url('https:\/\/raw.githubusercontent.com\/kubeflow\/pipelines\/cb36f87b727df0578f4c1e3fe9c24a30bb59e5a2\/components\/aws\/sagemaker\/train\/component.yaml')\r\nsagemaker_model_op = components.load_component_from_url('https:\/\/raw.githubusercontent.com\/kubeflow\/pipelines\/cb36f87b727df0578f4c1e3fe9c24a30bb59e5a2\/components\/aws\/sagemaker\/model\/component.yaml')\r\nsagemaker_deploy_op = components.load_component_from_url('https:\/\/raw.githubusercontent.com\/kubeflow\/pipelines\/cb36f87b727df0578f4c1e3fe9c24a30bb59e5a2\/components\/aws\/sagemaker\/deploy\/component.yaml')\r\n\r\nWhen i am trying to update the endpoint that already exists \r\n\r\npiece of code i used to update the endpoint.\r\n\r\n**#deploy the pipeline\r\nprediction = sagemaker_deploy_op(\r\n        region=aws_region,\r\n        endpoint_name='Endpoint-price-prediction-model',\r\n        endpoint_config_name='EndpointConfig-price-prediction-model',\r\n        update_endpoint=True,\r\n        model_name_1 = create_model.output,\r\n        instance_type_1='ml.m5.large'\r\n    )\r\n# compiling the pipeline\r\nkfp.compiler.Compiler().compile(car_price_prediction,'car-price-pred-pipeline.zip')**\r\n\r\n\r\n### What happened:\r\nI am getting this error \r\nTypeError: Sagemaker - Deploy Model() got an unexpected keyword argument 'update_endpoint'\r\n\r\nI think while compile the pipeline kfp is throwing this error.can you suggest me or help me out in this\r\n\r\n\r\nTraceback (most recent call last):\r\n--\r\n414 | File \"pipeline.py\", line 94, in <module>\r\n415 | kfp.compiler.Compiler().compile(car_price_prediction,'car-price-pred-pipeline.zip')\r\n416 | File \"\/root\/.pyenv\/versions\/3.8.3\/lib\/python3.8\/site-packages\/kfp\/compiler\/compiler.py\", line 920, in compile\r\n417 | self._create_and_write_workflow(\r\n418 | File \"\/root\/.pyenv\/versions\/3.8.3\/lib\/python3.8\/site-packages\/kfp\/compiler\/compiler.py\", line 972, in _create_and_write_workflow\r\n419 | workflow = self._create_workflow(\r\n420 | File \"\/root\/.pyenv\/versions\/3.8.3\/lib\/python3.8\/site-packages\/kfp\/compiler\/compiler.py\", line 813, in _create_workflow\r\n421 | pipeline_func(*args_list)\r\n422 | File \"pipeline.py\", line 85, in car_price_prediction\r\n423 | prediction = sagemaker_deploy_op(\r\n424 | TypeError: Sagemaker - Deploy Model() got an unexpected keyword argument 'update_endpoint'\r\n\r\n\r\n\r\n### What did you expect to happen:\r\nto update the endpoint without any issue\r\n### Environment:\r\n<!-- Please fill in those that seem relevant. -->\r\nusing kfp 1.1.2\r\nsagemaker 2.1.0\r\n\r\nHow did you deploy Kubeflow Pipelines (KFP)?\r\n<!-- If you are not sure, here's [an introduction of all options](https:\/\/www.kubeflow.org\/docs\/pipelines\/installation\/overview\/). -->\r\n\r\nKFP version: <!-- If you are not sure, build commit shows on bottom of KFP UI left sidenav. -->\r\n\r\nKFP SDK version: <!-- Please attach the output of this shell command: $pip list | grep kfp -->\r\nkfp-1.1.2.tar.gz \r\n\r\n### Anything else you would like to add:\r\n[Miscellaneous information that will assist in solving the issue.]\r\n\r\nPlease help me out \r\n\r\n\/kind bug\r\n<!-- Please include labels by uncommenting them to help us better triage issues, choose from the following -->\r\n<!--\r\n\/\/ \/area frontend\r\n\/\/ \/area backend\r\n\/\/ \/area sdk\r\n\/\/ \/area testing\r\n\/\/ \/area engprod\r\n-->\r\n",
        "Issue_answer_count":7,
        "Issue_self_closed":0.0,
        "Answer_body":"\/assign @mameshini \r\n\/assign @PatrickXYS \r\n\r\nDo you mind taking a look? Thanks @numerology Thanks!\r\n\r\n@akartsky @RedbackThomson Can you take a look?  Hi @jchaudari, \r\nThanks for reporting the issue, we are taking a look at it. \r\n\r\nThanks,\r\nMeghna Hi @jchaudari, \r\nAre you certain you are using the latest version of the components ? The attached yaml files show that you are using version 0.3.0 of the image which is very old. This feature was added more recently in version 0.9.0 - \r\nhttps:\/\/github.com\/kubeflow\/pipelines\/blob\/master\/components\/aws\/sagemaker\/Changelog.md. \r\n\r\nCould you please try with the newer version and let us know if that fixes your issue ?\r\nThanks,\r\nMeghna Baijal If there aren't any further issues, we'll close this by the end of the week. Otherwise, let us know. \/close @akartsky: Closing this issue.\n\n<details>\n\nIn response to [this](https:\/\/github.com\/kubeflow\/pipelines\/issues\/4888#issuecomment-763167821):\n\n>\/close\n\n\nInstructions for interacting with me using PR comments are available [here](https:\/\/git.k8s.io\/community\/contributors\/guide\/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes\/test-infra](https:\/\/github.com\/kubernetes\/test-infra\/issues\/new?title=Prow%20issue:) repository.\n<\/details>",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"typeerror deploi model got unexpect keyword argument updat endpoint step clear concis descript bug us usabl compon build kubeflow pipelin train compon load compon url http raw githubusercont com kubeflow pipelin cbfbdffcefecabbea compon aw train compon yaml model compon load compon url http raw githubusercont com kubeflow pipelin cbfbdffcefecabbea compon aw model compon yaml deploi compon load compon url http raw githubusercont com kubeflow pipelin cbfbdffcefecabbea compon aw deploi compon yaml try updat endpoint exist piec code updat endpoint deploi pipelin predict deploi region aw region endpoint endpoint price predict model endpoint config endpointconfig price predict model updat endpoint true model creat model output instanc type larg compil pipelin kfp compil compil compil car price predict car price pred pipelin zip happen get error typeerror deploi model got unexpect keyword argument updat endpoint think compil pipelin kfp throw error suggest help traceback recent file pipelin line kfp compil compil compil car price predict car price pred pipelin zip file root pyenv version lib python site packag kfp compil compil line compil self creat write workflow file root pyenv version lib python site packag kfp compil compil line creat write workflow workflow self creat workflow file root pyenv version lib python site packag kfp compil compil line creat workflow pipelin func arg list file pipelin line car price predict predict deploi typeerror deploi model got unexpect keyword argument updat endpoint expect happen updat endpoint issu environ kfp deploi kubeflow pipelin kfp kfp version kfp sdk version kfp tar like add miscellan inform assist solv issu help kind bug",
        "Issue_preprocessed_content":"deploi model got unexpect keyword argument step clear concis descript bug us usabl compon build kubeflow pipelin try updat endpoint exist piec code updat endpoint deploi pipelin predict compil pipelin deploi model got unexpect keyword argument think compil pipelin kfp throw help traceback file line file line compil file line workflow file line file line predict deploi model got unexpect keyword argument expect updat endpoint environ relev kfp deploi kubeflow pipelin sure kfp version kfp sdk version like inform solv help kind bug includ label help triag area frontend area backend area sdk area test area engprod",
        "Issue_gpt_summary_original":"The user wants to create a custom model and perform batch transform in Amazon SageMaker without HPO and training jobs. They have removed HPO and training jobs but are facing issues while compiling kfp. They are getting the desired output in Kubeflow but want to see the custom model output in SageMaker without HPO and batch job. The user also requests for any open source loan data model using KF.",
        "Issue_gpt_summary":"user want creat custom model perform batch transform hpo train job remov hpo train job face issu compil kfp get desir output kubeflow want custom model output hpo batch job user request open sourc loan data model",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/kubeflow\/pipelines\/issues\/4352",
        "Issue_title":"Want to create ANY model and do batch transform in without Training in Amazon SageMaker ",
        "Issue_created_time":1597092939000,
        "Issue_closed_time":1632453568000,
        "Issue_body":"### What steps did you take: Removed the HPO and Training Jobs only creating the model and batch transforming in SageMaker \r\n[Automatically taking the HPO and Training on SageMaker facing some issue while kfp compile]\r\n\r\n### What happened: Getting output properly in Kubefow. But I want to to see custom  model (ANY) output without HPO and Model training in Sagemaker\r\n\r\n### What did you expect to happen: Without HPO and batch job in SageMaker\r\n\r\n\r\n\r\n\r\n### Anything else you would like to add:\r\nAny open source loan data model using KF would be appriciated \r\n\r\n\/kind bug\r\n<!-- Please include labels by uncommenting them to help us better triage issues, choose from the following -->\r\n<!--\/\/compile(kfp.compile ) \r\n\/\r\n",
        "Issue_answer_count":8,
        "Issue_self_closed":0.0,
        "Answer_body":"\/assign @Jeffwan @PatrickXYS \r\nlooks like aws specific SageMaker KFP should works fine as regular KFP installed on EKS.\r\n\r\n@RedbackThomson @akartsky Any idea you can share here?  Hi @swarnaditya \r\nThank you for using SageMaker Components for Kubeflow Pipelines. Could you provide more details about the issue:\r\n- are you bringing your own model? Is it uploaded to S3?\r\n- are you bringing your own container or using one of the [pre-built SageMaker algorithms](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/algos.html)?\r\n- sample reproducible code\r\n\r\nHere is a sample pipeline with only model and batch transform job - https:\/\/github.com\/kubeflow\/pipelines\/blob\/master\/components\/aws\/sagemaker\/tests\/integration_tests\/resources\/definition\/transform_job_pipeline.py\r\n\r\nand here are the sample inputs for this pipeline - https:\/\/github.com\/kubeflow\/pipelines\/blob\/master\/components\/aws\/sagemaker\/tests\/integration_tests\/resources\/config\/kmeans-mnist-batch-transform\/config.yaml#L6-L23. Note: the variables enclosed in `(( ))` are replaced at runtime by our integration tests so you will not be able to run with these inputs directly but we can help you with your use-case\r\n\r\nIn case this helps, here is a customer blog who created a pipeline with model+Hosting - https:\/\/aws.amazon.com\/blogs\/machine-learning\/cisco-uses-amazon-sagemaker-and-kubeflow-to-create-a-hybrid-machine-learning-workflow\/ This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.\n \/assign @surajkota  @RedbackThomson  This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.\n \/close\r\n\r\nsince there is no updates on the issue @surajkota: Closing this issue.\n\n<details>\n\nIn response to [this](https:\/\/github.com\/kubeflow\/pipelines\/issues\/4352#issuecomment-926312361):\n\n>\/close\n\n\nInstructions for interacting with me using PR comments are available [here](https:\/\/git.k8s.io\/community\/contributors\/guide\/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes\/test-infra](https:\/\/github.com\/kubernetes\/test-infra\/issues\/new?title=Prow%20issue:) repository.\n<\/details>",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"want creat model batch transform train step remov hpo train job creat model batch transform automat take hpo train face issu kfp compil happen get output properli kubefow want custom model output hpo model train expect happen hpo batch job like add open sourc loan data model apprici kind bug compil kfp compil",
        "Issue_preprocessed_content":"want creat model batch transform train step remov hpo train job creat model batch transform take hpo train face kfp compil output properli kubefow want custom model output hpo model train expect hpo batch job like open sourc loan data model kind bug includ label help triag",
        "Issue_gpt_summary_original":"The user encountered an error while attempting to run the Sagemaker training operator using a custom image that is not hosted on ECR. The error message stated that a valid Amazon Elastic Container Registry path of the Docker image is required. The user expected to be able to run Sagemaker training jobs using images hosted from their personal registry instead of having to push images to ECR. The user deployed Kubeflow Pipelines as part of Kubeflow deployment on AWS EKS.",
        "Issue_gpt_summary":"user encount error attempt run train oper custom imag host ecr error messag state valid amazon elast contain registri path docker imag requir user expect abl run train job imag host person registri instead have push imag ecr user deploi kubeflow pipelin kubeflow deploy aw ek",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/kubeflow\/pipelines\/issues\/3728",
        "Issue_title":"Sagemaker Training Operator throws an error if custom image is not hosted on ECR",
        "Issue_created_time":1588992332000,
        "Issue_closed_time":1589522860000,
        "Issue_body":"### What steps did you take:\r\nAttempted to run the Sagemaker training operator using a custom image that is not hosted on ECR\r\n\r\n### What happened:\r\nI got the following error:\r\n```\r\nException: Invalid training image. Please provide a valid Amazon Elastic Container Registry path of the Docker image to run.\r\n```\r\n\r\n### What did you expect to happen:\r\nOur CI\/CD pipeline is set up to push images to our own personal registry that is not hosted on ECR - ideally, I would want to run Sagemaker training jobs using images hosted from our personal registry instead of having to also push our images to ECR (much more error-prone + having to maintain two container registries ...)\r\n\r\n\r\nHow did you deploy Kubeflow Pipelines (KFP)?\r\nDeployed kubeflow piplines as part of kubeflow deployment on AWS EKS",
        "Issue_answer_count":4,
        "Issue_self_closed":0.0,
        "Answer_body":"Thank you @marwan116  for trying out the operator. Currently SageMaker has support for images hosted in ECR only. \r\nSageMaker has support for various frameworks like TensorFlow, XGBoost, PyTorch etc as well as some [in-built algorithms](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/algos.html).\r\n\r\nIf you have custom image, [here](https:\/\/docs.aws.amazon.com\/AmazonECR\/latest\/userguide\/docker-push-ecr-image.html) is the instruction to put them into ECR.\r\n  https:\/\/github.com\/kubeflow\/pipelines\/issues\/3670 @marwan116 looks like question answered, I'm going to close this issue.\r\nBut feel free to reopen with `\/reopen` comment.\r\n\r\n\/close @Bobgy: Closing this issue.\n\n<details>\n\nIn response to [this](https:\/\/github.com\/kubeflow\/pipelines\/issues\/3728#issuecomment-629047584):\n\n>@marwan116 looks like question answered, I'm going to close this issue.\r\n>But feel free to reopen with `\/reopen` comment.\r\n>\r\n>\/close\n\n\nInstructions for interacting with me using PR comments are available [here](https:\/\/git.k8s.io\/community\/contributors\/guide\/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes\/test-infra](https:\/\/github.com\/kubernetes\/test-infra\/issues\/new?title=Prow%20issue:) repository.\n<\/details>",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"train oper throw error custom imag host ecr step attempt run train oper custom imag host ecr happen got follow error except invalid train imag provid valid amazon elast contain registri path docker imag run expect happen pipelin set push imag person registri host ecr ideal want run train job imag host person registri instead have push imag ecr error prone have maintain contain registri deploi kubeflow pipelin kfp deploi kubeflow piplin kubeflow deploy aw ek",
        "Issue_preprocessed_content":"train oper throw custom imag host ecr step run train oper custom imag host ecr got expect pipelin set push imag person registri host ecr want run train job imag host person registri instead have push imag ecr deploi kubeflow pipelin deploi kubeflow piplin kubeflow deploy aw ek",
        "Issue_gpt_summary_original":"The user encountered an error while running a custom image using the sagemaker training operator. The error occurred when the user used boto3 to manually download an object from s3, resulting in an \"Unable to locate credentials\" error. Although the boto credentials were found in environment variables, they did not make their way to the boto3 client instantiated inside the custom image. The user expected the credentials to be passed to the image that the training operator is running, but it did not happen.",
        "Issue_gpt_summary":"user encount error run custom imag train oper error occur user boto manual download object result unabl locat credenti error boto credenti environ variabl wai boto client instanti insid custom imag user expect credenti pass imag train oper run happen",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/kubeflow\/pipelines\/issues\/3670",
        "Issue_title":"Sagemaker Custom Training Job Error: Unable to locate botocore.credentials",
        "Issue_created_time":1588293591000,
        "Issue_closed_time":1589303399000,
        "Issue_body":"### What steps did you take:\r\nI run a custom image using the sagemaker training operator (https:\/\/raw.githubusercontent.com\/kubeflow\/pipelines\/master\/components\/aws\/sagemaker\/train\/component.yaml) and it ran fine. I am using `kfp.aws.use_aws_secret` and the objects from s3 are being correctly copied over to the specified local channel path.\r\n\r\nThe problem arises however if inside the custom script I use boto3 to manually download an object from s3 - then I get an error: Unable to locate credentials ...  \r\n\r\n### What happened:\r\nBelow is a copy of the component's logs - notice the very first log statement says that the boto credentials are found in environment variables ... but somehow they never make their way to the boto3 client that is instantiated inside the custom image \r\n\r\n```\r\nINFO:botocore.credentials:Found credentials in environment variables.\r\nINFO:root:Submitting Training Job to SageMaker...\r\nINFO:root:Created Training Job with name: TrainingJob-20200430232331-LPHY\r\nINFO:root:Training job in SageMaker: \r\nhttps:\/\/us-west-2.console.aws.amazon.com\/sagemaker\/home?region=us-west-2#\/jobs\/TrainingJob-20200430232331-LPHY\r\nINFO:root:CloudWatch logs: \r\nhttps:\/\/us-west-2.console.aws.amazon.com\/cloudwatch\/home?region=us-west-2#logStream:group=\/aws\/sagemaker\/TrainingJobs;prefix=TrainingJob-20200430232331-LPHY;streamFilter=typeLogStreamPrefix\r\nINFO:root:Job request submitted. Waiting for completion...\r\nINFO:root:Training job is still in status: InProgress\r\nINFO:root:Training job is still in status: InProgress\r\nINFO:root:Training job is still in status: InProgress\r\nINFO:root:Training job is still in status: InProgress\r\nINFO:root:Training job is still in status: InProgress\r\nINFO:root:Training job is still in status: InProgress\r\nINFO:root:Training job is still in status: InProgress\r\nINFO:root:Training failed with the following error: AlgorithmError: Exception during training: Unable to locate credentials\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 174, in main\r\n    preprocessor_path = get_local_path(params[\"preprocessor_path\"])\r\n  File \"main.py\", line 86, in get_local_path\r\n    for s3_object in s3_bucket.objects.all():\r\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/boto3\/resources\/collection.py\", line 83, in __iter__\r\n    for page in self.pages():\r\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/boto3\/resources\/collection.py\", line 166, in pages\r\n    for page in pages:\r\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/botocore\/paginate.py\", line 255, in __iter__\r\n    response = self._make_request(current_kwargs)\r\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/botocore\/paginate.py\", line 332, in _make_request\r\n    return self._method(**current_kwargs)\r\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/botocore\/client.py\", line 316, in _api_call\r\n    return self._make_api_call(operation_name, kwargs)\r\n  File \"\/opt\/conda\/lib\/python3.7\/site-packag\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 81, in <module>\r\n    main()\r\n  File \"train.py\", line 64, in main\r\n    _utils.wait_for_training_job(client, job_name)\r\n  File \"\/app\/common\/_utils.py\", line 185, in wait_for_training_job\r\n    raise Exception('Training job failed')\r\nException: Training job failed\r\n```\r\n\r\n### What did you expect to happen:\r\nI would have expected the credentials to be passed to the image that the training operator is running but it is not the case ...\r\n\r\n### Environment:\r\nHow did you deploy Kubeflow Pipelines (KFP)?\r\nI deployed kubeflow pipelines as part of my kubeflow deployment on AWS EKS:\r\n\r\nKFP version: \r\nBuild commit: 743746b\r\n\r\nKFP SDK version:\r\n0.5.0\r\n\r\n\/kind bug\r\n<!--\r\n\/\/ \/area frontend\r\n \/area backend\r\n \/area sdk\r\n\/\/ \/area testing\r\n\/\/ \/area engprod\r\n-->\r\n",
        "Issue_answer_count":6,
        "Issue_self_closed":1.0,
        "Answer_body":"Thanks Marwan for trying out the component. \r\nI believe your script was buried inside your custom image, if so that custom image runs inside sagemaker which does not inherit the `use_aws_secret` values. So either you need to add permission to the role https:\/\/github.com\/kubeflow\/pipelines\/blob\/master\/components\/aws\/sagemaker\/train\/component.yaml#L10 or read it from AWS secret manager. \r\n\r\nWould you mind sharing your script or minimal reproducible code ?  @gautamkmr  - thank you for taking the time to respond to this issue\r\n\r\nPlease find below a very simplified version of the script I'd like to run but hopefully should be good enough to show where the issue is - please note the comments in the script\r\n```\r\nimport pathlib\r\nimport os\r\nimport boto3\r\nimport sys\r\n\r\n\r\ndef main():\r\n    try:\r\n        # Reading data that sagemaker has copied from s3\r\n        # works fine\r\n        prefix = pathlib.Path('\/opt\/ml\/')\r\n        input_path = prefix \/ 'input\/data\/train\/'\r\n\r\n        with open(input_path \/ 'test.txt', 'r') as f:\r\n            content = f.read()\r\n\r\n        assert 'hello world' in content\r\n\r\n        # the below portion is trying to read data from s3\r\n        # using boto3 but it fails\r\n        bucket_name = os.environ['AWS_BUCKET']\r\n        object_name = 'dummy_input\/test.txt'\r\n        file_name = 'test.txt'\r\n\r\n        s3 = boto3.client('s3')\r\n\r\n        # specifically the below line fails:\r\n        # botocore.exceptions.NoCredentialsError: Unable to locate credentials\r\n        s3.download_file(bucket_name, object_name, file_name)\r\n\r\n    except Exception:\r\n        sys.exit(255)\r\n```\r\n\r\nHere is the script for compiling the pipeline just in case you need it\r\n```\r\nimport kfp.compiler as compiler\r\nimport json\r\nimport os\r\nfrom kfp import components, dsl\r\nfrom kfp.aws import use_aws_secret\r\n\r\n\r\n@dsl.pipeline(\r\n    name=\"sm_kfp_example\",\r\n    description=\"sample sagemaker training job\"\r\n)\r\ndef sm_kfp_example():\r\n    bucket = os.environ.get('AWS_BUCKET')\r\n    role = os.environ.get('SAGEMAKER_ROLE_ARN')\r\n\r\n    train_channels = json.dumps([{\r\n        'ChannelName': 'train',\r\n        'DataSource': {\r\n            'S3DataSource': {\r\n                'S3Uri': f's3:\/\/{bucket}\/dummy_input\/',\r\n                'S3DataType': 'S3Prefix',\r\n                'S3DataDistributionType': 'FullyReplicated'\r\n            }\r\n        },\r\n        'ContentType': '',\r\n        'CompressionType': 'None',\r\n        'RecordWrapperType': 'None',\r\n        'InputMode': 'File'\r\n    }])\r\n\r\n    # use the sagemaker training operator defined by aws\r\n    # [a wrapper around Sagemaker CreateTrainingJob]\r\n    repo_path = 'https:\/\/raw.githubusercontent.com\/kubeflow\/pipelines'\r\n    # commit hash of current version of kfp that we are using\r\n    commit = 'master'\r\n    suffix = 'components\/aws\/sagemaker\/train\/component.yaml'\r\n    path = f'{repo_path}\/{commit}\/{suffix}'\r\n\r\n    sagemaker_train_op = components.load_component_from_url(path)\r\n    output_path = f's3:\/\/{bucket}\/output'\r\n    account_id = os.environ.get('AWS_ACCOUNT_ID')\r\n    region = os.environ.get('AWS_REGION')\r\n    image = f'{account_id}.dkr.ecr.{region}.amazonaws.com\/sm_kfp_example:latest'\r\n\r\n    _ = sagemaker_train_op(\r\n        region=region,\r\n        endpoint_url='',\r\n        image=image,\r\n        training_input_mode='File',\r\n        hyperparameters='{}',\r\n        channels=train_channels,\r\n        instance_type='ml.m5.xlarge',\r\n        instance_count='1',\r\n        volume_size='20',\r\n        max_run_time='3600',\r\n        model_artifact_path=output_path,\r\n        output_encryption_key='',\r\n        network_isolation='True',\r\n        traffic_encryption='False',\r\n        spot_instance='False',\r\n        max_wait_time='3600',\r\n        checkpoint_config='{}',\r\n        role=role,\r\n    ).apply(\r\n        use_aws_secret('aws-secret', 'AWS_ACCESS_KEY_ID', 'AWS_SECRET_ACCESS_KEY')\r\n    )\r\n\r\n\r\ndef compile(pipeline_func):\r\n    pipeline_filename = pipeline_func.__name__ + \".pipeline.tar.gz\"\r\n    compiler.Compiler().compile(pipeline_func, pipeline_filename)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    # compile the pipeline\r\n    compile(sm_kfp_example)\r\n```\r\n\r\nThe very strange thing is if I try to create the training job using the sagemaker python sdk (i.e. not using sagemaker's k8s training operator) - the script runs fine - i.e. the credentials are passed down to the container - below is the script in case you need it\r\n\r\n```\r\nimport boto3\r\nimport sagemaker\r\nfrom sagemaker.estimator import Estimator\r\nimport os\r\n\r\naws_region = os.environ['AWS_REGION']\r\nalgorithm_name = \"sm_kfp_example\"\r\ns3_bucket = os.environ['AWS_BUCKET']\r\n\r\n# use the security token service to verify the account identity\r\nclient = boto3.client('sts')\r\naccount = client.get_caller_identity()['Account']\r\n\r\n# set the sagemaker role\r\nrole = os.environ['SAGEMAKER_ROLE_ARN']\r\n\r\n# create a boto_session\r\nboto_session = boto3.session.Session(\r\n    region_name=aws_region,\r\n)\r\n\r\n# get full training image url\r\ntraining_image = f\"{account}.dkr.ecr.{aws_region}.amazonaws.com\/{algorithm_name}:latest\"\r\n\r\n\r\n# specify location on s3_bucket to output the results\r\ns3_output_location = f's3:\/\/{s3_bucket}\/output'\r\n\r\n# create a sagemaker_session\r\nsagemaker_session = sagemaker.session.Session(boto_session=boto_session)\r\n\r\n# create an estimator\r\nestimator = Estimator(\r\n    training_image,\r\n    role,\r\n    train_instance_count=1,\r\n    train_instance_type='ml.m5.xlarge',\r\n    train_volume_size=10,  # 10 GB\r\n    train_max_run=600,  # 10 minutes = 600seconds\r\n    input_mode='File',\r\n    output_path=s3_output_location,\r\n    sagemaker_session=sagemaker_session,\r\n    hyperparameters={},\r\n    base_job_name=\"sagemaker-sample\",\r\n)\r\n\r\nestimator.fit(\r\n    inputs={\r\n        'train': f's3:\/\/{s3_bucket}\/dummy_input\/'\r\n    },\r\n    logs=True\r\n)\r\n```\r\n Note, to avoid opening other Sagemaker issues, I will list out some of the pain points I have faced trying to integrate sagemaker with Kubeflow here and let me know if there are any solutions to these - excuse me for not following protocol - but if these are deemed as valid issues -I would be glad to open up the relevant issues:\r\n\r\n- I can't seem to pass an image to sagemaker_training_op that is not hosted on ECR and if the image is hosted on ECR - it has to be in the same region as that specified for sagemaker_training_op ... \r\n\r\n- Currently, the sagemaker logs are being output to cloudwatch not to kubeflow (would be much easier if they can be forwarded to kubeflow)\r\n  There has been some undocumented change to the `load_component_*` functions. It used to return a `ContainerOp`, now it returns a `TaskSpec` instead.\r\n\r\nCurrently there are 2 possible workaround:\r\n\r\n1.  use the private func `_create_container_op_from_component_and_arguments` to generate ur containerop from taskspec\r\n```py\r\nfrom kfp.dsl._component_bridge import _create_container_op_from_component_and_arguments\r\n\r\ncomponent_op = components.load_component_from_url(...)\r\ntaskspec = component_op(...)\r\ncontainerop = _create_container_op_from_component_and_arguments(\r\n  taskspec.component_ref.spec, \r\n  taskspec.arguments, \r\n  taskspec.component_ref\r\n)\r\n```\r\n\r\n2. overwrite the default `_default_container_task_constructor`\r\n```py\r\nfrom kfp.dsl._component_bridge import _create_container_op_from_component_and_arguments\r\nimport kfp.components._components as _components\r\n\r\n_components._default_container_task_constructor = _create_container_op_from_component_and_arguments\r\n\r\n# now load_component will return a containerop\r\ncontainerop = components.load_component_from_url(...)\r\n```\r\n\r\nPS: @Ark-kun this is not the first time I seen this issue\/qns - what do u think? Hi @marwan116, I was able to reproduce the failure and the root cause is that the default value for `network_isolation` parameter is set to [False in python sdk](https:\/\/github.com\/aws\/sagemaker-python-sdk\/blob\/bf48fb1219bd8ea22e78a913bfa091e544c57cc3\/src\/sagemaker\/estimator.py#L1112)  whereas in the pipeline definition you provided it is set to True, which is also the [default value](https:\/\/github.com\/kubeflow\/pipelines\/blob\/master\/components\/aws\/sagemaker\/train\/component.yaml#L73-L75) in training component\r\n\r\nCan you try set it to False and let us know if your issue has been resolved ?\r\n\r\n\r\n----\r\n\r\nHere are some clarifications based on posts on this thread: \r\n\r\n- The logs you posted in the issue initially [under whats happened section](https:\/\/github.com\/kubeflow\/pipelines\/issues\/3670#issue-610481941) (except the exception) is from the component pod and NOT from the training job itself. As you have already observed, for the training job logs you need to go to cloudwatch.\r\n  - the first log line which you see `INFO:botocore.credentials:Found credentials in environment variables.` is from boto session which is created by the component backend to call create_training_job API. It uses the credentials are from `aws-secret` that you would have created. These credentials are only used to invoke the job and are not passed to the instance in SageMaker\r\n\r\n- The SageMaker instance which runs in AWS assumes the credentials from the role ARN you provide in`SAGEMAKER_ROLE_ARN` not not from the secret\r\n\r\nLet us know if you have more questions.\r\n @surajkota  - thank you so much for taking the time to reproduce this - yes you are right it is because I had `network_isolation` set to `True` - (sorry I should have taken the time to understand what `network_isolation` does)\r\n\r\nAlso thank you for the clarifications!\r\n\r\nI saw @gautamkmr graciously took the time to open an issue concerning the logs - thank you @gautamkmr !\r\n\r\nI am closing this now as this particular issue is now resolved",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"custom train job error unabl locat botocor credenti step run custom imag train oper http raw githubusercont com kubeflow pipelin master compon aw train compon yaml ran fine kfp aw us aw secret object correctli copi specifi local channel path problem aris insid custom script us boto manual download object error unabl locat credenti happen copi compon log notic log statement sai boto credenti environ variabl wai boto client instanti insid custom imag info botocor credenti credenti environ variabl info root submit train job info root creat train job trainingjob lphy info root train job http west consol aw amazon com home region west job trainingjob lphy info root cloudwatch log http west consol aw amazon com cloudwatch home region west logstream group aw trainingjob prefix trainingjob lphy streamfilt typelogstreamprefix info root job request submit wait complet info root train job statu inprogress info root train job statu inprogress info root train job statu inprogress info root train job statu inprogress info root train job statu inprogress info root train job statu inprogress info root train job statu inprogress info root train fail follow error algorithmerror except train unabl locat credenti traceback recent file main line main preprocessor path local path param preprocessor path file main line local path object bucket object file opt conda lib python site packag boto resourc collect line iter page self page file opt conda lib python site packag boto resourc collect line page page page file opt conda lib python site packag botocor pagin line iter respons self request current kwarg file opt conda lib python site packag botocor pagin line request return self method current kwarg file opt conda lib python site packag botocor client line api return self api oper kwarg file opt conda lib python site packag traceback recent file train line main file train line main util wait train job client job file app common util line wait train job rais except train job fail except train job fail expect happen expect credenti pass imag train oper run case environ deploi kubeflow pipelin kfp deploi kubeflow pipelin kubeflow deploy aw ek kfp version build commit kfp sdk version kind bug",
        "Issue_preprocessed_content":"custom train job unabl locat step run custom imag train oper ran fine object copi specifi local path problem aris insid custom script us boto download object unabl locat credenti copi compon log notic log statement sai boto credenti environ variabl wai boto client instanti insid custom imag expect expect credenti imag train oper case environ deploi kubeflow pipelin deploi kubeflow pipelin kubeflow deploy aw ek kfp version build kfp sdk version kind bug area frontend area backend area sdk area test area engprod",
        "Issue_gpt_summary_original":"The user is encountering an error while running a Kubeflow pipeline with AWS Sagemaker. The error is related to assigning hyperparameters, specifically 'k' and 'feature_dim', which are required but not defined in the pipeline parameters. The user is seeking assistance in resolving the error.",
        "Issue_gpt_summary":"user encount error run kubeflow pipelin error relat assign hyperparamet specif featur dim requir defin pipelin paramet user seek assist resolv error",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/kubeflow\/pipelines\/issues\/1370",
        "Issue_title":"Kubeflow-pipeline running with aws sagemaker throws an error passing K-Mean and feature_dim parameters",
        "Issue_created_time":1558527534000,
        "Issue_closed_time":1563269566000,
        "Issue_body":"Hi, \r\n\r\nI have copied the git code for aws sagemaker to execute through the Kubeflow pipeline\r\n\r\nhttps:\/\/github.com\/kubeflow\/pipelines\/blob\/master\/samples\/aws-samples\/mnist-kmeans-sagemaker\/mnist-classification-pipeline.py\r\n\r\nWhile executing the kubeflow pipeline, I am getting the error of assigning the hyperparameters, although in pipeline parameters there are no such parameters define.\r\n\r\nerror:\r\n\r\nTraining failed with the following error: ClientError: No value(s) were specified for 'k', 'feature_dim' which are required hyperparameter(s) (caused by ValidationError)\r\n\r\npipeline parameters are:\r\n\r\n@dsl.pipeline(\r\n    name='MNIST Classification pipeline',\r\n    description='MNIST Classification using KMEANS in SageMaker'\r\n)\r\ndef mnist_classification(region='us-east-1',\r\n    image='174872318107.dkr.ecr.us-west-2.amazonaws.com\/kmeans:1',\r\n    dataset_path='s3:\/\/s3-sagemaker-us-east-1\/mnist_kmeans_example\/data',\r\n    instance_type='ml.c4.8xlarge',\r\n    instance_count='2',\r\n    volume_size='50',\r\n    model_output_path='s3:\/\/s3-sagemaker-us-east-1\/mnist_kmeans_example\/model',\r\n    batch_transform_input='s3:\/\/s3-sagemaker-us-east-1\/mnist_kmeans_example\/input',\r\n    batch_transform_ouput='s3:\/\/s3-sagemaker-us-east-1\/mnist_kmeans_example\/output',\r\n    role_arn=''\r\n    ):\r\n\r\nPlease let me know why this error is appeared and how should it get resolved ?\r\n\r\nRegards,\r\nVarun\r\n",
        "Issue_answer_count":13,
        "Issue_self_closed":1.0,
        "Answer_body":"Hi @Jeffwan ,\r\n\r\nneed your support on this.\r\n\r\nI am using training image \"382416733822.dkr.ecr.us-east-1.amazonaws.com\/kmeans:1\" and it is throwing an error for mising values for parameters K and feature_dim. Although we are not using these parameters anywhere in pipeline.\r\n\r\nCan you please provide the solution ?\r\n\r\nRegards,\r\nVarun em. I may delete the configuration fields in clean up. Let me double check and come back to you @vackysh  I can reproduce this issue. \r\n\r\n`HyperParameters` was removed by me in this commit\r\nhttps:\/\/github.com\/kubeflow\/pipelines\/commit\/26f2719c28a731d8925ae2ce96252be1df2562aa\r\n\r\nAdd it back will solve this problem Image has been rebuilt and it should be good now.  Hi @Jeffwan ,\r\n\r\nThanks for your response.\r\n\r\nI again executed the pipeline using image \"382416733822.dkr.ecr.us-east-1.amazonaws.com\/kmeans:1\" , but getting the same issue\r\n\r\n\"Training failed with the following error: ClientError: No value(s) were specified for 'k', 'feature_dim' which are required hyperparameter(s) (caused by ValidationError)\"\r\n\r\nThe pipeline parameters are:\r\n\r\n@dsl.pipeline(\r\nname='MNIST Classification pipeline',\r\ndescription='MNIST Classification using KMEANS in SageMaker'\r\n)\r\ndef mnist_classification(region='us-east-1',\r\nimage='382416733822.dkr.ecr.us-east-1.amazonaws.com\/kmeans:1',\r\ndataset_path='s3:\/\/s3-sagemaker-us-east-1\/mnist_kmeans_example\/data',\r\ninstance_type='ml.c4.8xlarge',\r\ninstance_count='2',\r\nvolume_size='50',\r\nmodel_output_path='s3:\/\/s3-sagemaker-us-east-1\/mnist_kmeans_example\/model',\r\nbatch_transform_input='s3:\/\/s3-sagemaker-us-east-1\/mnist_kmeans_example\/input',\r\nbatch_transform_ouput='s3:\/\/s3-sagemaker-us-east-1\/mnist_kmeans_example\/output',\r\nrole_arn=''\r\n):\r\n\r\nPlease suggest how to get through it if issue has already fixed at your end.\r\n @vackysh I think the problem is your machine already has this image. could you go to the machine and do a force pull? \r\n```\r\nseedjeffwan\/kubeflow-pipeline-aws-sm:20190501-05\r\n``` HI @Jeffwan ,\r\n\r\nI refreshed the image It is now working fine.\r\nThank you so much.\r\n\r\nRegards,\r\nVarun Hi @Jeffwan,\r\n\r\nWhere can i get the actual source code (ML code ) reading from the image seedjeffwan\/kubeflow-pipeline-aws-sm:20190501-05 (not a docker file, but actual logic for train, predction) ?\r\n\r\nI actually working on similar automation and want to analyse the source code.\r\n\r\nRegards,\r\nVarun @vackysh This is a component example for training. \r\nhttps:\/\/github.com\/kubeflow\/pipelines\/blob\/master\/components\/aws\/sagemaker\/train\/src\/train.py\r\n\r\nNot sure if your work is internal or public. It would be perfect if you can make some contribution! Feel free to ping me on Slack or shoot me an email. Hi @Jeffwan  ,\r\n\r\nThanks for information. But i am looking for the main Kmean algorithms code that is used for training the model. I couldn't find that anywhere on path.\r\n\r\nI have a requirement where Scikit SVM model to get deploy on kubeflow pipeline using aws sagemaker services and S3. So i want to have a look on source ML code that has been passed through image as an input to pipeline.\r\n\r\nRegards,\r\nVarun\r\n\r\n @vackysh Now I get your point, in the example, I am using the container images from SageMaker. I think KMEANS one is first-party models and you might don't have access to it. What I suggest you to do is bring your own training image if you have customization request. This issue is resolved. Now closing > This issue is resolved. Now closing\r\n\r\nHave you figured out a way to make it? Did you try bring your own container? ",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"kubeflow pipelin run throw error pass mean featur dim paramet copi git code execut kubeflow pipelin http github com kubeflow pipelin blob master sampl aw sampl mnist kmean mnist classif pipelin execut kubeflow pipelin get error assign hyperparamet pipelin paramet paramet defin error train fail follow error clienterror valu specifi featur dim requir hyperparamet caus validationerror pipelin paramet dsl pipelin mnist classif pipelin descript mnist classif kmean def mnist classif region east imag dkr ecr west amazonaw com kmean dataset path east mnist kmean exampl data instanc type xlarg instanc count volum size model output path east mnist kmean exampl model batch transform input east mnist kmean exampl input batch transform ouput east mnist kmean exampl output role arn let know error appear resolv regard varun",
        "Issue_preprocessed_content":"throw paramet copi git code execut kubeflow pipelin execut kubeflow pipelin hyperparamet pipelin paramet paramet defin train fail valu specifi requir hyperparamet pipelin paramet mnist pipelin descript mnist kmean def let know resolv regard varun",
        "Issue_gpt_summary_original":"The user is encountering an issue with the Sagemaker Remote Test log not being reported correctly. The CodeBuild logs show a \"Failed\" status, but the actual logs do not show a failure and terminate abruptly. The expected behavior is for the PR commit status to say \"Failed\" if the CodeBuild log says \"Failed,\" and for the CodeBuild log to print out the error instead of terminating abruptly. The issue is observed in two commits of the PR and is related to the MX 1.6 DLC image.",
        "Issue_gpt_summary":"user encount issu remot test log report correctli codebuild log fail statu actual log failur termin abruptli expect behavior commit statu fail codebuild log sai fail codebuild log print error instead termin abruptli issu observ commit relat dlc imag",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws\/deep-learning-containers\/issues\/589",
        "Issue_title":"[bug] Sagemaker Remote Test reporting issues",
        "Issue_created_time":1600043448000,
        "Issue_closed_time":1626207887000,
        "Issue_body":"Checklist\r\n- [x] I've prepended issue tag with type of change: [bug]\r\n- [ ] (If applicable) I've attached the script to reproduce the bug\r\n- [ ] (If applicable) I've documented below the DLC image\/dockerfile this relates to\r\n- [ ] (If applicable) I've documented below the tests I've run on the DLC image\r\n- [ ] I'm using an existing DLC image listed here: https:\/\/docs.aws.amazon.com\/deep-learning-containers\/latest\/devguide\/deep-learning-containers-images.html\r\n- [ ] I've built my own container based off DLC (and I've attached the code used to build my own image)\r\n\r\n*Concise Description:*\r\nSM Remote Test log doesn't get reported correctly.\r\n\r\nObserved in 2 commits of the PR: https:\/\/github.com\/aws\/deep-learning-containers\/pull\/444\r\n\r\n- https:\/\/github.com\/aws\/deep-learning-containers\/pull\/444\/commits\/5dd2de96fb6f88707a030fca111ca6585534dbb8\r\n- https:\/\/github.com\/aws\/deep-learning-containers\/pull\/444\/commits\/867d3946aabd6e30accde84337e1f76c40211730\r\n\r\n*DLC image\/dockerfile:*\r\nMX 1.6 DLC\r\n\r\n*Current behavior:*\r\nGithub shows \"pending\" status.\r\nCodeBuild logs show \"Failed\" status.\r\nHowever, actual codebuild logs doesn't bear Failure log. It terminates abruptly.\r\n\r\n```\r\n\r\n============================= test session starts ==============================\r\nplatform linux -- Python 3.8.0, pytest-5.3.5, py-1.9.0, pluggy-0.13.1\r\nrootdir: \/codebuild\/output\/src687836801\/src\/github.com\/aws\/deep-learning-containers\/test\/dlc_tests\r\nplugins: rerunfailures-9.0, forked-1.3.0, xdist-1.31.0, timeout-1.4.2\r\ngw0 I \/ gw1 I \/ gw2 I \/ gw3 I \/ gw4 I \/ gw5 I \/ gw6 I \/ gw7 I\r\ngw0 [3] \/ gw1 [3] \/ gw2 [3] \/ gw3 [3] \/ gw4 [3] \/ gw5 [3] \/ gw6 [3] \/ gw7 [3]\r\n```\r\n\r\nSM-Cloudwatch log\r\nNavigating to the appropriate SM training log shows that the job ran for 2 hours and ended successfully. It says: \r\n`mx-tr-bench-gpu-4-node-py3-867d394-2020-09-11-21-28-30\/algo-1-1599859900`\r\n```\r\n2020-09-11 23:31:37,755 sagemaker-training-toolkit INFO     Reporting training SUCCESS\r\n```\r\n\r\n*Expected behavior:*\r\n\r\n1. PR commit status should say Failed if CodeBuild log says Failed\r\n2. CodeBuild log should not abruptly hang. It should print out the error. Currently it just terminates after printing some logs post session start.\r\n\r\n*Additional context:*\r\n",
        "Issue_answer_count":3,
        "Issue_self_closed":0.0,
        "Answer_body":"@saimidu mentioned that codebuild runs have a timeout of 90min. However, \r\n- codebuild should have shown status as timed out instead of Failed\r\n- PR commit status should have been failed instead of pending.\r\nSo that's still an open issue. Depends on #444 It appears this issue has been resolved by the PR mentioned above. Closing this ticket out.",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"bug remot test report issu checklist prepend issu tag type chang bug applic attach script reproduc bug applic document dlc imag dockerfil relat applic document test run dlc imag exist dlc imag list http doc aw amazon com deep learn contain latest devguid deep learn contain imag html built contain base dlc attach code build imag concis descript remot test log report correctli observ commit http github com aw deep learn contain pull http github com aw deep learn contain pull commit dddefbfafcacadbb http github com aw deep learn contain pull commit daabdeaccdeefc dlc imag dockerfil dlc current behavior github show pend statu codebuild log fail statu actual codebuild log bear failur log termin abruptli test session start platform linux python pytest pluggi rootdir codebuild output src src github com aw deep learn contain test dlc test plugin rerunfailur fork xdist timeout cloudwatch log navig appropri train log show job ran hour end successfulli sai bench gpu node algo train toolkit info report train success expect behavior commit statu fail codebuild log sai fail codebuild log abruptli hang print error current termin print log post session start addit context",
        "Issue_preprocessed_content":"remot test report checklist prepend tag type chang script reproduc bug document dlc relat document test run dlc imag exist dlc imag list built contain base dlc concis descript remot test log report observ dlc dlc behavior github show pend statu codebuild log fail statu actual codebuild log bear failur log termin abruptli log navig train log show job ran hour end sai expect behavior statu fail codebuild log sai fail codebuild log abruptli hang print termin print log post start context",
        "Issue_gpt_summary_original":"The user is encountering an apt-get error in sagemaker-local-test builds due to an active and running apt-get process, resulting in the inability to acquire the dpkg frontend lock.",
        "Issue_gpt_summary":"user encount apt error local test build activ run apt process result inabl acquir dpkg frontend lock",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws\/deep-learning-containers\/issues\/517",
        "Issue_title":"[bug] apt-get failure in sagemaker-local-test builds",
        "Issue_created_time":1597888000000,
        "Issue_closed_time":1598551848000,
        "Issue_body":"\r\n*Description:*\r\n\r\nAn apt-get error is seen in `sagemaker-local-test` builds as below. This is because `apt-get` process is already running and in active state.\r\n\r\n```\r\nE: Could not get lock \/var\/lib\/dpkg\/lock-frontend - open (11: Resource temporarily unavailable)\r\n--\r\n294 | E: Unable to acquire the dpkg frontend lock (\/var\/lib\/dpkg\/lock-frontend), is another process using it?\r\n```\r\n\r\n\r\n\r\n\r\n",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"bug apt failur local test build descript apt error seen local test build apt process run activ state lock var lib dpkg lock frontend open resourc temporarili unavail unabl acquir dpkg frontend lock var lib dpkg lock frontend process",
        "Issue_preprocessed_content":"failur build descript build activ state",
        "Issue_gpt_summary_original":"The user is unable to train on multiple GPUs in Sagemaker Notebook Terminal using Autogluon 0.4.0 TextPredictor. The user gets an error in spawning multiprocessing. However, when the user trains on a single GPU within the same instance and setup, it trains without any problem. The user expects to train across all 4 GPUs in the p3.8xl instance with no errors.",
        "Issue_gpt_summary":"user unabl train multipl gpu notebook termin autogluon textpredictor user get error spawn multiprocess user train singl gpu instanc setup train problem user expect train gpu instanc error",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/autogluon\/autogluon\/issues\/1650",
        "Issue_title":"[BUG] Unable to train on multiple GPUs in Sagemaker Notebook Terminal",
        "Issue_created_time":1649258575000,
        "Issue_closed_time":null,
        "Issue_body":"- [ X] I have checked that this bug exists on the latest stable version of AutoGluon\r\n- [ ] and\/or I have checked that this bug exists on the latest mainline of AutoGluon via source installation\r\n\r\n**Describe the bug**\r\nAutogluon 0.4.0 TextPredictor training on p3.8xl 4-GPU instance in Sagemaker Notebook terminal, with `env.num_gpus: 4` setting.  I get an error in spawning multiprocessing.  When I train with everything the same, but only on a single GPU within the same instance and setup, it trains without a problem.\r\n\r\n**Expected behavior**\r\nTrain across all 4 GPUs in the p3.8xl instance with no errors.\r\n\r\n**To Reproduce**\r\n* SageMaker Notebook p3.8xl instance\r\n* python 3.7.12.  \r\n* pip install torch==1.10.0 autogluon.text==0.4.0 awswrangler pandas autofluon.features==0.4.0\r\n* python train.py\r\n\r\nCode:\r\nin `train.py` file\r\n```from argparse import Namespace\r\n\r\nimport pandas as pd\r\nimport awswrangler as wr\r\nfrom autogluon.text import TextPredictor\r\n\r\nargs = Namespace(\r\n    train_filename = \"s3:\/\/ccds-asin-drc\/eu\/modeling-data\/mf2_no_emb\/train\/0\/train.parquet\",\r\n)\r\n\r\nmodel_config = {\r\n    \"eval_metric\": \"accuracy\",\r\n    \"time_limit\": 60*60*3,\r\n    \"features\": ['label', 'item_name_orig']\r\n}\r\n\r\nhyperparameters = {\r\n    'model.hf_text.checkpoint_name': 'microsoft\/mdeberta-v3-base',\r\n    'optimization.top_k': 1,\r\n    'optimization.lr_decay': 0.9,\r\n    'optimization.learning_rate': 1e-4,\r\n    'env.precision': 32,\r\n    'env.per_gpu_batch_size': 4,\r\n    'env.num_gpus': 4\r\n}\r\n\r\ntrain_df = wr.s3.read_parquet(args.full_train_filename)\r\nprint(train_df.info())\r\n\r\npredictor = TextPredictor(\r\n    label='label',\r\n    eval_metric=model_config['eval_metric']\r\n)\r\n\r\npredictor.fit(\r\n    train_data=train_df[model_config['features']],\r\n    hyperparameters=hyperparameters,\r\n    time_limit=model_config['time_limit']\r\n)\r\n\r\n```\r\n\r\n**Screenshots**\r\nError:\r\n```\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"\/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.7\/multiprocessing\/spawn.py\", line 105, in spawn_main\r\n    exitcode = _main(fd)\r\n  File \"\/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.7\/multiprocessing\/spawn.py\", line 114, in _main\r\n    prepare(preparation_data)\r\n  File \"\/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.7\/multiprocessing\/spawn.py\", line 225, in prepare\r\n    _fixup_main_from_path(data['init_main_from_path'])\r\n  File \"\/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.7\/multiprocessing\/spawn.py\", line 277, in _fixup_main_from_path\r\n    run_name=\"__mp_main__\")\r\n  File \"\/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.7\/runpy.py\", line 263, in run_path\r\n    pkg_name=pkg_name, script_name=fname)\r\n  File \"\/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.7\/runpy.py\", line 96, in _run_module_code\r\n    mod_name, mod_spec, pkg_name, script_name)\r\n  File \"\/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.7\/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"\/home\/ec2-user\/SageMaker\/rubinome_labs\/lab\/202203_drc_multilingual\/train_textonly.py\", line 46, in <module>\r\n    time_limit=model_config['time_limit']\r\n  File \"\/home\/ec2-user\/myagenv\/lib\/python3.7\/site-packages\/autogluon\/text\/text_prediction\/predictor.py\", line 248, in fit\r\n    seed=seed,\r\n  File \"\/home\/ec2-user\/myagenv\/lib\/python3.7\/site-packages\/autogluon\/text\/automm\/predictor.py\", line 410, in fit\r\n    enable_progress_bar=self._enable_progress_bar,\r\n  File \"\/home\/ec2-user\/myagenv\/lib\/python3.7\/site-packages\/autogluon\/text\/automm\/predictor.py\", line 561, in _fit\r\n    ckpt_path=self._ckpt_path,  # this is to resume training that was broken accidentally\r\n  File \"\/home\/ec2-user\/myagenv\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 741, in fit\r\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\r\n  File \"\/home\/ec2-user\/myagenv\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 685, in _call_and_handle_interrupt\r\n    return trainer_fn(*args, **kwargs)\r\n  File \"\/home\/ec2-user\/myagenv\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 777, in _fit_impl\r\n    self._run(model, ckpt_path=ckpt_path)\r\n  File \"\/home\/ec2-user\/myagenv\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 1199, in _run\r\n    self._dispatch()\r\n  File \"\/home\/ec2-user\/myagenv\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 1279, in _dispatch\r\n    self.training_type_plugin.start_training(self)\r\n  File \"\/home\/ec2-user\/myagenv\/lib\/python3.7\/site-packages\/pytorch_lightning\/plugins\/training_type\/ddp_spawn.py\", line 173, in start_training\r\n    self.spawn(self.new_process, trainer, self.mp_queue, return_result=False)\r\n  File \"\/home\/ec2-user\/myagenv\/lib\/python3.7\/site-packages\/pytorch_lightning\/plugins\/training_type\/ddp_spawn.py\", line 201, in spawn\r\n    mp.spawn(self._wrapped_function, args=(function, args, kwargs, return_queue), nprocs=self.num_processes)\r\n  File \"\/home\/ec2-user\/myagenv\/lib\/python3.7\/site-packages\/torch\/multiprocessing\/spawn.py\", line 230, in spawn\r\n    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\r\n  File \"\/home\/ec2-user\/myagenv\/lib\/python3.7\/site-packages\/torch\/multiprocessing\/spawn.py\", line 179, in start_processes\r\n    process.start()\r\n  File \"\/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.7\/multiprocessing\/process.py\", line 112, in start\r\n    self._popen = self._Popen(self)\r\n  File \"\/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.7\/multiprocessing\/context.py\", line 284, in _Popen\r\n    return Popen(process_obj)\r\n  File \"\/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.7\/multiprocessing\/popen_spawn_posix.py\", line 32, in __init__\r\n    super().__init__(process_obj)\r\n  File \"\/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.7\/multiprocessing\/popen_fork.py\", line 20, in __init__\r\n    self._launch(process_obj)\r\n  File \"\/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.7\/multiprocessing\/popen_spawn_posix.py\", line 42, in _launch\r\n    prep_data = spawn.get_preparation_data(process_obj._name)\r\n  File \"\/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.7\/multiprocessing\/spawn.py\", line 143, in get_preparation_data\r\n    _check_not_importing_main()\r\n  File \"\/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.7\/multiprocessing\/spawn.py\", line 136, in _check_not_importing_main\r\n    is not going to be frozen to produce an executable.''')\r\nRuntimeError: \r\n        An attempt has been made to start a new process before the\r\n        current process has finished its bootstrapping phase.\r\n\r\n        This probably means that you are not using fork to start your\r\n        child processes and you have forgotten to use the proper idiom\r\n        in the main module:\r\n\r\n            if __name__ == '__main__':\r\n                freeze_support()\r\n                ...\r\n\r\n        The \"freeze_support()\" line can be omitted if the program\r\n        is not going to be frozen to produce an executable.\r\n```\r\n\r\n**Installed Versions**\r\nWhich version of AutoGluon are you are using?  \r\nIf you are using 0.4.0 and newer, please run the following code snippet:\r\n<details>\r\n\r\n```python\r\nINSTALLED VERSIONS\r\n------------------\r\ndate                 : 2022-04-06\r\ntime                 : 15:22:16.975165\r\npython               : 3.7.12.final.0\r\nOS                   : Linux\r\nOS-release           : 4.14.252-131.483.amzn1.x86_64\r\nVersion              : #1 SMP Mon Nov 1 20:48:11 UTC 2021\r\nmachine              : x86_64\r\nprocessor            : x86_64\r\nnum_cores            : 32\r\ncpu_ram_mb           : 245845\r\ncuda version         : 11.450.142.00\r\nnum_gpus             : 4\r\ngpu_ram_mb           : [8404, 8476, 16160, 16160]\r\navail_disk_size_mb   : 11391\r\n\r\nautogluon.common     : 0.4.0\r\nautogluon.core       : 0.4.0\r\nautogluon.features   : 0.4.0\r\nautogluon.text       : 0.4.0\r\nautogluon_contrib_nlp: None\r\nboto3                : 1.21.34\r\ndask                 : 2021.11.2\r\ndistributed          : 2021.11.2\r\nfairscale            : 0.4.6\r\nmatplotlib           : 3.5.1\r\nnptyping             : 1.4.4\r\nnumpy                : 1.21.5\r\nomegaconf            : 2.1.1\r\npandas               : 1.3.5\r\nPIL                  : 9.0.1\r\npsutil               : 5.8.0\r\npytorch_lightning    : 1.5.10\r\nray                  : None\r\nrequests             : 2.27.1\r\nscipy                : 1.7.3\r\nsentencepiece        : None\r\nskimage              : 0.19.2\r\nsklearn              : 1.0.2\r\nsmart_open           : 5.2.1\r\ntimm                 : 0.5.4\r\ntorchmetrics         : 0.7.3\r\ntqdm                 : 4.64.0\r\ntransformers         : 4.16.2\r\n```\r\n\r\n<\/details>\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "Issue_answer_count":4,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"bug unabl train multipl gpu notebook termin check bug exist latest stabl version autogluon check bug exist latest mainlin autogluon sourc instal bug autogluon textpredictor train gpu instanc notebook termin env num gpu set error spawn multiprocess train singl gpu instanc setup train problem expect behavior train gpu instanc error reproduc notebook instanc python pip instal torch autogluon text awswrangl panda autofluon featur python train code train file argpars import namespac import panda import awswrangl autogluon text import textpredictor arg namespac train filenam ccd asin drc model data emb train train parquet model config eval metric accuraci time limit featur label item orig hyperparamet model text checkpoint microsoft mdeberta base optim optim decai optim learn rate env precis env gpu batch size env num gpu train read parquet arg train filenam print train info predictor textpredictor label label eval metric model config eval metric predictor fit train data train model config featur hyperparamet hyperparamet time limit model config time limit screenshot error traceback recent file line file home user anaconda env jupytersystemenv lib python multiprocess spawn line spawn main exitcod main file home user anaconda env jupytersystemenv lib python multiprocess spawn line main prepar prepar data file home user anaconda env jupytersystemenv lib python multiprocess spawn line prepar fixup main path data init main path file home user anaconda env jupytersystemenv lib python multiprocess spawn line fixup main path run main file home user anaconda env jupytersystemenv lib python runpi line run path pkg pkg script fname file home user anaconda env jupytersystemenv lib python runpi line run modul code mod mod spec pkg script file home user anaconda env jupytersystemenv lib python runpi line run code exec code run global file home user rubinom lab lab drc multilingu train textonli line time limit model config time limit file home user myagenv lib python site packag autogluon text text predict predictor line fit seed seed file home user myagenv lib python site packag autogluon text automm predictor line fit enabl progress bar self enabl progress bar file home user myagenv lib python site packag autogluon text automm predictor line fit ckpt path self ckpt path resum train broken accident file home user myagenv lib python site packag pytorch lightn trainer trainer line fit self fit impl model train dataload val dataload datamodul ckpt path file home user myagenv lib python site packag pytorch lightn trainer trainer line handl interrupt return trainer arg kwarg file home user myagenv lib python site packag pytorch lightn trainer trainer line fit impl self run model ckpt path ckpt path file home user myagenv lib python site packag pytorch lightn trainer trainer line run self dispatch file home user myagenv lib python site packag pytorch lightn trainer trainer line dispatch self train type plugin start train self file home user myagenv lib python site packag pytorch lightn plugin train type ddp spawn line start train self spawn self new process trainer self queue return result fals file home user myagenv lib python site packag pytorch lightn plugin train type ddp spawn line spawn spawn self wrap function arg function arg kwarg return queue nproc self num process file home user myagenv lib python site packag torch multiprocess spawn line spawn return start process arg nproc join daemon start method spawn file home user myagenv lib python site packag torch multiprocess spawn line start process process start file home user anaconda env jupytersystemenv lib python multiprocess process line start self popen self popen self file home user anaconda env jupytersystemenv lib python multiprocess context line popen return popen process obj file home user anaconda env jupytersystemenv lib python multiprocess popen spawn posix line init super init process obj file home user anaconda env jupytersystemenv lib python multiprocess popen fork line init self launch process obj file home user anaconda env jupytersystemenv lib python multiprocess popen spawn posix line launch prep data spawn prepar data process obj file home user anaconda env jupytersystemenv lib python multiprocess spawn line prepar data check import main file home user anaconda env jupytersystemenv lib python multiprocess spawn line check import main go frozen produc execut runtimeerror attempt start new process current process finish bootstrap phase probabl mean fork start child process forgotten us proper idiom main modul main freez support freez support line omit program go frozen produc execut instal version version autogluon newer run follow code snippet python instal version date time python final linux releas amzn version smp mon nov utc machin processor num core cpu ram cuda version num gpu gpu ram avail disk size autogluon common autogluon core autogluon featur autogluon text autogluon contrib nlp boto dask distribut fairscal matplotlib nptype numpi omegaconf panda pil psutil pytorch lightn rai request scipi sentencepiec skimag sklearn smart open timm torchmetr tqdm transform addit context add context problem",
        "Issue_preprocessed_content":"unabl train multipl gpu termin check bug exist latest stabl version autogluon check bug exist latest mainlin autogluon sourc bug autogluon textpredictor train instanc termin spawn train singl gpu instanc setup train problem expect behavior train gpu instanc reproduc instanc python pip awswrangl panda python code file version version autogluon newer run code detail detail context context problem",
        "Issue_gpt_summary_original":"The user is encountering an issue where the SageMaker endpoint is unable to find or open the model file, resulting in a server error. The user suspects that this may be related to the transition from MXNet to Pytorch and the way their artifacts are stored. The user is attempting to adapt the example model trained in the Multi-Modal documentation to deploy a multi-modal model and pass image paths to the SageMaker endpoint. The user is using AutoGluon version 0.4.0.",
        "Issue_gpt_summary":"user encount issu endpoint unabl open model file result server error user suspect relat transit mxnet pytorch wai artifact store user attempt adapt exampl model train multi modal document deploi multi modal model pass imag path endpoint user autogluon version",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/autogluon\/autogluon\/issues\/1644",
        "Issue_title":"[BUG] SageMaker endpoint appears unable to load model file \/ use image paths as features",
        "Issue_created_time":1648949150000,
        "Issue_closed_time":null,
        "Issue_body":"- [x] I have checked that this bug exists on the latest stable version of AutoGluon\r\n- [ ] and\/or I have checked that this bug exists on the latest mainline of AutoGluon via source installation\r\n\r\n**Describe the bug**\r\n```python\r\n...\r\nModelError: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from primary with message \"[Errno 2] No such file or directory: '\/.sagemaker\/mms\/models\/model\/predictor.pkl'\r\n...\r\nFileNotFoundError: [Errno 2] No such file or directory: '\/.sagemaker\/mms\/models\/model\/predictor.pkl'\r\n```\r\n\r\nIt appears that the SageMaker endpoint isn't able to find \/ open the model file. I was able to use the example code in the tutorial [Deploying AutoGluon Models with AWS SageMaker](https:\/\/auto.gluon.ai\/stable\/tutorials\/cloud_fit_deploy\/cloud-aws-sagemaker-deployment.html) and managed to deploy an endpoint to SageMaker. But I get this error when I go to make predictions with test data. I wonder if this might be related to transition from MXNet to Pytorch and how their artifacts are typically stored? I'm using `v0.4.0` but the predictor object is `sagemaker.mxnet.model.MXNetPredictor`. This discrepancy in framework seems supported be a related error that I found in a GitHub issue [here](https:\/\/github.com\/aws\/amazon-sagemaker-examples\/issues\/1238).\r\n\r\nNote also that I am attempting to adapt the example model trained in the [Multi-Modal documentation](https:\/\/auto.gluon.ai\/stable\/tutorials\/tabular_prediction\/tabular-multimodal.html) (i.e., using the PetFinder dataset), because I'm ultimately try to deploy a multi-modal model and figure out how to pass image_paths to the SageMaker endpoint. \r\n\r\nHere's the full traceback:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nModelError                                Traceback (most recent call last)\r\n<ipython-input-51-abf97eb84e0a> in <module>\r\n----> 1 predictions = predictor.predict(test_data[:1].values)\r\n\r\n~\/anaconda3\/envs\/betterbin\/lib\/python3.8\/site-packages\/sagemaker\/predictor.py in predict(self, data, initial_args, target_model, target_variant, inference_id)\r\n    159             data, initial_args, target_model, target_variant, inference_id\r\n    160         )\r\n--> 161         response = self.sagemaker_session.sagemaker_runtime_client.invoke_endpoint(**request_args)\r\n    162         return self._handle_response(response)\r\n    163 \r\n\r\n~\/anaconda3\/envs\/betterbin\/lib\/python3.8\/site-packages\/botocore\/client.py in _api_call(self, *args, **kwargs)\r\n    389                     \"%s() only accepts keyword arguments.\" % py_operation_name)\r\n    390             # The \"self\" in this scope is referring to the BaseClient.\r\n--> 391             return self._make_api_call(operation_name, kwargs)\r\n    392 \r\n    393         _api_call.__name__ = str(py_operation_name)\r\n\r\n~\/anaconda3\/envs\/betterbin\/lib\/python3.8\/site-packages\/botocore\/client.py in _make_api_call(self, operation_name, api_params)\r\n    717             error_code = parsed_response.get(\"Error\", {}).get(\"Code\")\r\n    718             error_class = self.exceptions.from_code(error_code)\r\n--> 719             raise error_class(parsed_response, operation_name)\r\n    720         else:\r\n    721             return parsed_response\r\n\r\nModelError: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from primary with message \"[Errno 2] No such file or directory: '\/.sagemaker\/mms\/models\/model\/predictor.pkl'\r\nTraceback (most recent call last):\r\n  File \"\/usr\/local\/lib\/python3.8\/dist-packages\/sagemaker_inference\/transformer.py\", line 110, in transform\r\n    self.validate_and_initialize(model_dir=model_dir)\r\n  File \"\/usr\/local\/lib\/python3.8\/dist-packages\/sagemaker_inference\/transformer.py\", line 158, in validate_and_initialize\r\n    self._model = self._model_fn(model_dir)\r\n  File \"\/opt\/ml\/model\/code\/tabular_serve.py\", line 11, in model_fn\r\n    model = TabularPredictor.load(model_dir)\r\n  File \"\/usr\/local\/lib\/python3.8\/dist-packages\/autogluon\/tabular\/predictor\/predictor.py\", line 2816, in load\r\n    predictor = cls._load(path=path)\r\n  File \"\/usr\/local\/lib\/python3.8\/dist-packages\/autogluon\/tabular\/predictor\/predictor.py\", line 2772, in _load\r\n    predictor: TabularPredictor = load_pkl.load(path=path + cls.predictor_file_name)\r\n  File \"\/usr\/local\/lib\/python3.8\/dist-packages\/autogluon\/common\/loaders\/load_pkl.py\", line 37, in load\r\n    with compression_fn_map[compression_fn]['open'](validated_path, 'rb', **compression_fn_kwargs) as fin:\r\nFileNotFoundError: [Errno 2] No such file or directory: '\/.sagemaker\/mms\/models\/model\/predictor.pkl'\r\n```\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**To Reproduce**\r\n\r\n1. Train a multi modal model, using code adapted from [Multimodal Data Tables: Tabular, Text, and Image Tutorial](https:\/\/auto.gluon.ai\/stable\/tutorials\/tabular_prediction\/tabular-multimodal.html): [petfinder_train.py](https:\/\/gist.github.com\/ijmiller2\/f5837977077674fe741fee031d2bad2a)\r\n2. Deploy the pet finder model: [petfinder_deploy.py](https:\/\/gist.github.com\/ijmiller2\/f6b21c2b0b40211161d1fb0252542189)\r\n\r\n**Screenshots**\r\nNA\r\n\r\n**Installed Versions**\r\nWhich version of AutoGluon are you are using?  \r\n`0.4.0`\r\n<details>\r\n\r\n```python\r\n# Replace this code with the output of the following:\r\nINSTALLED VERSIONS\r\n------------------\r\ndate                 : 2022-04-02\r\ntime                 : 19:45:52.692253\r\npython               : 3.9.7.final.0\r\nOS                   : Linux\r\nOS-release           : 5.4.0-66-generic\r\nVersion              : #74~18.04.2-Ubuntu SMP Fri Feb 5 11:17:31 UTC 2021\r\nmachine              : x86_64\r\nprocessor            : x86_64\r\nnum_cores            : 12\r\ncpu_ram_mb           : 64324\r\ncuda version         : None\r\nnum_gpus             : 0\r\ngpu_ram_mb           : []\r\navail_disk_size_mb   : 289302\r\n\r\nautogluon.common     : 0.4.0\r\nautogluon.core       : 0.4.0\r\nautogluon.features   : 0.4.0\r\nautogluon.tabular    : 0.4.0\r\nautogluon.text       : 0.4.0\r\nautogluon.vision     : 0.4.0\r\nautogluon_contrib_nlp: None\r\nboto3                : 1.21.21\r\ncatboost             : 1.0.4\r\ndask                 : 2021.11.2\r\ndistributed          : 2021.11.2\r\nfairscale            : 0.4.6\r\nfastai               : 2.5.3\r\ngluoncv              : 0.11.0\r\nlightgbm             : 3.3.2\r\nmatplotlib           : 3.5.1\r\nnetworkx             : 2.7.1\r\nnptyping             : 1.4.4\r\nnumpy                : 1.22.3\r\nomegaconf            : 2.1.1\r\npandas               : 1.3.5\r\nPIL                  : 9.0.1\r\npsutil               : 5.8.0\r\npytorch_lightning    : 1.5.10\r\nray                  : 1.8.0\r\nrequests             : 2.27.1\r\nscipy                : 1.7.3\r\nsentencepiece        : None\r\nskimage              : 0.19.2\r\nsklearn              : 1.0.2\r\nsmart_open           : 5.2.1\r\ntimm                 : 0.5.4\r\ntorch                : 1.10.1+cpu\r\ntorchmetrics         : 0.7.2\r\ntqdm                 : 4.63.0\r\ntransformers         : 4.16.2\r\nxgboost              : 1.4.2\r\n```\r\n\r\n<\/details>\r\n\r\n**Additional context**\r\n\r\nI am attempting to follow the [tutorial to deploy a model via Sagemaker](https:\/\/auto.gluon.ai\/stable\/tutorials\/cloud_fit_deploy\/cloud-aws-sagemaker-deployment.html), however, adapting to use the example model trained in the [Multi-Modal documentation](https:\/\/auto.gluon.ai\/stable\/tutorials\/tabular_prediction\/tabular-multimodal.html) (i.e., using the PetFinder dataset).\r\n",
        "Issue_answer_count":3,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"bug endpoint appear unabl load model file us imag path featur check bug exist latest stabl version autogluon check bug exist latest mainlin autogluon sourc instal bug python modelerror error occur modelerror call invokeendpoint oper receiv server error primari messag errno file directori mm model model predictor pkl filenotfounderror errno file directori mm model model predictor pkl appear endpoint isn abl open model file abl us exampl code tutori deploi autogluon model http auto gluon stabl tutori cloud fit deploi cloud aw deploy html manag deploi endpoint error predict test data wonder relat transit mxnet pytorch artifact typic store predictor object mxnet model mxnetpredictor discrep framework support relat error github issu http github com aw amazon exampl issu note attempt adapt exampl model train multi modal document http auto gluon stabl tutori tabular predict tabular multimod html petfind dataset ultim try deploi multi modal model figur pass imag path endpoint traceback modelerror traceback recent predict predictor predict test data valu anaconda env betterbin lib python site packag predictor predict self data initi arg target model target variant infer data initi arg target model target variant infer respons self session runtim client invok endpoint request arg return self handl respons respons anaconda env betterbin lib python site packag botocor client api self arg kwarg accept keyword argument oper self scope refer basecli return self api oper kwarg api str oper anaconda env betterbin lib python site packag botocor client api self oper api param error code pars respons error code error class self except code error code rais error class pars respons oper return pars respons modelerror error occur modelerror call invokeendpoint oper receiv server error primari messag errno file directori mm model model predictor pkl traceback recent file usr local lib python dist packag infer transform line transform self valid initi model dir model dir file usr local lib python dist packag infer transform line valid initi self model self model model dir file opt model code tabular serv line model model tabularpredictor load model dir file usr local lib python dist packag autogluon tabular predictor predictor line load predictor cl load path path file usr local lib python dist packag autogluon tabular predictor predictor line load predictor tabularpredictor load pkl load path path cl predictor file file usr local lib python dist packag autogluon common loader load pkl line load compress map compress open valid path compress kwarg fin filenotfounderror errno file directori mm model model predictor pkl expect behavior clear concis descript expect happen reproduc train multi modal model code adapt multimod data tabl tabular text imag tutori http auto gluon stabl tutori tabular predict tabular multimod html petfind train http gist github com ijmil ffefeedbada deploi pet finder model petfind deploi http gist github com ijmil fbcbbdfb screenshot instal version version autogluon python replac code output follow instal version date time python final linux releas gener version ubuntu smp fri feb utc machin processor num core cpu ram cuda version num gpu gpu ram avail disk size autogluon common autogluon core autogluon featur autogluon tabular autogluon text autogluon vision autogluon contrib nlp boto catboost dask distribut fairscal fastai gluoncv lightgbm matplotlib networkx nptype numpi omegaconf panda pil psutil pytorch lightn rai request scipi sentencepiec skimag sklearn smart open timm torch cpu torchmetr tqdm transform xgboost addit context attempt follow tutori deploi model http auto gluon stabl tutori cloud fit deploi cloud aw deploy html adapt us exampl model train multi modal document http auto gluon stabl tutori tabular predict tabular multimod html petfind dataset",
        "Issue_preprocessed_content":"endpoint unabl load model file us imag path featur check bug exist latest stabl version autogluon check bug exist latest mainlin autogluon sourc bug endpoint isn abl open model file abl us exampl code tutori manag deploi endpoint predict test data wonder relat transit mxnet pytorch artifact store predictor object discrep framework relat github note adapt exampl model train ultim try deploi model figur endpoint traceback expect behavior clear concis descript expect reproduc train multi modal model code adapt deploi pet finder model version version autogluon detail detail context adapt us exampl model train",
        "Issue_gpt_summary_original":"The user is facing difficulty in installing pygraphviz to make plot_ensemble_model() work in jupyter based environments. They have tried installing python3-dev, graphviz, libgraphviz-dev, pkg-config, and pygraphviz, but without success.",
        "Issue_gpt_summary":"user face difficulti instal pygraphviz plot ensembl model work jupyt base environ tri instal python dev graphviz libgraphviz dev pkg config pygraphviz success",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/autogluon\/autogluon\/issues\/1551",
        "Issue_title":"How to make plot_ensemble_model() work in sagemaker (or any jupyter based env)",
        "Issue_created_time":1645398079000,
        "Issue_closed_time":null,
        "Issue_body":"Has anyone figured out an easy way to make plot_ensemble_model() work in jupyter based environments? I'm having a lot of difficulty installing pygraphviz (think it might be related to pygraphviz not able to see where graphviz is being installed? but not sure)\r\n\r\nI've tried the following code without success: \r\n%pip install python3-dev\r\n%pip install graphviz\r\n%pip install libgraphviz-dev\r\n%pip install pkg-config\r\n\r\n%pip install pygraphviz\r\n\r\n\r\nThanks for the help!",
        "Issue_answer_count":3,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"plot ensembl model work jupyt base env figur easi wai plot ensembl model work jupyt base environ have lot difficulti instal pygraphviz think relat pygraphviz abl graphviz instal sure tri follow code success pip instal python dev pip instal graphviz pip instal libgraphviz dev pip instal pkg config pip instal pygraphviz thank help",
        "Issue_preprocessed_content":"work figur easi wai work jupyt base environ have lot pygraphviz tri code pip pip graphviz pip pip pip pygraphviz thank help",
        "Issue_gpt_summary_original":"the user encountered an importerror and attributeerror when trying to use autogluon's tabularprediction module in a notebook instance with a conda python 3 kernel.",
        "Issue_gpt_summary":"user encount importerror attributeerror try us autogluon tabularpredict modul notebook instanc conda python kernel",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/autogluon\/autogluon\/issues\/268",
        "Issue_title":"ImportError for TabularPrediction in SageMaker Notebook Instance",
        "Issue_created_time":1580947939000,
        "Issue_closed_time":1613263024000,
        "Issue_body":"I got **ImportError** when trying to use AutoGluon in a SageMaker instance (ml.c5d.4xlarge), with kernel being **conda_python3**.\r\n\r\nThe error I got is:\r\n```\r\nfrom autogluon import TabularPrediction as task\r\n```\r\n```\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-3-6f7d1b4fed2f> in <module>()\r\n----> 1 from autogluon import TabularPrediction as task\r\n\r\nImportError: cannot import name 'TabularPrediction'\r\n```\r\n\r\nIf I try\r\n```\r\nimport autogluon as ag\r\nag.TabularPrediction.Dataset(file_path='data\/nbc_golf_model_1_training.csv')\r\n```\r\n```\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-4-a8e4ec84df4b> in <module>()\r\n----> 1 ag.TabularPrediction.Dataset(file_path='nbc_golf_model_1_training.csv')\r\n\r\nAttributeError: module 'autogluon' has no attribute 'TabularPrediction'\r\n```\r\n\r\nFor your reference:\r\n\r\nI installed AutoGluon by using Version PIP in the notebook as usual.\r\n```\r\n!pip install --upgrade mxnet\r\n!pip install autogluon\r\n```\r\n\r\n```\r\nCollecting mxnet\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/92\/6c\/c6e5562f8face683cec73f5d4d74a58f8572c0595d54f1fed9d923020bbd\/mxnet-1.5.1.post0-py2.py3-none-manylinux1_x86_64.whl (25.4MB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 25.4MB 1.9MB\/s eta 0:00:01\r\nRequirement not upgraded as not directly required: requests<3,>=2.20.0 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from mxnet) (2.20.0)\r\nRequirement not upgraded as not directly required: graphviz<0.9.0,>=0.8.1 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from mxnet) (0.8.4)\r\nRequirement not upgraded as not directly required: numpy<2.0.0,>1.16.0 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from mxnet) (1.16.4)\r\nRequirement not upgraded as not directly required: chardet<3.1.0,>=3.0.2 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\r\nRequirement not upgraded as not directly required: idna<2.8,>=2.5 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from requests<3,>=2.20.0->mxnet) (2.6)\r\nRequirement not upgraded as not directly required: certifi>=2017.4.17 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from requests<3,>=2.20.0->mxnet) (2019.9.11)\r\nRequirement not upgraded as not directly required: urllib3<1.25,>=1.21.1 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from requests<3,>=2.20.0->mxnet) (1.23)\r\nInstalling collected packages: mxnet\r\nSuccessfully installed mxnet-1.5.1.post0\r\n```\r\nThere are 2 errors in the second installation step:\r\n\r\n**ERROR: sagemaker 1.43.4.post1 has requirement boto3>=1.9.213, but you'll have boto3 1.9.187 which is incompatible.\r\nERROR: awscli 1.16.283 has requirement botocore==1.13.19, but you'll have botocore 1.12.253 which is incompatible.**\r\n```\r\nCollecting autogluon\r\n  Downloading autogluon-0.0.5-py3-none-any.whl (328 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 328 kB 18.6 MB\/s eta 0:00:01\r\nRequirement already satisfied: tornado>=5.0.1 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from autogluon) (5.0.2)\r\nRequirement already satisfied: cryptography>=2.8 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from autogluon) (2.8)\r\nCollecting lightgbm==2.3.0\r\n  Downloading lightgbm-2.3.0-py2.py3-none-manylinux1_x86_64.whl (1.3 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.3 MB 33.4 MB\/s eta 0:00:01\r\nRequirement already satisfied: paramiko>=2.5.0 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from autogluon) (2.6.0)\r\nCollecting scipy>=1.3.3\r\n  Downloading scipy-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (26.1 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 26.1 MB 32.8 MB\/s eta 0:00:01\r\nCollecting boto3==1.9.187\r\n  Downloading boto3-1.9.187-py2.py3-none-any.whl (128 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 128 kB 36.5 MB\/s eta 0:00:01\r\nRequirement already satisfied: cython in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from autogluon) (0.28.2)\r\nCollecting scikit-optimize\r\n  Downloading scikit_optimize-0.7.1-py2.py3-none-any.whl (77 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 77 kB 10.7 MB\/s eta 0:00:01\r\nRequirement already satisfied: Pillow<=6.2.1 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from autogluon) (5.2.0)\r\nCollecting catboost\r\n  Downloading catboost-0.21-cp36-none-manylinux1_x86_64.whl (64.0 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 64.0 MB 36.8 MB\/s eta 0:00:01\r\nCollecting gluonnlp==0.8.1\r\n  Downloading gluonnlp-0.8.1.tar.gz (236 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 236 kB 63.1 MB\/s eta 0:00:01\r\nRequirement already satisfied: psutil>=5.0.0 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from autogluon) (5.6.3)\r\nRequirement already satisfied: pandas<1.0,>=0.24.0 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from autogluon) (0.24.2)\r\nRequirement already satisfied: graphviz in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from autogluon) (0.8.4)\r\nCollecting dask==2.6.0\r\n  Downloading dask-2.6.0-py3-none-any.whl (760 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 760 kB 66.0 MB\/s eta 0:00:01\r\nRequirement already satisfied: requests in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from autogluon) (2.20.0)\r\nCollecting scikit-learn==0.21.2\r\n  Downloading scikit_learn-0.21.2-cp36-cp36m-manylinux1_x86_64.whl (6.7 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6.7 MB 32.2 MB\/s eta 0:00:01\r\nCollecting distributed==2.6.0\r\n  Downloading distributed-2.6.0-py3-none-any.whl (560 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 560 kB 70.9 MB\/s eta 0:00:01\r\nRequirement already satisfied: matplotlib in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from autogluon) (3.0.3)\r\nCollecting ConfigSpace<=0.4.10\r\n  Downloading ConfigSpace-0.4.10.tar.gz (882 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 882 kB 72.3 MB\/s eta 0:00:01\r\nCollecting tqdm>=4.38.0\r\n  Downloading tqdm-4.42.1-py2.py3-none-any.whl (59 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 59 kB 10.6 MB\/s eta 0:00:01\r\nCollecting gluoncv>=0.5.0\r\n  Downloading gluoncv-0.6.0-py2.py3-none-any.whl (693 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 693 kB 69.3 MB\/s eta 0:00:01\r\nRequirement already satisfied: numpy>=1.16.0 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from autogluon) (1.16.4)\r\nRequirement already satisfied: cffi!=1.11.3,>=1.8 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from cryptography>=2.8->autogluon) (1.11.5)\r\nRequirement already satisfied: six>=1.4.1 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from cryptography>=2.8->autogluon) (1.11.0)\r\nRequirement already satisfied: bcrypt>=3.1.3 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from paramiko>=2.5.0->autogluon) (3.1.7)\r\nRequirement already satisfied: pynacl>=1.0.1 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from paramiko>=2.5.0->autogluon) (1.3.0)\r\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from boto3==1.9.187->autogluon) (0.9.4)\r\nRequirement already satisfied: s3transfer<0.3.0,>=0.2.0 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from boto3==1.9.187->autogluon) (0.2.1)\r\nCollecting botocore<1.13.0,>=1.12.187\r\n  Downloading botocore-1.12.253-py2.py3-none-any.whl (5.7 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5.7 MB 47.6 MB\/s eta 0:00:01\r\nCollecting pyaml\r\n  Downloading pyaml-19.12.0-py2.py3-none-any.whl (17 kB)\r\nCollecting joblib\r\n  Downloading joblib-0.14.1-py2.py3-none-any.whl (294 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 294 kB 55.6 MB\/s eta 0:00:01\r\nRequirement already satisfied: plotly in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from catboost->autogluon) (4.2.1)\r\nRequirement already satisfied: pytz>=2011k in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from pandas<1.0,>=0.24.0->autogluon) (2018.4)\r\nRequirement already satisfied: python-dateutil>=2.5.0 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from pandas<1.0,>=0.24.0->autogluon) (2.7.3)\r\nRequirement already satisfied: idna<2.8,>=2.5 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from requests->autogluon) (2.6)\r\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from requests->autogluon) (3.0.4)\r\nRequirement already satisfied: urllib3<1.25,>=1.21.1 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from requests->autogluon) (1.23)\r\nRequirement already satisfied: certifi>=2017.4.17 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from requests->autogluon) (2019.9.11)\r\nRequirement already satisfied: tblib in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from distributed==2.6.0->autogluon) (1.3.2)\r\nRequirement already satisfied: pyyaml in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from distributed==2.6.0->autogluon) (3.12)\r\nRequirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from distributed==2.6.0->autogluon) (1.5.10)\r\nRequirement already satisfied: msgpack in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from distributed==2.6.0->autogluon) (0.6.0)\r\nRequirement already satisfied: zict>=0.1.3 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from distributed==2.6.0->autogluon) (0.1.3)\r\nRequirement already satisfied: toolz>=0.7.4 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from distributed==2.6.0->autogluon) (0.9.0)\r\nRequirement already satisfied: cloudpickle>=0.2.2 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from distributed==2.6.0->autogluon) (0.5.3)\r\nRequirement already satisfied: click>=6.6 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from distributed==2.6.0->autogluon) (6.7)\r\nRequirement already satisfied: cycler>=0.10 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from matplotlib->autogluon) (0.10.0)\r\nRequirement already satisfied: kiwisolver>=1.0.1 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from matplotlib->autogluon) (1.0.1)\r\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from matplotlib->autogluon) (2.2.0)\r\nRequirement already satisfied: typing in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from ConfigSpace<=0.4.10->autogluon) (3.6.4)\r\nCollecting portalocker\r\n  Downloading portalocker-1.5.2-py2.py3-none-any.whl (14 kB)\r\nRequirement already satisfied: pycparser in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.8->autogluon) (2.18)\r\nRequirement already satisfied: docutils<0.16,>=0.10 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from botocore<1.13.0,>=1.12.187->boto3==1.9.187->autogluon) (0.14)\r\nRequirement already satisfied: retrying>=1.3.3 in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from plotly->catboost->autogluon) (1.3.3)\r\nRequirement already satisfied: heapdict in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from zict>=0.1.3->distributed==2.6.0->autogluon) (1.0.0)\r\nRequirement already satisfied: setuptools in \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages (from kiwisolver>=1.0.1->matplotlib->autogluon) (39.1.0)\r\nBuilding wheels for collected packages: gluonnlp, ConfigSpace\r\n  Building wheel for gluonnlp (setup.py) ... done\r\n  Created wheel for gluonnlp: filename=gluonnlp-0.8.1-py3-none-any.whl size=289392 sha256=3eba5a08b1bdd7719e9e6d869c3029e8aae5eb848f58c3f30ad5d42fe0969b9f\r\n  Stored in directory: \/home\/ec2-user\/.cache\/pip\/wheels\/70\/cb\/1c\/e6fb5e5eefcd5fe8ee2163f27c79a63c96d9a956e8d93fb496\r\n  Building wheel for ConfigSpace (setup.py) ... done\r\n  Created wheel for ConfigSpace: filename=ConfigSpace-0.4.10-cp36-cp36m-linux_x86_64.whl size=3000873 sha256=35ce111cf113601a2e6543690fb721b2449622e0c010e0b6bc094a498890edc4\r\n  Stored in directory: \/home\/ec2-user\/.cache\/pip\/wheels\/70\/71\/a2\/00ca7cb0f71294d73e8791d6fe5cd0c7401066ec3b7e1026db\r\nSuccessfully built gluonnlp ConfigSpace\r\nERROR: sagemaker 1.43.4.post1 has requirement boto3>=1.9.213, but you'll have boto3 1.9.187 which is incompatible.\r\nERROR: awscli 1.16.283 has requirement botocore==1.13.19, but you'll have botocore 1.12.253 which is incompatible.\r\nInstalling collected packages: scipy, joblib, scikit-learn, lightgbm, botocore, boto3, pyaml, scikit-optimize, catboost, gluonnlp, dask, distributed, ConfigSpace, tqdm, portalocker, gluoncv, autogluon\r\n  Attempting uninstall: scipy\r\n    Found existing installation: scipy 1.2.1\r\n    Uninstalling scipy-1.2.1:\r\n      Successfully uninstalled scipy-1.2.1\r\n  Attempting uninstall: scikit-learn\r\n    Found existing installation: scikit-learn 0.20.3\r\n    Uninstalling scikit-learn-0.20.3:\r\n      Successfully uninstalled scikit-learn-0.20.3\r\n  Attempting uninstall: botocore\r\n    Found existing installation: botocore 1.13.19\r\n    Uninstalling botocore-1.13.19:\r\n      Successfully uninstalled botocore-1.13.19\r\n  Attempting uninstall: boto3\r\n    Found existing installation: boto3 1.10.19\r\n    Uninstalling boto3-1.10.19:\r\n      Successfully uninstalled boto3-1.10.19\r\n  Attempting uninstall: dask\r\n    Found existing installation: dask 0.17.5\r\n    Uninstalling dask-0.17.5:\r\n      Successfully uninstalled dask-0.17.5\r\n  Attempting uninstall: distributed\r\n    Found existing installation: distributed 1.21.8\r\n    Uninstalling distributed-1.21.8:\r\n      Successfully uninstalled distributed-1.21.8\r\nSuccessfully installed ConfigSpace-0.4.10 autogluon-0.0.5 boto3-1.9.187 botocore-1.12.253 catboost-0.21 dask-2.6.0 distributed-2.6.0 gluoncv-0.6.0 gluonnlp-0.8.1 joblib-0.14.1 lightgbm-2.3.0 portalocker-1.5.2 pyaml-19.12.0 scikit-learn-0.21.2 scikit-optimize-0.7.1 scipy-1.4.1 tqdm-4.42.1\r\n```\r\n\r\n\r\n",
        "Issue_answer_count":2,
        "Issue_self_closed":0.0,
        "Answer_body":"Thanks for submitting this issue!\r\n\r\nWe haven't looked closely at which boto versions are functional with AutoGluon, but I would suspect using the newer version wouldn't cause issues.\r\n\r\nWe will take a look.\r\n @zhuwenzhen In the latest mainline of AutoGluon, the boto version limitation has been removed. This may resolve your issue if you install AutoGluon from source, or wait for AutoGluon 0.1 to be released.",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"importerror tabularpredict notebook instanc got importerror try us autogluon instanc xlarg kernel conda python error got autogluon import tabularpredict task importerror traceback recent autogluon import tabularpredict task importerror import tabularpredict try import autogluon tabularpredict dataset file path data nbc golf model train csv attributeerror traceback recent tabularpredict dataset file path nbc golf model train csv attributeerror modul autogluon attribut tabularpredict refer instal autogluon version pip notebook usual pip instal upgrad mxnet pip instal autogluon collect mxnet download http file pythonhost org packag ceffacececfddafcdffeddbbd mxnet post manylinux whl eta requir upgrad directli requir request home user anaconda env mxnet lib python site packag mxnet requir upgrad directli requir graphviz home user anaconda env mxnet lib python site packag mxnet requir upgrad directli requir numpi home user anaconda env mxnet lib python site packag mxnet requir upgrad directli requir chardet home user anaconda env mxnet lib python site packag request mxnet requir upgrad directli requir idna home user anaconda env mxnet lib python site packag request mxnet requir upgrad directli requir certifi home user anaconda env mxnet lib python site packag request mxnet requir upgrad directli requir urllib home user anaconda env mxnet lib python site packag request mxnet instal collect packag mxnet successfulli instal mxnet post error second instal step error post requir boto boto incompat error awscli requir botocor botocor incompat collect autogluon download autogluon whl eta requir satisfi tornado home user anaconda env mxnet lib python site packag autogluon requir satisfi cryptographi home user anaconda env mxnet lib python site packag autogluon collect lightgbm download lightgbm manylinux whl eta requir satisfi paramiko home user anaconda env mxnet lib python site packag autogluon collect scipi download scipi cpm manylinux whl eta collect boto download boto whl eta requir satisfi cython home user anaconda env mxnet lib python site packag autogluon collect scikit optim download scikit optim whl eta requir satisfi pillow home user anaconda env mxnet lib python site packag autogluon requir satisfi panda home user anaconda env mxnet lib python site packag autogluon requir satisfi graphviz home user anaconda env mxnet lib python site packag autogluon collect dask download dask whl eta requir satisfi request home user anaconda env mxnet lib python site packag autogluon collect scikit learn download scikit learn cpm manylinux whl eta collect distribut download distribut whl eta requir satisfi matplotlib home user anaconda env mxnet lib python site packag autogluon collect configspac download tqdm whl eta collect gluoncv download gluoncv whl eta requir satisfi numpi home user anaconda env mxnet lib python site packag autogluon requir satisfi cffi home user anaconda env mxnet lib python site packag cryptographi autogluon requir satisfi home user anaconda env mxnet lib python site packag cryptographi autogluon requir satisfi bcrypt home user anaconda env mxnet lib python site packag paramiko autogluon requir satisfi pynacl home user anaconda env mxnet lib python site packag paramiko autogluon requir satisfi jmespath home user anaconda env mxnet lib python site packag boto autogluon requir satisfi stransfer home user anaconda env mxnet lib python site packag boto autogluon collect botocor download botocor whl eta collect pyaml download pyaml whl collect joblib download joblib whl eta requir satisfi plotli home user anaconda env mxnet lib python site packag catboost autogluon requir satisfi pytz home user anaconda env mxnet lib python site packag panda autogluon requir satisfi python dateutil home user anaconda env mxnet lib python site packag panda autogluon requir satisfi idna home user anaconda env mxnet lib python site packag request autogluon requir satisfi chardet home user anaconda env mxnet lib python site packag request autogluon requir satisfi urllib home user anaconda env mxnet lib python site packag request autogluon requir satisfi certifi home user anaconda env mxnet lib python site packag request autogluon requir satisfi tblib home user anaconda env mxnet lib python site packag distribut autogluon requir satisfi pyyaml home user anaconda env mxnet lib python site packag distribut autogluon requir satisfi sortedcontain home user anaconda env mxnet lib python site packag distribut autogluon requir satisfi msgpack home user anaconda env mxnet lib python site packag distribut autogluon requir satisfi zict home user anaconda env mxnet lib python site packag distribut autogluon requir satisfi toolz home user anaconda env mxnet lib python site packag distribut autogluon requir satisfi cloudpickl home user anaconda env mxnet lib python site packag distribut autogluon requir satisfi click home user anaconda env mxnet lib python site packag distribut autogluon requir satisfi cycler home user anaconda env mxnet lib python site packag matplotlib autogluon requir satisfi kiwisolv home user anaconda env mxnet lib python site packag matplotlib autogluon requir satisfi pypars home user anaconda env mxnet lib python site packag matplotlib autogluon requir satisfi type home user anaconda env mxnet lib python site packag configspaceautogluon collect portalock download portalock whl requir satisfi pycpars home user anaconda env mxnet lib python site packag cffi cryptographi autogluon requir satisfi docutil home user anaconda env mxnet lib python site packag botocor boto autogluon requir satisfi retri home user anaconda env mxnet lib python site packag plotli catboost autogluon requir satisfi heapdict home user anaconda env mxnet lib python site packag zict distribut autogluon requir satisfi setuptool home user anaconda env mxnet lib python site packag kiwisolv matplotlib autogluon build wheel collect packag gluonnlp configspac build wheel gluonnlp setup creat wheel gluonnlp filenam gluonnlp whl size sha ebaabbddeedceaaeebfcfaddfebf store directori home user cach pip wheel efbeeefcdfeeefcacdaedfb build wheel configspac setup creat wheel configspac filenam configspac cpm linux whl size sha cecfaefbbecebbcaedc store directori home user cach pip wheel cacbfdedfecdcecbedb successfulli built gluonnlp configspac error post requir boto boto incompat error awscli requir botocor botocor incompat instal collect packag scipi joblib scikit learn lightgbm botocor boto pyaml scikit optim catboost gluonnlp dask distribut configspac tqdm portalock gluoncv autogluon attempt uninstal scipi exist instal scipi uninstal scipi successfulli uninstal scipi attempt uninstal scikit learn exist instal scikit learn uninstal scikit learn successfulli uninstal scikit learn attempt uninstal botocor exist instal botocor uninstal botocor successfulli uninstal botocor attempt uninstal boto exist instal boto uninstal boto successfulli uninstal boto attempt uninstal dask exist instal dask uninstal dask successfulli uninstal dask attempt uninstal distribut exist instal distribut uninstal distribut successfulli uninstal distribut successfulli instal configspac autogluon boto botocor catboost dask distribut gluoncv gluonnlp joblib lightgbm portalock pyaml scikit learn scikit optim scipi tqdm",
        "Issue_preprocessed_content":"tabularpredict instanc got try us autogluon instanc kernel got try refer autogluon version pip usual second step requir boto incompat awscli requir botocor",
        "Issue_gpt_summary_original":"The user is facing an issue while installing GluonTS on a Sagemaker notebook instance from Github. The error message indicates that the installation failed due to a module 'enum' attribute error. The user has previously installed GluonTS (0.5.2) using a different command, but it is not recognized when attempting to uninstall it. The environment consists of a Sagemaker notebook instance with conda_mxnet_p36 kernel, Python version 3.6, GluonTS version 0.5.2, and MXNet version 1.6.",
        "Issue_gpt_summary":"user face issu instal gluont notebook instanc github error messag indic instal fail modul enum attribut error user previous instal gluont differ command recogn attempt uninstal environ consist notebook instanc conda mxnet kernel python version gluont version mxnet version",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/awslabs\/gluonts\/issues\/1039",
        "Issue_title":"Issue with installing GlounTS on Sagemaker notebook instance from Github",
        "Issue_created_time":1600235220000,
        "Issue_closed_time":1600271697000,
        "Issue_body":"## Description\r\nI am following the instructions on https:\/\/github.com\/awslabs\/gluon-ts\/blob\/acfd7e14c4ef6eaa62fea6d6233a9e336f6366e4\/examples\/GluonTS_SageMaker_SDK_Tutorial.ipynb but at first step when I ran `!pip install --upgrade mxnet==1.6  git+https:\/\/github.com\/awslabs\/gluon-ts.git#egg=gluonts[dev]` I got the following error,\r\n\r\n## Error message or code output\r\n```Obtaining gluonts[dev] from git+https:\/\/github.com\/awslabs\/gluon-ts.git#egg=gluonts[dev]\r\n  Updating .\/src\/gluonts clone\r\n  Running command git fetch -q --tags\r\n  Running command git reset --hard -q fc203f51f01036e854ce6a0da1a43b562074e187\r\n  Installing build dependencies ... error\r\n  ERROR: Command errored out with exit status 1:\r\n   command: \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/bin\/python \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/pip install --ignore-installed --no-user --prefix \/tmp\/pip-build-env-_u9w80jg\/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https:\/\/pypi.org\/simple -- 'setuptools>=40.8.0' wheel\r\n       cwd: None\r\n  Complete output (14 lines):\r\n  Traceback (most recent call last):\r\n    File \"\/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/runpy.py\", line 193, in _run_module_as_main\r\n      \"__main__\", mod_spec)\r\n    File \"\/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/runpy.py\", line 85, in _run_code\r\n      exec(code, run_globals)\r\n    File \"\/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/pip\/__main__.py\", line 16, in <module>\r\n      from pip._internal.cli.main import main as _main  # isort:skip # noqa\r\n    File \"\/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/pip\/_internal\/cli\/main.py\", line 5, in <module>\r\n      import locale\r\n    File \"\/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/locale.py\", line 16, in <module>\r\n      import re\r\n    File \"\/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/re.py\", line 142, in <module>\r\n      class RegexFlag(enum.IntFlag):\r\n  AttributeError: module 'enum' has no attribute 'IntFlag'\r\n  ----------------------------------------\r\nERROR: Command errored out with exit status 1: \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/bin\/python \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/pip install --ignore-installed --no-user --prefix \/tmp\/pip-build-env-_u9w80jg\/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https:\/\/pypi.org\/simple -- 'setuptools>=40.8.0' wheel Check the logs for full command output.\r\n\r\n```\r\n\r\n\r\n## Environment\r\nNote: Previously, I installed Gluon-TS (0.5.2) using `! pip install --upgrade mxnet==1.6 gluonts` and if I do `! pip list` I can see the package is installed but when I ran `!pip uninstall glounts` it says `WARNING: Skipping glounts as it is not installed.`\r\n\r\n- Operating system: Sagemaker notebook instance with conda_mxnet_p36 kernel.\r\n- Python version: 3.6\r\n- GluonTS version: 0.5.2 is already installed.\r\n- MXNet version:1.6",
        "Issue_answer_count":2,
        "Issue_self_closed":0.0,
        "Answer_body":"According to [this](https:\/\/github.com\/iterative\/dvc\/issues\/1995), it could be that `enum34` is installed.\r\n\r\nCan you check whether this is also the case here? Thanks @jaheba ! That was the issue and by running `!pip uninstall -y enum34` it is resolved.",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"issu instal glount notebook instanc github descript follow instruct http github com awslab gluon blob acfdecefeaafeadaef exampl gluont sdk tutori ipynb step ran pip instal upgrad mxnet git http github com awslab gluon git egg gluont dev got follow error error messag code output obtain gluont dev git http github com awslab gluon git egg gluont dev updat src gluont clone run command git fetch tag run command git reset hard fcffeceadaab instal build depend error error command error exit statu command home user anaconda env mxnet bin python home user anaconda env mxnet lib python site packag pip instal ignor instal user prefix tmp pip build env uwjg overlai warn script locat binari binari http pypi org simpl setuptool wheel cwd complet output line traceback recent file home user anaconda env mxnet lib python runpi line run modul main main mod spec file home user anaconda env mxnet lib python runpi line run code exec code run global file home user anaconda env mxnet lib python site packag pip main line pip intern cli main import main main isort skip noqa file home user anaconda env mxnet lib python site packag pip intern cli main line import local file home user anaconda env mxnet lib python local line import file home user anaconda env mxnet lib python line class regexflag enum intflag attributeerror modul enum attribut intflag error command error exit statu home user anaconda env mxnet bin python home user anaconda env mxnet lib python site packag pip instal ignor instal user prefix tmp pip build env uwjg overlai warn script locat binari binari http pypi org simpl setuptool wheel check log command output environ note previous instal gluon pip instal upgrad mxnet gluont pip list packag instal ran pip uninstal glount sai warn skip glount instal oper notebook instanc conda mxnet kernel python version gluont version instal mxnet version",
        "Issue_preprocessed_content":"glount instanc github descript instruct step ran got code output environ note previous packag ran sai oper instanc kernel python version gluont version mxnet",
        "Issue_gpt_summary_original":"the user encountered challenges when attempting to run the example script 'benchmark_m4.py' on a gpu-instance \"ml.p2.xlarge\" on aws, resulting in a keyerror.",
        "Issue_gpt_summary":"user encount challeng attempt run exampl script benchmark gpu instanc xlarg aw result keyerror",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/awslabs\/gluonts\/issues\/426",
        "Issue_title":"Problems using GPU with Amazon SageMaker on AWS-instance \"ml.p2.xlarge\".",
        "Issue_created_time":1573166280000,
        "Issue_closed_time":1573208758000,
        "Issue_body":"## Description\r\nUsing Amazon SageMaker on an AWS GPU-instance \"ml.p2.xlarge\", I was not able to run the example `benchmark_m4.py` script (copy\/pasted in SageMaker) on GPU. \r\n\r\n## To Reproduce\r\nAfter starting the instance: \r\n```\r\n!pip install gluonts\r\n```\r\n\r\nNext cell: paste the slightly modified script `benchmark_m4.py` with a little modification:\r\n \r\n```python\r\nestimators = [\r\n    partial(\r\n        DeepAREstimator,\r\n        trainer=Trainer(\r\n            epochs=epochs, \r\n            num_batches_per_epoch=num_batches_per_epoch,\r\n            ctx=\"gpu\"\r\n        ),\r\n    ),\r\n]\r\n```\r\n(without specifying the context this works fine, but is only running on CPU)\r\n\r\n## Error Message\r\n\r\n```\r\nINFO:root:using dataset already processed in path \/home\/ec2-user\/.mxnet\/gluon-ts\/datasets\/m4_quarterly.\r\nINFO:root:Start model training\r\nINFO:root:using dataset already processed in path \/home\/ec2-user\/.mxnet\/gluon-ts\/datasets\/m4_yearly.\r\nINFO:root:Start model training\r\nevaluating gluonts.model.deepar._estimator.DeepAREstimator(cardinality=[24000], cell_type=\"lstm\", context_length=None, distr_output=gluonts.distribution.student_t.StudentTOutput(), dropout_rate=0.1, embedding_dimension=20, freq=\"3M\", lags_seq=None, num_cells=40, num_layers=2, num_parallel_samples=100, prediction_length=8, scaling=True, time_features=None, trainer=gluonts.trainer._base.Trainer(batch_size=32, clip_gradient=10.0, ctx=mxnet.context.Context(\"gpu\", 0), epochs=100, hybridize=True, init=\"xavier\", learning_rate=0.001, learning_rate_decay_factor=0.5, minimum_learning_rate=5e-05, num_batches_per_epoch=200, patience=10, weight_decay=1e-08), use_feat_dynamic_real=False, use_feat_static_cat=True) on TrainDatasets(metadata=<MetaData freq='3M' target=None feat_static_cat=[<CategoricalFeatureInfo name='feat_static_cat' cardinality='24000'>] feat_static_real=[] feat_dynamic_real=[] feat_dynamic_cat=[] prediction_length=8>, train=<gluonts.dataset.common.FileDataset object at 0x7f9377c9e748>, test=<gluonts.dataset.common.FileDataset object at 0x7f9377c53208>)\r\n[22:17:01] src\/ndarray\/ndarray.cc:1279: GPU is not enabled\r\n\r\nStack trace returned 10 entries:\r\n[bt] (0) \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/mxnet\/libmxnet.so(+0x23d55a) [0x7f93951c155a]\r\n[bt] (1) \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/mxnet\/libmxnet.so(+0x23dbc1) [0x7f93951c1bc1]\r\n[bt] (2) \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/mxnet\/libmxnet.so(mxnet::CopyFromTo(mxnet::NDArray const&, mxnet::NDArray const&, int, bool)+0x723) [0x7f9397cf7623]\r\n[bt] (3) \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/mxnet\/libmxnet.so(mxnet::imperative::PushFComputeEx(std::function<void (nnvm::NodeAttrs const&, mxnet::OpContext const&, std::vector<mxnet::NDArray, std::allocator<mxnet::NDArray> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::NDArray, std::allocator<mxnet::NDArray> > const&)> const&, nnvm::Op const*, nnvm::NodeAttrs const&, mxnet::Context const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::Resource, std::allocator<mxnet::Resource> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&)+0x47e) [0x7f9397bad59e]\r\n[bt] (4) \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/mxnet\/libmxnet.so(mxnet::Imperative::InvokeOp(mxnet::Context const&, nnvm::NodeAttrs const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, mxnet::DispatchMode, mxnet::OpStatePtr)+0x839) [0x7f9397bb28f9]\r\n[bt] (5) \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/mxnet\/libmxnet.so(mxnet::Imperative::Invoke(mxnet::Context const&, nnvm::NodeAttrs const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&)+0x38c) [0x7f9397bb317c]\r\n[bt] (6) \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/mxnet\/libmxnet.so(+0x2b34989) [0x7f9397ab8989]\r\n[bt] (7) \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/mxnet\/libmxnet.so(MXImperativeInvokeEx+0x6f) [0x7f9397ab8f7f]\r\n[bt] (8) \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/lib-dynload\/..\/..\/libffi.so.6(ffi_call_unix64+0x4c) [0x7f93d58efec0]\r\n[bt] (9) \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/lib-dynload\/..\/..\/libffi.so.6(ffi_call+0x22d) [0x7f93d58ef87d]\r\n\r\n\r\nevaluating gluonts.model.deepar._estimator.DeepAREstimator(cardinality=[23000], cell_type=\"lstm\", context_length=None, distr_output=gluonts.distribution.student_t.StudentTOutput(), dropout_rate=0.1, embedding_dimension=20, freq=\"12M\", lags_seq=None, num_cells=40, num_layers=2, num_parallel_samples=100, prediction_length=6, scaling=True, time_features=None, trainer=gluonts.trainer._base.Trainer(batch_size=32, clip_gradient=10.0, ctx=mxnet.context.Context(\"gpu\", 0), epochs=100, hybridize=True, init=\"xavier\", learning_rate=0.001, learning_rate_decay_factor=0.5, minimum_learning_rate=5e-05, num_batches_per_epoch=200, patience=10, weight_decay=1e-08), use_feat_dynamic_real=False, use_feat_static_cat=True) on TrainDatasets(metadata=<MetaData freq='12M' target=None feat_static_cat=[<CategoricalFeatureInfo name='feat_static_cat' cardinality='23000'>] feat_static_real=[] feat_dynamic_real=[] feat_dynamic_cat=[] prediction_length=6>, train=<gluonts.dataset.common.FileDataset object at 0x7f937812ce48>, test=<gluonts.dataset.common.FileDataset object at 0x7f9377c53208>)\r\n[22:17:01] src\/ndarray\/ndarray.cc:1279: GPU is not enabled\r\n\r\nStack trace returned 10 entries:\r\n[bt] (0) \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/mxnet\/libmxnet.so(+0x23d55a) [0x7f93951c155a]\r\n[bt] (1) \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/mxnet\/libmxnet.so(+0x23dbc1) [0x7f93951c1bc1]\r\n[bt] (2) \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/mxnet\/libmxnet.so(mxnet::CopyFromTo(mxnet::NDArray const&, mxnet::NDArray const&, int, bool)+0x723) [0x7f9397cf7623]\r\n[bt] (3) \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/mxnet\/libmxnet.so(mxnet::imperative::PushFComputeEx(std::function<void (nnvm::NodeAttrs const&, mxnet::OpContext const&, std::vector<mxnet::NDArray, std::allocator<mxnet::NDArray> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::NDArray, std::allocator<mxnet::NDArray> > const&)> const&, nnvm::Op const*, nnvm::NodeAttrs const&, mxnet::Context const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::Resource, std::allocator<mxnet::Resource> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&)+0x47e) [0x7f9397bad59e]\r\n[bt] (4) \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/mxnet\/libmxnet.so(mxnet::Imperative::InvokeOp(mxnet::Context const&, nnvm::NodeAttrs const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, mxnet::DispatchMode, mxnet::OpStatePtr)+0x839) [0x7f9397bb28f9]\r\n[bt] (5) \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/mxnet\/libmxnet.so(mxnet::Imperative::Invoke(mxnet::Context const&, nnvm::NodeAttrs const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&)+0x38c) [0x7f9397bb317c]\r\n[bt] (6) \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/mxnet\/libmxnet.so(+0x2b34989) [0x7f9397ab8989]\r\n[bt] (7) \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/mxnet\/libmxnet.so(MXImperativeInvokeEx+0x6f) [0x7f9397ab8f7f]\r\n[bt] (8) \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/lib-dynload\/..\/..\/libffi.so.6(ffi_call_unix64+0x4c) [0x7f93d58efec0]\r\n[bt] (9) \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/lib-dynload\/..\/..\/libffi.so.6(ffi_call+0x22d) [0x7f93d58ef87d]\r\n\r\n\r\n---------------------------------------------------------------------------\r\nKeyError                                  Traceback (most recent call last)\r\n<ipython-input-15-b3fbc3bdf424> in <module>()\r\n     88             \"MASE\",\r\n     89             \"sMAPE\",\r\n---> 90             \"MSIS\",\r\n     91         ]\r\n     92     ]\r\n\r\n~\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/pandas\/core\/frame.py in __getitem__(self, key)\r\n   2999             if is_iterator(key):\r\n   3000                 key = list(key)\r\n-> 3001             indexer = self.loc._convert_to_indexer(key, axis=1, raise_missing=True)\r\n   3002 \r\n   3003         # take() does not accept boolean indexers\r\n\r\n~\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/pandas\/core\/indexing.py in _convert_to_indexer(self, obj, axis, is_setter, raise_missing)\r\n   1283                 # When setting, missing keys are not allowed, even with .loc:\r\n   1284                 kwargs = {\"raise_missing\": True if is_setter else raise_missing}\r\n-> 1285                 return self._get_listlike_indexer(obj, axis, **kwargs)[1]\r\n   1286         else:\r\n   1287             try:\r\n\r\n~\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/pandas\/core\/indexing.py in _get_listlike_indexer(self, key, axis, raise_missing)\r\n   1090 \r\n   1091         self._validate_read_indexer(\r\n-> 1092             keyarr, indexer, o._get_axis_number(axis), raise_missing=raise_missing\r\n   1093         )\r\n   1094         return keyarr, indexer\r\n\r\n~\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/pandas\/core\/indexing.py in _validate_read_indexer(self, key, indexer, axis, raise_missing)\r\n   1175                 raise KeyError(\r\n   1176                     \"None of [{key}] are in the [{axis}]\".format(\r\n-> 1177                         key=key, axis=self.obj._get_axis_name(axis)\r\n   1178                     )\r\n   1179                 )\r\n\r\nKeyError: \"None of [Index(['dataset', 'estimator', 'RMSE', 'mean_wQuantileLoss', 'MASE', 'sMAPE',\\n       'MSIS'],\\n      dtype='object')] are in the [columns]\"\r\n```\r\n\r\n## Other\r\nIn addition, before installing gluonts (from https:\/\/beta.mxnet.io\/guide\/crash-course\/6-use_gpus.html): \r\n```python\r\nx = nd.ones((3,4), ctx=gpu())\r\nx\r\n```\r\n```\r\n[[1. 1. 1. 1.]\r\n [1. 1. 1. 1.]\r\n [1. 1. 1. 1.]]\r\n<NDArray 3x4 @gpu(0)>\r\n```\r\n\r\nAfter installing gluonts: \r\n\r\n```python\r\nx = nd.ones((3,4), ctx=gpu())\r\nx\r\n```\r\n```\r\n---------------------------------------------------------------------------\r\nMXNetError                                Traceback (most recent call last)\r\n<ipython-input-16-749bd657d613> in <module>()\r\n      5 \r\n      6 \r\n----> 7 x = nd.ones((3,4), ctx=gpu())\r\n      8 x\r\n\r\n~\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/mxnet\/ndarray\/ndarray.py in ones(shape, ctx, dtype, **kwargs)\r\n   2419     dtype = mx_real_t if dtype is None else dtype\r\n   2420     # pylint: disable= no-member, protected-access\r\n-> 2421     return _internal._ones(shape=shape, ctx=ctx, dtype=dtype, **kwargs)\r\n   2422     # pylint: enable= no-member, protected-access\r\n   2423 \r\n\r\n~\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/mxnet\/ndarray\/register.py in _ones(shape, ctx, dtype, out, name, **kwargs)\r\n\r\n~\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/mxnet\/_ctypes\/ndarray.py in _imperative_invoke(handle, ndargs, keys, vals, out)\r\n     90         c_str_array(keys),\r\n     91         c_str_array([str(s) for s in vals]),\r\n---> 92         ctypes.byref(out_stypes)))\r\n     93 \r\n     94     if original_output is not None:\r\n\r\n~\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/mxnet\/base.py in check_call(ret)\r\n    250     \"\"\"\r\n    251     if ret != 0:\r\n--> 252         raise MXNetError(py_str(_LIB.MXGetLastError()))\r\n    253 \r\n    254 \r\n\r\nMXNetError: [22:29:51] src\/imperative\/imperative.cc:79: Operator _ones is not implemented for GPU.\r\n\r\nStack trace returned 10 entries:\r\n[bt] (0) \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/mxnet\/libmxnet.so(+0x23d55a) [0x7f93951c155a]\r\n[bt] (1) \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/mxnet\/libmxnet.so(+0x23dbc1) [0x7f93951c1bc1]\r\n[bt] (2) \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/mxnet\/libmxnet.so(mxnet::Imperative::InvokeOp(mxnet::Context const&, nnvm::NodeAttrs const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, mxnet::DispatchMode, mxnet::OpStatePtr)+0x9fb) [0x7f9397bb2abb]\r\n[bt] (3) \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/mxnet\/libmxnet.so(mxnet::Imperative::Invoke(mxnet::Context const&, nnvm::NodeAttrs const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&)+0x38c) [0x7f9397bb317c]\r\n[bt] (4) \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/mxnet\/libmxnet.so(+0x2b34989) [0x7f9397ab8989]\r\n[bt] (5) \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\/mxnet\/libmxnet.so(MXImperativeInvokeEx+0x6f) [0x7f9397ab8f7f]\r\n[bt] (6) \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/lib-dynload\/..\/..\/libffi.so.6(ffi_call_unix64+0x4c) [0x7f93d58efec0]\r\n[bt] (7) \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/lib-dynload\/..\/..\/libffi.so.6(ffi_call+0x22d) [0x7f93d58ef87d]\r\n[bt] (8) \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/lib-dynload\/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f93d5b04e2e]\r\n[bt] (9) \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/lib-dynload\/_ctypes.cpython-36m-x86_64-linux-gnu.so(+0x12865) [0x7f93d5b05865]\r\n```\r\n\r\n## Environment\r\n\r\n- Amazon SageMaker, running on AWS instance \"ml.p2.xlarge\". \r\n- GluonTS version: 0.3.3 installed using pip.\r\n- Kernel: conda_mxnet_p36 \r\n\r\n",
        "Issue_answer_count":5,
        "Issue_self_closed":0.0,
        "Answer_body":"After installing GluonTS, could you try running in a cell \r\n\r\n```\r\n!pip show mxnet\r\n```\r\n\r\nand report the result? `!pip show mxnet` results in:\r\n\r\n```python\r\nName: mxnet\r\nVersion: 1.4.1\r\nSummary: MXNet is an ultra-scalable deep learning framework. This version uses openblas.\r\nHome-page: https:\/\/github.com\/apache\/incubator-mxnet\r\nAuthor: UNKNOWN\r\nAuthor-email: UNKNOWN\r\nLicense: Apache 2.0\r\nLocation: \/home\/ec2-user\/anaconda3\/envs\/mxnet_p36\/lib\/python3.6\/site-packages\r\nRequires: numpy, graphviz, requests\r\nRequired-by: gluonts\r\nYou are using pip version 10.0.1, however version 19.3.1 is available.\r\nYou should consider upgrading via the 'pip install --upgrade pip' command.\r\n```\r\n\r\n`!pip install mxnet --upgrade` led to conflicts with gluonts and numpy and the same error message with `GPU is not enabled`. \r\n @tm1611 hopefully this is solved with the upcoming `0.4` release (to be relased very soon), since #428 was merged. I think the problem is that with `gluonts<0.4` the vanilla mxnet package gets installed and replaces the one with built-in cuda for GPU processing. @tm1611 can you check if the problem is gone now when you install GluonTS from scratch on your instance? Yes, the problem with mxnet and dependencies was removed. Thanks a lot for the quick fix. \r\n\r\nUnrelated to this issue, but related to `m4_benchmark.py` and the sake of completeness: Using gluonts-version 0.4., one has to change `num_eval_samples` to `num_sampels` (see #421 ). ",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"problem gpu aw instanc xlarg descript aw gpu instanc xlarg abl run exampl benchmark script copi past gpu reproduc start instanc pip instal gluont cell past slightli modifi script benchmark littl modif python estim partial deeparestim trainer trainer epoch epoch num batch epoch num batch epoch ctx gpu specifi context work fine run cpu error messag info root dataset process path home user mxnet gluon dataset quarterli info root start model train info root dataset process path home user mxnet gluon dataset yearli info root start model train evalu gluont model deepar estim deeparestim cardin cell type lstm context length distr output gluont distribut student studenttoutput dropout rate embed dimens freq lag seq num cell num layer num parallel sampl predict length scale true time featur trainer gluont trainer base trainer batch size clip gradient ctx mxnet context context gpu epoch hybrid true init xavier learn rate learn rate decai factor minimum learn rate num batch epoch patienc weight decai us feat dynam real fals us feat static cat true traindataset metadata feat static real feat dynam real feat dynam cat predict length train test src ndarrai ndarrai gpu enabl stack trace return entri home user anaconda env mxnet lib python site packag mxnet libmxnet xda xfca home user anaconda env mxnet lib python site packag mxnet libmxnet xdbc xfcbc home user anaconda env mxnet lib python site packag mxnet libmxnet mxnet copyfromto mxnet ndarrai const mxnet ndarrai const int bool xfcf home user anaconda env mxnet lib python site packag mxnet libmxnet mxnet imper pushfcomputeex std function const std vector const std vector const const nnvm const nnvm nodeattr const mxnet context const std vector const std vector const std vector const std vector const std vector const std vector const xfbade home user anaconda env mxnet lib python site packag mxnet libmxnet mxnet imper invokeop mxnet context const nnvm nodeattr const std vector const std vector const std vector const mxnet dispatchmod mxnet opstateptr xfbbf home user anaconda env mxnet lib python site packag mxnet libmxnet mxnet imper invok mxnet context const nnvm nodeattr const std vector const std vector const xfbbc home user anaconda env mxnet lib python site packag mxnet libmxnet xfab home user anaconda env mxnet lib python site packag mxnet libmxnet mximperativeinvokeex xfabff home user anaconda env mxnet lib python lib dynload libffi ffi unix xfdefec home user anaconda env mxnet lib python lib dynload libffi ffi xfdefd evalu gluont model deepar estim deeparestim cardin cell type lstm context length distr output gluont distribut student studenttoutput dropout rate embed dimens freq lag seq num cell num layer num parallel sampl predict length scale true time featur trainer gluont trainer base trainer batch size clip gradient ctx mxnet context context gpu epoch hybrid true init xavier learn rate learn rate decai factor minimum learn rate num batch epoch patienc weight decai us feat dynam real fals us feat static cat true traindataset metadata feat static real feat dynam real feat dynam cat predict length train test src ndarrai ndarrai gpu enabl stack trace return entri home user anaconda env mxnet lib python site packag mxnet libmxnet xda xfca home user anaconda env mxnet lib python site packag mxnet libmxnet xdbc xfcbc home user anaconda env mxnet lib python site packag mxnet libmxnet mxnet copyfromto mxnet ndarrai const mxnet ndarrai const int bool xfcf home user anaconda env mxnet lib python site packag mxnet libmxnet mxnet imper pushfcomputeex std function const std vector const std vector const const nnvm const nnvm nodeattr const mxnet context const std vector const std vector const std vector const std vector const std vector const std vector const xfbade home user anaconda env mxnet lib python site packag mxnet libmxnet mxnet imper invokeop mxnet context const nnvm nodeattr const std vector const std vector const std vector const mxnet dispatchmod mxnet opstateptr xfbbf home user anaconda env mxnet lib python site packag mxnet libmxnet mxnet imper invok mxnet context const nnvm nodeattr const std vector const std vector const xfbbc home user anaconda env mxnet lib python site packag mxnet libmxnet xfab home user anaconda env mxnet lib python site packag mxnet libmxnet mximperativeinvokeex xfabff home user anaconda env mxnet lib python lib dynload libffi ffi unix xfdefec home user anaconda env mxnet lib python lib dynload libffi ffi xfdefd keyerror traceback recent mase smape msi anaconda env mxnet lib python site packag panda core frame getitem self kei iter kei kei list kei index self loc convert index kei axi rais miss true accept boolean index anaconda env mxnet lib python site packag panda core index convert index self obj axi setter rais miss set miss kei allow loc kwarg rais miss true setter rais miss return self listlik index obj axi kwarg try anaconda env mxnet lib python site packag panda core index listlik index self kei axi rais miss self valid read index keyarr index axi number axi rais miss rais miss return keyarr index anaconda env mxnet lib python site packag panda core index valid read index self kei index axi rais miss rais keyerror kei axi format kei kei axi self obj axi axi keyerror index dataset estim rmse mean wquantileloss mase smape msi dtype object column addit instal gluont http beta mxnet guid crash cours us gpu html python on ctx gpu instal gluont python on ctx gpu mxneterror traceback recent on ctx gpu anaconda env mxnet lib python site packag mxnet ndarrai ndarrai on shape ctx dtype kwarg dtype real dtype dtype pylint disabl member protect access return intern on shape shape ctx ctx dtype dtype kwarg pylint enabl member protect access anaconda env mxnet lib python site packag mxnet ndarrai regist on shape ctx dtype kwarg anaconda env mxnet lib python site packag mxnet ctype ndarrai imper invok handl ndarg kei val str arrai kei str arrai str val ctype byref stype origin output anaconda env mxnet lib python site packag mxnet base check ret ret rais mxneterror str lib mxgetlasterror mxneterror src imper imper oper on implement gpu stack trace return entri home user anaconda env mxnet lib python site packag mxnet libmxnet xda xfca home user anaconda env mxnet lib python site packag mxnet libmxnet xdbc xfcbc home user anaconda env mxnet lib python site packag mxnet libmxnet mxnet imper invokeop mxnet context const nnvm nodeattr const std vector const std vector const std vector const mxnet dispatchmod mxnet opstateptr xfb xfbbabb home user anaconda env mxnet lib python site packag mxnet libmxnet mxnet imper invok mxnet context const nnvm nodeattr const std vector const std vector const xfbbc home user anaconda env mxnet lib python site packag mxnet libmxnet xfab home user anaconda env mxnet lib python site packag mxnet libmxnet mximperativeinvokeex xfabff home user anaconda env mxnet lib python lib dynload libffi ffi unix xfdefec home user anaconda env mxnet lib python lib dynload libffi ffi xfdefd home user anaconda env mxnet lib python lib dynload ctype cpython linux gnu ctype callproc xce xfdbee home user anaconda env mxnet lib python lib dynload ctype cpython linux gnu xfdb environ run aw instanc xlarg gluont version instal pip kernel conda mxnet",
        "Issue_preprocessed_content":"problem gpu descript aw abl run exampl script gpu reproduc start instanc past slightli modifi script modif specifi context work fine cpu gluont gluont environ aw instanc gluont version pip kernel",
        "Issue_gpt_summary_original":"the user encountered a challenge where the conda environment for python3.6 in notebooks could not find `pandas.csvdataset`, resulting in an error when running `context.catalog.list()`.",
        "Issue_gpt_summary":"user encount challeng conda environ python notebook panda csvdataset result error run context catalog list",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/kedro-org\/kedro\/issues\/308",
        "Issue_title":"Sagemaker notebooks raise error for `pandas.CSVDataSet`",
        "Issue_created_time":1585713762000,
        "Issue_closed_time":1585791347000,
        "Issue_body":"## Description\r\nThe conda environment for python3.6 in notebooks cannot find `pandas.CSVDataSet`\r\n\r\n## Context\r\nI'm wanting to use sagemaker as my development environment. However, I cannot get kedro to run as expected in both the notebooks (for exploration and node development) and the terminal (for running pipelines).\r\n\r\n## Steps to Reproduce\r\n\r\n0. Startup a Sagemaker instance with defaults\r\n\r\nTerminal success:\r\n\r\n1. `pip install kedro` in the terminal\r\n2. `kedro new`\r\n2a. `testing` for name\r\n2b. `y` for example project\r\n3. `cd testing; kedro run` => Success!\r\n\r\nNotebook fail:\r\n1. Create a new `conda_python3` notebook in `testing\/notebooks\/`\r\n2. `!pip install kedro` in a notebook \r\n> The environments for the terminal and notebooks are separate by design in Sagemaker\r\n2. Load the kedro context as described [here](https:\/\/kedro.readthedocs.io\/en\/stable\/04_user_guide\/11_ipython.html#what-if-i-cannot-run-kedro-jupyter-notebook) \r\n> Note that I've started to use the code below; Without checking if `current_dir` exists, you need to restart the kernel if you want to reload the context as something in the last 2 lines of code causes the next invocation of `Path.cwd()` to point to the root dir not `notebook\/`, as intended.\r\n```\r\nif \"current_dir\" not in locals():\r\n    # Check it exists first. For some reason this is not an idempotent operation?\r\n    current_dir = Path.cwd()  # this points to 'notebooks\/' folder\r\nproj_path = current_dir.parent  # point back to the root of the project\r\ncontext = load_context(proj_path)\r\n```\r\n3. Run `context.catalog.list()`\r\n\r\n## Expected Result\r\nThe notebook should print:\r\n```\r\n['example_iris_data',\r\n 'parameters',\r\n 'params:example_test_data_ratio',\r\n 'params:example_num_train_iter',\r\n 'params:example_learning_rate']\r\n```\r\n\r\n## Actual Result\r\n```\r\nClass `pandas.CSVDataSet` not found.\r\n```\r\n\r\nFull trace.\r\n```\r\n---------------------------------------------------------------------------\r\nStopIteration                             Traceback (most recent call last)\r\n~\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/kedro\/io\/core.py in parse_dataset_definition(config, load_version, save_version)\r\n    416         try:\r\n--> 417             class_obj = next(obj for obj in trials if obj is not None)\r\n    418         except StopIteration:\r\n\r\nStopIteration: \r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nDataSetError                              Traceback (most recent call last)\r\n~\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/kedro\/io\/core.py in from_config(cls, name, config, load_version, save_version)\r\n    148             class_obj, config = parse_dataset_definition(\r\n--> 149                 config, load_version, save_version\r\n    150             )\r\n\r\n~\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/kedro\/io\/core.py in parse_dataset_definition(config, load_version, save_version)\r\n    418         except StopIteration:\r\n--> 419             raise DataSetError(\"Class `{}` not found.\".format(class_obj))\r\n    420 \r\n\r\nDataSetError: Class `pandas.CSVDataSet` not found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nDataSetError                              Traceback (most recent call last)\r\n<ipython-input-4-5848382c8bb9> in <module>()\r\n----> 1 context.catalog.list()\r\n\r\n~\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/kedro\/context\/context.py in catalog(self)\r\n    206 \r\n    207         \"\"\"\r\n--> 208         return self._get_catalog()\r\n    209 \r\n    210     @property\r\n\r\n~\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/kedro\/context\/context.py in _get_catalog(self, save_version, journal, load_versions)\r\n    243         conf_creds = self._get_config_credentials()\r\n    244         catalog = self._create_catalog(\r\n--> 245             conf_catalog, conf_creds, save_version, journal, load_versions\r\n    246         )\r\n    247         catalog.add_feed_dict(self._get_feed_dict())\r\n\r\n~\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/kedro\/context\/context.py in _create_catalog(self, conf_catalog, conf_creds, save_version, journal, load_versions)\r\n    267             save_version=save_version,\r\n    268             journal=journal,\r\n--> 269             load_versions=load_versions,\r\n    270         )\r\n    271 \r\n\r\n~\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/kedro\/io\/data_catalog.py in from_config(cls, catalog, credentials, load_versions, save_version, journal)\r\n    298             ds_config = _resolve_credentials(ds_config, credentials)\r\n    299             data_sets[ds_name] = AbstractDataSet.from_config(\r\n--> 300                 ds_name, ds_config, load_versions.get(ds_name), save_version\r\n    301             )\r\n    302         return cls(data_sets=data_sets, journal=journal)\r\n\r\n~\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/kedro\/io\/core.py in from_config(cls, name, config, load_version, save_version)\r\n    152             raise DataSetError(\r\n    153                 \"An exception occurred when parsing config \"\r\n--> 154                 \"for DataSet `{}`:\\n{}\".format(name, str(ex))\r\n    155             )\r\n    156 \r\n\r\nDataSetError: An exception occurred when parsing config for DataSet `example_iris_data`:\r\nClass `pandas.CSVDataSet` not found.\r\n```\r\n\r\n## Investigations so far\r\n\r\n### `CSVLocalDataSet`\r\nUpon changing the yaml type for iris.csv from `pandas.CSVDataSet` to `CSVLocalDataSet`, we get success on both the terminal and the notebook. However, this is not my desired outcome; The transition to using `pandas.CSVDataSet` makes it easier, for me at least, to use both S3 and local datasets.\r\n\r\n### `pip install kedro` output from notebook\r\n```\r\nCollecting kedro\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/67\/6f\/4faaa0e58728a318aeabc490271a636f87f6b9165245ce1d3adc764240cf\/kedro-0.15.8-py3-none-any.whl (12.5MB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 12.5MB 4.1MB\/s eta 0:00:01\r\nRequirement already satisfied: xlsxwriter<2.0,>=1.0.0 in \/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages (from kedro) (1.0.4)\r\nCollecting azure-storage-file<2.0,>=1.1.0 (from kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/c9\/33\/6c611563412ffc409b2413ac50e3a063133ea235b86c137759774c77f3ad\/azure_storage_file-1.4.0-py2.py3-none-any.whl\r\nCollecting fsspec<1.0,>=0.5.1 (from kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/6e\/2b\/63420d49d5e5f885451429e9e0f40ad1787eed0d32b1aedd6b10f9c2719a\/fsspec-0.7.1-py3-none-any.whl (66kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 71kB 33.5MB\/s ta 0:00:01\r\nRequirement already satisfied: pandas<1.0,>=0.24.0 in \/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages (from kedro) (0.24.2)\r\nCollecting s3fs<1.0,>=0.3.0 (from kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/b8\/e4\/b8fc59248399d2482b39340ec9be4bb2493846ac23641b43115a7e5cd675\/s3fs-0.4.2-py3-none-any.whl\r\nRequirement already satisfied: PyYAML<6.0,>=4.2 in \/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages (from kedro) (5.3.1)\r\nCollecting tables<3.6,>=3.4.4 (from kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/87\/f7\/bb0ec32a3f3dd74143a3108fbf737e6dcfd47f0ffd61b52af7106ab7a38a\/tables-3.5.2-cp36-cp36m-manylinux1_x86_64.whl (4.3MB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4.3MB 10.2MB\/s ta 0:00:01\r\nRequirement already satisfied: requests<3.0,>=2.20.0 in \/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages (from kedro) (2.20.0)\r\nCollecting toposort<2.0,>=1.5 (from kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/e9\/8a\/321cd8ea5f4a22a06e3ba30ef31ec33bea11a3443eeb1d89807640ee6ed4\/toposort-1.5-py2.py3-none-any.whl\r\nRequirement already satisfied: click<8.0 in \/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages (from kedro) (6.7)\r\nCollecting azure-storage-queue<2.0,>=1.1.0 (from kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/72\/94\/4db044f1c155b40c5ebc037bfd9d1c24562845692c06798fbe869fe160e6\/azure_storage_queue-1.4.0-py2.py3-none-any.whl\r\nCollecting cookiecutter<2.0,>=1.6.0 (from kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/86\/c9\/7184edfb0e89abedc37211743d1420810f6b49ae4fa695dfc443c273470d\/cookiecutter-1.7.0-py2.py3-none-any.whl (40kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40kB 24.6MB\/s ta 0:00:01\r\nCollecting pandas-gbq<1.0,>=0.12.0 (from kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/c3\/74\/126408f6bdb7b2cb1dcb8c6e4bd69a511a7f85792d686d1237d9825e6194\/pandas_gbq-0.13.1-py3-none-any.whl\r\nCollecting pip-tools<5.0.0,>=4.0.0 (from kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/94\/8f\/59495d651f3ced9b06b69545756a27296861a6edd6c5709fbe1265ed9032\/pip_tools-4.5.1-py2.py3-none-any.whl (41kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51kB 27.5MB\/s ta 0:00:01\r\nCollecting azure-storage-blob<2.0,>=1.1.0 (from kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/25\/f4\/a307ed89014e9abb5c5cfc8ca7f8f797d12f619f17a6059a6fd4b153b5d0\/azure_storage_blob-1.5.0-py2.py3-none-any.whl (75kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 81kB 35.2MB\/s ta 0:00:01\r\nCollecting pyarrow<1.0.0,>=0.12.0 (from kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/ba\/10\/93fad5849418eade4a4cd581f8cd27be1bbe51e18968ba1492140c887f3f\/pyarrow-0.16.0-cp36-cp36m-manylinux1_x86_64.whl (62.9MB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 62.9MB 779kB\/s eta 0:00:01    40% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                   | 25.7MB 56.1MB\/s eta 0:00:01\r\nRequirement already satisfied: SQLAlchemy<2.0,>=1.2.0 in \/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages (from kedro) (1.2.11)\r\nRequirement already satisfied: xlrd<2.0,>=1.0.0 in \/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages (from kedro) (1.1.0)\r\nCollecting python-json-logger<1.0,>=0.1.9 (from kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/80\/9d\/1c3393a6067716e04e6fcef95104c8426d262b4adaf18d7aa2470eab028d\/python-json-logger-0.1.11.tar.gz\r\nCollecting anyconfig<1.0,>=0.9.7 (from kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/4c\/00\/cc525eb0240b6ef196b98300d505114339bbb7ddd68e3155483f1eb32050\/anyconfig-0.9.10.tar.gz (103kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 112kB 34.4MB\/s ta 0:00:01\r\nCollecting azure-storage-common~=1.4 (from azure-storage-file<2.0,>=1.1.0->kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/05\/6c\/b2285bf3687768dbf61b6bc085b0c1be2893b6e2757a9d023263764177f3\/azure_storage_common-1.4.2-py2.py3-none-any.whl (47kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51kB 25.9MB\/s ta 0:00:01\r\nCollecting azure-common>=1.1.5 (from azure-storage-file<2.0,>=1.1.0->kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/e5\/4d\/d000fc3c5af601d00d55750b71da5c231fcb128f42ac95b208ed1091c2c1\/azure_common-1.1.25-py2.py3-none-any.whl\r\nRequirement already satisfied: python-dateutil>=2.5.0 in \/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages (from pandas<1.0,>=0.24.0->kedro) (2.7.3)\r\nRequirement already satisfied: numpy>=1.12.0 in \/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages (from pandas<1.0,>=0.24.0->kedro) (1.14.3)\r\nRequirement already satisfied: pytz>=2011k in \/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages (from pandas<1.0,>=0.24.0->kedro) (2018.4)\r\nRequirement already satisfied: botocore>=1.12.91 in \/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages (from s3fs<1.0,>=0.3.0->kedro) (1.15.27)\r\nRequirement already satisfied: mock>=2.0 in \/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages (from tables<3.6,>=3.4.4->kedro) (4.0.1)\r\nRequirement already satisfied: numexpr>=2.6.2 in \/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages (from tables<3.6,>=3.4.4->kedro) (2.6.5)\r\nRequirement already satisfied: six>=1.9.0 in \/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages (from tables<3.6,>=3.4.4->kedro) (1.11.0)\r\nRequirement already satisfied: certifi>=2017.4.17 in \/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages (from requests<3.0,>=2.20.0->kedro) (2019.11.28)\r\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in \/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages (from requests<3.0,>=2.20.0->kedro) (3.0.4)\r\nRequirement already satisfied: urllib3<1.25,>=1.21.1 in \/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages (from requests<3.0,>=2.20.0->kedro) (1.23)\r\nRequirement already satisfied: idna<2.8,>=2.5 in \/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages (from requests<3.0,>=2.20.0->kedro) (2.6)\r\nCollecting whichcraft>=0.4.0 (from cookiecutter<2.0,>=1.6.0->kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/b5\/a2\/81887a0dae2e4d2adc70d9a3557fdda969f863ced51cd3c47b587d25bce5\/whichcraft-0.6.1-py2.py3-none-any.whl\r\nCollecting future>=0.15.2 (from cookiecutter<2.0,>=1.6.0->kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/45\/0b\/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9\/future-0.18.2.tar.gz (829kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 829kB 27.8MB\/s ta 0:00:01\r\nCollecting poyo>=0.1.0 (from cookiecutter<2.0,>=1.6.0->kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/42\/50\/0b0820601bde2eda403f47b9a4a1f270098ed0dd4c00c443d883164bdccc\/poyo-0.5.0-py2.py3-none-any.whl\r\nCollecting binaryornot>=0.2.0 (from cookiecutter<2.0,>=1.6.0->kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/24\/7e\/f7b6f453e6481d1e233540262ccbfcf89adcd43606f44a028d7f5fae5eb2\/binaryornot-0.4.4-py2.py3-none-any.whl\r\nCollecting jinja2-time>=0.1.0 (from cookiecutter<2.0,>=1.6.0->kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/6a\/a1\/d44fa38306ffa34a7e1af09632b158e13ec89670ce491f8a15af3ebcb4e4\/jinja2_time-0.2.0-py2.py3-none-any.whl\r\nRequirement already satisfied: jinja2>=2.7 in \/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages (from cookiecutter<2.0,>=1.6.0->kedro) (2.10)\r\nCollecting google-auth-oauthlib (from pandas-gbq<1.0,>=0.12.0->kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/7b\/b8\/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b\/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\r\nCollecting google-auth (from pandas-gbq<1.0,>=0.12.0->kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/05\/b0\/cc391ebf8ebf7855cdcfe0a9a4cdc8dcd90287c90e1ac22651d104ac6481\/google_auth-1.12.0-py2.py3-none-any.whl (83kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 92kB 35.5MB\/s ta 0:00:01\r\nCollecting pydata-google-auth (from pandas-gbq<1.0,>=0.12.0->kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/87\/ed\/9c9f410c032645632de787b8c285a78496bd89590c777385b921eb89433d\/pydata_google_auth-0.3.0-py2.py3-none-any.whl\r\nRequirement already satisfied: setuptools in \/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages (from pandas-gbq<1.0,>=0.12.0->kedro) (39.1.0)\r\nCollecting google-cloud-bigquery>=1.11.1 (from pandas-gbq<1.0,>=0.12.0->kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/8f\/f7\/b6f55e144da37f38a79552a06103f2df4a9569e2dfc6d741a7e2a63d3592\/google_cloud_bigquery-1.24.0-py2.py3-none-any.whl (165kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 174kB 39.2MB\/s ta 0:00:01\r\nRequirement already satisfied: cryptography in \/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages (from azure-storage-common~=1.4->azure-storage-file<2.0,>=1.1.0->kedro) (2.8)\r\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in \/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages (from botocore>=1.12.91->s3fs<1.0,>=0.3.0->kedro) (0.9.4)\r\nRequirement already satisfied: docutils<0.16,>=0.10 in \/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages (from botocore>=1.12.91->s3fs<1.0,>=0.3.0->kedro) (0.14)\r\nCollecting arrow (from jinja2-time>=0.1.0->cookiecutter<2.0,>=1.6.0->kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/92\/fa\/f84896dede5decf284e6922134bf03fd26c90870bbf8015f4e8ee2a07bcc\/arrow-0.15.5-py2.py3-none-any.whl (46kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51kB 26.3MB\/s ta 0:00:01\r\nRequirement already satisfied: MarkupSafe>=0.23 in \/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages (from jinja2>=2.7->cookiecutter<2.0,>=1.6.0->kedro) (1.0)\r\nCollecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib->pandas-gbq<1.0,>=0.12.0->kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/a3\/12\/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379\/requests_oauthlib-1.3.0-py2.py3-none-any.whl\r\nCollecting pyasn1-modules>=0.2.1 (from google-auth->pandas-gbq<1.0,>=0.12.0->kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/95\/de\/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d\/pyasn1_modules-0.2.8-py2.py3-none-any.whl (155kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 163kB 32.5MB\/s ta 0:00:01\r\nRequirement already satisfied: rsa<4.1,>=3.1.4 in \/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages (from google-auth->pandas-gbq<1.0,>=0.12.0->kedro) (3.4.2)\r\nCollecting cachetools<5.0,>=2.0.0 (from google-auth->pandas-gbq<1.0,>=0.12.0->kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/08\/6a\/abf83cb951617793fd49c98cb9456860f5df66ff89883c8660aa0672d425\/cachetools-4.0.0-py3-none-any.whl\r\nCollecting google-api-core<2.0dev,>=1.15.0 (from google-cloud-bigquery>=1.11.1->pandas-gbq<1.0,>=0.12.0->kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/63\/7e\/a523169b0cc9ce62d56e07571db927286a94b1a5f51ac220bd97db825c77\/google_api_core-1.16.0-py2.py3-none-any.whl (70kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 71kB 29.9MB\/s ta 0:00:01\r\nCollecting google-cloud-core<2.0dev,>=1.1.0 (from google-cloud-bigquery>=1.11.1->pandas-gbq<1.0,>=0.12.0->kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/89\/3c\/8a7531839028c9690e6d14c650521f3bbaf26e53baaeb2784b8c3eb2fb97\/google_cloud_core-1.3.0-py2.py3-none-any.whl\r\nRequirement already satisfied: protobuf>=3.6.0 in \/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages (from google-cloud-bigquery>=1.11.1->pandas-gbq<1.0,>=0.12.0->kedro) (3.6.1)\r\nCollecting google-resumable-media<0.6dev,>=0.5.0 (from google-cloud-bigquery>=1.11.1->pandas-gbq<1.0,>=0.12.0->kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/35\/9e\/f73325d0466ce5bdc36333f1aeb2892ead7b76e79bdb5c8b0493961fa098\/google_resumable_media-0.5.0-py2.py3-none-any.whl\r\nRequirement already satisfied: cffi!=1.11.3,>=1.8 in \/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages (from cryptography->azure-storage-common~=1.4->azure-storage-file<2.0,>=1.1.0->kedro) (1.11.5)\r\nCollecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib->pandas-gbq<1.0,>=0.12.0->kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/05\/57\/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704\/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 153kB 42.0MB\/s ta 0:00:01\r\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in \/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages (from pyasn1-modules>=0.2.1->google-auth->pandas-gbq<1.0,>=0.12.0->kedro) (0.4.8)\r\nCollecting googleapis-common-protos<2.0dev,>=1.6.0 (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery>=1.11.1->pandas-gbq<1.0,>=0.12.0->kedro)\r\n  Downloading https:\/\/files.pythonhosted.org\/packages\/05\/46\/168fd780f594a4d61122f7f3dc0561686084319ad73b4febbf02ae8b32cf\/googleapis-common-protos-1.51.0.tar.gz\r\nRequirement already satisfied: pycparser in \/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages (from cffi!=1.11.3,>=1.8->cryptography->azure-storage-common~=1.4->azure-storage-file<2.0,>=1.1.0->kedro) (2.18)\r\nBuilding wheels for collected packages: python-json-logger, anyconfig, future, googleapis-common-protos\r\n  Running setup.py bdist_wheel for python-json-logger ... done\r\n  Stored in directory: \/home\/ec2-user\/.cache\/pip\/wheels\/97\/f7\/a1\/752e22bb30c1cfe38194ea0070a5c66e76ef4d06ad0c7dc401\r\n  Running setup.py bdist_wheel for anyconfig ... done\r\n  Stored in directory: \/home\/ec2-user\/.cache\/pip\/wheels\/5a\/82\/0d\/e374b7c77f4e4aa846a9bc2057e1d108c7f8e6b97a383befc9\r\n  Running setup.py bdist_wheel for future ... done\r\n  Stored in directory: \/home\/ec2-user\/.cache\/pip\/wheels\/8b\/99\/a0\/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\r\n  Running setup.py bdist_wheel for googleapis-common-protos ... done\r\n  Stored in directory: \/home\/ec2-user\/.cache\/pip\/wheels\/2c\/f9\/7f\/6eb87e636072bf467e25348bbeb96849333e6a080dca78f706\r\nSuccessfully built python-json-logger anyconfig future googleapis-common-protos\r\ncookiecutter 1.7.0 has requirement click>=7.0, but you'll have click 6.7 which is incompatible.\r\ngoogle-auth 1.12.0 has requirement setuptools>=40.3.0, but you'll have setuptools 39.1.0 which is incompatible.\r\ngoogle-cloud-bigquery 1.24.0 has requirement six<2.0.0dev,>=1.13.0, but you'll have six 1.11.0 which is incompatible.\r\npip-tools 4.5.1 has requirement click>=7, but you'll have click 6.7 which is incompatible.\r\nInstalling collected packages: azure-common, azure-storage-common, azure-storage-file, fsspec, s3fs, tables, toposort, azure-storage-queue, whichcraft, future, poyo, binaryornot, arrow, jinja2-time, cookiecutter, pyasn1-modules, cachetools, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, pydata-google-auth, googleapis-common-protos, google-api-core, google-cloud-core, google-resumable-media, google-cloud-bigquery, pandas-gbq, pip-tools, azure-storage-blob, pyarrow, python-json-logger, anyconfig, kedro\r\n  Found existing installation: s3fs 0.1.5\r\n    Uninstalling s3fs-0.1.5:\r\n      Successfully uninstalled s3fs-0.1.5\r\n  Found existing installation: tables 3.4.3\r\n    Uninstalling tables-3.4.3:\r\n      Successfully uninstalled tables-3.4.3\r\nSuccessfully installed anyconfig-0.9.10 arrow-0.15.5 azure-common-1.1.25 azure-storage-blob-1.5.0 azure-storage-common-1.4.2 azure-storage-file-1.4.0 azure-storage-queue-1.4.0 binaryornot-0.4.4 cachetools-4.0.0 cookiecutter-1.7.0 fsspec-0.7.1 future-0.18.2 google-api-core-1.16.0 google-auth-1.12.0 google-auth-oauthlib-0.4.1 google-cloud-bigquery-1.24.0 google-cloud-core-1.3.0 google-resumable-media-0.5.0 googleapis-common-protos-1.51.0 jinja2-time-0.2.0 kedro-0.15.8 oauthlib-3.1.0 pandas-gbq-0.13.1 pip-tools-4.5.1 poyo-0.5.0 pyarrow-0.16.0 pyasn1-modules-0.2.8 pydata-google-auth-0.3.0 python-json-logger-0.1.11 requests-oauthlib-1.3.0 s3fs-0.4.2 tables-3.5.2 toposort-1.5 whichcraft-0.6.1\r\n```\r\n\r\n### `pip install kedro` output from terminal\r\n```\r\nCollecting kedro\r\n  Using cached kedro-0.15.8-py3-none-any.whl (12.5 MB)\r\nCollecting pandas<1.0,>=0.24.0\r\n  Downloading pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10.4 MB 9.6 MB\/s \r\nCollecting azure-storage-file<2.0,>=1.1.0\r\n  Using cached azure_storage_file-1.4.0-py2.py3-none-any.whl (30 kB)\r\nCollecting click<8.0\r\n  Downloading click-7.1.1-py2.py3-none-any.whl (82 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 82 kB 1.7 MB\/s \r\nCollecting cookiecutter<2.0,>=1.6.0\r\n  Using cached cookiecutter-1.7.0-py2.py3-none-any.whl (40 kB)\r\nCollecting SQLAlchemy<2.0,>=1.2.0\r\n  Downloading SQLAlchemy-1.3.15.tar.gz (6.1 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6.1 MB 49.2 MB\/s \r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n    Preparing wheel metadata ... done\r\nCollecting tables<3.6,>=3.4.4\r\n  Using cached tables-3.5.2-cp36-cp36m-manylinux1_x86_64.whl (4.3 MB)\r\nProcessing \/home\/ec2-user\/.cache\/pip\/wheels\/97\/f7\/a1\/752e22bb30c1cfe38194ea0070a5c66e76ef4d06ad0c7dc401\/python_json_logger-0.1.11-py2.py3-none-any.whl\r\nCollecting azure-storage-blob<2.0,>=1.1.0\r\n  Using cached azure_storage_blob-1.5.0-py2.py3-none-any.whl (75 kB)\r\nCollecting pandas-gbq<1.0,>=0.12.0\r\n  Using cached pandas_gbq-0.13.1-py3-none-any.whl (23 kB)\r\nRequirement already satisfied: fsspec<1.0,>=0.5.1 in \/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.6\/site-packages (from kedro) (0.6.3)\r\nCollecting xlsxwriter<2.0,>=1.0.0\r\n  Downloading XlsxWriter-1.2.8-py2.py3-none-any.whl (141 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 141 kB 65.9 MB\/s \r\nCollecting pip-tools<5.0.0,>=4.0.0\r\n  Using cached pip_tools-4.5.1-py2.py3-none-any.whl (41 kB)\r\nCollecting pyarrow<1.0.0,>=0.12.0\r\n  Downloading pyarrow-0.16.0-cp36-cp36m-manylinux2014_x86_64.whl (63.1 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 63.1 MB 25 kB\/s \r\nCollecting xlrd<2.0,>=1.0.0\r\n  Downloading xlrd-1.2.0-py2.py3-none-any.whl (103 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 103 kB 66.5 MB\/s \r\nRequirement already satisfied: s3fs<1.0,>=0.3.0 in \/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.6\/site-packages (from kedro) (0.4.0)\r\nCollecting azure-storage-queue<2.0,>=1.1.0\r\n  Using cached azure_storage_queue-1.4.0-py2.py3-none-any.whl (23 kB)\r\nProcessing \/home\/ec2-user\/.cache\/pip\/wheels\/5a\/82\/0d\/e374b7c77f4e4aa846a9bc2057e1d108c7f8e6b97a383befc9\/anyconfig-0.9.10-py2.py3-none-any.whl\r\nCollecting toposort<2.0,>=1.5\r\n  Using cached toposort-1.5-py2.py3-none-any.whl (7.6 kB)\r\nRequirement already satisfied: PyYAML<6.0,>=4.2 in \/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.6\/site-packages (from kedro) (5.3.1)\r\nRequirement already satisfied: requests<3.0,>=2.20.0 in \/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.6\/site-packages (from kedro) (2.23.0)\r\nRequirement already satisfied: pytz>=2017.2 in \/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.6\/site-packages (from pandas<1.0,>=0.24.0->kedro) (2019.3)\r\nRequirement already satisfied: numpy>=1.13.3 in \/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.6\/site-packages (from pandas<1.0,>=0.24.0->kedro) (1.18.1)\r\nRequirement already satisfied: python-dateutil>=2.6.1 in \/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.6\/site-packages (from pandas<1.0,>=0.24.0->kedro) (2.8.1)\r\nCollecting azure-common>=1.1.5\r\n  Using cached azure_common-1.1.25-py2.py3-none-any.whl (12 kB)\r\nCollecting azure-storage-common~=1.4\r\n  Using cached azure_storage_common-1.4.2-py2.py3-none-any.whl (47 kB)\r\nCollecting poyo>=0.1.0\r\n  Using cached poyo-0.5.0-py2.py3-none-any.whl (10 kB)\r\nCollecting jinja2-time>=0.1.0\r\n  Using cached jinja2_time-0.2.0-py2.py3-none-any.whl (6.4 kB)\r\nCollecting whichcraft>=0.4.0\r\n  Using cached whichcraft-0.6.1-py2.py3-none-any.whl (5.2 kB)\r\nCollecting binaryornot>=0.2.0\r\n  Using cached binaryornot-0.4.4-py2.py3-none-any.whl (9.0 kB)\r\nRequirement already satisfied: jinja2>=2.7 in \/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.6\/site-packages (from cookiecutter<2.0,>=1.6.0->kedro) (2.11.1)\r\nProcessing \/home\/ec2-user\/.cache\/pip\/wheels\/8b\/99\/a0\/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\/future-0.18.2-cp36-none-any.whl\r\nRequirement already satisfied: mock>=2.0 in \/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.6\/site-packages (from tables<3.6,>=3.4.4->kedro) (3.0.5)\r\nCollecting numexpr>=2.6.2\r\n  Downloading numexpr-2.7.1-cp36-cp36m-manylinux1_x86_64.whl (162 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 162 kB 66.7 MB\/s \r\nRequirement already satisfied: six>=1.9.0 in \/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.6\/site-packages (from tables<3.6,>=3.4.4->kedro) (1.14.0)\r\nCollecting pydata-google-auth\r\n  Using cached pydata_google_auth-0.3.0-py2.py3-none-any.whl (12 kB)\r\nCollecting google-auth-oauthlib\r\n  Using cached google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\r\nCollecting google-cloud-bigquery>=1.11.1\r\n  Using cached google_cloud_bigquery-1.24.0-py2.py3-none-any.whl (165 kB)\r\nCollecting google-auth\r\n  Using cached google_auth-1.12.0-py2.py3-none-any.whl (83 kB)\r\nRequirement already satisfied: setuptools in \/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.6\/site-packages (from pandas-gbq<1.0,>=0.12.0->kedro) (46.1.1.post20200323)\r\nRequirement already satisfied: boto3>=1.9.91 in \/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.6\/site-packages (from s3fs<1.0,>=0.3.0->kedro) (1.12.27)\r\nRequirement already satisfied: botocore>=1.12.91 in \/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.6\/site-packages (from s3fs<1.0,>=0.3.0->kedro) (1.15.27)\r\nRequirement already satisfied: idna<3,>=2.5 in \/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.6\/site-packages (from requests<3.0,>=2.20.0->kedro) (2.9)\r\nRequirement already satisfied: chardet<4,>=3.0.2 in \/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.6\/site-packages (from requests<3.0,>=2.20.0->kedro) (3.0.4)\r\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in \/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.6\/site-packages (from requests<3.0,>=2.20.0->kedro) (1.22)\r\nRequirement already satisfied: certifi>=2017.4.17 in \/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.6\/site-packages (from requests<3.0,>=2.20.0->kedro) (2019.11.28)\r\nRequirement already satisfied: cryptography in \/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.6\/site-packages (from azure-storage-common~=1.4->azure-storage-file<2.0,>=1.1.0->kedro) (2.8)\r\nCollecting arrow\r\n  Using cached arrow-0.15.5-py2.py3-none-any.whl (46 kB)\r\nRequirement already satisfied: MarkupSafe>=0.23 in \/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.6\/site-packages (from jinja2>=2.7->cookiecutter<2.0,>=1.6.0->kedro) (1.1.1)\r\nCollecting requests-oauthlib>=0.7.0\r\n  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\r\nCollecting google-resumable-media<0.6dev,>=0.5.0\r\n  Using cached google_resumable_media-0.5.0-py2.py3-none-any.whl (38 kB)\r\nCollecting google-cloud-core<2.0dev,>=1.1.0\r\n  Using cached google_cloud_core-1.3.0-py2.py3-none-any.whl (26 kB)\r\nRequirement already satisfied: protobuf>=3.6.0 in \/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.6\/site-packages (from google-cloud-bigquery>=1.11.1->pandas-gbq<1.0,>=0.12.0->kedro) (3.11.3)\r\nCollecting google-api-core<2.0dev,>=1.15.0\r\n  Using cached google_api_core-1.16.0-py2.py3-none-any.whl (70 kB)\r\nCollecting pyasn1-modules>=0.2.1\r\n  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\r\nRequirement already satisfied: rsa<4.1,>=3.1.4 in \/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.6\/site-packages (from google-auth->pandas-gbq<1.0,>=0.12.0->kedro) (3.4.2)\r\nCollecting cachetools<5.0,>=2.0.0\r\n  Using cached cachetools-4.0.0-py3-none-any.whl (10 kB)\r\nRequirement already satisfied: s3transfer<0.4.0,>=0.3.0 in \/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.6\/site-packages (from boto3>=1.9.91->s3fs<1.0,>=0.3.0->kedro) (0.3.3)\r\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in \/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.6\/site-packages (from boto3>=1.9.91->s3fs<1.0,>=0.3.0->kedro) (0.9.4)\r\nRequirement already satisfied: docutils<0.16,>=0.10 in \/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.6\/site-packages (from botocore>=1.12.91->s3fs<1.0,>=0.3.0->kedro) (0.15.2)\r\nRequirement already satisfied: cffi!=1.11.3,>=1.8 in \/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.6\/site-packages (from cryptography->azure-storage-common~=1.4->azure-storage-file<2.0,>=1.1.0->kedro) (1.14.0)\r\nCollecting oauthlib>=3.0.0\r\n  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\r\nProcessing \/home\/ec2-user\/.cache\/pip\/wheels\/2c\/f9\/7f\/6eb87e636072bf467e25348bbeb96849333e6a080dca78f706\/googleapis_common_protos-1.51.0-cp36-none-any.whl\r\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in \/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.6\/site-packages (from pyasn1-modules>=0.2.1->google-auth->pandas-gbq<1.0,>=0.12.0->kedro) (0.4.8)\r\nRequirement already satisfied: pycparser in \/home\/ec2-user\/anaconda3\/envs\/JupyterSystemEnv\/lib\/python3.6\/site-packages (from cffi!=1.11.3,>=1.8->cryptography->azure-storage-common~=1.4->azure-storage-file<2.0,>=1.1.0->kedro) (2.20)\r\nBuilding wheels for collected packages: SQLAlchemy\r\n  Building wheel for SQLAlchemy (PEP 517) ... done\r\n  Created wheel for SQLAlchemy: filename=SQLAlchemy-1.3.15-cp36-cp36m-linux_x86_64.whl size=1215829 sha256=112167e02a19acada7f367d8aca55bbd1e0c655de9edfabebae5e9d055d9a9a6\r\n  Stored in directory: \/home\/ec2-user\/.cache\/pip\/wheels\/4a\/1b\/3a\/c73044d7be48baeb47cbee343334f7803726ca1e9ba7b29095\r\nSuccessfully built SQLAlchemy\r\nInstalling collected packages: pandas, azure-common, azure-storage-common, azure-storage-file, click, poyo, arrow, jinja2-time, whichcraft, binaryornot, future, cookiecutter, SQLAlchemy, numexpr, tables, python-json-logger, azure-storage-blob, pyasn1-modules, cachetools, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, pydata-google-auth, google-resumable-media, googleapis-common-protos, google-api-core, google-cloud-core, google-cloud-bigquery, pandas-gbq, xlsxwriter, pip-tools, pyarrow, xlrd, azure-storage-queue, anyconfig, toposort, kedro\r\n  Attempting uninstall: pandas\r\n    Found existing installation: pandas 0.22.0\r\n    Uninstalling pandas-0.22.0:\r\n      Successfully uninstalled pandas-0.22.0\r\nSuccessfully installed SQLAlchemy-1.3.15 anyconfig-0.9.10 arrow-0.15.5 azure-common-1.1.25 azure-storage-blob-1.5.0 azure-storage-common-1.4.2 azure-storage-file-1.4.0 azure-storage-queue-1.4.0 binaryornot-0.4.4 cachetools-4.0.0 click-7.1.1 cookiecutter-1.7.0 future-0.18.2 google-api-core-1.16.0 google-auth-1.12.0 google-auth-oauthlib-0.4.1 google-cloud-bigquery-1.24.0 google-cloud-core-1.3.0 google-resumable-media-0.5.0 googleapis-common-protos-1.51.0 jinja2-time-0.2.0 kedro-0.15.8 numexpr-2.7.1 oauthlib-3.1.0 pandas-0.25.3 pandas-gbq-0.13.1 pip-tools-4.5.1 poyo-0.5.0 pyarrow-0.16.0 pyasn1-modules-0.2.8 pydata-google-auth-0.3.0 python-json-logger-0.1.11 requests-oauthlib-1.3.0 tables-3.5.2 toposort-1.5 whichcraft-0.6.1 xlrd-1.2.0 xlsxwriter-1.2.8\r\n```\r\n\r\n## Your Environment\r\nInclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n|environment | terminal | notebook|\r\n|----|----|----|\r\n|`kedro -V` | kedro, version 0.15.8 | kedro, version 0.15.8|\r\n|`python -V` | Python 3.6.10 :: Anaconda, Inc. | Python 3.6.5 :: Anaconda, Inc.|\r\n|os |  `PRETTY_NAME=\"Amazon Linux AMI 2018.03\"\"` `ID_LIKE=\"rhel fedora\"` | `PRETTY_NAME=\"Amazon Linux AMI 2018.03\"\"` `ID_LIKE=\"rhel fedora\"`|\r\n|`pip freeze` | anyconfig==0.9.10<br>arrow==0.15.5<br>asn1crypto==1.3.0<br>attrs==19.3.0<br>autovizwidget==0.12.9<br>awscli==1.18.27<br>azure-common==1.1.25<br>azure-storage-blob==1.5.0<br>azure-storage-common==1.4.2<br>azure-storage-file==1.4.0<br>azure-storage-queue==1.4.0<br>backcall==0.1.0<br>bcrypt==3.1.7<br>binaryornot==0.4.4<br>bleach==3.1.0<br>boto3==1.12.27<br>botocore==1.15.27<br>cached-property==1.5.1<br>cachetools==4.0.0<br>certifi==2019.11.28<br>cffi==1.14.0<br>chardet==3.0.4<br>click==7.1.1<br>colorama==0.4.3<br>cookiecutter==1.7.0<br>cryptography==2.8<br>decorator==4.4.2<br>defusedxml==0.6.0<br>docker==4.2.0<br>docker-compose==1.25.4<br>dockerpty==0.4.1<br>docopt==0.6.2<br>docutils==0.15.2<br>entrypoints==0.3<br>environment-kernels==1.1.1<br>fsspec==0.6.3<br>future==0.18.2<br>gitdb==4.0.2<br>GitPython==3.1.0<br>google-api-core==1.16.0<br>google-auth==1.12.0<br>google-auth-oauthlib==0.4.1<br>google-cloud-bigquery==1.24.0<br>google-cloud-core==1.3.0<br>google-resumable-media==0.5.0<br>googleapis-common-protos==1.51.0<br>hdijupyterutils==0.12.9<br>idna==2.9<br>importlib-metadata==1.5.0<br>ipykernel==5.1.4<br>ipython==7.13.0<br>ipython-genutils==0.2.0<br>ipywidgets==7.5.1<br>jedi==0.16.0<br>Jinja2==2.11.1<br>jinja2-time==0.2.0<br>jmespath==0.9.4<br>json5==0.9.3<br>jsonschema==3.2.0<br>jupyter==1.0.0<br>jupyter-client==6.0.0<br>jupyter-console==6.1.0<br>jupyter-core==4.6.1<br>jupyterlab==1.2.7<br>jupyterlab-git==0.9.0<br>jupyterlab-server==1.0.7<br>kedro==0.15.8<br>MarkupSafe==1.1.1<br>mistune==0.8.4<br>mock==3.0.5<br>nb-conda==2.2.1<br>nb-conda-kernels==2.2.3<br>nbconvert==5.6.1<br>nbdime==2.0.0<br>nbexamples==0.0.0<br>nbformat==5.0.4<br>nbserverproxy==0.3.2<br>nose==1.3.7<br>notebook==5.7.8<br>numexpr==2.7.1<br>numpy==1.18.1<br>oauthlib==3.1.0<br>packaging==20.3<br>pandas==0.25.3<br>pandas-gbq==0.13.1<br>pandocfilters==1.4.2<br>paramiko==2.7.1<br>parso==0.6.2<br>pexpect==4.8.0<br>pickleshare==0.7.5<br>pid==3.0.0<br>pip-tools==4.5.1<br>plotly==4.5.4<br>poyo==0.5.0<br>prometheus-client==0.7.1<br>prompt-toolkit==3.0.3<br>protobuf==3.11.3<br>protobuf3-to-dict==0.1.5<br>psutil==5.7.0<br>psycopg2==2.8.4<br>ptyprocess==0.6.0<br>py4j==0.10.7<br>pyarrow==0.16.0<br>pyasn1==0.4.8<br>pyasn1-modules==0.2.8<br>pycparser==2.20<br>pydata-google-auth==0.3.0<br>pygal==2.4.0<br>Pygments==2.6.1<br>pykerberos==1.1.14<br>PyNaCl==1.3.0<br>pyOpenSSL==19.1.0<br>pyparsing==2.4.6<br>pyrsistent==0.15.7<br>PySocks==1.7.1<br>pyspark==2.3.2<br>python-dateutil==2.8.1<br>python-json-logger==0.1.11<br>pytz==2019.3<br>PyYAML==5.3.1<br>pyzmq==18.1.1<br>qtconsole==4.7.1<br>QtPy==1.9.0<br>requests==2.23.0<br>requests-kerberos==0.12.0<br>requests-oauthlib==1.3.0<br>retrying==1.3.3<br>rsa==3.4.2<br>s3fs==0.4.0<br>s3transfer==0.3.3<br>sagemaker==1.51.4<br>sagemaker-experiments==0.1.10<br>sagemaker-nbi-agent==1.0<br>sagemaker-pyspark==1.2.8<br>scipy==1.4.1<br>Send2Trash==1.5.0<br>six==1.14.0<br>smdebug-rulesconfig==0.1.2<br>smmap==3.0.1<br>sparkmagic==0.15.0<br>SQLAlchemy==1.3.15<br>tables==3.5.2<br>terminado==0.8.3<br>testpath==0.4.4<br>texttable==1.6.2<br>toposort==1.5<br>tornado==6.0.4<br>traitlets==4.3.3<br>urllib3==1.22<br>wcwidth==0.1.8<br>webencodings==0.5.1<br>websocket-client==0.57.0<br>whichcraft==0.6.1<br>widgetsnbextension==3.5.1<br>xlrd==1.2.0<br>XlsxWriter==1.2.8<br>zipp==2.2.0 | alabaster==0.7.10<br>anaconda-client==1.6.14<br>anaconda-project==0.8.2<br>anyconfig==0.9.10<br>arrow==0.15.5<br>asn1crypto==0.24.0<br>astroid==1.6.3<br>astropy==3.0.2<br>attrs==18.1.0<br>Automat==0.3.0<br>autovizwidget==0.15.0<br>awscli==1.18.27<br>azure-common==1.1.25<br>azure-storage-blob==1.5.0<br>azure-storage-common==1.4.2<br>azure-storage-file==1.4.0<br>azure-storage-queue==1.4.0<br>Babel==2.5.3<br>backcall==0.1.0<br>backports.shutil-get-terminal-size==1.0.0<br>bcrypt==3.1.7<br>beautifulsoup4==4.6.0<br>binaryornot==0.4.4<br>bitarray==0.8.1<br>bkcharts==0.2<br>blaze==0.11.3<br>bleach==2.1.3<br>bokeh==1.0.4<br>boto==2.48.0<br>boto3==1.12.27<br>botocore==1.15.27<br>Bottleneck==1.2.1<br>cached-property==1.5.1<br>cachetools==4.0.0<br>certifi==2019.11.28<br>cffi==1.11.5<br>characteristic==14.3.0<br>chardet==3.0.4<br>click==6.7<br>cloudpickle==0.5.3<br>clyent==1.2.2<br>colorama==0.3.9<br>contextlib2==0.5.5<br>cookiecutter==1.7.0<br>cryptography==2.8<br>cycler==0.10.0<br>Cython==0.28.4<br>cytoolz==0.9.0.1<br>dask==0.17.5<br>datashape==0.5.4<br>decorator==4.3.0<br>defusedxml==0.6.0<br>distributed==1.21.8<br>docker==4.2.0<br>docker-compose==1.25.4<br>dockerpty==0.4.1<br>docopt==0.6.2<br>docutils==0.14<br>entrypoints==0.2.3<br>enum34==1.1.9<br>environment-kernels==1.1.1<br>et-xmlfile==1.0.1<br>fastcache==1.0.2<br>filelock==3.0.4<br>Flask==1.0.2<br>Flask-Cors==3.0.4<br>fsspec==0.7.1<br>future==0.18.2<br>gevent==1.3.0<br>glob2==0.6<br>gmpy2==2.0.8<br>google-api-core==1.16.0<br>google-auth==1.12.0<br>google-auth-oauthlib==0.4.1<br>google-cloud-bigquery==1.24.0<br>google-cloud-core==1.3.0<br>google-resumable-media==0.5.0<br>googleapis-common-protos==1.51.0<br>greenlet==0.4.13<br>h5py==2.8.0<br>hdijupyterutils==0.15.0<br>heapdict==1.0.0<br>html5lib==1.0.1<br>idna==2.6<br>imageio==2.3.0<br>imagesize==1.0.0<br>importlib-metadata==1.5.0<br>ipykernel==4.8.2<br>ipyparallel==6.2.2<br>ipython==6.4.0<br>ipython-genutils==0.2.0<br>ipywidgets==7.4.0<br>isort==4.3.4<br>itsdangerous==0.24<br>jdcal==1.4<br>jedi==0.12.0<br>Jinja2==2.10<br>jinja2-time==0.2.0<br>jmespath==0.9.4<br>jsonschema==2.6.0<br>jupyter==1.0.0<br>jupyter-client==5.2.3<br>jupyter-console==5.2.0<br>jupyter-core==4.4.0<br>jupyterlab==0.32.1<br>jupyterlab-launcher==0.10.5<br>kedro==0.15.8<br>kiwisolver==1.0.1<br>lazy-object-proxy==1.3.1<br>llvmlite==0.23.1<br>locket==0.2.0<br>lxml==4.2.1<br>MarkupSafe==1.0<br>matplotlib==3.0.3<br>mccabe==0.6.1<br>mistune==0.8.3<br>mkl-fft==1.0.0<br>mkl-random==1.0.1<br>mock==4.0.1<br>more-itertools==4.1.0<br>mpmath==1.0.0<br>msgpack==0.6.0<br>msgpack-python==0.5.6<br>multipledispatch==0.5.0<br>nb-conda==2.2.1<br>nb-conda-kernels==2.2.2<br>nbconvert==5.4.1<br>nbformat==4.4.0<br>networkx==2.1<br>nltk==3.3<br>nose==1.3.7<br>notebook==5.5.0<br>numba==0.38.0<br>numexpr==2.6.5<br>numpy==1.14.3<br>numpydoc==0.8.0<br>oauthlib==3.1.0<br>odo==0.5.1<br>olefile==0.45.1<br>opencv-python==3.4.2.17<br>openpyxl==2.5.3<br>packaging==20.1<br>pandas==0.24.2<br>pandas-gbq==0.13.1<br>pandocfilters==1.4.2<br>paramiko==2.7.1<br>parso==0.2.0<br>partd==0.3.8<br>path.py==11.0.1<br>pathlib2==2.3.2<br>patsy==0.5.0<br>pep8==1.7.1<br>pexpect==4.5.0<br>pickleshare==0.7.4<br>Pillow==5.1.0<br>pip-tools==4.5.1<br>pkginfo==1.4.2<br>plotly==4.5.2<br>pluggy==0.6.0<br>ply==3.11<br>poyo==0.5.0<br>prompt-toolkit==1.0.15<br>protobuf==3.6.1<br>protobuf3-to-dict==0.1.5<br>psutil==5.4.5<br>psycopg2==2.7.5<br>ptyprocess==0.5.2<br>py==1.5.3<br>py4j==0.10.7<br>pyarrow==0.16.0<br>pyasn1==0.4.8<br>pyasn1-modules==0.2.8<br>pycodestyle==2.4.0<br>pycosat==0.6.3<br>pycparser==2.18<br>pycrypto==2.6.1<br>pycurl==7.43.0.1<br>pydata-google-auth==0.3.0<br>pyflakes==1.6.0<br>pygal==2.4.0<br>Pygments==2.2.0<br>pykerberos==1.2.1<br>pylint==1.8.4<br>PyNaCl==1.3.0<br>pyodbc==4.0.23<br>pyOpenSSL==18.0.0<br>pyparsing==2.2.0<br>PySocks==1.6.8<br>pyspark==2.3.2<br>pytest==3.5.1<br>pytest-arraydiff==0.2<br>pytest-astropy==0.3.0<br>pytest-doctestplus==0.1.3<br>pytest-openfiles==0.3.0<br>pytest-remotedata==0.2.1<br>python-dateutil==2.7.3<br>python-json-logger==0.1.11<br>pytz==2018.4<br>PyWavelets==0.5.2<br>PyYAML==5.3.1<br>pyzmq==17.0.0<br>QtAwesome==0.4.4<br>qtconsole==4.3.1<br>QtPy==1.4.1<br>requests==2.20.0<br>requests-kerberos==0.12.0<br>requests-oauthlib==1.3.0<br>retrying==1.3.3<br>rope==0.10.7<br>rsa==3.4.2<br>ruamel-yaml==0.15.35<br>s3fs==0.4.2<br>s3transfer==0.3.3<br>sagemaker==1.51.4<br>sagemaker-pyspark==1.2.8<br>scikit-image==0.13.1<br>scikit-learn==0.20.3<br>scipy==1.1.0<br>seaborn==0.8.1<br>Send2Trash==1.5.0<br>simplegeneric==0.8.1<br>singledispatch==3.4.0.3<br>six==1.11.0<br>smdebug-rulesconfig==0.1.2<br>snowballstemmer==1.2.1<br>sortedcollections==0.6.1<br>sortedcontainers==1.5.10<br>sparkmagic==0.12.5<br>Sphinx==1.7.4<br>sphinxcontrib-websupport==1.0.1<br>spyder==3.2.8<br>SQLAlchemy==1.2.11<br>statsmodels==0.9.0<br>sympy==1.1.1<br>tables==3.5.2<br>TBB==0.1<br>tblib==1.3.2<br>terminado==0.8.1<br>testpath==0.3.1<br>texttable==1.6.2<br>toolz==0.9.0<br>toposort==1.5<br>tornado==5.0.2<br>traitlets==4.3.2<br>typing==3.6.4<br>unicodecsv==0.14.1<br>urllib3==1.23<br>wcwidth==0.1.7<br>webencodings==0.5.1<br>websocket-client==0.57.0<br>Werkzeug==0.14.1<br>whichcraft==0.6.1<br>widgetsnbextension==3.4.2<br>wrapt==1.10.11<br>xlrd==1.1.0<br>XlsxWriter==1.0.4<br>xlwt==1.3.0<br>zict==0.1.3<br>zipp==3.0.0|\r\n",
        "Issue_answer_count":5,
        "Issue_self_closed":1.0,
        "Answer_body":"Kedro aside there are a couple of things that you can do to ensure that your environments match from the terminal vs notebook.  I am not familiar with the new `pandas.CSVDataSet` as I am just now starting with my first `0.15.8` myself.  We have struggled to get package installs correct through our notebooks, I make sure my team is all using their own environment, created from the terminal.\r\n\r\n## activate python3 from the terminal before install\r\n\r\nNote that the file browser on the left hand side of a SageMaker notebook is really mounted at `~\/SageMaker`.\r\n\r\n``` bash\r\nsource activate python3\r\n# may also be - conda activate python3\r\n# unrelated on windows it was - activate python 3\r\ncd ~\/SageMaker\/testing\/notebooks # this appears to be where your project is\r\nkedro install\r\n```\r\n## install ipykernel in your terminal env\r\n\r\nFor conda environments to show up in the notebook dropdown selection you will need `ipykernel` installed. see [docs](https:\/\/ipython.readthedocs.io\/en\/stable\/install\/kernel_install.html)\r\n\r\n```\r\nconda create -n testing python=3.6\r\npip install ipykernel\r\n# I typically don't have to go this far, but installing ipykernel is recommended by the docs\r\nipykernel install --user \r\ncd ~\/SageMaker\/testing\/notebooks # this appears to be where your project is\r\nkedro install\r\n```\r\n\r\n\r\nDo note that if you shut down your SageMaker notebook you will loose your packages and environments by default.\r\n\r\nI also noticed that you have a difference between pandas.  I have no idea if that changes things, but might be a simple fix. Your second idea worked @WaylonWalker. I slightly adapted it as it didn't work straight up:\r\n```\r\nconda create --yes --name kedroenv python=3.6 ipykernel\r\nsource activate kedroenv\r\npython -m ipykernel install --user --name kedroenv --display-name \"Kedro py3.6\"\r\n\r\ncd ~\/Sagemaker\r\nkedro new # Name testing and example pipeline\r\ncd testing\/\r\nkedro run\r\n```\r\nWith a reasonable solution, I'll call this issue closed. Massive thank you @WaylonWalker for pointing me in the right direction.\r\n\r\nCheers,\r\nTom @tjcuddihy We're working with the AWS team to produce a knowledge document on using Kedro and Sagemaker. Would we be able to talk to you about how you used them together? I'd be keen on learning more about how to make Sagemaker play nicely with kedro so I can still access everything I need from my kedro context. @yetudada I have an alpha version of a kedro plugin that plays nicely with sagemaker and allows you to run processing jobs. @uwaisiqbal then you might be interested in this knowledge article that was just published on AWS: https:\/\/aws.amazon.com\/blogs\/opensource\/using-kedro-pipelines-to-train-amazon-sagemaker-models\/ \ud83d\ude80 ",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"notebook rais error panda csvdataset descript conda environ python notebook panda csvdataset context want us develop environ run expect notebook explor node develop termin run pipelin step reproduc startup instanc default termin success pip instal termin new test exampl project test run success notebook fail creat new conda python notebook test notebook pip instal notebook environ termin notebook separ design load context describ http readthedoc stabl user guid ipython html run jupyt notebook note start us code check current dir exist need restart kernel want reload context line code caus invoc path cwd point root dir notebook intend current dir local check exist reason idempot oper current dir path cwd point notebook folder proj path current dir parent point root project context load context proj path run context catalog list expect result notebook print exampl iri data paramet param exampl test data ratio param exampl num train iter param exampl learn rate actual result class panda csvdataset trace stopiter traceback recent anaconda env python lib python site packag core pars dataset definit config load version save version try class obj obj obj trial obj stopiter stopiter handl except except occur dataseterror traceback recent anaconda env python lib python site packag core config cl config load version save version class obj config pars dataset definit config load version save version anaconda env python lib python site packag core pars dataset definit config load version save version stopiter rais dataseterror class format class obj dataseterror class panda csvdataset handl except except occur dataseterror traceback recent context catalog list anaconda env python lib python site packag context context catalog self return self catalog properti anaconda env python lib python site packag context context catalog self save version journal load version conf cred self config credenti catalog self creat catalog conf catalog conf cred save version journal load version catalog add feed dict self feed dict anaconda env python lib python site packag context context creat catalog self conf catalog conf cred save version journal load version save version save version journal journal load version load version anaconda env python lib python site packag data catalog config cl catalog credenti load version save version journal config resolv credenti config credenti data set abstractdataset config config load version save version return cl data set data set journal journal anaconda env python lib python site packag core config cl config load version save version rais dataseterror except occur pars config dataset format str dataseterror except occur pars config dataset exampl iri data class panda csvdataset investig far csvlocaldataset chang yaml type iri csv panda csvdataset csvlocaldataset success termin notebook desir outcom transit panda csvdataset make easier us local dataset pip instal output notebook collect download http file pythonhost org packag faaaeaaeabcaffbcedadccf whl eta requir satisfi xlsxwriter home user anaconda env python lib python site packag collect azur storag file download http file pythonhost org packag cffcbaceaeabccfad azur storag file whl collect fsspec download http file pythonhost org packag ddefeefadeeddbaeddbfca fsspec whl requir satisfi panda home user anaconda env python lib python site packag collect sf download http file pythonhost org packag bfcdbecbebbacbaecd sf whl requir satisfi pyyaml home user anaconda env python lib python site packag collect tabl download http file pythonhost org packag bbecafddafbfedcfdfffdbafabaa tabl cpm manylinux whl requir satisfi request home user anaconda env python lib python site packag collect toposort download http file pythonhost org packag cdeafaaebaefecbeaaeebdee toposort whl requir satisfi click download http file pythonhost org packag dbfcbcebcbfddccfbefe azur storag queue whl collect cookiecutt download http file pythonhost org packag edfbeabedcdfbaefadfccd cookiecutt whl collect panda gbq download http file pythonhost org packag fbdbbcbdcbcebdaafddd panda gbq whl collect pip tool download http file pythonhost org packag dfcedbbaaeddcfbe pip tool whl collect azur storag blob download http file pythonhost org packag aedeabbccfccaffdffaafdbbd azur storag blob whl collect pyarrow download http file pythonhost org packag fadeadeacdfcdbebbeebacff pyarrow cpm manylinux whl eta eta requir satisfi sqlalchemi home user anaconda env python lib python site packag requir satisfi xlrd home user anaconda env python lib python site packag collect python json logger download http file pythonhost org packag caeefcefcdbadafdaaeabd python json logger tar collect anyconfig download http file pythonhost org packag ccebbefbdbbbdddefeb anyconfig tar collect azur storag common azur storag file download http file pythonhost org packag bbfdbfbbcbcbebeadf azur storag common whl collect azur common azur storag file download http file pythonhost org packag dfccafddbdacfcbfacbedcc azur common whl requir satisfi python dateutil home user anaconda env python lib python site packag panda requir satisfi numpi home user anaconda env python lib python site packag panda requir satisfi pytz home user anaconda env python lib python site packag panda requir satisfi botocor home user anaconda env python lib python site packag sf requir satisfi mock home user anaconda env python lib python site packag tabl requir satisfi numexpr home user anaconda env python lib python site packag tabl requir satisfi home user anaconda env python lib python site packag tabl requir satisfi certifi home user anaconda env python lib python site packag request requir satisfi chardet home user anaconda env python lib python site packag request requir satisfi urllib home user anaconda env python lib python site packag request requir satisfi idna home user anaconda env python lib python site packag request collect whichcraft cookiecutt download http file pythonhost org packag adaeedadcdafddafcedcdcbdbc whichcraft whl collect futur cookiecutt download http file pythonhost org packag bfdbdcbdbfecbeddffdcfc futur tar collect poyo cookiecutt download http file pythonhost org packag bbdeedafbaafedddccdbdccc poyo whl collect binaryornot cookiecutt download http file pythonhost org packag fbfedeccbfcfadcdfadffaeeb binaryornot whl collect jinja time cookiecutt download http file pythonhost org packag dfaffaaeafbeeccefaafebcb jinja time whl requir satisfi jinja home user anaconda env python lib python site packag cookiecutt collect googl auth oauthlib panda gbq download http file pythonhost org packag defebeefcecfeeabfffaefb googl auth oauthlib whl collect googl auth panda gbq download http file pythonhost org packag ccebfebfcdcfeaacdcdcdceacdac googl auth whl collect pydata googl auth panda gbq download http file pythonhost org packag cfcdebcabdcbebd pydata googl auth whl requir satisfi setuptool home user anaconda env python lib python site packag panda gbq collect googl cloud bigqueri panda gbq download http file pythonhost org packag bfedafaafdfaedfcdaead googl cloud bigqueri whl requir satisfi cryptographi home user anaconda env python lib python site packag azur storag common azur storag file requir satisfi jmespath home user anaconda env python lib python site packag botocor sf requir satisfi docutil home user anaconda env python lib python site packag botocor sf collect arrow jinja time cookiecutt download http file pythonhost org packag fdededecfebffdcbbffeeeabcc arrow whl requir satisfi markupsaf home user anaconda env python lib python site packag jinja cookiecutt collect request oauthlib googl auth oauthlib panda gbq download http file pythonhost org packag bdabeaedfdfdbabddecfd request oauthlib whl collect pyasn modul googl auth panda gbq download http file pythonhost org packag aaecfaeadfcdaafbad pyasn modul whl requir satisfi rsa home user anaconda env python lib python site packag googl auth panda gbq collect cachetool googl auth panda gbq download http file pythonhost org packag abfcbfdccbfdfffcaad cachetool whl collect googl api core googl cloud bigqueri panda gbq download http file pythonhost org packag abcccededbabafacbddbc googl api core whl collect googl cloud core googl cloud bigqueri panda gbq download http file pythonhost org packag acedcfbbafebaaebbcebfb googl cloud core whl requir satisfi protobuf home user anaconda env python lib python site packag googl cloud bigqueri panda gbq collect googl resum media googl cloud bigqueri panda gbq download http file pythonhost org packag fdcebdcfaebeadbebdbcbfa googl resum media whl requir satisfi cffi home user anaconda env python lib python site packag cryptographi azur storag common azur storag file collect oauthlib request oauthlib googl auth oauthlib panda gbq download http file pythonhost org packag ceeafacafbababebdbceba oauthlib whl requir satisfi pyasn home user anaconda env python lib python site packag pyasn modul googl auth panda gbq collect googleapi common proto googl api core googl cloud bigqueri panda gbq download http file pythonhost org packag fdfadffdcadbfebbfaebcf googleapi common proto tar requir satisfi pycpars home user anaconda env python lib python site packag cffi cryptographi azur storag common azur storag file build wheel collect packag python json logger anyconfig futur googleapi common proto run setup bdist wheel python json logger store directori home user cach pip wheel ebbccfeeaaceefdadcdc run setup bdist wheel anyconfig store directori home user cach pip wheel ebcfeaaabcedcfebabefc run setup bdist wheel futur store directori home user cach pip wheel dafdcdabaabdfcb run setup bdist wheel googleapi common proto store directori home user cach pip wheel ebebfebbebeadcaf successfulli built python json logger anyconfig futur googleapi common proto cookiecutt requir click click incompat googl auth requir setuptool setuptool incompat googl cloud bigqueri requir incompat pip tool requir click click incompat instal collect packag azur common azur storag common azur storag file fsspec sf tabl toposort azur storag queue whichcraft futur poyo binaryornot arrow jinja time cookiecutt pyasn modul cachetool googl auth oauthlib request oauthlib googl auth oauthlib pydata googl auth googleapi common proto googl api core googl cloud core googl resum media googl cloud bigqueri panda gbq pip tool azur storag blob pyarrow python json logger anyconfig exist instal sf uninstal sf successfulli uninstal sf exist instal tabl uninstal tabl successfulli uninstal tabl successfulli instal anyconfig arrow azur common azur storag blob azur storag common azur storag file azur storag queue binaryornot cachetool cookiecutt fsspec futur googl api core googl auth googl auth oauthlib googl cloud bigqueri googl cloud core googl resum media googleapi common proto jinja time oauthlib panda gbq pip tool poyo pyarrow pyasn modul pydata googl auth python json logger request oauthlib sf tabl toposort whichcraft pip instal output termin collect cach whl collect panda download panda cpm manylinux whl collect azur storag file cach azur storag file whl collect click cach cookiecutt whl collect sqlalchemi download sqlalchemi tar instal build depend get requir build wheel prepar wheel metadata collect tabl cach tabl cpm manylinux whl process home user cach pip wheel ebbccfeeaaceefdadcdc python json logger whl collect azur storag blob cach azur storag blob whl collect panda gbq cach panda gbq whl requir satisfi fsspec home user anaconda env jupytersystemenv lib python site packag collect xlsxwriter download xlsxwriter whl collect pip tool cach pip tool whl collect pyarrow download pyarrow cpm manylinux whl collect xlrd download xlrd whl requir satisfi sf home user anaconda env jupytersystemenv lib python site packag collect azur storag queue cach azur storag queue whl process home user cach pip wheel ebcfeaaabcedcfebabefc anyconfig whl collect toposort cach toposort whl requir satisfi pyyaml home user anaconda env jupytersystemenv lib python site packag requir satisfi request home user anaconda env jupytersystemenv lib python site packag requir satisfi pytz home user anaconda env jupytersystemenv lib python site packag panda requir satisfi numpi home user anaconda env jupytersystemenv lib python site packag panda requir satisfi python dateutil home user anaconda env jupytersystemenv lib python site packag panda collect azur common cach azur common whl collect azur storag common cach azur storag common whl collect poyo cach poyo whl collect jinja time cach jinja time whl collect whichcraft cach whichcraft whl collect binaryornot cach binaryornot whl requir satisfi jinja home user anaconda env jupytersystemenv lib python site packag cookiecutt process home user cach pip wheel dafdcdabaabdfcb futur whl requir satisfi mock home user anaconda env jupytersystemenv lib python site packag tabl collect numexpr download numexpr cpm manylinux whl requir satisfi home user anaconda env jupytersystemenv lib python site packag tabl collect pydata googl auth cach pydata googl auth whl collect googl auth oauthlib cach googl auth oauthlib whl collect googl cloud bigqueri cach googl cloud bigqueri whl collect googl auth cach googl auth whl requir satisfi setuptool home user anaconda env jupytersystemenv lib python site packag panda gbq post requir satisfi boto home user anaconda env jupytersystemenv lib python site packag sf requir satisfi botocor home user anaconda env jupytersystemenv lib python site packag sf requir satisfi idna home user anaconda env jupytersystemenv lib python site packag request requir satisfi chardet home user anaconda env jupytersystemenv lib python site packag request requir satisfi urllib home user anaconda env jupytersystemenv lib python site packag request requir satisfi certifi home user anaconda env jupytersystemenv lib python site packag request requir satisfi cryptographi home user anaconda env jupytersystemenv lib python site packag azur storag common azur storag file collect arrow cach arrow whl requir satisfi markupsaf home user anaconda env jupytersystemenv lib python site packag jinja cookiecutt collect request oauthlib cach request oauthlib whl collect googl resum media cach googl resum media whl collect googl cloud core cach googl cloud core whl requir satisfi protobuf home user anaconda env jupytersystemenv lib python site packag googl cloud bigqueri panda gbq collect googl api core cach googl api core whl collect pyasn modul cach pyasn modul whl requir satisfi rsa home user anaconda env jupytersystemenv lib python site packag googl auth panda gbq collect cachetool cach cachetool whl requir satisfi stransfer home user anaconda env jupytersystemenv lib python site packag boto sf requir satisfi jmespath home user anaconda env jupytersystemenv lib python site packag boto sf requir satisfi docutil home user anaconda env jupytersystemenv lib python site packag botocor sf requir satisfi cffi home user anaconda env jupytersystemenv lib python site packag cryptographi azur storag common azur storag file collect oauthlib cach oauthlib whl process home user cach pip wheel ebebfebbebeadcaf googleapi common proto whl requir satisfi pyasn home user anaconda env jupytersystemenv lib python site packag pyasn modul googl auth panda gbq requir satisfi pycpars home user anaconda env jupytersystemenv lib python site packag cffi cryptographi azur storag common azur storag file build wheel collect packag sqlalchemi build wheel sqlalchemi pep creat wheel sqlalchemi filenam sqlalchemi cpm linux whl size sha eaacadafdacabbdecdeedfabebaeeddaa store directori home user cach pip wheel cdbebaebcbeefcaebab successfulli built sqlalchemi instal collect packag panda azur common azur storag common azur storag file click poyo arrow jinja time whichcraft binaryornot futur cookiecutt sqlalchemi numexpr tabl python json logger azur storag blob pyasn modul cachetool googl auth oauthlib request oauthlib googl auth oauthlib pydata googl auth googl resum media googleapi common proto googl api core googl cloud core googl cloud bigqueri panda gbq xlsxwriter pip tool pyarrow xlrd azur storag queue anyconfig toposort attempt uninstal panda exist instal panda uninstal panda successfulli uninstal panda successfulli instal sqlalchemi anyconfig arrow azur common azur storag blob azur storag common azur storag file azur storag queue binaryornot cachetool click cookiecutt futur googl api core googl auth googl auth oauthlib googl cloud bigqueri googl cloud core googl resum media googleapi common proto jinja time numexpr oauthlib panda panda gbq pip tool poyo pyarrow pyasn modul pydata googl auth python json logger request oauthlib tabl toposort whichcraft xlrd xlsxwriter environ includ relev detail environ experienc bug environ termin notebook version version python python anaconda python anaconda pretti amazon linux ami like rhel fedora pretti amazon linux ami like rhel fedora pip freez anyconfig arrow asncrypto attr autovizwidget awscli azur common azur storag blob azur storag common azur storag file azur storag queue backcal bcrypt binaryornot bleach boto botocor cach properti cachetool certifi cffi chardet click colorama cookiecutt cryptographi decor defusedxml docker docker compos dockerpti docopt docutil entrypoint environ kernel fsspec futur gitdb gitpython googl api core googl auth googl auth oauthlib googl cloud bigqueri googl cloud core googl resum media googleapi common proto hdijupyterutil idna importlib metadata ipykernel ipython ipython genutil ipywidget jedi jinja jinja time jmespath json jsonschema jupyt jupyt client jupyt consol jupyt core jupyterlab jupyterlab git jupyterlab server markupsaf mistun mock conda conda kernel nbconvert nbdime nbexampl nbformat nbserverproxi nose notebook numexpr numpi oauthlib packag panda panda gbq pandocfilt paramiko parso pexpect pickleshar pid pip tool plotli poyo prometheu client prompt toolkit protobuf protobuf dict psutil psycopg ptyprocess pyj pyarrow pyasn pyasn modul pycpars pydata googl auth pygal pygment pykerbero pynacl pyopenssl pypars pyrsist pysock pyspark python dateutil python json logger pytz pyyaml pyzmq qtconsol qtpy request request kerbero request oauthlib retri rsa sf stransfer experi nbi agent pyspark scipi sendtrash smdebug rulesconfig smmap sparkmag sqlalchemi tabl terminado testpath texttabl toposort tornado traitlet urllib wcwidth webencod websocket client whichcraft widgetsnbextens xlrd xlsxwriter zipp alabast anaconda client anaconda project anyconfig arrow asncrypto astroid astropi attr automat autovizwidget awscli azur common azur storag blob azur storag common azur storag file azur storag queue babel backcal backport shutil termin size bcrypt beautifulsoup binaryornot bitarrai bkchart blaze bleach bokeh boto boto botocor bottleneck cach properti cachetool certifi cffi characterist chardet click cloudpickl clyent colorama contextlib cookiecutt cryptographi cycler cython cytoolz dask datashap decor defusedxml distribut docker docker compos dockerpti docopt docutil entrypoint enum environ kernel xmlfile fastcach filelock flask flask cor fsspec futur gevent glob gmpy googl api core googl auth googl auth oauthlib googl cloud bigqueri googl cloud core googl resum media googleapi common proto greenlet hpy hdijupyterutil heapdict htmllib idna imageio images importlib metadata ipykernel ipyparallel ipython ipython genutil ipywidget isort itsdanger jdcal jedi jinja jinja time jmespath jsonschema jupyt jupyt client jupyt consol jupyt core jupyterlab jupyterlab launcher kiwisolv lazi object proxi llvmlite locket lxml markupsaf matplotlib mccabe mistun mkl fft mkl random mock itertool mpmath msgpack msgpack python multipledispatch conda conda kernel nbconvert nbformat networkx nltk nose notebook numba numexpr numpi numpydoc oauthlib odo olefil opencv python openpyxl packag panda panda gbq pandocfilt paramiko parso partd path pathlib patsi pep pexpect pickleshar pillow pip tool pkginfo plotli pluggi ply poyo prompt toolkit protobuf protobuf dict psutil psycopg ptyprocess pyj pyarrow pyasn pyasn modul pycodestyl pycosat pycpars pycrypto pycurl pydata googl auth pyflak pygal pygment pykerbero pylint pynacl pyodbc pyopenssl pypars pysock pyspark pytest pytest arraydiff pytest astropi pytest doctestplu pytest openfil pytest remotedata python dateutil python json logger pytz pywavelet pyyaml pyzmq qtawesom qtconsol qtpy request request kerbero request oauthlib retri rope rsa ruamel yaml sf stransfer pyspark scikit imag scikit learn scipi seaborn sendtrash simplegener singledispatch smdebug rulesconfig snowballstemm sortedcollect sortedcontain sparkmag sphinx sphinxcontrib websupport spyder sqlalchemi statsmodel sympi tabl tbb tblib terminado testpath texttabl toolz toposort tornado traitlet type unicodecsv urllib wcwidth webencod websocket client werkzeug whichcraft widgetsnbextens wrapt xlrd xlsxwriter xlwt zict zipp",
        "Issue_preprocessed_content":"rais descript conda environ context want us develop environ run expect termin step reproduc startup instanc default termin termin exampl project fail creat new environ termin separ design load context describ note start us code check exist restart kernel want reload context line code caus invoc point dir intend run expect result print actual result trace investig far chang yaml type termin desir outcom transit make easier us local dataset output output termin environ includ relev detail environ experienc bug environ termin version version python anaconda python anaconda",
        "Issue_gpt_summary_original":"The user encountered an error while running a query on the `aws_sagemaker_notebook_instance` table in Steampipe. The error message indicates that the `hydrate call listAwsSageMakerNotebookInstanceTags` failed with a panic interface conversion. The user is using Steampipe version v0.4.1 and aws plugin version v0.15.0.",
        "Issue_gpt_summary":"user encount error run queri aw notebook instanc tabl steampip error messag indic hydrat listawsnotebookinstancetag fail panic interfac convers user steampip version aw plugin version",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/turbot\/steampipe-plugin-aws\/issues\/364",
        "Issue_title":"Getting an error from `aws_sagemaker_notebook_instance` table. Please see the detail below.",
        "Issue_created_time":1620111416000,
        "Issue_closed_time":1623682749000,
        "Issue_body":"**Describe the bug**\r\n\r\nCreate a notebook instance in one of the configured region.\r\nRan the below query and got that error\r\n\r\n```\r\nselect * from aws_sagemaker_notebook_instance;\r\nError: hydrate call listAwsSageMakerNotebookInstanceTags failed with panic interface conversion: interface {} is *sagemaker.NotebookInstanceSummary, not *sagemaker.DescribeNotebookInstanceOutput\r\n\r\n```\r\n\r\n\r\n\r\n**Steampipe version (`steampipe -v`)**\r\n: v0.4.1\r\n\r\n**Plugin version (`steampipe plugin list`)**\r\naws: v0.15.0\r\n\r\n\r\n\r\n\r\n",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"get error aw notebook instanc tabl bug creat notebook instanc configur region ran queri got error select aw notebook instanc error hydrat listawsnotebookinstancetag fail panic interfac convers interfac notebookinstancesummari describenotebookinstanceoutput steampip version steampip plugin version steampip plugin list aw",
        "Issue_preprocessed_content":"tabl bug creat instanc configur region ran queri got steampip version plugin version aw",
        "Issue_gpt_summary_original":"the user encountered a challenge where zenml was failing to create a s3 bucket due to an incorrect regex in its name.",
        "Issue_gpt_summary":"user encount challeng zenml fail creat bucket incorrect regex",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/zenml-io\/zenml\/issues\/767",
        "Issue_title":"[BUG]: SageMaker + S3 artifact store fails trying to create a new bucket",
        "Issue_created_time":1657726485000,
        "Issue_closed_time":1657782683000,
        "Issue_body":"### Contact Details [Optional]\n\n_No response_\n\n### System Information\n\nZenml == 0.10.0\n\n### What happened?\n\nZenml is trying to create a s3 bucket and fails due to incorrect regex in its name.\n\n### Reproduction steps\n\n1. Create a SageMaker pipeline.\r\n2. Create a s3 artifact store.\r\n3. Run the pipeline\r\n\n\n### Relevant log output\n\n```shell\nCreating run for pipeline: mnist_pipeline\r\nCache enabled for pipeline mnist_pipeline\r\nUsing stack sagemaker_stack to run pipeline mnist_pipeline...\r\nStep importer has started.\r\nUsing cached version of importer.\r\nStep importer has finished in 0.045s.\r\nStep trainer has started.\r\nINFO:botocore.credentials:Found credentials in shared credentials file: ~\/.aws\/credentials\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 C:\\Users\\i25262\\PycharmProjects\\ZenML-Kubeflow\\venv\\lib\\site-packages\\s3fs\\ \u2502\r\n\u2502 core.py:752 in _mkdir                                                       \u2502\r\n\u2502                                                                             \u2502\r\n\u2502    749 \u2502   \u2502   \u2502   \u2502   \u2502   params[\"CreateBucketConfiguration\"] = {          \u2502\r\n\u2502    750 \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   \"LocationConstraint\": region_name            \u2502\r\n\u2502    751 \u2502   \u2502   \u2502   \u2502   \u2502   }                                                \u2502\r\n\u2502 >  752 \u2502   \u2502   \u2502   \u2502   await self._call_s3(\"create_bucket\", **params)       \u2502\r\n\u2502    753 \u2502   \u2502   \u2502   \u2502   self.invalidate_cache(\"\")                            \u2502\r\n\u2502    754 \u2502   \u2502   \u2502   \u2502   self.invalidate_cache(bucket)                        \u2502\r\n\u2502    755 \u2502   \u2502   \u2502   except ClientError as e:                                 \u2502\r\n\u2502                                                                             \u2502\r\n\u2502 C:\\Users\\i25262\\PycharmProjects\\ZenML-Kubeflow\\venv\\lib\\site-packages\\s3fs\\ \u2502\r\n\u2502 core.py:302 in _call_s3                                                     \u2502\r\n\u2502                                                                             \u2502\r\n\u2502    299 \u2502   \u2502   \u2502   except Exception as e:                                   \u2502\r\n\u2502    300 \u2502   \u2502   \u2502   \u2502   err = e                                              \u2502\r\n\u2502    301 \u2502   \u2502   err = translate_boto_error(err)                              \u2502\r\n\u2502 >  302 \u2502   \u2502   raise err                                                    \u2502\r\n\u2502    303 \u2502                                                                    \u2502\r\n\u2502    304 \u2502   call_s3 = sync_wrapper(_call_s3)                                 \u2502\r\n\u2502    305                                                                      \u2502\r\n\u2502                                                                             \u2502\r\n\u2502 C:\\Users\\i25262\\PycharmProjects\\ZenML-Kubeflow\\venv\\lib\\site-packages\\s3fs\\ \u2502\r\n\u2502 core.py:282 in _call_s3                                                     \u2502\r\n\u2502                                                                             \u2502\r\n\u2502    279 \u2502   \u2502   additional_kwargs = self._get_s3_method_kwargs(method, *akwa \u2502\r\n\u2502    280 \u2502   \u2502   for i in range(self.retries):                                \u2502\r\n\u2502    281 \u2502   \u2502   \u2502   try:                                                     \u2502\r\n\u2502 >  282 \u2502   \u2502   \u2502   \u2502   out = await method(**additional_kwargs)              \u2502\r\n\u2502    283 \u2502   \u2502   \u2502   \u2502   return out                                           \u2502\r\n\u2502    284 \u2502   \u2502   \u2502   except S3_RETRYABLE_ERRORS as e:                         \u2502\r\n\u2502    285 \u2502   \u2502   \u2502   \u2502   logger.debug(\"Retryable error: %s\", e)               \u2502\r\n\u2502                                                                             \u2502\r\n\u2502 C:\\Users\\i25262\\PycharmProjects\\ZenML-Kubeflow\\venv\\lib\\site-packages\\aiobo \u2502\r\n\u2502 tocore\\client.py:198 in _make_api_call                                      \u2502\r\n\u2502                                                                             \u2502\r\n\u2502   195 \u2502   \u2502   \u2502   'has_streaming_input': operation_model.has_streaming_inpu \u2502\r\n\u2502   196 \u2502   \u2502   \u2502   'auth_type': operation_model.auth_type,                   \u2502\r\n\u2502   197 \u2502   \u2502   }                                                             \u2502\r\n\u2502 > 198 \u2502   \u2502   request_dict = await self._convert_to_request_dict(           \u2502\r\n\u2502   199 \u2502   \u2502   \u2502   api_params, operation_model, context=request_context)     \u2502\r\n\u2502   200 \u2502   \u2502   resolve_checksum_context(request_dict, operation_model, api_p \u2502\r\n\u2502   201                                                                       \u2502\r\n\u2502                                                                             \u2502\r\n\u2502 C:\\Users\\i25262\\PycharmProjects\\ZenML-Kubeflow\\venv\\lib\\site-packages\\aiobo \u2502\r\n\u2502 tocore\\client.py:246 in _convert_to_request_dict                            \u2502\r\n\u2502                                                                             \u2502\r\n\u2502   243 \u2502                                                                     \u2502\r\n\u2502   244 \u2502   async def _convert_to_request_dict(self, api_params, operation_mo \u2502\r\n\u2502   245 \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   \u2502      context=None):                 \u2502\r\n\u2502 > 246 \u2502   \u2502   api_params = await self._emit_api_params(                     \u2502\r\n\u2502   247 \u2502   \u2502   \u2502   api_params, operation_model, context)                     \u2502\r\n\u2502   248 \u2502   \u2502   request_dict = self._serializer.serialize_to_request(         \u2502\r\n\u2502   249 \u2502   \u2502   \u2502   api_params, operation_model)                              \u2502\r\n\u2502                                                                             \u2502\r\n\u2502 C:\\Users\\i25262\\PycharmProjects\\ZenML-Kubeflow\\venv\\lib\\site-packages\\aiobo \u2502\r\n\u2502 tocore\\client.py:275 in _emit_api_params                                    \u2502\r\n\u2502                                                                             \u2502\r\n\u2502   272 \u2502   \u2502                                                                 \u2502\r\n\u2502   273 \u2502   \u2502   event_name = (                                                \u2502\r\n\u2502   274 \u2502   \u2502   \u2502   'before-parameter-build.{service_id}.{operation_name}')   \u2502\r\n\u2502 > 275 \u2502   \u2502   await self.meta.events.emit(                                  \u2502\r\n\u2502   276 \u2502   \u2502   \u2502   event_name.format(                                        \u2502\r\n\u2502   277 \u2502   \u2502   \u2502   \u2502   service_id=service_id,                                \u2502\r\n\u2502   278 \u2502   \u2502   \u2502   \u2502   operation_name=operation_name),                       \u2502\r\n\u2502                                                                             \u2502\r\n\u2502 C:\\Users\\i25262\\PycharmProjects\\ZenML-Kubeflow\\venv\\lib\\site-packages\\aiobo \u2502\r\n\u2502 tocore\\hooks.py:29 in _emit                                                 \u2502\r\n\u2502                                                                             \u2502\r\n\u2502   26 \u2502   \u2502   \u2502   if asyncio.iscoroutinefunction(handler):                   \u2502\r\n\u2502   27 \u2502   \u2502   \u2502   \u2502   response = await handler(**kwargs)                     \u2502\r\n\u2502   28 \u2502   \u2502   \u2502   else:                                                      \u2502\r\n\u2502 > 29 \u2502   \u2502   \u2502   \u2502   response = handler(**kwargs)                           \u2502\r\n\u2502   30 \u2502   \u2502   \u2502                                                              \u2502\r\n\u2502   31 \u2502   \u2502   \u2502   responses.append((handler, response))                      \u2502\r\n\u2502   32 \u2502   \u2502   \u2502   if stop_on_response and response is not None:              \u2502\r\n\u2502                                                                             \u2502\r\n\u2502 C:\\Users\\i25262\\PycharmProjects\\ZenML-Kubeflow\\venv\\lib\\site-packages\\botoc \u2502\r\n\u2502 ore\\handlers.py:243 in validate_bucket_name                                 \u2502\r\n\u2502                                                                             \u2502\r\n\u2502    240 \u2502   \u2502   \u2502   'Invalid bucket name \"%s\": Bucket name must match '      \u2502\r\n\u2502    241 \u2502   \u2502   \u2502   'the regex \"%s\" or be an ARN matching the regex \"%s\"' %  \u2502\r\n\u2502    242 \u2502   \u2502   \u2502   \u2502   bucket, VALID_BUCKET.pattern, VALID_S3_ARN.pattern)) \u2502\r\n\u2502 >  243 \u2502   \u2502   raise ParamValidationError(report=error_msg)                 \u2502\r\n\u2502    244                                                                      \u2502\r\n\u2502    245                                                                      \u2502\r\n\u2502    246 def sse_md5(params, **kwargs):                                       \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\nParamValidationError: Parameter validation failed:\r\nInvalid bucket name \"zenml-training\\trainer\\.system\\executor_execution\\24\": \r\nBucket name must match the regex \"^[a-zA-Z0-9.\\-_]{1,255}$\" or be an ARN \r\nmatching the regex \r\n\"^arn:(aws).*:(s3|s3-object-lambda):[a-z\\-0-9]*:[0-9]{12}:accesspoint[\/:][a-zA-\r\nZ0-9\\-.]{1,63}$|^arn:(aws).*:s3-outposts:[a-z\\-0-9]+:[0-9]{12}:outpost[\/:][a-zA\r\n-Z0-9\\-]{1,63}[\/:]accesspoint[\/:][a-zA-Z0-9\\-]{1,63}$\"\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 C:\\Users\\i25262\\PycharmProjects\\ZenML-Kubeflow\\run-sagemaker.py:87 in       \u2502\r\n\u2502 <module>                                                                    \u2502\r\n\u2502                                                                             \u2502\r\n\u2502   84 \u2502   \u2502   trainer=trainer(),                                             \u2502\r\n\u2502   85 \u2502   \u2502   evaluator=evaluator(),                                         \u2502\r\n\u2502   86 \u2502   )                                                                  \u2502\r\n\u2502 > 87 \u2502   pipeline.run()                                                     \u2502\r\n\u2502                                                                             \u2502\r\n\u2502 C:\\Users\\i25262\\PycharmProjects\\ZenML-Kubeflow\\venv\\lib\\site-packages\\zenml \u2502\r\n\u2502 \\pipelines\\base_pipeline.py:489 in run                                      \u2502\r\n\u2502                                                                             \u2502\r\n\u2502   486 \u2502   \u2502   self._reset_step_flags()                                      \u2502\r\n\u2502   487 \u2502   \u2502   self.validate_stack(stack)                                    \u2502\r\n\u2502   488 \u2502   \u2502                                                                 \u2502\r\n\u2502 > 489 \u2502   \u2502   return stack.deploy_pipeline(                                 \u2502\r\n\u2502   490 \u2502   \u2502   \u2502   self, runtime_configuration=runtime_configuration         \u2502\r\n\u2502   491 \u2502   \u2502   )                                                             \u2502\r\n\u2502   492                                                                       \u2502\r\n\u2502                                                                             \u2502\r\n\u2502 C:\\Users\\i25262\\PycharmProjects\\ZenML-Kubeflow\\venv\\lib\\site-packages\\zenml \u2502\r\n\u2502 \\stack\\stack.py:595 in deploy_pipeline                                      \u2502\r\n\u2502                                                                             \u2502\r\n\u2502   592 \u2502   \u2502   \u2502   pipeline=pipeline, runtime_configuration=runtime_configur \u2502\r\n\u2502   593 \u2502   \u2502   )                                                             \u2502\r\n\u2502   594 \u2502   \u2502                                                                 \u2502\r\n\u2502 > 595 \u2502   \u2502   return_value = self.orchestrator.run(                         \u2502\r\n\u2502   596 \u2502   \u2502   \u2502   pipeline, stack=self, runtime_configuration=runtime_confi \u2502\r\n\u2502   597 \u2502   \u2502   )                                                             \u2502\r\n\u2502   598                                                                       \u2502\r\n\u2502                                                                             \u2502\r\n\u2502 C:\\Users\\i25262\\PycharmProjects\\ZenML-Kubeflow\\venv\\lib\\site-packages\\zenml \u2502\r\n\u2502 \\orchestrators\\base_orchestrator.py:212 in run                              \u2502\r\n\u2502                                                                             \u2502\r\n\u2502   209 \u2502   \u2502   \u2502   pipeline=pipeline, pb2_pipeline=pb2_pipeline              \u2502\r\n\u2502   210 \u2502   \u2502   )                                                             \u2502\r\n\u2502   211 \u2502   \u2502                                                                 \u2502\r\n\u2502 > 212 \u2502   \u2502   result = self.prepare_or_run_pipeline(                        \u2502\r\n\u2502   213 \u2502   \u2502   \u2502   sorted_steps=sorted_steps,                                \u2502\r\n\u2502   214 \u2502   \u2502   \u2502   pipeline=pipeline,                                        \u2502\r\n\u2502   215 \u2502   \u2502   \u2502   pb2_pipeline=pb2_pipeline,                                \u2502\r\n\u2502                                                                             \u2502\r\n\u2502 C:\\Users\\i25262\\PycharmProjects\\ZenML-Kubeflow\\venv\\lib\\site-packages\\zenml \u2502\r\n\u2502 \\orchestrators\\local\\local_orchestrator.py:68 in prepare_or_run_pipeline    \u2502\r\n\u2502                                                                             \u2502\r\n\u2502   65 \u2502   \u2502                                                                  \u2502\r\n\u2502   66 \u2502   \u2502   # Run each step                                                \u2502\r\n\u2502   67 \u2502   \u2502   for step in sorted_steps:                                      \u2502\r\n\u2502 > 68 \u2502   \u2502   \u2502   self.run_step(                                             \u2502\r\n\u2502   69 \u2502   \u2502   \u2502   \u2502   step=step,                                             \u2502\r\n\u2502   70 \u2502   \u2502   \u2502   \u2502   run_name=runtime_configuration.run_name,               \u2502\r\n\u2502   71 \u2502   \u2502   \u2502   \u2502   pb2_pipeline=pb2_pipeline,                             \u2502\r\n\u2502                                                                             \u2502\r\n\u2502 C:\\Users\\i25262\\PycharmProjects\\ZenML-Kubeflow\\venv\\lib\\site-packages\\zenml \u2502\r\n\u2502 \\orchestrators\\base_orchestrator.py:316 in run_step                         \u2502\r\n\u2502                                                                             \u2502\r\n\u2502   313 \u2502   \u2502   # This is where the step actually gets executed using the     \u2502\r\n\u2502   314 \u2502   \u2502   # component_launcher                                          \u2502\r\n\u2502   315 \u2502   \u2502   repo.active_stack.prepare_step_run()                          \u2502\r\n\u2502 > 316 \u2502   \u2502   execution_info = self._execute_step(component_launcher)       \u2502\r\n\u2502   317 \u2502   \u2502   repo.active_stack.cleanup_step_run()                          \u2502\r\n\u2502   318 \u2502   \u2502                                                                 \u2502\r\n\u2502   319 \u2502   \u2502   return execution_info                                         \u2502\r\n\u2502                                                                             \u2502\r\n\u2502 C:\\Users\\i25262\\PycharmProjects\\ZenML-Kubeflow\\venv\\lib\\site-packages\\zenml \u2502\r\n\u2502 \\orchestrators\\base_orchestrator.py:340 in _execute_step                    \u2502\r\n\u2502                                                                             \u2502\r\n\u2502   337 \u2502   \u2502   start_time = time.time()                                      \u2502\r\n\u2502   338 \u2502   \u2502   logger.info(f\"Step `{pipeline_step_name}` has started.\")      \u2502\r\n\u2502   339 \u2502   \u2502   try:                                                          \u2502\r\n\u2502 > 340 \u2502   \u2502   \u2502   execution_info = tfx_launcher.launch()                    \u2502\r\n\u2502   341 \u2502   \u2502   \u2502   if execution_info and get_cache_status(execution_info):   \u2502\r\n\u2502   342 \u2502   \u2502   \u2502   \u2502   logger.info(f\"Using cached version of `{pipeline_step \u2502\r\n\u2502   343 \u2502   \u2502   except RuntimeError as e:                                     \u2502\r\n\u2502                                                                             \u2502\r\n\u2502 C:\\Users\\i25262\\PycharmProjects\\ZenML-Kubeflow\\venv\\lib\\site-packages\\tfx\\o \u2502\r\n\u2502 rchestration\\portable\\launcher.py:528 in launch                             \u2502\r\n\u2502                                                                             \u2502\r\n\u2502   525 \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   \u2502      self._pipeline_runtime_spe \u2502\r\n\u2502   526 \u2502                                                                     \u2502\r\n\u2502   527 \u2502   # Runs as a normal node.                                          \u2502\r\n\u2502 > 528 \u2502   execution_preparation_result = self._prepare_execution()          \u2502\r\n\u2502   529 \u2502   (execution_info, contexts,                                        \u2502\r\n\u2502   530 \u2502    is_execution_needed) = (execution_preparation_result.execution_i \u2502\r\n\u2502   531 \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   \u2502    execution_preparation_result.contexts,   \u2502\r\n\u2502                                                                             \u2502\r\n\u2502 C:\\Users\\i25262\\PycharmProjects\\ZenML-Kubeflow\\venv\\lib\\site-packages\\tfx\\o \u2502\r\n\u2502 rchestration\\portable\\launcher.py:388 in _prepare_execution                 \u2502\r\n\u2502                                                                             \u2502\r\n\u2502   385 \u2502   \u2502   \u2502     output_dict=output_artifacts,                           \u2502\r\n\u2502   386 \u2502   \u2502   \u2502     exec_properties=exec_properties,                        \u2502\r\n\u2502   387 \u2502   \u2502   \u2502     execution_output_uri=(                                  \u2502\r\n\u2502 > 388 \u2502   \u2502   \u2502   \u2502     self._output_resolver.get_executor_output_uri(execu \u2502\r\n\u2502   389 \u2502   \u2502   \u2502     stateful_working_dir=(                                  \u2502\r\n\u2502   390 \u2502   \u2502   \u2502   \u2502     self._output_resolver.get_stateful_working_director \u2502\r\n\u2502   391 \u2502   \u2502   \u2502     tmp_dir=self._output_resolver.make_tmp_dir(execution.id \u2502\r\n\u2502                                                                             \u2502\r\n\u2502 C:\\Users\\i25262\\PycharmProjects\\ZenML-Kubeflow\\venv\\lib\\site-packages\\tfx\\o \u2502\r\n\u2502 rchestration\\portable\\outputs_utils.py:172 in get_executor_output_uri       \u2502\r\n\u2502                                                                             \u2502\r\n\u2502   169 \u2502   \"\"\"Generates executor output uri given execution_id.\"\"\"           \u2502\r\n\u2502   170 \u2502   execution_dir = os.path.join(self._node_dir, _SYSTEM, _EXECUTOR_E \u2502\r\n\u2502   171 \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   \u2502    str(execution_id))                   \u2502\r\n\u2502 > 172 \u2502   fileio.makedirs(execution_dir)                                    \u2502\r\n\u2502   173 \u2502   return os.path.join(execution_dir, _EXECUTOR_OUTPUT_FILE)         \u2502\r\n\u2502   174                                                                       \u2502\r\n\u2502   175   def get_driver_output_uri(self) -> str:                             \u2502\r\n\u2502                                                                             \u2502\r\n\u2502 C:\\Users\\i25262\\PycharmProjects\\ZenML-Kubeflow\\venv\\lib\\site-packages\\tfx\\d \u2502\r\n\u2502 sl\\io\\fileio.py:80 in makedirs                                              \u2502\r\n\u2502                                                                             \u2502\r\n\u2502    77                                                                       \u2502\r\n\u2502    78 def makedirs(path: PathType) -> None:                                 \u2502\r\n\u2502    79   \"\"\"Make a directory at the given path, recursively creating parents \u2502\r\n\u2502 >  80   _get_filesystem(path).makedirs(path)                                \u2502\r\n\u2502    81                                                                       \u2502\r\n\u2502    82                                                                       \u2502\r\n\u2502    83 def mkdir(path: PathType) -> None:                                    \u2502\r\n\u2502                                                                             \u2502\r\n\u2502 C:\\Users\\i25262\\PycharmProjects\\ZenML-Kubeflow\\venv\\lib\\site-packages\\zenml \u2502\r\n\u2502 \\integrations\\s3\\artifact_stores\\s3_artifact_store.py:275 in makedirs       \u2502\r\n\u2502                                                                             \u2502\r\n\u2502   272 \u2502   \u2502   Args:                                                         \u2502\r\n\u2502   273 \u2502   \u2502   \u2502   path: The path to create.                                 \u2502\r\n\u2502   274 \u2502   \u2502   \"\"\"                                                           \u2502\r\n\u2502 > 275 \u2502   \u2502   self.filesystem.makedirs(path=path, exist_ok=True)            \u2502\r\n\u2502   276 \u2502                                                                     \u2502\r\n\u2502   277 \u2502   def mkdir(self, path: PathType) -> None:                          \u2502\r\n\u2502   278 \u2502   \u2502   \"\"\"Create a directory at the given path.                      \u2502\r\n\u2502                                                                             \u2502\r\n\u2502 C:\\Users\\i25262\\PycharmProjects\\ZenML-Kubeflow\\venv\\lib\\site-packages\\fsspe \u2502\r\n\u2502 c\\asyn.py:85 in wrapper                                                     \u2502\r\n\u2502                                                                             \u2502\r\n\u2502    82 \u2502   @functools.wraps(func)                                            \u2502\r\n\u2502    83 \u2502   def wrapper(*args, **kwargs):                                     \u2502\r\n\u2502    84 \u2502   \u2502   self = obj or args[0]                                         \u2502\r\n\u2502 >  85 \u2502   \u2502   return sync(self.loop, func, *args, **kwargs)                 \u2502\r\n\u2502    86 \u2502                                                                     \u2502\r\n\u2502    87 \u2502   return wrapper                                                    \u2502\r\n\u2502    88                                                                       \u2502\r\n\u2502                                                                             \u2502\r\n\u2502 C:\\Users\\i25262\\PycharmProjects\\ZenML-Kubeflow\\venv\\lib\\site-packages\\fsspe \u2502\r\n\u2502 c\\asyn.py:65 in sync                                                        \u2502\r\n\u2502                                                                             \u2502\r\n\u2502    62 \u2502   \u2502   # suppress asyncio.TimeoutError, raise FSTimeoutError         \u2502\r\n\u2502    63 \u2502   \u2502   raise FSTimeoutError from return_result                       \u2502\r\n\u2502    64 \u2502   elif isinstance(return_result, BaseException):                    \u2502\r\n\u2502 >  65 \u2502   \u2502   raise return_result                                           \u2502\r\n\u2502    66 \u2502   else:                                                             \u2502\r\n\u2502    67 \u2502   \u2502   return return_result                                          \u2502\r\n\u2502    68                                                                       \u2502\r\n\u2502                                                                             \u2502\r\n\u2502 C:\\Users\\i25262\\PycharmProjects\\ZenML-Kubeflow\\venv\\lib\\site-packages\\fsspe \u2502\r\n\u2502 c\\asyn.py:25 in _runner                                                     \u2502\r\n\u2502                                                                             \u2502\r\n\u2502    22 \u2502   if timeout is not None:                                           \u2502\r\n\u2502    23 \u2502   \u2502   coro = asyncio.wait_for(coro, timeout=timeout)                \u2502\r\n\u2502    24 \u2502   try:                                                              \u2502\r\n\u2502 >  25 \u2502   \u2502   result[0] = await coro                                        \u2502\r\n\u2502    26 \u2502   except Exception as ex:                                           \u2502\r\n\u2502    27 \u2502   \u2502   result[0] = ex                                                \u2502\r\n\u2502    28 \u2502   finally:                                                          \u2502\r\n\u2502                                                                             \u2502\r\n\u2502 C:\\Users\\i25262\\PycharmProjects\\ZenML-Kubeflow\\venv\\lib\\site-packages\\s3fs\\ \u2502\r\n\u2502 core.py:767 in _makedirs                                                    \u2502\r\n\u2502                                                                             \u2502\r\n\u2502    764 \u2502                                                                    \u2502\r\n\u2502    765 \u2502   async def _makedirs(self, path, exist_ok=False):                 \u2502\r\n\u2502    766 \u2502   \u2502   try:                                                         \u2502\r\n\u2502 >  767 \u2502   \u2502   \u2502   await self._mkdir(path, create_parents=True)             \u2502\r\n\u2502    768 \u2502   \u2502   except FileExistsError:                                      \u2502\r\n\u2502    769 \u2502   \u2502   \u2502   if exist_ok:                                             \u2502\r\n\u2502    770 \u2502   \u2502   \u2502   \u2502   pass                                                 \u2502\r\n\u2502                                                                             \u2502\r\n\u2502 C:\\Users\\i25262\\PycharmProjects\\ZenML-Kubeflow\\venv\\lib\\site-packages\\s3fs\\ \u2502\r\n\u2502 core.py:758 in _mkdir                                                       \u2502\r\n\u2502                                                                             \u2502\r\n\u2502    755 \u2502   \u2502   \u2502   except ClientError as e:                                 \u2502\r\n\u2502    756 \u2502   \u2502   \u2502   \u2502   raise translate_boto_error(e)                        \u2502\r\n\u2502    757 \u2502   \u2502   \u2502   except ParamValidationError as e:                        \u2502\r\n\u2502 >  758 \u2502   \u2502   \u2502   \u2502   raise ValueError(\"Bucket create failed %r: %s\" % (bu \u2502\r\n\u2502    759 \u2502   \u2502   else:                                                        \u2502\r\n\u2502    760 \u2502   \u2502   \u2502   # raises if bucket doesn't exist and doesn't get create  \u2502\r\n\u2502    761 \u2502   \u2502   \u2502   await self._ls(bucket)                                   \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\nValueError: Bucket create failed \r\n'zenml-training\\\\trainer\\\\.system\\\\executor_execution\\\\24': Parameter \r\nvalidation failed:\r\nInvalid bucket name \"zenml-training\\trainer\\.system\\executor_execution\\24\": \r\nBucket name must match the regex \"^[a-zA-Z0-9.\\-_]{1,255}$\" or be an ARN \r\nmatching the regex \r\n\"^arn:(aws).*:(s3|s3-object-lambda):[a-z\\-0-9]*:[0-9]{12}:accesspoint[\/:][a-zA-\r\nZ0-9\\-.]{1,63}$|^arn:(aws).*:s3-outposts:[a-z\\-0-9]+:[0-9]{12}:outpost[\/:][a-zA\r\n-Z0-9\\-]{1,63}[\/:]accesspoint[\/:][a-zA-Z0-9\\-]{1,63}$\"\n```\n\n\n### Code of Conduct\n\n- [X] I agree to follow this project's Code of Conduct",
        "Issue_answer_count":2,
        "Issue_self_closed":1.0,
        "Answer_body":"Hi @danguitavinas,\r\n\r\nI'm guessing from the stack trace that you're running on windows with the local orchestrator? If that's the case, my guess is that this issue should be fixed by #735.\r\n\r\nIf you're interested in trying this, you could install ZenML from that branch using the command `pip install git+https:\/\/github.com\/zenml-io\/zenml.git@bugfix\/windows-source-utils` @schustmi Thank you so much, that worked! Im closing the issue!",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"bug artifact store fail try creat new bucket contact detail option respons inform zenml happen zenml try creat bucket fail incorrect regex reproduct step creat pipelin creat artifact store run pipelin relev log output shell creat run pipelin mnist pipelin cach enabl pipelin mnist pipelin stack stack run pipelin mnist pipelin step import start cach version import step import finish step trainer start info botocor credenti credenti share credenti file aw credenti traceback recent user pycharmproject zenml kubeflow venv lib site packag sf core mkdir param createbucketconfigur locationconstraint region await self creat bucket param self invalid cach self invalid cach bucket clienterror user pycharmproject zenml kubeflow venv lib site packag sf core except err err translat boto error err rais err sync wrapper user pycharmproject zenml kubeflow venv lib site packag sf core addit kwarg self method kwarg method akwa rang self retri try await method addit kwarg return retryabl error logger debug retryabl error user pycharmproject zenml kubeflow venv lib site packag aiobo tocor client api stream input oper model stream inpu auth type oper model auth type request dict await self convert request dict api param oper model context request context resolv checksum context request dict oper model api user pycharmproject zenml kubeflow venv lib site packag aiobo tocor client convert request dict async def convert request dict self api param oper context api param await self emit api param api param oper model context request dict self serial serial request api param oper model user pycharmproject zenml kubeflow venv lib site packag aiobo tocor client emit api param event paramet build servic oper await self meta event emit event format servic servic oper oper user pycharmproject zenml kubeflow venv lib site packag aiobo tocor hook emit asyncio iscoroutinefunct handler respons await handler kwarg respons handler kwarg respons append handler respons stop respons respons user pycharmproject zenml kubeflow venv lib site packag botoc or handler valid bucket invalid bucket bucket match regex arn match regex bucket valid bucket pattern valid arn pattern rais paramvalidationerror report error msg def sse param kwarg paramvalidationerror paramet valid fail invalid bucket zenml train trainer executor execut bucket match regex arn match regex arn aw object lambda accesspoint arn aw outpost outpost accesspoint handl except except occur traceback recent user pycharmproject zenml kubeflow run trainer trainer evalu evalu pipelin run user pycharmproject zenml kubeflow venv lib site packag zenml pipelin base pipelin run self reset step flag self valid stack stack return stack deploi pipelin self runtim configur runtim configur user pycharmproject zenml kubeflow venv lib site packag zenml stack stack deploi pipelin pipelin pipelin runtim configur runtim configur return valu self orchestr run pipelin stack self runtim configur runtim confi user pycharmproject zenml kubeflow venv lib site packag zenml orchestr base orchestr run pipelin pipelin pipelin pipelin result self prepar run pipelin sort step sort step pipelin pipelin pipelin pipelin user pycharmproject zenml kubeflow venv lib site packag zenml orchestr local local orchestr prepar run pipelin run step step sort step self run step step step run runtim configur run pipelin pipelin user pycharmproject zenml kubeflow venv lib site packag zenml orchestr base orchestr run step step actual get execut compon launcher repo activ stack prepar step run execut info self execut step compon launcher repo activ stack cleanup step run return execut info user pycharmproject zenml kubeflow venv lib site packag zenml orchestr base orchestr execut step start time time time logger info step pipelin step start try execut info tfx launcher launch execut info cach statu execut info logger info cach version pipelin step runtimeerror user pycharmproject zenml kubeflow venv lib site packag tfx rchestrat portabl launcher launch self pipelin runtim spe run normal node execut prepar result self prepar execut execut info context execut need execut prepar result execut execut prepar result context user pycharmproject zenml kubeflow venv lib site packag tfx rchestrat portabl launcher prepar execut output dict output artifact exec properti exec properti execut output uri self output resolv executor output uri execu state work dir self output resolv state work director tmp dir self output resolv tmp dir execut user pycharmproject zenml kubeflow venv lib site packag tfx rchestrat portabl output util executor output uri gener executor output uri given execut execut dir path join self node dir executor str execut fileio makedir execut dir return path join execut dir executor output file def driver output uri self str user pycharmproject zenml kubeflow venv lib site packag tfx fileio makedir def makedir path pathtyp directori given path recurs creat parent filesystem path makedir path def mkdir path pathtyp user pycharmproject zenml kubeflow venv lib site packag zenml integr artifact store artifact store makedir arg path path creat self filesystem makedir path path exist true def mkdir self path pathtyp creat directori given path user pycharmproject zenml kubeflow venv lib site packag fsspe asyn wrapper functool wrap func def wrapper arg kwarg self obj arg return sync self loop func arg kwarg return wrapper user pycharmproject zenml kubeflow venv lib site packag fsspe asyn sync suppress asyncio timeouterror rais fstimeouterror rais fstimeouterror return result elif isinst return result baseexcept rais return result return return result user pycharmproject zenml kubeflow venv lib site packag fsspe asyn runner timeout coro asyncio wait coro timeout timeout try result await coro except result final user pycharmproject zenml kubeflow venv lib site packag sf core makedir async def makedir self path exist fals try await self mkdir path creat parent true fileexistserror exist pass user pycharmproject zenml kubeflow venv lib site packag sf core mkdir clienterror rais translat boto error paramvalidationerror rais valueerror bucket creat fail rais bucket exist creat await self bucket valueerror bucket creat fail zenml train trainer executor execut paramet valid fail invalid bucket zenml train trainer executor execut bucket match regex arn match regex arn aw object lambda accesspoint arn aw outpost outpost accesspoint code conduct agre follow project code conduct",
        "Issue_preprocessed_content":"artifact store fail try creat new bucket contact detail inform zenml zenml try creat bucket fail regex reproduct step creat pipelin creat artifact store run pipelin relev log output code conduct project code conduct",
        "Issue_gpt_summary_original":"The user is encountering a bug in SWB 5.2.6 version of SageMaker Jupyter Notebook workspace where a study fails to mount. The error message indicates that the FUSE package failed to install during on-start. The user can resolve the issue by running \"sudo yum install fuse\" and then running \/usr\/local.\/share\/workspace-environment\/bin\/mount_sh.sh \/usr\/local\/etc\/s3-mounts.json to mount the study.",
        "Issue_gpt_summary":"user encount bug swb version jupyt notebook workspac studi fail mount error messag indic fuse packag fail instal start user resolv issu run sudo yum instal fuse run usr local share workspac environ bin mount usr local mount json mount studi",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/awslabs\/service-workbench-on-aws\/issues\/1089",
        "Issue_title":"[Bug] study fail to mount in SWB 5.2.6 SageMaker Jupyter Notebook",
        "Issue_created_time":1671836610000,
        "Issue_closed_time":null,
        "Issue_body":"**Describe the bug**\r\nSWB 5.2.6 version - SageMaker jupyter notebook workspace can not mount a study.  see error in \/var\/log\/message\r\n\/usr\/local\/bin\/goofys[7248]: main.FATAL Mounting file system: Mount: mount: running fusermount: exec: \"fusermount\": executable file not found in $PATH#012#012stderr:\r\n\r\nLooks like the FUSE package failed to install during on-start.  if run \"sudo yum install fuse\" then you can run \/usr\/local.\/share\/workspace-environment\/bin\/mount_sh.sh \/usr\/local\/etc\/s3-mounts.json to mount the study. \r\n\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Versions (please complete the following information):**\r\n - Release Version installed [e.g. v1.0.3]\r\n - Is the deployment from a forked version of the repository?\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "Issue_answer_count":2,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"bug studi fail mount swb jupyt notebook bug swb version jupyt notebook workspac mount studi error var log messag usr local bin goofi main fatal mount file mount mount run fusermount exec fusermount execut file path stderr look like fuse packag fail instal start run sudo yum instal fuse run usr local share workspac environ bin mount usr local mount json mount studi reproduc step reproduc behavior click scroll error expect behavior clear concis descript expect happen screenshot applic add screenshot help explain problem version complet follow inform releas version instal deploy fork version repositori addit context add context problem",
        "Issue_preprocessed_content":"studi fail mount swb jupyt bug swb version jupyt workspac mount studi mount file mount mount fusermount exec fusermount execut file path like fuse packag fail run sudo yum fuse run mount studi reproduc step reproduc behavior click expect behavior clear concis descript expect help explain problem version releas version deploy fork version repositori context context problem",
        "Issue_gpt_summary_original":"The user is encountering an error message \"null is not an object\" while trying to connect to Sagemaker notebook. This error occurs when pop-ups are disabled in SWB and is confusing to the user. The user suggests a more descriptive error message such as \"Service Workbench is encountering an error showing content. Please enable pop-ups and refresh the page.\"",
        "Issue_gpt_summary":"user encount error messag null object try connect notebook error occur pop up disabl swb confus user user suggest descript error messag servic workbench encount error show content enabl pop up refresh page",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/awslabs\/service-workbench-on-aws\/issues\/1081",
        "Issue_title":"[Bug] More descriptive error message for \"null is not an object\" while trying to connect to Sagemaker notebook. ",
        "Issue_created_time":1670601495000,
        "Issue_closed_time":1671209314000,
        "Issue_body":"**Describe the bug**\r\nUsers get the error \"null is not an object\" when pop-ups are enabled in SWB (reference:[ issue #620](https:\/\/github.com\/awslabs\/service-workbench-on-aws\/issues\/620))\r\nThis error is illegible to the user and causes confusion. Can we make the error message more clear such as:\r\n\"Service Workbench is encountering an error showing content. Please enable pop-ups and refresh the page.\"\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Diable pop-ups \r\n2. Connect to a workspace\r\n\r\n**Expected behavior**\r\nIf the workspace is unable to open, a more legible error message should be shown, such as \"Service Workbench is encountering an error showing content. Please enable pop-ups and refresh the page.\"\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Versions (please complete the following information):**\r\n - Release Version installed [e.g. v4.3.1 and v5.0.0]\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"Hi @simranmakwana, thank you for creating this issue. There are currently no plans to enrich the error messages in the UI; the recommendation is for you to customize the error messages within your installation of SWB as you see fit. Please reply back if there are any concerns with this approach. Thank you! ",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"bug descript error messag null object try connect notebook bug user error null object pop up enabl swb refer issu http github com awslab servic workbench aw issu error illeg user caus confus error messag clear servic workbench encount error show content enabl pop up refresh page reproduc step reproduc behavior diabl pop up connect workspac expect behavior workspac unabl open legibl error messag shown servic workbench encount error show content enabl pop up refresh page screenshot applic add screenshot help explain problem version complet follow inform releas version instal addit context add context problem",
        "Issue_preprocessed_content":"descript object try bug user object enabl swb user caus confus clear servic workbench encount show content enabl refresh reproduc step reproduc behavior diabl workspac expect behavior workspac unabl open legibl shown servic workbench encount show content enabl refresh help explain problem version releas version context context problem",
        "Issue_gpt_summary_original":"The user is facing an issue where the idle Sagemaker Notebook instances are not stopping automatically after the specified time. The autostop.py script used by the `on-start` lifecycle rule of the instance CFN template is not working due to missing packages. The expected behavior is that the idle instances should stop automatically after the specified time. The user is using Release Version v5.0.0.",
        "Issue_gpt_summary":"user face issu idl notebook instanc stop automat specifi time autostop script start lifecycl rule instanc cfn templat work miss packag expect behavior idl instanc stop automat specifi time user releas version",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/awslabs\/service-workbench-on-aws\/issues\/1076",
        "Issue_title":"[Bug] Sagemaker instance does not stop automatically",
        "Issue_created_time":1670370218000,
        "Issue_closed_time":1671059684000,
        "Issue_body":"**Describe the bug**\r\n\r\nIdle Sagemaker Notebook instances do not stop after specified time.\r\n\r\nSWB runs autostop.py script to automatically stop Sagemaker Notebook instance. The script is used by `on-start` lifecycle rule of the instance CFN template. According to LifecycleConfigOnStart logs, some packages are missing and autostop script doesn\u2019t work.\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Make sure AutoStopIdleTimeInMinutes parameter in workspace type config is set to a required time (30 minutes in our case)\r\n2. Create a new workspace with Sagemaker notebook instance\r\n3. Leave the instance idle for the time specified (AutoStopIdleTimeInMinutes )\r\n4. After the specified time see that the instance is not stopped\r\n\r\n**Expected behavior**\r\nIdle Sagemaker Notebook instance automatically stops after specified time.\r\n\r\n**Screenshots**\r\n<img width=\"1308\" alt=\"Screen Shot 2022-12-07 at 10 43 09 am\" src=\"https:\/\/user-images.githubusercontent.com\/47466926\/206049662-5ff12457-8bd4-42bd-b12f-ce68fdfacaf6.png\">\r\n\r\n\r\n**Versions (please complete the following information):**\r\n - Release Version installed v5.0.0\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "Issue_answer_count":5,
        "Issue_self_closed":0.0,
        "Answer_body":"Thank you. We are aware of this issue and have a backlog item to resolve this! See https:\/\/github.com\/awslabs\/service-workbench-on-aws\/issues\/1065 for more information. Hi, please check the latest release [v5.2.5](https:\/\/github.com\/awslabs\/service-workbench-on-aws\/releases\/tag\/v5.2.5) for the fix to this issue.  Hi! I also want to note that you may need to stop and start any affected instances after upgrade and deploying SWB v5.2.5.\r\n\r\nIf this fixes your issue, please go ahead and close this issue. I am going to mark as closing-soon-if-no-response so we will close in about 7 days if we do not hear that this did not resolve the issue.\r\n\r\nThank you for the report! Hi Marianna,\nThank you. I am going to migrate to v5.2.5 tomorrow. If everything goes\nwell, I'll close the ticket soon.\n\n\nOn Tue, Dec 13, 2022 at 7:55 AM Marianna Ghirardelli <\n***@***.***> wrote:\n\n> Hi! I also want to note that you may need to stop and start any affected\n> instances after upgrade and deploying SWB v5.2.5.\n>\n> If this fixes your issue, please go ahead and close this issue. I am going\n> to mark as closing-soon-if-no-response so we will close in about 7 days if\n> we do not hear that this did not resolve the issue.\n>\n> Thank you for the report!\n>\n> \u2014\n> Reply to this email directly, view it on GitHub\n> <https:\/\/github.com\/awslabs\/service-workbench-on-aws\/issues\/1076#issuecomment-1347314897>,\n> or unsubscribe\n> <https:\/\/github.com\/notifications\/unsubscribe-auth\/ALKETLSEQCFIMAF5HX4CAT3WM6GN3ANCNFSM6AAAAAASWEAJP4>\n> .\n> You are receiving this because you authored the thread.Message ID:\n> ***@***.***>\n>\n Closing this issue since the fix was merged, please feel free to reopen the issue if it persists on your end.",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"bug instanc stop automat bug idl notebook instanc stop specifi time swb run autostop script automat stop notebook instanc script start lifecycl rule instanc cfn templat accord lifecycleconfigonstart log packag miss autostop script doesnt work reproduc step reproduc behavior sure autostopidletimeinminut paramet workspac type config set requir time minut case creat new workspac notebook instanc leav instanc idl time specifi autostopidletimeinminut specifi time instanc stop expect behavior idl notebook instanc automat stop specifi time screenshot version complet follow inform releas version instal addit context add context problem",
        "Issue_preprocessed_content":"instanc stop bug idl instanc stop specifi time swb run script stop instanc script lifecycl rule instanc cfn templat lifecycleconfigonstart log packag autostop script doesnt work reproduc step reproduc behavior sure autostopidletimeinminut paramet workspac type config set requir time creat new workspac instanc leav instanc idl time specifi specifi time instanc expect behavior idl instanc stop specifi time img width alt shot version releas version context context problem",
        "Issue_gpt_summary_original":"The user is encountering an issue where the study folders are not mounted when launching a Sagemaker notebook with an associated study. Upon investigation, the user found that there is no credentials file in the `~\/.aws` folder, which is generated by the `mount_s3.sh` script. The expected behavior is for the study folders to be mounted using the assumed roles in the AWS credentials file. This issue may or may not be associated with another bug the user noted with mounting s3 studies folders.",
        "Issue_gpt_summary":"user encount issu studi folder mount launch notebook associ studi investig user credenti file aw folder gener mount script expect behavior studi folder mount assum role aw credenti file issu associ bug user note mount studi folder",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/awslabs\/service-workbench-on-aws\/issues\/1073",
        "Issue_title":"[Bug] Sagemaker AWS Credentials not Populating",
        "Issue_created_time":1669825870000,
        "Issue_closed_time":1671215597000,
        "Issue_body":"When a Sagemaker notebook is launched with an associated study, the study folders are not mounted. Digging into this, I see that in the `~\/.aws` folder there is no credentials file, which is generated by the `mount_s3.sh` script.\r\n\r\n**To Reproduce**\r\n- Create a new data source (or use an existing one).\r\n- Select it and create a new Sagemaker instance using those studies. (Ensure that the folder has files so you can see them if they mount.)\r\n- After the instance launches, connect to it and see if the study folders are connected. If not, open a terminal and run `ls ~\/.aws` to see if the credential file is there.\r\n\r\n**Expected behavior**\r\nThe study folders are mounted using the assumed roles in the AWS credentials file, generated by `mount_s3.sh` script.\r\n\r\n**Screenshots**\r\n<img width=\"702\" alt=\"Screen Shot 2022-11-30 at 11 27 45 AM\" src=\"https:\/\/user-images.githubusercontent.com\/21109191\/204853707-789607d5-6fca-4a77-911d-50a5c36a549b.png\">\r\n<img width=\"526\" alt=\"Screen Shot 2022-11-30 at 11 27 36 AM\" src=\"https:\/\/user-images.githubusercontent.com\/21109191\/204853710-824ddc98-dfb5-4c8b-abbe-f19fa2453640.png\">\r\n\r\n**Versions (please complete the following information):**\r\n - Versions 5.0.0 & 4.3.1\r\n\r\n**Additional context**\r\nThis may or may not be associated with the other bug I noted with mounting s3 studies folders, [[Bug] SWB Sagemaker Study permission denied](https:\/\/github.com\/awslabs\/service-workbench-on-aws\/issues\/1067). It seems both of these issues are new, within the last couple weeks. And the environment has had no new deployments or changes within that time. Previous to these last couple weeks we had no issues with Sagemaker and study folders mounting.\r\n",
        "Issue_answer_count":11,
        "Issue_self_closed":1.0,
        "Answer_body":"Thanks for the bug report! We are aware of the issue mounting studies to Sagemaker instances and are actively trying to resolve it. We will let you know if we need any more info to help in our debugging. Although I am able to successfully mount studies to RStudio instances, I have noticed that it is inconsistent. \r\nWhen an RStudio instance is first launched, the user must open the terminal. This triggers some code to run automatically which then mounts the studies, making them visible in the file viewer. However, we have noticed that sometimes the studies are never mounted and the sub-folders are not visible to the user. This appears to happen randomly. When we stop, restart, and click into the terminal tab, the issue is resolved. @srpiatt please check the latest release [v5.2.5](https:\/\/github.com\/awslabs\/service-workbench-on-aws\/releases\/tag\/v5.2.5) for the fix to this issue.  Hi! I also want to note that you may need to stop and start any affected instances after upgrade and deploying SWB v5.2.5.\r\n\r\nIf this fixes your issue, please go ahead and close this issue. I am going to mark as closing-soon-if-no-response so we will close in about 7 days if we do not hear that this did not resolve the issue.\r\n\r\nThank you for the report! I pulled the changes committed for v5.2.5 into our forked repository, which is locked at 5.0.0 version. Credentials file is created and the studies folder is able to mount. Thank you! :D Same happen to me in version 5.2.6, terminal trick didn't resolve the issue  This worked for a while, but I just tried launching another instance today to test if we're still encountering a different permissions issue, and encountered this bug again. We have the changes from the v5.2.5 SWB version pulled, as I noted before. I verified that we haven't regressed and that the changes are present in this instance. This is what we're seeing in this new instance, as of today.\r\n\r\n<img width=\"586\" alt=\"Screen Shot 2023-01-09 at 4 29 30 PM\" src=\"https:\/\/user-images.githubusercontent.com\/21109191\/211414692-dd7f4d08-3564-43e3-93b8-839c46f33646.png\">\r\n\r\nCan anyone confirm that they're also seeing this bug again? A new issue popped up that cause this issue to appear again. Please try updating to version 5.2.7. Thanks! I'll give it a try. Is the change related to this commit, [https:\/\/github.com\/awslabs\/service-workbench-on-aws\/commit\/bdf978b1c909c37207902f1b29b0fd05b5b24208](https:\/\/github.com\/awslabs\/service-workbench-on-aws\/commit\/bdf978b1c909c37207902f1b29b0fd05b5b24208)? Until we update our fork to the latest version, we have to cherry pick these sorts of fixes. If yes, I can test that out today and close the ticket again if all good. :) yep, that's it! The changes worked for me. Thanks again, Tim! :D",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"bug aw credenti popul notebook launch associ studi studi folder mount dig aw folder credenti file gener mount script reproduc creat new data sourc us exist select creat new instanc studi ensur folder file mount instanc launch connect studi folder connect open termin run aw credenti file expect behavior studi folder mount assum role aw credenti file gener mount script screenshot version complet follow inform version addit context associ bug note mount studi folder bug swb studi permiss deni http github com awslab servic workbench aw issu issu new coupl week environ new deploy chang time previou coupl week issu studi folder mount",
        "Issue_preprocessed_content":"aw credenti popul launch studi studi folder mount folder credenti file gener script reproduc creat new data sourc select creat new instanc studi instanc launch studi folder open termin run credenti file expect behavior studi folder mount role aw credenti file gener script img width alt shot img width alt shot version version context bug note mount studi folder swb studi new coupl environ new deploy chang time previou coupl studi folder mount",
        "Issue_gpt_summary_original":"The user encountered an issue where an older Sagemaker instance was turned on, but one of the two study folders associated was not syncing any of the files. The system logs showed an error message indicating permission denied. The S3mounts parameter for the older instance that failed to sync was compared to a newer instance, and it was found that the FS role number for the private workspace study that wouldn't sync was different. The user is unsure what could cause the fs role number to change for a study and what else could cause this permissions denied error. This issue is causing a significant problem for the user as people actively using SWB have lost their work on Sagemaker stop because the folder they saved to isn't syncing.",
        "Issue_gpt_summary":"user encount issu older instanc turn studi folder associ sync file log show error messag indic permiss deni smount paramet older instanc fail sync compar newer instanc role number privat workspac studi wouldn sync differ user unsur caus role number chang studi caus permiss deni error issu caus signific problem user peopl activ swb lost work stop folder save isn sync",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/awslabs\/service-workbench-on-aws\/issues\/1067",
        "Issue_title":"[Bug] SWB Sagemaker Study permission denied",
        "Issue_created_time":1668634688000,
        "Issue_closed_time":null,
        "Issue_body":"We encountered an issue where an older Sagemaker instance (>2 months) was turned on. After starting, one of the two study folders associated were not syncing any of the files. In the system logs there's this error: `Nov 11 16:21:45 <ip redacted> \/usr\/local\/bin\/goofys[9204]: main.ERROR Unable to access '<bucket A, name redacted>': permission denied`\r\n\r\nComparing the S3mounts parameter for the Sagemaker stack of the older instance that fails to sync, and a newer instance (with the same studies), I see that the FS role number for the private workspace study that wouldn't sync is different.\r\n\r\nOld stack S3mounts parameter:\r\n```\r\n[\r\n  {\r\n    \"id\": \"Private-workspace\",\r\n    \"bucket\": \"<bucket A, name redacted>\",\r\n    \"region\": \"us-east-1\",\r\n    \"roleArn\": \"arn:aws:iam::<account redacted>:role\/swb-LhDhyIAqCHc0a4vrlU256w-fs-1662735997814\",\r\n    \"prefix\": \"Private-workspace\/\",\r\n    \"readable\": true,\r\n    \"writeable\": true\r\n  },\r\n  {\r\n    \"id\": \"READ-only\",\r\n    \"bucket\": \"<bucket A, name redacted>\",\r\n    \"region\": \"us-east-1\",\r\n    \"roleArn\": \"arn:aws:iam::<account redacted>:role\/swb-LhDhyIAqCHc0a4vrlU256w-fs-1661808852807\",\r\n    \"prefix\": \"READ-only\/\",\r\n    \"readable\": true,\r\n    \"writeable\": false\r\n  }\r\n]\r\n```\r\n\r\nNew stack S3mounts parameter:\r\n```\r\n[\r\n  {\r\n    \"id\": \"Private-workspace\",\r\n    \"bucket\": \"<bucket A, name redacted>\",\r\n    \"region\": \"us-east-1\",\r\n    \"roleArn\": \"arn:aws:iam::<account redacted>:role\/swb-LhDhyIAqCHc0a4vrlU256w-fs-1668521384862\",\r\n    \"prefix\": \"Private-workspace\/\",\r\n    \"readable\": true,\r\n    \"writeable\": true\r\n  },\r\n  {\r\n    \"id\": \"READ-only\",\r\n    \"bucket\": \"<bucket A, name redacted>\",\r\n    \"region\": \"us-east-1\",\r\n    \"roleArn\": \"arn:aws:iam::<account redacted>:role\/swb-LhDhyIAqCHc0a4vrlU256w-fs-1661808852807\",\r\n    \"prefix\": \"READ-only\/\",\r\n    \"readable\": true,\r\n    \"writeable\": false\r\n  }\r\n]\r\n```\r\n\r\nSome additional context, this bucket (and the associated SWB data source) that the two studies are a part of gets updated every couple months to add new study folders\/ids, but the existing studies don't typically change.\r\n\r\nWhat could cause the fs role number to change for a study? What else could cause this permissions denied error? \r\n\r\nThis is a pretty big problem for us, as we have had people actively using SWB and all their work is gone on Sagemaker stop, because the folder they saved to isn't syncing.\r\n\r\n**Versions (please complete the following information):**\r\n - SWB 4.3.1\r\n",
        "Issue_answer_count":24,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"bug swb studi permiss deni encount issu older instanc month turn start studi folder associ sync file log error nov usr local bin goofi main error unabl access permiss deni compar smount paramet stack older instanc fail sync newer instanc studi role number privat workspac studi wouldn sync differ old stack smount paramet privat workspac bucket region east rolearn arn aw iam role swb lhdhyiaqchcavrluw prefix privat workspac readabl true writeabl true read bucket region east rolearn arn aw iam role swb lhdhyiaqchcavrluw prefix read readabl true writeabl fals new stack smount paramet privat workspac bucket region east rolearn arn aw iam role swb lhdhyiaqchcavrluw prefix privat workspac readabl true writeabl true read bucket region east rolearn arn aw iam role swb lhdhyiaqchcavrluw prefix read readabl true writeabl fals addit context bucket associ swb data sourc studi get updat coupl month add new studi folder id exist studi typic chang caus role number chang studi caus permiss deni error pretti big problem peopl activ swb work gone stop folder save isn sync version complet follow inform swb",
        "Issue_preprocessed_content":"swb studi deni encount older instanc turn start studi folder sync file log compar mount paramet stack older instanc fail sync newer instanc role number privat workspac studi wouldn sync old stack mount paramet new stack mount paramet context bucket studi get updat coupl month new studi exist studi chang caus role number chang studi caus deni big problem peopl activ swb work gone stop folder save isn sync version swb",
        "Issue_gpt_summary_original":"The user encountered an issue where an older Sagemaker instance was turned on, but one of the two study folders associated was not syncing any of the files. The system logs showed an error related to permission denied. Upon comparing the S3mounts parameter for the older instance and a newer instance, the user found that the FS role number for the private workspace study that wouldn't sync is different. The user is seeking to understand what could cause the fs role number to change for a study.",
        "Issue_gpt_summary":"user encount issu older instanc turn studi folder associ sync file log show error relat permiss deni compar smount paramet older instanc newer instanc user role number privat workspac studi wouldn sync differ user seek understand caus role number chang studi",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/awslabs\/service-workbench-on-aws\/issues\/1066",
        "Issue_title":"[Bug] SWB Sagemaker Study permission denied",
        "Issue_created_time":1668633119000,
        "Issue_closed_time":1668634670000,
        "Issue_body":"We encountered an issue where an older Sagemaker instance (>2 months) was turned on. After starting, one of the two study folders associated were not syncing any of the files. In the system logs there's this error: `Nov 11 16:21:45 <ip redacted> \/usr\/local\/bin\/goofys[9204]: main.ERROR Unable to access '<bucket A, name redacted>': permission denied`\r\n\r\nComparing the S3mounts parameter for the Sagemaker stack of the older instance that fails to sync, and a newer instance (with the same studies), I see that the FS role number for the private workspace study that wouldn't sync is different.\r\n\r\nOld stack S3mounts parameter:\r\n```\r\n[\r\n  {\r\n    \"id\": \"Private-workspace\",\r\n    \"bucket\": \"<bucket A, name redacted>\",\r\n    \"region\": \"us-east-1\",\r\n    \"roleArn\": \"arn:aws:iam::<account redacted>:role\/swb-LhDhyIAqCHc0a4vrlU256w-fs-1662735997814\",\r\n    \"prefix\": \"Private-workspace\/\",\r\n    \"readable\": true,\r\n    \"writeable\": true\r\n  },\r\n  {\r\n    \"id\": \"READ-only\",\r\n    \"bucket\": \"<bucket A, name redacted>\",\r\n    \"region\": \"us-east-1\",\r\n    \"roleArn\": \"arn:aws:iam::<account redacted>:role\/swb-LhDhyIAqCHc0a4vrlU256w-fs-1661808852807\",\r\n    \"prefix\": \"READ-only\/\",\r\n    \"readable\": true,\r\n    \"writeable\": false\r\n  }\r\n]\r\n```\r\n\r\nNew stack S3mounts parameter:\r\n```\r\n[\r\n  {\r\n    \"id\": \"Private-workspace\",\r\n    \"bucket\": \"<bucket A, name redacted>\",\r\n    \"region\": \"us-east-1\",\r\n    \"roleArn\": \"arn:aws:iam::<account redacted>:role\/swb-LhDhyIAqCHc0a4vrlU256w-fs-1668521384862\",\r\n    \"prefix\": \"Private-workspace\/\",\r\n    \"readable\": true,\r\n    \"writeable\": true\r\n  },\r\n  {\r\n    \"id\": \"READ-only\",\r\n    \"bucket\": \"<bucket A, name redacted>\",\r\n    \"region\": \"us-east-1\",\r\n    \"roleArn\": \"arn:aws:iam::<account redacted>:role\/swb-LhDhyIAqCHc0a4vrlU256w-fs-1661808852807\",\r\n    \"prefix\": \"READ-only\/\",\r\n    \"readable\": true,\r\n    \"writeable\": false\r\n  }\r\n]\r\n```\r\n\r\nSome additional context, this bucket (and the associated SWB data source) that the two studies are a part of gets updated every couple months to add new study folders\/ids.\r\n\r\nMy question is: What could cause the fs role number to change for a study?\r\n\r\n**Versions (please complete the following information):**\r\n - SWB 4.3.1\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"I'm elevating this to a bug.",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"bug swb studi permiss deni encount issu older instanc month turn start studi folder associ sync file log error nov usr local bin goofi main error unabl access permiss deni compar smount paramet stack older instanc fail sync newer instanc studi role number privat workspac studi wouldn sync differ old stack smount paramet privat workspac bucket region east rolearn arn aw iam role swb lhdhyiaqchcavrluw prefix privat workspac readabl true writeabl true read bucket region east rolearn arn aw iam role swb lhdhyiaqchcavrluw prefix read readabl true writeabl fals new stack smount paramet privat workspac bucket region east rolearn arn aw iam role swb lhdhyiaqchcavrluw prefix privat workspac readabl true writeabl true read bucket region east rolearn arn aw iam role swb lhdhyiaqchcavrluw prefix read readabl true writeabl fals addit context bucket associ swb data sourc studi get updat coupl month add new studi folder id question caus role number chang studi version complet follow inform swb",
        "Issue_preprocessed_content":"swb studi deni encount older instanc turn start studi folder sync file log compar mount paramet stack older instanc fail sync newer instanc role number privat workspac studi wouldn sync old stack mount paramet new stack mount paramet context bucket studi get updat coupl month new studi question caus role number chang studi version swb",
        "Issue_gpt_summary_original":"The user encountered an issue with the Sagemaker autostop script, which caused instances to hang around for days. The cron job was failing due to a syntax error in the autostop.py script, which was not present in the file on the repo or the S3 bucket. The error was caused by a line introduced in a recent commit, and it is unclear how it got into the Sagemaker notebook and why it was not overridden by the custom config start. The expected behavior is for the autostop script in the S3 bucket to be used for SWB Sagemaker instances.",
        "Issue_gpt_summary":"user encount issu autostop script caus instanc hang dai cron job fail syntax error autostop script present file repo bucket error caus line introduc recent commit unclear got notebook overridden custom config start expect behavior autostop script bucket swb instanc",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/awslabs\/service-workbench-on-aws\/issues\/1065",
        "Issue_title":"[Bug] Sagemaker autostop script not pulling from s3 bucket",
        "Issue_created_time":1668620515000,
        "Issue_closed_time":1671215663000,
        "Issue_body":"**Describe the bug**\r\nWe encountered an interesting issue regarding the auto stop script. We had no code changes, but suddenly, Sagemaker instances started hanging around for days, with no use. Looking into the instance, the cron job was failing, because the autostop.py script had a syntax error. When I look at the script, it has this line `print(f'Notebook idle state set as {idle} because no kernel has been detected.')` which caused the syntax error. However, the file on the repo, as well as the s3 bucket, does not contain this line. So, after some digging, I found that this line was introduced here, in this commit [aws-samples\/amazon-sagemaker-notebook-instance-lifecycle-config-samples\/](https:\/\/github.com\/aws-samples\/amazon-sagemaker-notebook-instance-lifecycle-config-samples\/commit\/fdace58a6b9401c53dc17f5c64bef3ec40dbc70e). What I don't understand is how it got into the Sagemaker notebook, and why it's not being overridden by the custom config start we have here [sagemaker-notebook-instance.cfn.yml](https:\/\/github.com\/awslabs\/service-workbench-on-aws\/blob\/mainline\/addons\/addon-base-raas\/packages\/base-raas-cfn-templates\/src\/templates\/service-catalog\/sagemaker-notebook-instance.cfn.yml#L264-L272) This script and repo was updated in the last 16 hours to remove this syntax error.\r\n\r\n**To Reproduce**\r\nLaunch a Sagemaker instance. You can tell which version of the script it's using by looking at the autostop script, `less \/usr\/local\/bin\/autostop.py` and find lines 96-101.\r\n\r\nThe AWS version of the script on the `awslabs\/service-workbench-on-aws` repo has these lines, [reference](https:\/\/github.com\/awslabs\/service-workbench-on-aws\/blob\/mainline\/main\/solution\/post-deployment\/config\/environment-files\/offline-packages\/sagemaker\/autostop.py#L96-L100)\r\n```\r\nif notebook['kernel']['connections'] == 0:\r\n    if not is_idle(notebook['kernel']['last_activity']):\r\n        idle = False\r\nelse:\r\n    idle = False\r\n```\r\nAnd on the `aws-samples\/amazon-sagemaker-notebook-instance-lifecycle-config-samples` repo, [reference](https:\/\/github.com\/aws-samples\/amazon-sagemaker-notebook-instance-lifecycle-config-samples\/blob\/master\/scripts\/auto-stop-idle\/autostop.py#L96-L101)\r\n```\r\nif notebook['kernel']['connections'] == 0:\r\n    if not is_idle(notebook['kernel']['last_activity']):\r\n        idle = False\r\nelse:\r\n    idle = False\r\n    print('Notebook idle state set as %s because no kernel has been detected.' % idle)\r\n```\r\n\r\n**Expected behavior**\r\nThe autostop script in the s3 bucket should be the one used for SWB Sagemaker instances.\r\n\r\n**Screenshots**\r\n<img width=\"1510\" alt=\"Screen Shot 2022-11-16 at 12 14 21 PM\" src=\"https:\/\/user-images.githubusercontent.com\/21109191\/202251401-67da0253-e74e-40e9-8150-99a4a27017ff.png\">\r\n\r\n**Versions (please complete the following information):**\r\n - SWB 4.3.1\r\n",
        "Issue_answer_count":16,
        "Issue_self_closed":1.0,
        "Answer_body":"Just want to verify that the autostop script in your bucket had not been updated at some point in the past unexpectedly. Is that correct? Yes-- none of the files on the s3 bucket were changed in several months. I also downloaded the autostop script from the bucket to verify manually that it matches the SWB repo version. I was not able to replicate this in v5.2.2:\r\n<img width=\"937\" alt=\"Screen Shot 2022-11-30 at 3 34 26 PM\" src=\"https:\/\/user-images.githubusercontent.com\/43092418\/204903064-013c1899-2763-4c88-8cce-7b39128b0240.png\">\r\n\r\nIf you look at the CloudWatch log group \/aws\/sagemaker\/NotebookInstances\/BasicNotebookInstance-<id>\/LifecycleConfigOnStart do you see the following output (would be towards the end):\r\n<img width=\"960\" alt=\"Screen Shot 2022-11-30 at 3 36 08 PM\" src=\"https:\/\/user-images.githubusercontent.com\/43092418\/204903303-d180144c-62d9-4775-a233-83687012715b.png\">\r\nThis is triggered on start of the instance. The screenshot you posted was from your instance, correct? Do you see the lines, \r\n```\r\nprint('Notebook is not idle:', notebook['kernel']['execution_state'])\r\nidle = False\r\n``` \r\nthis line comes from this repo [aws-samples\/amazon-sagemaker-notebook-instance-lifecycle-config-samples](https:\/\/github.com\/aws-samples\/amazon-sagemaker-notebook-instance-lifecycle-config-samples\/blob\/master\/scripts\/auto-stop-idle\/autostop.py#L100-L101). It should be only the one line, like below\r\n```\r\nidle = False\r\n``` \r\nwhich comes from SWB here [awslabs\/service-workbench-on-aws](https:\/\/github.com\/awslabs\/service-workbench-on-aws\/blob\/mainline\/main\/solution\/post-deployment\/config\/environment-files\/offline-packages\/sagemaker\/autostop.py#L100)\r\n\r\nThe s3 file says it's downloaded, but for whatever reason it's not using that downloaded file, and instead using the file on aws-samples\/amazon-sagemaker-notebook-instance-lifecycle-config-samples. This introduces SWB to vulnerabilities when this code is changes and a bug is introduced in that repo. SWB should instead use the autostop script that it has saved in s3, because that is locked and changes that aren't intended wouldn't be introduced. The screenshot is from my instance, yes. SWB repo contains the lines:\r\n```\r\nprint('Notebook is not idle:', notebook['kernel']['execution_state'])\r\nidle = False\r\n```\r\n[here](https:\/\/github.com\/awslabs\/service-workbench-on-aws\/blob\/61200d06d1a607b9c0a209240813b261ade2c5e9\/main\/solution\/post-deployment\/config\/environment-files\/offline-packages\/sagemaker\/autostop.py#L105). It is the lines:\r\n```\r\nidle = False\r\nprint('Notebook idle state set as %s because no kernel has been detected.' % idle)\r\n```\r\nthat I thought you said were presenting the problem (that are in the samples repo but not SWB). Is that correct?\r\n\r\nHowever, I see that my instance is not stopping even though the autostop script is the same as the SWB repo.\r\n\r\nWhere did you see the error on the cron job for the autostop? Also, to clarify, you see that the Cloudwatch logs copy from the s3 bucket to local and that the s3 bucket file is the correct file? Yet, you see the wrong file when you less the file on the instance? Oh, you're right I was looking at the wrong line. My apologies! \r\n\r\nYes- for us it's successfully copying the correct file from s3 (which I downloaded to verify), but the autostop script (`\/usr\/local\/bin\/autostop.py`) is the wrong copy. Got it. And where do you see the cron job failing? Because it was not overwriting the autostop script with the one from our s3 bucket, and instead defaulting to the script from `aws-samples\/amazon-sagemaker-notebook-instance-lifecycle-config-samples`,  when the repo owners introduced this commit: https:\/\/github.com\/aws-samples\/amazon-sagemaker-notebook-instance-lifecycle-config-samples\/commit\/fdace58a6b9401c53dc17f5c64bef3ec40dbc70e, the cron job failed on lines like `print(f'Notebook idle state set as {idle} since kernel connections are ignored.')`, stating that the `print(f` part was invalid syntax.\r\n\r\nI guess the key issue is really why it didn't overwrite this default script with the s3 one, considering it successfully downloaded the one from s3. Secondly, it seems odd that this repo is somehow the default autostop script that the Sagemaker system uses. This introduces bugs if there's a failure in that script or a malicious commit. Yes, I see the problem in the other repo's commit. I am still trying to debug how the script is on your Sagemaker instance.\r\n\r\nGot ~two~ three more questions:\r\n1. Where _in you account_ did you see that error message from the cron job? CloudWatch logs? Sagemaker? etc.\r\n2. Are you working with AppStream-enabled SWB? Does Sagemaker have to go through AppStream to connect?\r\n3. What is the output from running this command in a terminal on the sagemaker instance: `\/usr\/bin\/python \/usr\/local\/bin\/autostop.py --time 300 --ignore-connections`? Sure. :D Yeah I don't know how the script was there automatically. I didn't see any code in our repo that would cause it to pull from there.\r\n\r\nWe do not have appstream enabled, but we do send traffic through a proxy lambda as well as a firewall instance. However, all the environment files that get downloaded for the bootstrap process were successful, so I don't think it was a network issue.\r\n\r\nThe reason I checked the autostop script was because I saw no note in the `\/var\/log\/autostop.log` file that the script is sent to via cron job. So I ran the script by hand.\r\n\r\nFor instance, right now autostop is not working. There's no messaging that tells you it's not working. When you look at the cron logs it shows this, with no errors. The `\/var\/log\/autostop.log` script doesn't show any messages or errors.\r\n```\r\n[root@ip-10-10-57-235 ec2-user]# grep autostop \/var\/log\/cron | tail -n 1\r\nDec  1 18:14:01 ip-10-10-57-235 CROND[9860]: (root) CMD (\/usr\/bin\/python \/usr\/local\/bin\/autostop.py --time 3600 --ignore-connections >> \/var\/log\/autostop.log)\r\n```\r\n\r\nBut if you run the autostop script exactly as the cron job has it, like below, you get an error \/right now\/ related to a boto3 import issue.\r\n```\r\n[root@ip-10-10-57-235 ec2-user]# \/usr\/bin\/python \/usr\/local\/bin\/autostop.py --time 3600\r\nTraceback (most recent call last):\r\n  File \"\/usr\/local\/bin\/autostop.py\", line 18, in <module>\r\n    import boto3\r\nImportError: No module named boto3\r\n```\r\n\r\nBoto3 changes were introduced in a commit here, [in the on-start script on aws-samples\/amazon-sagemaker-notebook-instance-lifecycle-config-samples](https:\/\/github.com\/aws-samples\/amazon-sagemaker-notebook-instance-lifecycle-config-samples\/commit\/13b4023c9dca45fea58b2129fe5848619284653a#diff-54051e148aa00ee3fa158cc346d6c243418d14718a6760171ef562887977748f) Yup, so I also get that problem when I try to invoke the autostop script (and my autostop script matches the SWB one). I think that is the root cause of this problem. I will add a backlog item to figure out why boto3 is not being imported correctly so that sagemaker notebooks can use them for autostop. \r\n\r\nIt still does not explain why you got the amazon-sagemaker-notebook-instance-lifecycle-config-samples in the instance. Was that only present in one instance or all instances? Is it possible someone manually changed the files when trying to debug the autostop not working?\r\n\r\nThanks so much for working through this with me! Yeah, no problem-- thanks for your patience and attention! :D\r\n\r\nI don't believe that the files have been altered. I am currently the only person on my team actively responsible for doing admin\/infrastructure activities for these systems. I've tried this on new instances to rule out individual Sagemaker systems changes by users. We have two different version of SWB deployed-- maybe there's a difference between versions.  @srpiatt please upgrade your SWB installation to the latest release [v5.2.5](https:\/\/github.com\/awslabs\/service-workbench-on-aws\/releases\/tag\/v5.2.5). Sagemaker made a change that caused all new instances to be spun up with the AL2 operating system. New Sagemaker instances will no longer be able to mount studies or autostop without the fix in v5.2.5 Hi! I also want to note that you may need to stop and start any affected instances after upgrade and deploying SWB v5.2.5.\r\n\r\nIf this fixes your issue, please go ahead and close this issue. I am going to mark as closing-soon-if-no-response so we will close in about 7 days if we do not hear that this did not resolve the issue.\r\n\r\nThank you for the report! I pulled the changes committed for v5.2.5 into our forked repository, which is locked at 5.0.0 version. Auto stop works. Still not sure how the file got replaced with the one in that repo, but it's a non-issue at the moment. Thank you! :D",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"bug autostop script pull bucket bug encount interest issu auto stop script code chang suddenli instanc start hang dai us look instanc cron job fail autostop script syntax error look script line print notebook idl state set idl kernel detect caus syntax error file repo bucket contain line dig line introduc commit aw sampl amazon notebook instanc lifecycl config sampl http github com aw sampl amazon notebook instanc lifecycl config sampl commit fdaceabcdcfcbefecdbc understand got notebook overridden custom config start notebook instanc cfn yml http github com awslab servic workbench aw blob mainlin addon addon base raa packag base raa cfn templat src templat servic catalog notebook instanc cfn yml script repo updat hour remov syntax error reproduc launch instanc tell version script look autostop script usr local bin autostop line aw version script awslab servic workbench aw repo line refer http github com awslab servic workbench aw blob mainlin main solut post deploy config environ file offlin packag autostop notebook kernel connect idl notebook kernel activ idl fals idl fals aw sampl amazon notebook instanc lifecycl config sampl repo refer http github com aw sampl amazon notebook instanc lifecycl config sampl blob master script auto stop idl autostop notebook kernel connect idl notebook kernel activ idl fals idl fals print notebook idl state set kernel detect idl expect behavior autostop script bucket swb instanc screenshot version complet follow inform swb",
        "Issue_preprocessed_content":"autostop script bucket bug encount interest auto stop script code chang instanc start hang dai us instanc cron job fail script syntax script line caus syntax file repo bucket contain line line introduc understand got custom config start script repo updat hour remov syntax reproduc launch instanc version script autostop script line aw version script repo line repo expect behavior autostop script bucket swb instanc img width alt shot version swb",
        "Issue_gpt_summary_original":"The user is unable to launch SageMaker notebook instances due to a missing permission for `sagemaker:AddTags`. This issue persists even when custom tags are not included in the workspace configuration. The error message indicates that the user is not authorized to perform the `sagemaker:AddTags` action on the resource.",
        "Issue_gpt_summary":"user unabl launch notebook instanc miss permiss addtag issu persist custom tag includ workspac configur error messag indic user author perform addtag action resourc",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/awslabs\/service-workbench-on-aws\/issues\/1018",
        "Issue_title":"[Bug] SageMaker instances can't be launched due to missing tags permission",
        "Issue_created_time":1658897296000,
        "Issue_closed_time":1659686697000,
        "Issue_body":"**Describe the bug**\r\nService Workbench appears to be unable to launch SageMaker notebook instances at all, due to a missing permission for `sagemaker:AddTags`. This seems to also be the case when custom tags aren't included in the workspace configuration.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Install Service Workbench from the latest version.\r\n2. Create a workspace configuration for a SageMaker notebook.\r\n3. Launch a workspace using the new configuration.\r\n4. Wait a few minutes and observe the error.\r\n\r\n**Expected behavior**\r\nExpected the notebook to launch :)\r\n\r\n**Screenshots**\r\n![image](https:\/\/user-images.githubusercontent.com\/900469\/181163664-98441ee8-7316-4d29-8f85-79d3e5e6ed3c.png)\r\n```\r\nError provisioning environment TestNotebook1. Reason: Errors from CloudFormation: [{LogicalResourceId : SC-455040667691-pp-auh6sv7j6dwr2, ResourceType : AWS::CloudFormation::Stack, StatusReason : The following resource(s) failed to create: [BasicNotebookInstance]. Rollback requested by user.}, {LogicalResourceId : BasicNotebookInstance, ResourceType : AWS::SageMaker::NotebookInstance, StatusReason : User: arn:aws:sts::XXXXXXXXXXXX:assumed-role\/dev-syd-timswb-LaunchConstraint\/servicecatalog is not authorized to perform: sagemaker:AddTags on resource: arn:aws:sagemaker:ap-southeast-2:XXXXXXXXXXXX:assumed:notebook-instance\/basicnotebookinstance-y4ices04e3sv because no identity-based policy allows the sagemaker:AddTags action (Service: AmazonSageMaker; Status Code: 400; Error Code: AccessDeniedException; Request ID: adee97b7-1c89-47e2-8ca7-5aa374a80004; Proxy: null)}, {LogicalResourceId : IAMRole, ResourceType : AWS::IAM::Role, StatusReason : Resource creation Initiated}, {LogicalResourceId : SecurityGroup, ResourceType : AWS::EC2::SecurityGroup, StatusReason : Resource creation Initiated}, {LogicalResourceId : InstanceRolePermissionBoundary, ResourceType : AWS::IAM::ManagedPolicy, StatusReason : Resource creation Initiated}, {LogicalResourceId : BasicNotebookInstanceLifecycleConfig, ResourceType : AWS::SageMaker::NotebookInstanceLifecycleConfig, StatusReason : Resource creation Initiated}, {LogicalResourceId : SC-455040667691-pp-auh6sv7j6dwr2, ResourceType : AWS::CloudFormation::Stack, StatusReason : User Initiated}]\r\n```\r\n\r\n**Versions (please complete the following information):**\r\n5.2.0\r\n(also replicated on an older 5.0.0 install)\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "Issue_answer_count":3,
        "Issue_self_closed":0.0,
        "Answer_body":"Further context - this only started happening approx. 32 hours ago. If I had to guess... maybe it should have never worked and something just happened to get 'fixed' in the IAM API yesterday? \ud83d\ude01  Hi @tdmalone is this still an issue? Hi @kcadette, it is, yes:\r\n\r\n```\r\nUser: arn:aws:sts::xxxxxxxxxxxx:assumed-role\/dev-syd-timswb-LaunchConstraint\/servicecatalog is not authorized to perform: sagemaker:AddTags on resource: arn:aws:sagemaker:ap-southeast-2:xxxxxxxxxxxx:notebook-instance\/basicnotebookinstance-lqerepcrnmaw because no identity-based policy allows the sagemaker:AddTags action (Service: AmazonSageMaker; Status Code: 400; Error Code: AccessDeniedException; Request ID: 4f72193d-aa17-41b9-8ed0-ee381686cb5b; Proxy: null)}\r\n```\r\n\r\nIt should be a one-line fix, so I've submitted a PR: https:\/\/github.com\/awslabs\/service-workbench-on-aws\/pull\/1021",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"bug instanc launch miss tag permiss bug servic workbench appear unabl launch notebook instanc miss permiss addtag case custom tag aren includ workspac configur reproduc step reproduc behavior instal servic workbench latest version creat workspac configur notebook launch workspac new configur wait minut observ error expect behavior expect notebook launch screenshot imag http user imag githubusercont com deeedc png error provis environ testnotebook reason error cloudform logicalresourceid auhsvjdwr resourcetyp aw cloudform stack statusreason follow resourc fail creat basicnotebookinst rollback request user logicalresourceid basicnotebookinst resourcetyp aw notebookinst statusreason user arn aw st xxxxxxxxxxxx assum role dev syd timswb launchconstraint servicecatalog author perform addtag resourc arn aw southeast xxxxxxxxxxxx assum notebook instanc basicnotebookinst yicesesv ident base polici allow addtag action servic amazon statu code error code accessdeniedexcept request adeeb aaa proxi null logicalresourceid iamrol resourcetyp aw iam role statusreason resourc creation initi logicalresourceid securitygroup resourcetyp aw securitygroup statusreason resourc creation initi logicalresourceid instancerolepermissionboundari resourcetyp aw iam managedpolici statusreason resourc creation initi logicalresourceid basicnotebookinstancelifecycleconfig resourcetyp aw notebookinstancelifecycleconfig statusreason resourc creation initi logicalresourceid auhsvjdwr resourcetyp aw cloudform stack statusreason user initi version complet follow inform replic older instal addit context add context problem",
        "Issue_preprocessed_content":"instanc launch tag bug servic workbench unabl launch instanc case custom tag aren includ workspac configur reproduc step reproduc behavior servic workbench latest version creat workspac configur launch workspac new configur wait minut observ expect behavior expect launch version replic older context context problem",
        "Issue_gpt_summary_original":"The user's SageMaker Notebook-v3 workspace that was previously working fine is now showing an \"Unknown\" status and cannot be connected to. Clicking on connect results in an empty window and an error message appears when going back to the SWB page. The expected behavior is that the workspace should be \"Stopped\" and accessible when clicking on Connect. The issue occurred despite the workspace working fine the previous week. The release version installed is 3.3.1.",
        "Issue_gpt_summary":"user notebook workspac previous work fine show unknown statu connect click connect result window error messag appear go swb page expect behavior workspac stop access click connect issu occur despit workspac work fine previou week releas version instal",
        "Issue_score_count":2
    },
    {
        "Issue_link":"https:\/\/github.com\/awslabs\/service-workbench-on-aws\/issues\/708",
        "Issue_title":"[Bug] SageMaker Notebook-v3 Workspace changed to \"Unknown\" status and cannot connect anymore",
        "Issue_created_time":1631554276000,
        "Issue_closed_time":1633460282000,
        "Issue_body":"**Describe the bug**\r\nA SageMaker Notebook-v3 workspace that was working fine on Friday today appears with the status as \"Unknown\". \r\nWhen clicking on connect the new window pop up but is empty, and when going back to the SWB page, we see the message, \"We have a problem! Something went wrong\"\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to 'Workspaces'\r\n2. Look for the workspace that was expected to be \"Stoped\"\r\n2. Click on 'connect'\r\n4. See error\r\n\r\n**Expected behavior**\r\nThat the workspace was \"Stopped\" and when clicking on Connect we can access to the workspace. \r\n\r\n**Screenshots**\r\n![Screen Shot 2021-09-13 at 1 27 57 PM](https:\/\/user-images.githubusercontent.com\/19646530\/133129766-85139082-e6e7-4fe1-8624-dedebf573ea5.png)\r\n\r\n**Versions (please complete the following information):**\r\nRelease Version installed: 3.3.1\r\n\r\n**Additional context**\r\nThe workspace was working fine all previous week, autostop and connect without any issue. Unknown status found today.",
        "Issue_answer_count":2,
        "Issue_self_closed":0.0,
        "Answer_body":"I think there's a good chance this instance was autostopped, but that information was not propagated to DDB correctly.\r\n\r\nCan you log onto the hosting account for that Sagemaker instance and check if it's currently in the `Stopped` state. If yes, the latest code fixes that issue.\r\nhttps:\/\/github.com\/awslabs\/service-workbench-on-aws\/commit\/8cb199b8093f5e799d2d87c228930a4929ebebb7 Hi @nguyen102 yes, I can confirm that the Sagemaker instance is  in the Stopped sate. So then, the latest code that you mention should fix the issue. ",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"bug notebook workspac chang unknown statu connect anymor bug notebook workspac work fine fridai todai appear statu unknown click connect new window pop go swb page messag problem went wrong reproduc step reproduc behavior workspac look workspac expect stope click connect error expect behavior workspac stop click connect access workspac screenshot screen shot http user imag githubusercont com dedebfea png version complet follow inform releas version instal addit context workspac work fine previou week autostop connect issu unknown statu todai",
        "Issue_preprocessed_content":"workspac chang unknown statu anymor bug workspac work fine fridai todai statu unknown click new window pop go swb page problem went wrong reproduc step reproduc behavior workspac workspac expect stope click expect behavior workspac click workspac version releas version context workspac work fine previou autostop unknown statu todai",
        "Issue_gpt_summary_original":"The user is encountering an error message \"null is not an object\" while trying to connect to Sagemaker notebook. The error is intermittent and occurs after the workspace has been open for a while. The notebook window is not opened after clicking on 'Connect'. The expected behavior is a new window should open with a Jupyter\/Sagemaker notebook in a new window.",
        "Issue_gpt_summary":"user encount error messag null object try connect notebook error intermitt occur workspac open notebook window open click connect expect behavior new window open jupyt notebook new window",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/awslabs\/service-workbench-on-aws\/issues\/620",
        "Issue_title":"\"null is not an object\" while trying to connect to Sagemaker notebook.",
        "Issue_created_time":1628006476000,
        "Issue_closed_time":1643923114000,
        "Issue_body":"**Describe the bug**\r\nOccasionally after starting a Sagemaker workspace, clicking 'Connect' gives an error in the bottom right-hand corner of the screen:\r\n\r\n> We have a problem!\r\n> null is not an object (evaluating 'l.location=s') \r\n\r\nin a little red box on the bottom-right of the screen. The notebook window is not opened after clicking on 'Connect'.\r\n\r\n**To Reproduce**\r\nThe error is intermittent. I *think* it may happen after the SW window has been open a while, because I noticed that the SW window automatically logged me out shortly after seeing this error.\r\n\r\n1. Click 'Start' for Sagemaker workspace and wait for the status to change to 'Available'. \r\n2. Click 'Connections', then 'Connect'\r\n3. See error\r\n\r\nWhen I logged out and back into Service Workbench, and was able to connect to the workspace successfully. \r\n\r\n**Expected behavior**\r\nA new window should open with a Jupyter\/Sagemaker notebook in a new window. \r\n\r\n**Versions (please complete the following information):**\r\n - 3.2.0\r\n",
        "Issue_answer_count":4,
        "Issue_self_closed":0.0,
        "Answer_body":"Hi @tom-christie, we believe the issue mentioned is due to access token getting expired. Please feel free to use the latest version with the fix ([v3.3.1](https:\/\/github.com\/awslabs\/service-workbench-on-aws\/releases\/tag\/v3.3.1)). We're seeing this issue on 4.1.1 as well. However, it appears to be persistent (i.e. it happens every time we connect to a SageMaker workspace). So far, we've only tested a single workspace config, but the error consistently shows up when we try to connect to different workspace instances using the same config. The workspace instances are new and running, at least as shown in the SWB UI. We haven't verified if the instances are available in the SageMaker console, however. Is it possible this is related to a popup blocker as reported in GALI-1224? It creates a similar error message.\r\nhttps:\/\/sim.amazon.com\/issues\/CHAMDOC-17 Yeah, I've seen the error happen because popups are disabled for the SWB domain. Once you enable popup for the SWB domain, it should allow you to connect to Sagemaker. Feel free to reopen this ticket if enabling popups didn't resolve your issue.",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"null object try connect notebook bug occasion start workspac click connect give error right hand corner screen problem null object evalu locat littl red box right screen notebook window open click connect reproduc error intermitt think happen window open notic window automat log shortli see error click start workspac wait statu chang avail click connect connect error log servic workbench abl connect workspac successfulli expect behavior new window open jupyt notebook new window version complet follow inform",
        "Issue_preprocessed_content":"object try bug start workspac click give corner problem object red box right window open click reproduc think window open notic window shortli click start workspac wait statu chang avail click servic workbench abl workspac expect behavior new window open jupyt new window version",
        "Issue_gpt_summary_original":"Users are experiencing an intermittent issue when connecting to Sagemaker workspaces where a blank browser launches instead of Sagemaker. This issue occurs for both newly created workspaces and workspaces that were already created but were stopped and restarted. The issue is experienced approximately once a week, and sometimes clearing the cache solves the issue, while other times it does not. Users receive a \"Something Went Wrong\" general error in SWB at Step 6.",
        "Issue_gpt_summary":"user experienc intermitt issu connect workspac blank browser launch instead issu occur newli creat workspac workspac creat stop restart issu experienc approxim week clear cach solv issu time user receiv went wrong gener error swb step",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/awslabs\/service-workbench-on-aws\/issues\/509",
        "Issue_title":"[Bug] Blank Page on Sagemaker Workspace Connect",
        "Issue_created_time":1622734645000,
        "Issue_closed_time":1624287519000,
        "Issue_body":"**Describe the bug**\r\nWhen connecting to Sagemaker workspaces, there is an intermittent issue where a blank browser launches instead of Sagemaker.  The issue presents for workspaces that are newly created as well as for workspaces that were already created, but were stopped and are being restarted.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n\r\nSTEP 1: Login as an Admin \r\nSTEP 2: Create a workspace (SageMaker)\r\nSTEP 3: Start the Workspace \r\nSTEP 5: Click \"Connect\"\r\nSTEP 6: A new blank web browser tab opens \r\nSTEP 7: Click \"Connect\" again, another blank web browser tab opens\r\n\r\nUser receives a \"Something Went Wrong\" general error in SWB at Step 6\r\n\r\nIn the client logs for the browser, there is also this error noted:\r\n              \"name\": \"x-cache\",\r\n              \"value\": \"Error from cloudfront\"\r\n   \r\n\r\n**Expected behavior**\r\nSagemaker workspace launch in browser\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Versions (please complete the following information):**\r\n - Release Version installed 3.0.0\r\n\r\n**Additional context**\r\nUser has cleared cache and it solved the issue, but for one of her employees clearing the cache did not solve the issue. \r\n\r\nThe issue is experienced approximately once a week. Sometimes clearing cache solves the issue. Other times going to incognito, and it does not solve the issue.\r\n\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"The relevant code snippet for this issue is [here](https:\/\/github.com\/awslabs\/service-workbench-on-aws\/blob\/7988c933d5f4d6c9878249a7521d64d891707824\/addons\/addon-base-raas-ui\/packages\/base-raas-ui\/src\/parts\/environments-sc\/parts\/ScEnvironmentHttpConnections.js#L60).\r\n\r\nI was unable to reproduce this issue (I'm using Chrome 90.0.4430.212) , but let's try to track this issue down.\r\n\r\nAre we unable to get the Sagemaker URL or is the browser failing to refer the user to the Sagemaker url?\r\n\r\nTo check if the browser is getting the Sagemaker URL correctly:\r\n1. Go to the Sagemaker workspace and click the connection button to open the \"HTTP Connections\" card \r\n2. Open the network tab in Chrome Inspect tool\r\n3. Clear all of the network activity\r\n4. Click on the `url` row on the sidebar\r\n5. In the new tab that opens up, select the sub tab for `response`.\r\n6. Check if a `url` is provided and try navigating to that `url` in the browser.\r\n\r\nIf the URL is valid and you can can navigate to the Sagemaker instance that way, then the issue is with the browser failing to redirect the user.\r\n\r\nhttps:\/\/user-images.githubusercontent.com\/3661906\/120824482-84a88d80-c526-11eb-883b-13d9b4cfa7f4.mov\r\nHere's a video of the process.\r\n\r\nPlease follow the instructions above to help us debug what is the cause of the issue. ",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"bug blank page workspac connect bug connect workspac intermitt issu blank browser launch instead issu present workspac newli creat workspac creat stop restart reproduc step reproduc behavior step login admin step creat workspac step start workspac step click connect step new blank web browser tab open step click connect blank web browser tab open user receiv went wrong gener error swb step client log browser error note cach valu error cloudfront expect behavior workspac launch browser screenshot applic add screenshot help explain problem version complet follow inform releas version instal addit context user clear cach solv issu employe clear cach solv issu issu experienc approxim week clear cach solv issu time go incognito solv issu",
        "Issue_preprocessed_content":"blank page workspac bug workspac blank browser launch instead present workspac newli creat workspac creat restart reproduc step reproduc behavior step login admin step creat workspac step start workspac step click step new blank web browser tab open step click blank web browser tab open user receiv went wrong gener swb step client log browser note valu cloudfront expect behavior workspac launch browser help explain problem version releas version context user clear cach solv clear cach solv experienc clear cach solv time go incognito solv",
        "Issue_gpt_summary_original":"The user is facing an issue where calling `stop_training_job` from the SageMaker client against an existing job that is not \"InProgress\" causes the client to hang. This issue only seems to happen within the sm-executor. The DEBUG output from the sm-executor shows that the request was rejected because the training job is in status Stopped.",
        "Issue_gpt_summary":"user face issu call stop train job client exist job inprogress caus client hang issu happen executor debug output executor show request reject train job statu stop",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/awslabs\/benchmark-ai\/issues\/928",
        "Issue_title":"[SM-Executor] SageMaker.stop_training_job hangs",
        "Issue_created_time":1570606746000,
        "Issue_closed_time":null,
        "Issue_body":"Calling `stop_training_job` from the SageMaker client against an existing by not \"InProgress\" job, causes the client to hang. This only seems to happen within the sm-executor though. \r\n\r\nHere's the output calling the method from the python interpreter within the pod:\r\n```\r\n# .\/python\r\nPython 3.7.3 | packaged by conda-forge | (default, Jul  1 2019, 21:52:21)\r\n[GCC 7.3.0] :: Anaconda, Inc. on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import boto3\r\n>>> client = boto3.client(\"sagemaker\")\r\n>>> client.stop_training_job(TrainingJobName=\"98cb7232-02b1-4a1b-a59e-55a8eca9e048\")\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"\/opt\/env\/lib\/python3.7\/site-packages\/botocore\/client.py\", line 357, in _api_call\r\n    return self._make_api_call(operation_name, kwargs)\r\n  File \"\/opt\/env\/lib\/python3.7\/site-packages\/botocore\/client.py\", line 661, in _make_api_call\r\n    raise error_class(parsed_response, operation_name)\r\nbotocore.exceptions.ClientError: An error occurred (ValidationException) when calling the StopTrainingJob operation: The request was rejected because the training job is in status Stopped.\r\n>>>\r\n```\r\n\r\nHere is the DEBUG output from the sm-executor\r\n```\r\n2019-10-09 06:39:38,252 INFO: Attempting to stop training job 98cb7232-02b1-4a1b-a59e-55a8eca9e048\r\n2019-10-09 06:39:38,252 DEBUG: Event before-parameter-build.sagemaker.StopTrainingJob: calling handler <function generate_idempotent_uuid at 0x7f54d82671e0>\r\n2019-10-09 06:39:38,253 DEBUG: Event before-call.sagemaker.StopTrainingJob: calling handler <function inject_api_version_header_if_needed at 0x7f54d8268b70>\r\n2019-10-09 06:39:38,253 DEBUG: Making request for OperationModel(name=StopTrainingJob) with params: {'url_path': '\/', 'query_string': '', 'method': 'POST', 'headers': {'X-Amz-Target': 'SageMaker.StopTrainingJob', 'Content-Type': 'application\/x-amz-json-1.1', 'User-Agent': 'Boto3\/1.9.221 Python\/3.7.3 Linux\/4.14.128-112.105.amzn2.x86_64 Botocore\/1.12.221'}, 'body': b'{\"TrainingJobName\": \"98cb7232-02b1-4a1b-a59e-55a8eca9e048\"}', 'url': 'https:\/\/api.sagemaker.us-east-1.amazonaws.com\/', 'context': {'client_region': 'us-east-1', 'client_config': <botocore.config.Config object at 0x7f54bacde518>, 'has_streaming_input': False, 'auth_type': None}}\r\n2019-10-09 06:39:38,253 DEBUG: Event request-created.sagemaker.StopTrainingJob: calling handler <bound method RequestSigner.handler of <botocore.signers.RequestSigner object at 0x7f54bacde4e0>>\r\n2019-10-09 06:39:38,254 DEBUG: Event choose-signer.sagemaker.StopTrainingJob: calling handler <function set_operation_specific_signer at 0x7f54d82670d0>\r\n2019-10-09 06:39:38,254 DEBUG: Calculating signature using v4 auth.\r\n2019-10-09 06:39:38,254 DEBUG: CanonicalRequest:\r\nPOST\r\n\/\r\n\r\ncontent-type:application\/x-amz-json-1.1\r\nhost:api.sagemaker.us-east-1.amazonaws.com\r\nx-amz-date:20191009T063938Z\r\nx-amz-security-token:FQoGZXIvYXdzEMj\/\/\/\/\/\/\/\/\/\/wEaDFbwYhfMhbwcrxMnQiKEAh9qXHxpmHbCDKDDcH4UNekdyuxX+8R3yub8KIGVZjEuvcH64xIAOgWnkb2ZtrIsoYUFWGQB2C6+NSptni65YVATyi6+ZedRB0RHjLyFE98l5b0DEcM5IE7O0xq7zflpIFTtOK9h7QeNh9n8MAe69xEvthv0Gd34dalXMlUFALYSvb6+Ewo7rvFPjDEZ+1xqlSLKwMbpA8YJ+ngJdhXCkiBGpCwXuXIP+zvSSx5+gENSWdzOJ\/OTdCKepxD25OutUvf5WN+usAkv1U4dDiG8MfPumZJg\/m93LUUzX3ok88XC6dMwajhayc9XH5n89ZyzgXmq5np\/wkCoU\/wbOLsMdvDaAy41KPSA9uwF\r\nx-amz-target:SageMaker.StopTrainingJob\r\n\r\ncontent-type;host;x-amz-date;x-amz-security-token;x-amz-target\r\n84e242897f2f826cc224094427e7ba8bc4c2f559097741460b59e162e8114c40\r\n2019-10-09 06:39:38,254 DEBUG: StringToSign:\r\nAWS4-HMAC-SHA256\r\n20191009T063938Z\r\n20191009\/us-east-1\/sagemaker\/aws4_request\r\n4320231908e4cd91204a6044a6201b1a74c0a63a2f708f9c4c27df2d6a6344db\r\n2019-10-09 06:39:38,255 DEBUG: Signature:\r\nc074cec50d69498f53c9f9283884363ee86010ccabece0d64f94e298f6d322ae\r\n2019-10-09 06:39:38,255 DEBUG: Sending http request: <AWSPreparedRequest stream_output=False, method=POST, url=https:\/\/api.sagemaker.us-east-1.amazonaws.com\/, headers={'X-Amz-Target': b'SageMaker.StopTrainingJob', 'Content-Type': b'application\/x-amz-json-1.1', 'User-Agent': b'Boto3\/1.9.221 Python\/3.7.3 Linux\/4.14.128-112.105.amzn2.x86_64 Botocore\/1.12.221', 'X-Amz-Date': b'20191009T063938Z', 'X-Amz-Security-Token': b'FQoGZXIvYXdzEMj\/\/\/\/\/\/\/\/\/\/wEaDFbwYhfMhbwcrxMnQiKEAh9qXHxpmHbCDKDDcH4UNekdyuxX+8R3yub8KIGVZjEuvcH64xIAOgWnkb2ZtrIsoYUFWGQB2C6+NSptni65YVATyi6+ZedRB0RHjLyFE98l5b0DEcM5IE7O0xq7zflpIFTtOK9h7QeNh9n8MAe69xEvthv0Gd34dalXMlUFALYSvb6+Ewo7rvFPjDEZ+1xqlSLKwMbpA8YJ+ngJdhXCkiBGpCwXuXIP+zvSSx5+gENSWdzOJ\/OTdCKepxD25OutUvf5WN+usAkv1U4dDiG8MfPumZJg\/m93LUUzX3ok88XC6dMwajhayc9XH5n89ZyzgXmq5np\/wkCoU\/wbOLsMdvDaAy41KPSA9uwF', 'Authorization': b'AWS4-HMAC-SHA256 Credential=ASIAYNI7SS57NFEDAZHQ\/20191009\/us-east-1\/sagemaker\/aws4_request, SignedHeaders=content-type;host;x-amz-date;x-amz-security-token;x-amz-target, Signature=c074cec50d69498f53c9f9283884363ee86010ccabece0d64f94e298f6d322ae', 'Content-Length': '59'}>\r\n2019-10-09 06:39:38,320 DEBUG: Response headers: {'x-amzn-RequestId': '03dd9de3-3672-4f4b-b575-a06d29e15e6b', 'Content-Type': 'application\/x-amz-json-1.1', 'Content-Length': '116', 'Date': 'Wed, 09 Oct 2019 06:39:37 GMT', 'Connection': 'close'}\r\n2019-10-09 06:39:38,320 DEBUG: Response body:\r\nb'{\"__type\":\"ValidationException\",\"message\":\"The request was rejected because the training job is in status Stopped.\"}'\r\n2019-10-09 06:39:38,320 DEBUG: Event needs-retry.sagemaker.StopTrainingJob: calling handler <botocore.retryhandler.RetryHandler object at 0x7f54bacde898>\r\n2019-10-09 06:39:38,321 DEBUG: No retry needed.\r\n```",
        "Issue_answer_count":0,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"executor stop train job hang call stop train job client exist inprogress job caus client hang happen executor output call method python interpret pod python python packag conda forg default jul gcc anaconda linux type help copyright credit licens inform import boto client boto client client stop train job trainingjobnam aeca traceback recent file line file opt env lib python site packag botocor client line api return self api oper kwarg file opt env lib python site packag botocor client line api rais error class pars respons oper botocor except clienterror error occur validationexcept call stoptrainingjob oper request reject train job statu stop debug output executor info attempt stop train job aeca debug event paramet build stoptrainingjob call handler debug event stoptrainingjob call handler debug make request operationmodel stoptrainingjob param url path queri string method post header amz target stoptrainingjob content type applic amz json user agent boto python linux amzn botocor bodi trainingjobnam aeca url http api east amazonaw com context client region east client config stream input fals auth type debug event request creat stoptrainingjob call handler debug event choos signer stoptrainingjob call handler debug calcul signatur auth debug canonicalrequest post content type applic amz json host api east amazonaw com amz date amz secur token fqogzxivyxdzemj weadfbwyhfmhbwcrxmnqikeahqxhxpmhbcdkddchunekdyuxx ryubkigvzjeuvchxiaogwnkbztrisoyufwgqbc nsptniyvatyi zedrbrhjlyfelbdecmieoxqzflpifttokhqenhnmaexevthvgddalxmlufalysvb eworvfpjdez xqlslkwmbpayj ngjdhxckibgpcwxuxip zvssx genswdzoj otdckepxdoutuvfwn usakvuddigmfpumzjg mluuzxokxcdmwajhaycxhnzyzgxmqnp wkcou wbolsmdvdaaykpsauwf amz target stoptrainingjob content type host amz date amz secur token amz target effccebabccfbeec debug stringtosign aw hmac sha east aw request ecdaabacaaffccdfdadb debug signatur ccecdfcfeeccabecedfefda debug send http request debug respons header amzn requestid ddde adeeb content type applic amz json content length date wed oct gmt connect close debug respons bodi type validationexcept messag request reject train job statu stop debug event need retri stoptrainingjob call handler debug retri need",
        "Issue_preprocessed_content":"hang client exist job caus client hang output method python interpret pod debug output",
        "Issue_gpt_summary_original":"The user is unable to run a benchmark on Sagemaker with Anubis as it shows an error message \"cannot execute the requested benchmark\". The user also tried to run a sample benchmark for Sagemaker but encountered the same error. The user is seeking advice on any additional specifications or changes required to run benchmarks on Sagemaker.",
        "Issue_gpt_summary":"user unabl run benchmark anubi show error messag execut request benchmark user tri run sampl benchmark encount error user seek advic addit specif chang requir run benchmark",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/awslabs\/benchmark-ai\/issues\/907",
        "Issue_title":"Cannot run benchmark for sagemaker",
        "Issue_created_time":1570150277000,
        "Issue_closed_time":1571326528000,
        "Issue_body":"When I tried to run benchmark on sagemaker with anubis, it showed processing benchmark submission request and then cannot execute the requested benchmark. \r\n<img width=\"1038\" alt=\"smmrcnn\" src=\"https:\/\/user-images.githubusercontent.com\/54413235\/66169329-e0ee3800-e5f4-11e9-887f-8e6fce87a917.png\">\r\n\r\nI also tried to run the sample for sagemaker https:\/\/github.com\/MXNetEdge\/benchmark-ai\/blob\/master\/sample-benchmarks\/sagemaker\/horovod.toml   and it showed with the same error\r\n<img width=\"1018\" alt=\"smsample\" src=\"https:\/\/user-images.githubusercontent.com\/54413235\/66169407-201c8900-e5f5-11e9-9de7-b46a7e9501a4.png\">\r\n\r\n\r\nBTW, when we wanna run with sagemaker, besides specify  execution_engine = \"aws.sagemaker\" and framework , is there anything else we need to specify or change?\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"3 tactics were used to address this issue (by @perdasilva): \r\nStop gap, watcher, error reporting in the status.\r\n@haohanchen-yagao - Please confirm and the close this issue.",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"run benchmark tri run benchmark anubi show process benchmark submiss request execut request benchmark tri run sampl http github com mxnetedg benchmark blob master sampl benchmark horovod toml show error btw wanna run specifi execut engin aw framework need specifi chang",
        "Issue_preprocessed_content":"run benchmark tri run benchmark anubi show benchmark request execut request benchmark img width alt tri run sampl show img width alt smsampl btw run specifi framework specifi chang",
        "Issue_gpt_summary_original":"The user is encountering an issue with the data path inside a Sagemaker notebook as the bucket of processed data does not exist, resulting in a NoSuchBucket error when calling the ListObjectsV2 operation.",
        "Issue_gpt_summary":"user encount issu data path insid notebook bucket process data exist result nosuchbucket error call listobjectsv oper",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/awslabs\/realtime-fraud-detection-with-gnn-on-dgl\/issues\/103",
        "Issue_title":"The data path inside sagemaker notebook does not work",
        "Issue_created_time":1620285557000,
        "Issue_closed_time":1621931178000,
        "Issue_body":"The bucket of processed data does not exist (src\/sagemaker\/FD_SL_Training_BYO_Codes.ipynb)\r\n\r\n\r\n### Reproduction Steps\r\n\r\naws s3 ls s3:\/\/fraud-detection-solution\/processed_data\r\n\r\n\r\n\r\n### Error Log\r\n\r\nAn error occurred (NoSuchBucket) when calling the ListObjectsV2 operation: The specified bucket does not exist\r\n\r\n\r\n\r\n### Environment\r\n\r\n  - **CDK CLI Version:** 1.75.0 (build 7708242)\r\n  - **Framework Version:** not installed\r\n  - **Node.js Version:**  not installed\r\n  - **OS               :**\r\n\r\n### Other\r\n\r\n<!-- e.g. detailed explanation, stacktraces, related issues, suggestions on how to fix, links for us to have context, eg. associated pull-request, stackoverflow, gitter, etc -->\r\n\r\n\r\n\r\n--- \r\n\r\nThis is :bug: Bug Report",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"data path insid notebook work bucket process data exist src train byo code ipynb reproduct step aw fraud detect solut process data error log error occur nosuchbucket call listobjectsv oper specifi bucket exist environ cdk cli version build framework version instal node version instal bug bug report",
        "Issue_preprocessed_content":"data path insid work bucket data exist reproduct step aw log listobjectsv oper specifi bucket exist environ cdk cli version framework version version detail explan stacktrac relat fix link context request stackoverflow bug bug report",
        "Issue_gpt_summary_original":"The user encountered an issue with their Sagemaker endpoint failing to deploy or timing out with a server error (0) bug. The error log shows that the backend worker process died due to a parameter conflict between the Sagemaker endpoint deployment code and the model training code on n-hidden and hidden_size. The user provided reproduction steps and environment details.",
        "Issue_gpt_summary":"user encount issu endpoint fail deploi time server error bug error log show backend worker process di paramet conflict endpoint deploy code model train code hidden hidden size user provid reproduct step environ detail",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/awslabs\/realtime-fraud-detection-with-gnn-on-dgl\/issues\/57",
        "Issue_title":"sagemaker endpoint fail to deploy or time out server error(0) bug",
        "Issue_created_time":1618212282000,
        "Issue_closed_time":1618279737000,
        "Issue_body":"Invoke Endpoint response time out. \r\n\r\n### Reproduction Steps\r\n\r\n{\r\n  \"trainingJob\": {\r\n    \"hyperparameters\": {\r\n    \"n-hidden\": \"2\",\r\n    \"n-epochs\": \"100\",\r\n    \"lr\":\"1e-2\"\r\n    },\r\n    \"instanceType\": \"ml.c5.9xlarge\",\r\n    \"timeoutInSeconds\": 10800    \r\n  }\r\n}\r\n\r\n\r\n\r\n### Error Log\r\nIn Inference Lambda CloudWatch:\r\n\r\nTask timed out after 120.10 seconds\r\n\r\n\r\nIn Sagemaker Training CloudWatch:\r\n\r\n2021-04-09   04:53:46,902 [INFO ] main org.pytorch.serve.ModelServer - Loading initial   models: model.mar\r\n--\r\n2021-04-09 04:53:49,837 [INFO ] main   org.pytorch.serve.archive.ModelArchive - eTag   8ff2b3de4bed4fb1bc7fe969652117ff\r\n2021-04-09 04:53:49,847 [INFO ] main   org.pytorch.serve.wlm.ModelManager - Model model loaded.\r\n2021-04-09 04:53:49,865 [INFO ] main   org.pytorch.serve.ModelServer - Initialize Inference server with:   EpollServerSocketChannel.\r\n2021-04-09 04:53:49,930 [INFO ] main   org.pytorch.serve.ModelServer - Inference API bind to: http:\/\/0.0.0.0:8080\r\n2021-04-09 04:53:49,930 [INFO ] main   org.pytorch.serve.ModelServer - Initialize Metrics server with:   EpollServerSocketChannel.\r\n2021-04-09 04:53:49,931 [INFO ] main   org.pytorch.serve.ModelServer - Metrics API bind to: http:\/\/127.0.0.1:8082\r\nModel server started.\r\n2021-04-09 04:53:49,957 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on   port: \/home\/model-server\/tmp\/.ts.sock.9000\r\n2021-04-09 04:53:49,959 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]55\r\n2021-04-09 04:53:49,959 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker   started.\r\n2021-04-09 04:53:49,959 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime:   3.6.13\r\n2021-04-09 04:53:49,963 [INFO ]   W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to:   \/home\/model-server\/tmp\/.ts.sock.9000\r\n2021-04-09 04:53:49,972 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection   accepted: \/home\/model-server\/tmp\/.ts.sock.9000.\r\n2021-04-09 04:53:50,017 [INFO ]   pool-2-thread-1 TS_METRICS -   CPUUtilization.Percent:33.3\\|#Level:Host\\|#hostname:model.aws.local,timestamp:1617944030\r\n2021-04-09 04:53:50,017 [INFO ]   pool-2-thread-1 TS_METRICS -   DiskAvailable.Gigabytes:19.622234344482422\\|#Level:Host\\|#hostname:model.aws.local,timestamp:1617944030\r\n2021-04-09 04:53:50,017 [INFO ]   pool-2-thread-1 TS_METRICS -   DiskUsage.Gigabytes:4.731609344482422\\|#Level:Host\\|#hostname:model.aws.local,timestamp:1617944030\r\n2021-04-09 04:53:50,017 [INFO ]   pool-2-thread-1 TS_METRICS -   DiskUtilization.Percent:19.4\\|#Level:Host\\|#hostname:model.aws.local,timestamp:1617944030\r\n2021-04-09 04:53:50,018 [INFO ]   pool-2-thread-1 TS_METRICS -   MemoryAvailable.Megabytes:30089.12109375\\|#Level:Host\\|#hostname:model.aws.local,timestamp:1617944030\r\n2021-04-09 04:53:50,018 [INFO ]   pool-2-thread-1 TS_METRICS -   MemoryUsed.Megabytes:902.6953125\\|#Level:Host\\|#hostname:model.aws.local,timestamp:1617944030\r\n2021-04-09 04:53:50,018 [INFO ]   pool-2-thread-1 TS_METRICS -   MemoryUtilization.Percent:4.1\\|#Level:Host\\|#hostname:model.aws.local,timestamp:1617944030\r\n2021-04-09 04:53:51,250 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Setting the   default backend to \"pytorch\". You can change it in the   ~\/.dgl\/config.json file or export the DGLBACKEND environment variable.\u00a0 Valid options are: pytorch, mxnet,   tensorflow (all lowercase)\r\n2021-04-09 04:53:51,250 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   ------------------ Loading model -------------------\r\n2021-04-09 04:53:51,250 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker   process died.\r\n2021-04-09 04:53:51,250 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most   recent call last):\r\n2021-04-09 04:53:51,250 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -\u00a0\u00a0 File   \"\/opt\/conda\/lib\/python3.6\/site-packages\/ts\/model_service_worker.py\",   line 176, in <module>\r\n2021-04-09 04:53:51,250 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -\u00a0\u00a0\u00a0\u00a0 worker.run_server()\r\n2021-04-09 04:53:51,250 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -\u00a0\u00a0 File   \"\/opt\/conda\/lib\/python3.6\/site-packages\/ts\/model_service_worker.py\",   line 148, in run_server\r\n2021-04-09 04:53:51,250 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -\u00a0\u00a0\u00a0\u00a0 self.handle_connection(cl_socket)\r\n2021-04-09 04:53:51,250 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -\u00a0\u00a0 File   \"\/opt\/conda\/lib\/python3.6\/site-packages\/ts\/model_service_worker.py\",   line 112, in handle_connection\r\n2021-04-09 04:53:51,250 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -\u00a0\u00a0\u00a0\u00a0 service, result, code =   self.load_model(msg)\r\n2021-04-09 04:53:51,250 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -\u00a0\u00a0 File   \"\/opt\/conda\/lib\/python3.6\/site-packages\/ts\/model_service_worker.py\",   line 85, in load_model\r\n2021-04-09 04:53:51,251 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -\u00a0\u00a0\u00a0\u00a0 service = model_loader.load(model_name,   model_dir, handler, gpu, batch_size)\r\n2021-04-09 04:53:51,251 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -\u00a0\u00a0 File   \"\/opt\/conda\/lib\/python3.6\/site-packages\/ts\/model_loader.py\", line   117, in load\r\n2021-04-09 04:53:51,251 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -\u00a0\u00a0\u00a0\u00a0   model_service.initialize(service.context)\r\n2021-04-09 04:53:51,251 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -\u00a0\u00a0 File   \"\/home\/model-server\/tmp\/models\/8ff2b3de4bed4fb1bc7fe969652117ff\/handler_service.py\",   line 51, in initialize\r\n2021-04-09 04:53:51,251 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -\u00a0\u00a0\u00a0\u00a0 super().initialize(context)\r\n2021-04-09 04:53:51,251 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -\u00a0\u00a0 File   \"\/opt\/conda\/lib\/python3.6\/site-packages\/sagemaker_inference\/default_handler_service.py\",   line 66, in initialize\r\n2021-04-09 04:53:51,251 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -\u00a0\u00a0\u00a0\u00a0   self._service.validate_and_initialize(model_dir=model_dir)\r\n2021-04-09 04:53:51,251 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -\u00a0\u00a0 File   \"\/opt\/conda\/lib\/python3.6\/site-packages\/sagemaker_inference\/transformer.py\",   line 158, in validate_and_initialize\r\n2021-04-09 04:53:51,251 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -\u00a0\u00a0\u00a0\u00a0 self._model = self._model_fn(model_dir)\r\n2021-04-09 04:53:51,251 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -\u00a0\u00a0 File   \"\/opt\/ml\/model\/code\/fd_sl_deployment_entry_point.py\", line 149, in   model_fn\r\n2021-04-09 04:53:51,251 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -\u00a0\u00a0\u00a0\u00a0 rgcn_model.load_state_dict(stat_dict)\r\n2021-04-09 04:53:51,251 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -\u00a0\u00a0 File   \"\/opt\/conda\/lib\/python3.6\/site-packages\/torch\/nn\/modules\/module.py\",   line 1045, in load_state_dict\r\n2021-04-09   04:53:51,251 [INFO ] W-9000-model_1-stdout   org.pytorch.serve.wlm.WorkerLifeCycle -\u00a0\u00a0\u00a0\u00a0   self.__class__.__name__, \"     \\t\".join(error_msgs)))\r\n2021-04-09 04:53:51,251 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - RuntimeError:   Error(s) in loading state_dict for HeteroRGCN:\r\n2021-04-09 04:53:51,251 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - #011size   mismatch for layers.0.weight.DeviceInfo<>target.weight: copying a param   with shape torch.Size([2, 390]) from checkpoint, the shape in current model   is torch.Size([16, 390]).\r\n2021-04-09 04:53:51,252 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - #011size   mismatch for layers.0.weight.DeviceInfo<>target.bias: copying a param   with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([16]).\r\n2021-04-09 04:53:51,252 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - #011size   mismatch for layers.0.weight.DeviceType<>target.weight: copying a param   with shape torch.Size([2, 390]) from checkpoint, the shape in current model   is torch.Size([16, 390]).\r\n2021-04-09 04:53:51,252 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - #011size   mismatch for layers.0.weight.DeviceType<>target.bias: copying a param   with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([16]).\r\n2021-04-09 04:53:51,252 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - #011size   mismatch for layers.0.weight.P_emaildomain<>target.weight: copying a   param with shape torch.Size([2, 390]) from checkpoint, the shape in current model   is torch.Size([16, 390]).\r\n2021-04-09 04:53:51,252 [INFO ]   W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - #011size   mismatch for layers.0.weight.P_emaildomain<>target.bias: copying a   param with shape torch.Size([2]) from checkpoint, the shape in current model   is torch.Size([16]).\r\n\r\n\r\n\r\n\r\n\r\n### Environment\r\n\r\n  - **CDK CLI Version:** <!-- Output of `cdk version` -->\r\n  - **Framework Version:**\r\n  - **Node.js Version:** <!-- Version of Node.js (run the command `node -v`) -->\r\n  - **OS               :**\r\n\r\n### Other\r\n\r\nCause of this bug:\r\n\r\nBackend worker process died.\r\nSagemaker Endpoint deployment code and model training code parameter conflict on n-hidden and hidden_size.\r\n\r\n\r\n--- \r\n\r\nThis is :bug: Bug Report",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"endpoint fail deploi time server error bug invok endpoint respons time reproduct step trainingjob hyperparamet hidden epoch instancetyp xlarg timeoutinsecond error log infer lambda cloudwatch task time second train cloudwatch info main org pytorch serv modelserv load initi model model mar info main org pytorch serv archiv modelarch etag ffbdebedfbbcfeff info main org pytorch serv wlm modelmanag model model load info main org pytorch serv modelserv initi infer server epollserversocketchannel info main org pytorch serv modelserv infer api bind http info main org pytorch serv modelserv initi metric server epollserversocketchannel info main org pytorch serv modelserv metric api bind http model server start info model stdout org pytorch serv wlm workerlifecycl listen port home model server tmp sock info model stdout org pytorch serv wlm workerlifecycl pid info model stdout org pytorch serv wlm workerlifecycl torch worker start info model stdout org pytorch serv wlm workerlifecycl python runtim info model org pytorch serv wlm workerthread connect home model server tmp sock info model stdout org pytorch serv wlm workerlifecycl connect accept home model server tmp sock info pool thread metric cpuutil percent level host hostnam model aw local timestamp info pool thread metric diskavail gigabyt level host hostnam model aw local timestamp info pool thread metric diskusag gigabyt level host hostnam model aw local timestamp info pool thread metric diskutil percent level host hostnam model aw local timestamp info pool thread metric memoryavail megabyt level host hostnam model aw local timestamp info pool thread metric memoryus megabyt level host hostnam model aw local timestamp info pool thread metric memoryutil percent level host hostnam model aw local timestamp info model stdout org pytorch serv wlm workerlifecycl set default backend pytorch chang dgl config json file export dglbackend environ variabl valid option pytorch mxnet tensorflow lowercas info model stdout org pytorch serv wlm workerlifecycl load model info model stdout org pytorch serv wlm workerlifecycl backend worker process di info model stdout org pytorch serv wlm workerlifecycl traceback recent info model stdout org pytorch serv wlm workerlifecycl file opt conda lib python site packag model servic worker line info model stdout org pytorch serv wlm workerlifecycl worker run server info model stdout org pytorch serv wlm workerlifecycl file opt conda lib python site packag model servic worker line run server info model stdout org pytorch serv wlm workerlifecycl self handl connect socket info model stdout org pytorch serv wlm workerlifecycl file opt conda lib python site packag model servic worker line handl connect info model stdout org pytorch serv wlm workerlifecycl servic result code self load model msg info model stdout org pytorch serv wlm workerlifecycl file opt conda lib python site packag model servic worker line load model info model stdout org pytorch serv wlm workerlifecycl servic model loader load model model dir handler gpu batch size info model stdout org pytorch serv wlm workerlifecycl file opt conda lib python site packag model loader line load info model stdout org pytorch serv wlm workerlifecycl model servic initi servic context info model stdout org pytorch serv wlm workerlifecycl file home model server tmp model ffbdebedfbbcfeff handler servic line initi info model stdout org pytorch serv wlm workerlifecycl super initi context info model stdout org pytorch serv wlm workerlifecycl file opt conda lib python site packag infer default handler servic line initi info model stdout org pytorch serv wlm workerlifecycl self servic valid initi model dir model dir info model stdout org pytorch serv wlm workerlifecycl file opt conda lib python site packag infer transform line valid initi info model stdout org pytorch serv wlm workerlifecycl self model self model model dir info model stdout org pytorch serv wlm workerlifecycl file opt model code deploy entri point line model info model stdout org pytorch serv wlm workerlifecycl rgcn model load state dict stat dict info model stdout org pytorch serv wlm workerlifecycl file opt conda lib python site packag torch modul modul line load state dict info model stdout org pytorch serv wlm workerlifecycl self class join error msg info model stdout org pytorch serv wlm workerlifecycl runtimeerror error load state dict heterorgcn info model stdout org pytorch serv wlm workerlifecycl size mismatch layer weight deviceinfo target weight copi param shape torch size checkpoint shape current model torch size info model stdout org pytorch serv wlm workerlifecycl size mismatch layer weight deviceinfo target bia copi param shape torch size checkpoint shape current model torch size info model stdout org pytorch serv wlm workerlifecycl size mismatch layer weight devicetyp target weight copi param shape torch size checkpoint shape current model torch size info model stdout org pytorch serv wlm workerlifecycl size mismatch layer weight devicetyp target bia copi param shape torch size checkpoint shape current model torch size info model stdout org pytorch serv wlm workerlifecycl size mismatch layer weight emaildomain target weight copi param shape torch size checkpoint shape current model torch size info model stdout org pytorch serv wlm workerlifecycl size mismatch layer weight emaildomain target bia copi param shape torch size checkpoint shape current model torch size environ cdk cli version framework version node version caus bug backend worker process di endpoint deploy code model train code paramet conflict hidden hidden size bug bug report",
        "Issue_preprocessed_content":"endpoint fail deploi time server bug invok endpoint respons time reproduct step trainingjob instancetyp timeoutinsecond log infer lambda cloudwatch task time second train cloudwatch main load initi model main etag bed main model model load main initi infer server main infer api bind main initi metric server main metric api bind model server start listen port torch worker start python runtim default backend pytorch chang file export dglbackend environ variabl valid option pytorch mxnet tensorflow load model backend worker di traceback file line file line file line servic result code file line servic handler gpu file line load file line initi file line initi file line file line file line load heterorgcn size mismatch copi param shape checkpoint shape model size mismatch copi param shape checkpoint shape model size mismatch copi param shape checkpoint shape model size mismatch copi param shape checkpoint shape model size mismatch copi param shape checkpoint shape model size mismatch copi param shape checkpoint shape model environ cdk cli version framework version version caus bug backend worker di endpoint deploy code model train code paramet conflict bug bug report",
        "Issue_gpt_summary_original":"The user is facing an issue with Sagemaker Multi-GPU distributed data training where \"model.generate\" is returning empty tensors. They are unsure if this is due to the feature not yet being supported on Sagemaker Multi-GPU or if there is an issue with their own modified scripts.",
        "Issue_gpt_summary":"user face issu multi gpu distribut data train model gener return tensor unsur featur support multi gpu issu modifi script",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/huggingface\/accelerate\/issues\/706",
        "Issue_title":"Have accelerate for  Distributed Training: Data Parallelism feature working on AWS Sagemaker yet?",
        "Issue_created_time":1663741563000,
        "Issue_closed_time":1664255368000,
        "Issue_body":"### System Info\n\n```Shell\npytorch: 1.10.2\r\npython:3.8\n```\n\n\n### Information\n\n- [ ] The official example scripts\n- [ ] My own modified scripts\n\n### Tasks\n\n- [ ] One of the scripts in the examples\/ folder of Accelerate or an officially supported `no_trainer` script in the `examples` folder of the `transformers` repo (such as `run_no_trainer_glue.py`)\n- [ ] My own task or dataset (give details below)\n\n### Reproduction\n\nSagemaker Multi-GPU distributed data training, while \"model.generate\" it always returns empty tensors.\n\n### Expected behavior\n\n```Shell\nI'm trying to run a distributed training in a Sagemaker training job, the inference is not working properly, I found it as a future work on huggingface documentation so I'm wondering If that's why it's not working yet on sagemaker Multi-GPU.\r\n\r\nThanks\n```\n",
        "Issue_answer_count":7,
        "Issue_self_closed":1.0,
        "Answer_body":"Hello @HebaGamalElDin, please provide minimal reproducible example for us to deep dive and help you.  Hello @pacman100, I'm fine tuning a transformer model from the hub of huggingface.. below is the training function that utilizes the accelerator on sagemaker training jobs.\r\n\r\n```\r\ndef train(context: Context, num_epochs):\r\n    model = context.model\r\n    model = accelerator.prepare(model)\r\n    optimizer = AdamW(model.parameters(), lr=1e-3)\r\n    \r\n    num_training_steps = num_epochs * len(context.train_dataloader)\r\n    lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=100, num_training_steps=num_training_steps)\r\n    optimizer, train_dataloader, eval_dataloader, lr_scheduler = accelerator.prepare(optimizer, context.train_dataloader, context.val_dataloader, lr_scheduler)\r\n    \r\n    \r\n    losses = []\r\n    min_cer = 1.0\r\n    min_train_loss = 1.0\r\n    for epoch in range(num_epochs):\r\n        model.train()\r\n        for j, batch in enumerate(train_dataloader):\r\n            inputs: torch.Tensor = batch[\"input\"]#.to(accelerator.device)\r\n            labels: torch.Tensor = batch[\"label_tensor\"]#.to(accelerator.device)\r\n\r\n            outputs = model(pixel_values=inputs, labels=labels)\r\n            #print(outputs)\r\n            loss = outputs.loss\r\n            accelerator.backward(loss)\r\n            #loss.backward()\r\n\r\n            optimizer.step()\r\n            lr_scheduler.step()\r\n            optimizer.zero_grad()\r\n            losses.append(loss)\r\n            accelerator.print(f\"Epoch {epoch}-------Batch---{j}-----Loss---{loss}\")\r\n            \r\n        model.eval()\r\n        for i, batch in enumerate(eval_dataloader):\r\n            inputs: torch.Tensor = batch[\"input\"]#.to(accelerator.device)\r\n            with torch.no_grad():\r\n                predictions = accelerator.unwrap_model(model).generate(inputs)\r\n\r\n                generated_ids = accelerator.gather(predictions).cpu().numpy()\r\n                print(f\"Generated IDs: {generated_ids}\")\r\n                labels = accelerator.gather(batch[\"label_tensor\"]).cpu().numpy()\r\n                \r\n                generated_text = context.processor.batch_decode(generated_ids, skip_special_tokens=True)\r\n                labels_text = context.processor.batch_decode(labels, skip_special_tokens=True)\r\n                \r\n                predictions, labels = postprocess_text(generated_text, labels_text)\r\n                \r\n                cer_metric.add_batch(predictions=predictions, references=labels)\r\n                wer_metric.add_batch(predictions=predictions, references=labels)\r\n                print(f\"Predictions: {predictions}-----------Labels: {labels}\")\r\n        cer = cer_metric.compute()\r\n        wer = wer_metric.compute()\r\n\r\n        accelerator.print(f\"Average CER: {cer}------ Average WER: {wer}\")\r\n```\r\n\r\nthe python estimator is as follows:\r\n\r\n```\r\nfrom sagemaker.pytorch import PyTorch\r\nimport sagemaker\r\nrole = sagemaker.get_execution_role()\r\npt_estimator = PyTorch(\r\n    base_job_name=\"transformer-ocr-training\",\r\n    source_dir=\"source\",\r\n    entry_point=\"Train.py\",\r\n    role=role,    \r\n    py_version=\"py38\",\r\n    \r\n    image_uri =\"763104351884.dkr.ecr.us-east-1.amazonaws.com\/huggingface-pytorch-training:1.10.2-transformers4.17.0-gpu-py38-cu113-ubuntu20.04\",\r\n\r\n    #framework_version=\"1.12.0\",\r\n\r\n    instance_count=1,\r\n    instance_type=\"ml.p3.16xlarge\"\r\n    #distribution={'smdistributed':{'dataparallel':{ 'enabled': True }}}\r\n)\r\n\r\npt_estimator.fit(\"s3:\/\/handwritten-ocr-training\")\r\n```\r\n\r\nExactly when I'm generate in for the evaluation set it always retrieves empty tensors. What am I missing here? However the number of processes is 8 GPUs so the accelerate has access to all of them however it's not generating in the validation all decoded strings are empty, appreciate your help! Hello @HebaGamalElDin, you are not using the \ud83e\udd17 Accelerate integration of AWS SageMaker correctly. To help you and others going forwards, I have spent time creating this repo https:\/\/github.com\/pacman100\/accelerate-aws-sagemaker which details on how to correctly use AWS SageMaker with \ud83e\udd17 Accelerate. it works correctly with generation `model.generate`. Please go through the README and files in the above repo and let us know if you still have issues.  Hello @pacman100 .. Thank you for the warm help.\r\nI have one question please, what I didn't get is how to configure accelerate inside the training job?\r\nmeaning where to run the command `accelerate config --config_file accelerate_config.yaml`? Have the [accelerate_config.yaml](https:\/\/github.com\/pacman100\/accelerate-aws-sagemaker\/blob\/af5caadcea0fa8186c11a784b6f86591c8fa5b3f\/src\/seq2seq\/accelerate_config.yaml) file should been replaced the python SDK estimator *PyTorch* in my case? Hello, you don't have to use any SageMaker estimator (PyTorch estimator in your case) as Accelerate internally uses Hugging Face SageMaker Estimator https:\/\/github.com\/huggingface\/accelerate\/blob\/main\/src\/accelerate\/commands\/launch.py#L776 along with all the necessary env variables to handle SageMaker DDP.\r\n\r\nJust create the accelerate config with command `accelerate config` on any virtual machine\/local machine\/sagemaker notebooks on which you have aws cli installed with aws credentials setup. After that when you run `accelerate launch` it will internally use HF estimator to create the training job on AWS SageMaker. I am running `accelerate config` and `accelerate launch` on a local machine with aws credentials setup.\r\n\r\n\r\n\r\n @pacman100 Okay I got that thank you.\r\nOne more question please, I'm encountering an issue when I'm testing, most of validation batches entirely are empty while some others are okay, this problem doesn't happen while training is on 1 GPU, What could be the problem here please?!\r\n**HINT: I'm logging the length of the text predictions coming by model.generate() for each batch, the majority is zero as shown in the below screenshot.**\r\n![image](https:\/\/user-images.githubusercontent.com\/36745656\/192077881-b5a598d0-1762-4335-9f2b-f07daa627318.png)\r\n",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"acceler distribut train data parallel featur work info shell pytorch python inform offici exampl script modifi script task script exampl folder acceler offici support trainer script exampl folder transform repo run trainer glue task dataset detail reproduct multi gpu distribut data train model gener return tensor expect behavior shell try run distribut train train job infer work properli futur work huggingfac document wonder work multi gpu thank",
        "Issue_preprocessed_content":"distribut train data featur work info inform exampl script modifi script task script exampl folder script folder repo task dataset reproduct distribut data train return tensor expect behavior",
        "Issue_gpt_summary_original":"The user has encountered an issue with the example DAG for Sagemaker, which currently only uses access key and secret key instead of a temporary access token. The user expects the DAG to use a temporary access token. No specific details about the error or expected behavior are provided.",
        "Issue_gpt_summary":"user encount issu exampl dag current us access kei secret kei instead temporari access token user expect dag us temporari access token specif detail error expect behavior provid",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/astronomer\/astronomer-providers\/issues\/738",
        "Issue_title":"Sagemaker example DAG to use aws session token",
        "Issue_created_time":1666950742000,
        "Issue_closed_time":1666960895000,
        "Issue_body":"**Describe the bug**\r\nCurrently the example DAG for sagemaker just uses access key and secret key. We need to use a temporary  access token\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Desktop (please complete the following information):**\r\n - OS: [e.g. iOS]\r\n - Browser [e.g. chrome, safari]\r\n - Version [e.g. 22]\r\n\r\n**Smartphone (please complete the following information):**\r\n - Device: [e.g. iPhone6]\r\n - OS: [e.g. iOS8.1]\r\n - Browser [e.g. stock browser, safari]\r\n - Version [e.g. 22]\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"exampl dag us aw session token bug current exampl dag us access kei secret kei need us temporari access token reproduc step reproduc behavior click scroll error expect behavior clear concis descript expect happen screenshot applic add screenshot help explain problem desktop complet follow inform io browser chrome safari version smartphon complet follow inform devic iphon io browser stock browser safari version addit context add context problem",
        "Issue_preprocessed_content":"exampl dag us aw token bug exampl dag us kei secret kei us temporari token reproduc step reproduc behavior click expect behavior clear concis descript expect help explain problem desktop browser version smartphon devic browser version context context problem",
        "Issue_gpt_summary_original":"The user has encountered a bug where the XCom return value of `SageMakerTransformOperatorAsync` and `SageMakerTrainingOperatorAsync` does not produce the expected output. The issue seems to be that some keys do not match the non-async operator output. The user has tried to reproduce the issue by running a DAG with traditional operators and then running the same DAG with async operators, and comparing the outputs. The expected behavior is for the XCom keys and values to match whatever the traditional non-async version of the operators output.",
        "Issue_gpt_summary":"user encount bug xcom return valu transformoperatorasync trainingoperatorasync produc expect output issu kei match non async oper output user tri reproduc issu run dag tradit oper run dag async oper compar output expect behavior xcom kei valu match tradit non async version oper output",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/astronomer\/astronomer-providers\/issues\/736",
        "Issue_title":"XCom Output of Sagemaker Async Operators",
        "Issue_created_time":1666892144000,
        "Issue_closed_time":1666957435000,
        "Issue_body":"**Describe the bug**\r\nXCom return value of `SageMakerTransformOperatorAsync`  and `SageMakerTrainingOperatorAsync` does not produce the expected output.\r\n\r\nIt seems like some key(s) don't match the non-async operator output.\r\n\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Run a dag with traditional operators\r\n2. Run same dag with Async operators\r\n3. Compare outputs\r\n\r\n**Expected behavior**\r\nThe Xcom keys and values should match whatever the traditional non-async version of the operators output.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"@bharanidharan14  I tested locally with the branch for the fix and seems to be fixed with your patch. Thank you!",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"xcom output async oper bug xcom return valu transformoperatorasync trainingoperatorasync produc expect output like kei match non async oper output reproduc step reproduc behavior run dag tradit oper run dag async oper compar output expect behavior xcom kei valu match tradit non async version oper output screenshot applic add screenshot help explain problem",
        "Issue_preprocessed_content":"xcom output async oper bug xcom return valu produc expect output like kei match oper output reproduc step reproduc behavior run dag tradit oper run dag async oper compar output expect behavior xcom kei valu match tradit version oper output help explain problem",
        "Issue_gpt_summary_original":"The user is encountering token errors with the new Sagemaker Async Operators despite using personal Access Key, Secret, and Session Token for authentication. The error message states that the security token included in the request is invalid. The user expects the operators to work without any authentication or token errors. The user has also noticed that the traditional operators work fine with the same authentication credentials.",
        "Issue_gpt_summary":"user encount token error new async oper despit person access kei secret session token authent error messag state secur token includ request invalid user expect oper work authent token error user notic tradit oper work fine authent credenti",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/astronomer\/astronomer-providers\/issues\/725",
        "Issue_title":"Token error with Sagemaker Async Operators",
        "Issue_created_time":1666713848000,
        "Issue_closed_time":1666859588000,
        "Issue_body":"**Describe the bug**\r\nGetting errors with the new Sagemaker Async Operators that I don't get with the traditional ones. I'm using a personal Access Key, Secret, and Session Token as I did with the non async operators for auth.\r\n\r\n```\r\nbotocore.exceptions.ClientError: An error occurred (UnrecognizedClientException) when calling the DescribeTrainingJob operation: The security token included in the request is invalid.\r\n```\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\nUse the SageMaker async operators with user Access Key, Secret, and Session Token\r\n\r\n**Expected behavior**\r\nExpect it to not have auth\/token errors.\r\n\r\n\r\n**Additional context**\r\nWhen I switch back to the traditional operators in the same dag with the same auth creds it works fine.\r\n\r\n\r\n@kentdanas also had similar issues and her auth was setup a little different.",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"The issue is with the session token is not considered while the secrete and access key is given in the connection proper field, not in the extra config",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"token error async oper bug get error new async oper tradit on person access kei secret session token non async oper auth botocor except clienterror error occur unrecognizedclientexcept call describetrainingjob oper secur token includ request invalid reproduc step reproduc behavior us async oper user access kei secret session token expect behavior expect auth token error addit context switch tradit oper dag auth cred work fine kentdana similar issu auth setup littl differ",
        "Issue_preprocessed_content":"token async oper bug new async oper tradit on person kei secret token non async oper auth reproduc step reproduc behavior us async oper user kei secret token expect behavior expect context switch tradit oper dag auth cred work fine similar auth setup",
        "Issue_gpt_summary_original":"The user is facing errors while trying to use Sagemaker Debugger with HPO and is getting a \"FileNotFoundError\" related to the debughookconfig.json file.",
        "Issue_gpt_summary":"user face error try us debugg hpo get filenotfounderror relat debughookconfig json file",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/awslabs\/sagemaker-debugger\/issues\/325",
        "Issue_title":"Sagemaker Debugger with HPO",
        "Issue_created_time":1597167105000,
        "Issue_closed_time":null,
        "Issue_body":"Can you please confirm if Sagemaker Debugger works with HPO. I get errors when the code that works perfectly fine with SM script mode fails when extended to HPO.\r\n\r\n` FileNotFoundError: [Errno 2] No such file or directory: '\/opt\/ml\/input\/config\/debughookconfig.json'`",
        "Issue_answer_count":1,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"debugg hpo confirm debugg work hpo error code work perfectli fine script mode fail extend hpo filenotfounderror errno file directori opt input config debughookconfig json",
        "Issue_preprocessed_content":"hpo confirm work hpo code work perfectli fine script mode fail extend hpo",
        "Issue_gpt_summary_original":"The user is encountering a bug in Amazon SageMaker Studio - Jupyter Lab where the Graph tab doesn't render when trying to execute a .path() query. The expected behavior is to see the Graph tab as shown in the screenshot from Jupyter.",
        "Issue_gpt_summary":"user encount bug studio jupyt lab graph tab render try execut path queri expect behavior graph tab shown screenshot jupyt",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws\/graph-notebook\/issues\/54",
        "Issue_title":"[BUG] Graph tab doesn't render in Amazon SageMaker Studio - Jupyter Lab",
        "Issue_created_time":1609843354000,
        "Issue_closed_time":1646674184000,
        "Issue_body":"**Describe the bug**\r\nWhen trying to execute a .path() query in Jupyter Lab the Graph tab doesn't render, instead it shows\r\n`\"Tab(children=(Output(layout=Layout(max_height='600px', overflow='scroll', width='100%')), Force(network=<graph\u2026\"`\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to Jupyter Lab\r\n2. Run a query with .path()\r\n\r\n**Current behavior**\r\nScreenshot taken from JupyterLab\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/4501996\/103637313-fb2f6800-4f53-11eb-9eac-8fd446c240bf.png)\r\n\r\n\r\n**Expected behavior**\r\nScreenshot taken from Jupyter\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/4501996\/103637180-bf949e00-4f53-11eb-8090-b2057c62cea3.png)\r\n",
        "Issue_answer_count":3,
        "Issue_self_closed":0.0,
        "Answer_body":"Thanks for reaching out! We haven't taken the work to support jupyterlabs yet, though we do build our visualization widget for labs already. Seems like the Tab widget isn't being displayed properly in the screenshot provided of labs, but that could be because our Force widget isn't installed properly. \r\n\r\nI have cut a feature request for this: #55 Thanks a lot!\r\nAppreciate it \ud83d\udc4d \r\n Widgets now render properly in JupyterLab as of #271 .",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"bug graph tab render studio jupyt lab bug try execut path queri jupyt lab graph tab render instead show tab children output layout layout max height overflow scroll width forc network graph reproduc step reproduc behavior jupyt lab run queri path current behavior screenshot taken jupyterlab imag http user imag githubusercont com fbf eac fdcbf png expect behavior screenshot taken jupyt imag http user imag githubusercont com bfe bccea png",
        "Issue_preprocessed_content":"graph tab render studio jupyt lab bug try execut path queri jupyt lab graph tab render instead show reproduc step reproduc behavior jupyt lab run queri path behavior taken jupyterlab expect behavior taken jupyt",
        "Issue_gpt_summary_original":"The user is encountering an error while using the LED model in SageMaker SMP training. They have tried several fixes, including matching the python, transformers, and pytorch versions, but are still facing issues. The error is in the \"modeling_led\" within the transformers module, which is expecting a different input_ids shape. The user tried to unsqueeze input tensors to the \"modeling_led\" to solve the above error, which helped move forward in the process, but they got another error further down in the code. The error message is \"Tensors must have the same number of dimensions: got 4 and 3.\" The user is seeking feedback and assistance in resolving the issue.",
        "Issue_gpt_summary":"user encount error led model smp train tri fix includ match python transform pytorch version face issu error model led transform modul expect differ input id shape user tri unsqueez input tensor model led solv error help forward process got error code error messag tensor number dimens got user seek feedback assist resolv issu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/huggingface\/transformers\/issues\/18060",
        "Issue_title":"LED Model returns AlgorithmError when using SageMaker SMP training #16890",
        "Issue_created_time":1657213837000,
        "Issue_closed_time":1660575729000,
        "Issue_body":"### System Info\n\ncc @philschmid  , cc @ydshieh  , cc @sgugger \r\n\r\nHello,\r\n\r\nThis is a follow up on a related post with the below link) with the same title:\r\nhttps:\/\/github.com\/huggingface\/transformers\/issues\/16890\r\n\r\nWe ade a bit of more progress but are still facing with some issues and are trying to fix them after trying out several fixes including matching the python, transformers, and pytorch versions according to the recommendations (3.8, 4.16.2, and 1.10.2, respectively):\r\n\r\n-ValueError: not enough values to unpack (expected 2, got 1)\r\n\r\nThe error is in the \u201cmodeling_led\u201d within the transformers module expecting a different input_ids shape. \r\n\r\nNew Update is we tried below to unsqueeze input tensors to the \"modeling_led\" to solve the above error:\r\ndef unsqueeze_col(example):\r\nreturn {\"input_ids\": torch.unsqueeze(example[\"input_ids\"], 0)}\r\npubmed_train = pubmed_train.map(unsqueeze_col)\r\n\r\n\r\nIt helped moving forward in the process, but we got another error, below, a little further down in the code:\r\n\r\nUnexpectedStatusException: Error for Training job huggingface-pytorch-training-2022-06-29-04-04-58-606: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\r\nExitCode 1\r\nErrorMessage \":RuntimeError: Tensors must have same number of dimensions: got 4 and 3\r\n :Environment variable SAGEMAKER_INSTANCE_TYPE is not set :Environment variable SAGEMAKER_INSTANCE_TYPE is not set :Environment variable SAGEMAKER_INSTANCE_TYPE is not set :Environment variable SAGEMAKER_INSTANCE_TYPE is not set :Environment variable SAGEMAKER_INSTANCE_TYPE is not set :Environment variable SAGEMAKER_INSTANCE_TYPE is not set :Environment variable SAGEMAKER_INSTANCE_TYPE is not set :Environment variable SAGEMAKER_INSTANCE_TYPE is not set -------------------------------------------------------------------------- Primary job  terminated normally, but 1 process returned a non-zero exit code. Per user-direction, the job has been aborted. mpirun.real detected that one or more processes exited with non-zero status, thus causing the job to be terminated. The first process to do so was:    Process name: [[41154,1],0]   Exit code:    1\"\r\nCommand \"mpirun --host algo-1:8 \r\n\r\n\r\nI\u2019d greatly appreciate your feedback. Please let me know if you need any further information about the project.\n\n### Who can help?\n\n[SageMakerAprilTraining.zip](https:\/\/github.com\/huggingface\/transformers\/files\/9065968\/SageMakerAprilTraining.zip)\r\n\n\n### Information\n\n- [ ] The official example scripts\n- [X] My own modified scripts\n\n### Tasks\n\n- [ ] An officially supported task in the `examples` folder (such as GLUE\/SQuAD, ...)\n- [X] My own task or dataset (give details below)\n\n### Reproduction\n\nRunning this attached file with the training python file\n\n### Expected behavior\n\nI have shared the notebook and the error raised in it for clarification",
        "Issue_answer_count":2,
        "Issue_self_closed":0.0,
        "Answer_body":"@omid0001 @kanwari3, \r\n\r\nWould it be possible for you to reproduce this issue (`not enough values to unpack`) without using SageMaker, i.e. just with a Python script?\r\n```bash\r\n[1,0]: bsz, seq_len = input_ids_shape[:2]\r\n[1,0]:ValueError: not enough values to unpack (expected 2, got 1)\r\n```\r\n\r\nIt would be a good idea to verify what data is received by the model first. Usually the batches in data (`input_ids`) should be already of the format `(batch_size, sequence_length)`, and if you see the above error, it is likely the data or its processing pipeline has some issues. Using `torch.unsqueeze` is not really a good idea, as it implies you have only `batch_size` being 1.\r\n\r\nMy suggestion:\r\n- Try to run your training without SageMaker (and without the using the fix `torch.unsqueeze`)\r\n- Check what is received by the model, and check in the data pipeline if it prepares the correct input format\r\n  - If you still get the issue and can't figure it out:\r\n    - I could try to help if you could provide the training script + data processing script + a tiny portion of your data    \r\n  - If the issue only occurs when you wrap the training in SageMaker, I don't have the competence to help in this case, sorry. This issue has been automatically marked as stale because it has not had recent activity. If you think this still needs to be addressed please comment on this thread.\n\nPlease note that issues that do not follow the [contributing guidelines](https:\/\/github.com\/huggingface\/transformers\/blob\/main\/CONTRIBUTING.md) are likely to be ignored.",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"led model return algorithmerror smp train info philschmid ydshieh sgugger hello follow relat post link titl http github com huggingfac transform issu ad bit progress face issu try fix try fix includ match python transform pytorch version accord recommend respect valueerror valu unpack expect got error model led transform modul expect differ input id shape new updat tri unsqueez input tensor model led solv error def unsqueez col exampl return input id torch unsqueez exampl input id pubm train pubm train map unsqueez col help move forward process got error littl code unexpectedstatusexcept error train job huggingfac pytorch train fail reason algorithmerror executeuserscripterror exitcod errormessag runtimeerror tensor number dimens got environ variabl instanc type set environ variabl instanc type set environ variabl instanc type set environ variabl instanc type set environ variabl instanc type set environ variabl instanc type set environ variabl instanc type set environ variabl instanc type set primari job termin normal process return non zero exit code user direct job abort mpirun real detect process exit non zero statu caus job termin process process exit code command mpirun host algo greatli appreci feedback let know need inform project help apriltrain zip http github com huggingfac transform file apriltrain zip inform offici exampl script modifi script task offici support task exampl folder glue squad task dataset detail reproduct run attach file train python file expect behavior share notebook error rais clarif",
        "Issue_preprocessed_content":"led model return smp train info relat post link titl ad bit face try fix try fix includ match python transform pytorch version valu unpack transform modul expect shape new updat tri input tensor solv def return help move forward got code unexpectedstatusexcept train job fail reason exitcod tensor number dimens got environ variabl set environ variabl set environ variabl set environ variabl set environ variabl set environ variabl set environ variabl set environ variabl set primari job termin return exit code job abort detect exit statu caus job termin exit code mpirun greatli let know inform project help inform exampl script modifi script task task folder task dataset reproduct file train python file expect behavior share rais clarif",
        "Issue_gpt_summary_original":"The user is encountering an error while training LayoutLMv2 on Sagemaker using Huggingface. The error occurs when importing transformers.models.layoutlmv2.modeling_layoutlmv2 due to an undefined value has_torch_function_variadic. The error traceback suggests that the issue is related to the torch version used in the training script.",
        "Issue_gpt_summary":"user encount error train layoutlmv huggingfac error occur import transform model layoutlmv model layoutlmv undefin valu torch function variad error traceback suggest issu relat torch version train script",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/huggingface\/transformers\/issues\/17855",
        "Issue_title":"LayoutLMv2 training on sagemaker error: undefined value has_torch_function_variadic",
        "Issue_created_time":1656007789000,
        "Issue_closed_time":1656429784000,
        "Issue_body":"### System Info\r\n\r\n```shell\r\ntransformer: 4.17.0\r\ntorch: 1.10.2\r\n\r\nPlatform: Sagemaker Deep Learning Container\r\n```\r\n\r\n\r\n### Who can help?\r\n\r\n@NielsRogge\r\n\r\n### Information\r\n\r\n- [ ] The official example scripts\r\n- [X] My own modified scripts\r\n\r\n### Tasks\r\n\r\n- [ ] An officially supported task in the `examples` folder (such as GLUE\/SQuAD, ...)\r\n- [ ] My own task or dataset (give details below)\r\n\r\n### Reproduction\r\n\r\nThe error only comes when training on Sagemaker using Huggingface.\r\n\r\nScripts to start training on Sagemaker:\r\n\r\nFolder organization:\r\n```\r\n.\/\r\n----sg_training.py\r\n----scripts\r\n-------requirements.txt\r\n-------train.py \r\n```\r\n\r\nsg_training.py:\r\n```\r\nimport boto3\r\nimport sagemaker\r\nfrom sagemaker.huggingface import HuggingFace\r\n\r\nif __name__ == \"__main__\":\r\n    iam_client = boto3.client(...)\r\n\r\n    role = iam_client.get_role(...)['Role']['Arn']\r\n    sess = sagemaker.Session()\r\n\r\n    sagemaker_session_bucket = 's3-sagemaker-session'\r\n\r\n    hyperparameters = {'epochs': 20,\r\n                       'train_batch_size': 1,\r\n                       'model_name': \"microsoft\/layoutxlm-base\",\r\n                       'output_dir': '\/opt\/ml\/model\/',\r\n                       'checkpoints': '\/opt\/ml\/checkpoints\/',\r\n                       'combine_train_val': True,\r\n                       'exp_tracker': \"all\",\r\n                       'exp_name': 'Sagemaker Training'\r\n                       }\r\n\r\n    huggingface_estimator = HuggingFace(entry_point='train.py',\r\n                                        source_dir='scripts',\r\n                                        instance_type='ml.p3.2xlarge',\r\n                                        instance_count=1,\r\n                                        role=role,\r\n                                        transformers_version='4.17.0',\r\n                                        pytorch_version='1.10.2',\r\n                                        py_version='py38',\r\n                                        hyperparameters=hyperparameters,\r\n                                        environment={'HF_TASK': 'text-classification'},\r\n                                        code_location='s3:\/\/dummy_code_location')\r\n\r\n    huggingface_estimator.fit()\r\n```\r\n\r\nEntrypoint scripts folder:\r\n\r\n\r\nrequirements.txt:\r\n```\r\ngit+https:\/\/github.com\/facebookresearch\/detectron2.git\r\n```\r\n\r\ntrain.py:\r\n```\r\nimport argparse\r\nimport logging\r\nimport os\r\nimport sys\r\n\r\nfrom transformers import LayoutLMv2ForSequenceClassification\r\n\r\n\r\ndef run():\r\n    model = LayoutLMv2ForSequenceClassification.from_pretrained('microsoft\/layoutxlm-base',\r\n                                                                num_labels=5)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument(\"--epochs\", type=int, default=3)\r\n    parser.add_argument(\"--exp_name\", type=str, default=\"Sagemaker Training\")\r\n    parser.add_argument(\"--train-batch-size\", type=int, default=2)\r\n    parser.add_argument(\"--eval-batch-size\", type=int, default=1)\r\n    parser.add_argument(\"--warmup_steps\", type=int, default=500)\r\n    parser.add_argument(\"--model_name\", type=str)\r\n    parser.add_argument(\"--learning_rate\", type=str, default=1e-5)\r\n    parser.add_argument(\"--combine_train_val\", type=bool, default=False)\r\n    # Data, model, and output directories\r\n    parser.add_argument(\"--output-data-dir\", type=str, default=os.environ[\"SM_OUTPUT_DATA_DIR\"])\r\n    parser.add_argument(\"--checkpoints\", type=str, default=\"\/opt\/ml\/checkpoints\")\r\n    parser.add_argument(\"--model-dir\", type=str, default='\/opt\/ml\/code\/model')\r\n    parser.add_argument(\"--n_gpus\", type=str, default=os.environ[\"SM_NUM_GPUS\"])\r\n    args, _ = parser.parse_known_args()\r\n\r\n    logger = logging.getLogger(__name__)\r\n    logging.basicConfig(\r\n        level=logging.getLevelName(\"INFO\"),\r\n        handlers=[logging.StreamHandler(sys.stdout)],\r\n        format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\r\n    )\r\n\r\n    run()\r\n\r\n```\r\n\r\n\r\n### Expected behavior\r\n\r\n```shell\r\nHere the log on the error from AWS Cloud Watch:\r\n\r\nInvoking script with the following command:\r\n\/opt\/conda\/bin\/python3.8 train.py --checkpoints \/opt\/ml\/checkpoints\/ --combine_train_val True --epochs 20 --exp_name Sagemaker_Training_doc_cls --exp_tracker all --model_name microsoft\/layoutxlm-base --output_dir \/opt\/ml\/model\/ --train_batch_size 1\r\nTraceback (most recent call last):\r\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/transformers\/file_utils.py\", line 2777, in _get_module\r\nreturn importlib.import_module(\".\" + module_name, self.__name__)\r\n  File \"\/opt\/conda\/lib\/python3.8\/importlib\/__init__.py\", line 127, in import_module\r\nreturn _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\r\nFile \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\r\nFile \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\r\nFile \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\r\nFile \"<frozen importlib._bootstrap_external>\", line 848, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nFile \"\/opt\/conda\/lib\/python3.8\/site-packages\/transformers\/models\/layoutlmv2\/modeling_layoutlmv2.py\", line 48, in <module>\r\nfrom detectron2.modeling import META_ARCH_REGISTRY\r\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/detectron2\/modeling\/__init__.py\", line 2, in <module>\r\nfrom detectron2.layers import ShapeSpec\r\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/detectron2\/layers\/__init__.py\", line 2, in <module>\r\nfrom .batch_norm import FrozenBatchNorm2d, get_norm, NaiveSyncBatchNorm, CycleBatchNormList\r\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/detectron2\/layers\/batch_norm.py\", line 4, in <module>\r\n    from fvcore.nn.distributed import differentiable_all_reduce\r\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/fvcore\/nn\/__init__.py\", line 4, in <module>\r\n    from .focal_loss import (\r\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/fvcore\/nn\/focal_loss.py\", line 52, in <module>\r\n    sigmoid_focal_loss_jit: \"torch.jit.ScriptModule\" = torch.jit.script(sigmoid_focal_loss)\r\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/torch\/jit\/_script.py\", line 1310, in script\r\nfn = torch._C._jit_script_compile(\r\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/torch\/jit\/_recursive.py\", line 838, in try_compile_fn\r\nreturn torch.jit.script(fn, _rcb=rcb)\r\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/torch\/jit\/_script.py\", line 1310, in script\r\nfn = torch._C._jit_script_compile(\r\nRuntimeError: \r\nundefined value has_torch_function_variadic:\r\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/torch\/utils\/smdebug.py\", line 2962\r\n         >>> loss.backward()\r\n    \"\"\"\r\n    if has_torch_function_variadic(input, target, weight, pos_weight):\r\n       ~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\r\n        return handle_torch_function(\r\n            binary_cross_entropy_with_logits,\r\n'binary_cross_entropy_with_logits' is being compiled since it was called from 'sigmoid_focal_loss'\r\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/fvcore\/nn\/focal_loss.py\", line 36\r\n    targets = targets.float()\r\n    p = torch.sigmoid(inputs)\r\n    ce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\r\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\r\n    p_t = p * targets + (1 - p) * (1 - targets)\r\n    loss = ce_loss * ((1 - p_t) ** gamma)\r\nThe above exception was the direct cause of the following exception:\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 6, in <module>\r\nfrom transformers import LayoutLMv2ForSequenceClassification\r\n  File \"<frozen importlib._bootstrap>\", line 1039, in _handle_fromlist\r\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/transformers\/file_utils.py\", line 2768, in __getattr__\r\nvalue = getattr(module, name)\r\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/transformers\/file_utils.py\", line 2767, in __getattr__\r\nmodule = self._get_module(self._class_to_module[name])\r\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/transformers\/file_utils.py\", line 2779, in _get_module\r\nraise RuntimeError(\r\nRuntimeError: Failed to import transformers.models.layoutlmv2.modeling_layoutlmv2 because of the following error (look up to see its traceback):\r\nundefined value has_torch_function_variadic:\r\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/torch\/utils\/smdebug.py\", line 2962\r\n         >>> loss.backward()\r\n    \"\"\"\r\n    if has_torch_function_variadic(input, target, weight, pos_weight):\r\n       ~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\r\n        return handle_torch_function(\r\n            binary_cross_entropy_with_logits,\r\n'binary_cross_entropy_with_logits' is being compiled since it was called from 'sigmoid_focal_loss'\r\n  File \"\/opt\/conda\/lib\/python3.8\/site-packages\/fvcore\/nn\/focal_loss.py\", line 36\r\n    targets = targets.float()\r\n    p = torch.sigmoid(inputs)\r\n    ce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\r\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\r\n    p_t = p * targets + (1 - p) * (1 - targets)\r\n    loss = ce_loss * ((1 - p_t) ** gamma)\r\n\r\n```\r\n```\r\n",
        "Issue_answer_count":8,
        "Issue_self_closed":0.0,
        "Answer_body":"cc @philschmid (hope I am tagging correctly) @Natlem could you try adding `debugger_hook_config=False` to the `HuggingFace` estimator? \r\n\r\n```python\r\n    huggingface_estimator = HuggingFace(entry_point='train.py',\r\n                                        source_dir='scripts',\r\n                                        instance_type='ml.p3.2xlarge',\r\n                                        instance_count=1,\r\n                                        role=role,\r\n                                        transformers_version='4.17.0',\r\n                                        pytorch_version='1.10.2',\r\n                                        py_version='py38',\r\n                                        hyperparameters=hyperparameters,\r\n                                        environment={'HF_TASK': 'text-classification'},\r\n                                        code_location='s3:\/\/dummy_code_location',\r\n                                        debugger_hook_config=False,\r\n)\r\n``` Hi @philschmid ,\r\n\r\nAdded the `debugger_hook_config=False`, the error is gone now. Thanks ! Awesome, closing the issue.  Feel free to reopen if you have more issues. @Natlem i forwarded the error to the AWS team to be able use the debugger soon.  @philschmid  Thanks ! @philschmid do you have any idea why this solves the problem? Is it documented by AWS anywhere?\r\n\r\nSagemaker Debugger has cost me multiple days of time in the mysterious problems it produces. Far more than anything else on Sagemaker. I posted an issue on awslabs about this awhile back and never got a reply. I would really like to know what is going on here\r\n\r\n**For anyone encountering this while using a HyperparameterTuner**\r\nPassing `debugger_hook_config=False` in the `Estimator` will not the solve the problem. Further, passing `environment={'USE_SMDEBUG':0}` also will not solve the problem. Somehow these settings never make it to a tuner's constituent training jobs.\r\n\r\nThe only way to solve it is to set `ENV USE_SMDEBUG=\"0\"` in the docker container that will be running the constituent training jobs. > Somehow these settings never make it to a tuner's constituent training jobs.\r\n\r\nAre you using the `HuggingFace` estimator or the `HyperparameterTuner`",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"layoutlmv train error undefin valu torch function variad info shell transform torch platform deep learn contain help nielsrogg inform offici exampl script modifi script task offici support task exampl folder glue squad task dataset detail reproduct error come train huggingfac script start train folder organ train script requir txt train train import boto import huggingfac import huggingfac main iam client boto client role iam client role role arn sess session session bucket session hyperparamet epoch train batch size model microsoft layoutxlm base output dir opt model checkpoint opt checkpoint combin train val true exp tracker exp train huggingfac estim huggingfac entri point train sourc dir script instanc type xlarg instanc count role role transform version pytorch version version hyperparamet hyperparamet environ task text classif code locat dummi code locat huggingfac estim fit entrypoint script folder requir txt git http github com facebookresearch detectron git train import argpars import log import import sy transform import layoutlmvforsequenceclassif def run model layoutlmvforsequenceclassif pretrain microsoft layoutxlm base num label main parser argpars argumentpars parser add argument epoch type int default parser add argument exp type str default train parser add argument train batch size type int default parser add argument eval batch size type int default parser add argument warmup step type int default parser add argument model type str parser add argument learn rate type str default parser add argument combin train val type bool default fals data model output directori parser add argument output data dir type str default environ output data dir parser add argument checkpoint type str default opt checkpoint parser add argument model dir type str default opt code model parser add argument gpu type str default environ num gpu arg parser pars known arg logger log getlogg log basicconfig level log getlevelnam info handler log streamhandl sy stdout format asctim levelnam messag run expect behavior shell log error aw cloud watch invok script follow command opt conda bin python train checkpoint opt checkpoint combin train val true epoch exp train doc cl exp tracker model microsoft layoutxlm base output dir opt model train batch size traceback recent file opt conda lib python site packag transform file util line modul return importlib import modul modul self file opt conda lib python importlib init line import modul return bootstrap gcd import level packag level file line gcd import file line load file line load unlock file line load unlock file line exec modul file line frame remov file opt conda lib python site packag transform model layoutlmv model layoutlmv line detectron model import meta arch registri file opt conda lib python site packag detectron model init line detectron layer import shapespec file opt conda lib python site packag detectron layer init line batch norm import frozenbatchnormd norm naivesyncbatchnorm cyclebatchnormlist file opt conda lib python site packag detectron layer batch norm line fvcore distribut import differenti reduc file opt conda lib python site packag fvcore init line focal loss import file opt conda lib python site packag fvcore focal loss line sigmoid focal loss jit torch jit scriptmodul torch jit script sigmoid focal loss file opt conda lib python site packag torch jit script line script torch jit script compil file opt conda lib python site packag torch jit recurs line try compil return torch jit script rcb rcb file opt conda lib python site packag torch jit script line script torch jit script compil runtimeerror undefin valu torch function variad file opt conda lib python site packag torch util smdebug line loss backward torch function variad input target weight po weight transform import layoutlmvforsequenceclassif file line handl fromlist file opt conda lib python site packag transform file util line getattr valu getattr modul file opt conda lib python site packag transform file util line getattr modul self modul self class modul file opt conda lib python site packag transform file util line modul rais runtimeerror runtimeerror fail import transform model layoutlmv model layoutlmv follow error look traceback undefin valu torch function variad file opt conda lib python site packag torch util smdebug line loss backward torch function variad input target weight po weight return handl torch function binari cross entropi logit binari cross entropi logit compil call sigmoid focal loss file opt conda lib python site packag fvcore focal loss line target target float torch sigmoid input loss binari cross entropi logit input target reduct target target loss loss gamma",
        "Issue_preprocessed_content":"layoutlmv train undefin valu info help inform exampl script modifi script task task folder task dataset reproduct come train script start train folder organ entrypoint script folder expect behavior",
        "Issue_gpt_summary_original":"The user has encountered an issue where \"pip install sacremoses>=0.0.50\" breaks on SageMaker Studio. This is likely to break \"pip install transformers\" on SageMaker Studio at some point. The user has provided a workaround by suggesting to install \"sacremoses==0.0.49\".",
        "Issue_gpt_summary":"user encount issu pip instal sacremos break studio like break pip instal transform studio point user provid workaround suggest instal sacremos",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/huggingface\/transformers\/issues\/17096",
        "Issue_title":"pip install \"sacremoses>=0.0.50\" breaks on SageMaker Studio",
        "Issue_created_time":1651754767000,
        "Issue_closed_time":1654502136000,
        "Issue_body":"### System Info\n\n```shell\nThis was verified today on a fresh SageMaker Studio instance running in us-west-2.\r\n\r\nIt's not a Transformer issue, but as sacremoses is a dependency, this is likely to break 'pip install transformers' on SageMaker Studio at some point.\n```\n\n\n### Who can help?\n\n_No response_\n\n### Information\n\n- [ ] The official example scripts\n- [ ] My own modified scripts\n\n### Tasks\n\n- [ ] An officially supported task in the `examples` folder (such as GLUE\/SQuAD, ...)\n- [ ] My own task or dataset (give details below)\n\n### Reproduction\n\n1) Open an SM Studio notebook\r\n\r\n2) Run the following cell:\r\n```\r\n%%sh\r\npip install \"sacremoses>=0.0.50\"\r\n```\r\n\r\nThe obvious workaround for now is\r\n```\r\npip install \"sacremoses==0.0.49\"\r\n```\r\n\r\n\n\n### Expected behavior\n\n```shell\nsacremoses should install without error.\n```\n",
        "Issue_answer_count":3,
        "Issue_self_closed":0.0,
        "Answer_body":"Thanks for the issue @juliensimon, this should be fixed by https:\/\/github.com\/huggingface\/transformers\/pull\/17049. It will be in the next release which should drop early next week. This issue has been automatically marked as stale because it has not had recent activity. If you think this still needs to be addressed please comment on this thread.\n\nPlease note that issues that do not follow the [contributing guidelines](https:\/\/github.com\/huggingface\/transformers\/blob\/main\/CONTRIBUTING.md) are likely to be ignored. Should be fixed now!",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"pip instal sacremos break studio info shell verifi todai fresh studio instanc run west transform issu sacremos depend like break pip instal transform studio point help respons inform offici exampl script modifi script task offici support task exampl folder glue squad task dataset detail reproduct open studio notebook run follow cell pip instal sacremos obviou workaround pip instal sacremos expect behavior shell sacremos instal error",
        "Issue_preprocessed_content":"pip break studio info help inform exampl script modifi script task task folder task dataset reproduct open studio run obviou workaround expect behavior",
        "Issue_gpt_summary_original":"The user is encountering an AlgorithmError while using SageMaker SMP training with HuggingFace estimator for the LED model. The error message suggests that there are not enough values to unpack, and the job has been aborted. The user has provided system information and reproduction steps and is seeking help from @ydshieh and @sgugger. The user expects successful training with the LED model using HuggingFace estimator and SageMaker SMP.",
        "Issue_gpt_summary":"user encount algorithmerror smp train huggingfac estim led model error messag suggest valu unpack job abort user provid inform reproduct step seek help ydshieh sgugger user expect success train led model huggingfac estim smp",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/huggingface\/transformers\/issues\/16890",
        "Issue_title":"LED Model returns AlgorithmError when using SageMaker SMP training",
        "Issue_created_time":1650634004000,
        "Issue_closed_time":1653922922000,
        "Issue_body":"### System Info\n\n```shell\nusing sagemaker \r\nmpi_options = {\r\n    \"enabled\" : True,\r\n    \"processes_per_host\" : 8\r\n}\r\n\r\nsmp_options = {\r\n    \"enabled\":True,\r\n    \"parameters\": {\r\n        \"microbatches\": 1,\r\n        \"placement_strategy\": \"spread\",\r\n        \"pipeline\": \"interleaved\",\r\n        \"optimize\": \"memory\",\r\n        \"partitions\": 2,\r\n        \"ddp\": True,\r\n    }\r\n}\r\n\r\ndistribution={\r\n    \"smdistributed\": {\"modelparallel\": smp_options},\r\n    \"mpi\": mpi_options\r\n}\r\nhyperparameters={'epochs': 1,\r\n                 'train_batch_size': 1,\r\n                 'eval_batch_size': 1,\r\n                 'model_name':HHousen\/distil-led-large-cnn-16384,\r\n                 'output_dir': 'bucket',\r\n                 'warmup_steps': 25,\r\n                 'checkpoint_s3_uri': 'bucket',\r\n                 'logging_steps':100,\r\n                 'evaluation_strategy':\"steps\",\r\n                 'gradient_accumulation_steps':10\r\n                 }\r\nhuggingface_estimator = HuggingFace(entry_point='trainer.py',\r\n                            source_dir='.\/scripts',\r\n                            instance_type='ml.p3.16xlarge',\r\n                            instance_count=1,\r\n                            role=role,\r\n                            volume=100,\r\n                            transformers_version='4.6.1',\r\n                            pytorch_version='1.8.1',\r\n                            py_version='py36',\r\n                            hyperparameters=hyperparameters,\r\n                                   distribution=distribution)\n```\n\n\n### Who can help?\n\n@ydshieh @sgugger\n\n### Information\n\n- [ ] The official example scripts\n- [ ] My own modified scripts\n\n### Tasks\n\n- [ ] An officially supported task in the `examples` folder (such as GLUE\/SQuAD, ...)\n- [ ] My own task or dataset (give details below)\n\n### Reproduction\n\n1. Create huggingface estimator\r\n2.     training_args = Seq2SeqTrainingArguments(\r\n        predict_with_generate=True,\r\n        evaluation_strategy=\"steps\",\r\n        per_device_train_batch_size=1,\r\n        per_device_eval_batch_size=1,\r\n        fp16=True,\r\n        fp16_backend=\"apex\",\r\n        output_dir=s3_bucket,\r\n        logging_steps=50,\r\n        warmup_steps=25,\r\n        gradient_accumulation_steps=10,\r\n    )\r\n\r\nError I get:\r\n[1,0]<stderr>:  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/smdistributed\/modelparallel\/torch\/patches\/tracing.py\", line 68, in trace_forward\r\n[1,0]<stderr>:    raise e\r\n[1,0]<stderr>:  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/smdistributed\/modelparallel\/torch\/patches\/tracing.py\", line 51, in trace_forward\r\n[1,0]<stderr>:    output = original_forward(self, *args, **kwargs)\r\n[1,0]<stderr>:  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/transformers\/models\/led\/modeling_led.py\", line 125, in forward\r\n[1,0]<stderr>:    return super().forward(positions)\r\n[1,0]<stderr>:  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/smdistributed\/modelparallel\/torch\/patches\/tracing.py\", line 68, in trace_forward\r\n[1,0]<stderr>:    raise e\r\n[1,0]<stderr>:  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/smdistributed\/modelparallel\/torch\/patches\/tracing.py\", line 51, in trace_forward\r\n[1,0]<stderr>:    output = original_forward(self, *args, **kwargs)\r\n[1,0]<stderr>:  File \"\/opt\/conda\/lib\/python3.6\/site-packages\/transformers\/models\/led\/modeling_led.py\", line 121, in forward\r\n[1,0]<stderr>:    bsz, seq_len = input_ids_shape[:2]\r\n[1,0]<stderr>:ValueError: not enough values to unpack (expected 2, got 1)\r\n--------------------------------------------------------------------------\r\nPrimary job  terminated normally, but 1 process returned\r\na non-zero exit code. Per user-direction, the job has been aborted.\r\n--------------------------------------------------------------------------\r\n--------------------------------------------------------------------------\r\nmpirun.real detected that one or more processes exited with non-zero status, thus causing\r\nthe job to be terminated. The first process to do so was:\r\n  Process name: [[41156,1],0]\r\n  Exit code:    1\r\n--------------------------------------------------------------------------\r\n\n\n### Expected behavior\n\n```shell\nTraining on a sagemaker notebook p3dn.24xlarge using fairscale `simple` and these versions\r\ntransformers-4.16.2\r\ntorch-1.10.2\r\nfairscale-0.4.5\r\npy37\r\n\r\nI can successfully train the LED model with my training data. Trying to get it to work with Huggingface estimator and sagemaker SMP I would assume the same outcome.\n```\n",
        "Issue_answer_count":4,
        "Issue_self_closed":0.0,
        "Answer_body":"cc @philschmid  I would also suggest @kanwari3 to\r\n- try to use the same Python\/PyTorch\/transformers versions (and other libraries) on SageMaker that work locally (if possible)\r\n- if the above doesn't work, try to use on local machine the same versions as those used on SageMaker, and see if you still get errors\r\n\r\nSo we have a better idea about if this is indeed a SageMaker issue or libraries issue This issue has been automatically marked as stale because it has not had recent activity. If you think this still needs to be addressed please comment on this thread.\n\nPlease note that issues that do not follow the [contributing guidelines](https:\/\/github.com\/huggingface\/transformers\/blob\/main\/CONTRIBUTING.md) are likely to be ignored. cc @philschmid  , cc @ydshieh ,  cc @sgugger \r\nHi, \r\n\r\nThis is a follow up on this post with the same title. We are trying to fix the issue and are still getting the same error after trying out several fixes including matching the python, transformers, and pytorch versions according to the recommendations (3.8, 4.16.2, and 1.10.2, respectively):\r\n\r\n-ValueError: not enough values to unpack (expected 2, got 1)\r\n\r\nThe error is in the \u201cmodeling_led\u201d within the transformers module expecting a different input_ids shape. We tried unsqueezing the input_ids and attention_masks but it didn\u2019t fix the error.\r\n\r\nNew Update is we tried below to unsqueeze input tensors to the \"modeling_led\" to solve the above error:\r\ndef unsqueeze_col(example):\r\n    return {\"input_ids\": torch.unsqueeze(example[\"input_ids\"], 0)}\r\npubmed_train = pubmed_train.map(unsqueeze_col)\r\n\r\nI\u2019d greatly appreciate your feedback. Please let me know if you need any further information about the project.",
        "Tool":"Amazon SageMaker",
        "Platform":"Github",
        "Issue_original_content":"led model return algorithmerror smp train info shell mpi option enabl true process host smp option enabl true paramet microbatch placement strategi spread pipelin interleav optim memori partit ddp true distribut smdistribut modelparallel smp option mpi mpi option hyperparamet epoch train batch size eval batch size model hhousen distil led larg cnn output dir bucket warmup step checkpoint uri bucket log step evalu strategi step gradient accumul step huggingfac estim huggingfac entri point trainer sourc dir script instanc type xlarg instanc count role role volum transform version pytorch version version hyperparamet hyperparamet distribut distribut help ydshieh sgugger inform offici exampl script modifi script task offici support task exampl folder glue squad task dataset detail reproduct creat huggingfac estim train arg seqseqtrainingargu predict gener true evalu strategi step devic train batch size devic eval batch size true backend apex output dir bucket log step warmup step gradient accumul step error file opt conda lib python site packag smdistribut modelparallel torch patch trace line trace forward rais file opt conda lib python site packag smdistribut modelparallel torch patch trace line trace forward output origin forward self arg kwarg file opt conda lib python site packag transform model led model led line forward return super forward posit file opt conda lib python site packag smdistribut modelparallel torch patch trace line trace forward rais file opt conda lib python site packag smdistribut modelparallel torch patch trace line trace forward output origin forward self arg kwarg file opt conda lib python site packag transform model led model led line forward bsz seq len input id shape valueerror valu unpack expect got primari job termin normal process return non zero exit code user direct job abort mpirun real detect process exit non zero statu caus job termin process process exit code expect behavior shell train notebook pdn xlarg fairscal simpl version transform torch fairscal successfulli train led model train data try work huggingfac estim smp assum outcom",
        "Issue_preprocessed_content":"led model return smp train info help inform exampl script modifi script task task folder task dataset reproduct creat estim seq seqtrainingargu file line rais file line output arg kwarg file line forward return file line rais file line output arg kwarg file line forward bsz valu unpack primari job termin return exit code job abort detect exit statu caus job termin exit code expect behavior",
        "Issue_gpt_summary_original":"The user encountered an ImportError while running an example command for online deployment in Azure ML. The error message indicates that the 'json' module cannot be imported from 'itsdangerous'.",
        "Issue_gpt_summary":"user encount importerror run exampl command onlin deploy error messag indic json modul import itsdanger",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/azureml-examples\/issues\/977",
        "Issue_title":"ImportError: cannot import name 'json' from 'itsdangerous' (\/azureml-envs\/azureml_9560a2159e2635db8931fa24bcadb555\/lib\/python3.7\/site-packages\/itsdangerous\/__init__.py)",
        "Issue_created_time":1645497684000,
        "Issue_closed_time":1645604942000,
        "Issue_body":"## Which example? Describe the issue\r\n\r\nexample:  az ml online-deployment create --name blue --endpoint-name amlarc-runner-simple-849b --resource-group lt-westus2-r6-amlarc-rg --workspace-name lt-westus2-r6-arc-ws --file azureml-examples\/cli\/endpoints\/online\/\/amlarc\/blue-deployment.yml --all-traffic\r\ndescription:\r\nFile \"\/var\/azureml-server\/entry.py\", line 1, in <module>\r\n    import create_app\r\n  File \"\/var\/azureml-server\/create_app.py\", line 3, in <module>\r\n    import aml_framework\r\n  File \"\/var\/azureml-server\/aml_framework.py\", line 9, in <module>\r\n    from synchronous.framework import *\r\n  File \"\/var\/azureml-server\/synchronous\/framework.py\", line 3, in <module>\r\n    from flask import Flask, request, g, Request, Response, Blueprint\r\n  File \"\/azureml-envs\/azureml_9560a2159e2635db8931fa24bcadb555\/lib\/python3.7\/site-packages\/flask\/__init__.py\", line 21, in <module>\r\n    from .app import Flask, Request, Response\r\n  File \"\/azureml-envs\/azureml_9560a2159e2635db8931fa24bcadb555\/lib\/python3.7\/site-packages\/flask\/app.py\", line 26, in <module>\r\n    from . import cli, json\r\n  File \"\/azureml-envs\/azureml_9560a2159e2635db8931fa24bcadb555\/lib\/python3.7\/site-packages\/flask\/json\/__init__.py\", line 21, in <module>\r\n    from itsdangerous import json as _json\r\nImportError: cannot import name 'json' from 'itsdangerous' (\/azureml-envs\/azureml_9560a2159e2635db8931fa24bcadb555\/lib\/python3.7\/site-packages\/itsdangerous\/__init__.py)\r\n\r\n## Additional context\r\n\r\nhttps:\/\/ml.azure.com\/endpoints\/realtime\/amlarc-runner-simple-849b\/logs?wsid=\/subscriptions\/589c7ae9-223e-45e3-a191-98433e0821a9\/resourcegroups\/lt-westus2-r6-amlarc-rg\/workspaces\/lt-westus2-r6-arc-ws&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\r\n\r\n-\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"This issue should be mitigated once the PR is merged: https:\/\/github.com\/Azure\/azureml-examples\/pull\/981",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"importerror import json itsdanger env aedbfabcadb lib python site packag itsdanger init exampl issu exampl onlin deploy creat blue endpoint amlarc runner simpl resourc group westu amlarc workspac westu arc file exampl cli endpoint onlin amlarc blue deploy yml traffic descript file var server entri line import creat app file var server creat app line import aml framework file var server aml framework line synchron framework import file var server synchron framework line flask import flask request request respons blueprint file env aedbfabcadb lib python site packag flask init line app import flask request respons file env aedbfabcadb lib python site packag flask app line import cli json file env aedbfabcadb lib python site packag flask json init line itsdanger import json json importerror import json itsdanger env aedbfabcadb lib python site packag itsdanger init addit context http azur com endpoint realtim amlarc runner simpl log wsid subscript cae resourcegroup westu amlarc workspac westu arc tid fbf dcddb",
        "Issue_preprocessed_content":"import json itsdanger exampl exampl creat blue descript file line import file line import file line import file line flask import flask request request respons blueprint file line import flask request respons file line import cli json file line itsdanger import json import json itsdanger context",
        "Issue_gpt_summary_original":"The user is reporting a bug related to updating test documentation to connect AzureML with GitHub actions. The steps to replicate the issue involve creating a new AzureML workspace, creating two new clusters, adding subscription ID to GitHub action secrets, installing Azure CLI, creating a Service Principal, and adding the output from the Service Principal as an action secret. The user has not mentioned any specific platform where the issue is happening.",
        "Issue_gpt_summary":"user report bug relat updat test document connect github action step replic issu involv creat new workspac creat new cluster ad subscript github action secret instal azur cli creat servic princip ad output servic princip action secret user mention specif platform issu happen",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/recommenders\/issues\/1862",
        "Issue_title":"[BUG] Update test documentation to connect AzureML with GitHub actions",
        "Issue_created_time":1669630421000,
        "Issue_closed_time":1669646142000,
        "Issue_body":"### Description\r\n<!--- Describe your issue\/bug\/request in detail -->\r\n\r\nSteps:\r\n1. Create a new AzureML workspace.\r\n    - Name: `azureml-test-workspace`\r\n    - Resource group: `recommenders_project_resources`\r\n    - Location: *Make sure you have enough quota in the location you choose*\r\n2. Create two new clusters: `cpu-cluster` and `gpu-cluster`. Go to compute, then compute cluster, then new.\r\n    - Select the CPU VM base. Anything above 32GB of RAM, and 8 cores should be fine.\r\n    - Select the GPU VM base. Anything above 56GB of RAM, and 6 cores, and an NVIDIA K80 should be fine.\r\n3. Add the subscription ID to GitHub action secrets [here](https:\/\/github.com\/microsoft\/recommenders\/settings\/secrets\/actions). Create a new repository secret called `AZUREML_TEST_SUBID` and add the subscription ID as the value.\r\n4. Make sure you have installed [Azure CLI](https:\/\/learn.microsoft.com\/en-us\/cli\/azure\/install-azure-cli), and that you are logged in: `az login`.\r\n5. Select your subscription: `az account set -s $AZURE_SUBSCRIPTION_ID`.\r\n5. Create a Service Principal: `az ad sp create-for-rbac --name \"CICD\" --role contributor --scopes \/subscriptions\/$AZURE_SUBSCRIPTION_ID --sdk-auth`.\r\n6. Add the output from the Service Principal (should be a JSON blob) as an action secret `AZUREML_TEST_CREDENTIALS`.\r\n\r\n\r\n\r\n### In which platform does it happen?\r\n<!--- Describe the platform where the issue is happening (use a list if needed) -->\r\n<!--- For example: -->\r\n<!--- * Azure Data Science Virtual Machine. -->\r\n<!--- * Azure Databricks.  -->\r\n<!--- * Other platforms.  -->\r\n\r\n### How do we replicate the issue?\r\n<!--- Please be specific as possible (use a list if needed). -->\r\n<!--- For example: -->\r\n<!--- * Create a conda environment for pyspark -->\r\n<!--- * Run unit test `test_sar_pyspark.py` with `pytest -m 'spark'` -->\r\n<!--- * ... -->\r\n\r\n### Expected behavior (i.e. solution)\r\n<!--- For example:  -->\r\n<!--- * The tests for SAR PySpark should pass successfully. -->\r\n\r\n### Other Comments\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"Error:\r\n```\r\n$ az ad sp create-for-rbac --name \"CICD\" --role contributor --scopes \/subscriptions\/$AZURE_SUBSCRIPTION_ID. --sdk-auth\r\nThis command or command group has been migrated to Microsoft Graph API. Please carefully review all breaking changes introduced during this migration: https:\/\/docs.microsoft.com\/cli\/azure\/microsoft-graph-migration\r\nOption '--sdk-auth' has been deprecated and will be removed in a future release.\r\nAADSTS530003: Your device is required to be managed to access this resource.\r\nTrace ID: XXXXXXXXXXXXXXXXXXXXXXX\r\nCorrelation ID: XXXXXXXXXXXXXXXXXXXXXXX\r\nTimestamp: 2022-11-28 10:02:57Z\r\nTo re-authenticate, please run:\r\naz login --scope https:\/\/graph.microsoft.com\/\/.default\r\n```\r\n",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"bug updat test document connect github action descript step creat new workspac test workspac resourc group recommend project resourc locat sure quota locat choos creat new cluster cpu cluster gpu cluster comput comput cluster new select cpu base ram core fine select gpu base ram core nvidia fine add subscript github action secret http github com microsoft recommend set secret action creat new repositori secret call test subid add subscript valu sure instal azur cli http learn microsoft com cli azur instal azur cli log login select subscript account set azur subscript creat servic princip creat rbac cicd role contributor scope subscript azur subscript sdk auth add output servic princip json blob action secret test credenti platform happen replic issu expect behavior solut comment",
        "Issue_preprocessed_content":"updat test document github action descript step creat new workspac resourc group locat sure quota locat creat new cluster comput comput cluster new select cpu base ram core fine select gpu base ram core nvidia fine subscript github action secret creat new repositori secret subscript valu sure select subscript creat servic princip output servic princip action secret platform platform exampl azur data scienc virtual machin azur databrick platform replic specif exampl creat conda environ pyspark run unit test expect behavior exampl test sar pyspark",
        "Issue_gpt_summary_original":"The user is encountering a bug in AzureML where the test process does not fail even if there is an error in the tests, making it difficult to identify errors. The user wants to receive a signal in GitHub when the tests fail so that the badge turns red and they are notified.",
        "Issue_gpt_summary":"user encount bug test process fail error test make difficult identifi error user want receiv signal github test fail badg turn red notifi",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/recommenders\/issues\/1852",
        "Issue_title":"[BUG] AzureML test process is not failing if there is an error in the tests",
        "Issue_created_time":1668674781000,
        "Issue_closed_time":null,
        "Issue_body":"### Description\r\n<!--- Describe your issue\/bug\/request in detail -->\r\nAzureML tests execute the code, but if the process fail, we are not getting a signal that is failing, which makes difficult to identify errors\r\n\r\n\r\n### In which platform does it happen?\r\n<!--- Describe the platform where the issue is happening (use a list if needed) -->\r\n<!--- For example: -->\r\n<!--- * Azure Data Science Virtual Machine. -->\r\n<!--- * Azure Databricks.  -->\r\n<!--- * Other platforms.  -->\r\n\r\n### How do we replicate the issue?\r\n<!--- Please be specific as possible (use a list if needed). -->\r\n<!--- For example: -->\r\n<!--- * Create a conda environment for pyspark -->\r\n<!--- * Run unit test `test_sar_pyspark.py` with `pytest -m 'spark'` -->\r\n<!--- * ... -->\r\nSee https:\/\/github.com\/microsoft\/recommenders\/actions\/runs\/3485981939\/jobs\/5832009213\r\n\r\n### Expected behavior (i.e. solution)\r\n<!--- For example:  -->\r\n<!--- * The tests for SAR PySpark should pass successfully. -->\r\nWe want to send back a signal to GitHub so if the tests fail, the badge is red and we are notified\r\n\r\n\r\n### Other Comments\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"bug test process fail error test descript test execut code process fail get signal fail make difficult identifi error platform happen replic issu http github com microsoft recommend action run job expect behavior solut want send signal github test fail badg red notifi comment",
        "Issue_preprocessed_content":"test fail test descript test execut code fail signal fail make identifi platform platform exampl azur data scienc virtual machin azur databrick platform replic specif exampl creat conda environ pyspark run unit test expect behavior exampl test sar pyspark want send signal github test fail badg red notifi",
        "Issue_gpt_summary_original":"The user encountered a bug in the xdeepfm test in AzureML, where the obtained value did not match the expected value. The issue occurred during integration testing and was marked with GPU, notebooks, and integration tags. The user provided a link to the GitHub repository where the issue occurred.",
        "Issue_gpt_summary":"user encount bug xdeepfm test obtain valu match expect valu issu occur integr test mark gpu notebook integr tag user provid link github repositori issu occur",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/recommenders\/issues\/1848",
        "Issue_title":"[BUG] xdeepfm error in AzureML test",
        "Issue_created_time":1668591744000,
        "Issue_closed_time":1668600473000,
        "Issue_body":"### Description\r\n<!--- Describe your issue\/bug\/request in detail -->\r\n```\r\n    @pytest.mark.gpu\r\n    @pytest.mark.notebooks\r\n    @pytest.mark.integration\r\n    @pytest.mark.parametrize(\r\n        \"syn_epochs, criteo_epochs, expected_values, seed\",\r\n        [\r\n            (\r\n                15,\r\n                10,\r\n                ***\r\n                    \"res_syn\": ***\"auc\": 0.9716, \"logloss\": 0.699***,\r\n                    \"res_real\": ***\"auc\": 0.749, \"logloss\": 0.4926***,\r\n                ***,\r\n                42,\r\n            )\r\n        ],\r\n    )\r\n    def test_xdeepfm_integration(\r\n        notebooks,\r\n        output_notebook,\r\n        kernel_name,\r\n        syn_epochs,\r\n        criteo_epochs,\r\n        expected_values,\r\n        seed,\r\n    ):\r\n        notebook_path = notebooks[\"xdeepfm_quickstart\"]\r\n        pm.execute_notebook(\r\n            notebook_path,\r\n            output_notebook,\r\n            kernel_name=kernel_name,\r\n            parameters=dict(\r\n                EPOCHS_FOR_SYNTHETIC_RUN=syn_epochs,\r\n                EPOCHS_FOR_CRITEO_RUN=criteo_epochs,\r\n                BATCH_SIZE_SYNTHETIC=1024,\r\n                BATCH_SIZE_CRITEO=1024,\r\n                RANDOM_SEED=seed,\r\n            ),\r\n        )\r\n        results = sb.read_notebook(output_notebook).scraps.dataframe.set_index(\"name\")[\r\n            \"data\"\r\n        ]\r\n    \r\n        for key, value in expected_values.items():\r\n>           assert results[key][\"auc\"] == pytest.approx(value[\"auc\"], rel=TOL, abs=ABS_TOL)\r\nE           assert 0.5131 == 0.9716 \u00b1 9.7e-02\r\nE             comparison failed\r\nE             Obtained: 0.5131\r\nE             Expected: 0.9716 \u00b1 9.7e-02\r\n```\r\n\r\n### In which platform does it happen?\r\n<!--- Describe the platform where the issue is happening (use a list if needed) -->\r\n<!--- For example: -->\r\n<!--- * Azure Data Science Virtual Machine. -->\r\n<!--- * Azure Databricks.  -->\r\n<!--- * Other platforms.  -->\r\n\r\n### How do we replicate the issue?\r\n<!--- Please be specific as possible (use a list if needed). -->\r\n<!--- For example: -->\r\n<!--- * Create a conda environment for pyspark -->\r\n<!--- * Run unit test `test_sar_pyspark.py` with `pytest -m 'spark'` -->\r\n<!--- * ... -->\r\nSee https:\/\/github.com\/microsoft\/recommenders\/actions\/runs\/3459763061\/jobs\/5775521889\r\n\r\n\r\n### Expected behavior (i.e. solution)\r\n<!--- For example:  -->\r\n<!--- * The tests for SAR PySpark should pass successfully. -->\r\n\r\n### Other Comments\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"```\r\n pytest tests\/integration\/examples\/test_notebooks_gpu.py::test_xdeepfm_integration --disable-warnings --durations 0\r\n```\r\nwith \r\n```\r\n@pytest.mark.gpu\r\n@pytest.mark.notebooks\r\n@pytest.mark.integration\r\n@pytest.mark.parametrize(\r\n    \"syn_epochs, criteo_epochs, expected_values, seed\",\r\n    [\r\n        (\r\n            15,\r\n            10,\r\n            {\r\n                \"res_syn\": {\"auc\": 0.9716, \"logloss\": 0.699},\r\n                \"res_real\": {\"auc\": 0.749, \"logloss\": 0.4926},\r\n            },\r\n            42,\r\n        )\r\n    ],\r\n)\r\ndef test_xdeepfm_integration(\r\n    notebooks,\r\n    output_notebook,\r\n    kernel_name,\r\n    syn_epochs,\r\n    criteo_epochs,\r\n    expected_values,\r\n    seed,\r\n):\r\n    notebook_path = notebooks[\"xdeepfm_quickstart\"]\r\n    pm.execute_notebook(\r\n        notebook_path,\r\n        output_notebook,\r\n        kernel_name=kernel_name,\r\n        parameters=dict(\r\n            EPOCHS_FOR_SYNTHETIC_RUN=syn_epochs,\r\n            EPOCHS_FOR_CRITEO_RUN=criteo_epochs,\r\n            BATCH_SIZE_SYNTHETIC=1024,\r\n            BATCH_SIZE_CRITEO=1024,\r\n            RANDOM_SEED=seed,\r\n        ),\r\n    )\r\n    results = sb.read_notebook(output_notebook).scraps.dataframe.set_index(\"name\")[\r\n        \"data\"\r\n    ]\r\n\r\n    for key, value in expected_values.items():\r\n        assert results[key][\"auc\"] == pytest.approx(value[\"auc\"], rel=TOL, abs=ABS_TOL)\r\n        assert results[key][\"logloss\"] == pytest.approx(\r\n            value[\"logloss\"], rel=TOL, abs=ABS_TOL\r\n        )\r\n```",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"bug xdeepfm error test descript pytest mark gpu pytest mark notebook pytest mark integr pytest mark parametr syn epoch criteo epoch expect valu seed re syn auc logloss re real auc logloss def test xdeepfm integr notebook output notebook kernel syn epoch criteo epoch expect valu seed notebook path notebook xdeepfm quickstart execut notebook notebook path output notebook kernel kernel paramet dict epoch synthet run syn epoch epoch criteo run criteo epoch batch size synthet batch size criteo random seed seed result read notebook output notebook scrap datafram set index data kei valu expect valu item assert result kei auc pytest approx valu auc rel tol ab ab tol assert comparison fail obtain expect platform happen replic issu http github com microsoft recommend action run job expect behavior solut comment",
        "Issue_preprocessed_content":"test descript platform platform exampl azur data scienc virtual machin azur databrick platform replic specif exampl creat conda environ pyspark run unit test expect behavior exampl test sar pyspark",
        "Issue_gpt_summary_original":"The user has encountered errors in some of the AzureML tests, specifically in the test_notebooks_gpu.py file. The errors are related to not finding certain names in the module. The platform where the issue is happening is not specified, and there are no instructions on how to replicate the issue. The expected behavior is not mentioned.",
        "Issue_gpt_summary":"user encount error test specif test notebook gpu file error relat find certain name modul platform issu happen specifi instruct replic issu expect behavior mention",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/recommenders\/issues\/1841",
        "Issue_title":"[BUG] Error in some of the AzureML tests",
        "Issue_created_time":1668089448000,
        "Issue_closed_time":1668591607000,
        "Issue_body":"### Description\r\n<!--- Describe your issue\/bug\/request in detail -->\r\nThere are some errors: https:\/\/github.com\/microsoft\/recommenders\/actions\/runs\/3402182291\/jobs\/5657762171#step:3:1022\r\n\r\n```\r\n=========================== short test summary info ============================\r\nERROR tests\/integration\/examples\/test_notebooks_gpu.py\r\nERROR tests\/integration\/examples\/test_notebooks_gpu.py\r\nERROR tests\/integration\/examples\/test_notebooks_gpu.py\r\n======================== 48 warnings, 3 errors in 3.79s ========================\r\nERROR: not found: \/mnt\/azureml\/cr\/j\/445b60537f0546449ad2693000a5417e\/exe\/wd\/tests\/integration\/examples\/test_notebooks_gpu.py::test_lightgcn_deep_dive_integration\r\n(no name '\/mnt\/azureml\/cr\/j\/445b60537f0546449ad2693000a5417e\/exe\/wd\/tests\/integration\/examples\/test_notebooks_gpu.py::test_lightgcn_deep_dive_integration' in any of [<Module tests\/integration\/examples\/test_notebooks_gpu.py>])\r\n\r\nERROR: not found: \/mnt\/azureml\/cr\/j\/445b60537f0546449ad2693000a5417e\/exe\/wd\/tests\/integration\/examples\/test_notebooks_gpu.py::test_dkn_quickstart_integration\r\n(no name '\/mnt\/azureml\/cr\/j\/445b60537f0546449ad2693000a5417e\/exe\/wd\/tests\/integration\/examples\/test_notebooks_gpu.py::test_dkn_quickstart_integration' in any of [<Module tests\/integration\/examples\/test_notebooks_gpu.py>])\r\n\r\nERROR: not found: \/mnt\/azureml\/cr\/j\/445b60537f0546449ad2693000a5417e\/exe\/wd\/tests\/integration\/examples\/test_notebooks_gpu.py::test_slirec_quickstart_integration\r\n(no name '\/mnt\/azureml\/cr\/j\/445b60537f0546449ad2693000a5417e\/exe\/wd\/tests\/integration\/examples\/test_notebooks_gpu.py::test_slirec_quickstart_integration' in any of [<Module tests\/integration\/examples\/test_notebooks_gpu.py>])\r\n\r\nINFO:submit_groupwise_azureml_pytest.py:Test execution completed!\r\n\r\n```\r\n\r\n\r\n### In which platform does it happen?\r\n<!--- Describe the platform where the issue is happening (use a list if needed) -->\r\n<!--- For example: -->\r\n<!--- * Azure Data Science Virtual Machine. -->\r\n<!--- * Azure Databricks.  -->\r\n<!--- * Other platforms.  -->\r\n\r\n### How do we replicate the issue?\r\n<!--- Please be specific as possible (use a list if needed). -->\r\n<!--- For example: -->\r\n<!--- * Create a conda environment for pyspark -->\r\n<!--- * Run unit test `test_sar_pyspark.py` with `pytest -m 'spark'` -->\r\n<!--- * ... -->\r\n\r\n### Expected behavior (i.e. solution)\r\n<!--- For example:  -->\r\n<!--- * The tests for SAR PySpark should pass successfully. -->\r\n\r\n### Other Comments\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"@pradnyeshjoshi any thoughts for this error?",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"bug error test descript error http github com microsoft recommend action run job step short test summari info error test integr exampl test notebook gpu error test integr exampl test notebook gpu error test integr exampl test notebook gpu warn error error mnt bfada ex test integr exampl test notebook gpu test lightgcn deep dive integr mnt bfada ex test integr exampl test notebook gpu test lightgcn deep dive integr error mnt bfada ex test integr exampl test notebook gpu test dkn quickstart integr mnt bfada ex test integr exampl test notebook gpu test dkn quickstart integr error mnt bfada ex test integr exampl test notebook gpu test slirec quickstart integr mnt bfada ex test integr exampl test notebook gpu test slirec quickstart integr info submit groupwis pytest test execut complet platform happen replic issu expect behavior solut comment",
        "Issue_preprocessed_content":"test descript platform platform exampl azur data scienc virtual machin azur databrick platform replic specif exampl creat conda environ pyspark run unit test expect behavior exampl test sar pyspark",
        "Issue_gpt_summary_original":"The user is encountering an issue with the SASRec integration test taking an unusually long time on an AzureML compute cluster triggered using a GitHub workflow. The runtime varies significantly from the ADO pipeline, and both machines are of the same type and use the same CUDA and CuDNN versions. The user needs to investigate why this is happening.",
        "Issue_gpt_summary":"user encount issu sasrec integr test take unusu long time comput cluster trigger github workflow runtim vari significantli ado pipelin machin type us cuda cudnn version user need investig happen",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/recommenders\/issues\/1716",
        "Issue_title":"[BUG] SASRec integration test unusually long time on AzureML compute cluster",
        "Issue_created_time":1652368299000,
        "Issue_closed_time":null,
        "Issue_body":"### Description\r\n<!--- Describe your issue\/bug\/request in detail -->\r\nRuntime of [tests\/integration\/examples\/test_notebooks_gpu.py::test_sasrec_quickstart_integration](https:\/\/github.com\/microsoft\/recommenders\/blob\/6987858116d21699f6d92661f03c1529383c7d88\/tests\/integration\/examples\/test_notebooks_gpu.py#L679) varies a lot on the following platforms:\r\n- As part of ADO pipeline, it takes ~562 sec to complete.\r\n- When run as an experiment on AzureML compute cluster triggered using a [GitHub workflow](https:\/\/github.com\/microsoft\/recommenders\/blob\/pradjoshi\/aml_tests\/.github\/workflows\/aml-nightly.yml), it takes ~7080 sec.\r\n\r\nWe need to investigate why this happens.\r\n\r\n### In which platform does it happen?\r\n<!--- Describe the platform where the issue is happening (use a list if needed) -->\r\n<!--- For example: -->\r\n<!--- * Azure Data Science Virtual Machine. -->\r\n<!--- * Azure Databricks.  -->\r\n<!--- * Other platforms.  -->\r\nBoth the machines are of same type (NC6s_V2), and use the same CUDA and CuDNN versions:\r\n`cudatoolkit=11.2`\r\n`cudnn=8.1`\r\n\r\n### How do we replicate the issue?\r\n<!--- Please be specific as possible (use a list if needed). -->\r\n<!--- For example: -->\r\n<!--- * Create a conda environment for pyspark -->\r\n<!--- * Run unit test `test_sar_pyspark.py` with `pytest -m 'spark'` -->\r\n<!--- * ... -->\r\nTrigger the [GitHub workflow](https:\/\/github.com\/microsoft\/recommenders\/blob\/pradjoshi\/aml_tests\/.github\/workflows\/aml-nightly.yml) manually and take a look at pytest logs in the dashboard to see the execution times.\r\n\r\n### Expected behavior (i.e. solution)\r\n<!--- For example:  -->\r\n<!--- * The tests for SAR PySpark should pass successfully. -->\r\n\r\n### Other Comments\r\n",
        "Issue_answer_count":0,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"bug sasrec integr test unusu long time comput cluster descript runtim test integr exampl test notebook gpu test sasrec quickstart integr http github com microsoft recommend blob dfdfccd test integr exampl test notebook gpu vari lot follow platform ado pipelin take sec complet run experi comput cluster trigger github workflow http github com microsoft recommend blob pradjoshi aml test github workflow aml nightli yml take sec need investig happen platform happen machin type nc us cuda cudnn version cudatoolkit cudnn replic issu trigger github workflow http github com microsoft recommend blob pradjoshi aml test github workflow aml nightli yml manual look pytest log dashboard execut time expect behavior solut comment",
        "Issue_preprocessed_content":"sasrec integr test long time comput cluster descript runtim vari lot platform ado pipelin take sec complet run experi comput cluster take sec investig platform platform exampl azur data scienc virtual machin azur databrick platform machin type us cuda version replic specif exampl creat conda environ pyspark run unit test pytest log dashboard execut time expect behavior exampl test sar pyspark",
        "Issue_gpt_summary_original":"The new version of Azure CLI is not compatible with the old Azure ML package, resulting in an error when creating an AzureML workspace. The issue is specific to Linux Ubuntu and has not been tested on other platforms. The expected solution is to fix the version of azure-cli-core to 2.0.75.",
        "Issue_gpt_summary":"new version azur cli compat old packag result error creat workspac issu specif linux ubuntu test platform expect solut fix version azur cli core",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/recommenders\/issues\/1171",
        "Issue_title":"[BUG] New ver. of Azure CLI is not compatible with the old Azure ML package",
        "Issue_created_time":1596320174000,
        "Issue_closed_time":1603980914000,
        "Issue_body":"### Description\r\nWe fixed azureml-sdk ver (==1.0.69) but not on azure-cli-core (>=2.0.75).\r\nThe new version of azure-cli is not compatible with the old azureml package and throws an error when creating AzureML workspace:\r\n\r\n```\r\nUnable to create the workspace. \r\n Azure Error: InvalidRequestContent\r\nMessage: The request content was invalid and could not be deserialized: 'Could not find member 'template' on object of type 'DeploymentDefinition'. Path 'template', line 1, position 12.'.\r\n```\r\n\r\nThere is an open issue at Azure cli about the similar error: https:\/\/github.com\/Azure\/azure-cli-extensions\/issues\/1591\r\n\r\n### In which platform does it happen?\r\nLinux Ubuntu\r\n(Haven't tested on other platforms)\r\n\r\n### How do we replicate the issue?\r\nInstall reco_pyspark and run operationalization notebook.\r\n\r\n### Expected behavior (i.e. solution)\r\nFix the version of azure-cli\r\n```\r\nazure-cli-core==2.0.75\r\n```\r\n\r\n### Other Comments\r\nI'm working on #1158 and #900.\r\nIf fixing the azure-cli-core version is okay, then I will address this issue together.\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"Seems we need to fix `azure-mgmt-cosmosdb` version as well... \r\n```\r\nAttributeError: module 'azure.mgmt.cosmosdb' has no attribute 'CosmosDB'\r\n```\r\n",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"bug new ver azur cli compat old packag descript fix sdk ver azur cli core new version azur cli compat old packag throw error creat workspac unabl creat workspac azur error invalidrequestcont messag request content invalid deseri member templat object type deploymentdefinit path templat line posit open issu azur cli similar error http github com azur azur cli extens issu platform happen linux ubuntu haven test platform replic issu instal reco pyspark run operation notebook expect behavior solut fix version azur cli azur cli core comment work fix azur cli core version okai address issu",
        "Issue_preprocessed_content":"new ver azur cli compat old packag descript fix sdk ver new version compat old packag throw creat workspac open azur cli similar platform linux ubuntu haven test platform replic run operation expect behavior fix version work fix version okai",
        "Issue_gpt_summary_original":"The user has encountered a bug related to the contrib package in AzureML. The product team has recommended removing the contrib package from `azureml-sdk[notebooks,tensorboard,contrib]==1.0.18` and ensuring that all tests pass. The user is questioning whether contrib is being used or planned to be used by the team. The expected solution is for everything to run smoothly. The issue is happening on DSVM and DB platforms.",
        "Issue_gpt_summary":"user encount bug relat contrib packag product team recommend remov contrib packag sdk notebook tensorboard contrib ensur test pass user question contrib plan team expect solut run smoothli issu happen dsvm platform",
        "Issue_score_count":1
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/recommenders\/issues\/695",
        "Issue_title":"[BUG] Remove contrib from azureml",
        "Issue_created_time":1553860230000,
        "Issue_closed_time":1555413510000,
        "Issue_body":"### Description\r\n<!--- Describe your issue\/bug\/request in detail -->\r\nThe product team mentioned that contrib package is not recomended for production, we need to remove contrib from here `azureml-sdk[notebooks,tensorboard,contrib]==1.0.18` and check that all the tests pass\r\n\r\n### In which platform does it happen?\r\n<!--- Describe the platform where the issue is happening (use a list if needed) -->\r\n<!--- For example: -->\r\n<!--- * Azure Data Science Virtual Machine. -->\r\n<!--- * Azure Databricks.  -->\r\n<!--- * Other platforms.  -->\r\nDSVM, DB\r\n\r\n### Expected behavior (i.e. solution)\r\n<!--- For example:  -->\r\n<!--- * The tests for SAR PySpark should pass successfully. -->\r\neverything runs\r\n\r\n### Other Comments\r\nquestion to @anargyri @loomlike @jreynolds01 @gramhagen @bethz @heatherbshapiro @jingyanwangms are we using contrib anywhere (or planning to use)?\r\n\r\n",
        "Issue_answer_count":12,
        "Issue_self_closed":1.0,
        "Answer_body":"azureml_hyperdrive_wide_and_deep notebook does**n't** use any azureml contrib modules. papermill PR in progress is using azureml.contrib.notebook. If it's not desired in the yaml file, I can install this package only inside the notebook. Will this work? mmm, yeah that would be a workaround.  Not in the Hyperdrive notebooks. since @jingyanwangms is the only one using it, can you take care of this issue in your PR? Do we want to require people to install things at the beginning of notebooks, though?  azureml.contrib.notebook is required for submitting notebook through aml. But if we don't want azureml.contrib to install as default in base yaml files, @heatherbshapiro what would you recommend doing here? @miguelgfierro Sure. I can do it in my PR. Hey guys\r\nI am getting an error while trying to run this line \"from azureml.contrib.notebook import NotebookRunConfig, AzureMLNotebookHandler\".\r\n**The error is ModuleNotFoundError: No module named 'azureml.contrib'** although I have installed azureml-contrib-notebook from pip. What should I do?\r\n HI @Raman1121 , which file in the code is this line in? I am trying to experiment with jupyter notebook on Azure through API calls by following the code snippet given here - \r\nhttps:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-contrib-notebook\/azureml.contrib.notebook.azuremlnotebookhandler?view=azure-ml-py Well, that code is not related to the Recommenders GitHub repo. Most likely you have not configured your conda or python settings appropriately.",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"bug remov contrib descript product team mention contrib packag recomend product need remov contrib sdk notebook tensorboard contrib check test pass platform happen dsvm expect behavior solut run comment question anargyri loomlik jreynold gramhagen bethz heatherbshapiro jingyanwangm contrib plan us",
        "Issue_preprocessed_content":"remov contrib descript product team mention contrib packag recomend product remov contrib check test platform platform exampl azur data scienc virtual machin azur databrick platform dsvm expect behavior exampl test sar pyspark run question contrib",
        "Issue_gpt_summary_original":"The user needs to remove the reference to Azure ML SDK preview private index from an operationalize notebook as it is now available through regular PyPi as a GA product and preview versions are unsupported.",
        "Issue_gpt_summary":"user need remov refer sdk preview privat index operation notebook avail regular pypi product preview version unsupport",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/recommenders\/issues\/451",
        "Issue_title":"Remove azureml sdk preview private PyPi index from operationalize notebook",
        "Issue_created_time":1548435846000,
        "Issue_closed_time":1548948415000,
        "Issue_body":"This [notebook](https:\/\/github.com\/Microsoft\/Recommenders\/blob\/master\/notebooks\/04_operationalize\/als_movie_o16n.ipynb) contains a reference to Azure ML SDK preview private index. \r\n\r\n    # Required packages for AzureML execution, history, and data preparation.\r\n    - --extra-index-url https:\/\/azuremlsdktestpypi.azureedge.net\/sdk-release\/Preview\/E7501C02541B433786111FE8E140CAA1\r\n\r\nGiven that Azure ML SDK is now available though regular PyPi as a GA product, and preview versions are unsupported, the extra-index-url should be removed.\r\n",
        "Issue_answer_count":3,
        "Issue_self_closed":0.0,
        "Answer_body":"hey @rastala thanks for the pointer, we are working on updating that notebook to a newer version of databricks and spark. @jreynolds01 is looking at this based on this issue https:\/\/github.com\/Microsoft\/Recommenders\/issues\/427 yes, this should be fixed with my PR. fixed with #438 ",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"remov sdk preview privat pypi index operation notebook notebook http github com microsoft recommend blob master notebook operation al movi ipynb contain refer sdk preview privat index requir packag execut histori data prepar extra index url http sdktestpypi azureedg net sdk releas preview ecbfeecaa given sdk avail regular pypi product preview version unsupport extra index url remov",
        "Issue_preprocessed_content":"remov sdk preview privat pypi index operation contain refer sdk preview privat index requir packag execut histori data prepar given sdk avail regular pypi product preview version remov",
        "Issue_gpt_summary_original":"The user is unable to open the R package locfit in Azure Machine Learning. They have followed the steps of downloading the package, creating a zip file, and uploading it to AML as a dataset. However, when executing the code, an error message is returned stating that there is no package called 'locfit_package'.",
        "Issue_gpt_summary":"user unabl open packag locfit follow step download packag creat zip file upload aml dataset execut code error messag return state packag call locfit packag",
        "Issue_score_count":1
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1590",
        "Issue_title":"Unable to open R locfit package in Azure Machine Learning",
        "Issue_created_time":1631291354000,
        "Issue_closed_time":null,
        "Issue_body":"I have trained a model locally using the R package locfit. I am now trying to run this in Azure Machine Learning.\r\n\r\nMost guides\/previous questions appear to be in relation to Azure Machine Learning (classic). Although I believe the process outlined in similar posts will be similar (e.g. here, here, I am still unable to get it to work.\r\n\r\nI have outlined the steps I have followed below:\r\n\r\nDownload locfit R package for windows Zip file from here\r\n\r\nPut this downloaded Zip file into a new Zip file entitled \"locfit_package\"\r\n\r\nI upload this \"locfit_package\" zip folder to AML as a dataset (Create Dataset > From Local Files > name: locfit_package dataset type: file > Upload the zip (\"locfit_package\") > Confirm upload is correct\r\n\r\nIn the R terminal I then execute the following code:\r\n\r\n```\r\ninstall.packages(\"src\/locfit_package.zip\", lib = \".\", repos = NULL, verbose = TRUE)\r\n\r\nlibrary(locfit_package, lib.loc=\".\", verbose=TRUE)\r\n\r\nlibrary(locfit)\r\n\r\n```\r\nThe following error message is then returned:\r\n\r\n```\r\nsystem (cmd0): \/usr\/lib\/R\/bin\/R CMD INSTALL\r\n\r\nWarning: invalid package \u2018src\/locfit_package.zip\u2019 Error: ERROR: no packages specified Warning message:\r\n\r\nIn install.packages(\"src\/locfit_package.zip\", lib = \".\", repos = NULL, : installation of package \u2018src\/locfit_package.zip\u2019 had non-zero exit status Error in library(locfit_package, lib.loc = \".\", verbose = TRUE) : there is no package called \u2018locfit_package\u2019 Execution halted\r\n\r\n\r\n```",
        "Issue_answer_count":1,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"unabl open locfit packag train model local packag locfit try run guid previou question appear relat classic believ process outlin similar post similar unabl work outlin step follow download locfit packag window zip file download zip file new zip file entitl locfit packag upload locfit packag zip folder aml dataset creat dataset local file locfit packag dataset type file upload zip locfit packag confirm upload correct termin execut follow code instal packag src locfit packag zip lib repo null verbos true librari locfit packag lib loc verbos true librari locfit follow error messag return cmd usr lib bin cmd instal warn invalid packag src locfit packag zip error error packag specifi warn messag instal packag src locfit packag zip lib repo null instal packag src locfit packag zip non zero exit statu error librari locfit packag lib loc verbos true packag call locfit packag execut halt",
        "Issue_preprocessed_content":"unabl open locfit packag train model packag locfit try run question relat believ outlin similar post similar confirm upload termin execut code return",
        "Issue_gpt_summary_original":"The user is encountering an issue while trying to mount an Azure Storage account in Azure ML. The mount works fine until a child run is started, after which the user is unable to access the mount and receives a \"No such file or directory\" error. The user has provided the code used to start the child run.",
        "Issue_gpt_summary":"user encount issu try mount azur storag account mount work fine child run start user unabl access mount receiv file directori error user provid code start child run",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1589",
        "Issue_title":"Azure ML mounting Storage Account",
        "Issue_created_time":1631278836000,
        "Issue_closed_time":null,
        "Issue_body":"Hello, \r\n\r\nWe are trying to mount an Azure Storage account in Azure ML. This works perfectly fine, until we start a child run. In the logs of the child run, we can see the following:\r\nSet Dataset input__c79bd306's target path to \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/ml-studio-01\/azureml\/train_classification_model_20210909_fr_1631216080_e3eca838\/wd\/input__c79bd306_f7faa3c3-938e-4cfc-950b-c91c9827dfa4\r\n\r\nBut when we try to access the mount, we get the following error: '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/ml-studio-01\/azureml\/train_classification_model_20210909_fr_1631216080_e3eca838\/wd\/input__c79bd306_f7faa3c3-938e-4cfc-950b-c91c9827dfa4': No such file or directory\r\n\r\nThe code to start the child run can be found below.\r\nThank you for your help.\r\n\r\n`child_config = ScriptRunConfig(source_directory='.',\r\n                                       script='src\/main_child.py',\r\n                                       arguments=arguments,\r\n                                       environment=environment,\r\n                                       docker_runtime_config=DockerConfiguration(use_docker=True),\r\n                                       compute_target=compute_target)\r\nrun.submit_child(child_config)`\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"mount storag account hello try mount azur storag account work perfectli fine start child run log child run follow set dataset input cbd target path mnt batch task share root job studio train classif model eeca input cbd ffaac cfc ccdfa try access mount follow error mnt batch task share root job studio train classif model eeca input cbd ffaac cfc ccdfa file directori code start child run thank help child config scriptrunconfig sourc directori script src main child argument argument environ environ docker runtim config dockerconfigur us docker true comput target comput target run submit child child config",
        "Issue_preprocessed_content":"mount storag try mount azur storag work perfectli fine start child run log child run set dataset target path try mount file directori code start child run thank help",
        "Issue_gpt_summary_original":"Pandas dataframes with arrays as column values are not being correctly persisted as AzureML datasets, resulting in an error when attempting to retrieve the data.",
        "Issue_gpt_summary":"panda datafram arrai column valu correctli persist dataset result error attempt retriev data",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1587",
        "Issue_title":"Pandas dataframes with array column values are not correctly persisted as AzureML datasets",
        "Issue_created_time":1630657501000,
        "Issue_closed_time":null,
        "Issue_body":"Pandas dataframes with arrays as column values seem to be incorrectly persisted. An example:\r\n\r\n```python\r\ntest_df = pd.DataFrame({'x': [np.random.rand(1000) for _ in range(1000)]})\r\nds = Datastore.get_default(ws)\r\nDataset.Tabular.register_pandas_dataframe(test_df, ds, 'test_dataset')\r\n\r\ntest_df.head()\r\n###\r\n\tx\r\n0\t[0.5044850335733219, 0.6054305053424696, 0.669...\r\n1\t[0.41759815476145723, 0.266477750018155, 0.511...\r\n2\t[0.6777708610872593, 0.16925324567267985, 0.16...\r\n3\t[0.4268294269387616, 0.6540643485117185, 0.033...\r\n4\t[0.6560106490417036, 0.5804652379458484, 0.582...\r\n\r\nDataset.get_by_name(ws, 'test_dataset').to_pandas_dataframe().head()\r\n###\r\nx\r\n0\tERROR\r\n1\tERROR\r\n2\tERROR\r\n3\tERROR\r\n4\tERROR\r\n```",
        "Issue_answer_count":0,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"panda datafram arrai column valu correctli persist dataset panda datafram arrai column valu incorrectli persist exampl python test datafram random rand rang datastor default dataset tabular regist panda datafram test test dataset test head dataset test dataset panda datafram head error error error error error",
        "Issue_preprocessed_content":"panda datafram column valu persist dataset panda datafram column valu persist exampl",
        "Issue_gpt_summary_original":"The user is facing an issue with identity-based access in V1.33 of Azure ML SDK. Previously, when registering a dataset with a datastore without credentials, the user was prompted to log in to get their AAD auth token to access the underlying data source. However, after the recent update, the same code prompts the message \"Getting data access token with Assigned Identity (client_id=clientid).\" The user has verified that the underlying datastore does not have Managed Identity on and that V1.32 SDK prompts them to log in. The user is using Azure SQL DB as a datastore and is seeking clarification on any changes made to the identity-based access feature in V1.33 SDK.",
        "Issue_gpt_summary":"user face issu ident base access sdk previous regist dataset datastor credenti user prompt log aad auth token access underli data sourc recent updat code prompt messag get data access token assign ident client clientid user verifi underli datastor manag ident sdk prompt log user azur sql datastor seek clarif chang ident base access featur sdk",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1584",
        "Issue_title":"Identity Based Access No longer works (with Azure SQL DB datastore) in V1.33 of Azure ML SDK",
        "Issue_created_time":1630006433000,
        "Issue_closed_time":1632248052000,
        "Issue_body":"Seems like recent upgrade to V1.33 for Azure ML SDK has changed how identity based access worked? Previously if you had a datastore (ex. SQL) with no credentials and then tried to register a dataset, it would prompt you to login to get your AAD auth token to see if you had permission to get access to the underlying data source. Seems like recent update the same code now seems to prompt this message instead of asking for user to login to and grab AD auth token:\r\n**_Getting data access token with Assigned Identity (client_id=clientid)._**\r\n\r\n\r\nI have verified the underlying datastore does not have Managed Identity on and V1.32 SDK Prompts me to log in at microsoft.com\/devicelogin and gives a code to enter and identity based access works normally after. Has any changes been made to the identity based access feature from on V1.33 SDK? According to the SDK docs, running the TabularDataset.to_pandas_dataframe() command should prompt an AD login if using no credentialed datastore into dataset creation. FYI currently using Azure SQL DB as datastore, any clarifications would be appreciated!\r\nazureml.core.Datastore class - Azure Machine Learning Python | Microsoft Docs\r\n",
        "Issue_answer_count":6,
        "Issue_self_closed":1.0,
        "Answer_body":"[70_driver_log.txt](https:\/\/github.com\/Azure\/MachineLearningNotebooks\/files\/7062339\/70_driver_log.txt)\r\n\r\nError generated in new compute that uses the V1.33 SDK Any updates to this? I had created another AML Workspace and issue disappeared but for some other subscriptions it still doesnt work and errors with the same thing as in the logs. Everything works perfectly fine in V1.32 of the SDK so not sure if new update changed some sort of Identity SDK used in Azure? The driver log had error message \"Compute has no identity provisioned.\" Try updating the compute to enable managed identity, and grant managed identity access to the data storage. Ah ok I was under the impression only the compute clusters had MI and not the compute instance. I'll take a look at the docs and will also re-configure the datastore which might be issue. @rudizhou428 we had some new feature for Compute Instance, which can use your identity in the CI, but, you need to re-create the CI as it won't automatically update the existing one. @chunyli0328 Ah ok cool, I ended up creating a new Azure ML Workspace and moved all my files over and since you need to recreate the CI and clusters, I'm guessing thats why it started to work again. Closing this issue, thanks for the help everyone!",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"ident base access longer work azur sql datastor sdk like recent upgrad sdk chang ident base access work previous datastor sql credenti tri regist dataset prompt login aad auth token permiss access underli data sourc like recent updat code prompt messag instead ask user login grab auth token get data access token assign ident client clientid verifi underli datastor manag ident sdk prompt log microsoft com devicelogin give code enter ident base access work normal chang ident base access featur sdk accord sdk doc run tabulardataset panda datafram command prompt login credenti datastor dataset creation fyi current azur sql datastor clarif appreci core datastor class python microsoft doc",
        "Issue_preprocessed_content":"ident base longer work sdk like recent upgrad sdk chang ident base work previous datastor credenti tri regist dataset prompt login auth token underli data sourc like recent updat code prompt instead ask user login grab auth token data token ident verifi underli datastor manag ident sdk prompt log give code enter ident base work chang ident base featur sdk sdk doc prompt login credenti datastor dataset creation fyi azur sql datastor clarif python microsoft doc",
        "Issue_gpt_summary_original":"The user is encountering an error while trying to install `azureml-core` package using pip on Windows 10 with Python 3.9.5 64-bit. The error is specifically related to the `ruamel.yaml` package during installation. The user suggests using a later version of `ruamel.yaml` as a possible solution.",
        "Issue_gpt_summary":"user encount error try instal core packag pip window python bit error specif relat ruamel yaml packag instal user suggest later version ruamel yaml possibl solut",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1564",
        "Issue_title":"pip install `azureml-core` fails on `ruamel.yaml`",
        "Issue_created_time":1627861519000,
        "Issue_closed_time":1629244160000,
        "Issue_body":"### System Specs\r\n**Operating System:** Windows 10\r\n**Python Version:** 3.9.5 64-bit\r\n\r\nWhen I run the command:\r\n\r\n```terminal\r\npip install azureml-core\r\n```\r\n\r\nI get an error during the installation, specifically on the `ruamel.yaml` package. I guess the first question I have is there any reason we are restricted to that specific version of `ruamel.yaml`? I was able to install the latest version **(0.17.10)** no problem, so if we could use a later version that would be the easiest fix.\r\n\r\n### Partial Log\r\n```terminal\r\nAttempting uninstall: ruamel.yaml\r\nFound existing installation: ruamel.yaml 0.17.10\r\nUninstalling ruamel.yaml-0.17.10:\r\nSuccessfully uninstalled ruamel.yaml-0.17.10\r\nRunning setup.py install for ruamel.yaml ... error\r\nERROR: Command errored out with exit status 1:\r\n```\r\n\r\n### Full Log\r\n[Error Log From Installation Run](https:\/\/github.com\/Azure\/MachineLearningNotebooks\/files\/6913613\/error.log)",
        "Issue_answer_count":2,
        "Issue_self_closed":0.0,
        "Answer_body":"0.17.5 introduced a breaking change hence there is an upperbound Thank you @vizhur! @areed1192, I'm closing this issue. Please reopen if you still have questions.",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"pip instal core fail ruamel yaml spec oper window python version bit run command termin pip instal core error instal specif ruamel yaml packag guess question reason restrict specif version ruamel yaml abl instal latest version problem us later version easiest fix partial log termin attempt uninstal ruamel yaml exist instal ruamel yaml uninstal ruamel yaml successfulli uninstal ruamel yaml run setup instal ruamel yaml error error command error exit statu log error log instal run http github com azur machinelearningnotebook file error log",
        "Issue_preprocessed_content":"pip fail spec oper window python version run packag question reason restrict specif version abl latest version problem us later version easiest fix partial log log log",
        "Issue_gpt_summary_original":"The user is encountering an AzureMLException while trying to download a registered model from the AMLS workspace. The file is being created in the target directory but with 0 bytes, indicating that no data is being transferred into it. The traceback shows a FileNotFoundError and an AzureMLException.",
        "Issue_gpt_summary":"user encount except try download regist model aml workspac file creat target directori byte indic data transfer traceback show filenotfounderror except",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1545",
        "Issue_title":"AzureMLException with model.download",
        "Issue_created_time":1625795312000,
        "Issue_closed_time":null,
        "Issue_body":"Hi!\r\n\r\nWhen trying to download a registered model from the AMLS workspace, I'm getting the following traceback. The file shows up in the `target_dir` (and ADLS path) however the size is 0 bytes, so it is making the file, however no data is being transferred into it.\r\n\r\n```python\r\n---------------------------------------------------------------------------\r\nFileNotFoundError                         Traceback (most recent call last)\r\n\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_file_utils\/file_utils.py in _retry(exec_func, clean_up_func, max_retries, exceptions)\r\n    432         try:\r\n--> 433             return exec_func()\r\n    434         except exceptions as request_exception:\r\n\r\n\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_file_utils\/file_utils.py in exec_func()\r\n    212                                                           max_connections=max_concurrency,\r\n--> 213                                                           validate_content=_validate_check_sum)\r\n    214             file_size = os.stat(path).st_size\r\n\r\n\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/baseblobservice.py in get_blob_to_path(self, container_name, blob_name, file_path, open_mode, snapshot, start_range, end_range, validate_content, progress_callback, max_connections, lease_id, if_modified_since, if_unmodified_since, if_match, if_none_match, timeout)\r\n   1855 \r\n-> 1856         with open(file_path, open_mode) as stream:\r\n   1857             blob = self.get_blob_to_stream(\r\n\r\nFileNotFoundError: [Errno 2] No such file or directory: '\/dbfs\/mnt\/prism0stg0dls\/amls\/enablers\/amls_model_saving\/models\/test2\/test2\/variables\/variables.data-00000-of-00001'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nAzureMLException                          Traceback (most recent call last)\r\n<command-3894832347418984> in <module>\r\n----> 1 existing_model.download(target_dir=\"\/dbfs\/mnt\/prism0stg0dls\/amls\/enablers\/amls_model_saving\/models\/test2\")\r\n\r\n\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/core\/model.py in download(self, target_dir, exist_ok, exists_ok)\r\n    999 \r\n   1000         # download files using sas\r\n-> 1001         file_paths = self._download_model_files(sas_to_relative_download_path, target_dir, exist_ok)\r\n   1002         if len(file_paths) == 0:\r\n   1003             raise WebserviceException(\"Illegal state. Unpack={}, Paths in target_dir is \"\r\n\r\n\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/core\/model.py in _download_model_files(self, sas_to_relative_download_path, target_dir, exist_ok)\r\n    940                                           \"{}\".format(target_path), logger=module_logger)\r\n    941             sas_to_relative_download_path[sas] = target_path\r\n--> 942             download_file(sas, target_path, stream=True)\r\n    943 \r\n    944         if self.unpack:\r\n\r\n\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_file_utils\/file_utils.py in download_file(source_uri, path, max_retries, stream, protocol, session, _validate_check_sum, max_concurrency)\r\n    219                                        'present in blob.'.format(file_size, content_length))\r\n    220 \r\n--> 221         return _retry(exec_func, max_retries=max_retries)\r\n    222 \r\n    223     # download using requests.Session\r\n\r\n\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_file_utils\/file_utils.py in _retry(exec_func, clean_up_func, max_retries, exceptions)\r\n    443             else:\r\n    444                 module_logger.error('Failed to download file with error: {}'.format(request_exception))\r\n--> 445                 raise AzureMLException('Download of file failed with error: {}'.format(request_exception))\r\n    446         finally:\r\n    447             clean_up_func()\r\n\r\nAzureMLException: AzureMLException:\r\n\tMessage: Download of file failed with error: [Errno 2] No such file or directory: '\/dbfs\/mnt\/prism0stg0dls\/amls\/enablers\/amls_model_saving\/models\/test2\/test2\/variables\/variables.data-00000-of-00001'\r\n\tInnerException None\r\n\tErrorResponse \r\n{\r\n    \"error\": {\r\n        \"message\": \"Download of file failed with error: [Errno 2] No such file or directory: '\/dbfs\/mnt\/prism0stg0dls\/amls\/enablers\/amls_model_saving\/models\/test2\/test2\/variables\/variables.data-00000-of-00001'\"\r\n    }\r\n}\r\n\r\n```\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/7530947\/125011096-a8c32700-e01c-11eb-83b4-4305be4095df.png)\r\n",
        "Issue_answer_count":0,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"except model download try download regist model aml workspac get follow traceback file show target dir adl path size byte make file data transfer python filenotfounderror traceback recent databrick python lib python site packag file util file util retri exec func clean func max retri except try return exec func except request except databrick python lib python site packag file util file util exec func max connect max concurr valid content valid check sum file size stat path size databrick python lib python site packag vendor azur storag blob baseblobservic blob path self contain blob file path open mode snapshot start rang end rang valid content progress callback max connect leas modifi unmodifi match match timeout open file path open mode stream blob self blob stream filenotfounderror errno file directori dbf mnt prismstgdl aml enabl aml model save model test test variabl variabl data handl except except occur except traceback recent exist model download target dir dbf mnt prismstgdl aml enabl aml model save model test databrick python lib python site packag core model download self target dir exist exist download file sa file path self download model file sa rel download path target dir exist len file path rais webserviceexcept illeg state unpack path target dir databrick python lib python site packag core model download model file self sa rel download path target dir exist format target path logger modul logger sa rel download path sa target path download file sa target path stream true self unpack databrick python lib python site packag file util file util download file sourc uri path max retri stream protocol session valid check sum max concurr present blob format file size content length return retri exec func max retri max retri download request session databrick python lib python site packag file util file util retri exec func clean func max retri except modul logger error fail download file error format request except rais except download file fail error format request except final clean func except except messag download file fail error errno file directori dbf mnt prismstgdl aml enabl aml model save model test test variabl variabl data innerexcept errorrespons error messag download file fail error errno file directori dbf mnt prismstgdl aml enabl aml model save model test test variabl variabl data imag http user imag githubusercont com bedf png",
        "Issue_preprocessed_content":"except try download regist model aml workspac traceback file show size byte make file data",
        "Issue_gpt_summary_original":"The user encountered a bug while loading `azureml_run_type_providers` in a fresh conda environment. The error occurred due to a failure to load entrypoint `azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto` with an exception `docker 5.0.0 (c:\\dev\\miniconda\\envs\\xxx\\lib\\site-packages), Requirement.parse('docker<5.0.0'), {'azureml-core'}`. The issue was resolved by specifying `docker<5.0.0` in the dependencies.",
        "Issue_gpt_summary":"user encount bug load run type provid fresh conda environ error occur failur load entrypoint pipelinerun pipelin core run pipelinerun dto except docker dev miniconda env xxx lib site packag requir pars docker core issu resolv specifi docker depend",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1537",
        "Issue_title":"Bug: Failure while loading azureml_run_type_providers",
        "Issue_created_time":1625218579000,
        "Issue_closed_time":1630367426000,
        "Issue_body":"In a fresh conda environment, I get several warnings that halt the script execution:\r\n```\r\n...\r\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (docker 5.0.0 (c:\\dev\\miniconda\\envs\\xxx\\lib\\site-packages), Requirement.parse('docker<5.0.0'), {'azureml-core'}).\r\n...\r\n```\r\n\r\nMy environment is specified by:\r\n```yaml\r\nname: xxx\r\nchannels:\r\n  - anaconda\r\n  - pytorch-lts\r\ndependencies:\r\n  - python=3.6\r\n  - pandas=1.1.3\r\n  - numpy=1.19.2\r\n  - scikit-learn=0.23.2\r\n  - matplotlib\r\n  - mkl=2020.2\r\n  - pytorch=1.8.1\r\n  - cpuonly=1.0\r\n  - pip\r\n  - pip:\r\n      - azureml-sdk==1.31.0\r\n      - azureml-defaults==1.31.0\r\n      - azure-storage-blob==12.8.1\r\n      - mlflow==1.18.0\r\n      - azureml-mlflow==1.31.0\r\n      - pytorch-lightning==1.3.8\r\n      - onnxruntime==1.8.0\r\n      - docker<5.0.0 # this is the fix needed\r\n```\r\nThe fix is to specify `docker<5.0.0`. Perhaps, there are some wrong deps checks somewhere.\r\n\r\n---\r\n#### Document Details\r\n\r\n\u26a0 *Do not edit this section. It is required for docs.microsoft.com \u279f GitHub issue linking.*\r\n\r\n* ID: eb938463-51c2-43f3-d528-76a07a28bec8\r\n* Version Independent ID: e15753c0-6fe1-100a-0efc-08c1f845dc83\r\n* Content: [Azure Machine Learning SDK for Python - Azure Machine Learning Python](https:\/\/docs.microsoft.com\/en-us\/python\/api\/overview\/azure\/ml\/?view=azure-ml-py)\r\n* Content Source: [AzureML-Docset\/docs-ref-conceptual\/index.md](https:\/\/github.com\/MicrosoftDocs\/MachineLearning-Python-pr\/blob\/live\/AzureML-Docset\/docs-ref-conceptual\/index.md)\r\n* Service: **machine-learning**\r\n* Sub-service: **core**\r\n* GitHub Login: @trevorbye\r\n* Microsoft Alias: **trbye**",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"Thanks for the report! azureml-sdk==1.13.0 does specify docker<5.0.0, while mlflow==1.18.0 requires 5.0.0. \r\n\r\nI'm going to close this issue as there is no action for azureml-sdk.",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"bug failur load run type provid fresh conda environ warn halt script execut failur load run type provid fail load entrypoint pipelinerun pipelin core run pipelinerun dto except docker dev miniconda env xxx lib site packag requir pars docker core environ specifi yaml xxx channel anaconda pytorch lt depend python panda numpi scikit learn matplotlib mkl pytorch cpuonli pip pip sdk default azur storag blob pytorch lightn onnxruntim docker fix need fix specifi docker wrong dep check document detail edit section requir doc microsoft com github issu link aabec version independ efc cfdc content sdk python python http doc microsoft com python api overview azur view azur content sourc docset doc ref conceptu index http github com microsoftdoc machinelearn python blob live docset doc ref conceptu index servic machin learn sub servic core github login trevorby microsoft alia trbye",
        "Issue_preprocessed_content":"bug failur load fresh conda environ warn halt script execut environ specifi fix specifi wrong dep check document detail edit section requir github version independ content content sourc servic core github login microsoft alia trbye",
        "Issue_gpt_summary_original":"The user has encountered a broken link in the AML doc to `azureml.core.runconfig.MpiConfiguration`.",
        "Issue_gpt_summary":"user encount broken link aml doc core runconfig mpiconfigur",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1534",
        "Issue_title":"Broken link in AML doc to azureml.core.runconfig.MpiConfiguration",
        "Issue_created_time":1624997173000,
        "Issue_closed_time":1626388206000,
        "Issue_body":"\r\n<img width=\"1430\" alt=\"image\" src=\"https:\/\/user-images.githubusercontent.com\/5203025\/123860354-63399680-d958-11eb-9dc8-dc0a52d67cc2.png\">\r\n\r\n---\r\n#### Document Details\r\n\r\n\u26a0 *Do not edit this section. It is required for docs.microsoft.com \u279f GitHub issue linking.*\r\n\r\n* ID: 109d9284-e234-5086-5da6-4155291361c8\r\n* Version Independent ID: 57cc0c7a-faa7-1a86-ee14-b9cf99fb540d\r\n* Content: [azureml.core.ScriptRunConfig class - Azure Machine Learning Python](https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.scriptrunconfig?view=azure-ml-py)\r\n* Content Source: [AzureML-Docset\/stable\/docs-ref-autogen\/azureml-core\/azureml.core.ScriptRunConfig.yml](https:\/\/github.com\/MicrosoftDocs\/MachineLearning-Python-pr\/blob\/live\/AzureML-Docset\/stable\/docs-ref-autogen\/azureml-core\/azureml.core.ScriptRunConfig.yml)\r\n* Service: **machine-learning**\r\n* Sub-service: **core**\r\n* GitHub Login: @DebFro\r\n* Microsoft Alias: **debfro**",
        "Issue_answer_count":2,
        "Issue_self_closed":0.0,
        "Answer_body":"Thanks for submitting the issue. I am fixing this broken link now.  The links should be fixed on next SDK release on Aug 3rd",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"broken link aml doc core runconfig mpiconfigur document detail edit section requir doc microsoft com github issu link version independ ccca faa bcffbd content core scriptrunconfig class python http doc microsoft com python api core core scriptrunconfig view azur content sourc docset stabl doc ref autogen core core scriptrunconfig yml http github com microsoftdoc machinelearn python blob live docset stabl doc ref autogen core core scriptrunconfig yml servic machin learn sub servic core github login debfro microsoft alia debfro",
        "Issue_preprocessed_content":"broken link aml doc img width alt imag document detail edit section requir github version independ content content sourc servic core github login microsoft alia debfro",
        "Issue_gpt_summary_original":"The user has encountered an exception while importing azureml.core after installing azure ml using a conda environment yml. The error message indicates a failure while loading azureml_run_type_providers due to a cryptography version issue. The user is seeking help to resolve the issue.",
        "Issue_gpt_summary":"user encount except import core instal conda environ yml error messag indic failur load run type provid cryptographi version issu user seek help resolv issu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1523",
        "Issue_title":"Warning while loading the azureml.core",
        "Issue_created_time":1624519136000,
        "Issue_closed_time":1626388114000,
        "Issue_body":"Hi,\r\n\r\nI have installed the azure ml using below environment yml, installation happened without any issues but when I import the azureml.core I am getting exception.\r\n\r\n**conda environment yml**\r\n```\r\nname: ati_reranking_automl_py36\r\ndependencies:\r\n  # The python interpreter version.\r\n  # Currently Azure ML only supports 3.5.2 and later.\r\n- pip==20.2.4\r\n- python==3.6.13\r\n- nb_conda\r\n- matplotlib==2.1.0\r\n- numpy==1.18.5\r\n- seaborn==0.9.0\r\n- urllib3<1.24\r\n- scipy>=1.4.1,<=1.5.2\r\n- scikit-learn==0.22.1\r\n- pandas==0.25.1\r\n- py-xgboost<=1.3.3\r\n- jupyterlab==1.0.2\r\n- ipykernel==5.3.4\r\n- pytorch::pytorch=1.4.0\r\n\r\n- pip:\r\n  # Base AzureML SDK\r\n  - azureml-sdk\r\n      \r\n  - pytorch-transformers==1.0.0\r\n\r\n  # Scoring deps\r\n  - inference-schema[numpy-support]\r\n```\r\n\r\n\r\n**Exception**\r\nimport azureml.core\r\n`Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (cryptography 2.3.1 (c:\\miniconda\\envs\\ati_reranking_automl_py36\\lib\\site-packages), Requirement.parse('cryptography<4.0.0,>=3.3.1; extra == \"crypto\"'), {'PyJWT'}).`\r\n\r\nAzure ML SDK Version:  1.31.0\r\n\r\n\r\nPlease help.\r\nThanks",
        "Issue_answer_count":2,
        "Issue_self_closed":0.0,
        "Answer_body":"Can you try installing [azureml-core](https:\/\/pypi.org\/project\/azureml-core\/) instead? This is unfortunately a package conflict issue. I was able to create the conda environment by removing all the version pinning on `matplotlib`, `numpy`, ... all the way to `pytorch`, and changed `azureml-sdk` to `azureml-core`.  \r\n\r\n```yml\r\nname: ati_reranking_automl_py36\r\ndependencies:\r\n  # The python interpreter version.\r\n  # Currently Azure ML only supports 3.5.2 and later.\r\n- pip==20.2.4\r\n- python==3.6.13\r\n- nb_conda\r\n- matplotlib\r\n- numpy\r\n- seaborn\r\n- urllib3\r\n- scipy\r\n- scikit-learn\r\n- pandas\r\n- py-xgboost\r\n- jupyterlab\r\n- ipykernel\r\n- pytorch\r\n\r\n- pip:\r\n  # Base AzureML SDK\r\n  - azureml-core\r\n\r\n  - pytorch-transformers==1.0.0\r\n\r\n  # Scoring deps\r\n  - inference-schema[numpy-support]                               \r\n```\r\n\r\n```bash\r\n(base) \u279c  jiazho_playground \u2717 conda activate ati_reranking_automl_py36\r\n(ati_reranking_automl_py36) \u279c  jiazho_playground git:(split-merge) \u2717 python\r\nPython 3.6.13 |Anaconda, Inc.| (default, Jun  4 2021, 14:25:59)\r\n[GCC 7.5.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import azureml.core\r\n>>>\r\n\r\n\r\n(ati_reranking_automl_py36) \u279c  jiazho_playground \u2717 pip freeze | grep azureml.core\r\nazureml-core==1.32.0\r\n```\r\n",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"warn load core instal environ yml instal happen issu import core get except conda environ yml ati rerank automl depend python interpret version current support later pip python conda matplotlib numpi seaborn urllib extra crypto pyjwt sdk version help thank",
        "Issue_preprocessed_content":"warn load core environ yml import core except conda environ yml except import core sdk version help thank",
        "Issue_gpt_summary_original":"The user is encountering an error while running a pipeline example in AzureML, which is yielding the warning \"Expected a StepRun object but received <class 'azureml.core.run.Run'> instead.\" The user is also getting the same warning in other pipelines and is unable to identify the cause of the issue. The user has provided a slightly reduced MWE for clarity.",
        "Issue_gpt_summary":"user encount error run pipelin exampl yield warn expect steprun object receiv instead user get warn pipelin unabl identifi caus issu user provid slightli reduc mwe clariti",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1517",
        "Issue_title":"AzureML Pipelines: Expected a StepRun object but received <class 'azureml.core.run.Run'> instead.",
        "Issue_created_time":1624292044000,
        "Issue_closed_time":1626719342000,
        "Issue_body":"I am running a lightly edited version of this pipeline example: https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/8f7717014b7e9b431c11857956982f0f718eb362\/how-to-use-azureml\/machine-learning-pipelines\/nyc-taxi-data-regression-model-building\/nyc-taxi-data-regression-model-building.ipynb\r\n\r\nand it is yielding me this error (or warning): `Expected a StepRun object but received <class 'azureml.core.run.Run'> instead.`\r\n\r\nI am also getting this same warning in other pipelines I make and I cannot figure out what is causing it.\r\n\r\nHere is a slightly reduced MWE for (hopefully) clarity:\r\n\r\n\r\n```\r\nfrom azureml.core import Workspace, Datastore, Dataset, Experiment\r\nfrom azureml.core.authentication import ServicePrincipalAuthentication\r\nfrom azureml.core.runconfig import RunConfiguration, DEFAULT_CPU_IMAGE\r\nfrom azureml.core.conda_dependencies import CondaDependencies\r\nfrom azureml.core.compute import ComputeTarget, AmlCompute\r\nfrom azureml.core.compute_target import ComputeTargetException\r\nfrom azureml.data import OutputFileDatasetConfig\r\nfrom azureml.pipeline.steps import PythonScriptStep\r\nfrom azureml.pipeline.core import Pipeline\r\n\r\nimport os\r\n\r\n# environment data\r\nfrom dotenv import load_dotenv  # pip install python-dotenv\r\nload_dotenv('.env') # load .env file with sp info\r\n```\r\n\r\n\r\n```\r\n# instantiate the service principal\r\nsp = ServicePrincipalAuthentication(tenant_id=os.environ['AML_TENANT_ID'],\r\n                                    service_principal_id=os.environ['AML_PRINCIPAL_ID'],\r\n                                    service_principal_password=os.environ['AML_PRINCIPAL_PASS'])\r\n```\r\n\r\n\r\n\r\n```\r\n# instantiate a workspace\r\nws = Workspace(subscription_id = \"redacted\",\r\n               resource_group = \"redacted\",\r\n               auth=sp,  # use service principal auth\r\n               workspace_name = \"redacted\")\r\n\r\nprint(\"Found workspace {} at location {}\".format(ws.name, ws.location))\r\n```\r\n\r\n\r\n```\r\n# pipeline step 1\r\nstep1 = PythonScriptStep(\r\n    name=\"generate_data\",\r\n    script_name=\"scripts\/mwe.py\",\r\n    arguments=[\"--save\", 'hello world'],\r\n    runconfig=RunConfiguration(),\r\n    compute_target='retry2',\r\n    allow_reuse=True\r\n)\r\n```\r\n\r\n```\r\n%%writefile scripts\/mwe.py\r\n\r\n# load packages\r\nimport os\r\nfrom azureml.core import Run\r\nimport argparse\r\nimport pandas as pd\r\n\r\nprint('hello world')\r\n```\r\n\r\n\r\n```\r\n# build the pipeline\r\npipeline1 = Pipeline(workspace=ws, steps=[step1])\r\n# validate the pipeline\r\npipeline1.validate()\r\n# submit a pipeline run\r\npipeline_run1 = Experiment(ws, 'mwe').submit(pipeline1)\r\n# run and wait for completion to check its results\r\npipeline_run1.wait_for_completion(show_output=True)\r\n\r\n```\r\n\r\n\r\n\r\n```\r\nExpected a StepRun object but received <class 'azureml.core.run.Run'> instead.\r\nThis usually indicates a package conflict with one of the dependencies of azureml-core or azureml-pipeline-core.\r\nPlease check for package conflicts in your python environment\r\n```\r\n",
        "Issue_answer_count":7,
        "Issue_self_closed":0.0,
        "Answer_body":"@afogarty85 can you share the version of SDK you are using? ```\r\nimport azureml\r\nprint(azureml.core.__version__)\r\n1.31.0\r\n``` @afogarty85, I'm unable to reproduce the error you are seeing. Is the pipeline running despite the error\/warning? It is running\/working anyways and indeed -- on a different workspace, I too cannot reproduce it. I am not sure why it is a symptom of the one I am on. I am opening a bug for investigation and will update you when I have a response.  I am also running into this issue with code that was working previously. Had a weekly pipeline scheduled to run at the start of every Monday. It usually took around a couple of minutes  to finish but looking back at some logs it seems like after June 13  runs were taking 100+ hours and most timed out. I tried to manually run the pipeline and hit the exact same issue with Expecting StepRun object, not sure if there was some sort of update around the middle of June to the SDK?\r\n\r\n\r\n***EDIT Had to update the Azure ML SDK along with the azureml-automl-core, azureml-pipeline-core, and azureml-pipeline packages*** I'm sharing the investigation from engineering below. Since this is expected behavior, we will not be fixing it. Hope this helps. \r\n\r\nThis bug is activated if the user has a package version conflict in their local python environment, the PipelineRun.wait_for_completion() method may fail with an error 'Unexpected keyword argument timeout_seconds'. This is because the run rehydration fails and we receive a run object with the wrong type, which doesn't have this argument.",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"pipelin expect steprun object receiv instead run lightli edit version pipelin exampl http github com azur machinelearningnotebook blob fbebcffeb us machin learn pipelin nyc taxi data regress model build nyc taxi data regress model build ipynb yield error warn expect steprun object receiv instead get warn pipelin figur caus slightli reduc mwe hopefulli clariti core import workspac datastor dataset experi core authent import serviceprincipalauthent core runconfig import runconfigur default cpu imag core conda depend import condadepend core comput import computetarget amlcomput core comput target import computetargetexcept data import outputfiledatasetconfig pipelin step import pythonscriptstep pipelin core import pipelin import environ data dotenv import load dotenv pip instal python dotenv load dotenv env load env file info instanti servic princip serviceprincipalauthent tenant environ aml tenant servic princip environ aml princip servic princip password environ aml princip pass instanti workspac workspac subscript redact resourc group redact auth us servic princip auth workspac redact print workspac locat format locat pipelin step step pythonscriptstep gener data script script mwe argument save hello world runconfig runconfigur comput target retri allow reus true writefil script mwe load packag import core import run import argpars import panda print hello world build pipelin pipelin pipelin workspac step step valid pipelin pipelin valid submit pipelin run pipelin run experi mwe submit pipelin run wait complet check result pipelin run wait complet output true expect steprun object receiv instead usual indic packag conflict depend core pipelin core check packag conflict python environ",
        "Issue_preprocessed_content":"pipelin expect steprun object receiv instead lightli edit version pipelin exampl yield warn pipelin figur caus slightli reduc mwe clariti",
        "Issue_gpt_summary_original":"The user is trying to deploy an ML model using the az ml model deploy command with additional files, but encounters an error stating that the Dockerfile instruction COPY is not allowed. The error message suggests that only certain instructions such as ARG, ENV, EXPOSE, LABEL, and RUN are allowed.",
        "Issue_gpt_summary":"user try deploi model model deploi command addit file encount error state dockerfil instruct copi allow error messag suggest certain instruct arg env expos label run allow",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1509",
        "Issue_title":"How to copy files into  docker image while deploying ml model using azure ml model deploy command",
        "Issue_created_time":1623592472000,
        "Issue_closed_time":1626798489000,
        "Issue_body":"I am trying to deploy ml model using az ml model deploy command with additional files.\r\n\r\nEg:-\r\n\r\naz ml model deploy --ds  docker-additional-steps.txt \r\n```\r\ndocker-additional-steps.txt\r\n\r\nCOPY *.txt \/var\/azureml-app\/\r\n```\r\n\r\nbut it gives an error as below\r\n```\r\nFailed\r\nERROR: {'Azure-cli-ml Version': '1.29.0', 'Error': WebserviceException:\r\n\tMessage: Image creation polling reached non-successful terminal state, current state: Failed\r\nError response from server:\r\nStatusCode: 400\r\nMessage: Failed to parse steps: COPY is not an allowed Dockerfile instruction. Allowed instructions: ARG, ENV, EXPOSE, LABEL, RUN\r\n\tInnerException None\r\n\tErrorResponse \r\n{\r\n    \"error\": {\r\n        \"message\": \"Image creation polling reached non-successful terminal state, current state: Failed\\nError response from server:\\nStatusCode: 400\\nMessage: Failed to parse steps: COPY is not an allowed Dockerfile instruction. Allowed instructions: ARG, ENV, EXPOSE, LABEL, RUN\"\r\n    }\r\n}}\r\n\r\n```",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"Extra docker steps is no longer supported. Please create an environment instead where you can inject files as you wish and use that environment for deployment. Here is a sample.\r\n\r\nhttps:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/deployment\/deploy-to-cloud\/model-register-and-deploy.ipynb\r\n",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"copi file docker imag deploi model model deploi command try deploi model model deploi command addit file model deploi docker addit step txt docker addit step txt copi txt var app give error fail error azur cli version error webserviceexcept messag imag creation poll reach non success termin state current state fail error respons server statuscod messag fail pars step copi allow dockerfil instruct allow instruct arg env expos label run innerexcept errorrespons error messag imag creation poll reach non success termin state current state fail nerror respons server nstatuscod nmessag fail pars step copi allow dockerfil instruct allow instruct arg env expos label run",
        "Issue_preprocessed_content":"copi file docker imag deploi model model deploi try deploi model model deploi file model deploi give",
        "Issue_gpt_summary_original":"The user is encountering a 'ClientRequestError' when trying to use Azure Computer Vision's OCR API in an Azure Machine Learning Notebook. The error occurs when trying to call the Computer Vision API from the notebook, but the same code works when run on a local machine. The error message suggests that there is a temporary failure in name resolution. The user has provided the code used and the Azure packages used, and suspects that the issue may be related to a previous issue (#1107).",
        "Issue_gpt_summary":"user encount clientrequesterror try us azur vision ocr api notebook error occur try vision api notebook code work run local machin error messag suggest temporari failur resolut user provid code azur packag suspect issu relat previou issu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1501",
        "Issue_title":"'ClientRequestError' when trying to use Azure Computer Vision API from Azure Machine Learning Notebook",
        "Issue_created_time":1622675126000,
        "Issue_closed_time":1631108652000,
        "Issue_body":"I'm trying to use Azure Computer Vision's OCR API in an Azure Machine Learning Notebook. However there seems to be an error when trying to call the Computer Vision API from an Azure Machine Learning Notebook. The same code works when I'm running it on a local machine.\r\nI'm following Azure Computer Vision's OCR Quickstart: https:\/\/docs.microsoft.com\/en-us\/azure\/cognitive-services\/computer-vision\/quickstarts-sdk\/client-library?tabs=visual-studio&pivots=programming-language-python\r\n\r\nWhen running the following code, `computervision_client.read(read_image_url, raw=True)` does not return but throws an exception.\r\nException:\r\n`ClientRequestError: Error occurred in request., ConnectionError: HTTPSConnectionPool(host='some-host.cognitiveservices.azure.com', port=443): Max retries exceeded with url: \/vision\/v3.2\/read\/analyze?model-version=latest&readingOrder=basic (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f59e0102820>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))`\r\n\r\nCode:\r\n```python\r\nfrom azure.cognitiveservices.vision.computervision import ComputerVisionClient\r\nfrom azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\r\nfrom azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\r\nfrom msrest.authentication import CognitiveServicesCredentials\r\n\r\nfrom array import array\r\nimport os\r\nfrom PIL import Image\r\nimport sys\r\nimport time\r\n\r\n'''\r\nAuthenticate\r\nAuthenticates your credentials and creates a client.\r\n'''\r\nsubscription_key = os.environ[\"COMPUTERVISION_KEY\"]\r\nendpoint = os.environ[\"COMPUTERVISION_URL\"]\r\n\r\ncomputervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))\r\n\r\n'''\r\nOCR: Read File using the Read API, extract text - remote\r\nThis example will extract text in an image, then print results, line by line.\r\nThis API call can also extract handwriting style text (not shown).\r\n'''\r\nprint(\"===== Read File - remote =====\")\r\n# Get an image with text\r\nread_image_url = \"https:\/\/raw.githubusercontent.com\/MicrosoftDocs\/azure-docs\/master\/articles\/cognitive-services\/Computer-vision\/Images\/readsample.jpg\"\r\n\r\n# Call API with URL and raw response (allows you to get the operation location)\r\nread_response = computervision_client.read(read_image_url,  raw=True) # <- THROWS EXCEPTION\r\n```\r\n\r\nUsed azure packages:\r\n```\r\nazure-ai-textanalytics                        5.1.0b7\r\nazure-cognitiveservices-vision-computervision 0.9.0\r\nazure-common                                  1.1.27\r\nazure-core                                    1.14.0\r\nazure-cosmos                                  4.2.0\r\nazure-graphrbac                               0.61.1\r\nazure-identity                                1.4.1\r\nazure-mgmt-authorization                      0.61.0\r\nazure-mgmt-containerregistry                  8.0.0\r\nazure-mgmt-core                               1.2.2\r\nazure-mgmt-keyvault                           2.2.0\r\nazure-mgmt-resource                           13.0.0\r\nazure-mgmt-storage                            11.2.0\r\nazure-storage-blob                            12.8.0\r\nazureml-automl-core                           1.29.0\r\nazureml-contrib-dataset                       1.29.0\r\nazureml-core                                  1.29.0.post1\r\nazureml-dataprep                              2.15.1\r\nazureml-dataprep-native                       33.0.0\r\nazureml-dataprep-rslex                        1.13.0\r\nazureml-dataset-runtime                       1.29.0\r\nazureml-pipeline-core                         1.29.0\r\nazureml-pipeline-steps                        1.29.0\r\nazureml-telemetry                             1.29.0\r\nazureml-train-automl-client                   1.29.0\r\nazureml-train-core                            1.29.0\r\nazureml-train-restclients-hyperdrive          1.29.0\r\nazureml-widgets                               1.29.0.post1\r\n```\r\n\r\nMaybe related to #1107",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"After a long while I've tried the exact same script in the same compute instance again. I don't experience the connection error anymore so I will close this ticket. I don't know what changed.",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"clientrequesterror try us azur vision api notebook try us azur vision ocr api notebook error try vision api notebook code work run local machin follow azur vision ocr quickstart http doc microsoft com azur cognit servic vision quickstart sdk client librari tab visual studio pivot program languag python run follow code computervis client read read imag url raw true return throw except except clientrequesterror error occur request connectionerror httpsconnectionpool host host cognitiveservic azur com port max retri exceed url vision read analyz model version latest readingord basic caus newconnectionerror fail establish new connect errno temporari failur resolut code python azur cognitiveservic vision computervis import computervisioncli azur cognitiveservic vision computervis model import operationstatuscod azur cognitiveservic vision computervis model import visualfeaturetyp msrest authent import cognitiveservicescredenti arrai import arrai import pil import imag import sy import time authent authent credenti creat client subscript kei environ computervis kei endpoint environ computervis url computervis client computervisioncli endpoint cognitiveservicescredenti subscript kei ocr read file read api extract text remot exampl extract text imag print result line line api extract handwrit style text shown print read file remot imag text read imag url http raw githubusercont com microsoftdoc azur doc master articl cognit servic vision imag readsampl jpg api url raw respons allow oper locat read respons computervis client read read imag url raw true throw except azur packag azur textanalyt azur cognitiveservic vision computervis azur common azur core azur cosmo azur graphrbac azur ident azur mgmt author azur mgmt containerregistri azur mgmt core azur mgmt keyvault azur mgmt resourc azur mgmt storag azur storag blob automl core contrib dataset core post dataprep dataprep nativ dataprep rslex dataset runtim pipelin core pipelin step telemetri train automl client train core train restclient hyperdr widget post mayb relat",
        "Issue_preprocessed_content":"try us azur vision api try us azur vision ocr api try vision api code work local machin azur vision ocr quickstart code return throw except except code azur packag mayb relat",
        "Issue_gpt_summary_original":"The user encountered an error message \"Environment name can not start with the prefix AzureML\" while running an experiment. They are following a GitHub tutorial and are unsure how to set the name of the environment. The user provided code snippets and references for context.",
        "Issue_gpt_summary":"user encount error messag environ start prefix run experi follow github tutori unsur set environ user provid code snippet refer context",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1468",
        "Issue_title":"AutoMLPipelineBuilder.get_many_models_train_steps - Error \"Environment name can not start with the prefix AzureML...\"",
        "Issue_created_time":1620766573000,
        "Issue_closed_time":1622654301000,
        "Issue_body":"Hello,\r\n\r\nWhen running the experiment, the error message **Environment name can not start with the prefix AzureML** was displayed. How can I set the name of the environment? I'm following the GitHub tutorial and haven't found anything about it.\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/29444086\/117882725-01767d80-b281-11eb-8df5-36d8683523e7.png)\r\n\r\nCode used:\r\n\r\n- Registering Dataset\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/29444086\/117883192-81044c80-b281-11eb-9dec-d73431948061.png)\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/29444086\/117883230-8c577800-b281-11eb-8445-060839369fe5.png)\r\n\r\n- Training Pipeline\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/29444086\/117883313-a5602900-b281-11eb-818d-3972111d7f9c.png)\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/29444086\/117883356-b315ae80-b281-11eb-99d9-1ac6c0989186.png)\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/29444086\/117883429-c7f24200-b281-11eb-88de-3979570adb55.png)\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/29444086\/117883465-d2144080-b281-11eb-8b9c-f74756bedd01.png)\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/29444086\/117883535-e48e7a00-b281-11eb-9d31-e035f44a0871.png)\r\n\r\nReferences:\r\n\r\n- https:\/\/github.com\/microsoft\/solution-accelerator-many-models\/tree\/master\/Automated_ML\/02_AutoML_Training_Pipeline\r\n- https:\/\/github.com\/MicrosoftDocs\/azure-docs\/issues\/65770\r\n\r\nBest regards,\r\nCristina\r\n\r\n\r\n---\r\n#### Detalhes do documento\r\n\r\n\u26a0 *N\u00e3o edite esta se\u00e7\u00e3o. \u00c9 necess\u00e1rio para a vincula\u00e7\u00e3o do problema do docs.microsoft.com \u279f GitHub.*\r\n\r\n* ID: 49399a7d-d4e8-370e-ce62-d60a6b64e412\r\n* Version Independent ID: 782d8ba4-75dd-27c3-5a46-a921c3ead4bf\r\n* Content: [azureml.contrib.automl.pipeline.steps.AutoMLPipelineBuilder class - Azure Machine Learning Python](https:\/\/docs.microsoft.com\/pt-br\/python\/api\/azureml-contrib-automl-pipeline-steps\/azureml.contrib.automl.pipeline.steps.automlpipelinebuilder?view=azure-ml-py)\r\n* Content Source: [AzureML-Docset\/stable\/docs-ref-autogen\/azureml-contrib-automl-pipeline-steps\/azureml.contrib.automl.pipeline.steps.AutoMLPipelineBuilder.yml](https:\/\/github.com\/MicrosoftDocs\/MachineLearning-Python-pr.pt-BR\/blob\/live\/AzureML-Docset\/stable\/docs-ref-autogen\/azureml-contrib-automl-pipeline-steps\/azureml.contrib.automl.pipeline.steps.AutoMLPipelineBuilder.yml)\r\n* Service: **machine-learning**\r\n* Sub-service: **core**\r\n* GitHub Login: @DebFro\r\n* Microsoft Alias: **debfro**",
        "Issue_answer_count":10,
        "Issue_self_closed":0.0,
        "Answer_body":"Hi,\r\n\r\nI have some updates:\r\n\r\n- I put the code below to set the environment.\r\n\r\nfrom azureml.core.environment import Environment\r\n\r\nenv = Environment.get(workspace=ws, name=\"AzureML-Tutorial\")\r\nmyenv = env.clone(\"automl_env\")\r\n\r\ntrain_steps = AutoMLPipelineBuilder.get_many_models_train_steps(experiment=experiment,\r\n                                                                automl_settings=automl_settings,\r\n                                                                train_data=dataset_input,\r\n                                                                compute_target=compute_target,\r\n                                                                partition_column_names=partition_column_names,\r\n                                                                node_count=1,\r\n                                                                process_count_per_node=2,\r\n                                                                run_invocation_timeout=3700,\r\n                                                                train_env=myenv)\r\n\r\n- The environment problem has been resolved, but now the process displays the message **ValueError: None is not in list**. I don't know what this means.\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/29444086\/118014360-82894f80-b329-11eb-8e6a-558d6606d7b1.png)\r\n\r\nFailure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (pyarrow 3.0.0 (\/azureml-envs\/azureml_f3e17a31e8bb78187505ee1343fa990d\/lib\/python3.6\/site-packages), Requirement.parse('pyarrow<2.0.0,>=0.17.0'), {'azureml-dataset-runtime'}).\r\nTraceback (most recent call last):\r\n  File \"\/azureml-envs\/azureml_f3e17a31e8bb78187505ee1343fa990d\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/runtime\/_many_models\/train_model.py\", line 212, in <module>\r\n    logs = run(data_file_path, args, automl_settings, current_step_run)\r\n  File \"\/azureml-envs\/azureml_f3e17a31e8bb78187505ee1343fa990d\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/runtime\/_many_models\/train_model.py\", line 100, in run\r\n    data = pd.read_csv(file_path, parse_dates=[timestamp_column])\r\n  File \"\/azureml-envs\/azureml_f3e17a31e8bb78187505ee1343fa990d\/lib\/python3.6\/site-packages\/pandas\/io\/parsers.py\", line 676, in parser_f\r\n    return _read(filepath_or_buffer, kwds)\r\n  File \"\/azureml-envs\/azureml_f3e17a31e8bb78187505ee1343fa990d\/lib\/python3.6\/site-packages\/pandas\/io\/parsers.py\", line 448, in _read\r\n    parser = TextFileReader(fp_or_buf, **kwds)\r\n  File \"\/azureml-envs\/azureml_f3e17a31e8bb78187505ee1343fa990d\/lib\/python3.6\/site-packages\/pandas\/io\/parsers.py\", line 880, in __init__\r\n    self._make_engine(self.engine)\r\n  File \"\/azureml-envs\/azureml_f3e17a31e8bb78187505ee1343fa990d\/lib\/python3.6\/site-packages\/pandas\/io\/parsers.py\", line 1114, in _make_engine\r\n    self._engine = CParserWrapper(self.f, **self.options)\r\n  File \"\/azureml-envs\/azureml_f3e17a31e8bb78187505ee1343fa990d\/lib\/python3.6\/site-packages\/pandas\/io\/parsers.py\", line 1949, in __init__\r\n    self._set_noconvert_columns()\r\n  File \"\/azureml-envs\/azureml_f3e17a31e8bb78187505ee1343fa990d\/lib\/python3.6\/site-packages\/pandas\/io\/parsers.py\", line 2015, in _set_noconvert_columns\r\n    _set(val)\r\n  File \"\/azureml-envs\/azureml_f3e17a31e8bb78187505ee1343fa990d\/lib\/python3.6\/site-packages\/pandas\/io\/parsers.py\", line 2005, in _set\r\n    x = names.index(x)\r\nValueError: None is not in list\r\n\r\nBest regards,\r\nCristina @crisansou is there any error surfaced in 70_driver_log? \r\nHi @shbijlan ,\r\n\r\nI deleted the workspace. I tried to reproduce the steps again but I couldn't even create the experiment, below is the error message. Can you tell which is the recommended version to use this solution?\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/29444086\/119876912-c752e000-befe-11eb-9a18-c8f03afae48c.png)\r\n\r\nI don't know if it's related, but I realized that now compute instance is using version 1.29.\r\n\r\n!pip install --upgrade azureml-sdk[automl]\r\n!pip install azureml-contrib-automl-pipeline-steps\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/29444086\/119877097-03864080-beff-11eb-8134-07d22a243284.png)\r\n\r\n\r\n\r\n\r\n> @crisansou is there any error surfaced in 70_driver_log?\r\n\r\n from azureml.core. import Environment\r\ntrain_env = Environment.get(workspace = ws, name = 'AzureML-AutoML')\r\n\r\nCan you please pass train_env like above for the workaround? There is a bug in our code that needs to be fixed. we will fix it in our next release.\r\n\r\nAlso this solution only supports 'forecasting' and needs a time_column_name passed in automl settings Hi @deeptim123 ,\r\n\r\nThanks for the instructions! After including the environment I was able to run the cell, but the pipeline ended with an error because I am using a regression model.\r\n\r\nIn the next release, in addition to fixing the bug, will it be possible to use regression?\r\n\r\n> from azureml.core. import Environment\r\n> train_env = Environment.get(workspace = ws, name = 'AzureML-AutoML')\r\n> \r\n> Can you please pass train_env like above for the workaround? There is a bug in our code that needs to be fixed. we will fix it in our next release.\r\n> \r\n> Also this solution only supports 'forecasting' and needs a time_column_name passed in automl settings\r\n\r\n There are currently no plans to support regression. @cartacioS  for visibility of this ask @deeptim123 ,\r\n\r\nThanks for the info. I think it's important to add this functionality for regression and classification as well.\r\n\r\n> There are currently no plans to support regression. @cartacioS for visibility of this ask\r\n\r\n @crisansou - this is currently not on our roadmap, and purposefully unprioritized as 90% of our customer base, especially customers investing in thousands+ models are leveraging only forecasting scenarios. Priorities change from one semester to the next, and it may be supported at a later date but is not in scope right now. If you are or have a direct customer who is blocked by the lack of many model support for regression and classification please contact me at sabina.cartacio@microsoft.com and we can further discuss.\r\n\r\nThanks! Hi @cartacioS ,\r\n\r\nGot it, thanks for the info! The project is starting now, but if it is really necessary to use the multiple models solution for regression I'll send you an email.\r\n\r\n> @crisansou - this is currently not on our roadmap, and purposefully unprioritized as 90% of our customer base, especially customers investing in thousands+ models are leveraging only forecasting scenarios. Priorities change from one semester to the next, and it may be supported at a later date but is not in scope right now. If you are or have a direct customer who is blocked by the lack of many model support for regression and classification please contact me at [sabina.cartacio@microsoft.com](mailto:sabina.cartacio@microsoft.com) and we can further discuss.\r\n> \r\n> Thanks!\r\n\r\n Closing as this is being tracked offline as a feature request for MANY MODELS, by Sabina.",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"automlpipelinebuild model train step error environ start prefix hello run experi error messag environ start prefix displai set environ follow github tutori haven imag http user imag githubusercont com png code regist dataset imag http user imag githubusercont com dec png imag http user imag githubusercont com png train pipelin imag http user imag githubusercont com dfc png imag http user imag githubusercont com bae acc png imag http user imag githubusercont com adb png imag http user imag githubusercont com fbedd png imag http user imag githubusercont com eea efa png refer http github com microsoft solut acceler model tree master autom automl train pipelin http github com microsoftdoc azur doc issu best regard cristina detalh documento edit esta seo necessrio para vinculao problema doc microsoft com github dabe version independ dba aceadbf content contrib automl pipelin step automlpipelinebuild class python http doc microsoft com python api contrib automl pipelin step contrib automl pipelin step automlpipelinebuild view azur content sourc docset stabl doc ref autogen contrib automl pipelin step contrib automl pipelin step automlpipelinebuild yml http github com microsoftdoc machinelearn python blob live docset stabl doc ref autogen contrib automl pipelin step contrib automl pipelin step automlpipelinebuild yml servic machin learn sub servic core github login debfro microsoft alia debfro",
        "Issue_preprocessed_content":"environ start prefix experi environ start prefix displai set environ github tutori haven code regist dataset train pipelin refer best regard cristina detalh documento edit esta seo para vinculao problema version independ content content sourc servic core github login microsoft alia debfro",
        "Issue_gpt_summary_original":"The user is seeking guidance on how to use `azureml.exceptions.WebserviceException` to effectively manage errors in REST API calls for Azure Machine Learning Service's AKS Webservice Endpoint. They want to know how to raise exceptions to provide proper feedback to end-users in case of unsuccessful API calls.",
        "Issue_gpt_summary":"user seek guidanc us except webserviceexcept effect manag error rest api call servic ak webservic endpoint want know rais except provid proper feedback end user case unsuccess api call",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1413",
        "Issue_title":"How to effectively use azureml.exceptions.WebserviceException for efficient REST API Error Management?",
        "Issue_created_time":1617254943000,
        "Issue_closed_time":1617344140000,
        "Issue_body":"In Azure Machine Learning Service, when we deploy a Model as an AKS Webservice Endpoint, how can we raise exceptions to let the end-user get proper feedback if their API call is unsuccessful? Azure mentions using `azureml.exceptions.WebserviceException` in their documentation. However, how do we use this class to raise exceptions in case the API call cannot be processed properly and the end-user is responsible for it?",
        "Issue_answer_count":2,
        "Issue_self_closed":1.0,
        "Answer_body":"@anirbansaha96 can you link to the doc you mention? The only doc I'm aware of about authoring errors is here: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-advanced-entry-script#binary-data\r\n \r\nWhich mentions using AMLResponse in the scoring file.\r\n\r\nAMLResponse will allow the writer of the scoring file to set a custom error message and api response code. Yes `return AMLResponse(\"Message\", status-code)` is what I was looking for. The documentation I was referring to: https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.exceptions.webserviceexception?view=azure-ml-py",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"effect us except webserviceexcept effici rest api error manag servic deploi model ak webservic endpoint rais except let end user proper feedback api unsuccess azur mention except webserviceexcept document us class rais except case api process properli end user respons",
        "Issue_preprocessed_content":"us rest api manag servic deploi model ak webservic endpoint rais except let proper api azur mention document us rais except case api properli respons",
        "Issue_gpt_summary_original":"The user is encountering an issue with the Azure ML Python SDK 1.24.0 image build, which fails with the error \"failed to get layer\". This issue was not present until a few days ago and occurs when submitting an experiment to the Azure ML workspace in the image build logs. The user is using the mcr.microsoft.com\/azureml\/base:intelmpi2018.3-ubuntu16.04 base image.",
        "Issue_gpt_summary":"user encount issu python sdk imag build fail error fail layer issu present dai ago occur submit experi workspac imag build log user mcr microsoft com base intelmpi ubuntu base imag",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1387",
        "Issue_title":"azure ml Python SDK 1.24.0 image build fails with the error failed to get layer was working fine before",
        "Issue_created_time":1615361317000,
        "Issue_closed_time":1623755236000,
        "Issue_body":"![image](https:\/\/user-images.githubusercontent.com\/74793968\/110592377-36daee00-81a0-11eb-8fb0-de7e2ba93af1.png)\r\n\r\nThis issue wasn't present until a few days ago. Issue shows up when we submit an experiment to azure ml workspace in the image build logs. We are using mcr.microsoft.com\/azureml\/base:intelmpi2018.3-ubuntu16.04 base image",
        "Issue_answer_count":6,
        "Issue_self_closed":1.0,
        "Answer_body":"I would think that is some transient issue. \r\nSide note, mcr.microsoft.com\/azureml\/base:intelmpi2018.3-ubuntu16.04 was deprecated in 2019, please use \r\nmcr.microsoft.com\/azureml\/intelmpi2018.3-ubuntu16.04 or better default cpu image from your client version that is pinned to a versioned tag Still facing the same issue. Kind of blocked is their some way i could fix this. Updated the image thanks for that is it local build? if yes, try to remove the image Nope it is remote compute build. It is in AML Compute cluster The issue got resolved we were earlier creating an image and storing it in Azure Container Registry. Now we don't pass it to RunConfiguration() object. We create it directly in the AML Build process and that has fixed the issue though now the image is not cached anymore so that is problematic. @MAQ-Ravijit-Ramana it would be great to get some details of your scenario, like the script you running",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"python sdk imag build fail error fail layer work fine imag http user imag githubusercont com daee deebaaf png issu wasn present dai ago issu show submit experi workspac imag build log mcr microsoft com base intelmpi ubuntu base imag",
        "Issue_preprocessed_content":"python sdk imag build fail fail layer work fine wasn present dai ago show submit experi workspac imag build log base imag",
        "Issue_gpt_summary_original":"The user is facing challenges in finding instructions on where to submit bugs\/glitches related to the Python azureml-sdk and is unsure if it should be done through Github or an Azure support ticket.",
        "Issue_gpt_summary":"user face challeng find instruct submit bug glitch relat python sdk unsur github azur support ticket",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1378",
        "Issue_title":"No instructions on where to submit bugs\/glitches related to the Python azureml-sdk",
        "Issue_created_time":1615198296000,
        "Issue_closed_time":null,
        "Issue_body":"\r\nAs, title says: there are no instructions on where to submit bugs\/glitches related to the Python azureml-sdk. \r\nIs it through github somewhere? Is it through an Azure support ticket? \r\n\r\n---\r\n#### Document Details\r\n\r\n\u26a0 *Do not edit this section. It is required for docs.microsoft.com \u279f GitHub issue linking.*\r\n\r\n* ID: eb938463-51c2-43f3-d528-76a07a28bec8\r\n* Version Independent ID: e15753c0-6fe1-100a-0efc-08c1f845dc83\r\n* Content: [Azure Machine Learning SDK for Python - Azure Machine Learning Python](https:\/\/docs.microsoft.com\/en-us\/python\/api\/overview\/azure\/ml\/?view=azure-ml-py)\r\n* Content Source: [AzureML-Docset\/docs-ref-conceptual\/index.md](https:\/\/github.com\/MicrosoftDocs\/MachineLearning-Python-pr\/blob\/live\/AzureML-Docset\/docs-ref-conceptual\/index.md)\r\n* Service: **machine-learning**\r\n* Sub-service: **core**\r\n* GitHub Login: @trevorbye\r\n* Microsoft Alias: **trbye**",
        "Issue_answer_count":2,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"instruct submit bug glitch relat python sdk titl sai instruct submit bug glitch relat python sdk github azur support ticket document detail edit section requir doc microsoft com github issu link aabec version independ efc cfdc content sdk python python http doc microsoft com python api overview azur view azur content sourc docset doc ref conceptu index http github com microsoftdoc machinelearn python blob live docset doc ref conceptu index servic machin learn sub servic core github login trevorby microsoft alia trbye",
        "Issue_preprocessed_content":"instruct submit relat python sdk titl sai instruct submit relat python sdk github azur ticket document detail edit section requir github version independ content content sourc servic core github login microsoft alia trbye",
        "Issue_gpt_summary_original":"The user is facing an issue while trying to start the training using a docker image from their local registry. The pipeline is unable to pull the docker image and is throwing an error message stating \"unauthorized: authentication required\". The user has tried setting the conda_env.python.user_managed_dependencies to False, which allows the pipeline to pull the image from the local registry, but it still crashes with the same error message while trying to pull the image for running it.",
        "Issue_gpt_summary":"user face issu try start train docker imag local registri pipelin unabl pull docker imag throw error messag state unauthor authent requir user tri set conda env python user manag depend fals allow pipelin pull imag local registri crash error messag try pull imag run",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1371",
        "Issue_title":"Azure ML Run docker command to pull public image failed ",
        "Issue_created_time":1614273729000,
        "Issue_closed_time":1614604742000,
        "Issue_body":"'m going through this notebook: https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/training\/train-on-remote-vm\/train-on-remote-vm.ipynb\r\n\r\nI need to start the training using the docker image from my local registry. I provided all required data in the environment I created:\r\n\r\nconda_env.docker.enabled = True\r\nconda_env.docker.base_image = \"tf_od_api:latest\"\r\nconda_env.docker.base_image_registry.address = \"mylocalacr.azurecr.io\"\r\nconda_env.docker.base_image_registry.username = \"MyToken\"\r\nconda_env.docker.base_image_registry.password = \"MyPassword\"\r\n\r\nconda_env.python.user_managed_dependencies = True\r\n\r\nsrc = ScriptRunConfig(source_directory='azureml-examples\/workflows\/train\/fastai\/pets\/src',\r\n                      script='aml_wrapper.py',\r\n                      compute_target=attached_dsvm_compute,\r\n                      environment=conda_env)\r\nrun = exp.submit(config=src)\r\nrun.wait_for_completion(show_output=True)\r\n\r\nAnd when I start the pipeline I got: \"FailedPullingImage: Unable to pull docker image\\n\\timageName: Run docker command to pull public image failed with error: error response from daemon: unauthorized: authentication required\"\r\n\r\nIf I set conda_env.python.user_managed_dependencies = False\r\n\r\nthen the pipeline can pull my image from my local registry, build a new image with all required python dependencies on top of my base image and push the new image to my local registry. But on the second step of the pipeline, when it tries to pull the image for running it, that was just created and pushed, it again crashes with the same error: \"Run docker command to pull public image failed with error: error response from daemon: unauthorized: authentication required\"",
        "Issue_answer_count":2,
        "Issue_self_closed":1.0,
        "Answer_body":"please try this \r\nhttps:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1247#issuecomment-738887772 Seems like it solved the issue. Thanks!",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"run docker command pull public imag fail go notebook http github com azur machinelearningnotebook blob master us train train remot train remot ipynb need start train docker imag local registri provid requir data environ creat conda env docker enabl true conda env docker base imag api latest conda env docker base imag registri address mylocalacr azurecr conda env docker base imag registri usernam mytoken conda env docker base imag registri password mypassword conda env python user manag depend true src scriptrunconfig sourc directori exampl workflow train fastai pet src script aml wrapper comput target attach dsvm comput environ conda env run exp submit config src run wait complet output true start pipelin got failedpullingimag unabl pull docker imag timagenam run docker command pull public imag fail error error respons daemon unauthor authent requir set conda env python user manag depend fals pipelin pull imag local registri build new imag requir python depend base imag push new imag local registri second step pipelin tri pull imag run creat push crash error run docker command pull public imag fail error error respons daemon unauthor authent requir",
        "Issue_preprocessed_content":"run docker public imag fail go start train docker imag local registri provid requir data environ creat true mytoken true src run start pipelin got unabl docker run docker public imag fail respons daemon unauthor authent requir set fals pipelin imag local registri build new imag requir python depend base imag push new imag local registri second step pipelin tri imag creat push crash run docker public imag fail respons daemon unauthor authent requir",
        "Issue_gpt_summary_original":"the user encountered a challenge when attempting to upload data to a datastore, resulting in an \"authorization permission mismatch\" error.",
        "Issue_gpt_summary":"user encount challeng attempt upload data datastor result author permiss mismatch error",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1348",
        "Issue_title":"ERROR:  Learning: Build AI solutions with Azure Machine Learning - 06 - Work with Data - Upload data to a datastore",
        "Issue_created_time":1613675010000,
        "Issue_closed_time":1613973498000,
        "Issue_body":"**Upload data to a datastore**\r\n![AzureUpload](https:\/\/user-images.githubusercontent.com\/947785\/108407641-3e325b80-71e1-11eb-85df-58479ed8db52.png)\r\n\r\nNow that you have determined the available datastores, you can upload files from your local file system to a datastore so that it will be accessible to experiments running in the workspace, regardless of where the experiment script is actually being run.\r\n\r\n_default_ds.upload_files(files=['.\/data\/diabetes.csv', '.\/data\/diabetes2.csv'], # Upload the diabetes csv files in \/data\r\n                       target_path='diabetes-data\/', # Put it in a folder path in the datastore\r\n                       overwrite=True, # Replace existing files of the same name\r\n                       show_progress=True)_\r\n\r\nUploading an estimated of 2 files\r\nUploading .\/data\/diabetes.csv\r\nUploading .\/data\/diabetes2.csv\r\nUploaded 0 files\r\n--- Logging error ---\r\nTraceback (most recent call last):\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/azure_storage_datastore.py\", line 332, in handler\r\n    result = future.result()\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/concurrent\/futures\/_base.py\", line 425, in result\r\n    return self.__get_result()\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/concurrent\/futures\/_base.py\", line 384, in __get_result\r\n    raise self._exception\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/concurrent\/futures\/thread.py\", line 56, in run\r\n    result = self.fn(*self.args, **self.kwargs)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/azure_storage_datastore.py\", line 787, in <lambda>\r\n    lambda target, source: lambda: self.blob_service.create_blob_from_path(self.container_name, target, source)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/blockblobservice.py\", line 463, in create_blob_from_path\r\n    timeout=timeout)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/blockblobservice.py\", line 582, in create_blob_from_stream\r\n    timeout=timeout)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/blockblobservice.py\", line 971, in _put_blob\r\n    return self._perform_request(request, _parse_base_properties)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_vendor\/azure_storage\/common\/storageclient.py\", line 381, in _perform_request\r\n    raise ex\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_vendor\/azure_storage\/common\/storageclient.py\", line 306, in _perform_request\r\n    raise ex\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_vendor\/azure_storage\/common\/storageclient.py\", line 292, in _perform_request\r\n    HTTPError(response.status, response.message, response.headers, response.body))\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_vendor\/azure_storage\/common\/_error.py\", line 115, in _http_error_handler\r\n    raise ex\r\nazure.common.AzureHttpError: This request is not authorized to perform this operation using this permission. ErrorCode: AuthorizationPermissionMismatch\r\n<?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>AuthorizationPermissionMismatch<\/Code><Message>This request is not authorized to perform this operation using this permission.\r\nRequestId:a9ffd72c-c01e-00d9-5220-064b2e000000\r\nTime:2021-02-18T18:02:54.3372191Z<\/Message><\/Error>\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/logging\/__init__.py\", line 994, in emit\r\n    msg = self.format(record)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/logging\/__init__.py\", line 840, in format\r\n    return fmt.format(record)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/logging\/__init__.py\", line 577, in format\r\n    record.message = record.getMessage()\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/logging\/__init__.py\", line 338, in getMessage\r\n    msg = msg % self.args\r\nTypeError: not all arguments converted during string formatting\r\nCall stack:\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/ipykernel_launcher.py\", line 16, in <module>\r\n    app.launch_new_instance()\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/traitlets\/config\/application.py\", line 664, in launch_instance\r\n    app.start()\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/ipykernel\/kernelapp.py\", line 612, in start\r\n    self.io_loop.start()\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/tornado\/platform\/asyncio.py\", line 199, in start\r\n    self.asyncio_loop.run_forever()\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/asyncio\/base_events.py\", line 438, in run_forever\r\n    self._run_once()\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/asyncio\/base_events.py\", line 1451, in _run_once\r\n    handle._run()\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/asyncio\/events.py\", line 145, in _run\r\n    self._callback(*self._args)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/tornado\/ioloop.py\", line 688, in <lambda>\r\n    lambda f: self._run_callback(functools.partial(callback, future))\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/tornado\/ioloop.py\", line 741, in _run_callback\r\n    ret = callback()\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/tornado\/gen.py\", line 814, in inner\r\n    self.ctx_run(self.run)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/contextvars\/__init__.py\", line 38, in run\r\n    return callable(*args, **kwargs)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/tornado\/gen.py\", line 775, in run\r\n    yielded = self.gen.send(value)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/ipykernel\/kernelbase.py\", line 362, in process_one\r\n    yield gen.maybe_future(dispatch(*args))\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/tornado\/gen.py\", line 234, in wrapper\r\n    yielded = ctx_run(next, result)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/contextvars\/__init__.py\", line 38, in run\r\n    return callable(*args, **kwargs)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/ipykernel\/kernelbase.py\", line 265, in dispatch_shell\r\n    yield gen.maybe_future(handler(stream, idents, msg))\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/tornado\/gen.py\", line 234, in wrapper\r\n    yielded = ctx_run(next, result)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/contextvars\/__init__.py\", line 38, in run\r\n    return callable(*args, **kwargs)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/ipykernel\/kernelbase.py\", line 542, in execute_request\r\n    user_expressions, allow_stdin,\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/tornado\/gen.py\", line 234, in wrapper\r\n    yielded = ctx_run(next, result)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/contextvars\/__init__.py\", line 38, in run\r\n    return callable(*args, **kwargs)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/ipykernel\/ipkernel.py\", line 302, in do_execute\r\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/ipykernel\/zmqshell.py\", line 539, in run_cell\r\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/IPython\/core\/interactiveshell.py\", line 2867, in run_cell\r\n    raw_cell, store_history, silent, shell_futures)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/IPython\/core\/interactiveshell.py\", line 2895, in _run_cell\r\n    return runner(coro)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/IPython\/core\/async_helpers.py\", line 68, in _pseudo_sync_runner\r\n    coro.send(None)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/IPython\/core\/interactiveshell.py\", line 3072, in run_cell_async\r\n    interactivity=interactivity, compiler=compiler, result=result)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/IPython\/core\/interactiveshell.py\", line 3263, in run_ast_nodes\r\n    if (await self.run_code(code, result,  async_=asy)):\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/IPython\/core\/interactiveshell.py\", line 3343, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-30-0f28dc9194af>\", line 4, in <module>\r\n    show_progress=True)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/azure_storage_datastore.py\", line 787, in upload_files\r\n    lambda target, source: lambda: self.blob_service.create_blob_from_path(self.container_name, target, source)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/azure_storage_datastore.py\", line 321, in _start_upload_task\r\n    tq.add_task(async_task)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_common\/async_utils\/task_queue.py\", line 55, in __exit__\r\n    self.flush(self.identity)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_common\/async_utils\/task_queue.py\", line 118, in flush\r\n    self._results.extend((task.wait(awaiter_name=self.identity) for task in completed_tasks))\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_common\/async_utils\/task_queue.py\", line 118, in <genexpr>\r\n    self._results.extend((task.wait(awaiter_name=self.identity) for task in completed_tasks))\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_common\/async_utils\/async_task.py\", line 58, in wait\r\n    res = self._handler(self._future, self._logger)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/azure_storage_datastore.py\", line 340, in handler\r\n    exception_handler(e, logger)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/azure_storage_datastore.py\", line 304, in exception_handler\r\n    logger.error(\"Upload failed, please make sure target_path does not start with invalid characters.\", e)\r\nMessage: 'Upload failed, please make sure target_path does not start with invalid characters.'\r\nArguments: (AzureHttpError('This request is not authorized to perform this operation using this permission. ErrorCode: AuthorizationPermissionMismatch\\n<?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>AuthorizationPermissionMismatch<\/Code><Message>This request is not authorized to perform this operation using this permission.\\nRequestId:a9ffd72c-c01e-00d9-5220-064b2e000000\\nTime:2021-02-18T18:02:54.3372191Z<\/Message><\/Error>',),)\r\n--- Logging error ---\r\nTraceback (most recent call last):\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/azure_storage_datastore.py\", line 332, in handler\r\n    result = future.result()\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/concurrent\/futures\/_base.py\", line 425, in result\r\n    return self.__get_result()\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/concurrent\/futures\/_base.py\", line 384, in __get_result\r\n    raise self._exception\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/concurrent\/futures\/thread.py\", line 56, in run\r\n    result = self.fn(*self.args, **self.kwargs)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/azure_storage_datastore.py\", line 787, in <lambda>\r\n    lambda target, source: lambda: self.blob_service.create_blob_from_path(self.container_name, target, source)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/blockblobservice.py\", line 463, in create_blob_from_path\r\n    timeout=timeout)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/blockblobservice.py\", line 582, in create_blob_from_stream\r\n    timeout=timeout)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/blockblobservice.py\", line 971, in _put_blob\r\n    return self._perform_request(request, _parse_base_properties)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_vendor\/azure_storage\/common\/storageclient.py\", line 381, in _perform_request\r\n    raise ex\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_vendor\/azure_storage\/common\/storageclient.py\", line 306, in _perform_request\r\n    raise ex\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_vendor\/azure_storage\/common\/storageclient.py\", line 292, in _perform_request\r\n    HTTPError(response.status, response.message, response.headers, response.body))\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_vendor\/azure_storage\/common\/_error.py\", line 115, in _http_error_handler\r\n    raise ex\r\nazure.common.AzureHttpError: This request is not authorized to perform this operation using this permission. ErrorCode: AuthorizationPermissionMismatch\r\n<?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>AuthorizationPermissionMismatch<\/Code><Message>This request is not authorized to perform this operation using this permission.\r\nRequestId:5488fc90-001e-0080-5d20-064ea8000000\r\nTime:2021-02-18T18:02:54.3372332Z<\/Message><\/Error>\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/logging\/__init__.py\", line 994, in emit\r\n    msg = self.format(record)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/logging\/__init__.py\", line 840, in format\r\n    return fmt.format(record)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/logging\/__init__.py\", line 577, in format\r\n    record.message = record.getMessage()\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/logging\/__init__.py\", line 338, in getMessage\r\n    msg = msg % self.args\r\nTypeError: not all arguments converted during string formatting\r\nCall stack:\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/ipykernel_launcher.py\", line 16, in <module>\r\n    app.launch_new_instance()\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/traitlets\/config\/application.py\", line 664, in launch_instance\r\n    app.start()\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/ipykernel\/kernelapp.py\", line 612, in start\r\n    self.io_loop.start()\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/tornado\/platform\/asyncio.py\", line 199, in start\r\n    self.asyncio_loop.run_forever()\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/asyncio\/base_events.py\", line 438, in run_forever\r\n    self._run_once()\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/asyncio\/base_events.py\", line 1451, in _run_once\r\n    handle._run()\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/asyncio\/events.py\", line 145, in _run\r\n    self._callback(*self._args)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/tornado\/ioloop.py\", line 688, in <lambda>\r\n    lambda f: self._run_callback(functools.partial(callback, future))\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/tornado\/ioloop.py\", line 741, in _run_callback\r\n    ret = callback()\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/tornado\/gen.py\", line 814, in inner\r\n    self.ctx_run(self.run)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/contextvars\/__init__.py\", line 38, in run\r\n    return callable(*args, **kwargs)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/tornado\/gen.py\", line 775, in run\r\n    yielded = self.gen.send(value)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/ipykernel\/kernelbase.py\", line 362, in process_one\r\n    yield gen.maybe_future(dispatch(*args))\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/tornado\/gen.py\", line 234, in wrapper\r\n    yielded = ctx_run(next, result)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/contextvars\/__init__.py\", line 38, in run\r\n    return callable(*args, **kwargs)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/ipykernel\/kernelbase.py\", line 265, in dispatch_shell\r\n    yield gen.maybe_future(handler(stream, idents, msg))\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/tornado\/gen.py\", line 234, in wrapper\r\n    yielded = ctx_run(next, result)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/contextvars\/__init__.py\", line 38, in run\r\n    return callable(*args, **kwargs)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/ipykernel\/kernelbase.py\", line 542, in execute_request\r\n    user_expressions, allow_stdin,\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/tornado\/gen.py\", line 234, in wrapper\r\n    yielded = ctx_run(next, result)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/contextvars\/__init__.py\", line 38, in run\r\n    return callable(*args, **kwargs)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/ipykernel\/ipkernel.py\", line 302, in do_execute\r\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/ipykernel\/zmqshell.py\", line 539, in run_cell\r\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/IPython\/core\/interactiveshell.py\", line 2867, in run_cell\r\n    raw_cell, store_history, silent, shell_futures)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/IPython\/core\/interactiveshell.py\", line 2895, in _run_cell\r\n    return runner(coro)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/IPython\/core\/async_helpers.py\", line 68, in _pseudo_sync_runner\r\n    coro.send(None)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/IPython\/core\/interactiveshell.py\", line 3072, in run_cell_async\r\n    interactivity=interactivity, compiler=compiler, result=result)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/IPython\/core\/interactiveshell.py\", line 3263, in run_ast_nodes\r\n    if (await self.run_code(code, result,  async_=asy)):\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/IPython\/core\/interactiveshell.py\", line 3343, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-30-0f28dc9194af>\", line 4, in <module>\r\n    show_progress=True)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/azure_storage_datastore.py\", line 787, in upload_files\r\n    lambda target, source: lambda: self.blob_service.create_blob_from_path(self.container_name, target, source)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/azure_storage_datastore.py\", line 321, in _start_upload_task\r\n    tq.add_task(async_task)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_common\/async_utils\/task_queue.py\", line 55, in __exit__\r\n    self.flush(self.identity)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_common\/async_utils\/task_queue.py\", line 118, in flush\r\n    self._results.extend((task.wait(awaiter_name=self.identity) for task in completed_tasks))\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_common\/async_utils\/task_queue.py\", line 118, in <genexpr>\r\n    self._results.extend((task.wait(awaiter_name=self.identity) for task in completed_tasks))\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_common\/async_utils\/async_task.py\", line 58, in wait\r\n    res = self._handler(self._future, self._logger)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/azure_storage_datastore.py\", line 340, in handler\r\n    exception_handler(e, logger)\r\n  File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/azure_storage_datastore.py\", line 304, in exception_handler\r\n    logger.error(\"Upload failed, please make sure target_path does not start with invalid characters.\", e)\r\nMessage: 'Upload failed, please make sure target_path does not start with invalid characters.'\r\nArguments: (AzureHttpError('This request is not authorized to perform this operation using this permission. ErrorCode: AuthorizationPermissionMismatch\\n<?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>AuthorizationPermissionMismatch<\/Code><Message>This request is not authorized to perform this operation using this permission.\\nRequestId:5488fc90-001e-0080-5d20-064ea8000000\\nTime:2021-02-18T18:02:54.3372332Z<\/Message><\/Error>',),)\r\n$AZUREML_DATAREFERENCE_010e49b94ea645928f99f4a15d7b3a00\r\nfrom azurem",
        "Issue_answer_count":4,
        "Issue_self_closed":0.0,
        "Answer_body":"@jb80016 can you provide more context on this issue? which example are you using? is it from this repository or elsewhere?  LEARNING PATH\r\nBuild AI solutions with Azure Machine Learning\r\nWork with Data in Azure Machine Learning  link:  https:\/\/docs.microsoft.com\/en-us\/learn\/modules\/work-with-data-in-aml\/ \r\nCloned this repository to workspace within Azure using public key:  git@github.com:MicrosoftLearning\/mslearn-dp100.git \r\n\r\nLet me know if any other info would be helpful.   I figured it out using:  \r\n\r\nfrom azureml.core import Workspace\r\nws = Workspace.from_config()\r\ndatastore = ws.get_default_datastore()\r\ndatastore.upload(src_dir='.\/data',\r\n                 target_path='diabetes-data',\r\n                 overwrite=True)\r\n\r\nfrom azureml.core import Dataset\r\n\r\n# Get the default datastore\r\ndefault_ds = ws.get_default_datastore()\r\n\r\n#Create a tabular dataset from the path on the datastore (this may take a short while)\r\ntab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data\/*.csv'))\r\n\r\n# Display the first 20 rows as a Pandas dataframe\r\ntab_data_set.take(20).to_pandas_dataframe() \r\n We are closing this issue, but if you have any follow-ups, please reopen it!  #please-close",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"error learn build solut work data upload data datastor upload data datastor azureupload http user imag githubusercont com eddb png avail datastor upload file local file datastor access experi run workspac regardless experi script actual run default upload file file data diabet csv data diabet csv upload diabet csv file data target path diabet data folder path datastor overwrit true replac exist file progress true upload estim file upload data diabet csv upload data diabet csv upload file log error traceback recent file anaconda env lib python site packag data azur storag datastor line handler result futur result file anaconda env lib python concurr futur base line result return self result file anaconda env lib python concurr futur base line result rais self except file anaconda env lib python concurr futur thread line run result self self arg self kwarg file anaconda env lib python site packag data azur storag datastor line lambda target sourc lambda self blob servic creat blob path self contain target sourc file anaconda env lib python site packag vendor azur storag blob blockblobservic line creat blob path timeout timeout file anaconda env lib python site packag vendor azur storag blob blockblobservic line creat blob stream timeout timeout file anaconda env lib python site packag vendor azur storag blob blockblobservic line blob return self perform request request pars base properti file anaconda env lib python site packag vendor azur storag common storagecli line perform request rais file anaconda env lib python site packag vendor azur storag common storagecli line perform request rais file anaconda env lib python site packag vendor azur storag common storagecli line perform request httperror respons statu respons messag respons header respons bodi file anaconda env lib python site packag vendor azur storag common error line http error handler rais azur common azurehttperror request author perform oper permiss errorcod authorizationpermissionmismatch authorizationpermissionmismatchthi request author perform oper permiss requestid affdc time handl except except occur traceback recent file anaconda env lib python log init line emit msg self format record file anaconda env lib python log init line format return fmt format record file anaconda env lib python log init line format record messag record getmessag file anaconda env lib python log init line getmessag msg msg self arg typeerror argument convert string format stack file anaconda env lib python runpi line run modul main main mod spec file anaconda env lib python runpi line run code exec code run global file anaconda env lib python site packag ipykernel launcher line app launch new instanc file anaconda env lib python site packag traitlet config applic line launch instanc app start file anaconda env lib python site packag ipykernel kernelapp line start self loop start file anaconda env lib python site packag tornado platform asyncio line start self asyncio loop run forev file anaconda env lib python asyncio base event line run forev self run file anaconda env lib python asyncio base event line run handl run file anaconda env lib python asyncio event line run self callback self arg file anaconda env lib python site packag tornado ioloop line lambda self run callback functool partial callback futur file anaconda env lib python site packag tornado ioloop line run callback ret callback file anaconda env lib python site packag tornado gen line inner self ctx run self run file anaconda env lib python site packag contextvar init line run return callabl arg kwarg file anaconda env lib python site packag tornado gen line run yield self gen send valu file anaconda env lib python site packag ipykernel kernelbas line process yield gen mayb futur dispatch arg file anaconda env lib python site packag tornado gen line wrapper yield ctx run result file anaconda env lib python site packag contextvar init line run return callabl arg kwarg file anaconda env lib python site packag ipykernel kernelbas line dispatch shell yield gen mayb futur handler stream ident msg file anaconda env lib python site packag tornado gen line wrapper yield ctx run result file anaconda env lib python site packag contextvar init line run return callabl arg kwarg file anaconda env lib python site packag ipykernel kernelbas line execut request user express allow stdin file anaconda env lib python site packag tornado gen line wrapper yield ctx run result file anaconda env lib python site packag contextvar init line run return callabl arg kwarg file anaconda env lib python site packag ipykernel ipkernel line execut re shell run cell code store histori store histori silent silent file anaconda env lib python site packag ipykernel zmqshell line run cell return super zmqinteractiveshel self run cell arg kwarg file anaconda env lib python site packag ipython core interactiveshel line run cell raw cell store histori silent shell futur file anaconda env lib python site packag ipython core interactiveshel line run cell return runner coro file anaconda env lib python site packag ipython core async helper line pseudo sync runner coro send file anaconda env lib python site packag ipython core interactiveshel line run cell async interact interact compil compil result result file anaconda env lib python site packag ipython core interactiveshel line run ast node await self run code code result async asi file anaconda env lib python site packag ipython core interactiveshel line run code exec code obj self user global self user file line progress true file anaconda env lib python site packag data azur storag datastor line upload file lambda target sourc lambda self blob servic creat blob path self contain target sourc file anaconda env lib python site packag data azur storag datastor line start upload task add task async task file anaconda env lib python site packag common async util task queue line exit self flush self ident file anaconda env lib python site packag common async util task queue line flush self result extend task wait await self ident task complet task file anaconda env lib python site packag common async util task queue line self result extend task wait await self ident task complet task file anaconda env lib python site packag common async util async task line wait re self handler self futur self logger file anaconda env lib python site packag data azur storag datastor line handler except handler logger file anaconda env lib python site packag data azur storag datastor line except handler logger error upload fail sure target path start invalid charact messag upload fail sure target path start invalid charact argument azurehttperror request author perform oper permiss errorcod authorizationpermissionmismatch nauthorizationpermissionmismatchthi request author perform oper permiss nrequestid affdc ntime log error traceback recent file anaconda env lib python site packag data azur storag datastor line handler result futur result file anaconda env lib python concurr futur base line result return self result file anaconda env lib python concurr futur base line result rais self except file anaconda env lib python concurr futur thread line run result self self arg self kwarg file anaconda env lib python site packag data azur storag datastor line lambda target sourc lambda self blob servic creat blob path self contain target sourc file anaconda env lib python site packag vendor azur storag blob blockblobservic line creat blob path timeout timeout file anaconda env lib python site packag vendor azur storag blob blockblobservic line creat blob stream timeout timeout file anaconda env lib python site packag vendor azur storag blob blockblobservic line blob return self perform request request pars base properti file anaconda env lib python site packag vendor azur storag common storagecli line perform request rais file anaconda env lib python site packag vendor azur storag common storagecli line perform request rais file anaconda env lib python site packag vendor azur storag common storagecli line perform request httperror respons statu respons messag respons header respons bodi file anaconda env lib python site packag vendor azur storag common error line http error handler rais azur common azurehttperror request author perform oper permiss errorcod authorizationpermissionmismatch authorizationpermissionmismatchthi request author perform oper permiss requestid time handl except except occur traceback recent file anaconda env lib python log init line emit msg self format record file anaconda env lib python log init line format return fmt format record file anaconda env lib python log init line format record messag record getmessag file anaconda env lib python log init line getmessag msg msg self arg typeerror argument convert string format stack file anaconda env lib python runpi line run modul main main mod spec file anaconda env lib python runpi line run code exec code run global file anaconda env lib python site packag ipykernel launcher line app launch new instanc file anaconda env lib python site packag traitlet config applic line launch instanc app start file anaconda env lib python site packag ipykernel kernelapp line start self loop start file anaconda env lib python site packag tornado platform asyncio line start self asyncio loop run forev file anaconda env lib python asyncio base event line run forev self run file anaconda env lib python asyncio base event line run handl run file anaconda env lib python asyncio event line run self callback self arg file anaconda env lib python site packag tornado ioloop line lambda self run callback functool partial callback futur file anaconda env lib python site packag tornado ioloop line run callback ret callback file anaconda env lib python site packag tornado gen line inner self ctx run self run file anaconda env lib python site packag contextvar init line run return callabl arg kwarg file anaconda env lib python site packag tornado gen line run yield self gen send valu file anaconda env lib python site packag ipykernel kernelbas line process yield gen mayb futur dispatch arg file anaconda env lib python site packag tornado gen line wrapper yield ctx run result file anaconda env lib python site packag contextvar init line run return callabl arg kwarg file anaconda env lib python site packag ipykernel kernelbas line dispatch shell yield gen mayb futur handler stream ident msg file anaconda env lib python site packag tornado gen line wrapper yield ctx run result file anaconda env lib python site packag contextvar init line run return callabl arg kwarg file anaconda env lib python site packag ipykernel kernelbas line execut request user express allow stdin file anaconda env lib python site packag tornado gen line wrapper yield ctx run result file anaconda env lib python site packag contextvar init line run return callabl arg kwarg file anaconda env lib python site packag ipykernel ipkernel line execut re shell run cell code store histori store histori silent silent file anaconda env lib python site packag ipykernel zmqshell line run cell return super zmqinteractiveshel self run cell arg kwarg file anaconda env lib python site packag ipython core interactiveshel line run cell raw cell store histori silent shell futur file anaconda env lib python site packag ipython core interactiveshel line run cell return runner coro file anaconda env lib python site packag ipython core async helper line pseudo sync runner coro send file anaconda env lib python site packag ipython core interactiveshel line run cell async interact interact compil compil result result file anaconda env lib python site packag ipython core interactiveshel line run ast node await self run code code result async asi file anaconda env lib python site packag ipython core interactiveshel line run code exec code obj self user global self user file line progress true file anaconda env lib python site packag data azur storag datastor line upload file lambda target sourc lambda self blob servic creat blob path self contain target sourc file anaconda env lib python site packag data azur storag datastor line start upload task add task async task file anaconda env lib python site packag common async util task queue line exit self flush self ident file anaconda env lib python site packag common async util task queue line flush self result extend task wait await self ident task complet task file anaconda env lib python site packag common async util task queue line self result extend task wait await self ident task complet task file anaconda env lib python site packag common async util async task line wait re self handler self futur self logger file anaconda env lib python site packag data azur storag datastor line handler except handler logger file anaconda env lib python site packag data azur storag datastor line except handler logger error upload fail sure target path start invalid charact messag upload fail sure target path start invalid charact argument azurehttperror request author perform oper permiss errorcod authorizationpermissionmismatch nauthorizationpermissionmismatchthi request author perform oper permiss nrequestid ntime datarefer ebeaffadba azurem",
        "Issue_preprocessed_content":"learn build solut work data upload data datastor upload data datastor avail datastor upload file local file datastor experi workspac experi script run upload diabet csv file data folder path datastor overwrit true replac exist file upload estim file upload upload upload file traceback file line handler result file line result return file line rais file line run result file line lambda target sourc lambda target sourc file line timeout timeout file line timeout timeout file line return file line rais file line rais file line file line rais request author perform oper xml request author perform oper handl except except traceback file line emit msg file line format return file line format file line msg msg argument convert string stack file line file line exec file line file line start file line start file line start file line file line file line file line lambda futur file line ret file line file line run return file line run yield file line yield file line yield result file line run return file line yield ident msg file line yield result file line run return file line file line yield result file line run return file line re silent silent file line return super kwarg file line silent file line return file line file line interact interact compil compil result result file line file line file line file line lambda target sourc lambda target sourc file line file line file line flush task file line task file line wait re file line handler file line upload fail sure start invalid argument traceback file line handler result file line result return file line rais file line run result file line lambda target sourc lambda target sourc file line timeout timeout file line timeout timeout file line return file line rais file line rais file line file line rais request author perform oper xml request author perform oper handl except except traceback file line emit msg file line format return file line format file line msg msg argument convert string stack file line file line exec file line file line start file line start file line start file line file line file line file line lambda futur file line ret file line file line run return file line run yield file line yield file line yield result file line run return file line yield ident msg file line yield result file line run return file line file line yield result file line run return file line re silent silent file line return super kwarg file line silent file line return file line file line interact interact compil compil result result file line file line file line file line lambda target sourc lambda target sourc file line file line file line flush task file line task file line wait re file line handler file line upload fail sure start invalid argument azurem",
        "Issue_gpt_summary_original":"The user is requesting a detailed description of `azureml-defaults` as it is necessary for deployment, but not documented. They have mentioned that `azureml-defaults` includes `azureml-core` and is required for deployment.",
        "Issue_gpt_summary":"user request detail descript default necessari deploy document mention default includ core requir deploy",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1341",
        "Issue_title":"azureml-defaults not described ",
        "Issue_created_time":1613523098000,
        "Issue_closed_time":null,
        "Issue_body":"\r\n[Enter feedback here]\r\n\r\nWe need details description of `azureml-defaults`. \r\n\r\nWe need this when deployment. In training, we usually use `azureml-core`. In deployment, `azureml-defaults` is necessary (only `azureml-core` is not enough to deploy). I heard `azureml-defaults` includes `azureml-core`. But it is not documented.\r\n\r\n---\r\n#### Document Details\r\n\r\n\u26a0 *Do not edit this section. It is required for docs.microsoft.com \u279f GitHub issue linking.*\r\n\r\n* ID: 8e0e12a4-b363-2726-06b4-9db2015efb32\r\n* Version Independent ID: e39a91ac-375b-a2cc-350d-a82cb7b0b035\r\n* Content: [Install the Azure Machine Learning SDK for Python - Azure Machine Learning Python](https:\/\/docs.microsoft.com\/en-us\/python\/api\/overview\/azure\/ml\/install?view=azure-ml-py)\r\n* Content Source: [AzureML-Docset\/docs-ref-conceptual\/install.md](https:\/\/github.com\/MicrosoftDocs\/MachineLearning-Python-pr\/blob\/live\/AzureML-Docset\/docs-ref-conceptual\/install.md)\r\n* Service: **machine-learning**\r\n* Sub-service: **core**\r\n* GitHub Login: @harneetvirk\r\n* Microsoft Alias: **harnvir**",
        "Issue_answer_count":4,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"default describ enter feedback need detail descript default need deploy train usual us core deploy default necessari core deploi heard default includ core document document detail edit section requir doc microsoft com github issu link eea dbefb version independ eaac acc acbbb content instal sdk python python http doc microsoft com python api overview azur instal view azur content sourc docset doc ref conceptu instal http github com microsoftdoc machinelearn python blob live docset doc ref conceptu instal servic machin learn sub servic core github login harneetvirk microsoft alia harnvir",
        "Issue_preprocessed_content":"default describ enter detail descript deploy train us deploy heard includ document document detail edit section requir github version independ content content sourc servic core github login microsoft alia harnvir",
        "Issue_gpt_summary_original":"The user encountered an error when trying to run an Azure ML pipeline with a local target, and received a ValueError message requesting a remote compute_target. The user suggests that this information should be added to the documentation, along with an explanation of why pipelines cannot be run on a local target.",
        "Issue_gpt_summary":"user encount error try run pipelin local target receiv valueerror messag request remot comput target user suggest inform ad document explan pipelin run local target",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1316",
        "Issue_title":"Local execution is not supported for Azure ML pipelines. ValueError: Please specify a remote compute_target. ",
        "Issue_created_time":1612300739000,
        "Issue_closed_time":1620257629000,
        "Issue_body":"\r\nWhen I try to run a pipeline with target as \"local\" it gives me an error. \r\nValueError: Please specify a remote compute_target. \r\nThis should be mentioned somewhere in the end of the page under target section. \r\nAlso please specify why pipelines cannot be run on local target? People like me waste a lot of time trying this & then realize its a shortcoming in the Azure ML Python SDK. \r\nPlease update this documentation page as soon as possible.\r\n![image](https:\/\/user-images.githubusercontent.com\/17008122\/106663751-73fe0000-65a4-11eb-87f7-fcc7613dd42f.png)\r\n\r\n---\r\n#### Document Details\r\n\r\n\u26a0 *Do not edit this section. It is required for docs.microsoft.com \u279f GitHub issue linking.*\r\n\r\n* ID: f2c8e18c-8443-67fe-b1f9-531de3599c8f\r\n* Version Independent ID: a8c897b7-c44b-1a72-52f2-f81bbdbce753\r\n* Content: [azureml.core.runconfig.RunConfiguration class - Azure Machine Learning Python](https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.runconfig.runconfiguration?view=azure-ml-py)\r\n* Content Source: [AzureML-Docset\/stable\/docs-ref-autogen\/azureml-core\/azureml.core.runconfig.RunConfiguration.yml](https:\/\/github.com\/MicrosoftDocs\/MachineLearning-Python-pr\/blob\/live\/AzureML-Docset\/stable\/docs-ref-autogen\/azureml-core\/azureml.core.runconfig.RunConfiguration.yml)\r\n* Service: **machine-learning**\r\n* Sub-service: **core**\r\n* GitHub Login: @DebFro\r\n* Microsoft Alias: **debfro**",
        "Issue_answer_count":8,
        "Issue_self_closed":0.0,
        "Answer_body":"apologies, we understand the frustration and are working to fully support local execution through Azure Machine Learning with our v2 developer experience, which is approaching public preview While it is allowed to Run AzureML experiments in Local Target using the Python SDK, I am expecting the pipelines as well to be allowed to run on local target. If this is an exception then it should be clearly flagged out & documented by Microsoft at all relevant places. Below 2 pages should definitely contain this note\r\n1. \r\nhttps:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.workspace(class)?view=azure-ml-py#azureml_core_Workspace_compute_targets\r\n(under compute_targets section)\r\n\r\n2.\r\nhttps:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.runconfig.runconfiguration?view=azure-ml-py\r\n(under target section)\r\n\r\nAlso please mention the target release date of v2 developer experience unfortunately the initial preview of v2 will not address this issue, I will allow the Pipelines team to give a more clear ETA for that. but initial preview is tentatively March 2021 Thank you for quick reply. I would be happy if this feature is included in the 2.0 release. Let me know if there is any way to rate this feature on higher priority.\r\n\r\nPS: Please change your screen name,  \"lostmygithubaccount\" is very confusing & unprofessional.  Hi @lostmygithubaccount and @meghalv .  I'm currently blocked by this issue.  I'm unable to allocate a remote Compute Target and I don't find an example on how to use my local computer.\r\n\r\nIs this feature already delivered?.  Do you have an example? Hi @lostmygithubaccount, \r\n\r\nwhat is the status of local execution of Pipelines in Azure Machine Learning? Why was this issue closed without any conclusive information or workaround? \r\n\r\nThis missing feature is blocking customers that want to use local IDE and debugging. The local pipeline is still in development. We don't have an ETA for the release date. Hi, I just wanted to contribute to the conversation and say that this feature would be much appreciated. Currently, it is difficult to bounce between local debugging and cloud deployment. This is because the lack of local pipeline support requires change in data-flow as well as various azureml-core variables that are accessible during pipeline runs. ",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"local execut support pipelin valueerror specifi remot comput target try run pipelin target local give error valueerror specifi remot comput target mention end page target section specifi pipelin run local target peopl like wast lot time try realiz shortcom python sdk updat document page soon possibl imag http user imag githubusercont com fccddf png document detail edit section requir doc microsoft com github issu link fcec decf version independ acb fbbdbce content core runconfig runconfigur class python http doc microsoft com python api core core runconfig runconfigur view azur content sourc docset stabl doc ref autogen core core runconfig runconfigur yml http github com microsoftdoc machinelearn python blob live docset stabl doc ref autogen core core runconfig runconfigur yml servic machin learn sub servic core github login debfro microsoft alia debfro",
        "Issue_preprocessed_content":"local execut pipelin specifi remot try run pipelin target local give specifi remot mention end page target section specifi pipelin run local target peopl like wast lot time try realiz shortcom python sdk updat document page document detail edit section requir github version independ content content sourc servic core github login microsoft alia debfro",
        "Issue_gpt_summary_original":"The user is encountering an issue with Azure's TabularDataset implementation when creating or reading parquet files that were originally written by Pandas\/Python. An index, \\_\\_index\\_level_0\\_\\_, is introduced which causes errors if not handled when making changes to datasets. The issue occurs when an index is unnamed but has been modified at some point. The user has provided an example notebook to reproduce the issue.",
        "Issue_gpt_summary":"user encount issu azur tabulardataset implement creat read parquet file origin written panda python index index level introduc caus error handl make chang dataset issu occur index unnam modifi point user provid exampl notebook reproduc issu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1299",
        "Issue_title":"AzureML TabularDataSet via parquet and pandas index error",
        "Issue_created_time":1611344395000,
        "Issue_closed_time":null,
        "Issue_body":"Azure's TabularDataset implementation introduces an index, \\_\\_index\\_level_0\\_\\_ when creating or reading parquet files that were originally written by Pandas\/Python.  This occurs when an index is unnamed but has been modified at some point; if an index is named we get an extra column with the same name as the index.\r\n\r\nWhen making changes to datasets, this additional field causes Azure errors if not handled.  Depending on what's been done to the index of the original dataset, you may or may not get that additional field.\r\n\r\nI have an example notebook that can be run to reproduce the issue.  It's here: https:\/\/github.com\/vla6\/Azure_notes\/blob\/main\/tabulardataset_parquet_index_di_issue.ipynb\r\n\r\nThe notebook requires an Azure Machine Learning workspace and a storage account to run",
        "Issue_answer_count":5,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"tabulardataset parquet panda index error azur tabulardataset implement introduc index index level creat read parquet file origin written panda python occur index unnam modifi point index name extra column index make chang dataset addit field caus azur error handl depend index origin dataset addit field exampl notebook run reproduc issu http github com vla azur note blob main tabulardataset parquet index issu ipynb notebook requir workspac storag account run",
        "Issue_preprocessed_content":"tabulardataset parquet panda index azur tabulardataset implement introduc index creat read parquet file index modifi point index name extra column index make chang dataset field caus azur handl depend index origin dataset field exampl run reproduc requir workspac storag run",
        "Issue_gpt_summary_original":"The user is facing an issue with version 1.20.0 of the python package azureml-contrib-pipeline-steps, which throws a type error while running a pipeline. The error does not occur with versions 1.19 or 1.18 of the package. The user has provided a minimal example of the code used and is using aml sdk 1.20.",
        "Issue_gpt_summary":"user face issu version python packag contrib pipelin step throw type error run pipelin error occur version packag user provid minim exampl code aml sdk",
        "Issue_score_count":4
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1417",
        "Issue_title":"python package azureml-contrib-pipeline-steps 1.20.0 not working ",
        "Issue_created_time":1611092820000,
        "Issue_closed_time":null,
        "Issue_body":"## Describe the issue\r\n\r\nversion 1.20.0 of python package azureml-contrib-pipeline-steps throws (works fine on version 1.19 or 1.18)\r\n\r\n File \"C:\/Users\/v-songshanli\/projects\/ashexplore\/object_identification\/obj_segmentation_azure_2_steps.py\", line 88, in run\r\n    pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\r\n  File \"C:\\Users\\v-songshanli\\Anaconda3\\envs\\pytouchEnv\\lib\\site-packages\\azureml\\core\\_experiment_method.py\", line 97, in wrapper\r\n    return init_func(self, *args, **kwargs)\r\n  File \"C:\\Users\\v-songshanli\\Anaconda3\\envs\\pytouchEnv\\lib\\site-packages\\azureml\\pipeline\\core\\pipeline.py\", line 177, in __init__\r\n    self._graph = self._graph_builder.build(self._name, steps, finalize=False)\r\n  File \"C:\\Users\\v-songshanli\\Anaconda3\\envs\\pytouchEnv\\lib\\site-packages\\azureml\\pipeline\\core\\builder.py\", line 1481, in build\r\n    graph = self.construct(name, steps)\r\n  File \"C:\\Users\\v-songshanli\\Anaconda3\\envs\\pytouchEnv\\lib\\site-packages\\azureml\\pipeline\\core\\builder.py\", line 1503, in construct\r\n    self.process_collection(steps)\r\n  File \"C:\\Users\\v-songshanli\\Anaconda3\\envs\\pytouchEnv\\lib\\site-packages\\azureml\\pipeline\\core\\builder.py\", line 1539, in process_collection\r\n    builder.process_collection(collection)\r\n  File \"C:\\Users\\v-songshanli\\Anaconda3\\envs\\pytouchEnv\\lib\\site-packages\\azureml\\pipeline\\core\\builder.py\", line 1830, in process_collection\r\n    self._base_builder.process_collection(item)\r\n  File \"C:\\Users\\v-songshanli\\Anaconda3\\envs\\pytouchEnv\\lib\\site-packages\\azureml\\pipeline\\core\\builder.py\", line 1533, in process_collection\r\n    return self.process_step(collection)\r\n  File \"C:\\Users\\v-songshanli\\Anaconda3\\envs\\pytouchEnv\\lib\\site-packages\\azureml\\pipeline\\core\\builder.py\", line 1577, in process_step\r\n    node = step.create_node(self._graph, self._default_datastore, self._context)\r\n  File \"C:\\Users\\v-songshanli\\Anaconda3\\envs\\pytouchEnv\\lib\\site-packages\\azureml\\pipeline\\steps\\python_script_step.py\", line 243, in create_node\r\n    return super(PythonScriptStep, self).create_node(\r\n  File \"C:\\Users\\v-songshanli\\Anaconda3\\envs\\pytouchEnv\\lib\\site-packages\\azureml\\pipeline\\core\\_python_script_step_base.py\", line 140, in create_node\r\n    self._set_compute_params_to_node(node,\r\n  File \"C:\\Users\\v-songshanli\\Anaconda3\\envs\\pytouchEnv\\lib\\site-packages\\azureml\\pipeline\\core\\_python_script_step_base.py\", line 229, in _set_compute_params_to_node\r\n    self._module_param_provider.set_params_to_node(\r\nTypeError: _set_params_to_node_hook() got an unexpected keyword argument 'command'\r\n\r\n## Minimal example\r\n\r\n```python\r\nfrom azureml.core import Workspace\r\n\r\nws = Workspace.from_config()\r\n\r\n\r\nsplit_step = PythonScriptStep(\r\n        name=\"Train Test Split\",\r\n        script_name=\"obj_segment_step_data_process.py\",\r\n        arguments=[\"--data-path\", dataset.as_named_input('pennfudan_data').as_mount(),\r\n                   \"--train-split\", train_split_data, \"--test-split\", test_split_data,\r\n                   \"--test-size\", 50],\r\n        compute_target=compute_target,\r\n        runconfig=aml_run_config,\r\n        source_directory=source_directory,\r\n        allow_reuse=False\r\n    )\r\n\r\npipeline_steps = [split_step ]\r\n\r\npipeline = Pipeline(workspace=ws, steps=pipeline_steps)\r\n```\r\n\r\n## Additional context\r\nI am using aml sdk 1.20. no type errors with version 1.19\/1.18 of azureml-contrib-pipeline-steps.\r\n-\r\n",
        "Issue_answer_count":3,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"python packag contrib pipelin step work issu version python packag contrib pipelin step throw work fine version file user songshanli project ashexplor object identif obj segment azur step line run pipelin pipelin workspac step pipelin step file user songshanli anaconda env pytouchenv lib site packag core experi method line wrapper return init func self arg kwarg file user songshanli anaconda env pytouchenv lib site packag pipelin core pipelin line init self graph self graph builder build self step final fals file user songshanli anaconda env pytouchenv lib site packag pipelin core builder line build graph self construct step file user songshanli anaconda env pytouchenv lib site packag pipelin core builder line construct self process collect step file user songshanli anaconda env pytouchenv lib site packag pipelin core builder line process collect builder process collect collect file user songshanli anaconda env pytouchenv lib site packag pipelin core builder line process collect self base builder process collect item file user songshanli anaconda env pytouchenv lib site packag pipelin core builder line process collect return self process step collect file user songshanli anaconda env pytouchenv lib site packag pipelin core builder line process step node step creat node self graph self default datastor self context file user songshanli anaconda env pytouchenv lib site packag pipelin step python script step line creat node return super pythonscriptstep self creat node file user songshanli anaconda env pytouchenv lib site packag pipelin core python script step base line creat node self set comput param node node file user songshanli anaconda env pytouchenv lib site packag pipelin core python script step base line set comput param node self modul param provid set param node typeerror set param node hook got unexpect keyword argument command minim exampl python core import workspac workspac config split step pythonscriptstep train test split script obj segment step data process argument data path dataset name input pennfudan data mount train split train split data test split test split data test size comput target comput target runconfig aml run config sourc directori sourc directori allow reus fals pipelin step split step pipelin pipelin workspac step pipelin step addit context aml sdk type error version contrib pipelin step",
        "Issue_preprocessed_content":"python packag work version python packag throw file line run pipelin pipelin file line return arg kwarg file line step final fals file line build graph step file line construct file line file line file line return file line node file line return super file line file line got unexpect keyword argument minim exampl context aml sdk type version",
        "Issue_gpt_summary_original":"The user encountered an error while trying to install Azureml-sdk using the command \"pip install azureml-sdk\" in an environment without a previous version of the package installed. The error message states that there is no matching distribution found for azureml-sdk.",
        "Issue_gpt_summary":"user encount error try instal sdk command pip instal sdk environ previou version packag instal error messag state match distribut sdk",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1285",
        "Issue_title":"Error Installing Azureml. (Python 3.9 support)",
        "Issue_created_time":1609957275000,
        "Issue_closed_time":1637097588000,
        "Issue_body":"This guidance results in an error:\r\n\r\n\"To install the default packages in an environment without a previous version of the package installed, run the following command.\" \r\n\r\nPS C:\\> pip install azureml-sdk\r\n\r\n`ERROR: Could not find a version that satisfies the requirement azureml-sdk (from versions: none)\r\nERROR: No matching distribution found for azureml-sdk`\r\n\r\nWhat am I missing?\r\n\r\nThanks,\r\nclaw\r\n---\r\n#### Document Details\r\n\r\n\u26a0 *Do not edit this section. It is required for docs.microsoft.com \u279f GitHub issue linking.*\r\n\r\n* ID: 8e0e12a4-b363-2726-06b4-9db2015efb32\r\n* Version Independent ID: e39a91ac-375b-a2cc-350d-a82cb7b0b035\r\n* Content: [Install the Azure Machine Learning SDK for Python - Azure Machine Learning Python](https:\/\/docs.microsoft.com\/en-us\/python\/api\/overview\/azure\/ml\/install?view=azure-ml-py)\r\n* Content Source: [AzureML-Docset\/docs-ref-conceptual\/install.md](https:\/\/github.com\/MicrosoftDocs\/MachineLearning-Python-pr\/blob\/live\/AzureML-Docset\/docs-ref-conceptual\/install.md)\r\n* Service: **machine-learning**\r\n* Sub-service: **core**\r\n* GitHub Login: @harneetvirk\r\n* Microsoft Alias: **harnvir**",
        "Issue_answer_count":15,
        "Issue_self_closed":0.0,
        "Answer_body":"@klawrawkz :  What is your OS? What is the python and pip version? \r\n\r\nazureml-sdk only supports Python 3.5 to 3.8. So, if you're using an out-of-range version of Python (older or newer), then you'll need to use a different version. Thanks for the reply @harneetvirk. I'm pretty sure it's not a python version issue.\r\n```\r\npy --version\r\nPython 3.9.1\r\n```\r\nCould be a Win 10 version issue?\r\n![image](https:\/\/user-images.githubusercontent.com\/48074223\/103943498-2f478c00-5100-11eb-9bfd-43443a4cb582.png)\r\n\r\nI ran this command and got farther. \r\n```\r\npip install --upgrade --upgrade-strategy eager azureml-sdk\r\n```\r\nI am stuck at this point now.\r\n```\r\n...\r\nINFO: pip is looking at multiple versions of azure-core to determine which version is compatible with other requirements. This could take a while.\r\nINFO: pip is looking at multiple versions of azure-mgmt-containerregistry to determine which version is compatible with other requirements. This could take a while.\r\nCollecting azure-mgmt-containerregistry>=2.0.0\r\n  Downloading azure_mgmt_containerregistry-2.7.0-py2.py3-none-any.whl (509 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 509 kB ...\r\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https:\/\/pip.pypa.io\/surveys\/backtracking\r\n  Downloading azure_mgmt_containerregistry-2.6.0-py2.py3-none-any.whl (501 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 501 kB 1.6 MB\/s\r\nINFO: pip is looking at multiple versions of azure-mgmt-core to determine which version is compatible with other requirements. This could take a while.\r\n  Downloading azure_mgmt_containerregistry-2.5.0-py2.py3-none-any.whl (494 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 494 kB 6.4 MB\/s\r\n  Downloading azure_mgmt_containerregistry-2.4.0-py2.py3-none-any.whl (482 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 482 kB 6.4 MB\/s\r\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https:\/\/pip.pypa.io\/surveys\/backtracking\r\n  Downloading azure_mgmt_containerregistry-2.3.0-py2.py3-none-any.whl (481 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 481 kB 6.8 MB\/s\r\n```\r\n\r\nWhat's your advice on commands to provide \"stricter constraints to reduce runtime?\" The command (above) has been \"running\" for ~24 hours, so I'm guessing that it's dead in the H20.\r\n\r\nKlaw azureml-sdk only supports Python 3.5 to 3.8, but you are having python 3.9.1 installed in the environment.  Please change the python version between 3.5 to 3.8.\r\n\r\nAlso, the latest pip 20.3 has a new dependency resolver which is resulting in this long running dependency resolutions. If you switch to older version of pip (<20.3), you will notice the difference in the performance. Gotcha, thanks for the info. I'll make the change.\r\n\r\nKlaw If azureml-sdk does not support Python 3.9, then the metadata should be updated from:\r\n```\r\nRequires-Python: >=3.5,<4\r\n```\r\nto:\r\n```\r\nRequires-Python: >=3.5,<3.9\r\n```\r\nIs this also true for the hundreds of subpackages that azureml-sdk depends on? When is Python 3.9 support coming? when will azureml-core be compatible with python 3.9? I am currently using azureml-sdk under Python 3.9 by installing with pip's `--ignore-requires-python` option, and everything I am using seems to work fine. But there are probably some other parts that don't work... @johan12345 is this in production environment? you are using it like this? or in your local env? In my local development environment.  `azureml-core` now supports Python 3.9. unfortunately although `azureml-core` might install w\/o errors in 3.9, `azureml-sdk` still creates errors. Installed w\/o errors in 3.8.12   azureml-sdk is a meta package.  azureml-core is one of the upstream that supports python 3.9 but there are some other AutoML dependencies in azureml-sdk  which do not support python 3.9.\r\n I have just updated azureml-sdk to allow Python 3.9.\r\nThis should be included in the next Azure ML SDK release, 1.45.0. What about 3.10? 3.11 is coming out soon too. @adamjstewart Python 3.10 is already supported in the new SDK V2 preview: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-v2\r\nI expect that we will support 3.10 in SDK V1 as well but I don't have a date for that.",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"error instal python support guidanc result error instal default packag environ previou version packag instal run follow command pip instal sdk error version satisfi requir sdk version error match distribut sdk miss thank claw document detail edit section requir doc microsoft com github issu link eea dbefb version independ eaac acc acbbb content instal sdk python python http doc microsoft com python api overview azur instal view azur content sourc docset doc ref conceptu instal http github com microsoftdoc machinelearn python blob live docset doc ref conceptu instal servic machin learn sub servic core github login harneetvirk microsoft alia harnvir",
        "Issue_preprocessed_content":" guidanc result default packag environ previou version packag run pip sdk thank claw document detail edit section requir github version independ content content sourc servic core github login microsoft alia harnvir",
        "Issue_gpt_summary_original":"The user is encountering an error while running a PythonScriptStep in Azure ML SDK version 1.11.0. The error message states that \"azureml-train-automl-runtime\" is required but not installed in the current environment. The user has provided a RunConfiguration that includes the missing dependency, but the error persists. This issue is preventing the user from running any pipelines that were previously working.",
        "Issue_gpt_summary":"user encount error run pythonscriptstep sdk version error messag state train automl runtim requir instal current environ user provid runconfigur includ miss depend error persist issu prevent user run pipelin previous work",
        "Issue_score_count":3
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1111",
        "Issue_title":"error: azureml-train-automl-runtime is required however it is included",
        "Issue_created_time":1598046974000,
        "Issue_closed_time":1598387113000,
        "Issue_body":"```Azure ML SDK Version:  1.11.0```\r\n\r\nIn a ```PythonScriptStep``` I'm getting a crash error that: \"\r\n```\r\nazureml-train-automl-runtime must be installed in the current environment to run local in process runs. Please install this dependency or provide a RunConfiguration.\r\n```\r\n\r\nHere is my RunConfiguration:\r\n```\r\ncompute_target = ComputeTarget(workspace=f.ws, name=compute_name)\r\n\r\ncd = CondaDependencies.create(\r\n    pip_packages=[\"pandas\", \"numpy\",\r\n                  \"azureml-defaults\", \"azureml-sdk[explain,automl]\", \"azureml-train-automl-runtime\"],\r\n    conda_packages=[\"xlrd\", \"scikit-learn\", \"numpy\", \"pyyaml\", \"pip\"])\r\namlcompute_run_config = RunConfiguration(conda_dependencies=cd)\r\namlcompute_run_config.environment.docker.enabled = True\r\n```\r\n\r\nhere is the step:\r\n```\r\nadd_vendor_sets = PythonScriptStep(\r\n    name='Add Vendor set',\r\n    script_name='add_vendor_set.py',\r\n    arguments=['--respondent_dir', level_respondent,\r\n                '--my_dir', my_raw,\r\n                '--output_dir', factset_processed],\r\n    compute_target=compute_target,\r\n    inputs=[level_respondent, my_raw],\r\n    outputs=[my_processed],\r\n    runconfig=amlcompute_run_config,\r\n    source_directory=os.path.join(os.getcwd(), 'pipes\/add_vendor_set'),\r\n    allow_reuse=True\r\n)\r\n```\r\n\r\nThe environment is obviously included, but also definitely missing.  I'm stuck and now none of my pipelines, that were running in previous version, will work. \r\n\r\n",
        "Issue_answer_count":5,
        "Issue_self_closed":1.0,
        "Answer_body":"can you share the full stacktrace? and is the error happening when you submit the pipeline script? or is it happening in the logs of the `PythonScriptStep`? ```\r\n\"error\": {\r\n        \"code\": \"UserError\",\r\n        \"message\": \"azureml-train-automl-runtime must be installed in the current environment to run local in process runs. Please install this dependency or provide a RunConfiguration.\",\r\n        \"detailsUri\": \"https:\/\/aka.ms\/azureml-known-errors\",\r\n        \"details\": [],\r\n        \"debugInfo\": {\r\n            \"type\": \"UserScriptException\",\r\n            \"message\": \"UserScriptException:\\n\\tMessage: azureml-train-automl-runtime must be installed in the current environment to run local in process runs. Please install this dependency or provide a RunConfiguration.\\n\\tInnerException OptionalDependencyMissingException:\\n\\tMessage: azureml-train-automl-runtime must be installed in the current environment to run local in process runs. Please install this dependency or provide a RunConfiguration.\\n\\tInnerException: None\\n\\tErrorResponse \\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"inner_error\\\": {\\n            \\\"code\\\": \\\"ValidationError\\\",\\n            \\\"inner_error\\\": {\\n                \\\"code\\\": \\\"ScenarioNotSuported\\\",\\n                \\\"inner_error\\\": {\\n                    \\\"code\\\": \\\"OptionalDependencyMissing\\\"\\n                }\\n            }\\n        },\\n        \\\"message\\\": \\\"azureml-train-automl-runtime must be installed in the current environment to run local in process runs. Please install this dependency or provide a RunConfiguration.\\\"\\n    }\\n}\\n\\tErrorResponse \\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"azureml-train-automl-runtime must be installed in the current environment to run local in process runs. Please install this dependency or provide a RunConfiguration.\\\"\\n    }\\n}\",\r\n            \"stackTrace\": \"  File \\\"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/pjx-d-cu1-mlw-models\/azureml\/d881de2a-9dba-4e74-805e-d3c6eaab2076\/mounts\/workspaceblobstore\/azureml\/d881de2a-9dba-4e74-805e-d3c6eaab2076\/azureml-setup\/context_manager_injector.py\\\", line 197, in execute_with_context\\n    raise UserScriptException(baseEx).with_traceback(exceptionInfo[2])\\n  File \\\"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/pjx-d-cu1-mlw-models\/azureml\/d881de2a-9dba-4e74-805e-d3c6eaab2076\/mounts\/workspaceblobstore\/azureml\/d881de2a-9dba-4e74-805e-d3c6eaab2076\/azureml-setup\/context_manager_injector.py\\\", line 166, in execute_with_context\\n    runpy.run_path(sys.argv[0], globals(), run_name=\\\"__main__\\\")\\n  File \\\"\/azureml-envs\/azureml_e96633b6ad93e7baf9c7240cba821e53\/lib\/python3.6\/runpy.py\\\", line 263, in run_path\\n    pkg_name=pkg_name, script_name=fname)\\n  File \\\"\/azureml-envs\/azureml_e96633b6ad93e7baf9c7240cba821e53\/lib\/python3.6\/runpy.py\\\", line 96, in _run_module_code\\n    mod_name, mod_spec, pkg_name, script_name)\\n  File \\\"\/azureml-envs\/azureml_e96633b6ad93e7baf9c7240cba821e53\/lib\/python3.6\/runpy.py\\\", line 85, in _run_code\\n    exec(code, run_globals)\\n  File \\\"run_models.py\\\", line 286, in \\n    main()\\n  File \\\"run_models.py\\\", line 197, in main\\n    run = experiment.submit(config=automl_config, tags=tags)\\n  File \\\"\/azureml-envs\/azureml_e96633b6ad93e7baf9c7240cba821e53\/lib\/python3.6\/site-packages\/azureml\/core\/experiment.py\\\", line 211, in submit\\n    run = submit_func(config, self.workspace, self.name, **kwargs)\\n  File \\\"\/azureml-envs\/azureml_e96633b6ad93e7baf9c7240cba821e53\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/automlconfig.py\\\", line 97, in _automl_static_submit\\n    show_output)\\n  File \\\"\/azureml-envs\/azureml_e96633b6ad93e7baf9c7240cba821e53\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/automlconfig.py\\\", line 255, in _start_execution\\n    automl_run = _default_execution(experiment, settings_obj, fit_params, True, show_output, parent_run_id)\\n  File \\\"\/azureml-envs\/azureml_e96633b6ad93e7baf9c7240cba821e53\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/automlconfig.py\\\", line 121, in _default_execution\\n    return automl_estimator.fit(**fit_params)\\n  File \\\"\/azureml-envs\/azureml_e96633b6ad93e7baf9c7240cba821e53\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/_azureautomlclient.py\\\", line 349, in fit\\n    \\\"azureml-train-automl-runtime must be installed in the current environment to run local in \\\"\\n\"\r\n        },\r\n        \"messageFormat\": \"azureml-train-automl-runtime must be installed in the current environment to run local in process runs. Please install this dependency or provide a RunConfiguration.\",\r\n        \"messageParameters\": {}\r\n    },\r\n    \"time\": \"0001-01-01T00:00:00.000Z\"\r\n}\r\n``` Here is my stack trace from the 70_driver_log.txt:\r\n```\r\nTraceback (most recent call last):\r\n  File \"run_models.py\", line 286, in <module>\r\n    main()\r\n  File \"run_models.py\", line 197, in main\r\n    run = experiment.submit(config=automl_config, tags=tags)\r\n  File \"\/azureml-envs\/azureml_e96633b6ad93e7baf9c7240cba821e53\/lib\/python3.6\/site-packages\/azureml\/core\/experiment.py\", line 211, in submit\r\n    run = submit_func(config, self.workspace, self.name, **kwargs)\r\n  File \"\/azureml-envs\/azureml_e96633b6ad93e7baf9c7240cba821e53\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/automlconfig.py\", line 97, in _automl_static_submit\r\n    show_output)\r\n  File \"\/azureml-envs\/azureml_e96633b6ad93e7baf9c7240cba821e53\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/automlconfig.py\", line 255, in _start_execution\r\n    automl_run = _default_execution(experiment, settings_obj, fit_params, True, show_output, parent_run_id)\r\n  File \"\/azureml-envs\/azureml_e96633b6ad93e7baf9c7240cba821e53\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/automlconfig.py\", line 121, in _default_execution\r\n    return automl_estimator.fit(**fit_params)\r\n  File \"\/azureml-envs\/azureml_e96633b6ad93e7baf9c7240cba821e53\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/_azureautomlclient.py\", line 349, in fit\r\n    \"azureml-train-automl-runtime must be installed in the current environment to run local in \"\r\nUserScriptException: UserScriptException:\r\n\tMessage: azureml-train-automl-runtime must be installed in the current environment to run local in process runs. Please install this dependency or provide a RunConfiguration.\r\n``` @swatig007 this is an error, @BillmanH is experiencing when submitting an AutoML run from within a `PythonScriptStep` rather than using an `AutoMLStep`. This approach worked for over a year, but is now throwing an error about `azureml-train-automl-runtime` not being installed. upgraded to 1.12.0, which solved this problem and opened other issues. ",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"error train automl runtim requir includ sdk version pythonscriptstep get crash error train automl runtim instal current environ run local process run instal depend provid runconfigur runconfigur comput target computetarget workspac comput condadepend creat pip packag panda numpi default sdk explain automl train automl runtim conda packag xlrd scikit learn numpi pyyaml pip amlcomput run config runconfigur conda depend amlcomput run config environ docker enabl true step add vendor set pythonscriptstep add vendor set script add vendor set argument respond dir level respond dir raw output dir factset process comput target comput target input level respond raw output process runconfig amlcomput run config sourc directori path join getcwd pipe add vendor set allow reus true environ obvious includ definit miss stuck pipelin run previou version work",
        "Issue_preprocessed_content":"requir includ crash runconfigur step environ obvious includ definit stuck pipelin previou version work",
        "Issue_gpt_summary_original":"The user is facing an issue where version history is not maintained when pulling data from an Azure SQL DB or DW into Azure ML datasets. Only the first version is refreshed every time new data is pulled. The user has provided a reproducible example to explain the issue.",
        "Issue_gpt_summary":"user face issu version histori maintain pull data azur sql dataset version refresh time new data pull user provid reproduc exampl explain issu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/944",
        "Issue_title":"BUG: Versioning not enabled when pulling data from SQL DB\/DW into Azure ML datasets",
        "Issue_created_time":1587712154000,
        "Issue_closed_time":1599067481000,
        "Issue_body":"\r\nWhenever I pull the data from an azure SQL DB or DW, the version history is not maintained. Everytime I pull a new data, the first version is only refreshing.\r\nI have created a reproducible example to explain my issue. \r\n\r\nhttps:\/\/github.com\/swaticolab\/MachineLearningNotebooks\/blob\/SQL_to_ML\/how-to-use-azureml\/machine-learning-pipelines\/intro-to-pipelines\/Connect_SQL_to_ML_dataset.ipynb",
        "Issue_answer_count":4,
        "Issue_self_closed":0.0,
        "Answer_body":"@swaticolab Could you please check if all versions are available when you specify the version with [get_by_name()](https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.abstract_dataset.abstractdataset?view=azure-ml-py#get-by-name-workspace--name--version--latest--)\r\n\r\nAlso, a note in azureml.core.dataset.dataset [documentation ](https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.dataset.dataset?view=azure-ml-py#to-pandas-dataframe--) mentions that [to_pandas_dataframe()](https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.dataset.dataset?view=azure-ml-py#to-pandas-dataframe--) is deprecated and replaced by azureml.data.tabulardataset [to_pandas_dataframe()](https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.tabulardataset?view=azure-ml-py#to-pandas-dataframe-on-error--null---out-of-range-datetime--null--). Could you please check with this implementation to check if all versions are shown? @RohitMungi-MSFT Yes I did try using the get_by_name() approach. But it was still not working. @MayMSFT  dataset is just a pointer to data in your storage. here is an article that explains how dataset versioning works:\r\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-version-track-datasets",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"bug version enabl pull data sql dataset pull data azur sql version histori maintain everytim pull new data version refresh creat reproduc exampl explain issu http github com swaticolab machinelearningnotebook blob sql us machin learn pipelin intro pipelin connect sql dataset ipynb",
        "Issue_preprocessed_content":"bug version enabl data sql dataset data azur sql version histori maintain everytim new data version refresh creat reproduc exampl explain",
        "Issue_gpt_summary_original":"The user is encountering an internal server error while deploying a container to AKS using Azure ML CLI. The error occurs sporadically and there is no clear pattern to it. The error message suggests creating a retry loop, but this would not address the underlying issue.",
        "Issue_gpt_summary":"user encount intern server error deploi contain ak cli error occur sporad clear pattern error messag suggest creat retri loop address underli issu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/841",
        "Issue_title":"Internal server error when deploying from Azure ML to AKS",
        "Issue_created_time":1583404471000,
        "Issue_closed_time":1583847372000,
        "Issue_body":"The team uses Azure ML CLI to deploy a container to AKS (az ml model deploy). Now and then (not always), they get an internal server error, see stack trace. They could not detect a clear pattern when this error occurs. Although it would be possible to create a retry loop in their Azure DevOps pipeline when this error occurs (as the error message also tells), this would not resolve the underlying issue.\r\n\r\n```\r\n2020-02-14T11:11:07.1739375Z ERROR: {'Azure-cli-ml Version': '1.0.85', 'Error': WebserviceException:\r\n\r\n2020-02-14T11:11:07.1739694Z \tMessage: Received bad response from Model Management Service:\r\n\r\n2020-02-14T11:11:07.1739785Z Response Code: 500\r\n\r\n2020-02-14T11:11:07.1740533Z Headers: {'Date': 'Fri, 14 Feb 2020 11:11:07 GMT', 'Content-Type': 'application\/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Request-Context': 'appId=cid-v1:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\r\n\r\n2020-02-14T11:11:07.1741400Z Content: b'{\"code\":\"InternalServerError\",\"statusCode\":500,\"message\":\"An internal server error occurred. Please try again. If the problem persists, contact support\"}'\r\n\r\n2020-02-14T11:11:07.1741516Z \tInnerException None\r\n\r\n2020-02-14T11:11:07.1741641Z \tErrorResponse \r\n\r\n2020-02-14T11:11:07.1741708Z {\r\n\r\n2020-02-14T11:11:07.1741813Z     \"error\": {\r\n\r\n2020-02-14T11:11:07.1742819Z         \"message\": \"Received bad response from Model Management Service:\\nResponse Code: 500\\nHeaders: {'Date': 'Fri, 14 Feb 2020 11:11:07 GMT', 'Content-Type': 'application\/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Request-Context': 'appId=cid-v1:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\\nContent: b'{\\\"code\\\":\\\"InternalServerError\\\",\\\"statusCode\\\":500,\\\"message\\\":\\\"An internal server error occurred. Please try again. If the problem persists, contact support\\\"}'\"\r\n\r\n2020-02-14T11:11:07.1743119Z     }\r\n\r\n2020-02-14T11:11:07.1743227Z }}\r\n```",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"@robinvdheijden \r\n\r\nThanks for reaching out to us. This is forum for Machine Learning Notebook only. Please open a new forum thread in [MSDN forum](https:\/\/social.msdn.microsoft.com\/Forums\/en-US\/home?forum=AzureMachineLearningService)as it could be better place to get help on your scenario. These forum community members could provide their expert guidance on your scenario based on their experience. Thanks.\r\n\r\nWe will now proceed to close this thread. If there are further questions regarding this matter, please respond here and @YutongTie-MSFT and we will gladly continue the discussion.",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"intern server error deploi ak team us cli deploi contain ak model deploi intern server error stack trace detect clear pattern error occur possibl creat retri loop azur devop pipelin error occur error messag tell resolv underli issu error azur cli version error webserviceexcept messag receiv bad respons model manag servic respons code header date fri feb gmt content type applic json transfer encod chunk connect aliv request context appid cid xxxxxxxx xxxx xxxx xxxx xxxxxxxxxxxx api support version preview strict transport secur max ag includesubdomain preload content code internalservererror statuscod messag intern server error occur try problem persist contact support innerexcept errorrespons error messag receiv bad respons model manag servic nrespons code nheader date fri feb gmt content type applic json transfer encod chunk connect aliv request context appid cid xxxxxxxx xxxx xxxx xxxx xxxxxxxxxxxx api support version preview strict transport secur max ag includesubdomain preload ncontent code internalservererror statuscod messag intern server error occur try problem persist contact support",
        "Issue_preprocessed_content":"intern server deploi ak team us cli deploi contain ak intern server stack trace detect clear creat retri azur devop pipelin resolv underli",
        "Issue_gpt_summary_original":"The user is encountering an import error while running a sample notebook for image classification. The error occurs when trying to import 'Dataset' from 'azureml.core'. The user has provided a reference YAML file that includes the necessary dependencies, and is requesting assistance from Microsoft to investigate the issue.",
        "Issue_gpt_summary":"user encount import error run sampl notebook imag classif error occur try import dataset core user provid refer yaml file includ necessari depend request assist microsoft investig issu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/787",
        "Issue_title":"Import Error - from azureml.core import Dataset  - ImportError: cannot import name 'Dataset'",
        "Issue_created_time":1581438052000,
        "Issue_closed_time":1581440044000,
        "Issue_body":"The following sample notebook fails \r\n### img-classification-part1-training.ipynb\r\n\r\nwhen running:\r\n\r\n### from azureml.core import Dataset\r\n\r\nfrom azureml.core import Dataset\r\nfrom azureml.opendatasets import MNIST\r\n\r\ndata_folder = os.path.join(os.getcwd(), 'data')\r\nos.makedirs(data_folder, exist_ok=True)\r\n\r\nmnist_file_dataset = MNIST.get_file_dataset()\r\nmnist_file_dataset.download(data_folder, overwrite=True)\r\n\r\nmnist_file_dataset = mnist_file_dataset.register(workspace=ws,\r\n                                                 name='mnist_opendataset',\r\n                                                 description='training and test dataset',\r\n                                                 create_new_version=True)\r\n\r\n\r\n**Here is the error**\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-5-ac2e91b46eec> in <module>\r\n----> 1 from azureml.core import Dataset\r\n      2 from azureml.opendatasets import MNIST\r\n      3 \r\n      4 data_folder = os.path.join(os.getcwd(), 'data')\r\n      5 os.makedirs(data_folder, exist_ok=True)\r\n\r\nImportError: cannot import name 'Dataset'\r\n\r\nreference: yml file:\r\nname: img-classification-part1-training\r\ndependencies:\r\n- pip:\r\n  - azureml-sdk\r\n  - azureml-widgets\r\n  - matplotlib\r\n  - sklearn\r\n  - pandas\r\n  - azureml-opendatasets\r\n\r\nAzure ML SDK Version:  1.0.17\r\nPython 3.6 - AzureML\r\n\r\n@microsoft\r\nPlease kindly investigate.\r\nMany thanks :)",
        "Issue_answer_count":2,
        "Issue_self_closed":1.0,
        "Answer_body":"@andrewkinsella, version `1.0.17` is from [almost a year ago](https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/azure-machine-learning-release-notes#2019-02-25). During that time, the `Datasets` class has evolved significantly (for the better). Can you try upgrading the SDK to the newest version and trying again? @MayMSFT  Thank you very much @swanderz \r\nI will try your recommendation.",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"import error core import dataset importerror import dataset follow sampl notebook fail img classif train ipynb run core import dataset core import dataset opendataset import mnist data folder path join getcwd data makedir data folder exist true mnist file dataset mnist file dataset mnist file dataset download data folder overwrit true mnist file dataset mnist file dataset regist workspac mnist opendataset descript train test dataset creat new version true error importerror traceback recent core import dataset opendataset import mnist data folder path join getcwd data makedir data folder exist true importerror import dataset refer yml file img classif train depend pip sdk widget matplotlib sklearn panda opendataset sdk version python microsoft kindli investig thank",
        "Issue_preprocessed_content":"import core import dataset import dataset sampl fail core import dataset core import dataset opendataset import mnist data overwrit true descript train test dataset traceback core import dataset opendataset import mnist data import dataset refer yml file depend pip sdk widget matplotlib sklearn panda opendataset sdk version python kindli investig thank",
        "Issue_gpt_summary_original":"The user encountered an error while using Azure Machine Learning with the XGBoostClassifier model. The error message indicates that the blacklisted and whitelisted models are the same, and suggests removing models from the blacklist or adding models to the whitelist. The user provided the automl_settings and automl_config used, and noted that XGBoostClassifier was installed in the notebook.",
        "Issue_gpt_summary":"user encount error xgboostclassifi model error messag indic blacklist whitelist model suggest remov model blacklist ad model whitelist user provid automl set automl config note xgboostclassifi instal notebook",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/767",
        "Issue_title":"Azure Machine Learning error: Can not use 'XGBoostClassifier'",
        "Issue_created_time":1581000215000,
        "Issue_closed_time":1583863460000,
        "Issue_body":"I got this error with Azure Machine Learning. \r\n\r\nConfigException: ConfigException:\r\n\tMessage: blacklisted and whitelisted models are exactly the same. Found: {'XGBoostClassifier'}.Please remove models from the blacklist or add models to the whitelist.\r\n\r\nThe settings are as follow. 'XGBoostClassifier' is in the whitelist; and backlist is None. Would you please help with the error?\r\n\r\nautoml_settings = {\r\n    \"iteration_timeout_minutes\": 2,\r\n    \"experiment_timeout_minutes\": 20,\r\n    \"enable_early_stopping\": True,\r\n    \"primary_metric\": 'accuracy',\r\n    \"featurization\": 'auto',\r\n    \"verbosity\": logging.INFO,\r\n    \"n_cross_validations\": 5\r\n}\r\n\r\nfrom azureml.train.automl import AutoMLConfig\r\n\r\nautoml_config = AutoMLConfig(task='classification',\r\n                             enable_tf = True,\r\n                             debug_log='automated_ml_errors.log',\r\n                             X=x_train.values,\r\n                             y=y_train.values.flatten(),\r\n                             blacklist_models = None,\r\n                             whitelist_models = ['XGBoostClassifier'],\r\n                             **automl_settings)\r\n\r\n(Note: XGBoostClassifier was installed in the notebook)",
        "Issue_answer_count":8,
        "Issue_self_closed":0.0,
        "Answer_body":"Hello,\r\n\r\nWe're so sorry you've encountered this issue. I've gone ahead and filed a work item to investigate and fix the issue around whitelisting XGBoost. We will reach out again here once a fix is in.\r\n\r\nThank you,\r\nSabina It could be possible that XGBoostClassifier was blacklisted by the system. We can double check if you can share your runId. In the meanwhile, we will improve the error msg for this scenario. Thanks! @waltz2u Can you please run the following line of code in your jupyter notebook and let me know what it says? \r\n\r\n`import xgboost`\r\n\r\nThanks,\r\nSabina Hi @waltz2u, I was able to reproduce and overcome this issue by double checking that import xgboost was installed correctly by trying `import xgboost`.\r\n\r\n\r\n`pip install \"py-xgboost<=0.80\"` fixed it on my end. Can you please try that and let us know if it solved the issue?  Hi @cartacioS and @jialiu103, sorry for the late reply. Yes it works now for me. Thank you very much.\r\n\r\nCD\r\n Will now proceed to close this thread. Thanks. @cartacioS I'm facing the same error, except that I'm kicking off the AutoML run from my local machine, using a remote compute as my aml compute target. Using this issue above, and this [one](https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/313), it seems that I would still need to add xgboost to my env (locally) although technically I won't be using that package in my AutoML exercise? @jadhosn If you do not require XGBoost for your training, you can simply ignore this warning. But if you want XGBoost to be a potential recommended model, then yes you will need to add XGBoost to your local environment regardless of local\/remote compute.",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"error us xgboostclassifi got error configexcept configexcept messag blacklist whitelist model exactli xgboostclassifi remov model blacklist add model whitelist set follow xgboostclassifi whitelist backlist help error automl set iter timeout minut experi timeout minut enabl earli stop true primari metric accuraci featur auto verbos log info cross valid train automl import automlconfig automl config automlconfig task classif enabl true debug log autom error log train valu train valu flatten blacklist model whitelist model xgboostclassifi automl set note xgboostclassifi instal notebook",
        "Issue_preprocessed_content":"us got configexcept configexcept blacklist whitelist model exactli remov model blacklist model whitelist whitelist backlist help import automlconfig automlconfig note",
        "Issue_gpt_summary_original":"The user is encountering an ImportError while trying to import 'AutoMLStep' from 'azureml.train.automl'.",
        "Issue_gpt_summary":"user encount importerror try import automlstep train automl",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/735",
        "Issue_title":"ImportError: cannot import name 'AutoMLStep' from 'azureml.train.automl",
        "Issue_created_time":1578967122000,
        "Issue_closed_time":1582730951000,
        "Issue_body":"ImportError: cannot import name 'AutoMLStep' from 'azureml.train.automl",
        "Issue_answer_count":14,
        "Issue_self_closed":0.0,
        "Answer_body":"@alla15747 Hi, thanks for reaching out to us. Could you please share your environment file so that we can know the details of this issue? @alla15747  please make sure that azureml-train-automl-runtime is installed in your environment if you using sdk>=1.0.76 or azureml-train-automl if using older version I'm running the code on the compute target and not my local machine. SDK 1.0.72\r\nHow to install packages in Azure Devops environment like azureml-train-automl? (base) C:\\Users\\aabdel137>pip freeze\r\nabsl-py==0.8.1\r\nadal==1.2.2\r\nalabaster==0.7.12\r\nanaconda-client==1.7.2\r\nanaconda-navigator==1.9.7\r\nanaconda-project==0.8.3\r\nansiwrap==0.8.4\r\napplicationinsights==0.11.9\r\nasn1crypto==0.24.0\r\nastor==0.8.0\r\nastroid==2.3.1\r\nastropy==3.2.1\r\natomicwrites==1.3.0\r\nattrs==19.3.0\r\nazure-common==1.1.23\r\nazure-graphrbac==0.61.1\r\nazure-mgmt-authorization==0.60.0\r\nazure-mgmt-containerregistry==2.8.0\r\nazure-mgmt-keyvault==2.0.0\r\nazure-mgmt-resource==5.1.0\r\nazure-mgmt-storage==6.0.0\r\nazureml-contrib-interpret==1.0.72\r\nazureml-contrib-notebook==1.0.72\r\nazureml-core==1.0.72\r\nazureml-dataprep==1.1.29\r\nazureml-dataprep-native==13.1.0\r\nazureml-explain-model==1.0.72\r\nazureml-interpret==1.0.72.1\r\nazureml-pipeline==1.0.72\r\nazureml-pipeline-core==1.0.72\r\nazureml-pipeline-steps==1.0.72\r\nazureml-sdk==1.0.72\r\nazureml-telemetry==1.0.72\r\nazureml-train==1.0.72\r\nazureml-train-core==1.0.72\r\nazureml-train-restclients-hyperdrive==1.0.72\r\nazureml-widgets==1.0.72\r\nBabel==2.7.0\r\nbackcall==0.1.0\r\nbackports.functools-lru-cache==1.5\r\nbackports.os==0.1.1\r\nbackports.shutil-get-terminal-size==1.0.0\r\nbackports.tempfile==1.0\r\nbackports.weakref==1.0.post1\r\nbeautifulsoup4==4.7.1\r\nbitarray==0.9.3\r\nbkcharts==0.2\r\nbleach==3.1.0\r\nbokeh==1.2.0\r\nboto==2.49.0\r\nBottleneck==1.2.1\r\ncertifi==2019.6.16\r\ncffi==1.12.3\r\nchardet==3.0.4\r\nClick==7.0\r\ncloudpickle==1.2.1\r\nclyent==1.2.2\r\ncolorama==0.4.1\r\ncomtypes==1.1.7\r\nconda==4.7.10\r\nconda-build==3.18.8\r\nconda-package-handling==1.3.11\r\nconda-verify==3.4.2\r\ncontextlib2==0.5.5\r\ncoverage==4.5.4\r\ncryptography==2.7\r\ncycler==0.10.0\r\nCython==0.29.12\r\ncytoolz==0.10.0\r\ndask==2.1.0\r\ndecorator==4.4.0\r\ndefusedxml==0.6.0\r\ndistributed==2.1.0\r\ndistro==1.4.0\r\ndocker==4.1.0\r\ndocutils==0.14\r\ndotnetcore2==2.1.10\r\nentrypoints==0.3\r\net-xmlfile==1.0.1\r\nfastcache==1.1.0\r\nfilelock==3.0.12\r\nflake8==3.7.9\r\nflake8-formatter-junit-xml==0.0.6\r\nFlask==1.1.1\r\nfusepy==3.0.1\r\nfuture==0.17.1\r\ngast==0.3.2\r\ngevent==1.4.0\r\nglob2==0.7\r\ngoogle-pasta==0.1.7\r\ngreenlet==0.4.15\r\ngrpcio==1.24.3\r\nh5py==2.9.0\r\nheapdict==1.0.0\r\nhtml5lib==1.0.1\r\nidna==2.8\r\nimageio==2.5.0\r\nimagesize==1.1.0\r\nimportlib-metadata==0.23\r\ninterpret-community==0.1.0.3.3\r\ninterpret-core==0.1.18\r\nipykernel==5.1.1\r\nipython==7.6.1\r\nipython-genutils==0.2.0\r\nipywidgets==7.5.0\r\nisodate==0.6.0\r\nisort==4.3.21\r\nitsdangerous==1.1.0\r\njdcal==1.4.1\r\njedi==0.13.3\r\njeepney==0.4.1\r\nJinja2==2.10.1\r\njmespath==0.9.4\r\njoblib==0.13.2\r\njson5==0.8.4\r\njsonpickle==1.2\r\njsonschema==3.0.1\r\njunit-xml==1.8\r\njupyter==1.0.0\r\njupyter-client==5.3.1\r\njupyter-console==6.0.0\r\njupyter-core==4.5.0\r\njupyterlab==1.0.2\r\njupyterlab-server==1.0.0\r\nKeras-Applications==1.0.8\r\nKeras-Preprocessing==1.1.0\r\nkeyring==18.0.0\r\nkiwisolver==1.1.0\r\nkmodes==0.10.1\r\nlazy-object-proxy==1.4.2\r\nlibarchive-c==2.8\r\nllvmlite==0.29.0\r\nlocket==0.2.0\r\nlxml==4.3.4\r\nMarkdown==3.1.1\r\nMarkupSafe==1.1.1\r\nmatplotlib==3.1.0\r\nmccabe==0.6.1\r\nmenuinst==1.4.16\r\nmistune==0.8.4\r\nmkl-fft==1.0.12\r\nmkl-random==1.0.2\r\nmkl-service==2.0.2\r\nmock==3.0.5\r\nmore-itertools==7.2.0\r\nmpmath==1.1.0\r\nmsgpack==0.6.1\r\nmsrest==0.6.10\r\nmsrestazure==0.6.2\r\nmultipledispatch==0.6.0\r\nnavigator-updater==0.2.1\r\nnbconvert==5.5.0\r\nnbformat==4.4.0\r\nndg-httpsclient==0.5.1\r\nnetworkx==2.3\r\nnltk==3.4.4\r\nnose==1.3.7\r\nnotebook==6.0.0\r\nnumba==0.44.1\r\nnumexpr==2.6.9\r\nnumpy==1.16.4\r\nnumpydoc==0.9.1\r\noauthlib==3.1.0\r\nolefile==0.46\r\nopenpyxl==2.6.2\r\npackaging==19.2\r\npandas==0.24.2\r\npandocfilters==1.4.2\r\npapermill==1.2.1\r\nparso==0.5.0\r\npartd==1.0.0\r\npath.py==12.0.1\r\npathlib2==2.3.4\r\npathspec==0.6.0\r\npatsy==0.5.1\r\npep8==1.7.1\r\npickleshare==0.7.5\r\nPillow==6.1.0\r\npkginfo==1.5.0.1\r\npluggy==0.13.0\r\nply==3.11\r\nprometheus-client==0.7.1\r\nprompt-toolkit==2.0.9\r\nprotobuf==3.10.0\r\npsutil==5.6.3\r\npy==1.8.0\r\npy4j==0.10.7\r\npyasn1==0.4.7\r\npycodestyle==2.5.0\r\npycosat==0.6.3\r\npycparser==2.19\r\npycrypto==2.6.1\r\npycurl==7.43.0.3\r\npyflakes==2.1.1\r\nPygments==2.4.2\r\nPyJWT==1.7.1\r\npylint==2.4.2\r\npyodbc==4.0.26\r\npyOpenSSL==19.0.0\r\npyparsing==2.4.2\r\npypiwin32==223\r\npyreadline==2.1\r\npyrsistent==0.14.11\r\nPySocks==1.7.0\r\npyspark==2.4.4\r\npytest==5.2.2\r\npytest-arraydiff==0.3\r\npytest-astropy==0.5.0\r\npytest-cov==2.7.1\r\npytest-doctestplus==0.3.0\r\npytest-openfiles==0.3.2\r\npytest-remotedata==0.3.1\r\npython-dateutil==2.8.0\r\npython-dotenv==0.10.3\r\npytz==2019.1\r\nPyWavelets==1.0.3\r\npywin32==223\r\npywinpty==0.5.5\r\nPyYAML==5.1.1\r\npyzmq==18.0.0\r\nQtAwesome==0.5.7\r\nqtconsole==4.5.1\r\nQtPy==1.8.0\r\nrequests==2.22.0\r\nrequests-oauthlib==1.2.0\r\nrope==0.14.0\r\nruamel-yaml==0.15.46\r\nruamel.yaml==0.15.89\r\nscikit-image==0.15.0\r\nscikit-learn==0.21.2\r\nscipy==1.2.1\r\nseaborn==0.9.0\r\nSecretStorage==3.1.1\r\nSend2Trash==1.5.0\r\nshap==0.29.3\r\nsimplegeneric==0.8.1\r\nsingledispatch==3.4.0.3\r\nsix==1.12.0\r\nsklearn==0.0\r\nsnowballstemmer==1.9.0\r\nsortedcollections==1.1.2\r\nsortedcontainers==2.1.0\r\nsoupsieve==1.8\r\nSphinx==2.1.2\r\nsphinxcontrib-applehelp==1.0.1\r\nsphinxcontrib-devhelp==1.0.1\r\nsphinxcontrib-htmlhelp==1.0.2\r\nsphinxcontrib-jsmath==1.0.1\r\nsphinxcontrib-qthelp==1.0.2\r\nsphinxcontrib-serializinghtml==1.1.3\r\nsphinxcontrib-websupport==1.1.2\r\nspyder==3.3.6\r\nspyder-kernels==0.5.1\r\nSQLAlchemy==1.3.5\r\nstatsmodels==0.10.0\r\nsympy==1.4\r\ntables==3.5.2\r\ntblib==1.4.0\r\ntenacity==5.1.5\r\ntensorboard==1.14.0\r\ntensorflow==1.14.0\r\ntensorflow-estimator==1.14.0\r\ntensorflow-gpu==1.14.0\r\ntermcolor==1.1.0\r\nterminado==0.8.2\r\ntestpath==0.4.2\r\ntextwrap3==0.9.2\r\ntf-estimator-nightly==1.14.0.dev2019031401\r\ntoolz==0.10.0\r\ntornado==6.0.3\r\ntqdm==4.37.0\r\ntraitlets==4.3.2\r\ntyped-ast==1.4.0\r\nunicodecsv==0.14.1\r\nunittest-xml-reporting==2.5.2\r\nurllib3==1.24.2\r\nwcwidth==0.1.7\r\nwebencodings==0.5.1\r\nwebsocket-client==0.56.0\r\nWerkzeug==0.15.4\r\nwidgetsnbextension==3.5.0\r\nwin-inet-pton==1.1.0\r\nwin-unicode-console==0.5\r\nwincertstore==0.2\r\nwrapt==1.11.2\r\nxlrd==1.2.0\r\nXlsxWriter==1.1.8\r\nxlwings==0.15.8\r\nxlwt==1.3.0\r\nzict==1.0.0\r\nzipp==0.6.0\r\n AutoML became a part of default distribution (azureml-sdk) since 1.0.83\r\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/azure-machine-learning-release-notes#2020-01-06\r\n\r\nif your client, that I believe pins the version of azureml sdk packages for the remote environment is 1.0.83, you will have automl on remote. \r\n\r\nIf you want to stay with 1.0.72 you can either reference automl extras azureml-sdk[automl] or explicitly reference azureml-train-automl (prefered).\r\n\r\nI would recommend to do both, upgrade client to the latest version and explicitly reference packages you need for your particular scenario not relying on metapackages like azureml-sdk\r\n\r\nOur reference doc will help you to get a set of the packages needed for your scenario\r\nhttps:\/\/docs.microsoft.com\/en-us\/python\/api\/overview\/azure\/ml\/?view=azure-ml-py\r\n\r\nBy design every AzureML Python SDK package will bring necessary internal dependencies (of course except some corner cases :) )\r\n Thanks Vizhur, do you mind showing an example on how to reference azureml-train-automl in Azure Devops or Portal? \r\nThank you for the links! Not sure about your particular scenario, would you mind to share your ADO scenario so I can think of how to update it? MY scenario is implementing MLOPs example with automl step. Let me try to pull some relevant folks into the thread For AutoML, all the remote dependencies will get taken care of and will match whatever local dependencies are installed, e.g. if you have azureml-train-automl==1.0.72 installed, that version will be installed remotely for the training job.\r\nWe provide 2 clients to submitting these remote jobs currently, a thin client for submitting some types of remote jobs which is included as part of azureml-sdk, and a fuller client which enables more experiences such as Pipeline runs as part of azureml-train-automl. Since it looks like you are trying to use Pipelines, you will need to install the full azureml-train-automl client.\r\n\r\nFurthermore, the namespace for AutoMLStep changed recently, if you are using <1.0.76 the namespace would be \"from azureml.train.automl import AutoMLStep\", for >=1.0.76, you'll want to use \"from azureml.train.automl.runtime import AutoMLStep\" instead. I'm have sdk 1.0.72 installed. And I'm using from azureml.train.automl import AutoMLStep. Is there anyway to check the sdk version on the compute target machine? From your pip freeze, it doesn't look like you have the AutoML SDK installed. For the pipelines experience, you will need to have the SDK installed locally, not just on the target compute. Could you run \"pip install azureml-train-automl\"? @alla15747 \r\nWe will now proceed to close this thread. If there are further questions regarding this matter, please respond here and @YutongTie-MSFT and we will gladly continue the discussion. @SKrupa - Are you running your own code or a particular notebook sample from this repo?\r\n\r\n",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"importerror import automlstep train automl importerror import automlstep train automl",
        "Issue_preprocessed_content":"import automlstep import automlstep",
        "Issue_gpt_summary_original":"The user is encountering an error while trying to import the ML library in an Azure Notebook VM. The error is related to the attribute error of the TensorFlow logging module.",
        "Issue_gpt_summary":"user encount error try import librari azur notebook error relat attribut error tensorflow log modul",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/644",
        "Issue_title":"Error trying to load azureml.train.automl",
        "Issue_created_time":1572995244000,
        "Issue_closed_time":1587086020000,
        "Issue_body":"Hello, receiving the following error in an Azure Notebook VM while trying to import the ML library - \r\n\r\nimport json\r\nimport pickle\r\nimport numpy as np\r\nimport pandas as pd\r\n# error here!!!\r\nfrom azureml.train.automl import AutoMLConfig\r\nfrom sklearn.externals import joblib\r\nfrom azureml.core.model import Model\r\nimport json\r\nimport pickle\r\nimport numpy as np\r\nimport pandas as pd\r\nfrom azureml.train.automl import AutoMLConfig\r\nfrom sklearn.externals import joblib\r\nfrom azureml.core.model import Model\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-2-b8d543bb7111> in <module>\r\n      3 import numpy as np\r\n      4 import pandas as pd\r\n----> 5 from azureml.train.automl import AutoMLConfig\r\n      6 from sklearn.externals import joblib\r\n      7 from azureml.core.model import Model\r\n \r\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/__init__.py in <module>\r\n     23     # Suppress the warnings at the import phase.\r\n     24     warnings.simplefilter(\"ignore\")\r\n---> 25     from ._automl import fit_pipeline\r\n     26     from .automlconfig import AutoMLConfig\r\n     27     from .automl_step import AutoMLStep, AutoMLStepRun\r\n \r\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/_automl.py in <module>\r\n     17 from automl.client.core.runtime.cache_store import CacheStore\r\n     18 from automl.client.core.runtime import logging_utilities as runtime_logging_utilities\r\n---> 19 from azureml.automl.core import data_transformation, fit_pipeline as fit_pipeline_helper\r\n     20 from azureml.automl.core.automl_pipeline import AutoMLPipeline\r\n     21 from azureml.automl.core.data_context import RawDataContext, TransformedDataContext\r\n \r\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/automl\/core\/fit_pipeline.py in <module>\r\n     18 from automl.client.core.common.limit_function_call_exceptions import TimeoutException\r\n     19 from automl.client.core.runtime.datasets import DatasetBase\r\n---> 20 from . import package_utilities, pipeline_run_helper, training_utilities\r\n     21 from .automl_base_settings import AutoMLBaseSettings\r\n     22 from .automl_pipeline import AutoMLPipeline\r\n \r\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/automl\/core\/pipeline_run_helper.py in <module>\r\n     18 from automl.client.core.common.exceptions import ClientException\r\n     19 from automl.client.core.runtime import metrics\r\n---> 20 from automl.client.core.runtime import pipeline_spec as pipeline_spec_module\r\n     21 from automl.client.core.runtime.datasets import DatasetBase\r\n     22 from automl.client.core.runtime.execution_context import ExecutionContext\r\n \r\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/automl\/core\/_vendor\/automl\/client\/core\/runtime\/pipeline_spec.py in <module>\r\n     21 \r\n     22 from automl.client.core.common import constants\r\n---> 23 from automl.client.core.runtime import model_wrappers, tf_wrappers\r\n     24 from automl.client.core.runtime.nimbus_wrappers import AveragedPerceptronBinaryClassifier, \\\r\n     25     AveragedPerceptronMulticlassClassifier, NimbusMlClassifierMixin, NimbusMlRegressorMixin\r\n \r\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/automl\/core\/_vendor\/automl\/client\/core\/runtime\/tf_wrappers.py in <module>\r\n     34 os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\r\n     35 if tf_found:\r\n---> 36     tf.logging.set_verbosity(tf.logging.ERROR)\r\n     37 \r\n     38     OPTIMIZERS = {\r\n \r\nAttributeError: module 'tensorflow' has no attribute 'logging'\r\n",
        "Issue_answer_count":3,
        "Issue_self_closed":0.0,
        "Answer_body":"Do you know which version of tensorflow you are using? \r\n\r\nThis SO question may be applicable: https:\/\/stackoverflow.com\/questions\/55318626\/module-tensorflow-has-no-attribute-logging Hello, Not sure about tensorflow.  This is a \"stock\" Notebook VM that was created last week, so no changes were made to the libraries. Hello,\r\n\r\nSorry for the inconvenience. This issue has been fixed since v1.0.72 but, it's related to the fact that tf==2.0. is installed by default on the notebook instance. It broke other things too as TF2.0 has many changes in its API. Your two options are to upgrade to v1.0.72+ or use the following code to downgrade tensorflow.\r\n\r\npip install -U tensorflow-gpu==1.14.0 \r\ntensorflow==estimator==1.14.0 \r\n\r\nThat should fix it for you.",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"error try load train automl hello receiv follow error azur notebook try import librari import json import pickl import numpi import panda error train automl import automlconfig sklearn extern import joblib core model import model import json import pickl import numpi import panda train automl import automlconfig sklearn extern import joblib core model import model attributeerror traceback recent import numpi import panda train automl import automlconfig sklearn extern import joblib core model import model anaconda env lib python site packag train automl init suppress warn import phase warn simplefilt ignor automl import fit pipelin automlconfig import automlconfig automl step import automlstep automlsteprun anaconda env lib python site packag train automl automl automl client core runtim cach store import cachestor automl client core runtim import log util runtim log util automl core import data transform fit pipelin fit pipelin helper automl core automl pipelin import automlpipelin automl core data context import rawdatacontext transformeddatacontext anaconda env lib python site packag automl core fit pipelin automl client core common limit function except import timeoutexcept automl client core runtim dataset import datasetbas import packag util pipelin run helper train util automl base set import automlbaseset automl pipelin import automlpipelin anaconda env lib python site packag automl core pipelin run helper automl client core common except import clientexcept automl client core runtim import metric automl client core runtim import pipelin spec pipelin spec modul automl client core runtim dataset import datasetbas automl client core runtim execut context import executioncontext anaconda env lib python site packag automl core vendor automl client core runtim pipelin spec automl client core common import constant automl client core runtim import model wrapper wrapper automl client core runtim nimbu wrapper import averagedperceptronbinaryclassifi averagedperceptronmulticlassclassifi nimbusmlclassifiermixin nimbusmlregressormixin anaconda env lib python site packag automl core vendor automl client core runtim wrapper environ cpp min log level log set verbos log error optim attributeerror modul tensorflow attribut log",
        "Issue_preprocessed_content":"try load receiv azur try import librari import json import pickl import numpi import panda import automlconfig import joblib import model import json import pickl import numpi import panda import automlconfig import joblib import model traceback import numpi import panda import automlconfig import joblib import model warn import phase import automlconfig import automlconfig import automlstep automlsteprun import cachestor import import import automlpipelin import rawdatacontext import timeoutexcept import datasetbas import import import automlpipelin import clientexcept import metric import import datasetbas import executioncontext import constant import import optim modul tensorflow",
        "Issue_gpt_summary_original":"The user is encountering a \"ModuleNotFoundError\" when attempting to import the \"ExplainationDashboard\" module from \"azureml.contrib.interpret\" in build 1.0.72, despite having installed and updated the SDK without any errors. The failing line is in a sample notebook for \"how to use\"\/explain-model\/tabular-data\/explain-regression-local.ipynb.",
        "Issue_gpt_summary":"user encount modulenotfounderror attempt import explainationdashboard modul contrib interpret build despit have instal updat sdk error fail line sampl notebook us explain model tabular data explain regress local ipynb",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/639",
        "Issue_title":"azureml.contrib.interpret - ModuleNotFoundError - build 1.0.72",
        "Issue_created_time":1572788594000,
        "Issue_closed_time":1573060395000,
        "Issue_body":"I've installed and updated the sdk yet when attempting to import the module for the ExplainationDashboard i keep getting the error that the interpret module does not exist.\r\ni am running build 1.0.72 and following the sample in 'how to use\"\/explain-model\/tabular-data\/explain-regression-local.ipynb \r\nthe failing line in the sample notebook is:\r\n**from azureml.contrib.interpret.visualize import ExplanationDashboard**\r\n**\"ModuleNotFoundError: No module named 'azureml.contrib.interpret' \"**\r\nthis is the update command i ran:\r\npip install --upgrade azureml-sdk[explain,automl,contrib] \r\n(the install ran fine - no errors)\r\njim",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"azureml-contrib-interpret is not a part of azureml-sdk contrib extras. Please install it separately",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"contrib interpret modulenotfounderror build instal updat sdk attempt import modul explainationdashboard get error interpret modul exist run build follow sampl us explain model tabular data explain regress local ipynb fail line sampl notebook contrib interpret visual import explanationdashboard modulenotfounderror modul name contrib interpret updat command ran pip instal upgrad sdk explain automl contrib instal ran fine error jim",
        "Issue_preprocessed_content":"build updat sdk import modul explainationdashboard interpret modul exist build sampl fail line sampl import explanationdashboard modul name updat ran pip sdk ran fine jim",
        "Issue_gpt_summary_original":"The user is encountering an error while using Azureml Automl, specifically in the azureml.PipelineStep automl step. The error message is \"Error: Null\" and the user is unsure how to interpret it. The error occurs consistently when the dataset has more than 1200 features, but works fine with fewer features. The user is questioning if there is a limitation with the number of features allowed.",
        "Issue_gpt_summary":"user encount error automl specif pipelinestep automl step error messag error null user unsur interpret error occur consist dataset featur work fine fewer featur user question limit number featur allow",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/534",
        "Issue_title":"Azureml Automl \"Error: Null\" Vague Error",
        "Issue_created_time":1566233711000,
        "Issue_closed_time":1581034133000,
        "Issue_body":"I'm not exactly sure on how to interpret this and what to refine. The error I'm getting is in the azureml.PipelineStep automl step. Here is the [link](https:\/\/mlworkspace.azure.ai\/portal\/subscriptions\/ff2e23ae-7d7c-4cbd-99b8-116bb94dca6e\/resourceGroups\/RG-ITSMLTeam-Dev\/providers\/Microsoft.MachineLearningServices\/workspaces\/avadevitsmlsvc\/experiments\/deal-deal-nema\/runs\/7abe9617-ac79-413b-8843-7fd3878313f0).\r\n\r\nWhen my dataset has more than ~1200 features, I consistently get this error, but when there are fewer features it works fine. Is there some limitation here?",
        "Issue_answer_count":5,
        "Issue_self_closed":1.0,
        "Answer_body":"Hi Nema. Unfortunately I don't have access to your workspace. Would you provide more details on the failed experiment such as experiment\/pipeline id so that I can take a look at the logs of it? Hi Sonny, here is the run id: `eb6f111d-1251-40d2-b745-e3c4fbb31fcf` Thank you for the runid. I found automl setup has been timed out after some time. I will work with automl team for more details.  It seems to have been a one-off random occurrence. Considering solved. Somehow I lost track on this. You can let me know if you have any further issues.  ",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"automl error null vagu error exactli sure interpret refin error get pipelinestep automl step link http mlworkspac azur portal subscript ffeae cbd bbdcae resourcegroup itsmlteam dev provid microsoft machinelearningservic workspac avadevitsmlsvc experi deal deal nema run ab fdf dataset featur consist error fewer featur work fine limit",
        "Issue_preprocessed_content":"automl vagu exactli sure interpret refin pipelinestep automl step dataset featur consist fewer featur work fine limit",
        "Issue_gpt_summary_original":"The user is unable to register a model using Jupyter Notebook and is receiving an error message stating \"HttpOperationError: Operation returned an invalid status code 'Service invocation failed!Request: GET https:\/\/cert-westeurope.experiments.azureml.net\/rp\/workspaces'\". The code being used to register the model is provided in the post.",
        "Issue_gpt_summary":"user unabl regist model jupyt notebook receiv error messag state httpoperationerror oper return invalid statu code servic invoc fail request http cert westeurop experi net workspac code regist model provid post",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/518",
        "Issue_title":"No name 'opendatasets' in module 'azureml' Error",
        "Issue_created_time":1565216029000,
        "Issue_closed_time":1565217619000,
        "Issue_body":"Hi,\r\nI was trying to follow this documentation: https:\/\/azure.microsoft.com\/en-us\/services\/open-datasets\/catalog\/noaa-integrated-surface-data\/ (Go to \"Data access\" tab)to use opendatasets module to access historical weather data. But it gives me the error message `No name 'opendatasets' in module 'azureml'`. \r\nI tried `pip install azureml-sdk[opendatasets]` as well, it shows `WARNING: azureml-sdk 1.0.55 does not provide the extra 'opendatasets'`.\r\nDo you know how to use the opendatasets module in azureml?\r\n\r\nThanks!",
        "Issue_answer_count":2,
        "Issue_self_closed":1.0,
        "Answer_body":"Find the solution, maybe because `opendatasets` is a preview module, so it is not included in azureml sdk yet. You can download through pip `pip install azureml-opendatasets` in your env. > pip install azureml-opendatasets\r\n\r\nThanks, was looking for the solution, this worked !! However, I had another error \" [WinError 5] Access is denied:\" This was solved by adding --user at the end of your command.",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"opendataset modul error try follow document http azur microsoft com servic open dataset catalog noaa integr surfac data data access tab us opendataset modul access histor weather data give error messag opendataset modul tri pip instal sdk opendataset show warn sdk provid extra opendataset know us opendataset modul thank",
        "Issue_preprocessed_content":"opendataset modul try document us opendataset modul histor weather data give tri show know us opendataset modul thank",
        "Issue_gpt_summary_original":"The user encountered a 502 Bad Gateway error after running a Tesla K80 compute instance on Azure ML and attempting to connect with VSCode on day 2. The error message suggests that the target may not be in a running state.",
        "Issue_gpt_summary":"user encount bad gatewai error run tesla comput instanc attempt connect vscode dai error messag suggest target run state",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/243",
        "Issue_title":"Unable to register the model using Jupyter Notebook with error message: \"HttpOperationError: Operation returned an invalid status code 'Service invocation failed!Request: GET https:\/\/cert-westeurope.experiments.azureml.net\/rp\/workspaces'\"",
        "Issue_created_time":1552039718000,
        "Issue_closed_time":1587148100000,
        "Issue_body":"> from azureml.core.model import Model\r\nmodel = Model.register(model_path = MODEL_FILENAME,\r\n                       model_name = \"MyONNXmodel\",\r\n                       tags = {\"onnx\":\"V0\"},\r\n                       description = \"test\",\r\n                       workspace = ws)\r\nthis is the python code I am using to register the model.",
        "Issue_answer_count":2,
        "Issue_self_closed":0.0,
        "Answer_body":"Thanks for your report. Are you still experiencing this issue? Have you posted on the forum https:\/\/social.msdn.microsoft.com\/Forums\/azure\/en-US\/home?forum=AzureMachineLearningService? Thank you for reaching out to us.  We see our answer this issue was delayed. Our apologies. We did not receive a response to our response, so will close this issue for now. Should you need further assistance, please submit a post on this forum. We are happy to help.\r\n",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"unabl regist model jupyt notebook error messag httpoperationerror oper return invalid statu code servic invoc fail request http cert westeurop experi net workspac core model import model model model regist model path model filenam model myonnxmodel tag onnx descript test workspac python code regist model",
        "Issue_preprocessed_content":"unabl regist model jupyt oper return invalid statu code servic invoc fail request import model model tag descript test workspac python code regist model",
        "Issue_gpt_summary_original":"The user is unable to login to Azure ML extension in VSCode due to an unknown error while retrieving subscriptions from Azure Account extension. The error occurs consistently and the user is using VSCode version 1.68.1 on Linux OS version 5.15.0-1022-azure.",
        "Issue_gpt_summary":"user unabl login extens vscode unknown error retriev subscript azur account extens error occur consist user vscode version linux version azur",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/vscode-tools-for-ai\/issues\/1850",
        "Issue_title":"502 Bad Gateway error after running Tesla K80 compute instance on azure ML",
        "Issue_created_time":1671822949000,
        "Issue_closed_time":null,
        "Issue_body":"<!-- IMPORTANT: Please be sure to remove any private information before submitting. -->\r\n\r\nDoes this occur consistently? YES <!-- TODO: Type Yes or No -->\r\nRepro steps:\r\n<!-- TODO: Share the steps needed to reliably reproduce the problem. Please include actual and expected results. -->\r\n\r\n1. Create compute instance in azure ML (Tesla K80) and add schedule\r\n2. Connect with VSCode on day 2. \r\n\r\nAction: Resolver.resolve\r\nError type: ce\r\nError Message: Failed to connect to target. Make sure that it exists and is in a running state (Error: Invalid response: 502 Bad Gateway)\r\n\r\n\r\nVersion: 0.22.0\r\nOS: darwin\r\nOS Release: 22.1.0\r\nProduct: Visual Studio Code\r\nProduct Version: 1.74.1\r\nLanguage: en\r\n\r\n<details>\r\n<summary>Call Stack<\/summary>\r\n\r\n```\r\nce.NotAvailable extensionHostProcess.js:92:17513\r\nb.handle400BadRequestAnd502BadGateway extension.js:2:1949684\r\nb.handleError extension.js:2:1948588\r\no.value extension.js:2:1911817\r\nextension.js:2:1960308\r\n```\r\n\r\n<\/details>\r\n",
        "Issue_answer_count":3,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"bad gatewai error run tesla comput instanc occur consist ye repro step creat comput instanc tesla add schedul connect vscode dai action resolv resolv error type error messag fail connect target sure exist run state error invalid respons bad gatewai version darwin releas product visual studio code product version languag stack notavail extensionhostprocess handlebadrequestandbadgatewai extens handleerror extens valu extens extens",
        "Issue_preprocessed_content":"bad gatewai tesla comput instanc consist ye repro step todo share step reliabl reproduc problem includ actual expect result creat comput instanc schedul vscode dai action type fail target sure exist state version darwin releas product visual studio code product version languag detail detail",
        "Issue_gpt_summary_original":"The user is facing an issue while connecting to VScode to AzureML. The error message states \"Unknown Error retrieving subscriptions from Azure Account extension\". The user has provided the version, OS, product, and language details along with the call stack. However, the user has not provided any reproducible steps to identify the root cause of the issue.",
        "Issue_gpt_summary":"user face issu connect vscode error messag state unknown error retriev subscript azur account extens user provid version product languag detail stack user provid reproduc step identifi root caus issu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/vscode-tools-for-ai\/issues\/1817",
        "Issue_title":"Unable to login in Azure ML extension in VSCode",
        "Issue_created_time":1669213419000,
        "Issue_closed_time":null,
        "Issue_body":"<!-- IMPORTANT: Please be sure to remove any private information before submitting. -->\r\n\r\nDoes this occur consistently? <!-- TODO: Type Yes or No -->\r\nRepro steps:\r\n<!-- TODO: Share the steps needed to reliably reproduce the problem. Please include actual and expected results. -->\r\n\r\n1.\r\n2.\r\n\r\nAction: azureAccount.onSessionsChanged\r\nError type: 123\r\nError Message: Unknown Error retrieving susbcriptions from Azure Account extension\r\n\r\n\r\nVersion: 0.22.0\r\nOS: linux\r\nOS Release: 5.15.0-1022-azure\r\nProduct: Visual Studio Code\r\nProduct Version: 1.68.1\r\nLanguage: en\r\n\r\n<details>\r\n<summary>Call Stack<\/summary>\r\n\r\n```\r\nb.<anonymous> extension.js:2:1976096\r\ns extension.js:2:1972783\r\n```\r\n\r\n<\/details>\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"unabl login extens vscode occur consist repro step action azureaccount onsessionschang error type error messag unknown error retriev susbcript azur account extens version linux releas azur product visual studio code product version languag stack extens extens",
        "Issue_preprocessed_content":"unabl login extens vscode consist repro step todo share step reliabl reproduc problem includ actual expect result action type unknown retriev susbcript azur extens version linux releas product visual studio code product version languag detail detail",
        "Issue_gpt_summary_original":"The user is encountering an error while trying to view properties of an ML default project in Visual Studio Azure ML extension. The error message states that the URI cannot begin with two slash characters if it does not contain an authority component.",
        "Issue_gpt_summary":"user encount error try view properti default project visual studio extens error messag state uri begin slash charact contain author compon",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/vscode-tools-for-ai\/issues\/1797",
        "Issue_title":"connecting to VScode to AzureML",
        "Issue_created_time":1668197837000,
        "Issue_closed_time":null,
        "Issue_body":"<!-- IMPORTANT: Please be sure to remove any private information before submitting. -->\r\n\r\nDoes this occur consistently? <!-- TODO: Type Yes or No -->\r\nRepro steps:\r\n<!-- TODO: Share the steps needed to reliably reproduce the problem. Please include actual and expected results. -->\r\n\r\n1.\r\n2.\r\n\r\nAction: azureAccount.onSessionsChanged\r\nError type: 123\r\nError Message: Unknown Error retrieving susbcriptions from Azure Account extension\r\n\r\n\r\nVersion: 0.20.0\r\nOS: win32\r\nOS Release: 10.0.19044\r\nProduct: Visual Studio Code\r\nProduct Version: 1.72.2\r\nLanguage: en\r\n\r\n<details>\r\n<summary>Call Stack<\/summary>\r\n\r\n```\r\nb.<anonymous> extension.js:2:1975925\r\ns extension.js:2:1972612\r\n```\r\n\r\n<\/details>\r\n\r\n",
        "Issue_answer_count":3,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"connect vscode occur consist repro step action azureaccount onsessionschang error type error messag unknown error retriev susbcript azur account extens version win releas product visual studio code product version languag stack extens extens",
        "Issue_preprocessed_content":"vscode consist repro step todo share step reliabl reproduc problem includ actual expect result action type unknown retriev susbcript azur extens version win releas product visual studio code product version languag detail detail",
        "Issue_gpt_summary_original":"The user is experiencing multiple consecutive sign-in requests from Azure ML plugin VS Code, and is encountering an error message \"Unknown Error retrieving subscriptions from Azure Account extension\". The user has provided details about the version, OS, and product version. However, the user has not provided any reproducible steps to help diagnose the issue.",
        "Issue_gpt_summary":"user experienc multipl consecut sign request plugin code encount error messag unknown error retriev subscript azur account extens user provid detail version product version user provid reproduc step help diagnos issu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/vscode-tools-for-ai\/issues\/1783",
        "Issue_title":"Visual Studio Azure ML extension error on \"View Properties\" ",
        "Issue_created_time":1667838269000,
        "Issue_closed_time":null,
        "Issue_body":"To reproduce the issue:\r\nRight click on ML default project in left hand bar.\r\nFrom the menu click \"View Properties\" and getting:\r\n\r\n[UriError]: If a URI does not contain an authority component, then the path cannot begin with two slash characters (\"\/\/\")",
        "Issue_answer_count":3,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"visual studio extens error view properti reproduc issu right click default project left hand bar menu click view properti get urierror uri contain author compon path begin slash charact",
        "Issue_preprocessed_content":"visual studio extens view properti reproduc right click default project left hand bar menu click view properti uri contain author compon path begin slash charact",
        "Issue_gpt_summary_original":"The user is facing issues while signing into Azure ML using VSCode with the latest version. The error message states \"Unknown Error retrieving subscriptions from Azure Account extension\". The user has provided the version, OS, product, and language details along with the call stack. The user has not provided any reproducible steps.",
        "Issue_gpt_summary":"user face issu sign vscode latest version error messag state unknown error retriev subscript azur account extens user provid version product languag detail stack user provid reproduc step",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/vscode-tools-for-ai\/issues\/1754",
        "Issue_title":"Mutliple consecutive sign-in requests from Azure ML plugin VS Code",
        "Issue_created_time":1665696667000,
        "Issue_closed_time":null,
        "Issue_body":"<!-- IMPORTANT: Please be sure to remove any private information before submitting. -->\r\n\r\nDoes this occur consistently? <!-- TODO: Type Yes or No -->\r\nRepro steps:\r\n<!-- TODO: Share the steps needed to reliably reproduce the problem. Please include actual and expected results. -->\r\n\r\n1.\r\n2.\r\n\r\nAction: azureAccount.onSessionsChanged\r\nError type: 123\r\nError Message: Unknown Error retrieving susbcriptions from Azure Account extension\r\n\r\n\r\nVersion: 0.20.0\r\nOS: linux\r\nOS Release: 5.15.0-1017-azure\r\nProduct: Visual Studio Code\r\nProduct Version: 1.72.2\r\nLanguage: en\r\n\r\n<details>\r\n<summary>Call Stack<\/summary>\r\n\r\n```\r\nb.<anonymous> extension.js:2:1975925\r\ns extension.js:2:1972612\r\n```\r\n\r\n<\/details>\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"mutlipl consecut sign request plugin code occur consist repro step action azureaccount onsessionschang error type error messag unknown error retriev susbcript azur account extens version linux releas azur product visual studio code product version languag stack extens extens",
        "Issue_preprocessed_content":"mutlipl consecut request plugin code consist repro step todo share step reliabl reproduc problem includ actual expect result action type unknown retriev susbcript azur extens version linux releas product visual studio code product version languag detail detail",
        "Issue_gpt_summary_original":"The user is encountering an error while working with Azure ML Studio on VSCode. The error message is \"Unknown Error retrieving subscriptions from Azure Account extension\" and the error type is 123. The user has provided the version, OS, product, product version, and language details along with the call stack. The user has not provided any reproducible steps.",
        "Issue_gpt_summary":"user encount error work studio vscode error messag unknown error retriev subscript azur account extens error type user provid version product product version languag detail stack user provid reproduc step",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/vscode-tools-for-ai\/issues\/1745",
        "Issue_title":"Problem signing into Azure ML using VSCode with latest version",
        "Issue_created_time":1664990324000,
        "Issue_closed_time":null,
        "Issue_body":"<!-- IMPORTANT: Please be sure to remove any private information before submitting. -->\r\n\r\nDoes this occur consistently? <!-- TODO: Type Yes or No -->\r\nRepro steps:\r\n<!-- TODO: Share the steps needed to reliably reproduce the problem. Please include actual and expected results. -->\r\n\r\n1.\r\n2.\r\n\r\nAction: azureAccount.onSessionsChanged\r\nError type: 123\r\nError Message: Unknown Error retrieving susbcriptions from Azure Account extension\r\n\r\n\r\nVersion: 0.20.0\r\nOS: win32\r\nOS Release: 10.0.19044\r\nProduct: Visual Studio Code\r\nProduct Version: 1.71.2\r\nLanguage: en\r\n\r\n<details>\r\n<summary>Call Stack<\/summary>\r\n\r\n```\r\nb.<anonymous> extension.js:2:1975925\r\ns extension.js:2:1972612\r\n```\r\n\r\n<\/details>\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"problem sign vscode latest version occur consist repro step action azureaccount onsessionschang error type error messag unknown error retriev susbcript azur account extens version win releas product visual studio code product version languag stack extens extens",
        "Issue_preprocessed_content":"problem sign vscode latest version consist repro step todo share step reliabl reproduc problem includ actual expect result action type unknown retriev susbcript azur extens version win releas product visual studio code product version languag detail detail",
        "Issue_gpt_summary_original":"The user is encountering an error while using the Azure Machine Learning extension in Visual Studio Code - Insiders. The error occurs consistently and asks the user to sign in again even after a successful sign-in. The error message is \"Unknown Error retrieving subscriptions from Azure Account extension\" with an error type of 123. The user has provided the version, OS, product, and language details along with the call stack.",
        "Issue_gpt_summary":"user encount error extens visual studio code insid error occur consist ask user sign success sign error messag unknown error retriev subscript azur account extens error type user provid version product languag detail stack",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/vscode-tools-for-ai\/issues\/1737",
        "Issue_title":"Working with Azure ML Studio on VSCode",
        "Issue_created_time":1664468718000,
        "Issue_closed_time":null,
        "Issue_body":"<!-- IMPORTANT: Please be sure to remove any private information before submitting. -->\r\n\r\nDoes this occur consistently? <!-- TODO: Type Yes or No -->\r\nRepro steps:\r\n<!-- TODO: Share the steps needed to reliably reproduce the problem. Please include actual and expected results. -->\r\n\r\n1.\r\n2.\r\n\r\nAction: azureAccount.onSessionsChanged\r\nError type: 123\r\nError Message: Unknown Error retrieving susbcriptions from Azure Account extension\r\n\r\n\r\nVersion: 0.18.0\r\nOS: darwin\r\nOS Release: 21.6.0\r\nProduct: Visual Studio Code\r\nProduct Version: 1.71.2\r\nLanguage: en\r\n\r\n<details>\r\n<summary>Call Stack<\/summary>\r\n\r\n```\r\nb.<anonymous> extension.js:2:2030116\r\ns extension.js:2:2026803\r\n```\r\n\r\n<\/details>\r\n",
        "Issue_answer_count":2,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"work studio vscode occur consist repro step action azureaccount onsessionschang error type error messag unknown error retriev susbcript azur account extens version darwin releas product visual studio code product version languag stack extens extens",
        "Issue_preprocessed_content":"work studio vscode consist repro step todo share step reliabl reproduc problem includ actual expect result action type unknown retriev susbcript azur extens version darwin releas product visual studio code product version languag detail detail",
        "Issue_gpt_summary_original":"The user needs to update the asset labels in Treeview to match Azure ML Studio, specifically renaming Experiments to Jobs and Datasets to Data. Other changes may also be considered.",
        "Issue_gpt_summary":"user need updat asset label treeview match studio specif renam experi job dataset data chang consid",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/vscode-tools-for-ai\/issues\/1714",
        "Issue_title":"I keep on getting this error continuously for Azure Machine Learning extension",
        "Issue_created_time":1662929331000,
        "Issue_closed_time":null,
        "Issue_body":"<!-- IMPORTANT: Please be sure to remove any private information before submitting. -->\r\n\r\nDoes this occur consistently? <!-- TODO: Type Yes or No -->\r\nRepro steps:\r\n<!-- TODO: Share the steps needed to reliably reproduce the problem. Please include actual and expected results. -->\r\n\r\n1. Azure sign in\r\n2. Sign in using Azure portal. You get the sign in successful, you may close the window message, but Azure asks to sign in again.\r\n\r\nAction: azureAccount.onSessionsChanged\r\nError type: 123\r\nError Message: Unknown Error retrieving susbcriptions from Azure Account extension\r\n\r\n\r\nVersion: 0.17.2022090809\r\nOS: win32\r\nOS Release: 10.0.19042\r\nProduct: Visual Studio Code - Insiders\r\nProduct Version: 1.72.0-insider\r\nLanguage: en\r\n\r\n<details>\r\n<summary>Call Stack<\/summary>\r\n\r\n```\r\nb.<anonymous> extension.js:2:2030116\r\ns extension.js:2:2026803\r\n```\r\n\r\n<\/details>\r\n",
        "Issue_answer_count":5,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"get error continu extens occur consist repro step azur sign sign azur portal sign success close window messag azur ask sign action azureaccount onsessionschang error type error messag unknown error retriev susbcript azur account extens version win releas product visual studio code insid product version insid languag stack extens extens",
        "Issue_preprocessed_content":"continu extens consist repro step todo share step reliabl reproduc problem includ actual expect result azur sign sign azur portal sign close window azur ask sign action type unknown retriev susbcript azur extens version win releas product visual studio code insid product version languag detail detail",
        "Issue_gpt_summary_original":"The user is unable to use Azure ML features when remotely connected to a compute due to a change in the vscode-azureml-remote extension, which is no longer supported in the web or codespaces. The main extension is also unavailable in these contexts, but changing the dependency should resolve the issue.",
        "Issue_gpt_summary":"user unabl us featur remot connect comput chang vscode remot extens longer support web codespac main extens unavail context chang depend resolv issu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/vscode-tools-for-ai\/issues\/1691",
        "Issue_title":"Update Treeview asset labels to match Azure ML Studio.",
        "Issue_created_time":1661895451000,
        "Issue_closed_time":1663956142000,
        "Issue_body":"In particular:\r\n- Experiments needs to be renamed to Jobs\r\n- Datasets needs to be renamed to Data\r\n\r\nFurther changes probably aren't absolutely necessary right now, but should be considered as well. See #616.",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"updat treeview asset label match studio particular experi need renam job dataset need renam data chang probabl aren absolut necessari right consid",
        "Issue_preprocessed_content":"updat label match studio particular experi renam job dataset renam data chang probabl aren absolut right consid",
        "Issue_gpt_summary_original":"The AzureML extension in VS Code (Insiders) prompts users to login twice when the user is signed out and reloads VS Code. This behavior is disruptive and unnecessary, and no other extensions for AWS or Azure do this.",
        "Issue_gpt_summary":"extens code insid prompt user login twice user sign reload code behavior disrupt unnecessari extens aw azur",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/vscode-tools-for-ai\/issues\/1655",
        "Issue_title":"Can't use Azure ML features when remotely connected to a compute",
        "Issue_created_time":1661811043000,
        "Issue_closed_time":1665527881000,
        "Issue_body":"Since we changed the vscode-azureml-remote extension to be of UI type it is not supported anymore in the web or codespaces.\r\n\r\nGiven that main extension depends on vscode-azureml-remote, main is also unavailable in the web or codespaces.\r\n\r\nChanging the dependency should enable the main extension in the web context again.",
        "Issue_answer_count":2,
        "Issue_self_closed":0.0,
        "Answer_body":"Seems to work when remotely connected via VS Code desktop, but it definitely doesn't work when connected via vscode.dev. The azure ml remote extension is disabled in this case. Seems like we should be able to support this. Yes, this is only on web platforms like vscode.dev or codespaces.",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"us featur remot connect comput chang vscode remot extens type support anymor web codespac given main extens depend vscode remot main unavail web codespac chang depend enabl main extens web context",
        "Issue_preprocessed_content":"us featur remot comput chang extens type anymor web codespac given main extens depend main unavail web codespac chang depend enabl main extens web context",
        "Issue_gpt_summary_original":"The user is unable to run and debug experiments locally on AzureML extension to VS Code version 0.10.0 as the option is not available in the settings. The user had to downgrade to version 0.6x to access the option. The current version also lacks documentation on the issue.",
        "Issue_gpt_summary":"user unabl run debug experi local extens code version option avail set user downgrad version access option current version lack document issu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/vscode-tools-for-ai\/issues\/1627",
        "Issue_title":"AzureML Prompts twice to login when VS Code (Insiders) loads",
        "Issue_created_time":1659626460000,
        "Issue_closed_time":null,
        "Issue_body":"## Expected Behavior\r\nIf the user is logged out, the AML extension should not prompt to login until the user specifically tries to run an AzureML command. Prompting when VS Code loads is disruptive and unnecessary, and no other extensions for AWS or Azure do this.\r\n\r\n## Actual Behavior\r\nIf you are signed out of the Azure ML extension and reload VS Code, you are prompted to login when it loads (Issue #1). If you click cancel, you are prompted again (#2). \r\n\r\n## Steps to Reproduce the Problem\r\n  1. Install the Azure ML Extension\r\n  2. Login\r\n  3. Logout\r\n  4. Reload VS Code\r\n  5. Click \"Cancel\" when prompted to login\r\n\r\n\r\n## Specifications\r\nAzure ML Extension Version 0.16.0\r\n \r\nVersion: 1.70.0-insider (Universal)\r\nCommit: da76f93349a72022ca4670c1b84860304616aaa2\r\nDate: 2022-08-03T05:55:27.651Z (1 day ago)\r\nElectron: 18.3.5\r\nChromium: 100.0.4896.160\r\nNode.js: 16.13.2\r\nV8: 10.0.139.17-electron.0\r\nOS: Darwin x64 21.6.0\r\n\r\n\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"prompt twice login code insid load expect behavior user log aml extens prompt login user specif tri run command prompt code load disrupt unnecessari extens aw azur actual behavior sign extens reload code prompt login load issu click cancel prompt step reproduc problem instal extens login logout reload code click cancel prompt login specif extens version version insid univers commit dafacacbaaa date dai ago electron chromium node electron darwin",
        "Issue_preprocessed_content":"prompt twice login code load expect behavior user aml extens prompt login user tri run prompt code load disrupt extens aw azur actual behavior sign extens reload code prompt login load click cancel prompt step reproduc problem extens login logout reload code click cancel prompt login specif extens version version date electron chromium darwin",
        "Issue_gpt_summary_original":"The user is encountering an issue with the error message displayed when attempting to execute a YAML that is not related to Azure ML. The current error message includes an option to report the issue, which is misleading. The user suggests removing the report issue button for this scenario.",
        "Issue_gpt_summary":"user encount issu error messag displai attempt execut yaml relat current error messag includ option report issu mislead user suggest remov report issu button scenario",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/vscode-tools-for-ai\/issues\/1589",
        "Issue_title":"Run and debug experiments locally - azureML.CLI Compatibility Mode for CLI v1 - cannot find",
        "Issue_created_time":1654678830000,
        "Issue_closed_time":1654701310000,
        "Issue_body":"## Expected Behavior\r\nIt seems new version on AzureML extension to VS Code doesn't have this option in settings. I needed to downgrade to 0.6x.\r\n\r\n## Actual Behavior\r\nCurrent version 0.10.0 doesn't have the option. Cannot locally debug or documentation doesn't provide info about that.\r\n\r\n## Specifications\r\n\r\n  - Version: 0.10.0\r\n  - Platform: VS Code, Windows\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"@michalmar We have completely deprecated the v1 CLI Compatibility mode settings from v0.8.0 onwards and v2 mode will be the way going forward :).",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"run debug experi local cli compat mode cli expect behavior new version extens code option set need downgrad actual behavior current version option local debug document provid info specif version platform code window",
        "Issue_preprocessed_content":"run debug experi cli compat mode cli expect behavior new version extens code option downgrad actual behavior version option debug document provid info specif version platform code window",
        "Issue_gpt_summary_original":"The user is encountering a reoccurring error message when opening a remote connection to Azure Machine Learning Compute Instance. The error message is related to a failed request to a specific URL and is causing annoyance to the user. The error type is REQUEST_SEND_ERROR and the user is running Visual Studio Code version 1.66.1 on a Linux OS.",
        "Issue_gpt_summary":"user encount reoccur error messag open remot connect comput instanc error messag relat fail request specif url caus annoy user error type request send error user run visual studio code version linux",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/vscode-tools-for-ai\/issues\/1588",
        "Issue_title":"Improve the error message when trying to execute a YAML that is not Azure ML realted",
        "Issue_created_time":1654285462000,
        "Issue_closed_time":1655835283000,
        "Issue_body":"Currently the customer is shown an error message but also has the option to report an issue which is misleading, we should remove the report issue button for this scenario.",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"improv error messag try execut yaml realt current custom shown error messag option report issu mislead remov report issu button scenario",
        "Issue_preprocessed_content":"improv try execut yaml realt custom shown option report mislead remov report scenario",
        "Issue_gpt_summary_original":"The user encountered an error while trying to add the AzureML extension on an OpenShift cluster. The error message indicates that the operation failed due to an inability to get the status from the local CRD with the error: {Error: Retry for given duration didn't get any results with err {status not populated}}.",
        "Issue_gpt_summary":"user encount error try add extens openshift cluster error messag indic oper fail inabl statu local crd error error retri given durat result err statu popul",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/vscode-tools-for-ai\/issues\/1541",
        "Issue_title":"Reoccurring error on opening connection to Azure Machine Learning Compute Instance",
        "Issue_created_time":1649744320000,
        "Issue_closed_time":1652117002000,
        "Issue_body":"<!-- IMPORTANT: Please be sure to remove any private information before submitting. -->\r\n\r\nDoes this occur consistently? <!-- TODO: Type Yes or No --> Yes\r\nRepro steps:\r\n<!-- TODO: Share the steps needed to reliably reproduce the problem. Please include actual and expected results. -->\r\n\r\n1. Open remote connection to Azure Machine Learning Compute Instance\r\n\r\nThis does not seem to cause any issues, but it's annoying to see the error message every time.\r\n\r\nAction: azureAccount.onSubscriptionsChanged\r\nError type: REQUEST_SEND_ERROR\r\nError Message: request to redacted:url failed, reason: getaddrinfo ENOTFOUND redacted:idworkspace.westeurope.api.azureml.ms\r\n\r\n\r\nVersion: 0.8.2\r\nOS: linux\r\nOS Release: 5.4.0-1068-azure\r\nProduct: Visual Studio Code\r\nProduct Version: 1.66.1\r\nLanguage: en\r\n\r\n<details>\r\n<summary>Call Stack<\/summary>\r\n\r\n```\r\nnew t extension.js:2:486489\r\nt.<anonymous> extension.js:2:470040\r\nextension.js:2:2450576\r\nObject.throw extension.js:2:2450681\r\nc extension.js:2:2449471\r\n```\r\n\r\n<\/details>\r\n",
        "Issue_answer_count":4,
        "Issue_self_closed":0.0,
        "Answer_body":"@evakkuri thanks for filing this issue. Is this happening every time you open a remote connection? Are you connecting to Compute Instance through the ML Studio? Currently this happens every time I connect. I'm not connecting via ML Studio, instead through VS Code with the Azure Machine Learning extension. @sevillal Can you please follow up here :) ? @evakkuri we have published version v0.10.0 of the extension. Could you please upgrade and retry to check if you issue is still reproducible? Please reopen this issue if that's the case.",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"reoccur error open connect comput instanc occur consist ye repro step open remot connect comput instanc caus issu annoi error messag time action azureaccount onsubscriptionschang error type request send error error messag request redact url fail reason getaddrinfo enotfound redact idworkspac westeurop api version linux releas azur product visual studio code product version languag stack new extens extens extens object throw extens extens",
        "Issue_preprocessed_content":"open comput instanc consist ye repro step todo share step reliabl reproduc problem includ actual expect result open remot comput instanc caus time action onsubscriptionschang type request redact url fail reason enotfound version linux releas product visual studio code product version languag detail detail",
        "Issue_gpt_summary_original":"The user encountered an error while installing an Azure ML training model piece. They installed grep via chocolatey, which allowed the script to go further, but now they are receiving an error message stating that the dataset with the name 'mnist_opendataset' is not found. The user is seeking help to troubleshoot this error as they need to demo it to a customer next week.",
        "Issue_gpt_summary":"user encount error instal train model piec instal grep chocolatei allow script receiv error messag state dataset mnist opendataset user seek help troubleshoot error need demo custom week",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/azure_arc\/issues\/1213",
        "Issue_title":"Can not add AzureML extention on openshift cluster ",
        "Issue_created_time":1653563264000,
        "Issue_closed_time":1654438640000,
        "Issue_body":"Error when adding extetnion azureml\r\naz k8s-extension create --name azureml-extension --extension-type Microsoft.AzureML.Kubernetes --config enableTraining= cluster-type conneced--cluster-name <your-AKS-cluster-name> --resource-group <your-RG-name> --scope cluster\r\n\r\n\r\ncrc\/providers\/Microsoft.KubernetesConfiguration\/extensions\/arcml-extension\/operations\/b5f5e30a-7439-4dd7-aab7-90bd438d320e\",\"name\":\"b5f5e30a-7439-4dd7-aab7-90bd438d320e\",\"status\":\"Creating\"}\r\ncli.azure.cli.core.sdk.policies: Request URL: 'https:\/\/management.azure.com\/subscriptions\/0ebcf6f3-37c0-4ab6-bc4a-4299fd25192a\/resourceGroups\/azurearctest\/providers\/Microsoft.Kubernetes\/ConnectedClusters\/tvl-crc\/providers\/Microsoft.KubernetesConfiguration\/extensions\/arcml-extension\/operations\/b5f5e30a-7439-4dd7-aab7-90bd438d320e?api-Version=2022-03-01'\r\ncli.azure.cli.core.sdk.policies: Request method: 'GET'\r\ncli.azure.cli.core.sdk.policies: Request headers:\r\ncli.azure.cli.core.sdk.policies:     'x-ms-client-request-id': 'f1bf020c-dc0d-11ec-a8c0-808abda5e54d'\r\ncli.azure.cli.core.sdk.policies:     'CommandName': 'k8s-extension create'\r\ncli.azure.cli.core.sdk.policies:     'ParameterSetName': '--name --extension-type --cluster-type --cluster-name --resource-group --name --auto-upgrade --scope --debug --config'\r\ncli.azure.cli.core.sdk.policies:     'User-Agent': 'AZURECLI\/2.36.0 (MSI) azsdk-python-azure-mgmt-kubernetesconfiguration\/1.0.0 Python\/3.10.4 (Windows-10-10.0.19044-SP0)'\r\ncli.azure.cli.core.sdk.policies:     'Authorization': '*****'\r\ncli.azure.cli.core.sdk.policies: Request body:\r\ncli.azure.cli.core.sdk.policies: This request has no body\r\nurllib3.connectionpool: [https:\/\/management.azure.com:443](https:\/\/nam06.safelinks.protection.outlook.com\/?url=https%3A%2F%2Fmanagement.azure.com%2F&data=05%7C01%7Cjohan.andolf%40microsoft.com%7C37b5d083c3d7447f133208da3e347a4a%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C637890692414003835%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=1kWOqV7FwAgqmYol4W7wfZRbf%2BCTKz9XucDBe%2FKgGKA%3D&reserved=0) \"GET \/subscriptions\/0ebcf6f3-37c0-4ab6-bc4a-4299fd25192a\/resourceGroups\/azurearctest\/providers\/Microsoft.Kubernetes\/ConnectedClusters\/tvl-crc\/providers\/Microsoft.KubernetesConfiguration\/extensions\/arcml-extension\/operations\/b5f5e30a-7439-4dd7-aab7-90bd438d320e?api-Version=2022-03-01 HTTP\/1.1\" 200 None\r\ncli.azure.cli.core.sdk.policies: Response status: 200\r\ncli.azure.cli.core.sdk.policies: Response headers:\r\ncli.azure.cli.core.sdk.policies:     'Cache-Control': 'no-cache'\r\ncli.azure.cli.core.sdk.policies:     'Pragma': 'no-cache'\r\ncli.azure.cli.core.sdk.policies:     'Transfer-Encoding': 'chunked'\r\ncli.azure.cli.core.sdk.policies:     'Content-Type': 'application\/json; charset=utf-8'\r\ncli.azure.cli.core.sdk.policies:     'Content-Encoding': 'gzip'\r\ncli.azure.cli.core.sdk.policies:     'Expires': '-1'\r\ncli.azure.cli.core.sdk.policies:     'Vary': 'Accept-Encoding'\r\ncli.azure.cli.core.sdk.policies:     'x-ms-ratelimit-remaining-subscription-reads': '11968'\r\ncli.azure.cli.core.sdk.policies:     'Strict-Transport-Security': 'max-age=31536000; includeSubDomains'\r\ncli.azure.cli.core.sdk.policies:     'api-supported-versions': '2019-11-01-Preview, 2021-05-01-preview, 2021-06-01-preview, 2021-09-01, 2021-11-01-preview, 2022-01-01-preview, 2022-03-01, 2022-04-02-preview'\r\ncli.azure.cli.core.sdk.policies:     'X-Content-Type-Options': 'nosniff'\r\ncli.azure.cli.core.sdk.policies:     'x-ms-request-id': '8d41b858-4f6d-4d30-819c-c34bef28d668'\r\ncli.azure.cli.core.sdk.policies:     'x-ms-correlation-request-id': '8d41b858-4f6d-4d30-819c-c34bef28d668'\r\ncli.azure.cli.core.sdk.policies:     'x-ms-routing-request-id': 'SWEDENCENTRAL:20220525T095135Z:8d41b858-4f6d-4d30-819c-c34bef28d668'\r\ncli.azure.cli.core.sdk.policies:     'Date': 'Wed, 25 May 2022 09:51:34 GMT'\r\ncli.azure.cli.core.sdk.policies: Response content:\r\ncli.azure.cli.core.sdk.policies: {\"id\":\"\/subscriptions\/0ebcf6f3-37c0-4ab6-bc4a-4299fd25192a\/resourceGroups\/azurearctest\/providers\/Microsoft.Kubernetes\/ConnectedClusters\/tvl-crc\/providers\/Microsoft.KubernetesConfiguration\/extensions\/arcml-extension\/operations\/b5f5e30a-7439-4dd7-aab7-90bd438d320e\",\"name\":\"b5f5e30a-7439-4dd7-aab7-90bd438d320e\",\"status\":\"Failed\",\"error\":{\"code\":\"ExtensionCreationFailed\",\"message\":\" error: Unable to get the status from the local CRD with the error : {Error : Retry for given duration didn't get any results with err {status not populated}}\"}}\r\ncli.azure.cli.core.util: azure.cli.core.util.handle_exception is called with an exception:\r\ncli.azure.cli.core.util: Traceback (most recent call last):\r\n  File \"D:\\a\\1\\s\\build_scripts\\windows\\artifacts\\cli\\Lib\\site-packages\\azure\/core\/polling\/base_polling.py\", line 483, in run\r\n  File \"D:\\a\\1\\s\\build_scripts\\windows\\artifacts\\cli\\Lib\\site-packages\\azure\/core\/polling\/base_polling.py\", line 522, in _poll\r\nazure.core.polling.base_polling.OperationFailed: Operation failed or canceled\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\a\\1\\s\\build_scripts\\windows\\artifacts\\cli\\Lib\\site-packages\\knack\/cli.py\", line 231, in invoke\r\n  File \"D:\\a\\1\\s\\build_scripts\\windows\\artifacts\\cli\\Lib\\site-packages\\azure\/cli\/core\/commands\/__init__.py\", line 658, in execute\r\n  File \"D:\\a\\1\\s\\build_scripts\\windows\\artifacts\\cli\\Lib\\site-packages\\azure\/cli\/core\/commands\/__init__.py\", line 721, in _run_jobs_serially\r\n  File \"D:\\a\\1\\s\\build_scripts\\windows\\artifacts\\cli\\Lib\\site-packages\\azure\/cli\/core\/commands\/__init__.py\", line 703, in _run_job\r\n  File \"D:\\a\\1\\s\\build_scripts\\windows\\artifacts\\cli\\Lib\\site-packages\\azure\/cli\/core\/commands\/__init__.py\", line 1008, in __call__\r\n  File \"D:\\a\\1\\s\\build_scripts\\windows\\artifacts\\cli\\Lib\\site-packages\\azure\/cli\/core\/commands\/__init__.py\", line 995, in __call__\r\n  File \"D:\\a\\1\\s\\build_scripts\\windows\\artifacts\\cli\\Lib\\site-packages\\azure\/core\/polling\/_poller.py\", line 255, in result\r\n  File \"D:\\a\\1\\s\\build_scripts\\windows\\artifacts\\cli\\Lib\\site-packages\\azure\/core\/tracing\/decorator.py\", line 83, in wrapper_use_tracer\r\n  File \"D:\\a\\1\\s\\build_scripts\\windows\\artifacts\\cli\\Lib\\site-packages\\azure\/core\/polling\/_poller.py\", line 275, in wait\r\n  File \"D:\\a\\1\\s\\build_scripts\\windows\\artifacts\\cli\\Lib\\site-packages\\azure\/core\/polling\/_poller.py\", line 192, in _start\r\n  File \"D:\\a\\1\\s\\build_scripts\\windows\\artifacts\\cli\\Lib\\site-packages\\azure\/core\/polling\/base_polling.py\", line 501, in run\r\nazure.core.exceptions.HttpResponseError: (ExtensionCreationFailed)  error: Unable to get the status from the local CRD with the error : {Error : Retry for given duration didn't get any results with err {status not populated}}\r\nCode: ExtensionCreationFailed\r\nMessage:  error: Unable to get the status from the local CRD with the error : {Error : Retry for given duration didn't get any results with err {status not populated}}\r\n\r\ncli.azure.cli.core.azclierror: (ExtensionCreationFailed)  error: Unable to get the status from the local CRD with the error : {Error : Retry for given duration didn't get any results with err {status not populated}}\r\nCode: ExtensionCreationFailed\r\nMessage:  error: Unable to get the status from the local CRD with the error : {Error : Retry for given duration didn't get any results with err {status not populated}}\r\naz_command_data_logger: (ExtensionCreationFailed)  error: Unable to get the status from the local CRD with the error : {Error : Retry for given duration didn't get any results with err {status not populated}}\r\nCode: ExtensionCreationFailed\r\nMessage:  error: Unable to get the status from the local CRD with the error : {Error : Retry for given duration didn't get any results with err {status not populated}}\r\ncli.knack.cli: Event: Cli.PostExecute [<function AzCliLogging.deinit_cmd_metadata_logging at 0x0387C190>]\r\naz_command_data_logger: exit code: 1\r\ncli.__main__: Command ran in 996.906 seconds (init: 0.535, invoke: 996.371)\r\ntelemetry.save: Save telemetry record of length 3581 in cache\r\ntelemetry.check: Returns Positive.\r\ntelemetry.main: Begin creating telemetry upload process.\r\ntelemetry.process: Creating upload process: \"C:\\Program Files (x86)\\Microsoft SDKs\\Azure\\CLI2\\python.exe C:\\Program Files (x86)\\Microsoft SDKs\\Azure\\CLI2\\Lib\\site-packages\\azure\\cli\\telemetry\\__init__.pyc C:\\Users\\ropa04\\.azure\"\r\ntelemetry.process: Return from creating process\r\ntelemetry.main: Finish creating telemetry upload process.",
        "Issue_answer_count":3,
        "Issue_self_closed":0.0,
        "Answer_body":"Hey friend! Thanks for opening this issue. We appreciate your contribution and welcome you to our community! We are glad to have you here and to have your input on the Azure Arc Jumpstart.<p><\/p> Hello Johan, thanks for submitting feedback. Have you checked the [prerequisites specific to ARO](https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-attach-kubernetes-anywhere?tabs=studio#prerequisites) prior to attempting the extension installation?  Hello @rataxe , have you checked the pre-reqs above. If you already had and still facing a problem, we recommend you open a support case as this is not strictly related to the Jumpstart project but to the product itself. ",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"add extent openshift cluster error ad extetnion extens creat extens extens type microsoft kubernet config enabletrain cluster type connec cluster resourc group scope cluster crc provid microsoft kubernetesconfigur extens arcml extens oper bfea aab bdde bfea aab bdde statu creat cli azur cli core sdk polici request url http manag azur com subscript ebcff bca fda resourcegroup azurearctest provid microsoft kubernet connectedclust tvl crc provid microsoft kubernetesconfigur extens arcml extens oper bfea aab bdde api version cli azur cli core sdk polici request method cli azur cli core sdk polici request header cli azur cli core sdk polici client request fbfc dcd abda cli azur cli core sdk polici commandnam extens creat cli azur cli core sdk polici parametersetnam extens type cluster type cluster resourc group auto upgrad scope debug config cli azur cli core sdk polici user agent azurecli msi azsdk python azur mgmt kubernetesconfigur python window cli azur cli core sdk polici author cli azur cli core sdk polici request bodi cli azur cli core sdk polici request bodi urllib connectionpool http manag azur com http nam safelink protect outlook com url http fmanag azur com data cjohan andolf microsoft com cbdcdfdaeaa cfbffafabdcddb cunknown ctwfpbgzsbdeyjwijoimcwljawmdailcjqijoivlumziilcjbtiiikhawwilcjxvcimn sdata kwoqvfwagqmyolwwfzrbf bctkzxucdb fkggka reserv subscript ebcff bca fda resourcegroup azurearctest provid microsoft kubernet connectedclust tvl crc provid microsoft kubernetesconfigur extens arcml extens oper bfea aab bdde api version http cli azur cli core sdk polici respons statu cli azur cli core sdk polici respons header cli azur cli core sdk polici cach control cach cli azur cli core sdk polici pragma cach cli azur cli core sdk polici transfer encod chunk cli azur cli core sdk polici content type applic json charset utf cli azur cli core sdk polici content encod gzip cli azur cli core sdk polici expir cli azur cli core sdk polici vari accept encod cli azur cli core sdk polici ratelimit remain subscript read cli azur cli core sdk polici strict transport secur max ag includesubdomain cli azur cli core sdk polici api support version preview preview preview preview preview preview cli azur cli core sdk polici content type option nosniff cli azur cli core sdk polici request cbefd cli azur cli core sdk polici correl request cbefd cli azur cli core sdk polici rout request swedencentr cbefd cli azur cli core sdk polici date wed gmt cli azur cli core sdk polici respons content cli azur cli core sdk polici subscript ebcff bca fda resourcegroup azurearctest provid microsoft kubernet connectedclust tvl crc provid microsoft kubernetesconfigur extens arcml extens oper bfea aab bdde bfea aab bdde statu fail error code extensioncreationfail messag error unabl statu local crd error error retri given durat result err statu popul cli azur cli core util azur cli core util handl except call except cli azur cli core util traceback recent file build script window artifact cli lib site packag azur core poll base poll line run file build script window artifact cli lib site packag azur core poll base poll line poll azur core poll base poll operationfail oper fail cancel handl except except occur traceback recent file build script window artifact cli lib site packag knack cli line invok file build script window artifact cli lib site packag azur cli core command init line execut file build script window artifact cli lib site packag azur cli core command init line run job serial file build script window artifact cli lib site packag azur cli core command init line run job file build script window artifact cli lib site packag azur cli core command init line file build script window artifact cli lib site packag azur cli core command init line file build script window artifact cli lib site packag azur core poll poller line result file build script window artifact cli lib site packag azur core trace decor line wrapper us tracer file build script window artifact cli lib site packag azur core poll poller line wait file build script window artifact cli lib site packag azur core poll poller line start file build script window artifact cli lib site packag azur core poll base poll line run azur core except httpresponseerror extensioncreationfail error unabl statu local crd error error retri given durat result err statu popul code extensioncreationfail messag error unabl statu local crd error error retri given durat result err statu popul cli azur cli core azclierror extensioncreationfail error unabl statu local crd error error retri given durat result err statu popul code extensioncreationfail messag error unabl statu local crd error error retri given durat result err statu popul command data logger extensioncreationfail error unabl statu local crd error error retri given durat result err statu popul code extensioncreationfail messag error unabl statu local crd error error retri given durat result err statu popul cli knack cli event cli postexecut command data logger exit code cli main command ran second init invok telemetri save save telemetri record length cach telemetri check return posit telemetri main begin creat telemetri upload process telemetri process creat upload process program file microsoft sdk azur cli python ex program file microsoft sdk azur cli lib site packag azur cli telemetri init pyc user ropa azur telemetri process return creat process telemetri main finish creat telemetri upload process",
        "Issue_preprocessed_content":"extent openshift cluster extetnion creat extens enabletrain cluster request url request method request header creat parametersetnam author request bodi request bodi respons statu respons header pragma chunk gzip expir vari includesubdomain date wed gmt respons content except traceback file line run file line oper fail cancel handl except except traceback file line invok file line execut file line file line file line file line file line result file line file line wait file line file line run unabl statu local crd code extensioncreationfail unabl statu local crd unabl statu local crd code extensioncreationfail unabl statu local crd unabl statu local crd code extensioncreationfail unabl statu local crd event exit code ran second save telemetri record length cach return posit begin creat telemetri upload creat upload file file return creat finish creat telemetri upload",
        "Issue_gpt_summary_original":"The issue is that models with crossval_count greater than 1 automatically switch to train on AzureML even if the user overrides --azureml=False. This behavior is confusing and the runner should fail if there are contradicting parameters. Additionally, the histopathology.DeepSMILECrck model is not trainable because it does not have a default encoder type, and there is a question of whether base classes should be flagged as not trainable and throw an error.",
        "Issue_gpt_summary":"issu model crossval count greater automat switch train user overrid fals behavior confus runner fail contradict paramet addition histopatholog deepsmilecrck model trainabl default encod type question base class flag trainabl throw error",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/azure_arc\/issues\/758",
        "Issue_title":"error when installing AZURE ML training model piece",
        "Issue_created_time":1631563330000,
        "Issue_closed_time":1631711922000,
        "Issue_body":"I was getting an error when azuremllogonscript.ps1 was running and trying to use grep in one line, but it could not find grep anywhere. So, I installed grep via chocolatey, and now the script goes further to line 267,and gives me the error below.\r\n\r\ngrep executes but now the error says \"Dataset with name 'mnist_opendataset' is not found\".\r\n\r\nAny help troubleshooting this error will be appreciated, I am trying to demo this to a customer. next week.\r\n\r\n**TEXT of the OUTPUT when error is encountered:**\r\n\r\n\r\nInstalling amlarc-compute K8s extension was successful.\r\n\r\nWarning: Falling back to use azure cli login credentials.\r\nIf you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\r\nPlease refer to aka.ms\/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\r\nLibrary configuration succeeded\r\n\r\nWarning: Falling back to use azure cli login credentials.\r\nIf you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\r\n\r\nPlease refer to aka.ms\/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\r\nClass KubernetesCompute: This is an experimental class, and may change at any time. Please see https:\/\/aka.ms\/azuremlexperimental for more information.\r\nClass KubernetesCompute: This is an experimental class, and may change at any time. Please see https:\/\/aka.ms\/azuremlexperimental for more information.\r\nfound compute target: ARC-ml\r\n\"\r\n Training model:\r\n                               \r\n            .....                                             .....\r\n         .........                                           .........\r\n        .........                 (((((((((##                 .........\r\n       .....                      (((((((####                      .....\r\n      ......                      #((########                      ......\r\n     ....... .............        ###########        ............. .......\r\n     ......................       ###########       ......................\r\n    .................*.....       ###########       ....,*.................\r\n    .........*******......       (((((((((((         ......*******.........\r\n         ............          (((((((((((     (.         ............\r\n                            .(((((((((((     (((((\/\r\n                          ((((((((((((     #(((((((##\r\n                        \/\/\/\/(((((((*     ##############\r\n                      \/\/\/\/\/\/(((((.         ,#############.\r\n                   ,**\/\/\/\/\/\/\/((               #############\/\r\n                    *\/\/\/\/\/\/\/\/&%%%%%%%%%%%%%%%%%%%##########\r\n                    \/\/\/\/\/\/\/&&&%&%%%%%%%%%%%%%%%&%&&#######(\r\n                     \/\/\/\/&&&&&&&%%%%%%%%%%%%%&&&&&&&&%####\r\n                     .(&&&&&&&&&&&&&&%%%%%%&&&&&&&&&&&&&#.\r\n\r\n\"\r\nWarning: Falling back to use azure cli login credentials.\r\nIf you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\r\nPlease refer to aka.ms\/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\r\nWARNING: Command group 'ml job' is experimental and under development. Reference and support levels: https:\/\/aka.ms\/CLI_refstatus\r\nUploading src:   0%|                                                                                                                                | 0.00\/3.08k [00:00<?, ?B\/s]\r\n\r\n**ERROR: Code: UserError**\r\n**Message: Dataset with name 'mnist_opendataset' is not found.**\r\n**You cannot call a method on a null-valued expression.**\r\n**At C:\\Temp\\AzureMLLogonScript.ps1:267 char:4**\r\n**+    $RunId = ($Job | grep '\\\"name\\\":').Split('\\\"')[3]**\r\n**+    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~**\r\n    **+ CategoryInfo          : InvalidOperation: (:) [], RuntimeException**\r\n    **+ FullyQualifiedErrorId : InvokeMethodOnNull**\r\n\r\n**RunId:**\r\n**Training model, hold tight...**\r\n**ERROR: argument --name\/-n: expected one argument**_****\r\n\r\nTRY THIS:\r\naz ml job show --name my-job-id --query \"{Name:name,Jobstatus:status}\" --output table --resource-group my-resource-group --workspace-name my-workspace\r\nShow the status of a job using --query argument to execute a JMESPath query on the results of commands.\r\n\r\nhttps:\/\/aka.ms\/cli_ref\r\nRead more about the command in reference docs\r\nJob Status:\r\nERROR: argument --name\/-n: expected one argument\r\n\r\nTRY THIS:\r\naz ml job show --name my-job-id --query \"{Name:name,Jobstatus:status}\" --output table --resource-group my-resource-group --workspace-name my-workspace\r\nShow the status of a job using --query argument to execute a JMESPath query on the results of commands.\r\n\r\nhttps:\/\/aka.ms\/cli_ref\r\nRead more about the command in reference docs\r\nJob Status:\r\nERROR: argument --name\/-n: expected one argument\r\n\r\nTRY THIS:\r\naz ml job show --name my-job-id --query \"{Name:name,Jobstatus:status}\" --output table --resource-group my-resource-group --workspace-name my-workspace\r\nShow the status of a job using --query argument to execute a JMESPath query on the results of commands.\r\n",
        "Issue_answer_count":3,
        "Issue_self_closed":0.0,
        "Answer_body":"Hi @arturoqu77 - thanks for reaching out. We tried to repro this issue but couldn't.\r\n\r\nThis [line of code](https:\/\/github.com\/microsoft\/azure_arc\/blob\/a322f4915a72f860779e4d92d7d111848883a344\/azure_arc_ml_jumpstart\/aks\/arm_template\/artifacts\/AzureMLLogonScript.ps1#L266) leverages grep to parse the file name. `grep` should have been installed as part of the [bootstrap](https:\/\/github.com\/microsoft\/azure_arc\/blob\/a322f4915a72f860779e4d92d7d111848883a344\/azure_arc_ml_jumpstart\/aks\/arm_template\/artifacts\/Bootstrap.ps1#L73). If  `grep` wasn't installed, this implies something must have interrupted the install before it got there.\r\n\r\nDid you by any chance RDP into the VM before the Deployment was fully finished? That would cause the chocolatey install flow to break - which would also explain why the Training above isn't working. \r\n\r\nAre you seeing Postman installed - this happens [after `grep`](https:\/\/github.com\/microsoft\/azure_arc\/blob\/a322f4915a72f860779e4d92d7d111848883a344\/azure_arc_ml_jumpstart\/aks\/arm_template\/artifacts\/Bootstrap.ps1#L73)? If not, this is probably what happened.\r\n\r\nCould you try the deployment in a new RG, but this time ensuring you RDP in once ARM returns success (and the Bootstrap script is successful in running - you can see this in the ARM deployment status from the RG)? If you can't repro this issue once more, we can eliminate the above. Hello,\n\nThank you for your reply. I may have logged on before the bootstrap completed, I re-started the deployment to a new RG and seems to be working now.\n\nThanks for the help.\n\nRegards\n\n***@***.***\nArturo Quiroga\nSr. Cloud Solutions Architect (CSA)\nAzure Applications & Infrastructure\n***@***.******@***.***>\n[MSFT_logo_Gray DE sized SIG1.png]\n\n\nFrom: Raki ***@***.***>\nDate: Tuesday, September 14, 2021 at 6:22 PM\nTo: microsoft\/azure_arc ***@***.***>\nCc: Arturo Quiroga ***@***.***>, Mention ***@***.***>\nSubject: Re: [microsoft\/azure_arc] error when installing AZURE ML training model piece (#758)\n\nHi @arturoqu77<https:\/\/nam06.safelinks.protection.outlook.com\/?url=https%3A%2F%2Fgithub.com%2Farturoqu77&data=04%7C01%7Carturoqu%40microsoft.com%7C4df75e22c063478509d008d977ce2b14%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C637672549666347896%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=r1kAuKxYlYhONjoSTk83SERggUvNcbP1Hr4vmNh29io%3D&reserved=0> - thanks for reaching out. We tried to repro this issue but couldn't.\n\nThis line of code<https:\/\/nam06.safelinks.protection.outlook.com\/?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fazure_arc%2Fblob%2Fa322f4915a72f860779e4d92d7d111848883a344%2Fazure_arc_ml_jumpstart%2Faks%2Farm_template%2Fartifacts%2FAzureMLLogonScript.ps1%23L266&data=04%7C01%7Carturoqu%40microsoft.com%7C4df75e22c063478509d008d977ce2b14%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C637672549666357889%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=oAjL%2BfBBF4QXfnwN9gcM9UqEB4OA0ZZrzMuKilatz5A%3D&reserved=0> leverages grep to parse the file name. grep should have been installed as part of the bootstrap<https:\/\/nam06.safelinks.protection.outlook.com\/?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fazure_arc%2Fblob%2Fa322f4915a72f860779e4d92d7d111848883a344%2Fazure_arc_ml_jumpstart%2Faks%2Farm_template%2Fartifacts%2FBootstrap.ps1%23L73&data=04%7C01%7Carturoqu%40microsoft.com%7C4df75e22c063478509d008d977ce2b14%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C637672549666357889%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=V8dzJxj3W5a6IL8T%2BvB0mijBm5Ng4G46bb%2Fcdo2uvz4%3D&reserved=0>. If grep wasn't installed, this implies something must have interrupted the install before it got there.\n\nDid you by any chance RDP into the VM before the Deployment was fully finished? That would cause the chocolatey install flow to break - which would also explain why the Training above isn't working.\n\nAre you seeing Postman installed - this happens after grep<https:\/\/nam06.safelinks.protection.outlook.com\/?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fazure_arc%2Fblob%2Fa322f4915a72f860779e4d92d7d111848883a344%2Fazure_arc_ml_jumpstart%2Faks%2Farm_template%2Fartifacts%2FBootstrap.ps1%23L73&data=04%7C01%7Carturoqu%40microsoft.com%7C4df75e22c063478509d008d977ce2b14%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C637672549666367883%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=XvpeFo2T7Kjr4qrIZYKO7eM0khlOddES9O3DGaw1yZ4%3D&reserved=0>? If not, this is probably what happened.\n\nCould you try the deployment in a new RG, but this time ensuring you RDP in once ARM returns success (and the Bootstrap script is successful in running - you can see this in the ARM deployment status from the RG)? If you can't repro this issue once more, we can eliminate the above.\n\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub<https:\/\/nam06.safelinks.protection.outlook.com\/?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fazure_arc%2Fissues%2F758%23issuecomment-919554382&data=04%7C01%7Carturoqu%40microsoft.com%7C4df75e22c063478509d008d977ce2b14%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C637672549666367883%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=ZBGNkrDGFcqvrdWHXy5iEGluQiq2Ph%2BZnfosqC3qTTU%3D&reserved=0>, or unsubscribe<https:\/\/nam06.safelinks.protection.outlook.com\/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAHV4QUFA72NR7CEJ3UPS5NLUB7DLDANCNFSM5D6SSBHA&data=04%7C01%7Carturoqu%40microsoft.com%7C4df75e22c063478509d008d977ce2b14%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C637672549666377877%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=ctEevpiqzC%2FQnTc6ho2hfr2PVGA%2FqwGJzj1pPUCEylY%3D&reserved=0>.\nTriage notifications on the go with GitHub Mobile for iOS<https:\/\/nam06.safelinks.protection.outlook.com\/?url=https%3A%2F%2Fapps.apple.com%2Fapp%2Fapple-store%2Fid1477376905%3Fct%3Dnotification-email%26mt%3D8%26pt%3D524675&data=04%7C01%7Carturoqu%40microsoft.com%7C4df75e22c063478509d008d977ce2b14%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C637672549666377877%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=cMCZqYPB6q8c9n%2BgPTk9f3MCQr%2BlV4GsOW9iPFSZtgE%3D&reserved=0> or Android<https:\/\/nam06.safelinks.protection.outlook.com\/?url=https%3A%2F%2Fplay.google.com%2Fstore%2Fapps%2Fdetails%3Fid%3Dcom.github.android%26referrer%3Dutm_campaign%253Dnotification-email%2526utm_medium%253Demail%2526utm_source%253Dgithub&data=04%7C01%7Carturoqu%40microsoft.com%7C4df75e22c063478509d008d977ce2b14%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C637672549666387876%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=6B5T09q%2Bx2Q2rWftui6b32lD1VLrCRMPiLSrTUS7xnI%3D&reserved=0>.\n Great!",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"error instal train model piec get error logonscript run try us grep line grep instal grep chocolatei script goe line give error grep execut error sai dataset mnist opendataset help troubleshoot error appreci try demo custom week text output error encount instal amlarc comput extens success warn fall us azur cli login credenti run code unattend mode user input recommend us serviceprincipalauthent msiauthent refer aka aml notebook auth differ authent mechan sdk librari configur succeed warn fall us azur cli login credenti run code unattend mode user input recommend us serviceprincipalauthent msiauthent refer aka aml notebook auth differ authent mechan sdk class kubernetescomput experiment class chang time http aka experiment inform class kubernetescomput experiment class chang time http aka experiment inform comput target arc train model warn fall us azur cli login credenti run code unattend mode user input recommend us serviceprincipalauthent msiauthent refer aka aml notebook auth differ authent mechan sdk warn command group job experiment develop refer support level http aka cli refstatu upload src error code usererror messag dataset mnist opendataset method null valu express temp logonscript char runid job grep split categoryinfo invalidoper runtimeexcept fullyqualifiederrorid invokemethodonnul runid train model hold tight error argument expect argument try job job queri jobstatu statu output tabl resourc group resourc group workspac workspac statu job queri argument execut jmespath queri result command http aka cli ref read command refer doc job statu error argument expect argument try job job queri jobstatu statu output tabl resourc group resourc group workspac workspac statu job queri argument execut jmespath queri result command http aka cli ref read command refer doc job statu error argument expect argument try job job queri jobstatu statu output tabl resourc group resourc group workspac workspac statu job queri argument execut jmespath queri result command",
        "Issue_preprocessed_content":"train model piec try us grep line grep grep chocolatei script goe line give grep execut sai dataset help try demo custom text output encount extens warn us azur cli login credenti run code mode user input us serviceprincipalauthent msiauthent refer authent mechan sdk librari configur warn us azur cli login credenti run code mode user input us serviceprincipalauthent msiauthent refer authent mechan sdk kubernetescomput experiment chang time inform kubernetescomput experiment chang time inform comput target train model categoryinfo invalidoper runid train model hold argument expect try job jobstatu statu tabl statu job argument execut jmespath queri result read refer doc job statu argument expect argument try job jobstatu statu tabl statu job argument execut jmespath queri result read refer doc job statu argument expect argument try job jobstatu statu tabl statu job argument execut jmespath queri result",
        "Issue_gpt_summary_original":"The user has encountered broken links in the introduction section of the 11_exploring_hyperparameters_on_azureml notebook related to object detection. The links to two notebooks, 02_mask_rcnn.ipynb and 03_training_accuracy_vs_speed.ipynb, are not working. The user is working from the master branch of the repo and expects the notebooks to be present or the links to be removed.",
        "Issue_gpt_summary":"user encount broken link introduct section explor hyperparamet notebook relat object detect link notebook mask rcnn ipynb train accuraci speed ipynb work user work master branch repo expect notebook present link remov",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/hi-ml\/issues\/335",
        "Issue_title":"Models that override  crossval_count with a value bigger than 1 automatically switch to train on AzureML even if user overrides --azureml=False",
        "Issue_created_time":1652108924000,
        "Issue_closed_time":1657547192000,
        "Issue_body":"Models that override  crossval_count with a value bigger than 1 automatically switch to train on AzureML even if user overrides --azureml=False\r\n\r\nThis behaviour is a bit confusing and I had to debug the code to understand what was happening. I would expect the runner to fail if there are contradicting parameters instead of overriding them for me and doing the opposite of what I want that is train locally.\r\n\r\nRepro with:\r\n\r\n\/home\/azureuser\/hi-ml\/hi-ml\/src\/health_ml\/runner.py --model=histopathology.DeepSMILECrck \r\n\r\nAlso the histopathology.DeepSMILECrck is not trainable because it does not have a default encoder type. Should we flag base classes as not trainable and throw an error?",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"Resolved in #420",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"model overrid crossval count valu bigger automat switch train user overrid fals model overrid crossval count valu bigger automat switch train user overrid fals behaviour bit confus debug code understand happen expect runner fail contradict paramet instead overrid opposit want train local repro home azureus src health runner model histopatholog deepsmilecrck histopatholog deepsmilecrck trainabl default encod type flag base class trainabl throw error",
        "Issue_preprocessed_content":"model valu switch train user model valu switch train user behaviour bit confus debug code understand expect fail contradict paramet instead want train repro trainabl default encod type flag base trainabl throw",
        "Issue_gpt_summary_original":"The user is requesting guidance on how to obtain a subscription id and fill in the necessary strings in the 11_exploring_hyperparameters_on_azureml notebook. They suggest adding an error message in the code cell to alert users who forget to fill in the values and provide guidance for novice users on obtaining their Azure subscription id.",
        "Issue_gpt_summary":"user request guidanc obtain subscript necessari string explor hyperparamet notebook suggest ad error messag code cell alert user forget valu provid guidanc novic user obtain azur subscript",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/computervision-recipes\/issues\/410",
        "Issue_title":"[BUG] Some links to notebooks in introduction are broken in 11_exploring_hyperparameters_on_azureml notebook",
        "Issue_created_time":1573072566000,
        "Issue_closed_time":null,
        "Issue_body":"### Description\r\n\r\nThe introduction section of the 11_exploring_hyperparameters_on_azureml notebook under object detection includes two broken links:\r\n` [02_mask_rcnn.ipynb](02_mask_rcnn.ipynb)`\r\n`[03_training_accuracy_vs_speed.ipynb](03_training_accuracy_vs_speed.ipynb)`\r\n\r\nThe master branch of this repo (which I am working from...please tell me that was intended...) does not contain these notebooks. \r\n\r\n### In which platform does it happen?\r\nAll.\r\n\r\n### How do we replicate the issue?\r\nClick the links\r\n\r\n### Expected behavior (i.e. solution)\r\nNotebooks are present or links are removed\r\n\r\n### Other Comments\r\n",
        "Issue_answer_count":0,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"bug link notebook introduct broken explor hyperparamet notebook descript introduct section explor hyperparamet notebook object detect includ broken link mask rcnn ipynb mask rcnn ipynb train accuraci speed ipynb train accuraci speed ipynb master branch repo work tell intend contain notebook platform happen replic issu click link expect behavior solut notebook present link remov comment",
        "Issue_preprocessed_content":"link introduct broken descript introduct section object detect includ broken link master branch repo contain platform replic click link expect behavior present link remov",
        "Issue_gpt_summary_original":"The user has encountered a bug where the link to 20_azure_workspace_setup.ipynb in the 11_exploring_hyperparameters_on_azureml notebook is broken. The link does not resolve properly, indicating that the relative location of the notebook has changed. The expected solution is for the link to work properly.",
        "Issue_gpt_summary":"user encount bug link azur workspac setup ipynb explor hyperparamet notebook broken link resolv properli indic rel locat notebook chang expect solut link work properli",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/computervision-recipes\/issues\/409",
        "Issue_title":"[FEATURE_REQUEST] Provide guidance on how to obtain a subscription id in 11_exploring_hyperparameters_on_azureml notebook",
        "Issue_created_time":1573072237000,
        "Issue_closed_time":null,
        "Issue_body":"### Description\r\n\r\nUsers need to modify the third code cell to specific a subscription id and the names that will be used for creating a resource group, workspace, etc. Some guidance within the notebook on how to obtain these values and fill in the strings would be helpful.\r\n\r\nIt would also be nice to throw an error in this code cell if users forget to fill in the values, so that users don't encounter a cryptic error from the call to `get_or_create_workspace()` later on.\r\n\r\n### Expected behavior with the suggested feature\r\n\r\nUsers who forget to fill in the string values in this code cell are alerted to the issue by an error message from this code cell. Novice users receive some guidance on how to obtain their Azure subscription id without having to reference other notebooks.\r\n\r\n### Other Comments\r\n",
        "Issue_answer_count":0,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"featur request provid guidanc obtain subscript explor hyperparamet notebook descript user need modifi code cell specif subscript name creat resourc group workspac guidanc notebook obtain valu string help nice throw error code cell user forget valu user encount cryptic error creat workspac later expect behavior suggest featur user forget string valu code cell alert issu error messag code cell novic user receiv guidanc obtain azur subscript have refer notebook comment",
        "Issue_preprocessed_content":"provid guidanc obtain subscript descript user modifi code specif subscript name creat resourc group workspac guidanc obtain valu string help nice throw code user forget valu user encount cryptic later expect behavior featur user forget string valu code alert code novic user receiv guidanc obtain azur subscript have refer",
        "Issue_gpt_summary_original":"The user has requested for an update of AzureML from version 1.0.30 to 1.0.72 as the current version is considered outdated.",
        "Issue_gpt_summary":"user request updat version current version consid outdat",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/computervision-recipes\/issues\/408",
        "Issue_title":"[BUG] Link to 20_azure_workspace_setup.ipynb in 11_exploring_hyperparameters_on_azureml notebook is broken",
        "Issue_created_time":1573071661000,
        "Issue_closed_time":null,
        "Issue_body":"### Description\r\n\r\nThe 11_exploring_hyperparameters_on_azureml notebook contains the following link in markdown:\r\n`[20_azure_workspace_setup.ipynb](..\/..\/classification\/notebooks\/20_azure_workspace_setup.ipynb)`\r\n\r\nThe link does not resolve properly -- it appears the relative location of the notebook has changed.\r\n\r\n### In which platform does it happen?\r\nAll\r\n\r\n### How do we replicate the issue?\r\nClick the link\r\n\r\n### Expected behavior (i.e. solution)\r\nLink works\r\n\r\n### Other Comments\r\n",
        "Issue_answer_count":0,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"bug link azur workspac setup ipynb explor hyperparamet notebook broken descript explor hyperparamet notebook contain follow link markdown azur workspac setup ipynb classif notebook azur workspac setup ipynb link resolv properli appear rel locat notebook chang platform happen replic issu click link expect behavior solut link work comment",
        "Issue_preprocessed_content":"link broken descript contain link markdown link resolv properli rel locat chang platform replic click link expect behavior link work",
        "Issue_gpt_summary_original":"The user is requesting to install utils_cv as a pip wheel in AzureML to avoid the cumbersome process of copying the whole directory and to add it as a dependency. They suggest creating a pip wheel package of utils_cv and adding it to the workspace as a private pip wheel.",
        "Issue_gpt_summary":"user request instal util pip wheel avoid cumbersom process copi directori add depend suggest creat pip wheel packag util ad workspac privat pip wheel",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/computervision-recipes\/issues\/404",
        "Issue_title":"[FEATURE_REQUEST] AzureML may need to be updated 1.0.30->1.0.72?",
        "Issue_created_time":1573068707000,
        "Issue_closed_time":null,
        "Issue_body":"### Description\r\nThe current version of AzureML is a little dated \r\nhttps:\/\/github.com\/microsoft\/ComputerVision\/blob\/3e0631e0dc7d5ddbfc6283b1e89b3ce51f0bd449\/environment.yml#L41\r\n",
        "Issue_answer_count":0,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"featur request need updat descript current version littl date http github com microsoft computervis blob eedcdddbfcbebcefbd environ yml",
        "Issue_preprocessed_content":"updat descript version date",
        "Issue_gpt_summary_original":"the user encountered an error in o16n with notebooks related to the deployment of aci and aks resources.",
        "Issue_gpt_summary":"user encount error notebook relat deploy aci ak resourc",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/computervision-recipes\/issues\/396",
        "Issue_title":"[FEATURE_REQUEST] Install utils_cv as a pip wheel in AzureML",
        "Issue_created_time":1573065169000,
        "Issue_closed_time":null,
        "Issue_body":"### Description\r\nIn https:\/\/github.com\/microsoft\/ComputerVision\/blob\/master\/scenarios\/detection\/11_exploring_hyperparameters_on_azureml.ipynb\r\nyou copy the whole directory in order to make use of the utils_cv\r\nThis is a bit cumbersome and unecesarily copies things around. You can create a pip wheel package of your utils_cv and add it as a dependency see here https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.environment(class)?view=azure-ml-py#add-private-pip-wheel-workspace--file-path--exist-ok-false-\r\n\r\n\r\n",
        "Issue_answer_count":0,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"featur request instal util pip wheel descript http github com microsoft computervis blob master scenario detect explor hyperparamet ipynb copi directori order us util bit cumbersom unecesarili copi thing creat pip wheel packag util add depend http doc microsoft com python api core core environ class view azur add privat pip wheel workspac file path exist fals",
        "Issue_preprocessed_content":"pip descript copi directori order us bit cumbersom unecesarili copi thing creat pip packag depend",
        "Issue_gpt_summary_original":"the user encountered a challenge with the pipeline -notebook-test-linux-cpu failing.",
        "Issue_gpt_summary":"user encount challeng pipelin notebook test linux cpu fail",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/computervision-recipes\/issues\/332",
        "Issue_title":"[BUG] Error in o16n with AzureML  notebooks",
        "Issue_created_time":1569349581000,
        "Issue_closed_time":null,
        "Issue_body":"### Description\r\n<!--- Describe your issue\/bug\/request in detail -->\r\n\r\nThis is the error, it looks it is related to the deployment of ACI and AKS resources. \r\n\r\n\r\n```\r\n.FFF.                                                                    [100%]\r\n=================================== FAILURES ===================================\r\n_____________________________ test_21_notebook_run _____________________________\r\n\r\nclassification_notebooks = {'00_webcam': '\/home\/vsts\/work\/1\/s\/classification\/notebooks\/00_webcam.ipynb', '01_training_introduction': '\/home\/vsts\/...3_training_accuracy_vs_speed': '\/home\/vsts\/work\/1\/s\/classification\/notebooks\/03_training_accuracy_vs_speed.ipynb', ...}\r\nsubscription_id = '***'\r\nresource_group = 'amlnotebookrg', workspace_name = 'amlnotebookws'\r\nworkspace_region = '***2'\r\n\r\n    @pytest.mark.azuremlnotebooks\r\n    def test_21_notebook_run(\r\n        classification_notebooks,\r\n        subscription_id,\r\n        resource_group,\r\n        workspace_name,\r\n        workspace_region,\r\n    ):\r\n        notebook_path = classification_notebooks[\r\n            \"21_deployment_on_azure_container_instances\"\r\n        ]\r\n        pm.execute_notebook(\r\n            notebook_path,\r\n            OUTPUT_NOTEBOOK,\r\n            parameters=dict(\r\n                PM_VERSION=pm.__version__,\r\n                subscription_id=subscription_id,\r\n                resource_group=resource_group,\r\n                workspace_name=workspace_name,\r\n                workspace_region=workspace_region,\r\n            ),\r\n>           kernel_name=KERNEL_NAME,\r\n        )\r\n\r\ntests\/smoke\/test_azureml_notebooks.py:58: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/site-packages\/papermill\/execute.py:108: in execute_notebook\r\n    raise_for_execution_errors(nb, output_path)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nnb = {'cells': [{'cell_type': 'code', 'metadata': {'inputHidden': True, 'hide_input': True}, 'execution_count': None, 'sour..._time': '2019-09-24T17:35:17.380577', 'duration': 1113.334717, 'exception': True}}, 'nbformat': 4, 'nbformat_minor': 2}\r\noutput_path = 'output.ipynb'\r\n\r\n    def raise_for_execution_errors(nb, output_path):\r\n        \"\"\"Assigned parameters into the appropriate place in the input notebook\r\n    \r\n        Parameters\r\n        ----------\r\n        nb : NotebookNode\r\n           Executable notebook object\r\n        output_path : str\r\n           Path to write executed notebook\r\n        \"\"\"\r\n        error = None\r\n        for cell in nb.cells:\r\n            if cell.get(\"outputs\") is None:\r\n                continue\r\n    \r\n            for output in cell.outputs:\r\n                if output.output_type == \"error\":\r\n                    error = PapermillExecutionError(\r\n                        exec_count=cell.execution_count,\r\n                        source=cell.source,\r\n                        ename=output.ename,\r\n                        evalue=output.evalue,\r\n                        traceback=output.traceback,\r\n                    )\r\n                    break\r\n    \r\n        if error:\r\n            # Write notebook back out with the Error Message at the top of the Notebook.\r\n            error_msg = ERROR_MESSAGE_TEMPLATE % str(error.exec_count)\r\n            error_msg_cell = nbformat.v4.new_code_cell(\r\n                source=\"%%html\\n\" + error_msg,\r\n                outputs=[\r\n                    nbformat.v4.new_output(output_type=\"display_data\", data={\"text\/html\": error_msg})\r\n                ],\r\n                metadata={\"inputHidden\": True, \"hide_input\": True},\r\n            )\r\n            nb.cells = [error_msg_cell] + nb.cells\r\n            write_ipynb(nb, output_path)\r\n>           raise error\r\nE           papermill.exceptions.PapermillExecutionError: \r\nE           ---------------------------------------------------------------------------\r\nE           Exception encountered at \"In [26]\":\r\nE           ---------------------------------------------------------------------------\r\nE           WebserviceException                       Traceback (most recent call last)\r\nE           \/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/site-packages\/azureml\/core\/webservice\/webservice.py in wait_for_deployment(self, show_output)\r\nE               511                                           'Error:\\n'\r\nE           --> 512                                           '{}'.format(self.state, logs_response, error_response), logger=module_logger)\r\nE               513             print('{} service creation operation finished, operation \"{}\"'.format(self._webservice_type,\r\nE           \r\nE           WebserviceException: WebserviceException:\r\nE           \tMessage: Service deployment polling reached non-successful terminal state, current service state: Unhealthy\r\nE           More information can be found using '.get_logs()'\r\nE           Error:\r\nE           {\r\nE             \"code\": \"AciDeploymentFailed\",\r\nE             \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\nPlease check the logs for your container instance: im-classif-websvc. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nYou can also try to run image amlnotebookw04a7b513.azurecr.io\/image-classif-resnet18-f48:1 locally. Please refer to http:\/\/aka.ms\/debugimage#service-launch-fails for more information.\",\r\nE             \"details\": [\r\nE               {\r\nE                 \"code\": \"CrashLoopBackOff\",\r\nE                 \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\nPlease check the logs for your container instance: im-classif-websvc. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nYou can also try to run image amlnotebookw04a7b513.azurecr.io\/image-classif-resnet18-f48:1 locally. Please refer to http:\/\/aka.ms\/debugimage#service-launch-fails for more information.\"\r\nE               }\r\nE             ]\r\nE           }\r\nE           \tInnerException None\r\nE           \tErrorResponse \r\nE           {\r\nE               \"error\": {\r\nE                   \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Unhealthy\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"message\\\": \\\"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\\\nPlease check the logs for your container instance: im-classif-websvc. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\\\nYou can also try to run image amlnotebookw04a7b513.azurecr.io\/image-classif-resnet18-f48:1 locally. Please refer to http:\/\/aka.ms\/debugimage#service-launch-fails for more information.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\\\nPlease check the logs for your container instance: im-classif-websvc. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\\\nYou can also try to run image amlnotebookw04a7b513.azurecr.io\/image-classif-resnet18-f48:1 locally. Please refer to http:\/\/aka.ms\/debugimage#service-launch-fails for more information.\\\"\\n    }\\n  ]\\n}\"\r\nE               }\r\nE           }\r\nE           \r\nE           During handling of the above exception, another exception occurred:\r\nE           \r\nE           WebserviceException                       Traceback (most recent call last)\r\nE           <ipython-input-26-21aec20dbbb2> in <module>\r\nE                 1 # Deploy the web service\r\nE           ----> 2 service.wait_for_deployment(show_output=True)\r\nE           \r\nE           \/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/site-packages\/azureml\/core\/webservice\/webservice.py in wait_for_deployment(self, show_output)\r\nE               519                                           'Current state is {}'.format(self.state), logger=module_logger)\r\nE               520             else:\r\nE           --> 521                 raise WebserviceException(e.message, logger=module_logger)\r\nE               522 \r\nE               523     def _wait_for_operation_to_complete(self, show_output):\r\nE           \r\nE           WebserviceException: WebserviceException:\r\nE           \tMessage: Service deployment polling reached non-successful terminal state, current service state: Unhealthy\r\nE           More information can be found using '.get_logs()'\r\nE           Error:\r\nE           {\r\nE             \"code\": \"AciDeploymentFailed\",\r\nE             \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\nPlease check the logs for your container instance: im-classif-websvc. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nYou can also try to run image amlnotebookw04a7b513.azurecr.io\/image-classif-resnet18-f48:1 locally. Please refer to http:\/\/aka.ms\/debugimage#service-launch-fails for more information.\",\r\nE             \"details\": [\r\nE               {\r\nE                 \"code\": \"CrashLoopBackOff\",\r\nE                 \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\nPlease check the logs for your container instance: im-classif-websvc. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nYou can also try to run image amlnotebookw04a7b513.azurecr.io\/image-classif-resnet18-f48:1 locally. Please refer to http:\/\/aka.ms\/debugimage#service-launch-fails for more information.\"\r\nE               }\r\nE             ]\r\nE           }\r\nE           \tInnerException None\r\nE           \tErrorResponse \r\nE           {\r\nE               \"error\": {\r\nE                   \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Unhealthy\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"message\\\": \\\"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\\\nPlease check the logs for your container instance: im-classif-websvc. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\\\nYou can also try to run image amlnotebookw04a7b513.azurecr.io\/image-classif-resnet18-f48:1 locally. Please refer to http:\/\/aka.ms\/debugimage#service-launch-fails for more information.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\\\nPlease check the logs for your container instance: im-classif-websvc. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\\\nYou can also try to run image amlnotebookw04a7b513.azurecr.io\/image-classif-resnet18-f48:1 locally. Please refer to http:\/\/aka.ms\/debugimage#service-launch-fails for more information.\\\"\\n    }\\n  ]\\n}\"\r\nE               }\r\nE           }\r\n\r\n\/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/site-packages\/papermill\/execute.py:192: PapermillExecutionError\r\n----------------------------- Captured stderr call -----------------------------\r\n\r\nExecuting:   0%|          | 0\/65 [00:00<?, ?cell\/s]\r\nExecuting:   2%|\u258f         | 1\/65 [00:00<01:03,  1.01cell\/s]\r\nExecuting:   5%|\u258d         | 3\/65 [00:01<00:44,  1.40cell\/s]\r\nExecuting:   8%|\u258a         | 5\/65 [00:01<00:31,  1.92cell\/s]\r\nExecuting:   9%|\u2589         | 6\/65 [00:04<01:13,  1.24s\/cell]\r\nExecuting:  12%|\u2588\u258f        | 8\/65 [00:05<01:00,  1.07s\/cell]\r\nExecuting:  15%|\u2588\u258c        | 10\/65 [00:05<00:43,  1.27cell\/s]\r\nExecuting:  18%|\u2588\u258a        | 12\/65 [00:05<00:30,  1.72cell\/s]\r\nExecuting:  20%|\u2588\u2588        | 13\/65 [00:06<00:22,  2.26cell\/s]\r\nExecuting:  23%|\u2588\u2588\u258e       | 15\/65 [00:07<00:23,  2.15cell\/s]\r\nExecuting:  26%|\u2588\u2588\u258c       | 17\/65 [00:07<00:16,  2.87cell\/s]\r\nExecuting:  28%|\u2588\u2588\u258a       | 18\/65 [00:13<01:34,  2.00s\/cell]\r\nExecuting:  31%|\u2588\u2588\u2588       | 20\/65 [00:13<01:04,  1.43s\/cell]\r\nExecuting:  32%|\u2588\u2588\u2588\u258f      | 21\/65 [00:15<01:06,  1.51s\/cell]\r\nExecuting:  35%|\u2588\u2588\u2588\u258c      | 23\/65 [00:15<00:45,  1.08s\/cell]\r\nExecuting:  37%|\u2588\u2588\u2588\u258b      | 24\/65 [00:16<00:45,  1.11s\/cell]\r\nExecuting:  38%|\u2588\u2588\u2588\u258a      | 25\/65 [00:18<00:54,  1.37s\/cell]\r\nExecuting:  42%|\u2588\u2588\u2588\u2588\u258f     | 27\/65 [00:18<00:37,  1.01cell\/s]\r\nExecuting:  43%|\u2588\u2588\u2588\u2588\u258e     | 28\/65 [00:20<00:50,  1.37s\/cell]\r\nExecuting:  45%|\u2588\u2588\u2588\u2588\u258d     | 29\/65 [00:21<00:38,  1.07s\/cell]\r\nExecuting:  48%|\u2588\u2588\u2588\u2588\u258a     | 31\/65 [00:22<00:33,  1.01cell\/s]\r\nExecuting:  51%|\u2588\u2588\u2588\u2588\u2588     | 33\/65 [00:22<00:22,  1.39cell\/s]\r\nExecuting:  52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 34\/65 [00:23<00:19,  1.61cell\/s]\r\nExecuting:  54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 35\/65 [00:23<00:14,  2.11cell\/s]\r\nExecuting:  57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 37\/65 [00:23<00:10,  2.76cell\/s]\r\nExecuting:  58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 38\/65 [00:23<00:07,  3.41cell\/s]\r\nExecuting:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 40\/65 [00:24<00:05,  4.18cell\/s]\r\nExecuting:  65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 42\/65 [00:24<00:04,  5.02cell\/s]\r\nExecuting:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 43\/65 [00:32<00:59,  2.70s\/cell]\r\nExecuting:  68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 44\/65 [11:52<1:12:00, 205.75s\/cell]\r\nExecuting:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 45\/65 [11:52<48:01, 144.08s\/cell]  \r\nExecuting:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 46\/65 [11:53<32:00, 101.08s\/cell]\r\nExecuting:  72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 47\/65 [11:53<21:14, 70.80s\/cell] \r\nExecuting:  74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 48\/65 [11:53<14:03, 49.63s\/cell]\r\nExecuting:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 49\/65 [11:53<09:16, 34.79s\/cell]\r\nExecuting:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 50\/65 [11:53<06:05, 24.40s\/cell]\r\nExecuting:  78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 51\/65 [11:56<04:07, 17.70s\/cell]\r\nExecuting:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 52\/65 [11:56<02:41, 12.44s\/cell]\r\nExecuting:  82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 53\/65 [18:32<25:30, 127.58s\/cell]\r\nExecuting:  82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 53\/65 [18:33<04:12, 21.01s\/cell] \r\n_____________________________ test_22_notebook_run _____________________________\r\n\r\nclassification_notebooks = {'00_webcam': '\/home\/vsts\/work\/1\/s\/classification\/notebooks\/00_webcam.ipynb', '01_training_introduction': '\/home\/vsts\/...3_training_accuracy_vs_speed': '\/home\/vsts\/work\/1\/s\/classification\/notebooks\/03_training_accuracy_vs_speed.ipynb', ...}\r\nsubscription_id = '***'\r\nresource_group = 'amlnotebookrg', workspace_name = 'amlnotebookws'\r\nworkspace_region = '***2'\r\n\r\n    @pytest.mark.azuremlnotebooks\r\n    def test_22_notebook_run(\r\n        classification_notebooks,\r\n        subscription_id,\r\n        resource_group,\r\n        workspace_name,\r\n        workspace_region,\r\n    ):\r\n        notebook_path = classification_notebooks[\r\n            \"22_deployment_on_azure_kubernetes_service\"\r\n        ]\r\n        pm.execute_notebook(\r\n            notebook_path,\r\n            OUTPUT_NOTEBOOK,\r\n            parameters=dict(\r\n                PM_VERSION=pm.__version__,\r\n                subscription_id=subscription_id,\r\n                resource_group=resource_group,\r\n                workspace_name=workspace_name,\r\n                workspace_region=workspace_region,\r\n            ),\r\n>           kernel_name=KERNEL_NAME,\r\n        )\r\n\r\ntests\/smoke\/test_azureml_notebooks.py:83: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/site-packages\/papermill\/execute.py:108: in execute_notebook\r\n    raise_for_execution_errors(nb, output_path)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nnb = {'cells': [{'cell_type': 'code', 'metadata': {'inputHidden': True, 'hide_input': True}, 'execution_count': None, 'sour..._time': '2019-09-24T17:58:40.389449', 'duration': 1402.445046, 'exception': True}}, 'nbformat': 4, 'nbformat_minor': 2}\r\noutput_path = 'output.ipynb'\r\n\r\n    def raise_for_execution_errors(nb, output_path):\r\n        \"\"\"Assigned parameters into the appropriate place in the input notebook\r\n    \r\n        Parameters\r\n        ----------\r\n        nb : NotebookNode\r\n           Executable notebook object\r\n        output_path : str\r\n           Path to write executed notebook\r\n        \"\"\"\r\n        error = None\r\n        for cell in nb.cells:\r\n            if cell.get(\"outputs\") is None:\r\n                continue\r\n    \r\n            for output in cell.outputs:\r\n                if output.output_type == \"error\":\r\n                    error = PapermillExecutionError(\r\n                        exec_count=cell.execution_count,\r\n                        source=cell.source,\r\n                        ename=output.ename,\r\n                        evalue=output.evalue,\r\n                        traceback=output.traceback,\r\n                    )\r\n                    break\r\n    \r\n        if error:\r\n            # Write notebook back out with the Error Message at the top of the Notebook.\r\n            error_msg = ERROR_MESSAGE_TEMPLATE % str(error.exec_count)\r\n            error_msg_cell = nbformat.v4.new_code_cell(\r\n                source=\"%%html\\n\" + error_msg,\r\n                outputs=[\r\n                    nbformat.v4.new_output(output_type=\"display_data\", data={\"text\/html\": error_msg})\r\n                ],\r\n                metadata={\"inputHidden\": True, \"hide_input\": True},\r\n            )\r\n            nb.cells = [error_msg_cell] + nb.cells\r\n            write_ipynb(nb, output_path)\r\n>           raise error\r\nE           papermill.exceptions.PapermillExecutionError: \r\nE           ---------------------------------------------------------------------------\r\nE           Exception encountered at \"In [12]\":\r\nE           ---------------------------------------------------------------------------\r\nE           WebserviceException                       Traceback (most recent call last)\r\nE           \/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/site-packages\/azureml\/core\/webservice\/webservice.py in wait_for_deployment(self, show_output)\r\nE               511                                           'Error:\\n'\r\nE           --> 512                                           '{}'.format(self.state, logs_response, error_response), logger=module_logger)\r\nE               513             print('{} service creation operation finished, operation \"{}\"'.format(self._webservice_type,\r\nE           \r\nE           WebserviceException: WebserviceException:\r\nE           \tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\r\nE           More information can be found using '.get_logs()'\r\nE           Error:\r\nE           {\r\nE             \"code\": \"KubernetesDeploymentFailed\",\r\nE             \"statusCode\": 400,\r\nE             \"message\": \"Kubernetes Deployment failed\",\r\nE             \"details\": [\r\nE               {\r\nE                 \"code\": \"CrashLoopBackOff\",\r\nE                 \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\nPlease check the logs for your container instance: aks-cpu-image-classif-web-svc. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nYou can also try to run image amlnotebookw04a7b513.azurecr.io\/image-classif-resnet18-f48:1 locally. Please refer to http:\/\/aka.ms\/debugimage#service-launch-fails for more information.\"\r\nE               }\r\nE             ]\r\nE           }\r\nE           \tInnerException None\r\nE           \tErrorResponse \r\nE           {\r\nE               \"error\": {\r\nE                   \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"KubernetesDeploymentFailed\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Kubernetes Deployment failed\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\\\nPlease check the logs for your container instance: aks-cpu-image-classif-web-svc. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\\\nYou can also try to run image amlnotebookw04a7b513.azurecr.io\/image-classif-resnet18-f48:1 locally. Please refer to http:\/\/aka.ms\/debugimage#service-launch-fails for more information.\\\"\\n    }\\n  ]\\n}\"\r\nE               }\r\nE           }\r\nE           \r\nE           During handling of the above exception, another exception occurred:\r\nE           \r\nE           WebserviceException                       Traceback (most recent call last)\r\nE           <ipython-input-12-ea5338712650> in <module>\r\nE                 8         deployment_target = aks_target\r\nE                 9     )\r\nE           ---> 10     aks_service.wait_for_deployment(show_output = True)\r\nE                11     print(f\"The web service is {aks_service.state}\")\r\nE                12 else:\r\nE           \r\nE           \/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/site-packages\/azureml\/core\/webservice\/webservice.py in wait_for_deployment(self, show_output)\r\nE               519                                           'Current state is {}'.format(self.state), logger=module_logger)\r\nE               520             else:\r\nE           --> 521                 raise WebserviceException(e.message, logger=module_logger)\r\nE               522 \r\nE               523     def _wait_for_operation_to_complete(self, show_output):\r\nE           \r\nE           WebserviceException: WebserviceException:\r\nE           \tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\r\nE           More information can be found using '.get_logs()'\r\nE           Error:\r\nE           {\r\nE             \"code\": \"KubernetesDeploymentFailed\",\r\nE             \"statusCode\": 400,\r\nE             \"message\": \"Kubernetes Deployment failed\",\r\nE             \"details\": [\r\nE               {\r\nE                 \"code\": \"CrashLoopBackOff\",\r\nE                 \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\nPlease check the logs for your container instance: aks-cpu-image-classif-web-svc. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nYou can also try to run image amlnotebookw04a7b513.azurecr.io\/image-classif-resnet18-f48:1 locally. Please refer to http:\/\/aka.ms\/debugimage#service-launch-fails for more information.\"\r\nE               }\r\nE             ]\r\nE           }\r\nE           \tInnerException None\r\nE           \tErrorResponse \r\nE           {\r\nE               \"error\": {\r\nE                   \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"KubernetesDeploymentFailed\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Kubernetes Deployment failed\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\\\nPlease check the logs for your container instance: aks-cpu-image-classif-web-svc. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\\\nYou can also try to run image amlnotebookw04a7b513.azurecr.io\/image-classif-resnet18-f48:1 locally. Please refer to http:\/\/aka.ms\/debugimage#service-launch-fails for more information.\\\"\\n    }\\n  ]\\n}\"\r\nE               }\r\nE           }\r\n\r\n\/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/site-packages\/papermill\/execute.py:192: PapermillExecutionError\r\n```\r\n\r\nFYI @PatrickBue @jiata any idea of what could be happening?\r\n\r\n### In which platform does it happen?\r\n<!--- Describe the platform where the issue is happening (use a list if needed) -->\r\n<!--- For example: -->\r\n<!--- * Windows\/Linux.  -->\r\n<!--- * CPU\/GPU.  -->\r\n<!--- * Azure Data Science Virtual Machine. -->\r\n\r\n### How do we replicate the issue?\r\n<!--- Please be specific as possible (use a list if needed). -->\r\n<!--- For example: -->\r\n<!--- * Create a Linux Data Science Virtual Machine one Azure with V100 GPU -->\r\n<!--- * Run unit test `test_classification_data.py` -->\r\n<!--- * ... -->\r\n\r\n### Expected behavior (i.e. solution)\r\n<!--- For example:  -->\r\n<!--- * The test `test_is_data_multilabel` for GPU model training should pass successfully. -->\r\n\r\n### Other Comments\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"bug error notebook descript error look relat deploy aci ak resourc fff failur test notebook run classif notebook webcam home vst work classif notebook webcam ipynb train introduct home vst train accuraci speed home vst work classif notebook train accuraci speed ipynb subscript resourc group amlnotebookrg workspac amlnotebookw workspac region pytest mark notebook def test notebook run classif notebook subscript resourc group workspac workspac region notebook path classif notebook deploy azur contain instanc execut notebook notebook path output notebook paramet dict version version subscript subscript resourc group resourc group workspac workspac workspac region workspac region kernel kernel test smoke test notebook usr share miniconda env lib python site packag papermil execut execut notebook rais execut error output path cell cell type code metadata inputhidden true hide input true execut count sour time durat except true nbformat nbformat minor output path output ipynb def rais execut error output path assign paramet appropri place input notebook paramet notebooknod execut notebook object output path str path write execut notebook error cell cell cell output continu output cell output output output type error error papermillexecutionerror exec count cell execut count sourc cell sourc enam output enam evalu output evalu traceback output traceback break error write notebook error messag notebook error msg error messag templat str error exec count error msg cell nbformat new code cell sourc html error msg output nbformat new output output type displai data data text html error msg metadata inputhidden true hide input true cell error msg cell cell write ipynb output path rais error papermil except papermillexecutionerror except encount webserviceexcept traceback recent usr share miniconda env lib python site packag core webservic webservic wait deploy self output error format self state log respons error respons logger modul logger print servic creation oper finish oper format self webservic type webserviceexcept webserviceexcept messag servic deploy poll reach non success termin state current servic state unhealthi inform log error code acideploymentfail messag aci deploy fail except contain applic crash caus error score file init function npleas check log contain instanc classif websvc aml sdk run print servic log servic object fetch log nyou try run imag amlnotebookwab azurecr imag classif resnet local refer http aka debugimag servic launch fail inform detail code crashloopbackoff messag contain applic crash caus error score file init function npleas check log contain instanc classif websvc aml sdk run print servic log servic object fetch log nyou try run imag amlnotebookwab azurecr imag classif resnet local refer http aka debugimag servic launch fail inform innerexcept errorrespons error messag servic deploy poll reach non success termin state current servic state unhealthi nmore inform log nerror code acideploymentfail messag aci deploy fail except contain applic crash caus error score file init function npleas check log contain instanc classif websvc aml sdk run print servic log servic object fetch log nyou try run imag amlnotebookwab azurecr imag classif resnet local refer http aka debugimag servic launch fail inform detail code crashloopbackoff messag contain applic crash caus error score file init function npleas check log contain instanc classif websvc aml sdk run print servic log servic object fetch log nyou try run imag amlnotebookwab azurecr imag classif resnet local refer http aka debugimag servic launch fail inform handl except except occur webserviceexcept traceback recent deploi web servic servic wait deploy output true usr share miniconda env lib python site packag core webservic webservic wait deploy self output current state format self state logger modul logger rais webserviceexcept messag logger modul logger def wait oper complet self output webserviceexcept webserviceexcept messag servic deploy poll reach non success termin state current servic state unhealthi inform log error code acideploymentfail messag aci deploy fail except contain applic crash caus error score file init function npleas check log contain instanc classif websvc aml sdk run print servic log servic object fetch log nyou try run imag amlnotebookwab azurecr imag classif resnet local refer http aka debugimag servic launch fail inform detail code crashloopbackoff messag contain applic crash caus error score file init function npleas check log contain instanc classif websvc aml sdk run print servic log servic object fetch log nyou try run imag amlnotebookwab azurecr imag classif resnet local refer http aka debugimag servic launch fail inform innerexcept errorrespons error messag servic deploy poll reach non success termin state current servic state unhealthi nmore inform log nerror code acideploymentfail messag aci deploy fail except contain applic crash caus error score file init function npleas check log contain instanc classif websvc aml sdk run print servic log servic object fetch log nyou try run imag amlnotebookwab azurecr imag classif resnet local refer http aka debugimag servic launch fail inform detail code crashloopbackoff messag contain applic crash caus error score file init function npleas check log contain instanc classif websvc aml sdk run print servic log servic object fetch log nyou try run imag amlnotebookwab azurecr imag classif resnet local refer http aka debugimag servic launch fail inform usr share miniconda env lib python site packag papermil execut papermillexecutionerror captur stderr execut kernel kernel test smoke test notebook usr share miniconda env lib python site packag papermil execut execut notebook rais execut error output path cell cell type code metadata inputhidden true hide input true execut count sour time durat except true nbformat nbformat minor output path output ipynb def rais execut error output path assign paramet appropri place input notebook paramet notebooknod execut notebook object output path str path write execut notebook error cell cell cell output continu output cell output output output type error error papermillexecutionerror exec count cell execut count sourc cell sourc enam output enam evalu output evalu traceback output traceback break error write notebook error messag notebook error msg error messag templat str error exec count error msg cell nbformat new code cell sourc html error msg output nbformat new output output type displai data data text html error msg metadata inputhidden true hide input true cell error msg cell cell write ipynb output path rais error papermil except papermillexecutionerror except encount webserviceexcept traceback recent usr share miniconda env lib python site packag core webservic webservic wait deploy self output error format self state log respons error respons logger modul logger print servic creation oper finish oper format self webservic type webserviceexcept webserviceexcept messag servic deploy poll reach non success termin state current servic state fail inform log error code kubernetesdeploymentfail statuscod messag kubernet deploy fail detail code crashloopbackoff messag contain applic crash caus error score file init function npleas check log contain instanc ak cpu imag classif web svc aml sdk run print servic log servic object fetch log nyou try run imag amlnotebookwab azurecr imag classif resnet local refer http aka debugimag servic launch fail inform innerexcept errorrespons error messag servic deploy poll reach non success termin state current servic state fail nmore inform log nerror code kubernetesdeploymentfail statuscod messag kubernet deploy fail detail code crashloopbackoff messag contain applic crash caus error score file init function npleas check log contain instanc ak cpu imag classif web svc aml sdk run print servic log servic object fetch log nyou try run imag amlnotebookwab azurecr imag classif resnet local refer http aka debugimag servic launch fail inform handl except except occur webserviceexcept traceback recent deploy target ak target ak servic wait deploy output true print web servic ak servic state usr share miniconda env lib python site packag core webservic webservic wait deploy self output current state format self state logger modul logger rais webserviceexcept messag logger modul logger def wait oper complet self output webserviceexcept webserviceexcept messag servic deploy poll reach non success termin state current servic state fail inform log error code kubernetesdeploymentfail statuscod messag kubernet deploy fail detail code crashloopbackoff messag contain applic crash caus error score file init function npleas check log contain instanc ak cpu imag classif web svc aml sdk run print servic log servic object fetch log nyou try run imag amlnotebookwab azurecr imag classif resnet local refer http aka debugimag servic launch fail inform innerexcept errorrespons error messag servic deploy poll reach non success termin state current servic state fail nmore inform log nerror code kubernetesdeploymentfail statuscod messag kubernet deploy fail detail code crashloopbackoff messag contain applic crash caus error score file init function npleas check log contain instanc ak cpu imag classif web svc aml sdk run print servic log servic object fetch log nyou try run imag amlnotebookwab azurecr imag classif resnet local refer http aka debugimag servic launch fail inform usr share miniconda env lib python site packag papermil execut papermillexecutionerror fyi patrickbu jiata idea happen platform happen replic issu expect behavior solut comment",
        "Issue_preprocessed_content":" descript relat deploy aci ak resourc fyi idea platform platform exampl azur data scienc virtual machin replic specif exampl creat linux data scienc virtual machin azur gpu run unit test expect behavior exampl test gpu model train",
        "Issue_gpt_summary_original":"The user is facing an issue in AzureML where memory utilization metrics are not correctly visible for all GPUs in a particular experiment. Additionally, the MemAllocated and MemReserved metrics are showing as zero, rendering them meaningless.",
        "Issue_gpt_summary":"user face issu memori util metric correctli visibl gpu particular experi addition memalloc memreserv metric show zero render meaningless",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/computervision-recipes\/issues\/320",
        "Issue_title":"[BUG] pipeline azureml-notebook-test-linux-cpu failing",
        "Issue_created_time":1568285443000,
        "Issue_closed_time":1569234937000,
        "Issue_body":"### Description\r\n<!--- Describe your issue\/bug\/request in detail -->\r\n```\r\n.FFF.                                                                    [100%]\r\n=================================== FAILURES ===================================\r\n_____________________________ test_21_notebook_run _____________________________\r\n\r\nclassification_notebooks = {'00_webcam': '\/home\/vsts\/work\/1\/s\/classification\/notebooks\/00_webcam.ipynb', '01_training_introduction': '\/home\/vsts\/...3_training_accuracy_vs_speed': '\/home\/vsts\/work\/1\/s\/classification\/notebooks\/03_training_accuracy_vs_speed.ipynb', ...}\r\nsubscription_id = '***'\r\nresource_group = 'amlnotebookrg', workspace_name = 'amlnotebookws'\r\nworkspace_region = '***2'\r\n\r\n    @pytest.mark.azuremlnotebooks\r\n    def test_21_notebook_run(\r\n        classification_notebooks,\r\n        subscription_id,\r\n        resource_group,\r\n        workspace_name,\r\n        workspace_region,\r\n    ):\r\n        notebook_path = classification_notebooks[\r\n            \"21_deployment_on_azure_container_instances\"\r\n        ]\r\n        pm.execute_notebook(\r\n            notebook_path,\r\n            OUTPUT_NOTEBOOK,\r\n            parameters=dict(\r\n                PM_VERSION=pm.__version__,\r\n                subscription_id=subscription_id,\r\n                resource_group=resource_group,\r\n                workspace_name=workspace_name,\r\n                workspace_region=workspace_region,\r\n            ),\r\n>           kernel_name=KERNEL_NAME,\r\n        )\r\n\r\ntests\/smoke\/test_azureml_notebooks.py:58: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/site-packages\/papermill\/execute.py:104: in execute_notebook\r\n    raise_for_execution_errors(nb, output_path)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nnb = {'cells': [{'cell_type': 'code', 'metadata': {'inputHidden': True, 'hide_input': True}, 'execution_count': None, 'sour...end_time': '2019-09-12T10:19:40.699401', 'duration': 5.033488, 'exception': True}}, 'nbformat': 4, 'nbformat_minor': 2}\r\noutput_path = 'output.ipynb'\r\n\r\n    def raise_for_execution_errors(nb, output_path):\r\n        \"\"\"Assigned parameters into the appropriate place in the input notebook\r\n    \r\n        Parameters\r\n        ----------\r\n        nb : NotebookNode\r\n           Executable notebook object\r\n        output_path : str\r\n           Path to write executed notebook\r\n        \"\"\"\r\n        error = None\r\n        for cell in nb.cells:\r\n            if cell.get(\"outputs\") is None:\r\n                continue\r\n    \r\n            for output in cell.outputs:\r\n                if output.output_type == \"error\":\r\n                    error = PapermillExecutionError(\r\n                        exec_count=cell.execution_count,\r\n                        source=cell.source,\r\n                        ename=output.ename,\r\n                        evalue=output.evalue,\r\n                        traceback=output.traceback,\r\n                    )\r\n                    break\r\n    \r\n        if error:\r\n            # Write notebook back out with the Error Message at the top of the Notebook.\r\n            error_msg = ERROR_MESSAGE_TEMPLATE % str(error.exec_count)\r\n            error_msg_cell = nbformat.v4.new_code_cell(\r\n                source=\"%%html\\n\" + error_msg,\r\n                outputs=[\r\n                    nbformat.v4.new_output(output_type=\"display_data\", data={\"text\/html\": error_msg})\r\n                ],\r\n                metadata={\"inputHidden\": True, \"hide_input\": True},\r\n            )\r\n            nb.cells = [error_msg_cell] + nb.cells\r\n            write_ipynb(nb, output_path)\r\n>           raise error\r\nE           papermill.exceptions.PapermillExecutionError: \r\nE           ---------------------------------------------------------------------------\r\nE           Exception encountered at \"In [2]\":\r\nE           ---------------------------------------------------------------------------\r\nE           SSLError                                  Traceback (most recent call last)\r\nE           \/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/urllib\/request.py in do_open(self, http_class, req, **http_conn_args)\r\nE              1317                 h.request(req.get_method(), req.selector, req.data, headers,\r\nE           -> 1318                           encode_chunked=req.has_header('Transfer-encoding'))\r\nE              1319             except OSError as err: # timeout error\r\nE           \r\nE           \/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/http\/client.py in request(self, method, url, body, headers, encode_chunked)\r\nE              1238         \"\"\"Send a complete request to the server.\"\"\"\r\nE           -> 1239         self._send_request(method, url, body, headers, encode_chunked)\r\nE              1240 \r\nE           \r\nE           \/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/http\/client.py in _send_request(self, method, url, body, headers, encode_chunked)\r\nE              1284             body = _encode(body, 'body')\r\nE           -> 1285         self.endheaders(body, encode_chunked=encode_chunked)\r\nE              1286 \r\nE           \r\nE           \/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/http\/client.py in endheaders(self, message_body, encode_chunked)\r\nE              1233             raise CannotSendHeader()\r\nE           -> 1234         self._send_output(message_body, encode_chunked=encode_chunked)\r\nE              1235 \r\nE           \r\nE           \/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/http\/client.py in _send_output(self, message_body, encode_chunked)\r\nE              1025         del self._buffer[:]\r\nE           -> 1026         self.send(msg)\r\nE              1027 \r\nE           \r\nE           \/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/http\/client.py in send(self, data)\r\nE               963             if self.auto_open:\r\nE           --> 964                 self.connect()\r\nE               965             else:\r\nE           \r\nE           \/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/http\/client.py in connect(self)\r\nE              1399             self.sock = self._context.wrap_socket(self.sock,\r\nE           -> 1400                                                   server_hostname=server_hostname)\r\nE              1401             if not self._context.check_hostname and self._check_hostname:\r\nE           \r\nE           \/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/ssl.py in wrap_socket(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\r\nE               406                          server_hostname=server_hostname,\r\nE           --> 407                          _context=self, _session=session)\r\nE               408 \r\nE           \r\nE           \/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/ssl.py in __init__(self, sock, keyfile, certfile, server_side, cert_reqs, ssl_version, ca_certs, do_handshake_on_connect, family, type, proto, fileno, suppress_ragged_eofs, npn_protocols, ciphers, server_hostname, _context, _session)\r\nE               816                         raise ValueError(\"do_handshake_on_connect should not be specified for non-blocking sockets\")\r\nE           --> 817                     self.do_handshake()\r\nE               818 \r\nE           \r\nE           \/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/ssl.py in do_handshake(self, block)\r\nE              1076                 self.settimeout(None)\r\nE           -> 1077             self._sslobj.do_handshake()\r\nE              1078         finally:\r\nE           \r\nE           \/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/ssl.py in do_handshake(self)\r\nE               688         \"\"\"Start the SSL\/TLS handshake.\"\"\"\r\nE           --> 689         self._sslobj.do_handshake()\r\nE               690         if self.context.check_hostname:\r\nE           \r\nE           SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:852)\r\nE           \r\nE           During handling of the above exception, another exception occurred:\r\nE           \r\nE           URLError                                  Traceback (most recent call last)\r\nE           <ipython-input-2-2e2a8adec5e2> in <module>\r\nE           ----> 1 learn = model_to_learner(models.resnet18(pretrained=True), IMAGENET_IM_SIZE)\r\nE           \r\nE           \/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/site-packages\/torchvision\/models\/resnet.py in resnet18(pretrained, progress, **kwargs)\r\nE               229     \"\"\"\r\nE               230     return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress,\r\nE           --> 231                    **kwargs)\r\nE               232 \r\nE               233 \r\nE           \r\nE           \/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/site-packages\/torchvision\/models\/resnet.py in _resnet(arch, block, layers, pretrained, progress, **kwargs)\r\nE               215     if pretrained:\r\nE               216         state_dict = load_state_dict_from_url(model_urls[arch],\r\nE           --> 217                                               progress=progress)\r\nE               218         model.load_state_dict(state_dict)\r\nE               219     return model\r\nE           \r\nE           \/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/site-packages\/torch\/hub.py in load_state_dict_from_url(url, model_dir, map_location, progress)\r\nE               460         sys.stderr.write('Downloading: \"{}\" to {}\\n'.format(url, cached_file))\r\nE               461         hash_prefix = HASH_REGEX.search(filename).group(1)\r\nE           --> 462         _download_url_to_file(url, cached_file, hash_prefix, progress=progress)\r\nE               463     return torch.load(cached_file, map_location=map_location)\r\nE           \r\nE           \/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/site-packages\/torch\/hub.py in _download_url_to_file(url, dst, hash_prefix, progress)\r\nE               370 def _download_url_to_file(url, dst, hash_prefix, progress):\r\nE               371     file_size = None\r\nE           --> 372     u = urlopen(url)\r\nE               373     meta = u.info()\r\nE               374     if hasattr(meta, 'getheaders'):\r\nE           \r\nE           \/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/urllib\/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context)\r\nE               221     else:\r\nE               222         opener = _opener\r\nE           --> 223     return opener.open(url, data, timeout)\r\nE               224 \r\nE               225 def install_opener(opener):\r\nE           \r\nE           \/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/urllib\/request.py in open(self, fullurl, data, timeout)\r\nE               524             req = meth(req)\r\nE               525 \r\nE           --> 526         response = self._open(req, data)\r\nE               527 \r\nE               528         # post-process response\r\nE           \r\nE           \/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/urllib\/request.py in _open(self, req, data)\r\nE               542         protocol = req.type\r\nE               543         result = self._call_chain(self.handle_open, protocol, protocol +\r\nE           --> 544                                   '_open', req)\r\nE               545         if result:\r\nE               546             return result\r\nE           \r\nE           \/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/urllib\/request.py in _call_chain(self, chain, kind, meth_name, *args)\r\nE               502         for handler in handlers:\r\nE               503             func = getattr(handler, meth_name)\r\nE           --> 504             result = func(*args)\r\nE               505             if result is not None:\r\nE               506                 return result\r\nE           \r\nE           \/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/urllib\/request.py in https_open(self, req)\r\nE              1359         def https_open(self, req):\r\nE              1360             return self.do_open(http.client.HTTPSConnection, req,\r\nE           -> 1361                 context=self._context, check_hostname=self._check_hostname)\r\nE              1362 \r\nE              1363         https_request = AbstractHTTPHandler.do_request_\r\nE           \r\nE           \/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/urllib\/request.py in do_open(self, http_class, req, **http_conn_args)\r\nE              1318                           encode_chunked=req.has_header('Transfer-encoding'))\r\nE              1319             except OSError as err: # timeout error\r\nE           -> 1320                 raise URLError(err)\r\nE              1321             r = h.getresponse()\r\nE              1322         except:\r\nE           \r\nE           URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:852)>\r\n\r\n\/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/site-packages\/papermill\/execute.py:188: PapermillExecutionError\r\n----------------------------- Captured stderr call -----------------------------\r\n\r\nExecuting:   0%|          | 0\/65 [00:00<?, ?cell\/s]\r\nExecuting:   2%|\u258f         | 1\/65 [00:00<00:56,  1.14cell\/s]\r\nExecuting:   5%|\u258d         | 3\/65 [00:01<00:39,  1.58cell\/s]\r\nExecuting:   8%|\u258a         | 5\/65 [00:01<00:27,  2.16cell\/s]\r\nExecuting:   9%|\u2589         | 6\/65 [00:03<01:00,  1.03s\/cell]\r\nExecuting:  12%|\u2588\u258f        | 8\/65 [00:04<00:47,  1.19cell\/s]\r\nExecuting:  12%|\u2588\u258f        | 8\/65 [00:05<00:35,  1.59cell\/s]\r\n_____________________________ test_22_notebook_run _____________________________\r\n\r\nclassification_notebooks = {'00_webcam': '\/home\/vsts\/work\/1\/s\/classification\/notebooks\/00_webcam.ipynb', '01_training_introduction': '\/home\/vsts\/...3_training_accuracy_vs_speed': '\/home\/vsts\/work\/1\/s\/classification\/notebooks\/03_training_accuracy_vs_speed.ipynb', ...}\r\nsubscription_id = '***'\r\nresource_group = 'amlnotebookrg', workspace_name = 'amlnotebookws'\r\nworkspace_region = '***2'\r\n\r\n    @pytest.mark.azuremlnotebooks\r\n    def test_22_notebook_run(\r\n        classification_notebooks,\r\n        subscription_id,\r\n        resource_group,\r\n        workspace_name,\r\n        workspace_region,\r\n    ):\r\n        notebook_path = classification_notebooks[\r\n            \"22_deployment_on_azure_kubernetes_service\"\r\n        ]\r\n        pm.execute_notebook(\r\n            notebook_path,\r\n            OUTPUT_NOTEBOOK,\r\n            parameters=dict(\r\n                PM_VERSION=pm.__version__,\r\n                subscription_id=subscription_id,\r\n                resource_group=resource_group,\r\n                workspace_name=workspace_name,\r\n                workspace_region=workspace_region,\r\n            ),\r\n>           kernel_name=KERNEL_NAME,\r\n        )\r\n\r\ntests\/smoke\/test_azureml_notebooks.py:83: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/site-packages\/papermill\/execute.py:104: in execute_notebook\r\n    raise_for_execution_errors(nb, output_path)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nnb = {'cells': [{'cell_type': 'code', 'metadata': {'inputHidden': True, 'hide_input': True}, 'execution_count': None, 'sour...end_time': '2019-09-12T10:19:46.959285', 'duration': 5.817276, 'exception': True}}, 'nbformat': 4, 'nbformat_minor': 2}\r\noutput_path = 'output.ipynb'\r\n\r\n    def raise_for_execution_errors(nb, output_path):\r\n        \"\"\"Assigned parameters into the appropriate place in the input notebook\r\n    \r\n        Parameters\r\n        ----------\r\n        nb : NotebookNode\r\n           Executable notebook object\r\n        output_path : str\r\n           Path to write executed notebook\r\n        \"\"\"\r\n        error = None\r\n        for cell in nb.cells:\r\n            if cell.get(\"outputs\") is None:\r\n                continue\r\n    \r\n            for output in cell.outputs:\r\n                if output.output_type == \"error\":\r\n                    error = PapermillExecutionError(\r\n                        exec_count=cell.execution_count,\r\n                        source=cell.source,\r\n                        ename=output.ename,\r\n                        evalue=output.evalue,\r\n                        traceback=output.traceback,\r\n                    )\r\n                    break\r\n    \r\n        if error:\r\n            # Write notebook back out with the Error Message at the top of the Notebook.\r\n            error_msg = ERROR_MESSAGE_TEMPLATE % str(error.exec_count)\r\n            error_msg_cell = nbformat.v4.new_code_cell(\r\n                source=\"%%html\\n\" + error_msg,\r\n                outputs=[\r\n                    nbformat.v4.new_output(output_type=\"display_data\", data={\"text\/html\": error_msg})\r\n                ],\r\n                metadata={\"inputHidden\": True, \"hide_input\": True},\r\n            )\r\n            nb.cells = [error_msg_cell] + nb.cells\r\n            write_ipynb(nb, output_path)\r\n>           raise error\r\nE           papermill.exceptions.PapermillExecutionError: \r\nE           ---------------------------------------------------------------------------\r\nE           Exception encountered at \"In [6]\":\r\nE           ---------------------------------------------------------------------------\r\nE           KeyError                                  Traceback (most recent call last)\r\nE           <ipython-input-6-af5043783823> in <module>\r\nE           ----> 1 docker_image = ws.images[\"image-classif-resnet18-f48\"]\r\nE           \r\nE           KeyError: 'image-classif-resnet18-f48'\r\n\r\n\/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/site-packages\/papermill\/execute.py:188: PapermillExecutionError\r\n----------------------------- Captured stderr call -----------------------------\r\n\r\nExecuting:   0%|          | 0\/36 [00:00<?, ?cell\/s]\r\nExecuting:   3%|\u258e         | 1\/36 [00:00<00:30,  1.16cell\/s]\r\nExecuting:  11%|\u2588         | 4\/36 [00:02<00:24,  1.32cell\/s]\r\nExecuting:  19%|\u2588\u2589        | 7\/36 [00:02<00:15,  1.84cell\/s]\r\nExecuting:  25%|\u2588\u2588\u258c       | 9\/36 [00:02<00:10,  2.52cell\/s]\r\nExecuting:  31%|\u2588\u2588\u2588       | 11\/36 [00:03<00:10,  2.47cell\/s]\r\nExecuting:  33%|\u2588\u2588\u2588\u258e      | 12\/36 [00:04<00:16,  1.50cell\/s]\r\nExecuting:  39%|\u2588\u2588\u2588\u2589      | 14\/36 [00:05<00:12,  1.81cell\/s]\r\nExecuting:  39%|\u2588\u2588\u2588\u2589      | 14\/36 [00:05<00:09,  2.41cell\/s]\r\n_____________________________ test_23_notebook_run _____________________________\r\n\r\nclassification_notebooks = {'00_webcam': '\/home\/vsts\/work\/1\/s\/classification\/notebooks\/00_webcam.ipynb', '01_training_introduction': '\/home\/vsts\/...3_training_accuracy_vs_speed': '\/home\/vsts\/work\/1\/s\/classification\/notebooks\/03_training_accuracy_vs_speed.ipynb', ...}\r\nsubscription_id = '***'\r\nresource_group = 'amlnotebookrg', workspace_name = 'amlnotebookws'\r\nworkspace_region = '***2'\r\n\r\n    @pytest.mark.azuremlnotebooks\r\n    def test_23_notebook_run(\r\n        classification_notebooks,\r\n        subscription_id,\r\n        resource_group,\r\n        workspace_name,\r\n        workspace_region,\r\n    ):\r\n        notebook_path = classification_notebooks[\"23_aci_aks_web_service_testing\"]\r\n        pm.execute_notebook(\r\n            notebook_path,\r\n            OUTPUT_NOTEBOOK,\r\n            parameters=dict(\r\n                PM_VERSION=pm.__version__,\r\n                subscription_id=subscription_id,\r\n                resource_group=resource_group,\r\n                workspace_name=workspace_name,\r\n                workspace_region=workspace_region,\r\n            ),\r\n>           kernel_name=KERNEL_NAME,\r\n        )\r\n\r\ntests\/smoke\/test_azureml_notebooks.py:106: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\/usr\/share\/miniconda\/envs\/cv\/lib\/python3.6\/site-packages\/papermill\/execute.py:104: in execute_notebook\r\n    raise_for_execution_errors(nb, output_path)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nnb = {'cells': [{'cell_type': 'code', 'metadata': {'inputHidden': True, 'hide_input': True}, 'execution_count': None, 'sour...end_time': '2019-09-12T10:19:53.061402', 'duration': 6.023939, 'exception': True}}, 'nbformat': 4, 'nbformat_minor': 2}\r\noutput_path = 'output.ipynb'\r\n\r\n    def raise_for_execution_errors(nb, output_path):\r\n        \"\"\"Assigned parameters into the appropriate place in the input notebook\r\n    \r\n        Parameters\r\n        ----------\r\n        nb : NotebookNode\r\n           Executable notebook object\r\n        output_path : str\r\n           Path to write executed notebook\r\n        \"\"\"\r\n        error = None\r\n        for cell in nb.cells:\r\n            if cell.get(\"outputs\") is None:\r\n                continue\r\n    \r\n            for output in cell.outputs:\r\n                if output.output_type == \"error\":\r\n                    error = PapermillExecutionError(\r\n                        exec_count=cell.execution_count,\r\n                        source=cell.source,\r\n                        ename=output.ename,\r\n                        evalue=output.evalue,\r\n                        traceback=output.traceback,\r\n                    )\r\n                    break\r\n    \r\n        if error:\r\n            # Write notebook back out with the Error Message at the top of the Notebook.\r\n            error_msg = ERROR_MESSAGE_TEMPLATE % str(error.exec_count)\r\n            error_msg_cell = nbformat.v4.new_code_cell(\r\n                source=\"%%html\\n\" + error_msg,\r\n                outputs=[\r\n                    nbformat.v4.new_output(output_type=\"display_data\", data={\"text\/html\": error_msg})\r\n                ],\r\n                metadata={\"inputHidden\": True, \"hide_input\": True},\r\n            )\r\n            nb.cells = [error_msg_cell] + nb.cells\r\n            write_ipynb(nb, output_path)\r\n>           raise error\r\nE           papermill.exceptions.PapermillExecutionError: \r\nE           ---------------------------------------------------------------------------\r\nE           Exception encountered at \"In [6]\":\r\nE           ---------------------------------------------------------------------------\r\nE           KeyError                                  Traceback (most recent call last)\r\nE           <ipython-input-6-883397ed965d> in <module>\r\nE                 1 # Retrieve the web services\r\nE           ----> 2 aci_service = ws.webservices['im-classif-websvc']\r\nE                 3 aks_service = ws.webservices['aks-cpu-image-classif-web-svc']\r\nE           \r\nE           KeyError: 'im-classif-websvc'\r\n```\r\n\r\n\r\n### In which platform does it happen?\r\n<!--- Describe the platform where the issue is happening (use a list if needed) -->\r\n<!--- For example: -->\r\n<!--- * Windows\/Linux.  -->\r\n<!--- * CPU\/GPU.  -->\r\n<!--- * Azure Data Science Virtual Machine. -->\r\n\r\n### How do we replicate the issue?\r\n<!--- Please be specific as possible (use a list if needed). -->\r\n<!--- For example: -->\r\n<!--- * Create a Linux Data Science Virtual Machine one Azure with V100 GPU -->\r\n<!--- * Run unit test `test_classification_data.py` -->\r\n<!--- * ... -->\r\n\r\n### Expected behavior (i.e. solution)\r\n<!--- For example:  -->\r\n<!--- * The test `test_is_data_multilabel` for GPU model training should pass successfully. -->\r\n\r\n### Other Comments\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"fixed with new pipeline and test machines",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"bug pipelin notebook test linux cpu fail descript fff failur test notebook run classif notebook webcam home vst work classif notebook webcam ipynb train introduct home vst train accuraci speed home vst work classif notebook train accuraci speed ipynb subscript resourc group amlnotebookrg workspac amlnotebookw workspac region pytest mark notebook def test notebook run classif notebook subscript resourc group workspac workspac region notebook path classif notebook deploy azur contain instanc execut notebook notebook path output notebook paramet dict version version subscript subscript resourc group resourc group workspac workspac workspac region workspac region kernel kernel test smoke test notebook usr share miniconda env lib python site packag papermil execut execut notebook rais execut error output path cell cell type code metadata inputhidden true hide input true execut count sour end time durat except true nbformat nbformat minor output path output ipynb def rais execut error output path assign paramet appropri place input notebook paramet notebooknod execut notebook object output path str path write execut notebook error cell cell cell output continu output cell output output output type error error papermillexecutionerror exec count cell execut count sourc cell sourc enam output enam evalu output evalu traceback output traceback break error write notebook error messag notebook error msg error messag templat str error exec count error msg cell nbformat new code cell sourc html error msg output nbformat new output output type displai data data text html error msg metadata inputhidden true hide input true cell error msg cell cell write ipynb output path rais error papermil except papermillexecutionerror except encount sslerror traceback recent usr share miniconda env lib python urllib request open self http class req http conn arg request req method req selector req data header encod chunk req header transfer encod oserror err timeout error usr share miniconda env lib python http client request self method url bodi header encod chunk send complet request server self send request method url bodi header encod chunk usr share miniconda env lib python http client send request self method url bodi header encod chunk bodi encod bodi bodi self endhead bodi encod chunk encod chunk usr share miniconda env lib python http client endhead self messag bodi encod chunk rais cannotsendhead self send output messag bodi encod chunk encod chunk usr share miniconda env lib python http client send output self messag bodi encod chunk del self buffer self send msg usr share miniconda env lib python http client send self data self auto open self connect usr share miniconda env lib python http client connect self self sock self context wrap socket self sock server hostnam server hostnam self context check hostnam self check hostnam usr share miniconda env lib python ssl wrap socket self sock server handshak connect suppress rag eof server hostnam session server hostnam server hostnam context self session session usr share miniconda env lib python ssl init self sock keyfil certfil server cert req ssl version cert handshak connect famili type proto fileno suppress rag eof npn protocol cipher server hostnam context session rais valueerror handshak connect specifi non block socket self handshak usr share miniconda env lib python ssl handshak self block self settimeout self sslobj handshak final usr share miniconda env lib python ssl handshak self start ssl tl handshak self sslobj handshak self context check hostnam sslerror ssl certif verifi fail certif verifi fail ssl handl except except occur urlerror traceback recent learn model learner model resnet pretrain true imagenet size usr share miniconda env lib python site packag torchvis model resnet resnet pretrain progress kwarg return resnet resnet basicblock pretrain progress kwarg usr share miniconda env lib python site packag torchvis model resnet resnet arch block layer pretrain progress kwarg pretrain state dict load state dict url model url arch progress progress model load state dict state dict return model usr share miniconda env lib python site packag torch hub load state dict url url model dir map locat progress sy stderr write download format url cach file hash prefix hash regex search filenam group download url file url cach file hash prefix progress progress return torch load cach file map locat map locat usr share miniconda env lib python site packag torch hub download url file url dst hash prefix progress def download url file url dst hash prefix progress file size urlopen url meta info hasattr meta gethead usr share miniconda env lib python urllib request urlopen url data timeout cafil capath cadefault context open open return open open url data timeout def instal open open usr share miniconda env lib python urllib request open self fullurl data timeout req meth req respons self open req data post process respons usr share miniconda env lib python urllib request open self req data protocol req type result self chain self handl open protocol protocol open req result return result usr share miniconda env lib python urllib request chain self chain kind meth arg handler handler func getattr handler meth result func arg result return result usr share miniconda env lib python urllib request http open self req def http open self req return self open http client httpsconnect req context self context check hostnam self check hostnam http request abstracthttphandl request usr share miniconda env lib python urllib request open self http class req http conn arg encod chunk req header transfer encod oserror err timeout error rais urlerror err getrespons urlerror usr share miniconda env lib python site packag papermil execut papermillexecutionerror captur stderr execut kernel kernel test smoke test notebook usr share miniconda env lib python site packag papermil execut execut notebook rais execut error output path cell cell type code metadata inputhidden true hide input true execut count sour end time durat except true nbformat nbformat minor output path output ipynb def rais execut error output path assign paramet appropri place input notebook paramet notebooknod execut notebook object output path str path write execut notebook error cell cell cell output continu output cell output output output type error error papermillexecutionerror exec count cell execut count sourc cell sourc enam output enam evalu output evalu traceback output traceback break error write notebook error messag notebook error msg error messag templat str error exec count error msg cell nbformat new code cell sourc html error msg output nbformat new output output type displai data data text html error msg metadata inputhidden true hide input true cell error msg cell cell write ipynb output path rais error papermil except papermillexecutionerror except encount keyerror traceback recent docker imag imag imag classif resnet keyerror imag classif resnet usr share miniconda env lib python site packag papermil execut papermillexecutionerror captur stderr execut kernel kernel test smoke test notebook usr share miniconda env lib python site packag papermil execut execut notebook rais execut error output path cell cell type code metadata inputhidden true hide input true execut count sour end time durat except true nbformat nbformat minor output path output ipynb def rais execut error output path assign paramet appropri place input notebook paramet notebooknod execut notebook object output path str path write execut notebook error cell cell cell output continu output cell output output output type error error papermillexecutionerror exec count cell execut count sourc cell sourc enam output enam evalu output evalu traceback output traceback break error write notebook error messag notebook error msg error messag templat str error exec count error msg cell nbformat new code cell sourc html error msg output nbformat new output output type displai data data text html error msg metadata inputhidden true hide input true cell error msg cell cell write ipynb output path rais error papermil except papermillexecutionerror except encount keyerror traceback recent retriev web servic aci servic webservic classif websvc ak servic webservic ak cpu imag classif web svc keyerror classif websvc platform happen replic issu expect behavior solut comment",
        "Issue_preprocessed_content":"pipelin fail descript platform platform exampl azur data scienc virtual machin replic specif exampl creat linux data scienc virtual machin azur gpu run unit test expect behavior exampl test gpu model train",
        "Issue_gpt_summary_original":"The user encountered a regression issue in the azure credentials module where the import statement caused the loading of azureml.core.authentication when it was not needed. The suggested solution is to add an import statement before InteractiveLoginAuthentication is called and remove the import statement from the top.",
        "Issue_gpt_summary":"user encount regress issu azur credenti modul import statement caus load core authent need suggest solut add import statement interactiveloginauthent call remov import statement",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/InnerEye-DeepLearning\/issues\/389",
        "Issue_title":"Memory utilization metrics are not correctly visible in AzureML",
        "Issue_created_time":1612434474000,
        "Issue_closed_time":1613669349000,
        "Issue_body":"Run 2236 in experiment \"master\" in RadiomicsNN: \r\n- Only metrics for 3 out of the 4 GPUs are visible\r\n- The MemAllocated and MemReserved metrics are all zero and hence meaningless.",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"Root cause: We are hitting the 50 metrics limit, https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/resource-limits-quotas-capacity.\r\nRemoving the meaningless metrics should reduce impact.",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"memori util metric correctli visibl run experi master radiomicsnn metric gpu visibl memalloc memreserv metric zero meaningless",
        "Issue_preprocessed_content":"memori util metric visibl run experi master metric gpu visibl memreserv metric zero",
        "Issue_gpt_summary_original":"The user is encountering a warning message about hyperdrive loading with azureml_run_type_providers while running any command that uses azureml. The warning message appears even after running the latest master branch in a fresh virtualenv. The expected behavior is that no warning message should be printed. The user is using macOS 10.15, A2ML Version: master branch rev 6fe45a4619e0fc80efde5c84015afbfb91b54d34, and Python Version: 3.7.7.",
        "Issue_gpt_summary":"user encount warn messag hyperdr load run type provid run command us warn messag appear run latest master branch fresh virtualenv expect behavior warn messag print user maco aml version master branch rev feaefcefdecafbfbbd python version",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/augerai\/a2ml\/issues\/175",
        "Issue_title":"azure credentials module should lazy-import any azureml.core modules",
        "Issue_created_time":1589931356000,
        "Issue_closed_time":1589931676000,
        "Issue_body":"A regression was introduced in https:\/\/github.com\/augerai\/a2ml\/commit\/c4f89d282fd951defe3e1d51d35386be2c55c7d9#diff-1cd4abe6fbca8804140fbb9b340e3cc8, where this import statement causes azureml.core.authentication to be loaded when it's not needed if you only have the default set of a2ml dependencies installed.\r\n\r\n```\r\n~\/.virtualenvs\/a2ml\/lib\/python3.7\/site-packages\/a2ml\/api\/azure\/credentials.py\", line 4, in <module>\r\n    from azureml.core.authentication import ServicePrincipalAuthentication, InteractiveLoginAuthentication\r\nModuleNotFoundError: No module named 'azureml'\r\n```\r\n\r\nThe following import statement could be added around L34, right before `InteractiveLoginAuthentication` is called:\r\n\r\n```python\r\nfrom azureml.core.authentication import InteractiveLoginAuthentication\r\n```\r\n\r\nThen this could be removed from the top:\r\n\r\n```python\r\nfrom azureml.core.authentication import ServicePrincipalAuthentication, InteractiveLoginAuthentication\r\n```",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"azur credenti modul lazi import core modul regress introduc http github com augerai aml commit cfdfddefeeddbeccd diff cdabefbcafbbbecc import statement caus core authent load need default set aml depend instal virtualenv aml lib python site packag aml api azur credenti line core authent import serviceprincipalauthent interactiveloginauthent modulenotfounderror modul name follow import statement ad right interactiveloginauthent call python core authent import interactiveloginauthent remov python core authent import serviceprincipalauthent interactiveloginauthent",
        "Issue_preprocessed_content":"azur credenti modul core modul introduc import statement caus load default set depend import statement right remov",
        "Issue_gpt_summary_original":"The user is facing a challenge where the logs generated by lightgbm during execution are not showing up in AzureML.",
        "Issue_gpt_summary":"user face challeng log gener lightgbm execut show",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/augerai\/a2ml\/issues\/173",
        "Issue_title":"Warning message about hyperdrive loading with azureml_run_type_providers",
        "Issue_created_time":1589926894000,
        "Issue_closed_time":1597072927000,
        "Issue_body":"If you run any command that uses azureml (i.e. `a2ml experiment leaderboard`, `a2ml model predict ...`), it prints out this strange warning message:\r\n\r\n```\r\nFailure while loading azureml_run_type_providers. Failed to load entrypoint hyperdrive = azureml.train.hyperdrive:HyperDriveRun._from_run_dto with exception (flake8 3.8.1 (~\/.virtualenvs\/a2ml\/lib\/python3.7\/site-packages), Requirement.parse('flake8<=3.7.9,>=3.1.0; python_version >= \"3.6\"')).\r\n```\r\n\r\n**Expected Behavior**\r\nNo warning message should be printed.\r\n\r\n**Steps to Reproduce the Issue**\r\n1. From latest master branch in a fresh virtualenv run: `make build install`\r\n2. `cd \/path\/to\/azure\/a2ml-project`\r\n3. `a2ml experiment leaderboard`\r\n4. Observe the warning message above.\r\n\r\n\r\n**Environment Details:**\r\n - OS: macOS 10.15\r\n - A2ML Version: master branch rev 6fe45a4619e0fc80efde5c84015afbfb91b54d34\r\n - Python Version: 3.7.7\r\n",
        "Issue_answer_count":2,
        "Issue_self_closed":1.0,
        "Answer_body":"try again pls, I cannot reproduce it with latest azure ml Not able to reproduce now.",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"warn messag hyperdr load run type provid run command us aml experi leaderboard aml model predict print strang warn messag failur load run type provid fail load entrypoint hyperdr train hyperdr hyperdriverun run dto except flake virtualenv aml lib python site packag requir pars flake python version expect behavior warn messag print step reproduc issu latest master branch fresh virtualenv run build instal path azur aml project aml experi leaderboard observ warn messag environ detail maco aml version master branch rev feaefcefdecafbfbbd python version",
        "Issue_preprocessed_content":"warn hyperdr load run us print strang warn expect behavior warn print step reproduc latest master branch fresh virtualenv run observ warn environ detail maco version master branch rev efd afbfb python version",
        "Issue_gpt_summary_original":"The user has encountered an issue where installing azureml-sdk downgrades pyarrow to 3.0.0, which breaks cudf. The error message shows that the module 'pyarrow.lib' has no attribute 'MonthDayNanoIntervalArray'.",
        "Issue_gpt_summary":"user encount issu instal sdk downgrad pyarrow break cudf error messag show modul pyarrow lib attribut monthdaynanointervalarrai",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/lightgbm-benchmark\/issues\/27",
        "Issue_title":"Show lightgbm logs in the logs in AzureML",
        "Issue_created_time":1630081759000,
        "Issue_closed_time":1630110931000,
        "Issue_body":"Current execution lets lightgbm handle its own logs, they are likely printed in stdout, but don't show up in AzureML",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"lightgbm log log current execut let lightgbm handl log like print stdout",
        "Issue_preprocessed_content":"lightgbm log log execut let lightgbm handl log like print stdout",
        "Issue_gpt_summary_original":"The user is encountering a CUDA error 46 while trying to run onnxruntime-gpu on an Azure Machine Learning instance with the openmpi4.1.0-cuda11.6-cudnn8-ubuntu20.04 base image. The error message suggests that all CUDA-capable devices are busy or unavailable. The user had previously run similar environments with earlier versions of CUDA and onnxruntime, which makes them think that the issue is related to the compatibility between CUDA versions and onnxruntime. The user is unsure if the issue is related to the difference between cudnn 8.4 used in the docker image and the compatibility list for onnxruntime, which suggests cudnn 8.2.",
        "Issue_gpt_summary":"user encount cuda error try run onnxruntim gpu instanc openmpi cuda cudnn ubuntu base imag error messag suggest cuda capabl devic busi unavail user previous run similar environ earlier version cuda onnxruntim make think issu relat compat cuda version onnxruntim user unsur issu relat differ cudnn docker imag compat list onnxruntim suggest cudnn",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/rapidsai\/cloud-ml-examples\/issues\/165",
        "Issue_title":"azureml-sdk downgrades pyarrow to 3.0.0 which breaks cudf",
        "Issue_created_time":1655998483000,
        "Issue_closed_time":null,
        "Issue_body":"### Steps to reproduce\r\n\r\n1. Create a fresh RAPIDS conda environment <br\/> `conda create -n rapids-22.06 -c rapidsai -c nvidia -c conda-forge rapids=22.06 python=3.8 cudatoolkit=11.5`\r\n2. `conda activate rapids-22.06`\r\n3. `conda list | grep pyarrow` shows 7.0.0 installed\r\n4. Launch python\/ipython and `import cudf` should work\r\n5. `pip install azureml-sdk`\r\n6. Launch python\/ipython and `import cudf` fails\r\n7. `conda list | grep pyarrow` shows 3.0.0 installed\r\n\r\n#### Error:\r\n```\r\n$ python -m cudf\r\nTraceback (most recent call last):\r\n  File \"\/home\/mmccarty\/miniconda3\/envs\/cloud-ml-examples-test\/lib\/python3.8\/runpy.py\", line 185, in _run_module_as_main\r\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\r\n  File \"\/home\/mmccarty\/miniconda3\/envs\/cloud-ml-examples-test\/lib\/python3.8\/runpy.py\", line 144, in _get_module_details\r\n    return _get_module_details(pkg_main_name, error)\r\n  File \"\/home\/mmccarty\/miniconda3\/envs\/cloud-ml-examples-test\/lib\/python3.8\/runpy.py\", line 111, in _get_module_details\r\n    __import__(pkg_name)\r\n  File \"\/home\/mmccarty\/miniconda3\/envs\/cloud-ml-examples-test\/lib\/python3.8\/site-packages\/cudf\/__init__.py\", line 13, in <module>\r\n    from cudf import api, core, datasets, testing\r\n  File \"\/home\/mmccarty\/miniconda3\/envs\/cloud-ml-examples-test\/lib\/python3.8\/site-packages\/cudf\/datasets.py\", line 7, in <module>\r\n    from cudf._lib.transform import bools_to_mask\r\n  File \"\/home\/mmccarty\/miniconda3\/envs\/cloud-ml-examples-test\/lib\/python3.8\/site-packages\/cudf\/_lib\/__init__.py\", line 4, in <module>\r\n    from . import (\r\n  File \"cudf\/_lib\/avro.pyx\", line 1, in init cudf._lib.avro\r\n  File \"cudf\/_lib\/column.pyx\", line 1, in init cudf._lib.column\r\n  File \"cudf\/_lib\/scalar.pyx\", line 37, in init cudf._lib.scalar\r\n  File \"cudf\/_lib\/interop.pyx\", line 1, in init cudf._lib.interop\r\nAttributeError: module 'pyarrow.lib' has no attribute 'MonthDayNanoIntervalArray'\r\n```",
        "Issue_answer_count":2,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"sdk downgrad pyarrow break cudf step reproduc creat fresh rapid conda environ conda creat rapid rapidsai nvidia conda forg rapid python cudatoolkit conda activ rapid conda list grep pyarrow show instal launch python ipython import cudf work pip instal sdk launch python ipython import cudf fail conda list grep pyarrow show instal error python cudf traceback recent file home mmccarti miniconda env cloud exampl test lib python runpi line run modul main mod mod spec code modul detail mod error file home mmccarti miniconda env cloud exampl test lib python runpi line modul detail return modul detail pkg main error file home mmccarti miniconda env cloud exampl test lib python runpi line modul detail import pkg file home mmccarti miniconda env cloud exampl test lib python site packag cudf init line cudf import api core dataset test file home mmccarti miniconda env cloud exampl test lib python site packag cudf dataset line cudf lib transform import bool mask file home mmccarti miniconda env cloud exampl test lib python site packag cudf lib init line import file cudf lib avro pyx line init cudf lib avro file cudf lib column pyx line init cudf lib column file cudf lib scalar pyx line init cudf lib scalar file cudf lib interop pyx line init cudf lib interop attributeerror modul pyarrow lib attribut monthdaynanointervalarrai",
        "Issue_preprocessed_content":"sdk downgrad break cudf step reproduc creat fresh rapid conda environ show launch work launch fail show",
        "Issue_gpt_summary_original":"the user encountered an issue with the mnist_pytorch example training with , which was unreasonably slow, taking 3-5 minutes per trial and nearly 50 minutes for the entire experiment, despite using a standard_nc6 with a single nvidia tesla k80 gpu.",
        "Issue_gpt_summary":"user encount issu mnist pytorch exampl train unreason slow take minut trial nearli minut entir experi despit standard singl nvidia tesla gpu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/onnxruntime\/issues\/14030",
        "Issue_title":"CUDA error 46 with CUDA 11.6 on Azure ML Linux image",
        "Issue_created_time":1671527243000,
        "Issue_closed_time":null,
        "Issue_body":"### Describe the issue\r\n\r\n I am trying to run onnxruntime-gpu on an Azure Machine Learning instance with this base image: [openmpi4.1.0-cuda11.6-cudnn8-ubuntu20.04](https:\/\/github.com\/Azure\/AzureML-Containers\/blob\/master\/base\/gpu\/openmpi4.1.0-cuda11.6-cudnn8-ubuntu20.04\/Dockerfile) using CUDA. When trying to create an inference session I get this error:\r\n\r\n```\r\n  File \"\/azureml-envs\/azureml_4ab38fdb3b18635e56f7e63921a429e8\/lib\/python3.9\/site-packages\/onnxruntime\/capi\/onnxruntime_inference_collection.py\", line 347, in __init__\r\n    self._create_inference_session(providers, provider_options, disabled_optimizers)\r\n  File \"\/azureml-envs\/azureml_4ab38fdb3b18635e56f7e63921a429e8\/lib\/python3.9\/site-packages\/onnxruntime\/capi\/onnxruntime_inference_collection.py\", line 395, in _create_inference_session\r\n    sess.initialize_session(providers, provider_options, disabled_optimizers)\r\nRuntimeError: \/onnxruntime_src\/onnxruntime\/core\/providers\/cuda\/cuda_call.cc:122 bool onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*) [with ERRTYPE = cudaError; bool THRW = true] \/onnxruntime_src\/onnxruntime\/core\/providers\/cuda\/cuda_call.cc:116 bool onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*) [with ERRTYPE = cudaError; bool THRW = true] CUDA failure 46: all CUDA-capable devices are busy or unavailable ; GPU=0 ; hostname=c7b375a29d54407dad59b0dd621129a7000000 ; expr=cudaDeviceSynchronize(); \r\n```\r\n\r\nI previously had this working with near identical environments using earlier versions of CUDA (e.g. [11.3](https:\/\/github.com\/Azure\/AzureML-Containers\/blob\/master\/base\/gpu\/openmpi4.1.0-cuda11.3-cudnn8-ubuntu20.04\/Dockerfile) with onnxruntime-gpu 1.12) which makes me think it is some error between CUDA versions and onnxruntime rather than a general configuration error.\r\n\r\nThe only potential difference I can see is that the docker image uses cudnn 8.4 while the compatibility list for onnxruntime says cudnn 8.2, though I think 8.4 should be back compatible? The error given doesn't really seem to match this case either\r\n\r\nAny advice would be much appreciated!\r\n\r\n### To reproduce\r\n\r\nInstall onnxruntime-gpu in a conda env with the above dockerfile and try to create an inference session\r\n\r\n### Urgency\r\n\r\n_No response_\r\n\r\n### Platform\r\n\r\nLinux\r\n\r\n### OS Version\r\n\r\n20.04\r\n\r\n### ONNX Runtime Installation\r\n\r\nReleased Package\r\n\r\n### ONNX Runtime Version or Commit ID\r\n\r\n1.13 and 1.12\r\n\r\n### ONNX Runtime API\r\n\r\nPython\r\n\r\n### Architecture\r\n\r\nX64\r\n\r\n### Execution Provider\r\n\r\nCUDA\r\n\r\n### Execution Provider Library Version\r\n\r\nCUDA 11.6",
        "Issue_answer_count":3,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"cuda error cuda linux imag issu try run onnxruntim gpu instanc base imag openmpi cuda cudnn ubuntu http github com azur contain blob master base gpu openmpi cuda cudnn ubuntu dockerfil cuda try creat infer session error file env abfdbbefea lib python site packag onnxruntim capi onnxruntim infer collect line init self creat infer session provid provid option disabl optim file env abfdbbefea lib python site packag onnxruntim capi onnxruntim infer collect line creat infer session sess initi session provid provid option disabl optim runtimeerror onnxruntim src onnxruntim core provid cuda cuda bool onnxruntim cudacal errtyp const char const char errtyp const char errtyp cudaerror bool thrw true onnxruntim src onnxruntim core provid cuda cuda bool onnxruntim cudacal errtyp const char const char errtyp const char errtyp cudaerror bool thrw true cuda failur cuda capabl devic busi unavail gpu hostnam cbaddadbdda expr cudadevicesynchron previous work near ident environ earlier version cuda http github com azur contain blob master base gpu openmpi cuda cudnn ubuntu dockerfil onnxruntim gpu make think error cuda version onnxruntim gener configur error potenti differ docker imag us cudnn compat list onnxruntim sai cudnn think compat error given match case advic appreci reproduc instal onnxruntim gpu conda env dockerfil try creat infer session urgenc respons platform linux version onnx runtim instal releas packag onnx runtim version commit onnx runtim api python architectur execut provid cuda execut provid librari version cuda",
        "Issue_preprocessed_content":"cuda cuda linux imag try run gpu instanc base imag cuda try creat infer previous work near ident environ earlier version cuda gpu make think cuda version gener configur potenti docker imag us compat list sai think compat given match case advic reproduc gpu conda env dockerfil try creat infer urgenc platform linux version runtim releas packag runtim version runtim api python architectur execut provid cuda execut provid librari version cuda",
        "Issue_gpt_summary_original":"Child models trained with the Alignment Enhanced architecture and dictionary on require dict.*.txt files from the parent model for preprocessing. However, these files are not being copied into the \/tmp directory on the AQUA server when launching an experiment through ClearML, causing preprocessing to fail on the child model.",
        "Issue_gpt_summary":"child model train align enhanc architectur dictionari requir dict txt file parent model preprocess file copi tmp directori aqua server launch experi caus preprocess fail child model",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/nni\/issues\/3518",
        "Issue_title":"Training extremely slow with Azure Machine Learning",
        "Issue_created_time":1617867548000,
        "Issue_closed_time":1662517763000,
        "Issue_body":"**Environment**:\r\n- NNI version: 2.0\r\n- NNI mode (local|remote|pai): remote\r\n- Client OS: Windows 10\r\n- Server OS (for remote mode only): Linux\r\n- Python version: 3.6.12\r\n- PyTorch\/TensorFlow version:  PyTorch1.7.1\r\n- Is conda\/virtualenv\/venv used?: conda\r\n- Is running in Docker?: No\r\n\r\n**Log message**:\r\n - nnimanager.log: \r\n [2021-04-07 15:24:48] INFO [ 'Datastore initialization done' ]\r\n[2021-04-07 15:24:48] INFO [ 'RestServer start' ]\r\n[2021-04-07 15:24:48] INFO [ 'RestServer base port is 8086' ]\r\n[2021-04-07 15:24:48] INFO [ 'Rest server listening on: http:\/\/0.0.0.0:8086' ]\r\n[2021-04-07 15:24:51] INFO [ 'NNIManager setClusterMetadata, key: aml_config, value: {\"subscriptionId\":\"xxxxxxxxxxxx\",\"resourceGroup\":\"xxxxxxxxxxxxxxx\",\"workspaceName\":\"xxxxxxxxxxxxxx\",\"computeTarget\":\"xxxxxxxxxxxxxxxx\"}' ]\r\n[2021-04-07 15:24:53] INFO [ 'NNIManager setClusterMetadata, key: nni_manager_ip, value: {\"nniManagerIp\":\"10.194.188.18\"}' ]\r\n[2021-04-07 15:24:55] INFO [ 'NNIManager setClusterMetadata, key: trial_config, value: {\"command\":\"python3 mnist.py\",\"codeDir\":\"C:\\\\\\\\Users\\\\\\\\yanmi\\\\\\\\nni\\\\\\\\examples\\\\\\\\trials\\\\\\\\mnist-pytorch\\\\\\\\.\",\"image\":\"msranni\/nni\"}' ]\r\n[2021-04-07 15:24:57] INFO [ 'Starting experiment: fy8bAx3K' ]\r\n[2021-04-07 15:24:57] INFO [ 'Change NNIManager status from: INITIALIZED to: RUNNING' ]\r\n[2021-04-07 15:24:57] INFO [ 'Add event listeners' ]\r\n[2021-04-07 15:24:57] INFO [ 'TrialDispatcher: started channel: AMLCommandChannel' ]\r\n[2021-04-07 15:24:57] INFO [ 'TrialDispatcher: copying code and settings.' ]\r\n[2021-04-07 15:25:06] INFO [ 'NNIManager received command from dispatcher: ID, ' ]\r\n[2021-04-07 15:25:06] INFO [ 'NNIManager received command from dispatcher: TR, {\"parameter_id\": 0, \"parameter_source\": \"algorithm\", \"parameters\": {\"batch_size\": 128, \"hidden_size\": 128, \"lr\": 0.1, \"momentum\": 0.754420685055723}, \"parameter_index\": 0}' ]\r\n[2021-04-07 15:25:07] INFO [ 'Initialize environments total number: 0' ]\r\n[2021-04-07 15:25:07] INFO [ 'TrialDispatcher: run loop started.' ]\r\n[2021-04-07 15:25:11] INFO [ 'submitTrialJob: form: {\"sequenceId\":0,\"hyperParameters\":{\"value\":\"{\\\\\"parameter_id\\\\\": 0, \\\\\"parameter_source\\\\\": \\\\\"algorithm\\\\\", \\\\\"parameters\\\\\": {\\\\\"batch_size\\\\\": 128, \\\\\"hidden_size\\\\\": 128, \\\\\"lr\\\\\": 0.1, \\\\\"momentum\\\\\": 0.754420685055723}, \\\\\"parameter_index\\\\\": 0}\",\"index\":0}}' ]\r\n[2021-04-07 15:25:12] INFO [ 'Assign environment service aml to environment XlEgg' ]\r\n[2021-04-07 15:25:24] INFO [ 'requested environment nni_exp_fy8bAx3K_1617834318_1a1683cd and job id is nni_exp_fy8bAx3K_env_XlEgg.' ]\r\n[2021-04-07 15:25:24] INFO [ 'requested new environment, live trials: 1, live environments: 0, neededEnvironmentCount: 1, requestedCount: 1' ]\r\n[2021-04-07 15:25:42] INFO [ 'EnvironmentInformation: nni_exp_fy8bAx3K_env_XlEgg change status from UNKNOWN to WAITING.' ]\r\n[2021-04-07 15:28:27] INFO [ 'EnvironmentInformation: nni_exp_fy8bAx3K_env_XlEgg change status from WAITING to RUNNING.' ]\r\n[2021-04-07 15:29:35] INFO [ 'TrialDispatcher: env nni_exp_fy8bAx3K_1617834318_1a1683cd received initialized message and runner is ready, env status: RUNNING.' ]\r\n[2021-04-07 15:29:35] INFO [ 'assigning environment nni_exp_fy8bAx3K_1617834318_1a1683cd to trial KH7Ph.' ]\r\n[2021-04-07 15:29:36] INFO [ 'Trial job KH7Ph status changed from WAITING to RUNNING' ]\r\n[2021-04-07 15:34:06] INFO [ 'Trial job KH7Ph status changed from RUNNING to SUCCEEDED' ]\r\n[2021-04-07 15:34:06] INFO [ 'NNIManager received command from dispatcher: TR, {\"parameter_id\": 1, \"parameter_source\": \"algorithm\", \"parameters\": {\"batch_size\": 128, \"hidden_size\": 128, \"lr\": 0.001, \"momentum\": 0.48989819362825704}, \"parameter_index\": 0}' ]\r\n[2021-04-07 15:34:11] INFO [ 'submitTrialJob: form: {\"sequenceId\":1,\"hyperParameters\":{\"value\":\"{\\\\\"parameter_id\\\\\": 1, \\\\\"parameter_source\\\\\": \\\\\"algorithm\\\\\", \\\\\"parameters\\\\\": {\\\\\"batch_size\\\\\": 128, \\\\\"hidden_size\\\\\": 128, \\\\\"lr\\\\\": 0.001, \\\\\"momentum\\\\\": 0.48989819362825704}, \\\\\"parameter_index\\\\\": 0}\",\"index\":0}}' ]\r\n[2021-04-07 15:34:12] INFO [ 'assigning environment nni_exp_fy8bAx3K_1617834318_1a1683cd to trial Uh6jK.' ]\r\n[2021-04-07 15:34:16] INFO [ 'Trial job Uh6jK status changed from WAITING to RUNNING' ]\r\n[2021-04-07 15:37:26] INFO [ 'Trial job Uh6jK status changed from RUNNING to SUCCEEDED' ]\r\n[2021-04-07 15:37:26] INFO [ 'NNIManager received command from dispatcher: TR, {\"parameter_id\": 2, \"parameter_source\": \"algorithm\", \"parameters\": {\"batch_size\": 16, \"hidden_size\": 256, \"lr\": 0.01, \"momentum\": 0.7009004965885264}, \"parameter_index\": 0}' ]\r\n[2021-04-07 15:37:31] INFO [ 'submitTrialJob: form: {\"sequenceId\":2,\"hyperParameters\":{\"value\":\"{\\\\\"parameter_id\\\\\": 2, \\\\\"parameter_source\\\\\": \\\\\"algorithm\\\\\", \\\\\"parameters\\\\\": {\\\\\"batch_size\\\\\": 16, \\\\\"hidden_size\\\\\": 256, \\\\\"lr\\\\\": 0.01, \\\\\"momentum\\\\\": 0.7009004965885264}, \\\\\"parameter_index\\\\\": 0}\",\"index\":0}}' ]\r\n[2021-04-07 15:37:32] INFO [ 'assigning environment nni_exp_fy8bAx3K_1617834318_1a1683cd to trial JqjWi.' ]\r\n[2021-04-07 15:37:36] INFO [ 'Trial job JqjWi status changed from WAITING to RUNNING' ]\r\n[2021-04-07 15:41:26] INFO [ 'Trial job JqjWi status changed from RUNNING to SUCCEEDED' ]\r\n[2021-04-07 15:41:26] INFO [ 'NNIManager received command from dispatcher: TR, {\"parameter_id\": 3, \"parameter_source\": \"algorithm\", \"parameters\": {\"batch_size\": 32, \"hidden_size\": 512, \"lr\": 0.1, \"momentum\": 0.6258856288476062}, \"parameter_index\": 0}' ]\r\n[2021-04-07 15:41:31] INFO [ 'submitTrialJob: form: {\"sequenceId\":3,\"hyperParameters\":{\"value\":\"{\\\\\"parameter_id\\\\\": 3, \\\\\"parameter_source\\\\\": \\\\\"algorithm\\\\\", \\\\\"parameters\\\\\": {\\\\\"batch_size\\\\\": 32, \\\\\"hidden_size\\\\\": 512, \\\\\"lr\\\\\": 0.1, \\\\\"momentum\\\\\": 0.6258856288476062}, \\\\\"parameter_index\\\\\": 0}\",\"index\":0}}' ]\r\n[2021-04-07 15:41:32] INFO [ 'assigning environment nni_exp_fy8bAx3K_1617834318_1a1683cd to trial ijhph.' ]\r\n[2021-04-07 15:41:36] INFO [ 'Trial job ijhph status changed from WAITING to RUNNING' ]\r\n[2021-04-07 15:46:31] INFO [ 'Trial job ijhph status changed from RUNNING to SUCCEEDED' ]\r\n[2021-04-07 15:46:31] INFO [ 'NNIManager received command from dispatcher: TR, {\"parameter_id\": 4, \"parameter_source\": \"algorithm\", \"parameters\": {\"batch_size\": 128, \"hidden_size\": 1024, \"lr\": 0.1, \"momentum\": 0.30905289366545063}, \"parameter_index\": 0}' ]\r\n[2021-04-07 15:46:36] INFO [ 'submitTrialJob: form: {\"sequenceId\":4,\"hyperParameters\":{\"value\":\"{\\\\\"parameter_id\\\\\": 4, \\\\\"parameter_source\\\\\": \\\\\"algorithm\\\\\", \\\\\"parameters\\\\\": {\\\\\"batch_size\\\\\": 128, \\\\\"hidden_size\\\\\": 1024, \\\\\"lr\\\\\": 0.1, \\\\\"momentum\\\\\": 0.30905289366545063}, \\\\\"parameter_index\\\\\": 0}\",\"index\":0}}' ]\r\n[2021-04-07 15:46:38] INFO [ 'assigning environment nni_exp_fy8bAx3K_1617834318_1a1683cd to trial bElKu.' ]\r\n[2021-04-07 15:46:41] INFO [ 'Trial job bElKu status changed from WAITING to RUNNING' ]\r\n[2021-04-07 15:52:06] INFO [ 'Trial job bElKu status changed from RUNNING to SUCCEEDED' ]\r\n[2021-04-07 15:52:06] INFO [ 'NNIManager received command from dispatcher: TR, {\"parameter_id\": 5, \"parameter_source\": \"algorithm\", \"parameters\": {\"batch_size\": 128, \"hidden_size\": 1024, \"lr\": 0.0001, \"momentum\": 0.0003307910747289977}, \"parameter_index\": 0}' ]\r\n[2021-04-07 15:52:11] INFO [ 'submitTrialJob: form: {\"sequenceId\":5,\"hyperParameters\":{\"value\":\"{\\\\\"parameter_id\\\\\": 5, \\\\\"parameter_source\\\\\": \\\\\"algorithm\\\\\", \\\\\"parameters\\\\\": {\\\\\"batch_size\\\\\": 128, \\\\\"hidden_size\\\\\": 1024, \\\\\"lr\\\\\": 0.0001, \\\\\"momentum\\\\\": 0.0003307910747289977}, \\\\\"parameter_index\\\\\": 0}\",\"index\":0}}' ]\r\n[2021-04-07 15:52:12] INFO [ 'assigning environment nni_exp_fy8bAx3K_1617834318_1a1683cd to trial upDtw.' ]\r\n[2021-04-07 15:52:16] INFO [ 'Trial job upDtw status changed from WAITING to RUNNING' ]\r\n[2021-04-07 15:56:07] INFO [ 'Trial job upDtw status changed from RUNNING to SUCCEEDED' ]\r\n[2021-04-07 15:56:07] INFO [ 'NNIManager received command from dispatcher: TR, {\"parameter_id\": 6, \"parameter_source\": \"algorithm\", \"parameters\": {\"batch_size\": 64, \"hidden_size\": 128, \"lr\": 0.01, \"momentum\": 0.876381947693324}, \"parameter_index\": 0}' ]\r\n[2021-04-07 15:56:12] INFO [ 'submitTrialJob: form: {\"sequenceId\":6,\"hyperParameters\":{\"value\":\"{\\\\\"parameter_id\\\\\": 6, \\\\\"parameter_source\\\\\": \\\\\"algorithm\\\\\", \\\\\"parameters\\\\\": {\\\\\"batch_size\\\\\": 64, \\\\\"hidden_size\\\\\": 128, \\\\\"lr\\\\\": 0.01, \\\\\"momentum\\\\\": 0.876381947693324}, \\\\\"parameter_index\\\\\": 0}\",\"index\":0}}' ]\r\n[2021-04-07 15:56:12] INFO [ 'assigning environment nni_exp_fy8bAx3K_1617834318_1a1683cd to trial Zgo5Q.' ]\r\n[2021-04-07 15:56:17] INFO [ 'Trial job Zgo5Q status changed from WAITING to RUNNING' ]\r\n[2021-04-07 15:59:32] INFO [ 'Trial job Zgo5Q status changed from RUNNING to SUCCEEDED' ]\r\n[2021-04-07 15:59:32] INFO [ 'NNIManager received command from dispatcher: TR, {\"parameter_id\": 7, \"parameter_source\": \"algorithm\", \"parameters\": {\"batch_size\": 128, \"hidden_size\": 512, \"lr\": 0.1, \"momentum\": 0.2948365715286464}, \"parameter_index\": 0}' ]\r\n[2021-04-07 15:59:37] INFO [ 'submitTrialJob: form: {\"sequenceId\":7,\"hyperParameters\":{\"value\":\"{\\\\\"parameter_id\\\\\": 7, \\\\\"parameter_source\\\\\": \\\\\"algorithm\\\\\", \\\\\"parameters\\\\\": {\\\\\"batch_size\\\\\": 128, \\\\\"hidden_size\\\\\": 512, \\\\\"lr\\\\\": 0.1, \\\\\"momentum\\\\\": 0.2948365715286464}, \\\\\"parameter_index\\\\\": 0}\",\"index\":0}}' ]\r\n[2021-04-07 15:59:38] INFO [ 'assigning environment nni_exp_fy8bAx3K_1617834318_1a1683cd to trial T92cL.' ]\r\n[2021-04-07 15:59:42] INFO [ 'Trial job T92cL status changed from WAITING to RUNNING' ]\r\n[2021-04-07 16:02:49] INFO [ 'Trial job T92cL status changed from RUNNING to SUCCEEDED' ]\r\n[2021-04-07 16:02:49] INFO [ 'NNIManager received command from dispatcher: TR, {\"parameter_id\": 8, \"parameter_source\": \"algorithm\", \"parameters\": {\"batch_size\": 16, \"hidden_size\": 128, \"lr\": 0.001, \"momentum\": 0.5108633717497612}, \"parameter_index\": 0}' ]\r\n[2021-04-07 16:02:54] INFO [ 'submitTrialJob: form: {\"sequenceId\":8,\"hyperParameters\":{\"value\":\"{\\\\\"parameter_id\\\\\": 8, \\\\\"parameter_source\\\\\": \\\\\"algorithm\\\\\", \\\\\"parameters\\\\\": {\\\\\"batch_size\\\\\": 16, \\\\\"hidden_size\\\\\": 128, \\\\\"lr\\\\\": 0.001, \\\\\"momentum\\\\\": 0.5108633717497612}, \\\\\"parameter_index\\\\\": 0}\",\"index\":0}}' ]\r\n[2021-04-07 16:02:54] INFO [ 'assigning environment nni_exp_fy8bAx3K_1617834318_1a1683cd to trial RoHBk.' ]\r\n[2021-04-07 16:02:59] INFO [ 'Trial job RoHBk status changed from WAITING to RUNNING' ]\r\n[2021-04-07 16:06:58] INFO [ 'Trial job RoHBk status changed from RUNNING to SUCCEEDED' ]\r\n[2021-04-07 16:06:58] INFO [ 'NNIManager received command from dispatcher: TR, {\"parameter_id\": 9, \"parameter_source\": \"algorithm\", \"parameters\": {\"batch_size\": 32, \"hidden_size\": 1024, \"lr\": 0.1, \"momentum\": 0.1371728116640185}, \"parameter_index\": 0}' ]\r\n[2021-04-07 16:07:03] INFO [ 'submitTrialJob: form: {\"sequenceId\":9,\"hyperParameters\":{\"value\":\"{\\\\\"parameter_id\\\\\": 9, \\\\\"parameter_source\\\\\": \\\\\"algorithm\\\\\", \\\\\"parameters\\\\\": {\\\\\"batch_size\\\\\": 32, \\\\\"hidden_size\\\\\": 1024, \\\\\"lr\\\\\": 0.1, \\\\\"momentum\\\\\": 0.1371728116640185}, \\\\\"parameter_index\\\\\": 0}\",\"index\":0}}' ]\r\n[2021-04-07 16:07:06] INFO [ 'assigning environment nni_exp_fy8bAx3K_1617834318_1a1683cd to trial UURlR.' ]\r\n[2021-04-07 16:07:08] INFO [ 'Trial job UURlR status changed from WAITING to RUNNING' ]\r\n[2021-04-07 16:07:08] INFO [ 'Change NNIManager status from: RUNNING to: NO_MORE_TRIAL' ]\r\n[2021-04-07 16:10:36] INFO [ 'Trial job UURlR status changed from RUNNING to SUCCEEDED' ]\r\n[2021-04-07 16:10:36] INFO [ 'Change NNIManager status from: NO_MORE_TRIAL to: DONE' ]\r\n[2021-04-07 16:10:36] INFO [ 'NNIManager received command from dispatcher: TR, {\"parameter_id\": 10, \"parameter_source\": \"algorithm\", \"parameters\": {\"batch_size\": 16, \"hidden_size\": 128, \"lr\": 0.01, \"momentum\": 0.5296207133227185}, \"parameter_index\": 0}' ]\r\n[2021-04-07 16:10:36] INFO [ 'Experiment done.' ]\r\n[2021-04-07 16:20:40] INFO [ 'EnvironmentInformation: nni_exp_fy8bAx3K_env_XlEgg change status from RUNNING to UNKNOWN.' ]\r\n[2021-04-07 16:21:10] INFO [ 'EnvironmentInformation: nni_exp_fy8bAx3K_env_XlEgg change status from UNKNOWN to SUCCEEDED.' ]\r\n\r\n - dispatcher.log:\r\n [2021-04-07 15:24:58] INFO (nni.runtime.msg_dispatcher_base\/MainThread) Dispatcher started\r\n[2021-04-07 15:25:06] INFO (hyperopt.tpe\/Thread-1) tpe_transform took 0.001968 seconds\r\n[2021-04-07 15:25:06] INFO (hyperopt.tpe\/Thread-1) TPE using 0 trials\r\n[2021-04-07 15:34:06] INFO (hyperopt.tpe\/Thread-1) tpe_transform took 0.000997 seconds\r\n[2021-04-07 15:34:06] INFO (hyperopt.tpe\/Thread-1) TPE using 1\/1 trials with best loss -98.950000\r\n[2021-04-07 15:37:26] INFO (hyperopt.tpe\/Thread-1) tpe_transform took 0.001003 seconds\r\n[2021-04-07 15:37:26] INFO (hyperopt.tpe\/Thread-1) TPE using 2\/2 trials with best loss -98.950000\r\n[2021-04-07 15:41:26] INFO (hyperopt.tpe\/Thread-1) tpe_transform took 0.001019 seconds\r\n[2021-04-07 15:41:26] INFO (hyperopt.tpe\/Thread-1) TPE using 3\/3 trials with best loss -99.220000\r\n[2021-04-07 15:46:31] INFO (hyperopt.tpe\/Thread-1) tpe_transform took 0.001025 seconds\r\n[2021-04-07 15:46:31] INFO (hyperopt.tpe\/Thread-1) TPE using 4\/4 trials with best loss -99.220000\r\n[2021-04-07 15:52:06] INFO (hyperopt.tpe\/Thread-1) tpe_transform took 0.000998 seconds\r\n[2021-04-07 15:52:06] INFO (hyperopt.tpe\/Thread-1) TPE using 5\/5 trials with best loss -99.300000\r\n[2021-04-07 15:56:07] INFO (hyperopt.tpe\/Thread-1) tpe_transform took 0.000969 seconds\r\n[2021-04-07 15:56:07] INFO (hyperopt.tpe\/Thread-1) TPE using 6\/6 trials with best loss -99.300000\r\n[2021-04-07 15:59:32] INFO (hyperopt.tpe\/Thread-1) tpe_transform took 0.001000 seconds\r\n[2021-04-07 15:59:32] INFO (hyperopt.tpe\/Thread-1) TPE using 7\/7 trials with best loss -99.300000\r\n[2021-04-07 16:02:49] INFO (hyperopt.tpe\/Thread-1) tpe_transform took 0.001994 seconds\r\n[2021-04-07 16:02:49] INFO (hyperopt.tpe\/Thread-1) TPE using 8\/8 trials with best loss -99.300000\r\n[2021-04-07 16:06:58] INFO (hyperopt.tpe\/Thread-1) tpe_transform took 0.000997 seconds\r\n[2021-04-07 16:06:58] INFO (hyperopt.tpe\/Thread-1) TPE using 9\/9 trials with best loss -99.300000\r\n[2021-04-07 16:10:36] INFO (hyperopt.tpe\/Thread-1) tpe_transform took 0.000997 seconds\r\n[2021-04-07 16:10:36] INFO (hyperopt.tpe\/Thread-1) TPE using 10\/10 trials with best loss -99.340000\r\n\r\n - nnictl stdout and stderr:\r\n\r\n-----------------------------------------------------------------------\r\n                Experiment start time 2021-04-07 15:24:42\r\n-----------------------------------------------------------------------\r\n\r\n-----------------------------------------------------------------------\r\n                Experiment start time 2021-04-07 15:24:42\r\n-----------------------------------------------------------------------\r\n(node:16168) MaxListenersExceededWarning: Possible EventEmitter memory leak detected. 11 message listeners added. Use emitter.setMaxListeners() to increase limit\r\n(node:16168) MaxListenersExceededWarning: Possible EventEmitter memory leak detected. 11 error listeners added. Use emitter.setMaxListeners() to increase limit\r\n(node:16168) MaxListenersExceededWarning: Possible EventEmitter memory leak detected. 11 close listeners added. Use emitter.setMaxListeners() to increase limit\r\n\r\n<!-- Where can you find the log files: [log](https:\/\/github.com\/microsoft\/nni\/blob\/master\/docs\/en_US\/Tutorial\/HowToDebug.md#experiment-root-director), [stdout\/stderr](https:\/\/github.com\/microsoft\/nni\/blob\/master\/docs\/en_US\/Tutorial\/Nnictl.md#nnictl%20log%20stdout) -->\r\n\r\n**What issue meet, what's expected?**:\r\nThe mnist_pytorch example training with Azure ML is unreasonably slow, each trial take about 3 to 5 mins. The entire experiment took nearly 50 mins. I was expecting it to be much faster given that it's using STANDARD_NC6 with GPU - 1 x NVIDIA Tesla K80.\r\n\r\n**How to reproduce it?**: \r\nFollow this doc https:\/\/nni.readthedocs.io\/en\/latest\/TrainingService\/AMLMode.html\r\n\r\n**Additional information**:\r\nTried adding gpuNum: 1 and useActiveGpu: true in config file, only made it even slower with trials spending more time in waiting status, also instead of doing all 10 trials in 1 run, each trial take 1 run.",
        "Issue_answer_count":7,
        "Issue_self_closed":0.0,
        "Answer_body":"@yangmingwanli Each run only start one trial job, and then start new run? @SparkSnail After adding gpuNum: 1 and useActiveGpu: true, yes each run only start one trial job, and then start new run.\r\nWithout making these changes, it will finish all trials in one run, just very slowly. I reproduced this issue, and this seems to be a bug, will fix it ASAP. @SparkSnail , does it look like going to be a hard to fix bug? Is there any workaround before fix is released? Thanks!  Have you tried setting gpuNum:0, and resubmit the job? Just tried that, after setting gpuNum:0, training is still extremely slow, didn't start new run for new trial, but failed after two trials due to \"Converting circular structure to JSON\" error. @SparkSnail is it a bug that needs to be fixed? \r\n\r\n> \"Converting circular structure to JSON\" error.\r\n   \r\nthis error had been fixed in NNI v2.3.\r\n\r\n",
        "Tool":"Azure Machine Learning",
        "Platform":"Github",
        "Issue_original_content":"train extrem slow environ nni version nni mode local remot pai remot client window server remot mode linux python version pytorch tensorflow version pytorch conda virtualenv venv conda run docker log messag nnimanag log info datastor initi info restserv start info restserv base port info rest server listen http info nnimanag setclustermetadata kei aml config valu subscriptionid xxxxxxxxxxxx resourcegroup xxxxxxxxxxxxxxx workspacenam xxxxxxxxxxxxxx computetarget xxxxxxxxxxxxxxxx info nnimanag setclustermetadata kei nni manag valu nnimanagerip info nnimanag setclustermetadata kei trial config valu command python mnist codedir user yanmi nni exampl trial mnist pytorch imag msranni nni info start experi fybaxk info chang nnimanag statu initi run info add event listen info trialdispatch start channel amlcommandchannel info trialdispatch copi code set info nnimanag receiv command dispatch info nnimanag receiv command dispatch paramet paramet sourc algorithm paramet batch size hidden size momentum paramet index info initi environ total number info trialdispatch run loop start info submittrialjob form sequenceid hyperparamet valu paramet paramet sourc algorithm paramet batch size hidden size momentum paramet index index info assign environ servic aml environ xlegg info request environ nni exp fybaxk acd job nni exp fybaxk env xlegg info request new environ live trial live environ neededenvironmentcount requestedcount info environmentinform nni exp fybaxk env xlegg chang statu unknown wait info environmentinform nni exp fybaxk env xlegg chang statu wait run info trialdispatch env nni exp fybaxk acd receiv initi messag runner readi env statu run info assign environ nni exp fybaxk acd trial khph info trial job khph statu chang wait run info trial job khph statu chang run succeed info nnimanag receiv command dispatch paramet paramet sourc algorithm paramet batch size hidden size momentum paramet index info submittrialjob form sequenceid hyperparamet valu paramet paramet sourc algorithm paramet batch size hidden size momentum paramet index index info assign environ nni exp fybaxk acd trial uhjk info trial job uhjk statu chang wait run info trial job uhjk statu chang run succeed info nnimanag receiv command dispatch paramet paramet sourc algorithm paramet batch size hidden size momentum paramet index info submittrialjob form sequenceid hyperparamet valu paramet paramet sourc algorithm paramet batch size hidden size momentum paramet index index info assign environ nni exp fybaxk acd trial jqjwi info trial job jqjwi statu chang wait run info trial job jqjwi statu chang run succeed info nnimanag receiv command dispatch paramet paramet sourc algorithm paramet batch size hidden size momentum paramet index info submittrialjob form sequenceid hyperparamet valu paramet paramet sourc algorithm paramet batch size hidden size momentum paramet index index info assign environ nni exp fybaxk acd trial ijhph info trial job ijhph statu chang wait run info trial job ijhph statu chang run succeed info nnimanag receiv command dispatch paramet paramet sourc algorithm paramet batch size hidden size momentum paramet index info submittrialjob form sequenceid hyperparamet valu paramet paramet sourc algorithm paramet batch size hidden size momentum paramet index index info assign environ nni exp fybaxk acd trial belku info trial job belku statu chang wait run info trial job belku statu chang run succeed info nnimanag receiv command dispatch paramet paramet sourc algorithm paramet batch size hidden size momentum paramet index info submittrialjob form sequenceid hyperparamet valu paramet paramet sourc algorithm paramet batch size hidden size momentum paramet index index info assign environ nni exp fybaxk acd trial updtw info trial job updtw statu chang wait run info trial job updtw statu chang run succeed info nnimanag receiv command dispatch paramet paramet sourc algorithm paramet batch size hidden size momentum paramet index info submittrialjob form sequenceid hyperparamet valu paramet paramet sourc algorithm paramet batch size hidden size momentum paramet index index info assign environ nni exp fybaxk acd trial zgoq info trial job zgoq statu chang wait run info trial job zgoq statu chang run succeed info nnimanag receiv command dispatch paramet paramet sourc algorithm paramet batch size hidden size momentum paramet index info submittrialjob form sequenceid hyperparamet valu paramet paramet sourc algorithm paramet batch size hidden size momentum paramet index index info assign environ nni exp fybaxk acd trial tcl info trial job tcl statu chang wait run info trial job tcl statu chang run succeed info nnimanag receiv command dispatch paramet paramet sourc algorithm paramet batch size hidden size momentum paramet index info submittrialjob form sequenceid hyperparamet valu paramet paramet sourc algorithm paramet batch size hidden size momentum paramet index index info assign environ nni exp fybaxk acd trial rohbk info trial job rohbk statu chang wait run info trial job rohbk statu chang run succeed info nnimanag receiv command dispatch paramet paramet sourc algorithm paramet batch size hidden size momentum paramet index info submittrialjob form sequenceid hyperparamet valu paramet paramet sourc algorithm paramet batch size hidden size momentum paramet index index info assign environ nni exp fybaxk acd trial uurlr info trial job uurlr statu chang wait run info chang nnimanag statu run trial info trial job uurlr statu chang run succeed info chang nnimanag statu trial info nnimanag receiv command dispatch paramet paramet sourc algorithm paramet batch size hidden size momentum paramet index info experi info environmentinform nni exp fybaxk env xlegg chang statu run unknown info environmentinform nni exp fybaxk env xlegg chang statu unknown succeed dispatch log info nni runtim msg dispatch base mainthread dispatch start info hyperopt tpe thread tpe transform took second info hyperopt tpe thread tpe trial info hyperopt tpe thread tpe transform took second info hyperopt tpe thread tpe trial best loss info hyperopt tpe thread tpe transform took second info hyperopt tpe thread tpe trial best loss info hyperopt tpe thread tpe transform took second info hyperopt tpe thread tpe trial best loss info hyperopt tpe thread tpe transform took second info hyperopt tpe thread tpe trial best loss info hyperopt tpe thread tpe transform took second info hyperopt tpe thread tpe trial best loss info hyperopt tpe thread tpe transform took second info hyperopt tpe thread tpe trial best loss info hyperopt tpe thread tpe transform took second info hyperopt tpe thread tpe trial best loss info hyperopt tpe thread tpe transform took second info hyperopt tpe thread tpe trial best loss info hyperopt tpe thread tpe transform took second info hyperopt tpe thread tpe trial best loss info hyperopt tpe thread tpe transform took second info hyperopt tpe thread tpe trial best loss nnictl stdout stderr experi start time experi start time node maxlistenersexceededwarn possibl eventemitt memori leak detect messag listen ad us emitt setmaxlisten increas limit node maxlistenersexceededwarn possibl eventemitt memori leak detect error listen ad us emitt setmaxlisten increas limit node maxlistenersexceededwarn possibl eventemitt memori leak detect close listen ad us emitt setmaxlisten increas limit issu meet expect mnist pytorch exampl train unreason slow trial min entir experi took nearli min expect faster given standard gpu nvidia tesla reproduc follow doc http nni readthedoc latest trainingservic amlmod html addit inform tri ad gpunum useactivegpu true config file slower trial spend time wait statu instead trial run trial run",
        "Issue_preprocessed_content":"train extrem slow environ version mode remot client window server linux python version version conda docker log log info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info info dispatch start info second info tpe trial info second info tpe trial best info second info tpe trial best info second info tpe trial best info second info tpe trial best info second info tpe trial best info second info tpe trial best info second info tpe trial best info second info tpe trial best info second info tpe trial best info second info tpe trial best stdout experi start time experi start time node memori leak detect listen us setmaxlisten increas limit node memori leak detect listen us setmaxlisten increas limit node memori leak detect close listen us setmaxlisten increas limit log file expect exampl train unreason slow trial min entir experi nearli min expect faster given gpu nvidia tesla reproduc doc inform tri gpunum useactivegpu true config file slower trial spend time wait statu instead trial run trial run",
        "Issue_gpt_summary_original":"The user is facing an issue with the `silnlp.nmt.translate` script, which always creates a ClearML task. The user wants this to be optional and execute locally by default.",
        "Issue_gpt_summary":"user face issu silnlp nmt translat script creat task user want option execut local default",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/sillsdev\/silnlp\/issues\/125",
        "Issue_title":"Child models need to copy the dict.*.txt files from the parent model when launching an experiment on ClearML",
        "Issue_created_time":1644785881000,
        "Issue_closed_time":null,
        "Issue_body":"If a parent model was trained with the Alignment Enhanced architecture and the dictionary on, preprocessing for the child model will look for the dict.*.txt files (dict.src.txt, dict.trg.txt, dict.vref.txt) from the parent model.  Those files are not currently being copied into the \/tmp directory on the AQUA server when the experiment is launched through ClearML, so preprocessing fails on the child model.\r\n\r\nSample [experiment ](https:\/\/app.pro.clear.ml\/projects\/2243ca6c76d642699db1f28951bbb78a\/experiments\/fc444552b21243149fd3c90a9a4c6c8d\/execution?columns=selected&columns=type&columns=name&columns=tags&columns=status&columns=project.name&columns=users&columns=started&columns=last_update&columns=last_iteration&columns=parent.name&order=-last_update&filter=)with this failure.",
        "Issue_answer_count":0,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"ClearML",
        "Platform":"Github",
        "Issue_original_content":"child model need copi dict txt file parent model launch experi parent model train align enhanc architectur dictionari preprocess child model look dict txt file dict src txt dict trg txt dict vref txt parent model file current copi tmp directori aqua server experi launch preprocess fail child model sampl experi http app pro clear project cacddbfbbba experi fcbfdcaaccd execut column select column type column column tag column statu column project column user column start column updat column iter column parent order updat filter failur",
        "Issue_preprocessed_content":"child model copi file parent model launch experi parent model train align enhanc architectur dictionari child model file parent model file copi tmp directori aqua server experi launch fail child model sampl failur",
        "Issue_gpt_summary_original":"The user encountered an error while trying to run a local translation command, which attempted to use ClearML even though the ClearML argument was not set in the command line. The error message indicates that the ClearML credentials were invalid, preventing the translation from running on the local machine.",
        "Issue_gpt_summary":"user encount error try run local translat command attempt us argument set command line error messag indic credenti invalid prevent translat run local machin",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/sillsdev\/silnlp\/issues\/120",
        "Issue_title":"Execute translate script without creating ClearML task",
        "Issue_created_time":1641546207000,
        "Issue_closed_time":1657980432000,
        "Issue_body":"Currently, the `silnlp.nmt.translate` script always creates a ClearML task. This should be optional. By default, it should just execute locally.",
        "Issue_answer_count":3,
        "Issue_self_closed":0.0,
        "Answer_body":"I think that this error might be preventing me from using the Translate script locally.\r\n\r\nWhen I try I get the following error:\r\nInstalling the current project: silnlp (1.0.0)\r\n(silnlp-gt_VMn9E-py3.8) david@pop-os:~\/silnlp$ python -m silnlp.nmt.translate BT-English\/cba-en\/cba-en_cp01 --src-project cba --trg-iso en --books EXO --output-usfm BT-English\/cba-en\/cba-en_cp01\/02EXOcbaNT --checkpoint best\r\n2022-06-28 21:02:08,808 - silnlp.common.environment - INFO - Using workspace: \/home\/david\/disk2\/gutenberg as per environment variable SIL_NLP_DATA_PATH.\r\n2022-06-28 21:02:09,149 - silnlp.common.utils - INFO - Git commit: f46a63c3b3\r\nRetrying (Retry(total=239, connect=239, read=240, redirect=240, status=240)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f97e4556fa0>: Failed to establish a new connection: [Errno -5] No address associated with hostname')': \/auth.login\r\nRetrying (Retry(total=238, connect=238, read=240, redirect=240, status=240)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f97e4569190>: Failed to establish a new connection: [Errno -5] No address associated with hostname')': \/auth.login\r\n^CRetrying (Retry(total=237, connect=237, read=240, redirect=240, status=240)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f97e4569340>: Failed to establish a new connection: [Errno -5] No address associated with hostname')': \/auth.login\r\n\r\nprint(args):\r\nNamespace(books=['EXO'], checkpoint='best', clearml_queue=None, eager_execution=False, end_seq=None, experiment='BT-English\/cba-en\/cba-en_cp01', memory_growth=False, output_usfm='BT-English\/cba-en\/cba-en_cp01\/02EXOcbaNT', src=None, src_prefix=None, src_project='cbaNT', start_seq=None, trg=None, trg_iso='en', trg_prefix=None)\r\n Tested this for translating and it worked fine.   (silnlp-gt_VMn9E-py3.8) david@pop-os:~\/silnlp$ python -m silnlp.nmt.translate --checkpoint last --src-project tl-TCB --src \/home\/david\/disk2\/gutenberg\/Paratext\/projects\/TCB\/091SAtlASD15.SFM --trg-iso blx --output-usfm \/home\/david\/disk2\/gutenberg\/BT-Tagalog\/to_blx\/tl_blx_uni_dup_share_preserve\/results\/091SAAMIU_last.sfm BT-Tagalog\/to_blx\/tl_blx_uni_dup_share_preserve\r\n2022-07-16 15:03:40,452 - silnlp.common.environment - INFO - Using workspace: \/home\/david\/disk2\/gutenberg as per environment variable SIL_NLP_DATA_PATH.\r\n2022-07-16 15:03:40,828 - silnlp.common.utils - INFO - Git commit: 8cd5b9c649\r\nTraceback (most recent call last):\r\n  File \"\/usr\/lib\/python3.8\/runpy.py\", line 194, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"\/usr\/lib\/python3.8\/runpy.py\", line 87, in _run_code\r\n    exec(code, run_globals)\r\n  File \"\/home\/david\/silnlp\/silnlp\/nmt\/translate.py\", line 231, in <module>\r\n    main()\r\n  File \"\/home\/david\/silnlp\/silnlp\/nmt\/translate.py\", line 225, in main\r\n    translator.translate_text_file(args.src, args.trg_iso, args.trg)\r\n  File \"\/home\/david\/silnlp\/silnlp\/nmt\/translate.py\", line 151, in translate_text_file\r\n    self.init_translation_task(experiment_suffix=f\"_{self.checkpoint}_{os.path.basename(src_file_path)}\")\r\n  File \"\/home\/david\/silnlp\/silnlp\/nmt\/translate.py\", line 79, in init_translation_task\r\n    self.clearml = SILClearML(\r\n  File \"<string>\", line 9, in __init__\r\n  File \"\/home\/david\/silnlp\/silnlp\/common\/clearml_connection.py\", line 24, in __post_init__\r\n    self.name = self.name.replace(\"\\\\\", \"\/\")\r\nAttributeError: 'NoneType' object has no attribute 'replace'\r\n",
        "Tool":"ClearML",
        "Platform":"Github",
        "Issue_original_content":"execut translat script creat task current silnlp nmt translat script creat task option default execut local",
        "Issue_preprocessed_content":"execut translat script creat task script creat task option default execut",
        "Issue_gpt_summary_original":"The user is encountering a \"comet-ml not installed\" error despite having installed comet-ml. The error occurs when trying to instantiate Trainer with `report_to='comet_ml'` in the TrainingArguments. The error message suggests that the CometCallback requires comet-ml to be installed.",
        "Issue_gpt_summary":"user encount instal error despit have instal error occur try instanti trainer report trainingargu error messag suggest callback requir instal",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/sillsdev\/silnlp\/issues\/109",
        "Issue_title":"Translate is trying to use ClearML even though it was not requested. Preventing translation on local machine.",
        "Issue_created_time":1637586010000,
        "Issue_closed_time":1637601038000,
        "Issue_body":"I tried to translate with the following command line and trace.\r\nThe command is meant to run locally, but there is an error about ClearML credentials. The ClearML argument was not set in the command line.\r\n\r\n```\r\npython -m silnlp.nmt.translate --checkpoint 6000 --src-project GELA3_2021_11_22 --book OT --trg-iso en  nlg-en-4\r\n2021-11-22 12:53:27.859063: I tensorflow\/stream_executor\/platform\/default\/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\n2021-11-22 12:53:30,996 - silnlp.common.environment - INFO - Using workspace: \/home\/david\/Gutenberg_new as per environment variable SIL_NLP_DATA_PATH.\r\n2021-11-22 12:53:31,372 - silnlp.common.utils - INFO - Git commit: 12aca87cab\r\nTraceback (most recent call last):\r\n  File \"\/usr\/lib\/python3.8\/runpy.py\", line 194, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"\/usr\/lib\/python3.8\/runpy.py\", line 87, in _run_code\r\n    exec(code, run_globals)\r\n  File \"\/home\/david\/silnlp\/silnlp\/nmt\/translate.py\", line 181, in <module>\r\n    main()\r\n  File \"\/home\/david\/silnlp\/silnlp\/nmt\/translate.py\", line 169, in main\r\n    translator.translate_book(\r\n  File \"\/home\/david\/silnlp\/silnlp\/nmt\/translate.py\", line 82, in translate_book\r\n    self.init_translation_task(experiment_suffix=f\"_{self.checkpoint}_{book}\")\r\n  File \"\/home\/david\/silnlp\/silnlp\/nmt\/translate.py\", line 57, in init_translation_task\r\n    self.clearml = SILClearML(\r\n  File \"<string>\", line 8, in __init__\r\n  File \"\/home\/david\/silnlp\/silnlp\/common\/clearml.py\", line 27, in __post_init__\r\n    self.task = Task.init(\r\n  File \"\/home\/david\/.cache\/pypoetry\/virtualenvs\/silnlp-gt_VMn9E-py3.8\/lib\/python3.8\/site-packages\/clearml\/task.py\", line 491, in init\r\n    task = cls._create_dev_task(\r\n  File \"\/home\/david\/.cache\/pypoetry\/virtualenvs\/silnlp-gt_VMn9E-py3.8\/lib\/python3.8\/site-packages\/clearml\/task.py\", line 2554, in _create_dev_task\r\n    task = cls(\r\n  File \"\/home\/david\/.cache\/pypoetry\/virtualenvs\/silnlp-gt_VMn9E-py3.8\/lib\/python3.8\/site-packages\/clearml\/task.py\", line 164, in __init__\r\n    super(Task, self).__init__(**kwargs)\r\n  File \"\/home\/david\/.cache\/pypoetry\/virtualenvs\/silnlp-gt_VMn9E-py3.8\/lib\/python3.8\/site-packages\/clearml\/backend_interface\/task\/task.py\", line 151, in __init__\r\n    super(Task, self).__init__(id=task_id, session=session, log=log)\r\n  File \"\/home\/david\/.cache\/pypoetry\/virtualenvs\/silnlp-gt_VMn9E-py3.8\/lib\/python3.8\/site-packages\/clearml\/backend_interface\/base.py\", line 131, in __init__\r\n    super(IdObjectBase, self).__init__(session, log, **kwargs)\r\n  File \"\/home\/david\/.cache\/pypoetry\/virtualenvs\/silnlp-gt_VMn9E-py3.8\/lib\/python3.8\/site-packages\/clearml\/backend_interface\/base.py\", line 34, in __init__\r\n    self._session = session or self._get_default_session()\r\n  File \"\/home\/david\/.cache\/pypoetry\/virtualenvs\/silnlp-gt_VMn9E-py3.8\/lib\/python3.8\/site-packages\/clearml\/backend_interface\/base.py\", line 101, in _get_default_session\r\n    InterfaceBase._default_session = Session(\r\n  File \"\/home\/david\/.cache\/pypoetry\/virtualenvs\/silnlp-gt_VMn9E-py3.8\/lib\/python3.8\/site-packages\/clearml\/backend_api\/session\/session.py\", line 198, in __init__\r\n    self.refresh_token()\r\n  File \"\/home\/david\/.cache\/pypoetry\/virtualenvs\/silnlp-gt_VMn9E-py3.8\/lib\/python3.8\/site-packages\/clearml\/backend_api\/session\/token_manager.py\", line 104, in refresh_token\r\n    self._set_token(self._do_refresh_token(self.__token, exp=self.req_token_expiration_sec))\r\n  File \"\/home\/david\/.cache\/pypoetry\/virtualenvs\/silnlp-gt_VMn9E-py3.8\/lib\/python3.8\/site-packages\/clearml\/backend_api\/session\/session.py\", line 713, in _do_refresh_token\r\n    six.reraise(*sys.exc_info())\r\n  File \"\/home\/david\/.cache\/pypoetry\/virtualenvs\/silnlp-gt_VMn9E-py3.8\/lib\/python3.8\/site-packages\/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"\/home\/david\/.cache\/pypoetry\/virtualenvs\/silnlp-gt_VMn9E-py3.8\/lib\/python3.8\/site-packages\/clearml\/backend_api\/session\/session.py\", line 699, in _do_refresh_token\r\n    raise LoginError(\r\nclearml.backend_api.session.session.LoginError: Failed getting token (error 401 from https:\/\/api.pro.clear.ml): Unauthorized (invalid credentials) (failed to locate provided credentials)\r\ndavid@pop-os:~\/silnlp$ \r\n```\r\n\r\n\r\n",
        "Issue_answer_count":2,
        "Issue_self_closed":1.0,
        "Answer_body":"@davidbaines, Did that fix it? Yes! Thanks so much.",
        "Tool":"ClearML",
        "Platform":"Github",
        "Issue_original_content":"translat try us request prevent translat local machin tri translat follow command line trace command meant run local error credenti argument set command line python silnlp nmt translat checkpoint src project gela book trg iso nlg tensorflow stream executor platform default dso loader successfulli open dynam librari libcudart silnlp common environ info workspac home david gutenberg new environ variabl sil nlp data path silnlp common util info git commit acacab traceback recent file usr lib python runpi line run modul main return run code code main global file usr lib python runpi line run code exec code run global file home david silnlp silnlp nmt translat line main file home david silnlp silnlp nmt translat line main translat translat book file home david silnlp silnlp nmt translat line translat book self init translat task experi suffix self checkpoint book file home david silnlp silnlp nmt translat line init translat task self sil file line init file home david silnlp silnlp common line post init self task task init file home david cach pypoetri virtualenv silnlp vmne lib python site packag task line init task cl creat dev task file home david cach pypoetri virtualenv silnlp vmne lib python site packag task line creat dev task task cl file home david cach pypoetri virtualenv silnlp vmne lib python site packag task line init super task self init kwarg file home david cach pypoetri virtualenv silnlp vmne lib python site packag backend interfac task task line init super task self init task session session log log file home david cach pypoetri virtualenv silnlp vmne lib python site packag backend interfac base line init super idobjectbas self init session log kwarg file home david cach pypoetri virtualenv silnlp vmne lib python site packag backend interfac base line init self session session self default session file home david cach pypoetri virtualenv silnlp vmne lib python site packag backend interfac base line default session interfacebas default session session file home david cach pypoetri virtualenv silnlp vmne lib python site packag backend api session session line init self refresh token file home david cach pypoetri virtualenv silnlp vmne lib python site packag backend api session token manag line refresh token self set token self refresh token self token exp self req token expir sec file home david cach pypoetri virtualenv silnlp vmne lib python site packag backend api session session line refresh token rerais sy exc info file home david cach pypoetri virtualenv silnlp vmne lib python site packag line rerais rais valu file home david cach pypoetri virtualenv silnlp vmne lib python site packag backend api session session line refresh token rais loginerror backend api session session loginerror fail get token error http api pro clear unauthor invalid credenti fail locat provid credenti david pop silnlp",
        "Issue_preprocessed_content":"translat try us request prevent translat local machin tri translat line trace meant run credenti argument set line",
        "Issue_gpt_summary_original":"The user is unable to create a comet logger when using pytorch lightning cli. The error message shows that the `self._kwargs` has an unexpected keyword argument 'agg_key_funcs'.",
        "Issue_gpt_summary":"user unabl creat logger pytorch lightn cli error messag show self kwarg unexpect keyword argument agg kei func",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/huggingface\/transformers\/issues\/17691",
        "Issue_title":"\"comet-ml not installed\" error in Trainer (despite comet-ml being installed)",
        "Issue_created_time":1655132901000,
        "Issue_closed_time":1662130932000,
        "Issue_body":"### System Info\n\n```shell\n- `transformers` version: 4.19.4\r\n- Platform: Linux-4.19.0-17-amd64-x86_64-with-glibc2.31\r\n- Python version: 3.9.6\r\n- Huggingface_hub version: 0.4.0\r\n- PyTorch version (GPU?): 1.11.0+cu102 (False)\r\n- Tensorflow version (GPU?): 2.4.1 (False)\r\n- Flax version (CPU?\/GPU?\/TPU?): 0.4.0 (cpu)\r\n- Jax version: 0.3.4\r\n- JaxLib version: 0.3.2\r\n- Using GPU in script?: no\r\n- Using distributed or parallel set-up in script?: no\n```\n\n\n### Who can help?\n\n@sg\n\n### Information\n\n- [ ] The official example scripts\n- [X] My own modified scripts\n\n### Tasks\n\n- [X] An officially supported task in the `examples` folder (such as GLUE\/SQuAD, ...)\n- [ ] My own task or dataset (give details below)\n\n### Reproduction\n\n1. Install comet-ml (in my case comet-ml==3.31.3)\r\n2. Create TrainingArguments with `report-to='comet_ml'\r\n3. Try to instantiate Trainer\r\n\r\n\r\nThis can be reproduced by adding `report_to='comet_ml'` to training arguments in this notebook:\r\nhttps:\/\/github.com\/NielsRogge\/Transformers-Tutorials\/blob\/master\/BERT\/Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb\r\n\r\nFollowing error happens when creating the Trainer:\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n\/tmp\/ipykernel_5296\/3132099784.py in <module>\r\n----> 1 trainer = Trainer(\r\n      2     model,\r\n      3     args,\r\n      4     train_dataset=encoded_dataset[\"train\"],\r\n      5     eval_dataset=encoded_dataset[\"validation\"],\r\n\r\n\/opt\/conda\/lib\/python3.9\/site-packages\/transformers\/trainer.py in __init__(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\r\n    444         default_callbacks = DEFAULT_CALLBACKS + get_reporting_integration_callbacks(self.args.report_to)\r\n    445         callbacks = default_callbacks if callbacks is None else default_callbacks + callbacks\r\n--> 446         self.callback_handler = CallbackHandler(\r\n    447             callbacks, self.model, self.tokenizer, self.optimizer, self.lr_scheduler\r\n    448         )\r\n\r\n\/opt\/conda\/lib\/python3.9\/site-packages\/transformers\/trainer_callback.py in __init__(self, callbacks, model, tokenizer, optimizer, lr_scheduler)\r\n    288         self.callbacks = []\r\n    289         for cb in callbacks:\r\n--> 290             self.add_callback(cb)\r\n    291         self.model = model\r\n    292         self.tokenizer = tokenizer\r\n\r\n\/opt\/conda\/lib\/python3.9\/site-packages\/transformers\/trainer_callback.py in add_callback(self, callback)\r\n    305 \r\n    306     def add_callback(self, callback):\r\n--> 307         cb = callback() if isinstance(callback, type) else callback\r\n    308         cb_class = callback if isinstance(callback, type) else callback.__class__\r\n    309         if cb_class in [c.__class__ for c in self.callbacks]:\r\n\r\n\/opt\/conda\/lib\/python3.9\/site-packages\/transformers\/integrations.py in __init__(self)\r\n    667     def __init__(self):\r\n    668         if not _has_comet:\r\n--> 669             raise RuntimeError(\"CometCallback requires comet-ml to be installed. Run `pip install comet-ml`.\")\r\n    670         self._initialized = False\r\n    671         self._log_assets = False\r\n\r\nRuntimeError: CometCallback requires comet-ml to be installed. Run `pip install comet-ml`.\r\n```\n\n### Expected behavior\n\n```shell\nA Trainer is successfully created with cometml callback enabled.\n```\n",
        "Issue_answer_count":8,
        "Issue_self_closed":0.0,
        "Answer_body":"cc @sgugger  As the error message indicates, you need to have cometml installed to use it `report_to=\"comet_ml\"`\r\n```\r\nRuntimeError: CometCallback requires comet-ml to be installed. Run `pip install comet-ml`.\r\n```\r\nIt also tells you exactly which command to run to fix this: `pip install comet-ml`. Hey,\r\nThe issue here is that error appears despite cometml being installed (with pip).\r\n\r\nEDIT: Edited the issue title to make it more clear.\r\n\r\nOn Mon, Jul 4, 2022, 14:33 Sylvain Gugger ***@***.***> wrote:\r\n\r\n> As the error message indicates, you need to have cometml installed to use\r\n> it report_to=\"comet_ml\"\r\n>\r\n> RuntimeError: CometCallback requires comet-ml to be installed. Run `pip install comet-ml`.\r\n>\r\n> It also tells you exactly which command to run to fix this: pip install\r\n> comet-ml.\r\n>\r\n> \u2014\r\n> Reply to this email directly, view it on GitHub\r\n> <https:\/\/github.com\/huggingface\/transformers\/issues\/17691#issuecomment-1173767326>,\r\n> or unsubscribe\r\n> <https:\/\/github.com\/notifications\/unsubscribe-auth\/AF7MPQSGKFHH4UZWW3JTEWLVSLKYRANCNFSM5YURU4KQ>\r\n> .\r\n> You are receiving this because you authored the thread.Message ID:\r\n> ***@***.***>\r\n>\r\n Did you properly initialize it with your API key then? This issue has been automatically marked as stale because it has not had recent activity. If you think this still needs to be addressed please comment on this thread.\n\nPlease note that issues that do not follow the [contributing guidelines](https:\/\/github.com\/huggingface\/transformers\/blob\/main\/CONTRIBUTING.md) are likely to be ignored. @sgugger How to do it? In [this](https:\/\/huggingface.co\/docs\/transformers\/main_classes\/callback) doc, there's no mentioning about API key in comet callback. I tried set up COMET_API_KEY, COMET_MODE, COMET_PROJECT_NAME inside function that runs on spawn, but no luck so far. Also downgraded comet-ml till 3.1.17.\r\n\r\n`os.environ[\"COMET_API_KEY\"] = \"<api-key>\"`\r\n`os.environ[\"COMET_MODE\"] = \"ONLINE\"`\r\n`os.environ[\"COMET_PROJECT_NAME\"] = \"<project-name>\"` Maybe open an issue with them? We did not write this integration with comet-ml and we don't maintain it. It was written by the Comet team :-) This issue has been automatically marked as stale because it has not had recent activity. If you think this still needs to be addressed please comment on this thread.\n\nPlease note that issues that do not follow the [contributing guidelines](https:\/\/github.com\/huggingface\/transformers\/blob\/main\/CONTRIBUTING.md) are likely to be ignored.",
        "Tool":"Comet",
        "Platform":"Github",
        "Issue_original_content":"instal error trainer despit instal info shell transform version platform linux amd glibc python version huggingfac hub version pytorch version gpu fals tensorflow version gpu fals flax version cpu gpu tpu cpu jax version jaxlib version gpu script distribut parallel set script help inform offici exampl script modifi script task offici support task exampl folder glue squad task dataset detail reproduct instal case creat trainingargu report try instanti trainer reproduc ad report train argument notebook http github com nielsrogg transform tutori blob master bert fine tune bert friend multi label text classif ipynb follow error happen creat trainer runtimeerror traceback recent tmp ipykernel trainer trainer model arg train dataset encod dataset train eval dataset encod dataset valid opt conda lib python site packag transform trainer init self model arg data collat train dataset eval dataset token model init comput metric callback optim preprocess logit metric default callback default callback report integr callback self arg report callback default callback callback default callback callback self callback handler callbackhandl callback self model self token self optim self schedul opt conda lib python site packag transform trainer callback init self callback model token optim schedul self callback callback self add callback self model model self token token opt conda lib python site packag transform trainer callback add callback self callback def add callback self callback callback isinst callback type callback class callback isinst callback type callback class class class self callback opt conda lib python site packag transform integr init self def init self rais runtimeerror callback requir instal run pip instal self initi fals self log asset fals runtimeerror callback requir instal run pip instal expect behavior shell trainer successfulli creat callback enabl",
        "Issue_preprocessed_content":"trainer info help inform exampl script modifi script task task folder task dataset reproduct creat trainingargu train argument creat trainer expect behavior",
        "Issue_gpt_summary_original":"The user has encountered a bug where the RichProgressBar does not display progress bar when using Comet logger. The issue has been verified to work correctly with tensorboard and wandb. The user has provided a code snippet and environment details for reference.",
        "Issue_gpt_summary":"user encount bug richprogressbar displai progress bar logger issu verifi work correctli tensorboard user provid code snippet environ detail refer",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning\/issues\/12734",
        "Issue_title":"Unable to create comet logger when using pytorch lightning cli.",
        "Issue_created_time":1649790124000,
        "Issue_closed_time":1650063297000,
        "Issue_body":"## \ud83d\udc1b Bug\r\n\r\nUnable to create comet logger when using pytorch lightning cli.\r\n\r\n### To Reproduce\r\nhttps:\/\/colab.research.google.com\/drive\/1cvEyYHceKjunKpcGY39oFrinWnIVydJV?usp=sharing\r\n\r\n### Expected behavior\r\nRun model.\r\n\r\n### Environment\r\n\r\n* CUDA:\r\n\t- GPU:\r\n\t\t- Tesla T4\r\n\t- available:         True\r\n\t- version:           11.1\r\n* Packages:\r\n\t- numpy:             1.21.5\r\n\t- pyTorch_debug:     False\r\n\t- pyTorch_version:   1.10.0+cu111\r\n\t- pytorch-lightning: 1.6.0\r\n\t- tqdm:              4.63.0\r\n* System:\r\n\t- OS:                Linux\r\n\t- architecture:\r\n\t\t- 64bit\r\n\t\t- \r\n\t- processor:         x86_64\r\n\t- python:            3.7.13\r\n\t- version:           1 SMP Tue Dec 7 09:58:10 PST 2021\r\n\r\n### Additional context\r\n\r\nError message:\r\n```\r\nEpoch 1: 100% 32\/32 [00:00<00:00, 300.70it\/s, loss=-15.4, v_num=ff79]Traceback (most recent call last):\r\n  File \"main.py\", line 48, in <module>\r\n    cli = LightningCLI(BoringModel, LitDataset, save_config_callback=None)\r\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/pytorch_lightning\/utilities\/cli.py\", line 564, in __init__\r\n    self._run_subcommand(self.subcommand)\r\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/pytorch_lightning\/utilities\/cli.py\", line 835, in _run_subcommand\r\n    fn(**fn_kwargs)\r\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/pytorch_lightning\/trainer\/trainer.py\", line 772, in fit\r\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\r\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/pytorch_lightning\/trainer\/trainer.py\", line 724, in _call_and_handle_interrupt\r\n    return trainer_fn(*args, **kwargs)\r\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/pytorch_lightning\/trainer\/trainer.py\", line 812, in _fit_impl\r\n    results = self._run(model, ckpt_path=self.ckpt_path)\r\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/pytorch_lightning\/trainer\/trainer.py\", line 1237, in _run\r\n    results = self._run_stage()\r\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/pytorch_lightning\/trainer\/trainer.py\", line 1324, in _run_stage\r\n    return self._run_train()\r\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/pytorch_lightning\/trainer\/trainer.py\", line 1354, in _run_train\r\n    self.fit_loop.run()\r\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/pytorch_lightning\/loops\/base.py\", line 204, in run\r\n    self.advance(*args, **kwargs)\r\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/pytorch_lightning\/loops\/fit_loop.py\", line 269, in advance\r\n    self._outputs = self.epoch_loop.run(self._data_fetcher)\r\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/pytorch_lightning\/loops\/base.py\", line 204, in run\r\n    self.advance(*args, **kwargs)\r\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/pytorch_lightning\/loops\/epoch\/training_epoch_loop.py\", line 246, in advance\r\n    self.trainer._logger_connector.update_train_step_metrics()\r\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/pytorch_lightning\/trainer\/connectors\/logger_connector\/logger_connector.py\", line 202, in update_train_step_metrics\r\n    self.log_metrics(self.metrics[\"log\"])\r\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/pytorch_lightning\/trainer\/connectors\/logger_connector\/logger_connector.py\", line 130, in log_metrics\r\n    logger.log_metrics(metrics=scalar_metrics, step=step)\r\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/pytorch_lightning\/utilities\/rank_zero.py\", line 32, in wrapped_fn\r\n    return fn(*args, **kwargs)\r\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/pytorch_lightning\/loggers\/comet.py\", line 252, in log_metrics\r\n    self.experiment.log_metrics(metrics_without_epoch, step=step, epoch=epoch)\r\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/pytorch_lightning\/loggers\/base.py\", line 41, in experiment\r\n    return get_experiment() or DummyExperiment()\r\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/pytorch_lightning\/utilities\/rank_zero.py\", line 32, in wrapped_fn\r\n    return fn(*args, **kwargs)\r\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/pytorch_lightning\/loggers\/base.py\", line 39, in get_experiment\r\n    return fn(self)\r\n  File \"\/usr\/local\/lib\/python3.7\/dist-packages\/pytorch_lightning\/loggers\/comet.py\", line 223, in experiment\r\n    offline_directory=self.save_dir, project_name=self._project_name, **self._kwargs\r\nTypeError: __init__() got an unexpected keyword argument 'agg_key_funcs'\r\n```\r\nFor some reason, `self._kwargs` there has `{'agg_key_funcs': None, 'agg_default_func': None}`.\n\ncc @awaelchli @edward-io @borda @ananthsub @rohitgr7 @kamil-kaczmarek @Raalsky @Blaizzy",
        "Issue_answer_count":4,
        "Issue_self_closed":0.0,
        "Answer_body":"Facing the same issue but with W and B. see https:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/issues\/12529 and https:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/issues\/12714 This was fixed and included in the 1.6.1 release. Could you try upgrading lightning? \r\n`pip install --upgrade pytorch-lightning` \ud83e\udd1f  @awaelchli not the same bug, but my colab link to reproduce the bug is now throwing another error.",
        "Tool":"Comet",
        "Platform":"Github",
        "Issue_original_content":"unabl creat logger pytorch lightn cli bug unabl creat logger pytorch lightn cli reproduc http colab research googl com drive cveyyhcekjunkpcgyofrinwnivydjv usp share expect behavior run model environ cuda gpu tesla avail true version packag numpi pytorch debug fals pytorch version pytorch lightn tqdm linux architectur bit processor python version smp tue dec pst addit context error messag epoch cli lightningcli boringmodel litdataset save config callback file usr local lib python dist packag pytorch lightn util cli line init self run subcommand self subcommand file usr local lib python dist packag pytorch lightn util cli line run subcommand kwarg file usr local lib python dist packag pytorch lightn trainer trainer line fit self fit impl model train dataload val dataload datamodul ckpt path file usr local lib python dist packag pytorch lightn trainer trainer line handl interrupt return trainer arg kwarg file usr local lib python dist packag pytorch lightn trainer trainer line fit impl result self run model ckpt path self ckpt path file usr local lib python dist packag pytorch lightn trainer trainer line run result self run stage file usr local lib python dist packag pytorch lightn trainer trainer line run stage return self run train file usr local lib python dist packag pytorch lightn trainer trainer line run train self fit loop run file usr local lib python dist packag pytorch lightn loop base line run self advanc arg kwarg file usr local lib python dist packag pytorch lightn loop fit loop line advanc self output self epoch loop run self data fetcher file usr local lib python dist packag pytorch lightn loop base line run self advanc arg kwarg file usr local lib python dist packag pytorch lightn loop epoch train epoch loop line advanc self trainer logger connector updat train step metric file usr local lib python dist packag pytorch lightn trainer connector logger connector logger connector line updat train step metric self log metric self metric log file usr local lib python dist packag pytorch lightn trainer connector logger connector logger connector line log metric logger log metric metric scalar metric step step file usr local lib python dist packag pytorch lightn util rank zero line wrap return arg kwarg file usr local lib python dist packag pytorch lightn logger line log metric self experi log metric metric epoch step step epoch epoch file usr local lib python dist packag pytorch lightn logger base line experi return experi dummyexperi file usr local lib python dist packag pytorch lightn util rank zero line wrap return arg kwarg file usr local lib python dist packag pytorch lightn logger base line experi return self file usr local lib python dist packag pytorch lightn logger line experi offlin directori self save dir project self project self kwarg typeerror init got unexpect keyword argument agg kei func reason self kwarg agg kei func agg default func awaelchli edward borda ananthsub rohitgr kamil kaczmarek raalski blaizzi",
        "Issue_preprocessed_content":"unabl creat pytorch lightn cli bug unabl creat pytorch lightn cli reproduc expect behavior run model environ cuda gpu tesla avail true version packag numpi fals tqdm linux architectur bit python version smp tue dec pst context reason",
        "Issue_gpt_summary_original":"the user encountered a challenge where the training of a resnet model on multi-core tpus crashed and printed an error message of \"dumping computation\" at the start of the validation loop when using a logger ( or .ml).",
        "Issue_gpt_summary":"user encount challeng train resnet model multi core tpu crash print error messag dump comput start valid loop logger",
        "Issue_score_count":1
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning\/issues\/11043",
        "Issue_title":"RichProgressBar doesn't display progress bar when using Comet logger.",
        "Issue_created_time":1639406686000,
        "Issue_closed_time":1666742778000,
        "Issue_body":"## \ud83d\udc1b Bug\r\n\r\nRichProgressBar doesn't display progress bar when using Comet logger.\r\nI verified it works correctly with tensorboard and wandb.\r\n\r\n\r\n### To Reproduce\r\n```python\r\nimport comet_ml\r\nimport os\r\n\r\nimport torch\r\nfrom pytorch_lightning import LightningModule, Trainer\r\nfrom torch.utils.data import DataLoader, Dataset\r\nfrom pytorch_lightning.loggers import CometLogger\r\nfrom pytorch_lightning.callbacks import RichProgressBar\r\n\r\n\r\nclass RandomDataset(Dataset):\r\n    def __init__(self, size: int, length: int):\r\n        self.len = length\r\n        self.data = torch.randn(length, size)\r\n\r\n    def __getitem__(self, index):\r\n        return self.data[index]\r\n\r\n    def __len__(self):\r\n        return self.len\r\n\r\n\r\nclass BoringModel(LightningModule):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.layer = torch.nn.Linear(32, 2)\r\n\r\n    def forward(self, x):\r\n        return self.layer(x)\r\n\r\n    def loss(self, batch, prediction):\r\n        # An arbitrary loss to have a loss that updates the model weights during `Trainer.fit` calls\r\n        return torch.nn.functional.mse_loss(prediction, torch.ones_like(prediction))\r\n\r\n    def step(self, x):\r\n        x = self(x)\r\n        out = torch.nn.functional.mse_loss(x, torch.ones_like(x))\r\n        return out\r\n\r\n    def training_step(self, batch, batch_idx):\r\n        output = self(batch)\r\n        loss = self.loss(batch, output)\r\n        return {\"loss\": loss}\r\n\r\n    def training_step_end(self, training_step_outputs):\r\n        return training_step_outputs\r\n\r\n    def training_epoch_end(self, outputs) -> None:\r\n        torch.stack([x[\"loss\"] for x in outputs]).mean()\r\n\r\n    def validation_step(self, batch, batch_idx):\r\n        output = self(batch)\r\n        loss = self.loss(batch, output)\r\n        return {\"x\": loss}\r\n\r\n    def validation_epoch_end(self, outputs) -> None:\r\n        torch.stack([x[\"x\"] for x in outputs]).mean()\r\n\r\n    def test_step(self, batch, batch_idx):\r\n        output = self(batch)\r\n        loss = self.loss(batch, output)\r\n        return {\"y\": loss}\r\n\r\n    def test_epoch_end(self, outputs) -> None:\r\n        torch.stack([x[\"y\"] for x in outputs]).mean()\r\n\r\n    def configure_optimizers(self):\r\n        optimizer = torch.optim.SGD(self.layer.parameters(), lr=0.1)\r\n        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1)\r\n        return [optimizer], [lr_scheduler]\r\n\r\n    def train_dataloader(self):\r\n        return DataLoader(RandomDataset(32, 64))\r\n\r\n    def val_dataloader(self):\r\n        return DataLoader(RandomDataset(32, 64))\r\n\r\n    def test_dataloader(self):\r\n        return DataLoader(RandomDataset(32, 64))\r\n\r\n    def predict_dataloader(self):\r\n        return DataLoader(RandomDataset(32, 64))\r\n\r\n\r\nmodel = BoringModel()\r\n\r\nlogger = CometLogger(api_key=os.environ.get(\"COMET_API_TOKEN\"))\r\n\r\ntrainer = Trainer(logger=logger, max_epochs=100, callbacks=[RichProgressBar()])\r\n# trainer = Trainer(logger=logger, max_epochs=100)\r\n\r\ntrainer.fit(model=model)\r\n```\r\n\r\n### Environment\r\n- PyTorch Lightning Version 1.5.5\r\n- PyTorch Version 1.10.0\r\n- Python version 3.8\r\n- OS Ubuntu 20.04\n\ncc @kaushikb11 @rohitgr7 @SeanNaren",
        "Issue_answer_count":6,
        "Issue_self_closed":0.0,
        "Answer_body":"This issue has been automatically marked as stale because it hasn't had any recent activity. This issue will be closed in 7 days if no further activity occurs. Thank you for your contributions, Pytorch Lightning Team!\n This issue has been automatically marked as stale because it hasn't had any recent activity. This issue will be closed in 7 days if no further activity occurs. Thank you for your contributions, Pytorch Lightning Team!\n Is there any update for this bug? Any update on this issue?\r\nI'm experiencing the same problem when using `comet` logger and `RichProgressBar` @ItamarKanter @JackLin-Authme I just tried this and can see the rich progress bar working fine. Is it possible that I am using a newer version of either rich or comet that now fixed the problem? Do you still have documentation of what version(s) you were using?\r\n\r\nI'm closing the issue now, but if you find any more issues related to this we can continue the investigation.  I still experience the issue. Adding more information on this, the progress bar DO show, however only after it has been completed. Moreover, any `rich.print` calls show no color, including the progress bar itself. The only solution I found is to stop using the Comet logger.\r\n\r\npackage versions:\r\npytorch-lightning     1.9.0\r\ncomet-ml                 3.32.0\r\nrich                          13.3.1\r\n\r\n",
        "Tool":"Comet",
        "Platform":"Github",
        "Issue_original_content":"richprogressbar displai progress bar logger bug richprogressbar displai progress bar logger verifi work correctli tensorboard reproduc python import import import torch pytorch lightn import lightningmodul trainer torch util data import dataload dataset pytorch lightn logger import logger pytorch lightn callback import richprogressbar class randomdataset dataset def init self size int length int self len length self data torch randn length size def getitem self index return self data index def len self return self len class boringmodel lightningmodul def init self super init self layer torch linear def forward self return self layer def loss self batch predict arbitrari loss loss updat model weight trainer fit call return torch function mse loss predict torch on like predict def step self self torch function mse loss torch on like return def train step self batch batch idx output self batch loss self loss batch output return loss loss def train step end self train step output return train step output def train epoch end self output torch stack loss output mean def valid step self batch batch idx output self batch loss self loss batch output return loss def valid epoch end self output torch stack output mean def test step self batch batch idx output self batch loss self loss batch output return loss def test epoch end self output torch stack output mean def configur optim self optim torch optim sgd self layer paramet schedul torch optim schedul steplr optim step size return optim schedul def train dataload self return dataload randomdataset def val dataload self return dataload randomdataset def test dataload self return dataload randomdataset def predict dataload self return dataload randomdataset model boringmodel logger logger api kei environ api token trainer trainer logger logger max epoch callback richprogressbar trainer trainer logger logger max epoch trainer fit model model environ pytorch lightn version pytorch version python version ubuntu kaushikb rohitgr seannaren",
        "Issue_preprocessed_content":"displai bar bug displai bar verifi work tensorboard reproduc environ pytorch lightn version pytorch version python version ubuntu",
        "Issue_gpt_summary_original":"The user is reporting a bug with the Comet Logger not logging with tpu_cores=8. They have provided a BoringModel colab link and are requesting help reproducing the issue. They have also requested the user to provide their environment details.",
        "Issue_gpt_summary":"user report bug logger log tpu core provid boringmodel colab link request help reproduc issu request user provid environ detail",
        "Issue_score_count":6
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning\/issues\/9879",
        "Issue_title":"\"dumps computation\" at the start of validation loop when using wandb\/comet.ml logger during multi-core tpu training",
        "Issue_created_time":1633792312000,
        "Issue_closed_time":1642181493000,
        "Issue_body":"## \ud83d\udc1b Bug\r\n\r\nI am training a resnet model on multi core tpus on kaggle. I get this error:\r\n```\r\nDumping Computation:\r\n2021-10-08 23:57:50.220206: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %constant.92108 = s32[] constant(0)\r\n2021-10-08 23:57:50.220217: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %compare.92110 = pred[] compare(s32[] %constant.92102, s32[] %constant.92108), direction=NE, type=UNSIGNED\r\n2021-10-08 23:57:50.220227: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %constant.92109 = f32[] constant(1)\r\n2021-10-08 23:57:50.220238: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %convert.92111 = f32[] convert(s32[] %constant.92102)\r\n2021-10-08 23:57:50.220248: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %divide.92112 = f32[] divide(f32[] %constant.92109, f32[] %convert.92111)\r\n2021-10-08 23:57:50.220260: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %constant.92113 = f32[] constant(nan)\r\n2021-10-08 23:57:50.220271: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %select.92114 = f32[] select(pred[] %compare.92110, f32[] %divide.92112, f32[] %constant.92113)\r\n2021-10-08 23:57:50.220281: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %multiply.92115 = f32[] multiply(f32[] %reduce.92107, f32[] %select.92114)\r\n2021-10-08 23:57:50.220292: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %convert.92116 = f32[] convert(f32[] %multiply.92115)\r\n2021-10-08 23:57:50.220302: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %reshape.134449 = f32[1]{0} reshape(f32[] %convert.92116)\r\n2021-10-08 23:57:50.220312: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %reshape.92081 = f32[1]{0} reshape(f32[] %p3148.47101)\r\n2021-10-08 23:57:50.220323: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %concatenate.92082 = f32[1]{0} concatenate(f32[1]{0} %reshape.92081), dimensions={0}\r\n2021-10-08 23:57:50.220333: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %constant.92083 = f32[] constant(0)\r\n2021-10-08 23:57:50.220343: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %reduce.92089 = f32[] reduce(f32[1]{0} %concatenate.92082, f32[] %constant.92083), dimensions={0}, to_apply=%AddComputation.92085\r\n2021-10-08 23:57:50.220353: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %constant.92084 = s32[] constant(1)\r\n2021-10-08 23:57:50.220364: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %constant.92090 = s32[] constant(0)\r\n2021-10-08 23:57:50.220375: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %compare.92092 = pred[] compare(s32[] %constant.92084, s32[] %constant.92090), direction=NE, type=UNSIGNED\r\n2021-10-08 23:57:50.220387: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %constant.92091 = f32[] constant(1)\r\n2021-10-08 23:57:50.220397: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %convert.92093 = f32[] convert(s32[] %constant.92084)\r\n2021-10-08 23:57:50.220408: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %divide.92094 = f32[] divide(f32[] %constant.92091, f32[] %convert.92093)\r\n2021-10-08 23:57:50.220418: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %constant.92095 = f32[] constant(nan)\r\n2021-10-08 23:57:50.220465: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %select.92096 = f32[] select(pred[] %compare.92092, f32[] %divide.92094, f32[] %constant.92095)\r\n2021-10-08 23:57:50.220482: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %multiply.92097 = f32[] multiply(f32[] %reduce.92089, f32[] %select.92096)\r\n2021-10-08 23:57:50.220494: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %convert.92098 = f32[] convert(f32[] %multiply.92097)\r\n2021-10-08 23:57:50.220504: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %reshape.134450 = f32[1]{0} reshape(f32[] %convert.92098)\r\n2021-10-08 23:57:50.220515: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %reshape.92063 = f32[1]{0} reshape(f32[] %p3147.47082)\r\n2021-10-08 23:57:50.220525: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %concatenate.92064 = f32[1]{0} concatenate(f32[1]{0} %reshape.92063), dimensions={0}\r\n2021-10-08 23:57:50.220535: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %constant.92065 = f32[] constant(0)\r\n2021-10-08 23:57:50.220545: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %reduce.92071 = f32[] reduce(f32[1]{0} %concatenate.92064, f32[] %constant.92065), dimensions={0}, to_apply=%AddComputation.92067\r\n2021-10-08 23:57:50.220556: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %constant.92066 = s32[] constant(1)\r\n2021-10-08 23:57:50.220566: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %constant.92072 = s32[] constant(0)\r\n2021-10-08 23:57:50.220576: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %compare.92074 = pred[] compare(s32[] %constant.92066, s32[] %constant.92072), direction=NE, type=UNSIGNED\r\n2021-10-08 23:57:50.220587: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %constant.92073 = f32[] constant(1)\r\n2021-10-08 23:57:50.220598: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %convert.92075 = f32[] convert(s32[] %constant.92066)\r\n2021-10-08 23:57:50.220608: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %divide.92076 = f32[] divide(f32[] %constant.92073, f32[] %convert.92075)\r\n2021-10-08 23:57:50.220618: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %constant.92077 = f32[] constant(nan)\r\n2021-10-08 23:57:50.220629: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %select.92078 = f32[] select(pred[] %compare.92074, f32[] %divide.92076, f32[] %constant.92077)\r\n2021-10-08 23:57:50.220640: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %multiply.92079 = f32[] multiply(f32[] %reduce.92071, f32[] %select.92078)\r\n2021-10-08 23:57:50.220650: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %convert.92080 = f32[] convert(f32[] %multiply.92079)\r\n2021-10-08 23:57:50.220660: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %reshape.134451 = f32[1]{0} reshape(f32[] %convert.92080)\r\n2021-10-08 23:57:50.220670: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %reshape.92045 = f32[1]{0} reshape(f32[] %p3146.47063)\r\n2021-10-08 23:57:50.220680: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %concatenate.92046 = f32[1]{0} concatenate(f32[1]{0} %reshape.92045), dimensions={0}\r\n2021-10-08 23:57:50.220691: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %constant.92047 = f32[] constant(0)\r\n2021-10-08 23:57:50.220701: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %reduce.92053 = f32[] reduce(f32[1]{0} %concatenate.92046, f32[] %constant.92047), dimensions={0}, to_apply=%AddComputation.92049\r\n2021-10-08 23:57:50.220711: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %constant.92048 = s32[] constant(1)\r\n2021-10-08 23:57:50.220722: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %constant.92054 = s32[] constant(0)\r\n2021-10-08 23:57:50.220733: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %compare.92056 = pred[] compare(s32[] %constant.92048, s32[] %constant.92054), direction=NE, type=UNSIGNED\r\n2021-10-08 23:57:50.220759: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %constant.92055 = f32[] constant(1)\r\n2021-10-08 23:57:50.220770: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %convert.92057 = f32[] convert(s32[] %constant.92048)\r\n2021-10-08 23:57:50.220781: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %divide.92058 = f32[] divide(f32[] %constant.92055, f32[] %convert.92057)\r\n2021-10-08 23:57:50.220792: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %constant.92059 = f32[] constant(nan)\r\n2021-10-08 23:57:50.220803: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %select.92060 = f32[] select(pred[] %compare.92056, f32[] %divide.92058, f32[] %constant.92059)\r\n2021-10-08 23:57:50.220813: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %multiply.92061 = f32[] multiply(f32[] %reduce.92053, f32[] %select.92060)\r\n2021-10-08 23:57:50.220823: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %convert.92062 = f32[] convert(f32[] %multiply.92061)\r\n2021-10-08 23:57:50.220833: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %reshape.134452 = f32[1]{0} reshape(f32[] %convert.92062)\r\n2021-10-08 23:57:50.220843: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %reshape.92027 = f32[1]{0} reshape(f32[] %p3145.47044)\r\n2021-10-08 23:57:50.220854: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %concatenate.92028 = f32[1]{0} concatenate(f32[1]{0} %reshape.92027), dimensions={0}\r\n2021-10-08 23:57:50.220865: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %constant.92029 = f32[] constant(0)\r\n2021-10-08 23:57:50.220876: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %reduce.92035 = f32[] reduce(f32[1]{0} %concatenate.92028, f32[] %constant.92029), dimensions={0}, to_apply=%AddComputation.92031\r\n2021-10-08 23:57:50.220888: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %constant.92030 = s32[] constant(1)\r\n2021-10-08 23:57:50.220899: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %constant.92036 = s32[] constant(0)\r\n2021-10-08 23:57:50.220910: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %compare.92038 = pred[] compare(s32[] %constant.92030, s32[] %constant.92036), direction=NE, type=UNSIGNED\r\n2021-10-08 23:57:50.220921: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %constant.92037 = f32[] constant(1)\r\n2021-10-08 23:57:50.220932: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %convert.92039 = f32[] convert(s32[] %constant.92030)\r\n2021-10-08 23:57:50.220942: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %divide.92040 = f32[] divide(f32[] %constant.92037, f32[] %convert.92039)\r\n2021-10-08 23:57:50.220953: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %constant.92041 = f32[] constant(nan)\r\n2021-10-08 23:57:50.220964: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %select.92042 = f32[] select(pred[] %compare.92038, f32[] %divide.92040, f32[] %constant.92041)\r\n2021-10-08 23:57:50.220975: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %multiply.92043 = f32[] multiply(f32[] %reduce.92035, f32[] %select.92042)\r\n2021-10-08 23:57:50.220986: E tensorflow\/compiler\/xla\/xla_client\/xla_util.cc:76] %convert.92044 = f32[] convert(f32[] %multiply.92043)\r\n```\r\nThis text goes on and on for several pages.\r\n\r\nThe first epoch runs fine at first and just as the validation loop starts, the training crashes and this text is printed as output.\r\n\r\nNote that this only happens when using a logger (wandb or comet.ml) and everything works fine when I do `self.print` or normal `print` as evident in this [notebook](https:\/\/www.kaggle.com\/rustyelectron\/documentclassification-pytorch-tpu-no-logging\/).\r\n\r\n> I have also tried adding very small batch sizes so this probably isn't a memory issue\r\n\r\n### To Reproduce\r\n\r\nSee this [notebook](https:\/\/www.kaggle.com\/rustyelectron\/documentclassification-pytorch-tpu-resnet200d) that uses wandb and [this](https:\/\/www.kaggle.com\/rustyelectron\/documentclassification-pytorch-tpu-comet-ml) with comet.ml.\r\n\r\n### Expected behavior\r\n\r\nTraining should run normally with no issues and logging should work.\r\n\r\n### Environment\r\n\r\n* CUDA:\r\n\t- GPU:\r\n\t- available:         False\r\n\t- version:           None\r\n* Packages:\r\n\t- numpy:             1.19.5\r\n\t- pyTorch_debug:     False\r\n\t- pyTorch_version:   1.7.1+cpu\r\n\t- pytorch-lightning: 1.4.4\r\n\t- tqdm:              4.62.1\r\n\t- pytorch-xla  1.7\r\n* System:\r\n\t- OS:                Linux\r\n\t- architecture:\r\n\t\t- 64bit\r\n\t\t- \r\n\t- processor:         x86_64\r\n\t- python:            3.7.10\r\n\r\n### Additional context\r\nNone\r\n\n\ncc @kaushikb11 @rohitgr7 @awaelchli @morganmcg1 @AyushExel @borisdayma @scottire",
        "Issue_answer_count":11,
        "Issue_self_closed":0.0,
        "Answer_body":"Thanks @rusty-electron for opening the issue.\r\n\r\nIs there any more information before the line \"Dumping Computation:\"?  No error output, just the logs from wandb logger and the progressbars created by `tqdm`. Dear @rusty-electron,\r\n\r\nWe are working with the Wandb Team on a large fix. Hopefully it will work for this use-case too.\r\n\r\nWe will keep you updated.\r\n\r\nBest,\r\nT.C @tchaton Thanks for the info. I shall be looking out for the fix. @tchaton Is there an issue to track the Wandb updates? @borisdayma Any idea ?\r\n It's actually a few different PR's ongoing.\r\nI think we should have something next week that will handle these scenarios. This issue has been automatically marked as stale because it hasn't had any recent activity. This issue will be closed in 7 days if no further activity occurs. Thank you for your contributions, Pytorch Lightning Team!\n @borisdayma Did it end up being an issue on the wandb side? I didn't follow the development lately. If it's still work in progress, could you point us to a PR or issue? Thx in advance <3  We're actually still in the process of updating the way multiprocess is supported.\r\nThere's been good progress, just a few edge cases to handle. This issue has been automatically marked as stale because it hasn't had any recent activity. This issue will be closed in 7 days if no further activity occurs. Thank you for your contributions, Pytorch Lightning Team!\n",
        "Tool":"Comet",
        "Platform":"Github",
        "Issue_original_content":"dump comput start valid loop logger multi core tpu train bug train resnet model multi core tpu kaggl error dump comput tensorflow compil xla xla client xla util constant constant tensorflow compil xla xla client xla util compar pred compar constant constant direct type unsign tensorflow compil xla xla client xla util constant constant tensorflow compil xla xla client xla util convert convert constant tensorflow compil xla xla client xla util divid divid constant convert tensorflow compil xla xla client xla util constant constant nan tensorflow compil xla xla client xla util select select pred compar divid constant tensorflow compil xla xla client xla util multipli multipli reduc select tensorflow compil xla xla client xla util convert convert multipli tensorflow compil xla xla client xla util reshap reshap convert tensorflow compil xla xla client xla util reshap reshap tensorflow compil xla xla client xla util concaten concaten reshap dimens tensorflow compil xla xla client xla util constant constant tensorflow compil xla xla client xla util reduc reduc concaten constant dimens appli addcomput tensorflow compil xla xla client xla util constant constant tensorflow compil xla xla client xla util constant constant tensorflow compil xla xla client xla util compar pred compar constant constant direct type unsign tensorflow compil xla xla client xla util constant constant tensorflow compil xla xla client xla util convert convert constant tensorflow compil xla xla client xla util divid divid constant convert tensorflow compil xla xla client xla util constant constant nan tensorflow compil xla xla client xla util select select pred compar divid constant tensorflow compil xla xla client xla util multipli multipli reduc select tensorflow compil xla xla client xla util convert convert multipli tensorflow compil xla xla client xla util reshap reshap convert tensorflow compil xla xla client xla util reshap reshap tensorflow compil xla xla client xla util concaten concaten reshap dimens tensorflow compil xla xla client xla util constant constant tensorflow compil xla xla client xla util reduc reduc concaten constant dimens appli addcomput tensorflow compil xla xla client xla util constant constant tensorflow compil xla xla client xla util constant constant tensorflow compil xla xla client xla util compar pred compar constant constant direct type unsign tensorflow compil xla xla client xla util constant constant tensorflow compil xla xla client xla util convert convert constant tensorflow compil xla xla client xla util divid divid constant convert tensorflow compil xla xla client xla util constant constant nan tensorflow compil xla xla client xla util select select pred compar divid constant tensorflow compil xla xla client xla util multipli multipli reduc select tensorflow compil xla xla client xla util convert convert multipli tensorflow compil xla xla client xla util reshap reshap convert tensorflow compil xla xla client xla util reshap reshap tensorflow compil xla xla client xla util concaten concaten reshap dimens tensorflow compil xla xla client xla util constant constant tensorflow compil xla xla client xla util reduc reduc concaten constant dimens appli addcomput tensorflow compil xla xla client xla util constant constant tensorflow compil xla xla client xla util constant constant tensorflow compil xla xla client xla util compar pred compar constant constant direct type unsign tensorflow compil xla xla client xla util constant constant tensorflow compil xla xla client xla util convert convert constant tensorflow compil xla xla client xla util divid divid constant convert tensorflow compil xla xla client xla util constant constant nan tensorflow compil xla xla client xla util select select pred compar divid constant tensorflow compil xla xla client xla util multipli multipli reduc select tensorflow compil xla xla client xla util convert convert multipli tensorflow compil xla xla client xla util reshap reshap convert tensorflow compil xla xla client xla util reshap reshap tensorflow compil xla xla client xla util concaten concaten reshap dimens tensorflow compil xla xla client xla util constant constant tensorflow compil xla xla client xla util reduc reduc concaten constant dimens appli addcomput tensorflow compil xla xla client xla util constant constant tensorflow compil xla xla client xla util constant constant tensorflow compil xla xla client xla util compar pred compar constant constant direct type unsign tensorflow compil xla xla client xla util constant constant tensorflow compil xla xla client xla util convert convert constant tensorflow compil xla xla client xla util divid divid constant convert tensorflow compil xla xla client xla util constant constant nan tensorflow compil xla xla client xla util select select pred compar divid constant tensorflow compil xla xla client xla util multipli multipli reduc select tensorflow compil xla xla client xla util convert convert multipli text goe page epoch run fine valid loop start train crash text print output note happen logger work fine self print normal print evid notebook http www kaggl com rustyelectron documentclassif pytorch tpu log tri ad small batch size probabl isn memori issu reproduc notebook http www kaggl com rustyelectron documentclassif pytorch tpu resnetd us http www kaggl com rustyelectron documentclassif pytorch tpu expect behavior train run normal issu log work environ cuda gpu avail fals version packag numpi pytorch debug fals pytorch version cpu pytorch lightn tqdm pytorch xla linux architectur bit processor python addit context kaushikb rohitgr awaelchli morganmcg ayushexel borisdayma scottir",
        "Issue_preprocessed_content":"dump comput start valid tpu train bug train resnet model multi core tpu text goe page epoch run fine valid start train crash text print output note work fine normal evid tri batch size probabl isn memori reproduc us expect behavior train run work environ cuda gpu avail fals version packag numpi fals tqdm linux architectur bit python context",
        "Issue_gpt_summary_original":"Upgrading from pytorch-lightning 1.2.4 to 1.3.1 causes the pytorch comet logger to produce multiple experiments, one for each GPU, when running a ddp multi-gpu experiment on a SLURM cluster. Only one of them logs any metrics, the others just sit. The expected behavior is a single comet experiment for a single call to trainer.fit(). The user is unable to provide a reproducible example due to the inability to do multi-gpu ddp in colab and the need for a comet authentication.",
        "Issue_gpt_summary":"upgrad pytorch lightn caus pytorch logger produc multipl experi gpu run ddp multi gpu experi slurm cluster log metric sit expect behavior singl experi singl trainer fit user unabl provid reproduc exampl inabl multi gpu ddp colab need authent",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning\/issues\/7880",
        "Issue_title":"Comet Logger doesn't seem to log with tpu_cores=8",
        "Issue_created_time":1623138830000,
        "Issue_closed_time":1636988013000,
        "Issue_body":"## \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n## Please reproduce using the BoringModel\r\n\r\n\r\n<!-- Please paste your BoringModel colab link here. -->\r\n\r\n### To Reproduce\r\n\r\nUse following [**BoringModel**](https:\/\/colab.research.google.com\/drive\/1HvWVVTK8j2Nj52qU4Q4YCyzOm0_aLQF3?usp=sharing) and post here\r\n\r\n<!-- If you could not reproduce using the BoringModel and still think there's a bug, please post here -->\r\n\r\n### Expected behavior\r\n\r\n<!-- FILL IN -->\r\n\r\n### Environment\r\n\r\n**Note**: `Bugs with code` are solved faster ! `Colab Notebook` should be made `public` !\r\n\r\n* `IDE`: Please, use our python [bug_report_model.py](https:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/blob\/master\/pl_examples\/bug_report_model.py\r\n) template.\r\n\r\n* `Colab Notebook`: Please copy and paste the output from our [environment collection script](https:\/\/raw.githubusercontent.com\/PyTorchLightning\/pytorch-lightning\/master\/tests\/collect_env_details.py) (or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https:\/\/raw.githubusercontent.com\/PyTorchLightning\/pytorch-lightning\/master\/tests\/collect_env_details.py\r\n# For security purposes, please check the contents of collect_env_details.py before running it.\r\npython collect_env_details.py\r\n```\r\n\r\n - PyTorch Version (e.g., 1.0):\r\n - OS (e.g., Linux):\r\n - How you installed PyTorch (`conda`, `pip`, source):\r\n - Build command you used (if compiling from source):\r\n - Python version:\r\n - CUDA\/cuDNN version:\r\n - GPU models and configuration:\r\n - Any other relevant information:\r\n\r\n### Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n\n\ncc @tchaton",
        "Issue_answer_count":2,
        "Issue_self_closed":1.0,
        "Answer_body":"@tchaton Is this a lightning issue? Closing this issue as there is no progress nor manifestation from the Comet Team.",
        "Tool":"Comet",
        "Platform":"Github",
        "Issue_original_content":"logger log tpu core bug reproduc boringmodel reproduc us follow boringmodel http colab research googl com drive hvwvvtkjnjquqycyzom alqf usp share post expect behavior environ note bug code solv faster colab notebook public id us python bug report model http github com pytorchlightn pytorch lightn blob master exampl bug report model templat colab notebook copi past output environ collect script http raw githubusercont com pytorchlightn pytorch lightn master test collect env detail checklist manual script run wget http raw githubusercont com pytorchlightn pytorch lightn master test collect env detail secur purpos check content collect env detail run python collect env detail pytorch version linux instal pytorch conda pip sourc build command compil sourc python version cuda cudnn version gpu model configur relev inform addit context tchaton",
        "Issue_preprocessed_content":"log bug clear concis descript bug reproduc boringmodel past boringmodel colab link reproduc us post reproduc boringmodel think bug post expect behavior environ note solv faster us python templat copi past output script run pytorch version pytorch build python version version gpu model configur relev inform context context problem",
        "Issue_gpt_summary_original":"The issue is that when `logger.log_metrics(metrics)` is called with a `CometLogger`, `metrics` may be modified in-place, which can lead to confusing errors. The other loggers do not change `metrics` in-place when `log_metrics` is called. The user is willing to submit a PR to fix this issue and has some questions regarding the changes.",
        "Issue_gpt_summary":"issu logger log metric metric call logger metric modifi place lead confus error logger chang metric place log metric call user will submit fix issu question chang",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning\/issues\/7599",
        "Issue_title":"Upgrading from 1.2.4 to 1.3.1 causes the pytorch comet logger to produce multiple experiments.",
        "Issue_created_time":1621374020000,
        "Issue_closed_time":1631600832000,
        "Issue_body":"## \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\nWhen running a ddp multi-gpu experiment on a SLURM cluster, pytorch-lightning==1.3.1, but not 1.2.4, creates multiple comet experiments, one for each GPU. Only one of them logs any metrics, the others just sit. \r\n\r\n<img width=\"748\" alt=\"Screen Shot 2021-05-18 at 2 00 40 PM\" src=\"https:\/\/user-images.githubusercontent.com\/1208492\/118725668-1903b800-b7e5-11eb-84a5-096fa79fe332.png\">\r\n\r\n<img width=\"1477\" alt=\"Screen Shot 2021-05-18 at 1 59 26 PM\" src=\"https:\/\/user-images.githubusercontent.com\/1208492\/118725654-143f0400-b7e5-11eb-949b-4eb8de527502.png\">\r\n  \r\nHere is an experiment from the 'main' GPU, the one that actually logs the metrics.\r\nhttps:\/\/www.comet.ml\/bw4sz\/everglades\/view\/SYQJplzX3SBwVfG27moJV0b8p\r\n\r\nHere is the same run, a gpu that just announces itself and does not log anything else:\r\nhttps:\/\/www.comet.ml\/bw4sz\/everglades\/4d1b0d55601444ffbea00bd87b456c1e\r\n\r\n## Please reproduce using the BoringModel\r\n\r\n### To Reproduce\r\n\r\n<!-- If you could not reproduce using the BoringModel and still think there's a bug, please post here -->\r\n\r\nI do not know how to make a reproducible example, since you cannot do multi-gpu ddp in colab and would need a comet authentication, which I cannot paste here.\r\n\r\n### Expected behavior\r\n\r\nA single comet experiment for a single call to trainer.fit(). This was the behavior in lightning 1.2.4.\r\n\r\n### Environment\r\n\r\n**Note**: `Bugs with code` are solved faster ! `Colab Notebook` should be made `public` !\r\n\r\n* `IDE`: Please, use our python [bug_report_model.py](https:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/blob\/master\/pl_examples\/bug_report_model.py\r\n) template.\r\n\r\n* `Colab Notebook`: Please copy and paste the output from our [environment collection script](https:\/\/raw.githubusercontent.com\/PyTorchLightning\/pytorch-lightning\/master\/tests\/collect_env_details.py) (or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https:\/\/raw.githubusercontent.com\/PyTorchLightning\/pytorch-lightning\/master\/tests\/collect_env_details.py\r\n# For security purposes, please check the contents of collect_env_details.py before running it.\r\npython collect_env_details.py\r\n```\r\n\r\n - PyTorch Version (e.g., 1.0): \r\n torch==1.8.1\r\n pytorch-lightning==1.3.1\r\n - OS (e.g., Linux): Linux\r\n - How you installed PyTorch (`conda`, `pip`, source): pip\r\n - Build command you used (if compiling from source):\r\n - Python version: Python 3.8.8\r\n - CUDA\/cuDNN version: 10\r\n - GPU models and configuration: GeForce 2080Ti\r\n\r\n--\r\n\r\n<br class=\"Apple-interchange-newline\">\r\n - Any other relevant information:\r\n SLURM HPC Cluster, single node.\r\n\r\n### Additional context\r\nProblem appears after upgrading to 1.3.1 from 1.2.4. I believe it is related to the thought behind this SO post:\r\n\r\nhttps:\/\/stackoverflow.com\/questions\/66854148\/proper-way-to-log-things-when-using-pytorch-lightning-ddp",
        "Issue_answer_count":7,
        "Issue_self_closed":0.0,
        "Answer_body":"Hey @bw4sz,\r\n\r\nThanks for reporting this bug. While we investigate the source of bug, I think you could use this workaround in the meanwhile.\r\n\r\n`COMET_EXPERIMENT_KEY='something' python ...` and use it in your code ?\r\n\r\n```\r\n        comet_logger = CometLogger(\r\n            api_key=os.environ.get('COMET_API_KEY'),\r\n            workspace=os.environ.get('COMET_WORKSPACE'),  # Optional\r\n            save_dir='.',  # Optional\r\n            project_name='default_project',  # Optional\r\n            rest_api_key=os.environ.get('COMET_REST_API_KEY'),  # Optional\r\n            experiment_key=os.environ.get('COMET_EXPERIMENT_KEY'),  # Optional\r\n            experiment_name='default'  # Optional\r\n        )\r\n```\r\n\r\nBest,\r\nT.C Hi, I have a similar bug using wandb using a similar setup (slurm, ddp) This issue has been automatically marked as stale because it hasn't had any recent activity. This issue will be closed in 7 days if no further activity occurs. Thank you for your contributions, Pytorch Lightning Team!\n I've been investigating a bit with Wandb, and i only have the bug when using SLURM. When using ddp on a local machine, i don't have duplicated runs I have the same issue with MLFlow using SLURM. I also find this with comet_ml on SLURM. Tough to make a reproducible thing\nhere. maintainers, what can we do to move this forward?\n\nOn Thu, Aug 5, 2021 at 7:35 AM Andre Costa ***@***.***> wrote:\n\n> I have the same issue with MLFlow using SLURM.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/issues\/7599#issuecomment-893510320>,\n> or unsubscribe\n> <https:\/\/github.com\/notifications\/unsubscribe-auth\/AAJHBLC5WEF6ZMD5IYI4F4LT3KOSFANCNFSM45DLJZPA>\n> .\n> Triage notifications on the go with GitHub Mobile for iOS\n> <https:\/\/apps.apple.com\/app\/apple-store\/id1477376905?ct=notification-email&mt=8&pt=524675>\n> or Android\n> <https:\/\/play.google.com\/store\/apps\/details?id=com.github.android&utm_campaign=notification-email>\n> .\n>\n\n\n-- \nBen Weinstein, Ph.D.\nPostdoctoral Fellow\nUniversity of Florida\nhttp:\/\/benweinstein.weebly.com\/\n This issue has been automatically marked as stale because it hasn't had any recent activity. This issue will be closed in 7 days if no further activity occurs. Thank you for your contributions, Pytorch Lightning Team!\n",
        "Tool":"Comet",
        "Platform":"Github",
        "Issue_original_content":"upgrad caus pytorch logger produc multipl experi bug run ddp multi gpu experi slurm cluster pytorch lightn creat multipl experi gpu log metric sit experi main gpu actual log metric http www bwsz everglad view syqjplzxsbwvfgmojvbp run gpu announc log http www bwsz everglad dbdffbeabdbc reproduc boringmodel reproduc know reproduc exampl multi gpu ddp colab need authent past expect behavior singl experi singl trainer fit behavior lightn environ note bug code solv faster colab notebook public id us python bug report model http github com pytorchlightn pytorch lightn blob master exampl bug report model templat colab notebook copi past output environ collect script http raw githubusercont com pytorchlightn pytorch lightn master test collect env detail checklist manual script run wget http raw githubusercont com pytorchlightn pytorch lightn master test collect env detail secur purpos check content collect env detail run python collect env detail pytorch version torch pytorch lightn linux linux instal pytorch conda pip sourc pip build command compil sourc python version python cuda cudnn version gpu model configur geforc relev inform slurm hpc cluster singl node addit context problem appear upgrad believ relat thought post http stackoverflow com question proper wai log thing pytorch lightn ddp",
        "Issue_preprocessed_content":"upgrad caus pytorch produc multipl experi bug clear concis descript bug experi slurm cluster creat multipl experi gpu log metric sit img width alt shot img width alt shot experi main gpu log metric run gpu log reproduc boringmodel reproduc reproduc boringmodel think bug post know reproduc exampl colab authent past expect behavior singl experi singl behavior lightn environ note solv faster us python templat copi past output script run pytorch version linux pytorch pip build python version python version gpu model configur geforc relev inform slurm hpc cluster singl node context problem upgrad believ relat thought post",
        "Issue_gpt_summary_original":"The user is facing an issue with importing `CometLogger` due to a recent refactoring of logger imports. The `comet_ml` library needs to be imported before `torch` and `tensorboard` for it to work properly. However, since the refactoring, `torch` is now imported before `comet_ml` in `loggers\/comet.py`, which forces users to manually add an unused import for `comet_ml` before importing `CometLogger` to avoid the `ImportError`. The expected behavior is for the `comet_ml` import inside `loggers\/comet.py` to come before the `torch` import, even if it violates usual import ordering.",
        "Issue_gpt_summary":"user face issu import logger recent refactor logger import librari need import torch tensorboard work properli refactor torch import logger forc user manual add unus import import logger avoid importerror expect behavior import insid logger come torch import violat usual import order",
        "Issue_score_count":1
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning\/issues\/7021",
        "Issue_title":"CometLogger can modify logged metrics in-place ",
        "Issue_created_time":1618430187000,
        "Issue_closed_time":1630398077000,
        "Issue_body":"When `logger.log_metrics(metrics)` is called with a `CometLogger`, `metrics` may be modified in-place. This can lead to confusing errors. E.g. if the user does\r\n\r\n```python\r\ndef training_step(self, batch, batch_idx):\r\n    losses = self._get_losses(batch)\r\n    self.logger.log_metrics(losses)\r\n    return losses\r\n```\r\n\r\nthen `losses` will have all the tensors moved to the CPU and their gradients detached, leading to an error like `RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn` when backprop is attempted.\r\n\r\nNone of the other loggers change `metrics` in-place when `log_metrics` is called. All of them except neptune say that they just accept `metrics: Dict[str, float]`, though some others (e.g. the tensorboard logger) have code to handle `torch.Tensor`s or other types as well.\r\n\r\nThe `CSVLogger` uses the following for handling tensors:\r\n```python\r\ndef _handle_value(value):\r\n    if isinstance(value, torch.Tensor):\r\n        return value.item()\r\n    return value\r\n...\r\nmetrics = {k: _handle_value(v) for k, v in metrics_dict.items()}\r\n```\r\n\r\nThe `TensorBoardLogger` similarly has\r\n\r\n```python\r\nfor k, v in metrics.items():\r\n    if isinstance(v, torch.Tensor):\r\n        v = v.item()\r\n    ...\r\n    self.experiment.add_scalar(k, v, step)\r\n```\r\n\r\nIn the `CometLogger`, the current tensor conversion code is\r\n\r\n```python\r\nfor key, val in metrics.items():\r\n  if is_tensor(val):\r\n    metrics[key] = val.cpu().detach()\r\n```\r\n\r\nbut then the entire `metrics` dictionary is copied later in the function anyway, so it doesn't really make sense to do in-place modification then copy everything.\r\n\r\nI'm happy to submit a PR to fix this so that the `CometLogger` doesn't modify the original `metrics` dictionary. I just wanted to ask for a couple of opinions before changing things:\r\n\r\n1. Should I keep the current tensor conversion behavior for `CometLogger` (`val.cpu().detach()`) or switch to using `val.item()`? My preference would be the latter, though this does change the behavior (see at the end).\r\n2. Should I update the other loggers to all accept `metrics: Dict[str, Union[float, torch.Tensor]]` and have them all use the same method (probably imported from `loggers\/base.py`) to convert to a `Dict[str, float]`?\r\n3. * I don't know the other loggers, so I'm not sure if tensors are actually not supported or if the type annotation isn't precise and the conversion is happening in third-party code\r\n\r\n---\r\n\r\n`val.cpu().detach()` vs `val.item()`\r\n* Comet sort of has support for tensors with >1 element, so using the first method will make logging such tensors valid while the second method would throw an error. However, I don't think anybody would be using this behavior on purpose. If you do `logger.log_metrics({\"test\": torch.tensor([1.0, 10.0])})`, you get `COMET WARNING: Cannot safely convert array([ 1., 10.], dtype=float32) object to a scalar value, using its string representation for logging`. The metric itself doesn't even appear in the web interface for CometML, so I assume you can only access it if you query for it directly through their API.\r\n",
        "Issue_answer_count":10,
        "Issue_self_closed":0.0,
        "Answer_body":"PR on this is more than welcome! Great observation. Btw I believe we don't expect users to directly call `self.logger.log_metrics`, but we should still fix it :) \n\n\n> val.cpu().detach() vs val.item()\n\nDoes Comet accept scalar tensors? If it can do the tensor->Python conversion (why wouldn't it), I would go with `val.cpu().detach()` as in the other loggers. @neighthan still interested to send a fix for this?  This issue has been automatically marked as stale because it hasn't had any recent activity. This issue will be closed in 7 days if no further activity occurs. Thank you for your contributions, Pytorch Lightning Team!\n This issue has been automatically marked as stale because it hasn't had any recent activity. This issue will be closed in 7 days if no further activity occurs. Thank you for your contributions, Pytorch Lightning Team!\n Hi @awaelchli! I am new to open source contribution and since this is a good first issue, I would like to try my hand at it! Dear @sohamtiwari3120,\r\n\r\nYes, feel free to take on this one and open a PR.\r\n\r\nBest,\r\nT.C Hi @tchaton,\r\n\r\nCan you please review my PR. There are a few checks that failed and I am unable to determine the exact cause for the same.\r\n\r\nSincerely,\r\nSoham Hey @ sohamtiwari3120,\r\n\r\nApproved. Mind adding a test to prevent regression ?\r\n\r\nBest,\r\nT.C Hi @tchaton \r\n\r\nI would love to try! However, it would be my first time writing tests. Therefore could you please help me with the following:\r\n- can you explain how will the test to prevent regression look like,\r\n- also could you provide any references useful for beginners in writing tests.\r\n\r\nSincerely,\r\nSoham Dear @sohamtiwari3120,\r\n\r\nCheck out this document: https:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/blob\/master\/.github\/CONTRIBUTING.md\r\n\r\nIn this case, the test should ensure the values aren't modified the logged metrics owned by the trainer.\r\n\r\nBest,\r\nT.C",
        "Tool":"Comet",
        "Platform":"Github",
        "Issue_original_content":"logger modifi log metric place logger log metric metric call logger metric modifi place lead confus error user python def train step self batch batch idx loss self loss batch self logger log metric loss return loss loss tensor move cpu gradient detach lead error like runtimeerror element tensor requir grad grad backprop attempt logger chang metric place log metric call accept metric dict str float tensorboard logger code handl torch tensor type csvlogger us follow handl tensor python def handl valu valu isinst valu torch tensor return valu item return valu metric handl valu metric dict item tensorboardlogg similarli python metric item isinst torch tensor item self experi add scalar step logger current tensor convers code python kei val metric item tensor val metric kei val cpu detach entir metric dictionari copi later function sens place modif copi happi submit fix logger modifi origin metric dictionari want ask coupl opinion chang thing current tensor convers behavior logger val cpu detach switch val item prefer chang behavior end updat logger accept metric dict str union float torch tensor us method probabl import logger base convert dict str float know logger sure tensor actual support type annot isn precis convers happen parti code val cpu detach val item sort support tensor element method log tensor valid second method throw error think anybodi behavior purpos logger log metric test torch tensor warn safe convert arrai dtype float object scalar valu string represent log metric appear web interfac assum access queri directli api",
        "Issue_preprocessed_content":"modifi metric modifi lead confus user tensor move cpu gradient detach lead like backprop chang code handl type us handl tensor similarli tensor convers code entir dictionari copi later function sens modif copi submit fix modifi origin dictionari want ask coupl opinion chang thing tensor convers behavior detach prefer chang behavior updat us method convert know sure tensor type isn precis convers code sort tensor element method tensor valid second method throw think anybodi behavior purpos metric web interfac queri directli api",
        "Issue_gpt_summary_original":"The user has encountered a bug in the logger behavior of PyTorchLightning after a recent update. The logger starts using `COMET_EXPERIMENT_KEY` but does not respect it if it is already set. The logger overwrites the user's value, deletes the variable, and ignores the set variable in the version function. The user plans to create a pull request to fix the issue.",
        "Issue_gpt_summary":"user encount bug logger behavior pytorchlightn recent updat logger start experi kei respect set logger overwrit user valu delet variabl ignor set variabl version function user plan creat pull request fix issu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning\/issues\/5829",
        "Issue_title":"Must manually import `comet_ml` before `CometLogger` to avoid import error",
        "Issue_created_time":1612502289000,
        "Issue_closed_time":1615221269000,
        "Issue_body":"## \ud83d\udc1b Bug\r\nA few weeks ago, a [refactoring of logger imports](https:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/commit\/ec0fb7a3ec709699243c76dae04ee1e4ce2406a0#diff-7a041199139ffcca72689f9a15f47657330ff9d3206a46103e7a061a5fe2bc09) changed the ordering of imports for the `CometLogger`. However, comet requires for `comet_ml` to be imported before some other dependencies, i.e. torch and tensorboard, to work properly. If not, you get the following error:\r\n```\r\nImportError: You must import Comet before these modules: torch, tensorboard\r\n```\r\n\r\nBefore the imports reordering, comet's import requirements could be met by importing `CometLogger` before torch and tensorboard. However, since the refactoring, torch is now imported before comet in `loggers\/comet.py` itself. This forces users to manually add an unused import for `comet_ml` before importing `CometLogger` to avoid the above `ImportError`.\r\n\r\n### To Reproduce\r\nThis [**BoringModel**](https:\/\/colab.research.google.com\/drive\/1u7vE02v40RCebEXg1515KMuCxvelAcNF?usp=sharing) example reproduces the `ImportError`.\r\n\r\n### Expected behavior\r\nUsers should not have to manually import `comet_ml` before `CometLogger` to avoid triggering the `ImportError`. The `comet_ml` import inside `loggers\/comet.py` should exceptionally come before the `torch` import, even if it violates usual import ordering.",
        "Issue_answer_count":6,
        "Issue_self_closed":1.0,
        "Answer_body":"Thanks for the report! Mind sending a PR to fix this? cc @Borda  Sorry for the long delay in getting back to you on this issue. I tried to fix it by manually rearranging the imports, with the relevant annotations so that this manual placement would be ignored by `isort`. However, I can't seem to be able to make it work like it used to.\r\n\r\nIn the end, I think it might be better to solve this issue elsewhere for me, either in my own code or upstream with Comet to see if they can improve on their requirement of being imported first. Seems like a pain to solve this.\r\n@nathanpainchaud You can set a env variable `COMET_DISABLE_AUTO_LOGGING=1`, not sure how much it helps or what side effects it has. \r\nJust saw it in the docs [here](https:\/\/www.comet.ml\/docs\/python-sdk\/warnings-errors\/). @awaelchli Thanks for the link! I've not yet tried to disable Comet auto-logging, since I'm a bit fearful about the logging capabilities I might lose.\r\n\r\nI first created the issue here because I thought it might be solved easily by simply reordering the imports in Lightning, but I'm fully aware that would only cover up the symptoms, and not treat the underlying issue. I think the best solution, even if it's ugly IMO, is to manually import Comet at the very beginning of my main script.\r\n\r\nA more permanent resolution to the issue, if possible, should come from upstream. Therefore, I'm closing the issue here, but if anyone as a better idea on how to resolve this issue, they're welcome to re-open it :slightly_smiling_face:  So I have something to add to this which is very strange. I usually run my experiments on a slurm cluster, I just found that when I launch through sbatch I don't get this error, but when I use srun to get a terminal on a node to do some debugging I do get the error. I have no idea why they would be different.",
        "Tool":"Comet",
        "Platform":"Github",
        "Issue_original_content":"manual import logger avoid import error bug week ago refactor logger import http github com pytorchlightn pytorch lightn commit ecfbaeccdaeeeecea diff affccafafffdaeaafebc chang order import logger requir import depend torch tensorboard work properli follow error importerror import modul torch tensorboard import reorder import requir met import logger torch tensorboard refactor torch import logger forc user manual add unus import import logger avoid importerror reproduc boringmodel http colab research googl com drive uvevrcebexgkmucxvelacnf usp share exampl reproduc importerror expect behavior user manual import logger avoid trigger importerror import insid logger exception come torch import violat usual import order",
        "Issue_preprocessed_content":"import avoid import bug ago chang order import requir import depend torch tensorboard work properli import reorder import requir met import torch tensorboard refactor torch import forc user unus import import avoid reproduc exampl reproduc expect behavior user import avoid import insid come import violat usual import order",
        "Issue_gpt_summary_original":"The user is encountering an error with CometLogger when using an API key without a save directory. The error occurs because the train loop tries to read the save directory, which is not set. The issue can be resolved by setting the save directory to None.",
        "Issue_gpt_summary":"user encount error logger api kei save directori error occur train loop tri read save directori set issu resolv set save directori",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning\/issues\/4229",
        "Issue_title":"Comet logger overrides COMET_EXPERIMENT_KEY env variable",
        "Issue_created_time":1603104554000,
        "Issue_closed_time":1603809056000,
        "Issue_body":"After https:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/pull\/2553  there is a changed logger behavior. It starts using `COMET_EXPERIMENT_KEY`. But it doesn't respect it if it is set already.\r\nSo the bug is in the following.\r\nI already set this variable \r\nThen logger overwrites my value here https:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/blob\/master\/pytorch_lightning\/loggers\/comet.py#L189\r\nThen it deletes this variable at all here https:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/blob\/master\/pytorch_lightning\/loggers\/comet.py#L215\r\nThis way it ignores my variable and deletes it at all later\r\nMoreover in version function it also ignores my set variable\r\nI will create a pull request to fix it ",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"Comet",
        "Platform":"Github",
        "Issue_original_content":"logger overrid experi kei env variabl http github com pytorchlightn pytorch lightn pull chang logger behavior start experi kei respect set bug follow set variabl logger overwrit valu http github com pytorchlightn pytorch lightn blob master pytorch lightn logger delet variabl http github com pytorchlightn pytorch lightn blob master pytorch lightn logger wai ignor variabl delet later version function ignor set variabl creat pull request fix",
        "Issue_preprocessed_content":"env variabl chang behavior start respect set bug set variabl overwrit valu delet variabl wai ignor variabl delet later version function ignor set variabl creat request fix",
        "Issue_gpt_summary_original":"The user is encountering an error while running on ddp mode with comet logger. The error message indicates that the local object 'SummaryTopic' cannot be pickled, resulting in an AttributeError. The code runs when the logger is detached from the trainer.",
        "Issue_gpt_summary":"user encount error run ddp mode logger error messag indic local object summarytop pickl result attributeerror code run logger detach trainer",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning\/issues\/3417",
        "Issue_title":"CometLogger failing without save_dir",
        "Issue_created_time":1599655027000,
        "Issue_closed_time":1599658056000,
        "Issue_body":"<!-- \r\n### Common bugs:\r\n1. Tensorboard not showing in Jupyter-notebook see [issue 79](https:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/issues\/79).    \r\n2. PyTorch 1.1.0 vs 1.2.0 support [see FAQ](https:\/\/github.com\/PyTorchLightning\/pytorch-lightning#faq)    \r\n-->\r\n\r\n## \ud83d\udc1b Bug\r\n\r\nCometmllogger with api key and  without save dir results in error.\r\nThis happens due to this if https:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/blob\/master\/pytorch_lightning\/loggers\/comet.py#L135\r\n_save_dir is not set and later train loop tries to read it and fails.\r\nThis can be fixed by setting _save_dir to None. I will supply PR in a moment\r\n\r\n### To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n```\r\n    model = LightningModel({})\r\n    comet_logger = CometLogger(\r\n        api_key=KEY,\r\n        workspace=\"workspace\"\r\n    )\r\n\r\n    trainer = Trainer(logger=comet_logger)\r\n    trainer.fit(model)\r\n```\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n\r\n\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n\r\nTraceback (most recent call last):\r\ntrainer.fit(model)\r\nFile \"\/python3.8\/site-packages\/pytorch_lightning\/trainer\/states.py\", line 48, in wrapped_fn\r\nresult = fn(self, *args, **kwargs)\r\nFile \"\/python3.8\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 1073, in fit\r\nresults = self.accelerator_backend.train(model)\r\nFile \"\/python3.8\/site-packages\/pytorch_lightning\/accelerators\/gpu_backend.py\", line 51, in train\r\nresults = self.trainer.run_pretrain_routine(model)\r\nFile \"\/python3.8\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 1239, in run_pretrain_routine\r\nself.train()\r\nFile \"\/python3.8\/site-packages\/pytorch_lightning\/trainer\/training_loop.py\", line 363, in train\r\nself.on_train_start()\r\nFile \"\/python3.8\/site-packages\/pytorch_lightning\/trainer\/callback_hook.py\", line 111, in on_train_start\r\ncallback.on_train_start(self, self.get_model())\r\nFile \"\/python3.8\/site-packages\/pytorch_lightning\/utilities\/distributed.py\", line 27, in wrapped_fn\r\nreturn fn(*args, **kwargs)\r\nFile \"\/python3.8\/site-packages\/pytorch_lightning\/callbacks\/model_checkpoint.py\", line 296, in on_train_start\r\nsave_dir = trainer.logger.save_dir or trainer.default_root_dir\r\nFile \"\/python3.8\/site-packages\/pytorch_lightning\/loggers\/comet.py\", line 253, in save_dir\r\nreturn self._save_dir\r\n\r\n### Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"Hi! thanks for your contribution!, great first issue!",
        "Tool":"Comet",
        "Platform":"Github",
        "Issue_original_content":"logger fail save dir bug mllogger api kei save dir result error happen http github com pytorchlightn pytorch lightn blob master pytorch lightn logger save dir set later train loop tri read fail fix set save dir suppli moment reproduc step reproduc behavior model lightningmodel logger logger api kei kei workspac workspac trainer trainer logger logger trainer fit model traceback recent trainer fit model file python site packag pytorch lightn trainer state line wrap result self arg kwarg file python site packag pytorch lightn trainer trainer line fit result self acceler backend train model file python site packag pytorch lightn acceler gpu backend line train result self trainer run pretrain routin model file python site packag pytorch lightn trainer trainer line run pretrain routin self train file python site packag pytorch lightn trainer train loop line train self train start file python site packag pytorch lightn trainer callback hook line train start callback train start self self model file python site packag pytorch lightn util distribut line wrap return arg kwarg file python site packag pytorch lightn callback model checkpoint line train start save dir trainer logger save dir trainer default root dir file python site packag pytorch lightn logger line save dir return self save dir addit context",
        "Issue_preprocessed_content":"fail bug api kei save dir result set later train tri read fail fix moment reproduc step reproduc behavior code sampl stack trace provid clear concis descript expect traceback file line result file line fit result file line train result file line file line train file line file line return file line file line return context context problem",
        "Issue_gpt_summary_original":"The user is encountering an issue where the Comet logger cannot be pickled after an experiment has been created. Initializing the logger object and Trainer object with the logger works fine, but accessing the experiment attribute which creates the OfflineExperiment object fails. The expected behavior is to be able to pickle loggers for distributed training. The user is using pytorch-lightning version 0.7.5 and Python version 3.7.6 on a Darwin system.",
        "Issue_gpt_summary":"user encount issu logger pickl experi creat initi logger object trainer object logger work fine access experi attribut creat offlineexperi object fail expect behavior abl pickl logger distribut train user pytorch lightn version python version darwin",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning\/issues\/1704",
        "Issue_title":"Error running on ddp (can't pickle local object 'SummaryTopic) with comet logger",
        "Issue_created_time":1588434434000,
        "Issue_closed_time":1591023634000,
        "Issue_body":"I have the following problem running on ddp mode with cometlogger.\r\nWhen I detach the logger from the trainer (i.e deleting`logger=comet_logger`) the code runs.\r\n```\r\nException has occurred: AttributeError\r\nCan't pickle local object 'SummaryTopic.__init__.<locals>.default'\r\n  File \"\/path\/multiprocessing\/reduction.py\", line 60, in dump\r\n    ForkingPickler(file, protocol).dump(obj)\r\n  File \"\/path\/multiprocessing\/popen_spawn_posix.py\", line 47, in _launch\r\n    reduction.dump(process_obj, fp)\r\n  File \"\/path\/multiprocessing\/popen_fork.py\", line 20, in __init__\r\n    self._launch(process_obj)\r\n  File \"\/path\/multiprocessing\/popen_spawn_posix.py\", line 32, in __init__\r\n    super().__init__(process_obj)\r\n  File \"\/path\/multiprocessing\/context.py\", line 284, in _Popen\r\n    return Popen(process_obj)\r\n  File \"\/path\/multiprocessing\/process.py\", line 112, in start\r\n    self._popen = self._Popen(self)\r\n  File \"\/path\/site-packages\/torch\/multiprocessing\/spawn.py\", line 162, in spawn\r\n    process.start()\r\n  File \"\/path\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 751, in fit\r\n    mp.spawn(self.ddp_train, nprocs=self.num_processes, args=(model,))\r\n  File \"\/repo_path\/train.py\", line 158, in main_train\r\n    trainer.fit(model)\r\n  File \"\/repo_path\/train.py\", line 72, in main\r\n    main_train(model_class_pointer, hyperparams, logger)\r\n  File \"\/repo_path\/train.py\", line 167, in <module>\r\n    main()\r\n  File \"\/path\/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"\/path\/runpy.py\", line 96, in _run_module_code\r\n    mod_name, mod_spec, pkg_name, script_name)\r\n  File \"\/path\/runpy.py\", line 263, in run_path\r\n    pkg_name=pkg_name, script_name=fname)\r\n  File \"\/path\/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"\/path\/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n```",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"@ceyzaguirre4 pls ^^",
        "Tool":"Comet",
        "Platform":"Github",
        "Issue_original_content":"error run ddp pickl local object summarytop logger follow problem run ddp mode logger detach logger trainer delet logger logger code run except occur attributeerror pickl local object summarytop init default file path multiprocess reduct line dump forkingpickl file protocol dump obj file path multiprocess popen spawn posix line launch reduct dump process obj file path multiprocess popen fork line init self launch process obj file path multiprocess popen spawn posix line init super init process obj file path multiprocess context line popen return popen process obj file path multiprocess process line start self popen self popen self file path site packag torch multiprocess spawn line spawn process start file path site packag pytorch lightn trainer trainer line fit spawn self ddp train nproc self num process arg model file repo path train line main train trainer fit model file repo path train line main main train model class pointer hyperparam logger file repo path train line main file path runpi line run code exec code run global file path runpi line run modul code mod mod spec pkg script file path runpi line run path pkg pkg script fname file path runpi line run code exec code run global file path runpi line run modul main main mod spec",
        "Issue_preprocessed_content":" problem mode detach trainer code run",
        "Issue_gpt_summary_original":"The user is facing an issue where test metrics are no longer being pushed to Comet.ML and possibly other logging destinations after updating to PyTorch Lightning 0.7.2. The issue can be reproduced by running a fast-run of training. The user has provided the environment details for reference.",
        "Issue_gpt_summary":"user face issu test metric longer push possibl log destin updat pytorch lightn issu reproduc run fast run train user provid environ detail refer",
        "Issue_score_count":6
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning\/issues\/1682",
        "Issue_title":"Comet logger cannot be pickled after creating an experiment",
        "Issue_created_time":1588303817000,
        "Issue_closed_time":1591023635000,
        "Issue_body":"## \ud83d\udc1b Bug \r\n\r\nThe Comet logger cannot be pickled after an experiment (at least an OfflineExperiment) has been created.\r\n\r\n### To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n\r\ninitialize the logger object (works fine)\r\n```\r\nfrom pytorch_lightning.loggers import CometLogger\r\nimport tests.base.utils as tutils\r\nfrom pytorch_lightning import Trainer\r\nimport pickle\r\n\r\nmodel, _ = tutils.get_default_model()\r\nlogger = CometLogger(save_dir='test')\r\npickle.dumps(logger)\r\n```\r\n\r\ninitialize a Trainer object with the logger (works fine)\r\n```\r\ntrainer = Trainer(\r\n    max_epochs=1,\r\n    logger=logger\r\n)\r\npickle.dumps(logger)\r\npickle.dumps(trainer)\r\n```\r\n\r\naccess the `experiment` attribute which creates the OfflineExperiment object (fails)\r\n```\r\nlogger.experiment\r\npickle.dumps(logger)\r\n>> TypeError: can't pickle _thread.lock objects\r\n```\r\n\r\n### Expected behavior\r\n\r\nWe should be able to pickle loggers for distributed training.\r\n\r\n### Environment\r\n\r\n* CUDA:\r\n        - GPU:\r\n        - available:         False\r\n        - version:           None\r\n* Packages:\r\n        - numpy:             1.18.1\r\n        - pyTorch_debug:     False\r\n        - pyTorch_version:   1.4.0\r\n        - pytorch-lightning: 0.7.5\r\n        - tensorboard:       2.1.0\r\n        - tqdm:              4.42.0\r\n* System:\r\n        - OS:                Darwin\r\n        - architecture:\r\n                - 64bit\r\n                - \r\n        - processor:         i386\r\n        - python:            3.7.6\r\n        - version:           Darwin Kernel Version 19.3.0: Thu Jan  9 20:58:23 PST 2020; root:xnu-6153.81.5~1\/RELEASE_X86_64\r\n\r\n",
        "Issue_answer_count":11,
        "Issue_self_closed":0.0,
        "Answer_body":"@ceyzaguirre4 pls ^^ I don't know if it can help or if it is the right place, but a similar error occurswhen running in ddp mode with the WandB logger.\r\n\r\nWandB uses a lambda function at some point.\r\n\r\nDoes the logger have to pickled ? Couldn't it log only on rank 0 at epoch_end ?\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"..\/train.py\", line 140, in <module>\r\n    main(args.gpus, args.nodes, args.fast_dev_run, args.mixed_precision, project_config, hparams)\r\n  File \"..\/train.py\", line 117, in main\r\n    trainer.fit(model)\r\n  File \"\/home\/clear\/fbartocc\/miniconda3\/envs\/Depth_env\/lib\/python3.8\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 751, in fit\r\n    mp.spawn(self.ddp_train, nprocs=self.num_processes, args=(model,))\r\n  File \"\/home\/clear\/fbartocc\/miniconda3\/envs\/Depth_env\/lib\/python3.8\/site-packages\/torch\/multiprocessing\/spawn.py\", line 200, in spawn\r\n    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\r\n  File \"\/home\/clear\/fbartocc\/miniconda3\/envs\/Depth_env\/lib\/python3.8\/site-packages\/torch\/multiprocessing\/spawn.py\", line 149, in start_processes\r\n    process.start()\r\n  File \"\/home\/clear\/fbartocc\/miniconda3\/envs\/Depth_env\/lib\/python3.8\/multiprocessing\/process.py\", line 121, in start\r\n    self._popen = self._Popen(self)\r\n  File \"\/home\/clear\/fbartocc\/miniconda3\/envs\/Depth_env\/lib\/python3.8\/multiprocessing\/context.py\", line 283, in _Popen\r\n    return Popen(process_obj)\r\n  File \"\/home\/clear\/fbartocc\/miniconda3\/envs\/Depth_env\/lib\/python3.8\/multiprocessing\/popen_spawn_posix.py\", line 32, in __init__\r\n    super().__init__(process_obj)\r\n  File \"\/home\/clear\/fbartocc\/miniconda3\/envs\/Depth_env\/lib\/python3.8\/multiprocessing\/popen_fork.py\", line 19, in __init__\r\n    self._launch(process_obj)\r\n  File \"\/home\/clear\/fbartocc\/miniconda3\/envs\/Depth_env\/lib\/python3.8\/multiprocessing\/popen_spawn_posix.py\", line 47, in _launch\r\n    reduction.dump(process_obj, fp)\r\n  File \"\/home\/clear\/fbartocc\/miniconda3\/envs\/Depth_env\/lib\/python3.8\/multiprocessing\/reduction.py\", line 60, in dump\r\n    ForkingPickler(file, protocol).dump(obj)\r\nAttributeError: Can't pickle local object 'TorchHistory.add_log_hooks_to_pytorch_module.<locals>.<lambda>'\r\n```\r\n\r\nalso related: \r\n#1704 I had the same error as @jeremyjordan  `can't pickle _thread.lock objects`. This happened when I added the  `logger` and additional `callbacks` in `from_argparse_args`, as explained here https:\/\/pytorch-lightning.readthedocs.io\/en\/latest\/hyperparameters.html\r\n\r\n```\r\ntrainer = pl.Trainer.from_argparse_args(hparams, logger=logger, callbacks=[PrinterCallback(), ])\r\n```\r\nI could make the problem go away by directly overwriting the members of `Trainer`\r\n\r\n```\r\ntrainer = pl.Trainer.from_argparse_args(hparams)\r\ntrainer.logger = logger\r\ntrainer.callbacks.append(PrinterCallback())\r\n``` Same issue as @F-Barto using a wandb logger across 2 nodes with `ddp`. same issue when using wandb logger with ddp same here.. @joseluisvaz your workaround doesn't solve the callback issue.. when I try to add a callback like this it is simply being ignored :\/ but adding it the Trainer init call normally works.. so I'm pretty sure the error is thrown by the logger (I'm using TB) not the callbacks. Same issue, using wandb logger with 8 gpus in an AWS p2.8xlarge machine  With CometLogger, I get this error only when the experiment name is declared. If it is not declared, I get no issue. I still have this error with 1.5.10 on macOS\r\n\r\n```\r\nError executing job with overrides: ['train.pl_trainer.fast_dev_run=False', 'train.pl_trainer.gpus=0', 'train.pl_trainer.precision=32', 'logging.wandb_arg.mode=offline']\r\nTraceback (most recent call last):\r\n  File \"\/Users\/ric\/Documents\/PhD\/Projects\/ed-experiments\/src\/train.py\", line 78, in main\r\n    train(conf)\r\n  File \"\/Users\/ric\/Documents\/PhD\/Projects\/ed-experiments\/src\/train.py\", line 70, in train\r\n    trainer.fit(pl_module, datamodule=pl_data_module)\r\n  File \"\/Users\/ric\/mambaforge\/envs\/ed\/lib\/python3.9\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 740, in fit\r\n    self._call_and_handle_interrupt(\r\n  File \"\/Users\/ric\/mambaforge\/envs\/ed\/lib\/python3.9\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 685, in _call_and_handle_interrupt\r\n    return trainer_fn(*args, **kwargs)\r\n  File \"\/Users\/ric\/mambaforge\/envs\/ed\/lib\/python3.9\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 777, in _fit_impl\r\n    self._run(model, ckpt_path=ckpt_path)\r\n  File \"\/Users\/ric\/mambaforge\/envs\/ed\/lib\/python3.9\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 1199, in _run\r\n    self._dispatch()\r\n  File \"\/Users\/ric\/mambaforge\/envs\/ed\/lib\/python3.9\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 1279, in _dispatch\r\n    self.training_type_plugin.start_training(self)\r\n  File \"\/Users\/ric\/mambaforge\/envs\/ed\/lib\/python3.9\/site-packages\/pytorch_lightning\/plugins\/training_type\/training_type_plugin.py\", line 202, in start_training\r\n    self._results = trainer.run_stage()\r\n  File \"\/Users\/ric\/mambaforge\/envs\/ed\/lib\/python3.9\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 1289, in run_stage\r\n    return self._run_train()\r\n  File \"\/Users\/ric\/mambaforge\/envs\/ed\/lib\/python3.9\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 1311, in _run_train\r\n    self._run_sanity_check(self.lightning_module)\r\n  File \"\/Users\/ric\/mambaforge\/envs\/ed\/lib\/python3.9\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 1375, in _run_sanity_check\r\n    self._evaluation_loop.run()\r\n  File \"\/Users\/ric\/mambaforge\/envs\/ed\/lib\/python3.9\/site-packages\/pytorch_lightning\/loops\/base.py\", line 145, in run\r\n    self.advance(*args, **kwargs)\r\n  File \"\/Users\/ric\/mambaforge\/envs\/ed\/lib\/python3.9\/site-packages\/pytorch_lightning\/loops\/dataloader\/evaluation_loop.py\", line 110, in advance\r\n    dl_outputs = self.epoch_loop.run(dataloader, dataloader_idx, dl_max_batches, self.num_dataloaders)\r\n  File \"\/Users\/ric\/mambaforge\/envs\/ed\/lib\/python3.9\/site-packages\/pytorch_lightning\/loops\/base.py\", line 140, in run\r\n    self.on_run_start(*args, **kwargs)\r\n  File \"\/Users\/ric\/mambaforge\/envs\/ed\/lib\/python3.9\/site-packages\/pytorch_lightning\/loops\/epoch\/evaluation_epoch_loop.py\", line 86, in on_run_start\r\n    self._dataloader_iter = _update_dataloader_iter(data_fetcher, self.batch_progress.current.ready)\r\n  File \"\/Users\/ric\/mambaforge\/envs\/ed\/lib\/python3.9\/site-packages\/pytorch_lightning\/loops\/utilities.py\", line 121, in _update_dataloader_iter\r\n    dataloader_iter = enumerate(data_fetcher, batch_idx)\r\n  File \"\/Users\/ric\/mambaforge\/envs\/ed\/lib\/python3.9\/site-packages\/pytorch_lightning\/utilities\/fetching.py\", line 198, in __iter__\r\n    self._apply_patch()\r\n  File \"\/Users\/ric\/mambaforge\/envs\/ed\/lib\/python3.9\/site-packages\/pytorch_lightning\/utilities\/fetching.py\", line 133, in _apply_patch\r\n    apply_to_collections(self.loaders, self.loader_iters, (Iterator, DataLoader), _apply_patch_fn)\r\n  File \"\/Users\/ric\/mambaforge\/envs\/ed\/lib\/python3.9\/site-packages\/pytorch_lightning\/utilities\/fetching.py\", line 181, in loader_iters\r\n    loader_iters = self.dataloader_iter.loader_iters\r\n  File \"\/Users\/ric\/mambaforge\/envs\/ed\/lib\/python3.9\/site-packages\/pytorch_lightning\/trainer\/supporters.py\", line 537, in loader_iters\r\n    self._loader_iters = self.create_loader_iters(self.loaders)\r\n  File \"\/Users\/ric\/mambaforge\/envs\/ed\/lib\/python3.9\/site-packages\/pytorch_lightning\/trainer\/supporters.py\", line 577, in create_loader_iters\r\n    return apply_to_collection(loaders, Iterable, iter, wrong_dtype=(Sequence, Mapping))\r\n  File \"\/Users\/ric\/mambaforge\/envs\/ed\/lib\/python3.9\/site-packages\/pytorch_lightning\/utilities\/apply_func.py\", line 104, in apply_to_collection\r\n    v = apply_to_collection(\r\n  File \"\/Users\/ric\/mambaforge\/envs\/ed\/lib\/python3.9\/site-packages\/pytorch_lightning\/utilities\/apply_func.py\", line 96, in apply_to_collection\r\n    return function(data, *args, **kwargs)\r\n  File \"\/Users\/ric\/mambaforge\/envs\/ed\/lib\/python3.9\/site-packages\/pytorch_lightning\/trainer\/supporters.py\", line 177, in __iter__\r\n    self._loader_iter = iter(self.loader)\r\n  File \"\/Users\/ric\/mambaforge\/envs\/ed\/lib\/python3.9\/site-packages\/torch\/utils\/data\/dataloader.py\", line 359, in __iter__\r\n    return self._get_iterator()\r\n  File \"\/Users\/ric\/mambaforge\/envs\/ed\/lib\/python3.9\/site-packages\/torch\/utils\/data\/dataloader.py\", line 305, in _get_iterator\r\n    return _MultiProcessingDataLoaderIter(self)\r\n  File \"\/Users\/ric\/mambaforge\/envs\/ed\/lib\/python3.9\/site-packages\/torch\/utils\/data\/dataloader.py\", line 918, in __init__\r\n    w.start()\r\n  File \"\/Users\/ric\/mambaforge\/envs\/ed\/lib\/python3.9\/multiprocessing\/process.py\", line 121, in start\r\n    self._popen = self._Popen(self)\r\n  File \"\/Users\/ric\/mambaforge\/envs\/ed\/lib\/python3.9\/multiprocessing\/context.py\", line 224, in _Popen\r\n    return _default_context.get_context().Process._Popen(process_obj)\r\n  File \"\/Users\/ric\/mambaforge\/envs\/ed\/lib\/python3.9\/multiprocessing\/context.py\", line 284, in _Popen\r\n    return Popen(process_obj)\r\n  File \"\/Users\/ric\/mambaforge\/envs\/ed\/lib\/python3.9\/multiprocessing\/popen_spawn_posix.py\", line 32, in __init__\r\n    super().__init__(process_obj)\r\n  File \"\/Users\/ric\/mambaforge\/envs\/ed\/lib\/python3.9\/multiprocessing\/popen_fork.py\", line 19, in __init__\r\n    self._launch(process_obj)\r\n  File \"\/Users\/ric\/mambaforge\/envs\/ed\/lib\/python3.9\/multiprocessing\/popen_spawn_posix.py\", line 47, in _launch\r\n    reduction.dump(process_obj, fp)\r\n  File \"\/Users\/ric\/mambaforge\/envs\/ed\/lib\/python3.9\/multiprocessing\/reduction.py\", line 60, in dump\r\n    ForkingPickler(file, protocol).dump(obj)\r\nAttributeError: Can't pickle local object 'TorchHistory.add_log_hooks_to_pytorch_module.<locals>.<lambda>'\r\n``` I still see this bug as well with WandB logger. Currently having this issue with wandbLogger.",
        "Tool":"Comet",
        "Platform":"Github",
        "Issue_original_content":"logger pickl creat experi bug logger pickl experi offlineexperi creat reproduc step reproduc behavior initi logger object work fine pytorch lightn logger import logger import test base util tutil pytorch lightn import trainer import pickl model tutil default model logger logger save dir test pickl dump logger initi trainer object logger work fine trainer trainer max epoch logger logger pickl dump logger pickl dump trainer access experi attribut creat offlineexperi object fail logger experi pickl dump logger typeerror pickl thread lock object expect behavior abl pickl logger distribut train environ cuda gpu avail fals version packag numpi pytorch debug fals pytorch version pytorch lightn tensorboard tqdm darwin architectur bit processor python version darwin kernel version thu jan pst root xnu releas",
        "Issue_preprocessed_content":"pickl creat experi bug pickl experi creat reproduc step reproduc behavior initi object initi trainer object creat object expect behavior abl pickl distribut train environ cuda gpu avail fals version packag numpi fals tensorboard tqdm darwin architectur bit python version darwin kernel version thu jan pst",
        "Issue_gpt_summary_original":"The user is facing an issue where test metrics are not being logged to Comet after training a model using `Trainer.fit` and then testing it using `Trainer.test`. The metrics are logged correctly during training but not during testing. The user suspects that the issue is caused by `logger.finalize(\"success\")` being called at the end of the training routine, which in turn calls `experiment.end()` inside the logger, causing the `Experiment` object to not expect any more information. The user suggests creating another `Trainer` object with another logger as a workaround, but this would log the metrics into a different Comet experiment from the original.",
        "Issue_gpt_summary":"user face issu test metric log train model trainer fit test trainer test metric log correctli train test user suspect issu caus logger final success call end train routin turn call experi end insid logger caus experi object expect inform user suggest creat trainer object logger workaround log metric differ experi origin",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning\/issues\/1460",
        "Issue_title":"Test metrics are no longer pushed to Comet.ML (and perhaps others)",
        "Issue_created_time":1586647457000,
        "Issue_closed_time":1586910754000,
        "Issue_body":"## \ud83d\udc1b Bug\r\n\r\nPyTorch Lightning 0.7.2 used to publish test metrics to Comet.ML.  Commit https:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/commit\/ddbf7de6dc97924de07331f1575ee0b37cb7f7aa has broken this functionality.\r\n\r\n### To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\nRun fast-run of training and observe test metrics not being submitted to Comet.ML (and possibly other logging destinations).\r\n\r\n### Environment\r\n\r\n```\r\ncuda:\r\n        GPU:\r\n                Tesla T4\r\n        available:           True\r\n        version:             10.1\r\npackages:\r\n        numpy:               1.17.2\r\n        pyTorch_debug:       False\r\n        pyTorch_version:     1.4.0\r\n        pytorch-lightning:   0.7.4-dev\r\n        tensorboard:         2.2.0\r\n        tqdm:                4.45.0\r\nsystem:\r\n        OS:                  Linux\r\n        architecture:\r\n                64bit\r\n\r\n        processor:           x86_64\r\n        python:              3.6.8\r\n        version:             #69-Ubuntu SMP Thu Mar 26 02:17:29 UTC 2020\r\n```\r\n\r\ncc @alexeykarnachev",
        "Issue_answer_count":6,
        "Issue_self_closed":0.0,
        "Answer_body":"Hi! thanks for your contribution!, great first issue! @PyTorchLightning\/core-contributors or @alsrgv mind submitting a PR? good catch! Happy to, but I could use some pointers into what may be broken.  Does logging use aggregation with flush in the end, and that flush is somehow not called for the test pass?  @alexeykarnachev, any ideas? Shall be fixed in #1459 Sorry, guys, totally missed the messages.\r\n@Borda , is anything required from my end? I think it is fine, just if you have an idea why the Github Actions fails\/hangs...\r\nhttps:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/pull\/1459\/checks?check_run_id=584135478",
        "Tool":"Comet",
        "Platform":"Github",
        "Issue_original_content":"test metric longer push bug pytorch lightn publish test metric commit http github com pytorchlightn pytorch lightn commit ddbfdedcdefeebcbfaa broken function reproduc step reproduc behavior run fast run train observ test metric submit possibl log destin environ cuda gpu tesla avail true version packag numpi pytorch debug fals pytorch version pytorch lightn dev tensorboard tqdm linux architectur bit processor python version ubuntu smp thu mar utc alexeykarnachev",
        "Issue_preprocessed_content":"test metric longer push bug pytorch lightn publish test metric broken function reproduc step reproduc behavior run train observ test metric environ",
        "Issue_gpt_summary_original":"The user is encountering a warning message related to the use of the deprecated Comet API logger, comet_ml.papi, instead of the newer comet_ml.api. The warning suggests using the updated API and provides a link for more information.",
        "Issue_gpt_summary":"user encount warn messag relat us deprec api logger papi instead newer api warn suggest updat api provid link inform",
        "Issue_score_count":2
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning\/issues\/760",
        "Issue_title":"Test metrics not logging to Comet after training",
        "Issue_created_time":1580225794000,
        "Issue_closed_time":1582760093000,
        "Issue_body":"## \ud83d\udc1b Bug\r\n\r\nWhen testing a model with `Trainer.test` metrics are not logged to Comet if the model was previously trained using `Trainer.fit`. While training metrics are logged correctly.\r\n\r\n\r\n#### Code sample\r\n```\r\n    comet_logger = CometLogger()\r\n    trainer = Trainer(logger=comet_logger)\r\n    model = get_model()\r\n\r\n    trainer.fit(model) # Metrics are logged to Comet\r\n    trainer.test(model) # No metrics are logged to Comet\r\n```\r\n\r\n### Expected behavior\r\n\r\nTest metrics should also be logged in to Comet.\r\n\r\n### Environment\r\n\r\n```\r\n- PyTorch version: 1.3.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.1.243\r\n\r\nOS: Ubuntu 18.04.3 LTS\r\nGCC version: (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0\r\nCMake version: version 3.10.2\r\n\r\nPython version: 3.7\r\nIs CUDA available: Yes\r\nCUDA runtime version: 10.1.168\r\nGPU models and configuration:\r\nGPU 0: GeForce GTX 1080 Ti\r\nGPU 1: GeForce GTX 1080 Ti\r\nGPU 2: GeForce GTX 1080 Ti\r\nGPU 3: GeForce GTX 1080 Ti\r\nGPU 4: GeForce GTX 1080 Ti\r\nGPU 5: GeForce GTX 1080 Ti\r\nGPU 6: GeForce GTX 1080 Ti\r\nGPU 7: GeForce GTX 1080 Ti\r\n\r\nNvidia driver version: 418.67\r\ncuDNN version: \/usr\/local\/cuda-10.1\/targets\/x86_64-linux\/lib\/libcudnn.so.7.6.1\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.16.4\r\n[pip3] pytorch-lightning==0.6.0\r\n[pip3] torch==1.3.0\r\n[pip3] torchvision==0.4.1\r\n[conda] Could not collect\r\n```\r\n\r\n### Additional context\r\n\r\nI believe the issue is caused because at the [end of the training routine](https:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/blob\/deffbaba7ffb16ff57b56fe65f62df761f25fbd6\/pytorch_lightning\/trainer\/training_loop.py#L366), `logger.finalize(\"success\")` is called. This in turn calls `experiment.end()` inside the logger and the `Experiment` object doesn't expect to send more information after this.\r\n\r\nAn alternative is to create another `Trainer` object, with another logger but this means that the metrics will be logged into a different Comet experiment from the original. This issue can be solved using the `ExistingExperiment` object form the Comet SDK, but the solution seems a little hacky and the `CometLogger` currently doesn't support this kind of experiment.\r\n",
        "Issue_answer_count":10,
        "Issue_self_closed":0.0,
        "Answer_body":"Did you find a solution?\r\nMind submitting a PR?\r\n@fdelrio89  I did solve the issue but in a kind of hacky way. It's not that elegant but it works for me, and I haven't had the time to think of a better solution.\r\n\r\nI solved it by getting the experiment key and creating another logger and trainer with it.\r\n```\r\n    comet_logger = CometLogger()\r\n    trainer = Trainer(logger=comet_logger)\r\n    model = get_model()\r\n\r\n    trainer.fit(model)\r\n\r\n    experiment_key = comet_logger.experiment.get_key()\r\n    comet_logger = CometLogger(experiment_key=experiment_key)\r\n    trainer = Trainer(logger=comet_logger)\r\n\r\n    trainer.test(model)\r\n```\r\n\r\nFor this to work, I had to modify the `CometLogger` class to accept the `experiment_key` and create a `CometExistingExperiment` from the Comet SDK when this param is present.\r\n\r\n```\r\nclass CometLogger(LightningLoggerBase):\r\n     ...\r\n\r\n    @property\r\n    def experiment(self):\r\n        ...\r\n\r\n        if self.mode == \"online\":\r\n            if self.experiment_key is None:\r\n                self._experiment = CometExperiment(\r\n                    api_key=self.api_key,\r\n                    workspace=self.workspace,\r\n                    project_name=self.project_name,\r\n                    **self._kwargs\r\n                )\r\n            else:\r\n                self._experiment = CometExistingExperiment(\r\n                    api_key=self.api_key,\r\n                    workspace=self.workspace,\r\n                    project_name=self.project_name,\r\n                    previous_experiment=self.experiment_key,\r\n                    **self._kwargs\r\n                )\r\n        else:\r\n            ...\r\n\r\n        return self._experiment\r\n```\r\n\r\nI can happily do the PR if this solution is acceptable for you guys, but I think a better solution can be achieved I haven't had the time to think about it @williamFalcon. @williamFalcon Any progress on this Issue? I am facing the same problem.\r\n @fdelrio89 Since the logger object is available for the lifetime of the trainer, maybe you can refactor to store the `experiment_key` directly in the logger object itself, instead of having to re-instantiate the logger.  @xssChauhan good idea, I just submitted a PR (https:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/pull\/892) considering this. Thanks!\r\n I assume that it was fixed by #892\r\n if you have some other problems feel free to reopen or create a new... :robot:  Actually I'm still facing the problem. @dvirginz are you using the latest master? may you provide a minimal example? > @dvirginz are you using the latest master? may you provide a minimal example?\r\n\r\nYou are right, sorry. \r\nAfter building from source it works.  I should probably open a new issue, but it happens with Weights & Biases logger too. I haven't had the time to delve deep into it yet.",
        "Tool":"Comet",
        "Platform":"Github",
        "Issue_original_content":"test metric log train bug test model trainer test metric log model previous train trainer fit train metric log correctli code sampl logger logger trainer trainer logger logger model model trainer fit model metric log trainer test model metric log expect behavior test metric log environ pytorch version debug build cuda build pytorch ubuntu lt gcc version ubuntu ubuntu cmake version version python version cuda avail ye cuda runtim version gpu model configur gpu geforc gtx gpu geforc gtx gpu geforc gtx gpu geforc gtx gpu geforc gtx gpu geforc gtx gpu geforc gtx gpu geforc gtx nvidia driver version cudnn version usr local cuda target linux lib libcudnn version relev librari pip numpi pip pytorch lightn pip torch pip torchvis conda collect addit context believ issu caus end train routin http github com pytorchlightn pytorch lightn blob deffbabaffbffbfefdfffbd pytorch lightn trainer train loop logger final success call turn call experi end insid logger experi object expect send inform altern creat trainer object logger mean metric log differ experi origin issu solv existingexperi object form sdk solut littl hacki logger current support kind experi",
        "Issue_preprocessed_content":"test metric train bug test model metric model previous train train metric code sampl expect behavior test metric environ context believ caus turn insid object expect send inform altern creat object mean metric experi origin solv object form sdk solut hacki kind experi",
        "Issue_gpt_summary_original":"The user is encountering a NotImplementedError when trying to create a CometLogger instance and passing it to Trainer using trainer(logger=my_comet_logger) because CometLogger does not implement the name() and version() class methods. This raises an error when the logger version is checked during training.",
        "Issue_gpt_summary":"user encount notimplementederror try creat logger instanc pass trainer trainer logger logger logger implement version class method rais error logger version check train",
        "Issue_score_count":1
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning\/issues\/618",
        "Issue_title":"Comet PAPI Depreciated",
        "Issue_created_time":1575967432000,
        "Issue_closed_time":1576023863000,
        "Issue_body":"Use of the Comet API logger reports an unecessary depreciation warning relating to the use of comet_ml.papi, rather than the newer comet_ml.api.\r\n\r\nExample:\r\n`COMET WARNING: You have imported comet_ml.papi; this interface is deprecated. Please use comet_ml.api instead. For more information, see: https:\/\/www.comet.ml\/docs\/python-sdk\/releases\/#release-300`",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"Comet",
        "Platform":"Github",
        "Issue_original_content":"papi depreci us api logger report unecessari depreci warn relat us papi newer api exampl warn import papi interfac deprec us api instead inform http www doc python sdk releas releas",
        "Issue_preprocessed_content":"papi depreci us api report depreci warn relat us newer exampl",
        "Issue_gpt_summary_original":"The user is encountering an error while trying to train on Window 11 using YOLOv5. The error message suggests that there is a KeyError related to the dataset path. The user has tried multiple datasets but is still facing the same issue. There has been no response to the user's query yet.",
        "Issue_gpt_summary":"user encount error try train window yolov error messag suggest keyerror relat dataset path user tri multipl dataset face issu respons user queri",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning\/issues\/470",
        "Issue_title":"CometLogger does not implement name() and version() class methods",
        "Issue_created_time":1573092782000,
        "Issue_closed_time":1573531232000,
        "Issue_body":"Explicitly creating a CometLogger instance and passing it to Trainer using trainer(logger=my_comet_logger) raises a NotImplementedError because CometLogger does not implement the name() and version() class methods.\r\n\r\nBelow is the traceback:\r\n`\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 126, in <module>\r\n    trainer.fit(model)\r\n  File \"\/home\/ryan\/miniconda3\/envs\/compling\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 351, in fit\r\n    self.single_gpu_train(model)\r\n  File \"\/home\/ryan\/miniconda3\/envs\/compling\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/dp_mixin.py\", line 77, in single_gpu_train\r\n    self.run_pretrain_routine(model)\r\n  File \"\/home\/ryan\/miniconda3\/envs\/compling\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 471, in run_pretrain_routine\r\n    self.train()\r\n  File \"\/home\/ryan\/miniconda3\/envs\/compling\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/train_loop_mixin.py\", line 60, in train\r\n    self.run_training_epoch()\r\n  File \"\/home\/ryan\/miniconda3\/envs\/compling\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/train_loop_mixin.py\", line 99, in run_training_epoch\r\n    output = self.run_training_batch(batch, batch_nb)\r\n  File \"\/home\/ryan\/miniconda3\/envs\/compling\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/train_loop_mixin.py\", line 255, in run_training_batch\r\n    self.main_progress_bar.set_postfix(**self.training_tqdm_dict)\r\n  File \"\/home\/ryan\/miniconda3\/envs\/compling\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 309, in training_tqdm_dict\r\n    if self.logger is not None and self.logger.version is not None:\r\n  File \"\/home\/ryan\/miniconda3\/envs\/compling\/lib\/python3.7\/site-packages\/pytorch_lightning\/logging\/base.py\", line 76, in version\r\n    raise NotImplementedError(\"Sub-classes must provide a version property\")\r\n`\r\n\r\n",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"Comet",
        "Platform":"Github",
        "Issue_original_content":"logger implement version class method explicitli creat logger instanc pass trainer trainer logger logger rais notimplementederror logger implement version class method traceback traceback recent file main line trainer fit model file home ryan miniconda env compl lib python site packag pytorch lightn trainer trainer line fit self singl gpu train model file home ryan miniconda env compl lib python site packag pytorch lightn trainer mixin line singl gpu train self run pretrain routin model file home ryan miniconda env compl lib python site packag pytorch lightn trainer trainer line run pretrain routin self train file home ryan miniconda env compl lib python site packag pytorch lightn trainer train loop mixin line train self run train epoch file home ryan miniconda env compl lib python site packag pytorch lightn trainer train loop mixin line run train epoch output self run train batch batch batch file home ryan miniconda env compl lib python site packag pytorch lightn trainer train loop mixin line run train batch self main progress bar set postfix self train tqdm dict file home ryan miniconda env compl lib python site packag pytorch lightn trainer trainer line train tqdm dict self logger self logger version file home ryan miniconda env compl lib python site packag pytorch lightn log base line version rais notimplementederror sub class provid version properti",
        "Issue_preprocessed_content":"implement version method explicitli creat instanc trainer rais implement version method traceback",
        "Issue_gpt_summary_original":"The user is facing an issue with the learning rate plot in Comet while trying to keep track of learning rate updates. The learning rate being plotted is not the expected one, especially when using the learning_rate_warmup_epochs option. The plotted learning rate is constant for the first few epochs and eventually decreases due to reduce_learning_rate_on_plateau. The user is unsure if this issue is related to the error message \"Failed to extract parameters from Optimizer.init()\".",
        "Issue_gpt_summary":"user face issu learn rate plot try track learn rate updat learn rate plot expect especi learn rate warmup epoch option plot learn rate constant epoch eventu decreas reduc learn rate plateau user unsur issu relat error messag fail extract paramet optim init",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/ultralytics\/yolov5\/issues\/10301",
        "Issue_title":"Comet Bug: Unable to train on Window 11",
        "Issue_created_time":1669476859000,
        "Issue_closed_time":null,
        "Issue_body":"### Search before asking\n\n- [X] I have searched the YOLOv5 [issues](https:\/\/github.com\/ultralytics\/yolov5\/issues) and [discussions](https:\/\/github.com\/ultralytics\/yolov5\/discussions) and found no similar questions.\n\n\n### Question\n\nI am unable to train alway the same error:\r\n\r\npython train.py --img 640 --batch 16 --epochs 5 --data dataset.yaml --weights yolov5s.pt\r\ntrain: weights=yolov5s.pt, cfg=, data=dataset.yaml, hyp=data\\hyps\\hyp.scratch-low.yaml, epochs=5, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs\\train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\r\ngithub: skipping check (not a git repository), for updates see https:\/\/github.com\/ultralytics\/yolov5\r\nYOLOv5  2022-11-26 Python-3.9.13 torch-1.13.0+cpu CPU\r\n\r\nhyperparameters: lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\r\nClearML: run 'pip install clearml' to automatically track, visualize and remotely train YOLOv5  in ClearML\r\nTensorBoard: Start with 'tensorboard --logdir runs\\train', view at http:\/\/localhost:6006\/\r\nCOMET WARNING: Comet credentials have not been set. Comet will default to offline logging. Please set your credentials to enable online logging.\r\nCOMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: tensorboard, torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\r\nCOMET INFO: Using 'C:\\\\Users\\\\telem\\\\Desktop\\\\Yolo\\\\.cometml-runs' path as offline directory. Pass 'offline_directory' parameter into constructor or set the 'COMET_OFFLINE_DIRECTORY' environment variable to manually choose where to store offline experiment archives.\r\nCOMET WARNING: Native output logging mode is not available, falling back to basic output logging\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\telem\\Desktop\\Yolo\\train.py\", line 633, in <module>\r\n    main(opt)\r\n  File \"C:\\Users\\telem\\Desktop\\Yolo\\train.py\", line 527, in main\r\n    train(opt.hyp, opt, device, callbacks)\r\n  File \"C:\\Users\\telem\\Desktop\\Yolo\\train.py\", line 95, in train\r\n    loggers = Loggers(save_dir, weights, opt, hyp, LOGGER)  # loggers instance\r\n  File \"C:\\Users\\telem\\Desktop\\Yolo\\utils\\loggers\\__init__.py\", line 132, in __init__\r\n    self.comet_logger = CometLogger(self.opt, self.hyp)\r\n  File \"C:\\Users\\telem\\Desktop\\Yolo\\utils\\loggers\\comet\\__init__.py\", line 97, in __init__\r\n    self.data_dict = self.check_dataset(self.opt.data)\r\n  File \"C:\\Users\\telem\\Desktop\\Yolo\\utils\\loggers\\comet\\__init__.py\", line 234, in check_dataset\r\n    if data_config['path'].startswith(COMET_PREFIX):\r\nKeyError: 'path'\r\nCOMET INFO: ----------------------------------\r\nCOMET INFO: Comet.ml OfflineExperiment Summary\r\nCOMET INFO: ----------------------------------\r\nCOMET INFO:   Data:\r\nCOMET INFO:     display_summary_level : 1\r\nCOMET INFO:     url                   : [OfflineExperiment will get URL after upload]\r\nCOMET INFO:   Others:\r\nCOMET INFO:     offline_experiment : True\r\nCOMET INFO:   Uploads:\r\nCOMET INFO:     environment details : 1\r\nCOMET INFO:     installed packages  : 1\r\nCOMET INFO: ----------------------------------\r\nCOMET WARNING: Experiment Name is generated at upload time for Offline Experiments unless set explicitly with Experiment.set_name\r\nCOMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: tensorboard, torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\r\nCOMET INFO: Still saving offline stats to messages file before program termination (may take up to 120 seconds)\r\nCOMET INFO: Starting saving the offline archive\r\nCOMET INFO: To upload this offline experiment, run:\r\n    comet upload C:\\Users\\telem\\Desktop\\Yolo\\.cometml-runs\\5f05924ec89f489db0356c7c3201ce0f.zip\r\n\r\nI have tested many dataset and alway the same error any advice ?\r\n\n\n### Additional\n\n_No response_",
        "Issue_answer_count":15,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Comet",
        "Platform":"Github",
        "Issue_original_content":"bug unabl train window search ask search yolov issu http github com ultralyt yolov issu discuss http github com ultralyt yolov discuss similar question question unabl train alwai error python train img batch epoch data dataset yaml weight yolov train weight yolov cfg data dataset yaml hyp data hyp hyp scratch low yaml epoch batch size imgsz rect fals resum fals nosav fals noval fals noautoanchor fals noplot fals evolv bucket cach imag weight fals devic multi scale fals singl cl fals optim sgd sync fals worker project run train exp exist fals quad fals co fals label smooth patienc freez save period seed local rank entiti upload dataset fals bbox interv artifact alia latest github skip check git repositori updat http github com ultralyt yolov yolov python torch cpu cpu hyperparamet lrf momentum weight decai warmup epoch warmup momentum warmup bia box cl cl obj obj iou anchor gamma hsv hsv hsv degre translat scale shear perspect flipud fliplr mosaic mixup copi past run pip instal automat track visual remot train yolov tensorboard start tensorboard logdir run train view http localhost warn credenti set default offlin log set credenti enabl onlin log warn disabl auto log function import follow modul tensorboard torch metric hyperparamet log log metric log paramet info user telem desktop yolo run path offlin directori pass offlin directori paramet constructor set offlin directori environ variabl manual choos store offlin experi archiv warn nativ output log mode avail fall basic output log traceback recent file user telem desktop yolo train line main opt file user telem desktop yolo train line main train opt hyp opt devic callback file user telem desktop yolo train line train logger logger save dir weight opt hyp logger logger instanc file user telem desktop yolo util logger init line init self logger logger self opt self hyp file user telem desktop yolo util logger init line init self data dict self check dataset self opt data file user telem desktop yolo util logger init line check dataset data config path startswith prefix keyerror path info info offlineexperi summari info info data info displai summari level info url offlineexperi url upload info info offlin experi true info upload info environ detail info instal packag info warn experi gener upload time offlin experi set explicitli experi set warn disabl auto log function import follow modul tensorboard torch metric hyperparamet log log metric log paramet info save offlin stat messag file program termin second info start save offlin archiv info upload offlin experi run upload user telem desktop yolo run fecfdbcccef zip test dataset alwai error advic addit respons",
        "Issue_preprocessed_content":"bug unabl train window search ask search yolov similar question question unabl train alwai python train cfg epoch imgsz rect fals resum fals nosav fals noval fals noautoanchor fals noplot fals evolv bucket cach devic optim sgd worker exp quad fals patienc entiti github check updat yolov cpu hyperparamet run pip track visual remot train yolov tensorboard start tensorboard view warn credenti set default set credenti enabl onlin warn disabl function import modul tensorboard torch metric hyperparamet info path directori paramet constructor set environ variabl store experi archiv warn nativ output mode avail basic output traceback file line main file line main opt devic file line train instanc file line file line file line path info info info info data info info url info info true info upload info environ detail info packag info warn experi gener upload time experi set explicitli warn disabl function import modul tensorboard torch metric hyperparamet info save stat file program termin info start save archiv info upload experi run upload test dataset alwai advic",
        "Issue_gpt_summary_original":"The user is facing a logging issue when activating the Comet contrib in Ludwig. Most of the Ludwig log messages disappear, and the expected behavior is to display the log messages when the Comet contrib is activated. The issue is that Ludwig is using the root-level logger configured through `logging.basicConfig`, and the first call to `logging.info` will configure the root logger with no configuration, which will create a StreamHandler pointing to `\/dev\/stderr`. The user recommends moving from using the root logger and configuring the logger through `basicConfig` to using a `ludwig` logger and configuring it manually.",
        "Issue_gpt_summary":"user face log issu activ contrib ludwig ludwig log messag disappear expect behavior displai log messag contrib activ issu ludwig root level logger configur log basicconfig log info configur root logger configur creat streamhandl point dev stderr user recommend move root logger configur logger basicconfig ludwig logger configur manual",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/ludwig-ai\/ludwig\/issues\/733",
        "Issue_title":"The learning rate plot in Comet is not the expected one",
        "Issue_created_time":1591889615000,
        "Issue_closed_time":null,
        "Issue_body":"Hi! I've been trying the comet.ml integration and I must say this has been a great addition to the framework. \ud83d\ude4c\r\n\r\nI wanted to exploit it to keep track of the learning rate updates, but the lr being plot is not the one that I expected, especially when trying the learning_rate_warmup_epochs option, which I set to 6 as suggested. The learning rate that is plot on comet is the one set in learning_rate, and it's constant for the first epochs.\r\n\r\nCould this be related to this error?\r\n\r\n`COMET ERROR: Failed to extract parameters from Optimizer.init()\r\n`\r\n\r\n**To Reproduce**\r\n1. Setup comet\r\n2. Set  learning_rate_warmup_epochs option to 6\r\n\r\n**Expected behavior**\r\nI expected to see the lr increase in the first 6 epochs, reach the lr set in learning_rate, and eventually decrease, as I set also reduce_learning_rate_on_plateau .\r\n\r\n**Actual behavior**\r\nThe lr is equal to the set learning_rate in the first epochs, and eventually decreases due to reduce_learning_rate_on_plateau .\r\n",
        "Issue_answer_count":6,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Comet",
        "Platform":"Github",
        "Issue_original_content":"learn rate plot expect try integr great addit framework want exploit track learn rate updat plot expect especi try learn rate warmup epoch option set suggest learn rate plot set learn rate constant epoch relat error error fail extract paramet optim init reproduc setup set learn rate warmup epoch option expect behavior expect increas epoch reach set learn rate eventu decreas set reduc learn rate plateau actual behavior equal set learn rate epoch eventu decreas reduc learn rate plateau",
        "Issue_preprocessed_content":"learn rate plot expect try integr great framework want exploit track learn rate updat plot expect try option set learn rate plot set constant epoch relat reproduc setup set option expect behavior expect increas epoch reach set decreas set actual behavior equal set epoch decreas",
        "Issue_gpt_summary_original":"The user is facing an issue with the \"Reproduce\" feature of Comet as it fails at the \"apply patch\" stage.",
        "Issue_gpt_summary":"user face issu reproduc featur fail appli patch stage",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/ludwig-ai\/ludwig\/issues\/340",
        "Issue_title":"Logging issue when activating Comet contrib",
        "Issue_created_time":1557825272000,
        "Issue_closed_time":1559077203000,
        "Issue_body":"**Describe the bug**\r\n\r\nWhen activating the Comet contrib, most of Ludwig log message disappears.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n\r\nLaunch: `ludwig experiment --data_csv reuters-allcats.csv --model_definition_file model_definition.yaml -l info --comet`\r\n\r\nYou won't see the following output:\r\n```\r\n _         _        _      \r\n| |_  _ __| |_ __ _(_)__ _ \r\n| | || \/ _` \\ V  V \/ \/ _` |\r\n|_|\\_,_\\__,_|\\_\/\\_\/|_\\__, |\r\n                     |___\/ \r\nludwig v0.1.2 - Experiment\r\n\r\nExperiment name: experiment\r\nModel name: run\r\nOutput path: results\/experiment_run_43\r\n\r\n\r\nludwig_version: '0.1.2'\r\n```\r\n\r\n**Expected behavior**\r\n\r\nThe log messages should be displayed when the Comet contrib is activated.\r\n\r\n**Environment (please complete the following information):**\r\n - OS: Fedora\r\n - Version 28\r\n- Python version: 3.6.8\r\n- Ludwig version: 0.1.2\r\n\r\n**Additional context**\r\n\r\nI think the issue is that ludwig is using the root-level logger configured through `logging.basicConfig`. The comet contrib integration contains some logging calls, for example, https:\/\/github.com\/uber\/ludwig\/blob\/master\/ludwig\/contribs\/comet.py#L56.\r\n\r\nThose calls happen before any `basicConfig` call https:\/\/github.com\/uber\/ludwig\/blob\/master\/ludwig\/experiment.py#L461.\r\n\r\nThe issue with calling the root-level `logging.info`, `logging.error` and so on is that they will call `logging.basicConfig` on their own if the root logger is not configured yet https:\/\/github.com\/python\/cpython\/blob\/master\/Lib\/logging\/__init__.py#L2065. The direct effect is that the first call to `logging.info` will configure the root logger with no configuration which will create a StreamHandler pointing to `\/dev\/stderr`.\r\n\r\nThe unfortunate side-effect is that calling `basicConfig` will do nothing as the root handler as already a handler so the root logger will not be set to the right log level and the stream handler will not point to the right device.\r\n\r\nI would recommend moving from using the root logger and configure the logger through `basicConfig` to using a `ludwig` logger and configure it manually, it's not that more complex. I can help if wanted.\r\n\r\nOne last issue with using the root logger is when configuring the root logger to the debug level, all libraries which are logging will start displaying their log messages. That includes requests and is polluting the output. Using a separate logger would also solve this issue.\r\n",
        "Issue_answer_count":8,
        "Issue_self_closed":0.0,
        "Answer_body":"@Lothiraldan thanks for reporting this. It is indeed a bug to fix. Also notifying @dsblank as he is the main contributor of the comet integration.\r\nWould gladly accept your help offer on this. I'd like to avoid having a logger object that is passed around the whole codebase, but apart from that I'm open to suggestions.\r\n @w4nderlust Yes, and @Lothiraldan and I both are on the Comet team, so we have already been discussing this. @Lothiraldan has much expertise in loggers, so I look forward to his suggestions as well. Hi @w4nderlust, thank you for your prompt answer. I forgot to said that I'm working with @dsblank in the Comet team.\r\n\r\nHaving a non-global logger is ideal but not always feasible.\r\n\r\nThe approach I'm using in my projects is the following, use a logger per module: `LOGGER = logging.getLogger(__name__)`. As the __name__ often contains your project name, you get will get loggers like `dulwich`, `dulwich.experiment`, `dulwich.contribs.comet`. I think I have taken this idea from Django https:\/\/docs.djangoproject.com\/en\/2.1\/topics\/logging\/#using-logging.\r\n\r\nThis way you can configure the top-level logger for your project and every other loggers will just propagate the log messages to it and uses the configured handlers. This unlock having different log level on a module basis or even different handlers if needed.\r\n\r\nI would highly recommend having a central function where the top-level logger is configured, something like https:\/\/github.com\/Lothiraldan\/balto\/blob\/master\/balto\/_logging.py#L6, I found it that it really helps for maintaining a coherent logging configuration.\r\n\r\nApart from that, the Ludwig project seems to be only using a StreamHandler right now so there is no much expertise I can give you on the handlers subjects.\r\n\r\nDon't hesitate if you have some questions. Thanks for the detailed explanation @Lothiraldan . @msaisumanth Is on top of it. It looks pretty straightforward: have a single global logger setup function, add a logger in every module, use that logger instead of logging. I expect this to be solved pretty quickly.\r\nThank you again! @Lothiraldan please take a look at https:\/\/github.com\/uber\/ludwig\/pull\/352\r\nI was able to verify that the output is getting printed as expected. @w4nderlust if this makes sense, I'll modify the other modules as well.  @Lothiraldan it would be great if you could take a look at the PR, it should solve the issue, but wanted to doublecheck with you before merging it. We merged the PR as we believe it works fine, @Lothiraldan if you could take a look at it to confirm it's fine for you too, that owuld be great. I made some comments, sorry for the delay, I was busy with some other stuff.",
        "Tool":"Comet",
        "Platform":"Github",
        "Issue_original_content":"log issu activ contrib bug activ contrib ludwig log messag disappear reproduc step reproduc behavior launch ludwig experi data csv reuter allcat csv model definit file model definit yaml info won follow output ludwig experi experi experi model run output path result experi run ludwig version expect behavior log messag displai contrib activ environ complet follow inform fedora version python version ludwig version addit context think issu ludwig root level logger configur log basicconfig contrib integr contain log call exampl http github com uber ludwig blob master ludwig contrib call happen basicconfig http github com uber ludwig blob master ludwig experi issu call root level log info log error log basicconfig root logger configur http github com python cpython blob master lib log init direct effect log info configur root logger configur creat streamhandl point dev stderr unfortun effect call basicconfig root handler handler root logger set right log level stream handler point right devic recommend move root logger configur logger basicconfig ludwig logger configur manual complex help want issu root logger configur root logger debug level librari log start displai log messag includ request pollut output separ logger solv issu",
        "Issue_preprocessed_content":"activ contrib bug activ contrib ludwig log reproduc step reproduc behavior launch won output expect behavior log displai contrib activ environ fedora version python version ludwig version context think ludwig level configur contrib integr contain exampl level configur direct configur configur creat streamhandl point unfortun handler handler set right log level stream handler point right devic move configur configur complex help want configur debug level librari start displai log includ request output separ solv",
        "Issue_gpt_summary_original":"When using nn.DataParallel, the name of the model saved in comet.ml will be DataParallel, according to the user. No error messages, stack traces, or logs were provided. The user did not provide any steps to reproduce the issue or any additional context.",
        "Issue_gpt_summary":"dataparallel model save dataparallel accord user error messag stack trace log provid user provid step reproduc issu addit context",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/cc-ai\/climategan\/issues\/116",
        "Issue_title":"Comet \"Reproduce\" feature doesn't work",
        "Issue_created_time":1595861398000,
        "Issue_closed_time":1624956881000,
        "Issue_body":"It fails at the \"apply patch\" stage",
        "Issue_answer_count":3,
        "Issue_self_closed":0.0,
        "Answer_body":"is this still an issue @51N84D ? Yeah, this still doesn't work. I don't think anyone has tried to resolve it yet Ok ; should we in your opinion?",
        "Tool":"Comet",
        "Platform":"Github",
        "Issue_original_content":"reproduc featur work fail appli patch stage",
        "Issue_preprocessed_content":"reproduc featur work fail patch stage",
        "Issue_gpt_summary_original":"The user encountered a warning message in Enchanter v0.7.0 stating that the function `log_asset_data(..., file_name=...)` is deprecated and should be replaced with `log_asset_data(..., name=...)` when using Context API. The user did not provide any error messages, stack traces, or logs, nor did they provide steps to reproduce the issue.",
        "Issue_gpt_summary":"user encount warn messag enchant state function log asset data file deprec replac log asset data context api user provid error messag stack trace log provid step reproduc issu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/khirotaka\/enchanter\/issues\/132",
        "Issue_title":"When using nn.DataParallel, the name of the model saved in comet.ml will be DataParallel.",
        "Issue_created_time":1600305917000,
        "Issue_closed_time":1600309841000,
        "Issue_body":"When using nn.DataParallel, the name of the model saved in comet.ml will be DataParallel.\r\n\r\n## Expected behavior\r\n\r\n<!-- Please write a clear and concise description of what you expected to happen. -->\r\n\r\n## Environment\r\n\r\n- Enchanter version: 0.7.0\r\n- Python version: 3.6.6\r\n- OS: Ubuntu 18.04\r\n- (Optional) Other libraries and their versions:\r\n\r\n## Error messages, stack traces, or logs\r\n\r\n```\r\n# error messages, stack traces, or logs\r\n```\r\n\r\n## Steps to reproduce\r\n\r\n1.\r\n2.\r\n3.\r\n\r\n## Reproducible examples (optional)\r\n\r\n```python\r\n# python code\r\n```\r\n\r\n## Additional context (optional)\r\n\r\n<!-- Please add any other context or screenshots about the problem here. -->",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"Issue-Label Bot is automatically applying the label `bug` to this issue, with a confidence of 0.68. Please mark this comment with :thumbsup: or :thumbsdown: to give our bot feedback! \n\n Links: [app homepage](https:\/\/github.com\/marketplace\/issue-label-bot), [dashboard](https:\/\/mlbot.net\/data\/khirotaka\/enchanter) and [code](https:\/\/github.com\/hamelsmu\/MLapp) for this bot.",
        "Tool":"Comet",
        "Platform":"Github",
        "Issue_original_content":"dataparallel model save dataparallel dataparallel model save dataparallel expect behavior environ enchant version python version ubuntu option librari version error messag stack trace log error messag stack trace log step reproduc reproduc exampl option python python code addit context option",
        "Issue_preprocessed_content":"model save model save expect behavior write clear concis descript expect environ enchant version python version ubuntu librari version stack trace log step reproduc reproduc exampl context context problem",
        "Issue_gpt_summary_original":"The user is encountering issues with the pipeline `sentence_embedding\/dvc.yaml` as it is not correctly defined for `evaluation:deps`. This is causing problems with pulling the model `biobert_nli_sts_cord19_v1` and running the training stage before the evaluation stage for the models `tf_idf\/` and `count\/`. The user is unable to run `dvc pull -d` and `dvc repro -f` without errors about missing files.",
        "Issue_gpt_summary":"user encount issu pipelin sentenc embed yaml correctli defin evalu dep caus problem pull model biobert nli st cord run train stage evalu stage model idf count user unabl run pull repro error miss file",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/khirotaka\/enchanter\/issues\/129",
        "Issue_title":"COMET WARNING: log_asset_data(..., file_name=...) is deprecated; use log_asset_data(..., name=...)",
        "Issue_created_time":1600151670000,
        "Issue_closed_time":1600153381000,
        "Issue_body":"Enchanter v0.7.0 raise `COMET WARNING: log_asset_data(..., file_name=...) is deprecated; use log_asset_data(..., name=...)` when using Context API\r\n\r\n## Expected behavior\r\n\r\n<!-- Please write a clear and concise description of what you expected to happen. -->\r\n\r\n## Environment\r\n\r\n- Enchanter version: v0.7.0\r\n- Python version: ?\r\n- OS: Linux\r\n- (Optional) Other libraries and their versions: Google Colab with GPU\r\n\r\n## Error messages, stack traces, or logs\r\n\r\n```\r\n# error messages, stack traces, or logs\r\n```\r\n\r\n## Steps to reproduce\r\n\r\n1.\r\n2.\r\n3.\r\n\r\n## Reproducible examples (optional)\r\n\r\n```python\r\nrunner = ClassificationRunner(\r\n    net, optimizer, criterion, Experiment()\r\n)\r\n\r\nwith runner:\r\n    runner.scaler = torch.cuda.amp.GradScaler()\r\n\r\n    runner.add_loader(\"train\", trainloader)\r\n    runner.add_loader(\"test\", testloader)\r\n    runner.train_config(epochs=20)\r\n\r\n    runner.run()\r\n```\r\n\r\n## Additional context (optional)\r\n\r\n<!-- Please add any other context or screenshots about the problem here. -->",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"Issue-Label Bot is automatically applying the label `bug` to this issue, with a confidence of 0.69. Please mark this comment with :thumbsup: or :thumbsdown: to give our bot feedback! \n\n Links: [app homepage](https:\/\/github.com\/marketplace\/issue-label-bot), [dashboard](https:\/\/mlbot.net\/data\/khirotaka\/enchanter) and [code](https:\/\/github.com\/hamelsmu\/MLapp) for this bot.",
        "Tool":"Comet",
        "Platform":"Github",
        "Issue_original_content":"warn log asset data file deprec us log asset data enchant rais warn log asset data file deprec us log asset data context api expect behavior environ enchant version python version linux option librari version googl colab gpu error messag stack trace log error messag stack trace log step reproduc reproduc exampl option python runner classificationrunn net optim criterion experi runner runner scaler torch cuda amp gradscal runner add loader train trainload runner add loader test testload runner train config epoch runner run addit context option",
        "Issue_preprocessed_content":"warn deprec us enchant rais context api expect behavior write clear concis descript expect environ enchant version python version linux librari version colab gpu stack trace log step reproduc reproduc exampl context context problem",
        "Issue_gpt_summary_original":"The user is encountering a bug in DVC evaluation which crashes due to \"int64 not JSON serializable\" error. The bug was introduced by #348 and the error traceback is provided in the post. The user has also provided steps to reproduce the error.",
        "Issue_gpt_summary":"user encount bug evalu crash int json serializ error bug introduc error traceback provid post user provid step reproduc error",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/BlueBrain\/Search\/issues\/396",
        "Issue_title":"Fix the definition of pipelines\/sentence_embedding\/dvc.yaml",
        "Issue_created_time":1625148874000,
        "Issue_closed_time":1626683431000,
        "Issue_body":"## \ud83d\udc1b Bug description\r\n\r\nThe pipeline `sentence_embedding\/dvc.yaml` is not correctly defined for `evaluation:deps`.\r\n\r\nThis creates the following issues:\r\n  - The evaluation stage does not know how to pull the model `biobert_nli_sts_cord19_v1\/`.\r\n  - The training stage does not know it has to run before the evaluation stage for the models `tf_idf\/` and `count\/`.\r\n\r\n## To reproduce\r\n\r\n```\r\ngit checkout 12988ef564dd4e6373a7455f5ee30c0608e2e972\r\nexport PIPELINE=data_and_models\/pipelines\/sentence_embedding\/dvc.yaml\r\ndvc pull -d $PIPELINE\r\ndvc repro -f $PIPELINE\r\n```\r\n\r\nThis will give the error:\r\n```\r\nRunning stage 'data_and_models\/pipelines\/sentence_embedding\/dvc.yaml:evaluation@biobert_nli_sts_cord19_v1':\r\n...\r\nAttributeError: Path ..\/..\/models\/sentence_embedding\/biobert_nli_sts_cord19_v1\/ not found\r\n```\r\n\r\nAfter manually pulling `biobert_nli_sts_cord19_v1`, this will give the error:\r\n```\r\nRunning stage 'data_and_models\/pipelines\/sentence_embedding\/dvc.yaml:evaluation@tf_idf':\r\n...\r\nFileNotFoundError: [Errno 2] No such file or directory: '..\/..\/models\/sentence_embedding\/tf_idf\/model.pkl'\r\n```\r\n\r\n## Expected behavior\r\n\r\n`dvc pull -d` and `dvc repro -f` should run without errors about missing files.",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"DVC",
        "Platform":"Github",
        "Issue_original_content":"fix definit pipelin sentenc embed yaml bug descript pipelin sentenc embed yaml correctli defin evalu dep creat follow issu evalu stage know pull model biobert nli st cord train stage know run evalu stage model idf count reproduc git checkout efddeafeece export pipelin data model pipelin sentenc embed yaml pull pipelin repro pipelin error run stage data model pipelin sentenc embed yaml evalu biobert nli st cord attributeerror path model sentenc embed biobert nli st cord manual pull biobert nli st cord error run stage data model pipelin sentenc embed yaml evalu idf filenotfounderror errno file directori model sentenc embed idf model pkl expect behavior pull repro run error miss file",
        "Issue_preprocessed_content":"fix definit bug descript pipelin defin creat evalu stage know model train stage know run evalu stage model reproduc expect behavior run file",
        "Issue_gpt_summary_original":"The user is facing an issue with znNodes not working with `dvc.<...>` and is trying to fix the docstring and test it with a Node that has `dvc.params` and `dvc.outs`.",
        "Issue_gpt_summary":"user face issu znnode work try fix docstr test node param out",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/BlueBrain\/Search\/issues\/361",
        "Issue_title":"DVC eval crashes \"int64 not JSON serializable\"",
        "Issue_created_time":1620385977000,
        "Issue_closed_time":1620393602000,
        "Issue_body":"The DVC evaluation is crashing. After investigation, the bug was introduced by #348.\r\n\r\nThe bug:\r\n```\r\nTraceback (most recent call last):\r\n  File \"eval.py\", line 111, in <module>\r\n    main()\r\n  File \"eval.py\", line 107, in main\r\n    json.dump(all_metrics_dict, f)\r\n  File \"\/opt\/conda\/lib\/python3.8\/json\/__init__.py\", line 179, in dump\r\n    for chunk in iterable:\r\n  File \"\/opt\/conda\/lib\/python3.8\/json\/encoder.py\", line 431, in _iterencode\r\n    yield from _iterencode_dict(o, _current_indent_level)\r\n  File \"\/opt\/conda\/lib\/python3.8\/json\/encoder.py\", line 405, in _iterencode_dict\r\n    yield from chunks\r\n  File \"\/opt\/conda\/lib\/python3.8\/json\/encoder.py\", line 438, in _iterencode\r\n    o = _default(o)\r\n  File \"\/opt\/conda\/lib\/python3.8\/json\/encoder.py\", line 179, in default\r\n    raise TypeError(f'Object of type {o.__class__.__name__} '\r\nTypeError: Object of type int64 is not JSON serializable\r\n```\r\n\r\nTo reproduce:\r\n\r\n```\r\n# For the bug introduced by #348, use 0bb500551b1b7c6f5bb9228335aa4df30a654e9c.\r\n# For the working code __before__ #348, use b9c886966ca4d893b41457a17262e198e3ba7f03.\r\nexport COMMIT=...\r\n\r\ngit clone https:\/\/github.com\/BlueBrain\/Search\r\ncd Search\/\r\n\r\n# Change <image> and <container>.\r\ndocker build -f data_and_models\/pipelines\/ner\/Dockerfile --build-arg BBS_REVISION=$COMMIT -t <image> .\r\ndocker run -it --rm -v \/raid:\/raid --name <container> <image>\r\n\r\ngit checkout $COMMIT\r\ngit checkout -- data_and_models\/pipelines\/ner\/dvc.lock\r\n\r\ncd data_and_models\/pipelines\/ner\/\r\ndvc pull --with-deps evaluation@organism\r\ndvc repro -fs evaluation@organism\r\n```\r\n\r\n_Originally posted by @pafonta in https:\/\/github.com\/BlueBrain\/Search\/issues\/335#issuecomment-833506692_",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"DVC",
        "Platform":"Github",
        "Issue_original_content":"eval crash int json serializ evalu crash investig bug introduc bug traceback recent file eval line main file eval line main json dump metric dict file opt conda lib python json init line dump chunk iter file opt conda lib python json encod line iterencod yield iterencod dict current indent level file opt conda lib python json encod line iterencod dict yield chunk file opt conda lib python json encod line iterencod default file opt conda lib python json encod line default rais typeerror object type class typeerror object type int json serializ reproduc bug introduc us bbbbcfbbaadfaec work code us bccadbaeebaf export commit git clone http github com bluebrain search search chang docker build data model pipelin ner dockerfil build arg bb revis commit docker run raid raid git checkout commit git checkout data model pipelin ner lock data model pipelin ner pull dep evalu organ repro evalu organ origin post pafonta http github com bluebrain search issu issuecom",
        "Issue_preprocessed_content":"eval crash int json serializ evalu crash investig bug introduc bug reproduc post",
        "Issue_gpt_summary_original":"The user is facing an issue where using only \"zn.Method\" without \"zn.params\" in a Node does not add parameters to the \"dvc.yaml\" file, causing it to not depend on the \"params.yaml\" file.",
        "Issue_gpt_summary":"user face issu method param node add paramet yaml file caus depend param yaml file",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/zincware\/ZnTrack\/issues\/348",
        "Issue_title":"znNodes not working with `dvc.<...>`",
        "Issue_created_time":1658850596000,
        "Issue_closed_time":null,
        "Issue_body":"- [ ] fix docstring\r\n- [ ] test with a Node that has `dvc.params` and `dvc.outs`\r\n\r\nhttps:\/\/github.com\/zincware\/ZnTrack\/blob\/cd2c4f05ad5abf2b23da80fe56558cef6c73e636\/zntrack\/zn\/nodes.py#L11-L28",
        "Issue_answer_count":0,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"DVC",
        "Platform":"Github",
        "Issue_original_content":"znnode work fix docstr test node param out http github com zincwar zntrack blob cdcfadabfbdafecefc zntrack node",
        "Issue_preprocessed_content":"work fix docstr test node",
        "Issue_gpt_summary_original":"The user encountered an error while running a benchmark due to the fact that the `.dvc.lock` file was git-ignored. Removing this line from the `.gitignore` file resolved the issue, but there may be a need for better ways to handle the `dvc.lock` file in the future.",
        "Issue_gpt_summary":"user encount error run benchmark fact lock file git ignor remov line gitignor file resolv issu need better wai handl lock file futur",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/zincware\/ZnTrack\/issues\/211",
        "Issue_title":"zn.Method does not add params to `dvc.yaml`",
        "Issue_created_time":1643228171000,
        "Issue_closed_time":1643235530000,
        "Issue_body":"When only `zn.Method` without `zn.params` is used in a Node the `dvc.yaml` will not depend on the `params.yaml`.\r\n",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"DVC",
        "Platform":"Github",
        "Issue_original_content":"method add param yaml method param node yaml depend param yaml",
        "Issue_preprocessed_content":"param node depend",
        "Issue_gpt_summary_original":"The user needs to update dvc for dvc-bench to work with versions greater than 2.0.0, but ignoring lockfile is not allowed.",
        "Issue_gpt_summary":"user need updat bench work version greater ignor lockfil allow",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/zincware\/ZnTrack\/issues\/76",
        "Issue_title":"raise Error if pre-initialized DVC option is being changed",
        "Issue_created_time":1633013182000,
        "Issue_closed_time":1634716886000,
        "Issue_body":"One can either define a DVC option with default values in the init, which could be considered a constant, or change a DVC option that has no default values in the call method.\r\n\r\nIf a pre-intialized DVC option is being changed within the call that can lead to issues and should either raise an exception or at least log that it can lead to not supported problems",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"DVC",
        "Platform":"Github",
        "Issue_original_content":"rais error pre initi option chang defin option default valu init consid constant chang option default valu method pre intial option chang lead issu rais except log lead support problem",
        "Issue_preprocessed_content":"rais option chang defin option default valu init consid constant chang option default valu method option chang lead rais except log lead problem",
        "Issue_gpt_summary_original":"The user is encountering an issue where dvc is attempting to launch an updater using an asv script, resulting in an error message indicating an unknown mode. The user suggests setting the CI or DVC_TEST environment variable as a workaround to prevent dvc from launching the updater.",
        "Issue_gpt_summary":"user encount issu attempt launch updat asv script result error messag indic unknown mode user suggest set test environ variabl workaround prevent launch updat",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/iterative\/dvc-bench\/issues\/255",
        "Issue_title":"ERROR: 'dvc.lock' is git-ignored.",
        "Issue_created_time":1619681675000,
        "Issue_closed_time":1621495987000,
        "Issue_body":"```\r\n$ dvc repro run_benchmarks\r\nERROR: 'dvc.lock' is git-ignored.\r\n```\r\n\r\n`.dvc.lock` in `.gitignore` causes Exceptions at running benchmark. Delete this line solves this problem. And because of #168 maybe we need some better ways to deal with `dvc.lock`.",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"DVC",
        "Platform":"Github",
        "Issue_original_content":"error lock git ignor repro run benchmark error lock git ignor lock gitignor caus except run benchmark delet line solv problem mayb need better wai deal lock",
        "Issue_preprocessed_content":" caus except benchmark delet line solv problem mayb wai deal",
        "Issue_gpt_summary_original":"The user encountered several issues while running experiments using `example-dvc-experiments`. These issues include dvc not being installed by `pip install -r requirements.txt`, an error while running `dvc pull`, all images being listed when running the `extract` stage using `dvc exp run`, and unclear instructions regarding the use of `dvc repro` and `dvc exp run`. The user suggests including `dvc` in `requirements.txt` and clarifying the instructions for using `dvc repro` and `dvc exp run`.",
        "Issue_gpt_summary":"user encount issu run experi exampl experi issu includ instal pip instal requir txt error run pull imag list run extract stage exp run unclear instruct us repro exp run user suggest includ requir txt clarifi instruct repro exp run",
        "Issue_score_count":1
    },
    {
        "Issue_link":"https:\/\/github.com\/iterative\/dvc-bench\/issues\/244",
        "Issue_title":"requirements: update dvc",
        "Issue_created_time":1616672577000,
        "Issue_closed_time":1628758546000,
        "Issue_body":"After https:\/\/github.com\/iterative\/dvc\/pull\/5265\r\nWe do not allow ignoring lockfile. `dvc-bench` is running currently on some older version of `dvc`, though it would be good to adjust it so that it works with `>2.0.0`.",
        "Issue_answer_count":2,
        "Issue_self_closed":1.0,
        "Answer_body":"@pared Sorry, not sure I understand what do we need to update here. Could you elaborate, please? Fixed by #267, forgot to close.",
        "Tool":"DVC",
        "Platform":"Github",
        "Issue_original_content":"requir updat http github com iter pull allow ignor lockfil bench run current older version good adjust work",
        "Issue_preprocessed_content":"requir updat ignor lockfil older version",
        "Issue_gpt_summary_original":"The user is facing an issue where the example-get-started is broken with the latest DVC, as they are unable to fetch data from the cloud due to a corrupted lockfile.",
        "Issue_gpt_summary":"user face issu exampl start broken latest unabl fetch data cloud corrupt lockfil",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/iterative\/dvc-bench\/issues\/149",
        "Issue_title":"dvc tries to launch updater using asv script",
        "Issue_created_time":1593808834000,
        "Issue_closed_time":1594041670000,
        "Issue_body":"In every run you can see:\r\n```\r\n               2020-07-03 23:24:19,549 DEBUG: Trying to spawn '['\/home\/efiop\/git\/dvc-bench\/envs\/76391772e92136ec87b9940d70226329\/bin\/python', '\r\n\/home\/efiop\/.pyenv\/versions\/3.8.3\/envs\/dvc-3.8.3\/lib\/python3.8\/site-packages\/asv\/benchmark.py', 'daemon', '-q', 'updater']'\r\n               2020-07-03 23:24:19,550 DEBUG: Spawned '['\/home\/efiop\/git\/dvc-bench\/envs\/76391772e92136ec87b9940d70226329\/bin\/python', '\/home\/ef\r\niop\/.pyenv\/versions\/3.8.3\/envs\/dvc-3.8.3\/lib\/python3.8\/site-packages\/asv\/benchmark.py', 'daemon', '-q', 'updater']'\r\n               Unknown mode daemon\r\n```\r\nwe clearly need to take more care on dvc-side, but a good enough workaround is to set CI or DVC_TEST env var to make dvc skip launching the updater.",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"DVC",
        "Platform":"Github",
        "Issue_original_content":"tri launch updat asv script run debug try spawn home efiop git bench env eecbd bin python home efiop pyenv version env lib python site packag asv benchmark daemon updat debug spawn home efiop git bench env eecbd bin python home iop pyenv version env lib python site packag asv benchmark daemon updat unknown mode daemon clearli need care good workaround set test env var skip launch updat",
        "Issue_preprocessed_content":"tri launch updat asv script run clearli care workaround set env var skip launch updat",
        "Issue_gpt_summary_original":"The user needs to rebuild the \"get-started\" feature with the latest DVC version because every DVC command changes the `.gitignore` file, causing inconvenience when switching between branches.",
        "Issue_gpt_summary":"user need rebuild start featur latest version command chang gitignor file caus inconveni switch branch",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/iterative\/example-repos-dev\/issues\/98",
        "Issue_title":"Various issues in `example-dvc-experiments`",
        "Issue_created_time":1638880026000,
        "Issue_closed_time":1642605521000,
        "Issue_body":"> These are reported by @tapadipti (thanks). I'm moving here to discuss and follow: \r\n\r\nI was running experiments by following the docs (https:\/\/dvc.org\/doc\/start\/experiments) and encountered the following issues. Sharing here for any required action.\r\n1. dvc is not installed by `pip install -r requirements.txt`. So, if someone is trying to use a new virtual env, they need to install dvc separately. Would be good to include `dvc` in `requirements.txt`.\r\n2. `dvc pull` gave this error:\r\n   ```\r\n   ERROR: failed to pull data from the cloud - Checkout failed for following targets:\r\n   models\/model.h5\r\n   metrics\r\n   Is your cache up to date?\r\n   <https:\/\/error.dvc.org\/missing-files>\r\n   ```\r\n\r\n3. `dvc exp run` lists all the image when running the `extract` stage. Would be good to remove `-v` from `tar -xvzf data\/images.tar.gz --directory data`\r\n4. `If you used dvc repro before` section in the doc is a little unclear. Does `dvc exp run` replace `dvc repro`? If yes, can we state this clearly? Also would be great to change this statement `We use dvc repro to run the pipeline...` to `dvc repro runs the pipeline...`",
        "Issue_answer_count":11,
        "Issue_self_closed":1.0,
        "Answer_body":"This seems high priority. We can remove `bug` and change to `p1` after 2. is addressed at least, I think. > 1. dvc is not installed by `pip install -r requirements.txt`. So, if someone is trying to use a new virtual env, they need to install dvc separately. Would be good to include `dvc` in `requirements.txt`.\r\n\r\nThis was a bit intentional to let the users install DVC themselves, and a bit to prevent version conflicts. There are some conditions (like installing DVC to system and venv both with different dependencies) that cause weird behavior. \r\n\r\nWe can go on to this route though, it's a single line of change. Is it better to add `dvc` to the `requirements.txt` @shcheklein?  If this was intentional and we don't want to include `dvc` in `requirements.txt`, then we should add an instruction that the user should install `dvc`. Currently, such an instruction is missing. It is unlikely that many people will reach the experiments page of the tutorial without first having installed `dvc`. But in case they try to work a new venv, it can be a `lil confusing. I remembered why I left `-v` in `tar`, it was taking some time after `extract` to start running and the experiment looks like it's frozen. I've now updated the project not to use `-v` in `tar`, and also updated `model.h5` in the remote. (We had a bug in DVC that was preventing to upload experiments.) Could you now check whether the project works as intended? @tapadipti \r\n\r\nI'll create separate PRs in the docs for content updates. Thank you.  Thanks @iesahin \r\n\r\n`dvc pull` gave this error:\r\n```                                                                                                                    \r\nERROR: failed to pull data from the cloud - Checkout failed for following targets:\r\n\/Users\/tapadiptisitaula\/Documents\/test\/example-dvc-experiments\/models\/model.h5\r\nIs your cache up to date?\r\n<https:\/\/error.dvc.org\/missing-files>\r\n```\r\nSo looks like `metrics` worked but not `model.h5`. And this time, the full file path is displayed.\r\n\r\nRemoving `-v` worked. The files are not listed anymore.\r\n\r\n ```\r\n> ERROR: failed to pull data from the cloud - Checkout failed for following targets:\r\n\/Users\/tapadiptisitaula\/Documents\/test\/example-dvc-experiments\/models\/model.h5\r\n```\r\n\r\nInteresting. I double checked yesterday that the script pushing the artifacts has completed successfully. Now, I've checked again and it says:\r\n\r\n```\r\ndvc push\r\nEverything is up to date.\r\n```\r\n\r\nCould you check the MD5 line in `dvc.lock`, corresponding to this line: https:\/\/github.com\/iterative\/example-dvc-experiments\/blob\/main\/dvc.lock#L36\r\n\r\nWhat's the MD5 hash value there, in your installation?\r\n Also, I've checked after cloning the repository: \r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/476310\/145449841-16ae8f43-7ce3-4459-a0d3-225d67214ab0.png)\r\n\r\n@tapadipti  The current staging version in https:\/\/github.com\/iterative\/example-dvc-staging resolves all of these issues. I think we can push it to `example-dvc-experiments`.  @iesahin sounds good. The most recent https:\/\/github.com\/iterative\/example-dvc-experiments resolves all these issues. The codification changes are in #97. Closing this. ",
        "Tool":"DVC",
        "Platform":"Github",
        "Issue_original_content":"issu exampl experi report tapadipti thank move discuss follow run experi follow doc http org doc start experi encount follow issu share requir action instal pip instal requir txt try us new virtual env need instal separ good includ requir txt pull gave error error fail pull data cloud checkout fail follow target model model metric cach date exp run list imag run extract stage good remov tar xvzf data imag tar directori data repro section doc littl unclear exp run replac repro ye state clearli great chang statement us repro run pipelin repro run pipelin",
        "Issue_preprocessed_content":" report move experi doc encount share requir action try us new virtual env separ includ exp run extract tar xvzf data repro exp run repro us repro run",
        "Issue_gpt_summary_original":"The user is facing an issue with the \"pull\" command on DagsHub remote, as it fails to pull dvc on Windows. The user has to manually pull dvc again, which is a permanent issue on Windows. Although not urgent, it is an annoyance for the user.",
        "Issue_gpt_summary":"user face issu pull command dagshub remot fail pull window user manual pull perman issu window urgent annoy user",
        "Issue_score_count":1
    },
    {
        "Issue_link":"https:\/\/github.com\/iterative\/example-repos-dev\/issues\/17",
        "Issue_title":"example-get-started is broken with latest DVC",
        "Issue_created_time":1606072868000,
        "Issue_closed_time":1606074573000,
        "Issue_body":"> From https:\/\/github.com\/iterative\/dvc.org\/issues\/1743#issuecomment-730726776\r\n\r\n```console\r\n$ git@github.com:iterative\/example-get-started.git\r\n...\r\n$ cd example-get-started\r\n$ dvc fetch\r\nERROR: failed to fetch data from the cloud - Lockfile 'dvc.lock' is corrupted.\r\n```",
        "Issue_answer_count":7,
        "Issue_self_closed":1.0,
        "Answer_body":"What DVC version do you use? It should be be fixed in the most recent one. 1.9.1 on Windows (latest) the latest version is 1.10 something. if it's not updated on Windows then we have a problem with Win releases cc @efiop  Ah I was wrong, you're right. Works with 1.10.1 which I got from https:\/\/github.com\/iterative\/dvc\/releases\/\r\n\r\nThe problem is that the dvc.org home page download button is stuck at 1.9.1 for all platforms, it seems. Opened iterative\/dvc.org\/issues\/1964, resolving here. I use the latest dvc version [DVC version: 1.11.16 (pip)] and have got the same issue while following the [installation](https:\/\/github.com\/iterative\/example-get-started) steps:\r\nOS: Mac OS Mojave 10.14.6\r\n```\r\n$ dvc pull\r\nEverything is up to date.                                             \r\nERROR: failed to pull data from the cloud - Lockfile 'dvc.lock' is corrupted.\r\n``` @yakushechkin example-get-started is migrating to dvc 2.0, so it is no longer compatible with older dvc versions. We plan on releasing 2.0 on Wednesday. You could try `pip install --pre dvc` to install dvc pre-release. Sorry for the inconvenience.",
        "Tool":"DVC",
        "Platform":"Github",
        "Issue_original_content":"exampl start broken latest http github com iter org issu issuecom consol git github com iter exampl start git exampl start fetch error fail fetch data cloud lockfil lock corrupt",
        "Issue_preprocessed_content":"broken latest ",
        "Issue_gpt_summary_original":"The user is facing an issue where DVC and Git services are not detecting the root directory of the repository correctly. They assume that the current working directory is where they can find the `.git` and `.dvc` directories, which affects their logic to automatically initialize DVC on behalf of the user. The user suggests detecting the correct paths to resolve the issue. Relevant resources have been provided for further information.",
        "Issue_gpt_summary":"user face issu git servic detect root directori repositori correctli assum current work directori git directori affect logic automat initi behalf user user suggest detect correct path resolv issu relev resourc provid inform",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/iterative\/example-repos-dev\/issues\/12",
        "Issue_title":"need to rebuild get-started with the latest DVC version",
        "Issue_created_time":1582914224000,
        "Issue_closed_time":1588739140000,
        "Issue_body":"Experience is broken since every DVC command changes `.gitignore` now - makes it very annoying to jump between branches.",
        "Issue_answer_count":2,
        "Issue_self_closed":1.0,
        "Answer_body":"This will be done as part of iterative\/dvc.org\/issues\/599. Shall we close here? Yep.",
        "Tool":"DVC",
        "Platform":"Github",
        "Issue_original_content":"need rebuild start latest version experi broken command chang gitignor make annoi jump branch",
        "Issue_preprocessed_content":"rebuild latest version experi broken chang make jump branch",
        "Issue_gpt_summary_original":"The user is encountering an error when using `fds clone` for a non-DVC repository. The error message states that the user is not inside a DVC repository. The user suggests that after cloning the Git server, FDS should check if the repo contains DVC files. If it does, FDS will start a wizard to set the user name and password for each remote storage in the local config and pull all the files from the remotes. If it doesn't contain DVC files, FDS will initialize DVC and start a wizard to set the remote user name, password, and name.",
        "Issue_gpt_summary":"user encount error fd clone non repositori error messag state user insid repositori user suggest clone git server fd check repo contain file fd start wizard set user password remot storag local config pull file remot contain file fd initi start wizard set remot user password",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/DagsHub\/fds\/issues\/121",
        "Issue_title":"fds fails to pull dvc on windows",
        "Issue_created_time":1647838452000,
        "Issue_closed_time":null,
        "Issue_body":"When running pull command on DagsHub remote. I receive dvc pull failure, so I have to manually pull dvc again. \n\nThis issue permanent issue on windows. \n\n```bash\nfds clone <remote> \n\n```\n\nIt is not urgent issue, but in annoyance category. ",
        "Issue_answer_count":3,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"DVC",
        "Platform":"Github",
        "Issue_original_content":"fd fail pull window run pull command dagshub remot receiv pull failur manual pull issu perman issu window bash fd clone urgent issu annoy categori",
        "Issue_preprocessed_content":"fd fail window dagshub remot receiv failur perman window urgent categori",
        "Issue_gpt_summary_original":"The user is facing an issue while trying to add files to DVC tracking using the `fds add` command. The user tried to add a directory containing image files but the command failed to execute.",
        "Issue_gpt_summary":"user face issu try add file track fd add command user tri add directori contain imag file command fail execut",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/DagsHub\/fds\/issues\/92",
        "Issue_title":"DVC and Git services don't correctly detect the repo root directory",
        "Issue_created_time":1629832721000,
        "Issue_closed_time":1630227884000,
        "Issue_body":"It seems they both assume that the current working dir is where they can find the `.git` and `.dvc` dirs.\r\nWe should correctly detect those paths, as it affects all our logic to e.g. automatically dvc init on behalf of the user.\r\n\r\nRelevant resources:\r\n1. https:\/\/stackoverflow.com\/a\/957978\r\n2. https:\/\/dvc.org\/doc\/command-reference\/root",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"DVC",
        "Platform":"Github",
        "Issue_original_content":"git servic correctli detect repo root directori assum current work dir git dir correctli detect path affect logic automat init behalf user relev resourc http stackoverflow com http org doc command refer root",
        "Issue_preprocessed_content":"git servic detect repo directori work dir dir detect path logic init behalf user relev resourc",
        "Issue_gpt_summary_original":"The user is facing an issue where the DVC add prompt is always displayed, even when there is no selection to make since the list of files is empty. The prompt should only be displayed if there is something to add.",
        "Issue_gpt_summary":"user face issu add prompt displai select list file prompt displai add",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/DagsHub\/fds\/issues\/87",
        "Issue_title":"fsd clone for non-DVC repos throws an error",
        "Issue_created_time":1628503684000,
        "Issue_closed_time":1630576282000,
        "Issue_body":"When using `fds clone` for non-DVC repo it throws the following error:\r\n\r\n`ERROR: you are not inside of a DVC repository (checked up to mount point '\/')`\r\n\r\nCloning a non-DVC repo using FDS can be a common use case, e.g., cloning a DAGsHub repo containing many files, but none of them are tracked by DVC nur the repo contains DVC config files. \r\n\r\nI suggest that after cloning the Git server, FDS will check if the repo contains DVC files. \r\n\r\nif it contains DVC files:\r\n  - echo 'Starting DVC Clone...`\r\n  - FDS will start a wizard to set the user name and password for each remote storage in the local config. (consider checking if they are set in the global config file first?)\r\n  - FDS will pull all the files from the remotes and show a progress bar (might be reasonable to ask if the user wants to pull the files from each remote)\r\n \r\nIt doesn't contain DVC files:\r\n  - FDS will initialize DVC\r\n  \r\n    if the Git server URL is DAGsHub's:\r\n      - FDS will set DAGsHub storage as the remote using the Git URL (replacing`.git` with `.dvc`).\r\n      - FDS will start a wizard to set the remote user name, password, and name.\r\n      \r\n    else:\r\n       - FDS will start a wizard asking do you want to set a DVC remote\r\n       if yes:\r\n           - With the wizard, the user will set the remote URL, name, username, and password.\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"DVC",
        "Platform":"Github",
        "Issue_original_content":"fsd clone non repo throw error fd clone non repo throw follow error error insid repositori check mount point clone non repo fd common us case clone dagshub repo contain file track nur repo contain config file suggest clone git server fd check repo contain file contain file echo start clone fd start wizard set user password remot storag local config consid check set global config file fd pull file remot progress bar reason ask user want pull file remot contain file fd initi git server url dagshub fd set dagshub storag remot git url replac git fd start wizard set remot user password fd start wizard ask want set remot ye wizard user set remot url usernam password",
        "Issue_preprocessed_content":"fsd clone non repo throw non repo throw clone non repo fd us case clone dagshub repo contain file track nur repo contain config file clone git server fd check repo contain file contain file echo start fd start wizard set user remot storag local config fd file remot bar contain file fd initi git server url dagshub fd set dagshub storag remot git url fd start wizard set remot user fd start wizard ask want set remot ye wizard user set remot url usernam",
        "Issue_gpt_summary_original":"The user encountered an issue where the markdown in the dvc install prompt is not being rendered as markdown.",
        "Issue_gpt_summary":"user encount issu markdown instal prompt render markdown",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/DagsHub\/fds\/issues\/39",
        "Issue_title":"Fails to add files to DVC tracking",
        "Issue_created_time":1622120972000,
        "Issue_closed_time":1622139051000,
        "Issue_body":"When running the `fds add` command for data files it tries to add them to DVC tracking but fails.\r\n\r\nIn my case I tried to add the raw-data directory that contains the following image files:\r\n```\r\n$ tree data\/raw-data\r\ndata\/raw-data\r\n\u251c\u2500\u2500 IM-0001-0001.jpeg\r\n\u251c\u2500\u2500 IM-0003-0001.jpeg\r\n\u251c\u2500\u2500 IM-0005-0001.jpeg\r\n\u251c\u2500\u2500 IM-0006-0001.jpeg\r\n\u251c\u2500\u2500 IM-0007-0001.jpeg\r\n\u251c\u2500\u2500 IM-0009-0001.jpeg\r\n\u251c\u2500\u2500 IM-0010-0001.jpeg\r\n\u251c\u2500\u2500 IM-0011-0001-0001.jpeg\r\n\u251c\u2500\u2500 IM-0011-0001-0002.jpeg\r\n\u251c\u2500\u2500 IM-0011-0001.jpeg\r\n\u251c\u2500\u2500 IM-0013-0001.jpeg\r\n\u251c\u2500\u2500 IM-0015-0001.jpeg\r\n\u251c\u2500\u2500 IM-0016-0001.jpeg\r\n\u251c\u2500\u2500 IM-0017-0001.jpeg\r\n....\r\n```\r\nBut fds failed to execute the add command:\r\n```\r\n$ fds add data\/raw-data\r\n========== Make your selection, Press \"h\" for help ==========\r\n\r\nDVC add failed to execute\r\n```",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"DVC",
        "Platform":"Github",
        "Issue_original_content":"fail add file track run fd add command data file tri add track fail case tri add raw data directori contain follow imag file tree data raw data data raw data jpeg jpeg jpeg jpeg jpeg jpeg jpeg jpeg jpeg jpeg jpeg jpeg jpeg jpeg fd fail execut add command fd add data raw data select press help add fail execut",
        "Issue_preprocessed_content":"fail file track data file tri track fail case tri directori contain imag file fd fail execut",
        "Issue_gpt_summary_original":"The user is facing an issue where the \"delete\" action just removes the base image file, which is not correct as the base images are under control by DVC. The right way to remove a file that has been previously added to DVC is using its remove command, which removes the file pointer. The deletion of the base image is not needed because it is not actually in the repository. The right way to do the deletion would be using DVC remove command, which is already available in the wrapper, and is how it must be implemented in the action.",
        "Issue_gpt_summary":"user face issu delet action remov base imag file correct base imag control right wai remov file previous ad remov command remov file pointer delet base imag need actual repositori right wai delet remov command avail wrapper implement action",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/DagsHub\/fds\/issues\/37",
        "Issue_title":"Only display the DVC add prompt if there is anything to add",
        "Issue_created_time":1622117855000,
        "Issue_closed_time":1622551859000,
        "Issue_body":"Currently, it will display always display\r\n`========== Make your selection, Press \"h\" for help ==========`\r\neven if there is no selection to make since the list of files is empty\r\n\r\nhttps:\/\/github.com\/DAGsHub\/fds\/blob\/a8fea54f59131d3ddea4df5184adeee3ecc9998f\/fds\/services\/dvc_service.py#L119",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"Fixed in #46 ",
        "Tool":"DVC",
        "Platform":"Github",
        "Issue_original_content":"displai add prompt add current displai displai select press help select list file http github com dagshub fd blob afeafdddeadfadeeeeccf fd servic servic",
        "Issue_preprocessed_content":"displai prompt displai displai select list file",
        "Issue_gpt_summary_original":"The user is facing challenges with the current implementation of the rename action in DVC, which uses shutils' mv command to rename the base image. This approach is invalid as it creates two identical files with different names when a DVC pull is performed. The user suggests using the dvc rename command to rename the actual file, pointer, and update the path property for consistency.",
        "Issue_gpt_summary":"user face challeng current implement renam action us shutil command renam base imag approach invalid creat ident file differ name pull perform user suggest renam command renam actual file pointer updat path properti consist",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/DagsHub\/fds\/issues\/13",
        "Issue_title":"Markdown in dvc install prompt isn't rendered as markdown",
        "Issue_created_time":1621771875000,
        "Issue_closed_time":1621785253000,
        "Issue_body":"`Should we install dvc[https:\/\/dvc.org\/] (`pip install dvc <3`) for you right now?`\r\nhttps:\/\/github.com\/DAGsHub\/fds\/blob\/6e93c2b3259a7601f392c09604a60fc0ff360ad8\/fds\/run.py#L27",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"DVC",
        "Platform":"Github",
        "Issue_original_content":"markdown instal prompt isn render markdown instal http org pip instal right http github com dagshub fd blob ecbafcafcffad fd run",
        "Issue_preprocessed_content":"markdown prompt isn render markdown pip",
        "Issue_gpt_summary_original":"The user is facing an issue with the load_dataset function from Hugging Face as it is unable to access the DVC tracked data directory due to a data loading bug. The error message displayed is \"OSError: [Errno 30] Read-only file system: '\/data'\".",
        "Issue_gpt_summary":"user face issu load dataset function hug face unabl access track data directori data load bug error messag displai oserror errno read file data",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Nautilus-Cyberneering\/nautilus-librarian\/issues\/79",
        "Issue_title":"Use DVC remove instead of just removing the base image file",
        "Issue_created_time":1643114302000,
        "Issue_closed_time":1643645434000,
        "Issue_body":"The problem described in this issue es very similar to #77 .\r\n\r\nCurrently, the \"delete\" action just removes the base image file. This is not correct for some reasons:\r\n\r\n- The base images are under control by DVC. The right way to remove a file that has been previously added to DVC is using its remove command, which removes the file pointer.\r\n- The deletion of the base image is not needed because it is not actually in the repository: it is pushed to the DVC remote storage during the base image generation and does not persist after this finishes. In case that the file were in the working tree because it was pulled at the beginning of some workflow execution, we can remove it just for good practices, but it would be removed at the end of the execution anyhow.\r\n\r\nTo summarize: the right way to do the deletion would be using DVC _remove_ command, which is already available in the wrapper, and is how it must be implemented in the action.\r\n",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"DVC",
        "Platform":"Github",
        "Issue_original_content":"us remov instead remov base imag file problem describ issu similar current delet action remov base imag file correct reason base imag control right wai remov file previous ad remov command remov file pointer delet base imag need actual repositori push remot storag base imag gener persist finish case file work tree pull begin workflow execut remov good practic remov end execut summar right wai delet remov command avail wrapper implement action",
        "Issue_preprocessed_content":"us remov instead remov base imag file problem describ similar delet action remov base imag file reason base imag control right wai remov file previous remov remov file pointer delet base imag repositori push remot storag base imag gener persist finish case file work workflow execut remov practic remov end execut right wai delet avail implement action",
        "Issue_gpt_summary_original":"The user is facing an issue with the missing \"params\" field for the evaluate stage in their dvc.yaml file.",
        "Issue_gpt_summary":"user face issu miss param field evalu stage yaml file",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Nautilus-Cyberneering\/nautilus-librarian\/issues\/77",
        "Issue_title":"Use DVC move instead of system's mv in rename action",
        "Issue_created_time":1642662749000,
        "Issue_closed_time":1643122571000,
        "Issue_body":"The current implementation of the rename action (to be triggered when the \"rename\" section of the DVC diff contains elements) includes the actual rename of the base image using the shutils' mv command. \r\n\r\n```python\r\nguard_that_base_image_exists(base_filename_old)\r\ncreate_output_folder(base_filename_new)\r\nmove(f\"{base_filename_old}\", f\"{base_filename_new}\")\r\n```\r\n\r\nThis rename is to be committed afterwards so that the rename of the base image is applied to the main branch.\r\n\r\nHowever, this approach is invalid:\r\n\r\n- If only the actual file is renamed, when a DVC pull is performed, the file with the previous name will be pulled. We will get two identical files with different names.\r\n- Nor can we just rename the pointer (.dvc file), as the pointer file name is irrelevant to DVC. The _path_ property inside the pointer is what determines the filename of the pulled file.\r\n\r\nThe right, convenient way to implement the file rename action is using the **dvc rename** command that performs all these actions:\r\n\r\n- Rename the actual file\r\n- Rename the pointer\r\n- Update the _path_ property\r\n\r\nFor consistency, we should use our DVC wrapper. If the move command is not wrapped there, we can do it as part of this issue.",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"DVC",
        "Platform":"Github",
        "Issue_original_content":"us instead renam action current implement renam action trigger renam section diff contain element includ actual renam base imag shutil command python guard base imag exist base filenam old creat output folder base filenam new base filenam old base filenam new renam commit renam base imag appli main branch approach invalid actual file renam pull perform file previou pull ident file differ name renam pointer file pointer file irrelev path properti insid pointer determin filenam pull file right conveni wai implement file renam action renam command perform action renam actual file renam pointer updat path properti consist us wrapper command wrap issu",
        "Issue_preprocessed_content":"us instead renam action implement renam action includ actual renam base imag shutil renam renam base imag main branch invalid actual file renam perform file previou ident file name renam pointer pointer file properti insid pointer determin filenam file right conveni wai implement file renam action renam perform action renam actual file renam pointer updat properti consist us",
        "Issue_gpt_summary_original":"The user is facing a DVC bad request issue while using Minio.",
        "Issue_gpt_summary":"user face bad request issu minio",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/johannespischinger\/senti_anal\/issues\/11",
        "Issue_title":"data loading bug with dvc",
        "Issue_created_time":1641729327000,
        "Issue_closed_time":1642070875000,
        "Issue_body":"load_dataset function from hugging face can't access the dvc tracked data directory \r\n--> OSError: [Errno 30] Read-only file system: '\/data'",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"What command are you using? Note `\/data` is not same as `.\/data`",
        "Tool":"DVC",
        "Platform":"Github",
        "Issue_original_content":"data load bug load dataset function hug face access track data directori oserror errno read file data",
        "Issue_preprocessed_content":"data load bug function face track data directori file",
        "Issue_gpt_summary_original":"The user is facing an issue with the \"dvc-cc init\" command as it only takes the first three letters of the repository name for the DVC folder name. The user is also prompted to enter the remote DVC folder and username for accessing the DVC storage server.",
        "Issue_gpt_summary":"user face issu init command take letter repositori folder user prompt enter remot folder usernam access storag server",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/se4ai2122-cs-uniba\/CT-COVID\/issues\/30",
        "Issue_title":"Missing params field for evaluate stage in dvc.yaml",
        "Issue_created_time":1638704752000,
        "Issue_closed_time":1638706309000,
        "Issue_body":"",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"DVC",
        "Platform":"Github",
        "Issue_original_content":"miss param field evalu stage yaml ",
        "Issue_preprocessed_content":"param field evalu stage yaml ",
        "Issue_gpt_summary_original":"The user is unable to use \"dvc pull\" in the result branch due to an error message that says \"rmdir: data: Das Ger\u00e4t oder die Ressource ist belegt\" when trying to view the results after successfully completing a job. The issue is related to the sshfs connection that is mounted to use external data. The user has to unmount the \"data\" folder using fusermount -u data before viewing the results and then mount it again to start a new job.",
        "Issue_gpt_summary":"user unabl us pull result branch error messag sai rmdir data da gert oder die ressourc ist belegt try view result successfulli complet job issu relat sshf connect mount us extern data user unmount data folder fusermount data view result mount start new job",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/csia-pme\/csia-pme\/issues\/39",
        "Issue_title":"Resolve DVC Bad request with Minio",
        "Issue_created_time":1670317034000,
        "Issue_closed_time":1670919923000,
        "Issue_body":"![10a2a57d-e765-4359-915e-a60163bd6ec8](https:\/\/user-images.githubusercontent.com\/58698728\/205865653-bf35fb85-19cb-4e95-958e-619d13015db0.jpg)\r\n",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"DVC",
        "Platform":"Github",
        "Issue_original_content":"resolv bad request minio aad abdec http user imag githubusercont com bffb ddb jpg",
        "Issue_preprocessed_content":"resolv bad request minio ",
        "Issue_gpt_summary_original":"The user is unable to call \"dvc-cc run\" as the dvc servername and url are not found. This is due to the dvc\/config file being created with whitespaces, which dvc-cc cannot read. The user has provided additional context including the versions of dvc, faice, and dvc-cc being used.",
        "Issue_gpt_summary":"user unabl run servernam url config file creat whitespac read user provid addit context includ version faic",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/deep-projects\/dvc-cc\/issues\/28",
        "Issue_title":"\"dvc-cc init\" just take three letters for the dvc folder name?",
        "Issue_created_time":1584006633000,
        "Issue_closed_time":null,
        "Issue_body":"CALL DVC-CC INIT just takes the first three letters of the repo name???\r\n\r\nHere you can enter the folder where you want to store the DVC files on the DVC Storage Server.\r\n\tThe remote DVC folder that you want use (default: ~\/*****\/***\/TES): \r\nThe username with that you can access the DVC storage server \"dt1.f4.htw-berlin.de\".\r\n",
        "Issue_answer_count":0,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"DVC",
        "Platform":"Github",
        "Issue_original_content":"init letter folder init take letter repo enter folder want store file storag server remot folder want us default te usernam access storag server htw berlin",
        "Issue_preprocessed_content":"init folder init take repo enter folder want store file storag server remot folder want us usernam storag server",
        "Issue_gpt_summary_original":"The user cloned a GitHub repository and set up the IDE workspace with the `vscode-dvc` extension. However, after checking out a specific branch, the DVC view and Plots Dashboard failed to load, and the Experiments Table showed \"No Experiments to Display.\" Other components loaded, and the DVC virtual environment was loaded via the MS Python extension.",
        "Issue_gpt_summary":"user clone github repositori set id workspac vscode extens check specif branch view plot dashboard fail load experi tabl show experi displai compon load virtual environ load python extens",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/deep-projects\/dvc-cc\/issues\/27",
        "Issue_title":"\"dvc pull\" does not work in the result branch if a sshfs connection is mounted",
        "Issue_created_time":1583006053000,
        "Issue_closed_time":null,
        "Issue_body":"**Describe the bug**\r\n> Entsprechend dem Tutorial habe ich mit sshfs den data Ordner\r\n> gemountet, um externe Daten verwenden zu k\u00f6nnen, was soweit auch\r\n> funktioniert.\r\n> Wenn ich dann aber nach erfolgreich abgeschlossenem Job die Ergebnisse\r\n> ansehen will (git pull, git checkout rcc_00XX_ergebnis_branch, dvc\r\n> pull), bekomme ich eine Fehlermeldung:\r\n> \r\n> rmdir: data: Das Ger\u00e4t oder die Ressource ist belegt\r\n> \r\n> Wenn ich vorher mit fusermount -u data den Dataordner wieder unmounte,\r\n> funktioniert alles wie erwartet. Ist das das zu erwartende Verhalten?\r\n> Muss ich also \"data\" unmounten, um die Ergebnisse ansehen zu k\u00f6nnen?\r\n> Und dann erneut mounten, um einen neuen Job zu starten?\r\n\r\n> dvc -V 0.87.0\r\n> faice -v 9.1.0\r\n> dvc-cc -v 0.8.66",
        "Issue_answer_count":0,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"DVC",
        "Platform":"Github",
        "Issue_original_content":"pull work result branch sshf connect mount bug entsprechend dem tutori habe ich mit sshf den data ordner gemountet extern daten verwenden knnen soweit auch funktioniert wenn ich dann aber nach erfolgreich abgeschlossenem job die ergebniss ansehen git pull git checkout rcc ergebni branch pull bekomm ich ein fehlermeldung rmdir data da gert oder die ressourc ist belegt wenn ich vorher mit fusermount data den dataordn wieder unmount funktioniert all wie erwartet ist da da erwartend verhalten muss ich data unmounten die ergebniss ansehen knnen und dann erneut mounten einen neuen job starten faic",
        "Issue_preprocessed_content":"work result branch mount bug entsprechend dem tutori habe ich mit den data ordner gemountet extern daten verwenden soweit auch funktioniert ich aber nach erfolgreich job die ansehen ich ein fehlermeldung rmdir data da gert oder die ist belegt ich vorher mit fusermount data den dataordn wieder unmount funktioniert wie erwartet ist da da erwartend verhalten ich data unmounten die ansehen und erneut mounten einen neuen job starten faic",
        "Issue_gpt_summary_original":"The user is encountering an error while trying to use the \"dvc pull\" command, which requires mantis credentials and is not publicly accessible. The error message states that the user does not have permission to access the object, resulting in a 403 Forbidden error. To resolve the issue, the user needs to make the bucket public and read-only.",
        "Issue_gpt_summary":"user encount error try us pull command requir manti credenti publicli access error messag state user permiss access object result forbidden error resolv issu user need bucket public read",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/deep-projects\/dvc-cc\/issues\/26",
        "Issue_title":"dvc servername and url not found by calling \"dvc-cc run\"",
        "Issue_created_time":1583005907000,
        "Issue_closed_time":null,
        "Issue_body":"**Describe the bug**\r\nIf the dvc\/config file is created with whitespaces dvc-cc cann't read the config file.\r\n\r\n**To Reproduce**\r\nCreate a dvc\/config file like this:\r\n`[core]\r\n    remote = dvc_connection\r\n['remote \"dvc_connection\"']\r\n    url = ...............\r\n    ask_password = true\r\n\r\n**Additional context**\r\n> dvc -V 0.87.0\r\n> faice -v 9.1.0\r\n> dvc-cc -v 0.8.66\r\n",
        "Issue_answer_count":0,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"DVC",
        "Platform":"Github",
        "Issue_original_content":"servernam url call run bug config file creat whitespac cann read config file reproduc creat config file like core remot connect remot connect url ask password true addit context faic",
        "Issue_preprocessed_content":"servernam url run bug config file creat whitespac read config file reproduc creat config file like remot remot url true context faic",
        "Issue_gpt_summary_original":"The user is facing an issue where the post-gen hook is trying to configure a DVC remote even when no name is provided, resulting in a non-fatal error. The user suggests that the hook should not attempt to set a remote if no name is given.",
        "Issue_gpt_summary":"user face issu post gen hook try configur remot provid result non fatal error user suggest hook attempt set remot given",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/iterative\/dvc-checkpoints-mnist\/issues\/20",
        "Issue_title":"DVC View and Plots don't load in `vscode-dvc`",
        "Issue_created_time":1655687938000,
        "Issue_closed_time":null,
        "Issue_body":"UPDATE: Summary in https:\/\/github.com\/iterative\/dvc-checkpoints-mnist\/issues\/20#issuecomment-1164570090\r\n\r\nI cloned https:\/\/github.com\/iterative\/dvc-checkpoints-mnist. I setup the IDE workspace so the extension is active.\r\n\r\nI haven't run any experiments:\r\n![image](https:\/\/user-images.githubusercontent.com\/1477535\/174509065-ac8f2c97-0d7f-4b1f-b6c4-e36603406c50.png)\r\n\r\nI check out the [`make_checkpoint`](https:\/\/github.com\/iterative\/dvc-checkpoints-mnist\/tree\/make_checkpoint) branch. The DVC view and Plots Dashboard never load.\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/1477535\/174508899-c1e5788a-2ead-446d-bab6-0239cbc27519.png)\r\n\r\nThe Experiments Table says \"No Experiments to Display.\"\r\n\r\nOther components do load.\r\n\r\nDVC virtual env is loaded via MS Python extension.\r\n\r\n```console\r\n$ dvc version\r\nDVC version: 2.11.0 (pip)\r\n---------------------------------\r\nPlatform: Python 3.9.13 on macOS-12.4-arm64-arm-64bit\r\nSupports:\r\n        webhdfs (fsspec = 2022.5.0),\r\n        http (aiohttp = 3.8.1, aiohttp-retry = 2.4.6),\r\n        https (aiohttp = 3.8.1, aiohttp-retry = 2.4.6)\r\nCache types: <https:\/\/error.dvc.org\/no-dvc-cache>\r\nCaches: local\r\nRemotes: None\r\nWorkspace directory: apfs on \/dev\/disk3s1s1\r\nRepo: dvc, git\r\n```\r\n\r\n---\r\n\r\n~~p.s. the same happens in the included `demo\/` project if I set up the extension with `\"dvc.dvcPath\": \"demo\/.env\/bin\/dvc\"` in .vscode\/settings.json (no MS Python extension).~~",
        "Issue_answer_count":11,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"DVC",
        "Platform":"Github",
        "Issue_original_content":"view plot load vscode updat summari http github com iter checkpoint mnist issu issuecom clone http github com iter checkpoint mnist setup id workspac extens activ haven run experi imag http user imag githubusercont com acfc png check checkpoint http github com iter checkpoint mnist tree checkpoint branch view plot dashboard load imag http user imag githubusercont com cea ead bab cbc png experi tabl sai experi displai compon load virtual env load python extens consol version version pip platform python maco arm arm bit support webhdf fsspec http aiohttp aiohttp retri http aiohttp aiohttp retri cach type cach local remot workspac directori apf dev diskss repo git happen includ demo project set extens path demo env bin vscode set json python extens",
        "Issue_preprocessed_content":"view plot load updat clone setup id workspac extens activ haven run experi check branch view plot dashboard load experi tabl sai experi compon load virtual env load python extens includ project set extens",
        "Issue_gpt_summary_original":"The user encountered an error while using the `dvclive` package in their `train.py` file. They received an `AttributeError` stating that the module 'dvclive' has no attribute 'log'. They were only able to run the example by using a workaround of importing `Live` from `dvclive`. The user is questioning if there have been any updates to the `dvclive` API.",
        "Issue_gpt_summary":"user encount error live packag train file receiv attributeerror state modul live attribut log abl run exampl workaround import live live user question updat live api",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/MantisAI\/Rasa-MLOPs\/issues\/5",
        "Issue_title":"Remote storage is not publicly accessible (dvc pull fails)",
        "Issue_created_time":1634634148000,
        "Issue_closed_time":1668173479000,
        "Issue_body":"`ERROR: unexpected error - Forbidden: An error occurred (403) when calling the HeadObject operation: Forbidden`\r\n\r\n`dvc pull` needs mantis creds so a reader will not be able to follow. we need to make the bucket public and read only.",
        "Issue_answer_count":4,
        "Issue_self_closed":1.0,
        "Answer_body":"So:\r\n1. You will need to have aws credentials set up with `aws configure`, having installed awscli (which is in the virtualenv)\r\n2. I'm having some issues getting the mantisnlp-public bucket to be accessible to dvc with a non mantis aws profile. I don't know if this is related but did you try `--acl public-read`? I had some problems with public buckets in grants tagger and for me it was resolved by adding this flag. example https:\/\/github.com\/wellcometrust\/grants_tagger\/blob\/970abbc63b448c4d14d7b70fa13ca29760a897ce\/Makefile#L94 I've done this at the bucket level, not at the individual object level, because they are added by dvc. It _should_ be working... btw this issue is probably badly named because:\r\n1. You only need to set `AWS_PROFILE` if you have more than one set of aws credentials\r\n2. You can also set `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` in the folder to the same effect, and users can decide how best to do this.",
        "Tool":"DVC",
        "Platform":"Github",
        "Issue_original_content":"remot storag publicli access pull fail error unexpect error forbidden error occur call headobject oper forbidden pull need manti cred reader abl follow need bucket public read",
        "Issue_preprocessed_content":"remot storag publicli manti cred reader abl bucket public read",
        "Issue_gpt_summary_original":"The user is encountering a \"FileNotFoundError\" while trying to run the \"kedro mlflow ui\" command after running \"kedro mlflow init\" command. The error message indicates that the 'mlflow_tracking_uri' key in mlflow.yml is relative and is converted to a valid uri.",
        "Issue_gpt_summary":"user encount filenotfounderror try run command run init command error messag indic track uri kei yml rel convert valid uri",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/adamtupper\/cookiecutter-lvsn-workflow\/issues\/9",
        "Issue_title":"Post-gen hook shouldn't configure a DVC remote if no name is provided",
        "Issue_created_time":1623947751000,
        "Issue_closed_time":null,
        "Issue_body":"If the DVC remote name is left blank, the post-gen hook shouldn't try to set one. Currently this raises a (non-fatal) error.",
        "Issue_answer_count":0,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"DVC",
        "Platform":"Github",
        "Issue_original_content":"post gen hook shouldn configur remot provid remot left blank post gen hook shouldn try set current rais non fatal error",
        "Issue_preprocessed_content":"shouldn configur remot provid remot left blank shouldn try set rais",
        "Issue_gpt_summary_original":"The user has encountered an issue where the success message is displayed even if the environment folder does not exist while running \"kedro mlflow init --env=xxx\". The user suggests moving the code inside the \"try\" block to display an error message instead of a success message.",
        "Issue_gpt_summary":"user encount issu success messag displai environ folder exist run init env xxx user suggest move code insid try block displai error messag instead success messag",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/iterative\/checkpoints-tutorial\/issues\/1",
        "Issue_title":"AttributeError: module 'dvclive' has no attribute 'log'",
        "Issue_created_time":1633694389000,
        "Issue_closed_time":1633697794000,
        "Issue_body":"I try to follow this Checkpoints tutorial and documentation page https:\/\/dvc.org\/doc\/user-guide\/experiment-management\/checkpoints \r\n\r\nHowever, after adding `dvclive` in the train.py file with this code: \r\n\r\n import the dvclive package with the other imports:\r\n\r\n```python\r\nimport dvclive\r\n...\r\n    ...\r\n    for k, v in metrics.items():\r\n        print('Epoch %s: %s=%s'%(i, k, v))\r\n        dvclive.log(k, v)\r\n    dvclive.next_step()\r\n```\r\nI got an error: \r\n```bash \r\n\u276f dvc exp run\r\nModified checkpoint experiment based on 'exp-defaa' will be created   \r\nRunning stage 'train':                                                                                                                                                                                                                                               \r\n> python train.py\r\n...\r\nEpoch 1: loss=0.1541447937488556\r\nTraceback (most recent call last):\r\n  File \"[USER-PATH]\/checkpoints-tutorial\/train.py\", line 125, in <module>\r\n    main()\r\n  File \"[USER-PATH]\/checkpoints-tutorial\/train.py\", line 118, in main\r\n    dvclive.log(name=k, val=v)\r\nAttributeError: module 'dvclive' has no attribute 'log'\r\n\r\nfile:\/\/\/[USER-PATH]\/checkpoints-tutorial\/dvclive.html\r\nERROR: failed to reproduce 'dvc.yaml': failed to run: python train.py, exited with 1\r\n``` \r\n\r\nI only could run the example with the following trick: \r\n```python\r\nfrom dvclive import Live \r\ndvclive = Live()\r\n```\r\nAre there any updated in `dvclive` API? \r\n\r\nSystem info\r\n```bash \r\n\u276f dvc doctor\r\nDVC version: 2.6.4 (pip)\r\n---------------------------------\r\nPlatform: Python 3.9.4 on macOS-11.6-x86_64-i386-64bit\r\nSupports:\r\n        hdfs (pyarrow = 5.0.0),\r\n        http (requests = 2.26.0),\r\n        https (requests = 2.26.0)\r\nCache types: reflink, hardlink, symlink\r\nCache directory: apfs on \/dev\/disk1s1s1\r\nCaches: local\r\nRemotes: None\r\nWorkspace directory: apfs on \/dev\/disk1s1s1\r\nRepo: dvc, git\r\n```\r\n\r\nFIY @flippedcoder @daavoo ",
        "Issue_answer_count":2,
        "Issue_self_closed":0.0,
        "Answer_body":"Thanks for the catch @mike0sv ! No trouble (literally, no trouble at all since it was @mnrozhkov :))",
        "Tool":"DVC",
        "Platform":"Github",
        "Issue_original_content":"attributeerror modul live attribut log try follow checkpoint tutori document page http org doc user guid experi manag checkpoint ad live train file code import live packag import python import live metric item print epoch live log live step got error bash exp run modifi checkpoint experi base exp defaa creat run stage train python train epoch loss traceback recent file user path checkpoint tutori train line main file user path checkpoint tutori train line main live log val attributeerror modul live attribut log file user path checkpoint tutori live html error fail reproduc yaml fail run python train exit run exampl follow trick python live import live live live updat live api info bash doctor version pip platform python maco bit support hdf pyarrow http request http request cach type reflink hardlink symlink cach directori apf dev diskss cach local remot workspac directori apf dev diskss repo git fii flippedcod daavoo",
        "Issue_preprocessed_content":"modul live log try checkpoint tutori document page file code import live packag import got run exampl trick updat api info fii",
        "Issue_gpt_summary_original":"The user is facing an issue with the kedro-mlflow plugin not working with projects created with kedro==0.18.1. When the user tries to run the pipeline, an error is raised due to the removal of the private attribute '_active_session' in kedro==0.18.1. The solution is to use the 'after_context_created' hook to retrieve and set up the configuration.",
        "Issue_gpt_summary":"user face issu plugin work project creat user tri run pipelin error rais remov privat attribut activ session solut us context creat hook retriev set configur",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/issues\/361",
        "Issue_title":"kedro mlflow ui gets a FileNotFoundError",
        "Issue_created_time":1664539296000,
        "Issue_closed_time":1664786016000,
        "Issue_body":"Firstly I'd like to apologize if this is a dummy question.\r\nI'm following the tutorial to get introduced to kedro mlflow,; after running the command \"kedro mlflow init\" I tried to run the command \"kedro mlflofw ui\" but I get an error:\r\n\r\nINFO     The 'mlflow_tracking_uri' key in mlflow.yml is relative ('server.mlflow_tracking_uri = mlruns'). It is converted to a valid uri: 'file:\/\/\/C:\/Users\/e107338\/PycharmProjects\/mlflow\/kedro-mlflow-example\/mlruns'                                                   kedro_mlflow_config.py:202\r\n\r\nAfter the Traceback I get an error: FileNotFoundErrror\r\n",
        "Issue_answer_count":2,
        "Issue_self_closed":1.0,
        "Answer_body":"Hi, \r\n\r\nI am sorry to see you are experiencing issues. this is not a dummy question, it sounds like a bug. \r\n\r\nI've just ran this: \r\n\r\n```bash\r\nconda create -n km-361 python=3.9 -y\r\nconda activate km-361\r\npip install kedro==0.18.3\r\npip install mlflow==1.29.0\r\npip install kedro-mlflow==0.11.3\r\nkedro new --starter=pandas-iris\r\ncd iris\r\nkedro mlflow init\r\nkedro mlflow ui\r\n```\r\n\r\nthen I opened ``http:\/\/127.0.0.1:5000`` and th UI opened as expected. \r\n\r\nCan you tell me: \r\n- your python version\r\n- your OS\r\n- your ``kedro`` \/ ``mlflow`` \/ ``kedro-mlflow`` version\r\n- the project using\r\n- the exact error message\r\n- check if you have a ``MLFLOW_TRACKING_URI`` environment set It turned out fine  after trying again! Sorry and thanks for your consideration!",
        "Tool":"Kedro",
        "Platform":"Github",
        "Issue_original_content":"get filenotfounderror firstli like apolog dummi question follow tutori introduc run command init tri run command mlflofw error info track uri kei yml rel server track uri convert valid uri file user pycharmproject exampl config traceback error filenotfounderrror",
        "Issue_preprocessed_content":"get firstli like apolog question tutori introduc init tri run mlflofw info kei yml rel convert valid uri traceback",
        "Issue_gpt_summary_original":"The user is facing an issue with KedroPipelineModel where unnecessary pipeline input dependencies are required to execute. The `initial_catalog` property is causing problems as it contains some Kedro Datasets that are not necessary to train the model. The user used a Kedro plugin to load a specific dataset during training, but after updating the plugin, the model cannot be loaded as the load function uses the old Kedro Catalog with the old plugin version. The user suggests logging only necessary information in MLflow to avoid this issue. The user hopes for a solution where the Kedro Catalog can be updated without having to retrain the models.",
        "Issue_gpt_summary":"user face issu pipelinemodel unnecessari pipelin input depend requir execut initi catalog properti caus problem contain dataset necessari train model user plugin load specif dataset train updat plugin model load load function us old catalog old plugin version user suggest log necessari inform avoid issu user hope solut catalog updat have retrain model",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/issues\/336",
        "Issue_title":"kedro mlflow init displays a wrong sucess message when the env folder does not exist",
        "Issue_created_time":1656532075000,
        "Issue_closed_time":1657139268000,
        "Issue_body":"## Description\r\n\r\nWhen running ``kedro mlflow init --env=xxx``, a success message is displayed even if the env \"xxx\" folder does not exist, instead of an error message. We should move this code : \r\n\r\nhttps:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/blob\/d31820a7d4ea808d0a4460d41966b762a404b5a5\/kedro_mlflow\/framework\/cli\/cli.py#L116-L122\r\n\r\ninside the \"try\" block above.",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"Kedro",
        "Platform":"Github",
        "Issue_original_content":"init displai wrong sucess messag env folder exist descript run init env xxx success messag displai env xxx folder exist instead error messag code http github com galileo galilei blob dadeadadbaba framework cli cli insid try block",
        "Issue_preprocessed_content":"init displai wrong env folder exist descript displai env folder exist instead code insid try block",
        "Issue_gpt_summary_original":"The user is unable to initialize the kedro-mlflow project as the CLI commands are not available. The user has tried to create a Kedro project using the starter `pandas-iris` and installing kedro-mlflow, but the `mlflow` command is unknown to Kedro inside the project folder. The user is seeking advice on how to fix this issue. The bug also happens with the last version on master.",
        "Issue_gpt_summary":"user unabl initi project cli command avail user tri creat project starter panda iri instal command unknown insid project folder user seek advic fix issu bug happen version master",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/issues\/309",
        "Issue_title":"kedro-mlflow is broken with kedro==0.18.1",
        "Issue_created_time":1652380533000,
        "Issue_closed_time":1652640252000,
        "Issue_body":"## Description\r\n\r\nThe plugin does not work with projects created with ``kedro==0.18.1``\r\n\r\n## Context\r\n\r\nTry to launch ``kedro run`` in a project with ``kedro==0.18.1`` and kedro-mlflow installed.\r\n\r\n\r\n## Steps to Reproduce\r\n\r\n```python\r\nconda create -n temp python=3.8 -y\r\nconda activate temp\r\npip install kedro==0.18.1 kedro-mlflow==0.9.0\r\nkedro new --starter=pandas-iris\r\ncd pandas-iris\r\nkedro mlflow init\r\nkedro run\r\n```\r\n\r\n## Expected Result\r\n\r\nThis should run the pipeleine and log the parameters.\r\n\r\n## Actual Result\r\n\r\nThis raises the following error:\r\n\r\n```bash\r\nAttributeError: module 'kedro.framework.session.session' has no attribute '_active_session'\r\n```\r\n\r\n## Your Environment\r\n\r\nInclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* `kedro` and `kedro-mlflow` version used (`pip show kedro` and `pip show kedro-mlflow`): ``kedro==0.18.1`` and ``kedro-mlflow<=0.9.0``\r\n* Python version used (`python -V`): All\r\n* Operating system and version: All\r\n\r\n## Does the bug also happen with the last version on master?\r\n\r\nYes\r\n\r\n## Solution\r\n\r\nCurrently, kedro-mlflow uses [the private ``_active_session`` global variable to access the configuration](https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/blob\/e855f59faa76c881b32616880608d41c064c23a0\/kedro_mlflow\/config\/kedro_mlflow_config.py#L233-L247) inside a hook. \r\n\r\nWith kedro==0.18.1, this private attribute was removed and the new recommandation is to use the ``after_context_created`` hook. \r\n\r\nRetrieving the configuration and set it up should be moved to this new hook:\r\n\r\nhttps:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/blob\/963c338d6259dd118232c45801abe0a2b0a463df\/kedro_mlflow\/framework\/hooks\/pipeline_hook.py#L108-L109",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"Closed by #313 ",
        "Tool":"Kedro",
        "Platform":"Github",
        "Issue_original_content":"broken descript plugin work project creat context try launch run project instal step reproduc python conda creat temp python conda activ temp pip instal new starter panda iri panda iri init run expect result run pipelein log paramet actual result rais follow error bash attributeerror modul framework session session attribut activ session environ includ relev detail environ experienc bug version pip pip python version python oper version bug happen version master ye solut current us privat activ session global variabl access configur http github com galileo galilei blob effaacbdcca config config insid hook privat attribut remov new recommand us context creat hook retriev configur set move new hook http github com galileo galilei blob cdddcabeabadf framework hook pipelin hook",
        "Issue_preprocessed_content":"broken descript plugin work project creat context try launch project step reproduc expect result run pipelein log paramet actual result rais environ includ relev detail environ experienc bug python version oper version bug version master ye solut us insid privat remov new us retriev configur set move new",
        "Issue_gpt_summary_original":"The user is facing an issue where the `ui` command in `kedro mlflow` is not using the options specified in the `mlflow.yml` file. The expected result is for the MLflow UI to open on port 5001, but it opens on the default port 5000. The user's environment includes `kedro` version 0.17.0, `kedro-mlflow` version 0.6.0, Python version 3.6.8, and Windows operating system. The solution is to pass the arguments in the command.",
        "Issue_gpt_summary":"user face issu command option specifi yml file expect result open port open default port user environ includ version version python version window oper solut pass argument command",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/issues\/273",
        "Issue_title":"KedroPipelineModel requires unnecessary pipeline input dependencies to be executed",
        "Issue_created_time":1640015142000,
        "Issue_closed_time":1644791409000,
        "Issue_body":"Hi @Galileo-Galilei\r\n\r\n## Description\r\nthe KedroPipelineModel has a `initial_catalog` property which causes some problems. This `initial_catalog` can contain some Kedro Datasets but it's not necessary to log them when you train your model. because of this property I can't load my model anymore. I have to train it again.\r\n\r\nI explain : when I trained my model I used a kedro home-made plugin to load a specific dataset (which has no impact for my model). After that, I updated this plugin independently of my ML project. Today, I want to load my model but I can't because the load function uses the old Kedro Catalog with my old plugin version which is not in my environnement anymore. \r\n\r\n## Context\r\nIt would be great if we can update the kedro-catalog (only dataset and not the artifacts for the model of course !) without having to retrain our models.\r\n\r\n## Possible Implementation\r\nLog in Mlflow what is only necessary.\r\n\r\nI hope my issue is clear.\r\n\r\nthank you",
        "Issue_answer_count":2,
        "Issue_self_closed":0.0,
        "Answer_body":"Hi, I can reproduce the issue, thank you very much for the feedback. To clarify, what happens here is the following: \r\n\r\n- the input of your inference pipeline is persisted in Kedro because you load it from the disk (e.g., pandas.ExcelDataSet)\r\n- after you log it in mlflow, it will be converted to a ``MemoryDataSet``, and you directly pass a pandas Dataframe when you want to reuse it. Mlflow complains that you need to have ``openpyxl`` installed, while you never use it in your pipeline, and you don't need it to predict.\r\n\r\nThis extra dependency is not useful as you mention. I will remove it in a patch release soon.\r\n\r\n For anyone having the same issue, notice that you can now export a pipeline as a mlflow model with the [``kedro mlflow modelify``](https:\/\/kedro-mlflow.readthedocs.io\/en\/stable\/source\/05_pipeline_serving\/03_cli_modelify.html) command.",
        "Tool":"Kedro",
        "Platform":"Github",
        "Issue_original_content":"pipelinemodel requir unnecessari pipelin input depend execut galileo galilei descript pipelinemodel initi catalog properti caus problem initi catalog contain dataset necessari log train model properti load model anymor train explain train model home plugin load specif dataset impact model updat plugin independ project todai want load model load function us old catalog old plugin version environn anymor context great updat catalog dataset artifact model cours have retrain model possibl implement log necessari hope issu clear thank",
        "Issue_preprocessed_content":"pipelinemodel requir pipelin input depend execut descript pipelinemodel properti caus problem contain dataset log train model properti load model anymor train explain train model plugin load specif dataset updat plugin independ project todai want load model load function us old catalog old plugin version anymor context great updat catalog have retrain model implement log hope clear thank",
        "Issue_gpt_summary_original":"The Kedro MLflow CLI is not accessible if the project only contains a pyproject.toml file and not a .kedro.yml file. The only available command is \"new,\" and the project is not considered a Kedro project. The issue is caused by the is_kedro_project function, which does not recognize a folder as the root of a Kedro project if it does not have a .kedro.yml file.",
        "Issue_gpt_summary":"cli access project contain pyproject toml file yml file avail command new project consid project issu caus project function recogn folder root project yml file",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/issues\/193",
        "Issue_title":"kedro-mlflow CLI is unavailable inside a Kedro project",
        "Issue_created_time":1619193727000,
        "Issue_closed_time":1619987466000,
        "Issue_body":"## Description\r\n\r\nI try to reproduce the minimal example from the Docs: a Kedro project using the starter `pandas-iris` using the `kedro-mlflow` functinality. I do not arrive at initializing the kedro-mlflow project, since the cli commands are not available.\r\n\r\n## Context\r\n\r\nIt is unclear to me if this is connected to #157 \r\nI wanted to start looking into kedro-mlflow, but got immediatle blocked by the initialization of the project. Therefore any advice on where to look to fix this would also be appreciated. \r\n\r\n## Steps to Reproduce\r\n\r\n```\r\nconda create -n kedro_mlflow python=3.8\r\nconda activate kedro_mlflow\r\npip install kedro-mlflow\r\nkedro mlflow -h\r\nkedro new --starter=pandas-iris\r\ncd mlflow_test\/\r\nkedro mlflow -h\r\n> ERROR \"No such command 'mlflow'\"\r\n```\r\n\r\n## Expected Result\r\n\r\n`kedro mlflow` is available in a project directory, i.e. `kedro mlflow -h` gives the same output inside the folder as before\r\n\r\n## Actual Result\r\n\r\ninside the project folder the `mlflow` command is unknown to Kedro\r\n\r\n```\r\n...\/miniconda3\/envs\/kedro_mlflow\/lib\/python3.8\/site-packages\/pkg_resources\/__init__.py:1130: DeprecationWarning: Use of .. or absolute path in a resource path is not allowed and will raise exceptions in a future release.\r\n  return get_provider(package_or_requirement).get_resource_filename(\r\n....\/miniconda3\/envs\/kedro_mlflow\/lib\/python3.8\/site-packages\/mlflow\/types\/schema.py:49: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \r\nDeprecated in NumPy 1.20; for more details and guidance: https:\/\/numpy.org\/devdocs\/release\/1.20.0-notes.html#deprecations\r\n  binary = (7, np.dtype(\"bytes\"), \"BinaryType\", np.object)\r\n2021-04-23 17:49:52,197 - root - INFO - Registered hooks from 2 installed plugin(s): kedro-mlflow-0.7.1\r\nUsage: kedro [OPTIONS] COMMAND [ARGS]...\r\nTry 'kedro -h' for help.\r\n\r\nError: No such command 'mlflow'.\r\n\r\n```\r\n\r\n## Your Environment\r\n\r\nUbuntu 18.04.5\r\n\r\n- Kedro 0.17.3\r\n- kedro-mlflow 0.7.1\r\n- python 3.8.8.\r\n- mlflow 1.15.0\r\n\r\n## Does the bug also happen with the last version on master?\r\n\r\nyes",
        "Issue_answer_count":6,
        "Issue_self_closed":0.0,
        "Answer_body":"Hi, \r\n\r\nI wil try to check it out this weekend, but the `kedro==0.17.3` version is brand new (it was released yesterday), and given my experience with past kedro versions update 2 things might have happened on kedro's side: \r\n- They have broken the auto-discovery mechanism (I've seen in the release note that they change the CLI command discovery to enale overriding project commands by plugins)\r\n- They have not updated their `pandas-iris` starter yet which does not match the new version and is only compliant with `kedro==0.17.2`. \r\n\r\nWhile I am investigating, would you please confirm that :\r\n- `kedro-mlflow` works fine with kedro==0.17.2 with your setup\r\n- `kedro-mlflow` works fine if you don't use the `pandas-iris` starter: try `kedro new` with `kedro==0.17.3` and then add one ode to test the plugin\r\n- I'd be glad to see if another plugin (e.g. `kedro-viz`) is facing the same problem that kedro-mlflow. Would you mind checking?\r\n\r\nOf course there is the possibility that the problem comes from `kedro-mlflow` itself, but I hardly believe it. I'll tell you within 2 days. I am sorry, I am quite busy for now and I will not debug this before next week. Once again, it is very likely kedro's plugin discovery mechanism has been broken in the new release, I strongly suggest you go back to `kedro==0.17.2`.\r\n\r\nNext actions: \r\n- [X] reproduce the bug -> Done, thanks for the very good reproducible example\r\n- [X] Check if it happens with other plugins (say kedro-viz) -> `kedro viz` global command is properly discovered\r\n- [X] Check if hooks are properly loaded -> everything works fine if I add a `mlflow.yml` manually in the `conf\/local` folder (or any folder in `conf\/` actually). -> **This is a short term solution for you**,e ven if it is not very convenient. You can find allowed keys [in the documentation](https:\/\/kedro-mlflow.readthedocs.io\/en\/latest\/source\/04_experimentation_tracking\/01_configuration.html#the-mlflow-yml-file) or irectly [copy paste it from the code](https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/blob\/master\/kedro_mlflow\/template\/project\/mlflow.yml)\r\n- [X] Check if the tests pass with kedro==0.17.3 -> *Some tests are failing, but not the one related to the CLI commands which seems discovered. I need to investigate further*.\r\n- [x] Check if other plugins with *local* commands are discovered\r\n- [x] Check if it also happens it an empty project (i.e. *not* a starter)\r\n First of all, thank you for looking so quickly into it!\r\n\r\nFrom how I read your second message you already know that, but to answer your questions:\r\n- detecting `kedro mlflow` works fine with `kedro==0.17.2`\r\n- the problem is consistent with kedro==0.17.3 independent if I use the pandas-iris starter or not\r\n- `kedro viz` is found also with `kedro=0.17.3`\r\n\r\nAgain, thank you for providing workarounds directly on Monday morning, I can nicely work with those! A question for my understanding of the plugin: As long as the hooks are loaded, the mlflow functionality depends only on a `mlflow.yml` to be present, and all that `kedro mlflow init` does is copy this file from the template into `conf\/local`, is this correct? TL;DR: \r\n\r\nInstall this version for now, it should make the command available again:\r\n\r\n```console\r\npip uninstall kedro-mlflow\r\npip install git+https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow.git@bug\/no-cli\r\n```\r\n**Beware:** it is very important to uninstall your existing version of kedro-mlflow before reinstalling because the patch has the same version number that the current release.\r\n\r\nIf you confirm this works for you, I will deploy the patch to PyPI before kedro provides a patch on their side.\r\n_____________________________\r\n\r\nHi, some follow-up about this bug:\r\n\r\n- I've figured out *what* is going on but not *why* it happens. The `mlflow` group of command exists both at global (`new`) and project (`init`, `ui`) levels and for an unknown reason, `kedro` takes into account only one group of command in its `0.17.3` version. This is a bug I will report to the core team. However, it does not affect their other plugins (kedro-viz, kedro-docker, kedro-airflow) because none of them has both global and project commands.\r\n- The quickest (hacky) fix is to remove the global group of command to the make the project ones available. I've done this in the branch `bug\/no-cli` of the repo.\r\n\r\nTo answer your question: \r\n\r\n> A question for my understanding of the plugin: As long as the hooks are loaded, the mlflow functionality depends only on a mlflow.yml to be present, and all that kedro mlflow init does is copy this file from the template into conf\/local, is this correct?\r\n\r\nExactly: the `init` command renders the template (i.e. copy paste it + replace the jinja tags with dynamic values like the name of your project) to a folder in your `conf\/` folder (by default `local`, but you can specify an environment like this: `kedro mlflow init --env=<your-env-folder>`). The hooks contain all the code logic  and this mlflow.yml file is just here to pass parameters to them. \r\n\r\nThe other project command is `kedro mlflow ui` which is just a wrapper of \"mlflow ui\" with the parameters (mlflow_tracking_uri, port, host) defined in your `mlflow.yml` file.\r\n thanks, form a quick test I would say: the patch works like a charm! Hi @dmb23, I've just deployed the patch to PyPI. You can use `pip install kedro_mlflow==0.7.2`` and it should be ok for now. I close the issue, but feel free to reopen if you still encounter any issue in this new version.",
        "Tool":"Kedro",
        "Platform":"Github",
        "Issue_original_content":"cli unavail insid project descript try reproduc minim exampl doc project starter panda iri functin arriv initi project cli command avail context unclear connect want start look got immediatl block initi project advic look fix appreci step reproduc conda creat python conda activ pip instal new starter panda iri test error command expect result avail project directori give output insid folder actual result insid project folder command unknown miniconda env lib python site packag pkg resourc init deprecationwarn us absolut path resourc path allow rais except futur releas return provid packag requir resourc filenam miniconda env lib python site packag type schema deprecationwarn object deprec alia builtin object silenc warn us object modifi behavior safe deprec numpi detail guidanc http numpi org devdoc releas note html deprec binari dtype byte binarytyp object root info regist hook instal plugin usag option command arg try help error command environ ubuntu python bug happen version master ye",
        "Issue_preprocessed_content":"cli unavail insid project descript try reproduc minim exampl doc project starter functin initi project cli avail context unclear want start got block initi project advic fix step reproduc expect result avail project directori give output insid folder actual result insid project folder deprec alia builtin silenc warn us modifi behavior safe deprec numpi detail guidanc binari binarytyp info regist plugin usag try help environ ubuntu python bug version master ye",
        "Issue_gpt_summary_original":"The user is unable to load a previously saved KedroPipelineModel from mlflow due to a \"cannot pickle context artifacts\" error caused by a non-deepcopyable dataset (in this case, a keras tokenizer). The issue occurs with kedro and kedro-mlflow versions 0.16.5 and 0.4.0, and the bug also happens with the latest version on develop. A potential solution involves modifying a line of code in the kedro_mlflow package.",
        "Issue_gpt_summary":"user unabl load previous save pipelinemodel pickl context artifact error caus non deepcopy dataset case kera token issu occur version bug happen latest version develop potenti solut involv modifi line code packag",
        "Issue_score_count":2
    },
    {
        "Issue_link":"https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/issues\/187",
        "Issue_title":"kedro mlflow ui does not use arguments from mlflow.yml",
        "Issue_created_time":1617627646000,
        "Issue_closed_time":1618006798000,
        "Issue_body":"## Description\r\n\r\nAs described in [this stackoverflow question](https:\/\/stackoverflow.com\/questions\/66917129\/specify-host-and-port-in-mlflow-yml-and-run-kedro-mlflow-ui-but-host-and-port), the `ui` command does not use the options\r\n\r\n## Context & Steps to Reproduce\r\n\r\n- Create a kedro project\r\n- Call `kedro mlflow init`\r\n- Modify the port in `mlflow.yml` to 5001\r\n- Launch `kedro mlflow ui`\r\n\r\n## Expected Result\r\n\r\nThe mlflow UI should open in port 5001.\r\n\r\n## Actual Result\r\n\r\nIt opens on port 5000 (the default).\r\n\r\n## Your Environment\r\n\r\nInclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* `kedro` version: 0.17.0\r\n* `kedro-mlflow` version: 0.6.0\r\n* Python version used (`python -V`): 3.6.8\r\n* Operating system and version: Windows\r\n\r\n## Does the bug also happen with the last version on master?\r\n\r\nYes\r\n\r\n## Solution\r\n\r\nWe should pass the arguments in the command: \r\n\r\nhttps:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/blob\/477147f6aa2dbf59c67f916b2002dea2de74d1fd\/kedro_mlflow\/framework\/cli\/cli.py#L149-L151",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"Kedro",
        "Platform":"Github",
        "Issue_original_content":"us argument yml descript describ stackoverflow question http stackoverflow com question specifi host port yml run host port command us option context step reproduc creat project init modifi port yml launch expect result open port actual result open port default environ includ relev detail environ experienc bug version version python version python oper version window bug happen version master ye solut pass argument command http github com galileo galilei blob faadbfcfbdeadedfd framework cli cli",
        "Issue_preprocessed_content":"us argument yml descript describ us option context step reproduc creat project modifi port launch expect result open port actual result open port environ includ relev detail environ experienc bug python oper version window bug version master ye solut argument",
        "Issue_gpt_summary_original":"The mlflow run status shows \"FINISHED\" instead of \"FAILED\" when the kedro run fails, making it difficult to distinguish between successful and failed runs in the mlflow ui. The potential solution suggested is to replace certain lines of code or retrieve the current run status from mlflow.",
        "Issue_gpt_summary":"run statu show finish instead fail run fail make difficult distinguish success fail run potenti solut suggest replac certain line code retriev current run statu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/issues\/157",
        "Issue_title":"kedro mlflow cli is broken if configuration is declared in pyproject.toml",
        "Issue_created_time":1610404594000,
        "Issue_closed_time":1615716614000,
        "Issue_body":"## Description\r\n\r\nKedro enable to declare configuration either in ``.kedro.yml`` or in ``pyproject.toml`` (in the ``[tool.kedro]`` section). We claim to support both, but the CLI commands are not accessible if the project contains only a ``pyproject.toml file``.\r\n\r\n## Steps to Reproduce\r\n\r\nCall ``kedro mlflow init`` inside a project with no ``.kedro.yml`` file but only a ``pyproject.toml``.\r\n\r\n## Expected Result\r\n\r\nThe cli commands should be available (``init``)\r\n\r\n## Actual Result\r\nOnly the ``new`` command is available. This is not considered as a kedro project.\r\n\r\n```\r\n-- Separate them if you have more than one.\r\n```\r\n\r\n## Your Environment\r\n\r\n* `kedro` and `kedro-mlflow` version used (`pip show kedro` and `pip show kedro-mlflow`): kedro==16.6, kedro-mlflow==0.4.1\r\n* Python version used (`python -V`): 3.7.9\r\n* Operating system and version: Windows 7\r\n\r\n## Does the bug also happen with the last version on develop?\r\n\r\nYes\r\n\r\n## Solution\r\n\r\nThe error comes from the ``is_kedro_project`` function which does not consider that a folder is the root of a kdro project if it does not contain a ``.kedro.yml``.",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"This will wait the migration to `kedro>=0.17.0` (cf. #144) in milestone 0.6.0 because kedro has bradnd new utilities to handle this part. This will remove boilerplate code from the plugin and ensure consistency with future kedro changes.",
        "Tool":"Kedro",
        "Platform":"Github",
        "Issue_original_content":"cli broken configur declar pyproject toml descript enabl declar configur yml pyproject toml tool section support cli command access project contain pyproject toml file step reproduc init insid project yml file pyproject toml expect result cli command avail init actual result new command avail consid project separ environ version pip pip python version python oper version window bug happen version develop ye solut error come project function consid folder root kdro project contain yml",
        "Issue_preprocessed_content":"cli broken configur declar descript enabl declar configur cli project contain step reproduc insid project file expect result cli avail actual result avail consid project environ function consid folder kdro project contain",
        "Issue_gpt_summary_original":"The user is encountering issues with kedro-viz and kedro pipeline list when using PipelineML objects in hooks.py with kedro template>=0.16.5. The kedro run command works fine, but the visualization commands fail. The user has tried different versions of kedro-viz and kedro but the issue persists. The potential solution is to implement the __add__ method of the PipelineML class.",
        "Issue_gpt_summary":"user encount issu viz pipelin list pipelineml object hook templat run command work fine visual command fail user tri differ version viz issu persist potenti solut implement add method pipelineml class",
        "Issue_score_count":1
    },
    {
        "Issue_link":"https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/issues\/122",
        "Issue_title":"A KedroPipelineModel cannot be loaded from mlflow if its catalog contains non deepcopy-able DataSets",
        "Issue_created_time":1605983313000,
        "Issue_closed_time":1606599848000,
        "Issue_body":"## Description\r\n\r\nI tried to load a KedroPipelineModel from mlflow, and I got a \"cannot pickle context artifacts\" error, which is due do the \r\n\r\n## Context\r\n\r\nI cannot load a previously saved KedroPipelineModel generated by pipeline_ml_factory.\r\n\r\n## Steps to Reproduce\r\n\r\nSave A KedroPipelineModel with a dataset that contains an object which cannot be deepcopied (for me, a keras tokenizer)\r\n\r\n## Expected Result\r\n\r\nThe model should be loaded\r\n\r\n## Actual Result\r\n\r\nAn error is raised\r\n\r\n## Your Environment\r\nInclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* `kedro` and `kedro-mlflow` version used: 0.16.5 and 0.4.0\r\n* Python version used (`python -V`): 3.6.8\r\n* Windows 10 & CentOS were tested\r\n\r\n## Does the bug also happen with the last version on develop?\r\n\r\nYes\r\n\r\n# Potential solution\r\n\r\nThe faulty line is:\r\n\r\nhttps:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/blob\/63dcd501bfe98bebc81f25f70020ff4141c1e91c\/kedro_mlflow\/mlflow\/kedro_pipeline_model.py#L45",
        "Issue_answer_count":2,
        "Issue_self_closed":1.0,
        "Answer_body":"Does removing the faulty line and using directly the initial_catalog make the model loadable again ? if Yes, we have two options :\r\n\r\n* We no longer deepcopy the initial_catalog\r\n* We copy each DataSet of the catalog with his own loader (for example, we use tf.keras.models.clone_model for keras model DataSet ...)\r\n\r\nKnowing that the `KedroPipelineModel` is intented to be used in a separated process (at inference-time), we can just remove the deepcopy part (there won't be a conflict with another function using the same catalog)\r\n After some investigation, the issues comes from the MLflowAbstractModelDataSet, and particularly the `self._mlflow_model_module` attribute which is a module and not deepcopiable by nature. I suggest to store it as a string, and have a property attribute to load the module on the fly.\r\n\r\nNote that this is a problem which occurs only when the DataSet is not deepcopiable (and not the underlying value the DataSet can load(), so we can quite safely assume that it should not occur often). If it does, we should consider a more radical solution among the ones you suggest.",
        "Tool":"Kedro",
        "Platform":"Github",
        "Issue_original_content":"pipelinemodel load catalog contain non deepcopi abl dataset descript tri load pipelinemodel got pickl context artifact error context load previous save pipelinemodel gener pipelin factori step reproduc save pipelinemodel dataset contain object deepcopi kera token expect result model load actual result error rais environ includ relev detail environ experienc bug version python version python window cento test bug happen version develop ye potenti solut faulti line http github com galileo galilei blob dcdbfebebcffffcec pipelin model",
        "Issue_preprocessed_content":"pipelinemodel load catalog contain non abl dataset descript tri load pipelinemodel got pickl context artifact context load previous save pipelinemodel gener step reproduc save pipelinemodel dataset contain object expect result model load actual result rais environ includ relev detail environ experienc bug python window cento test bug version develop ye potenti solut faulti line",
        "Issue_gpt_summary_original":"The user encountered a TypeError when using the suggested VSCode configuration for debugging Kedro. The error is caused by commandline arguments being None when running the pipeline directly through run.py.",
        "Issue_gpt_summary":"user encount typeerror suggest vscode configur debug error caus commandlin argument run pipelin directli run",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/issues\/121",
        "Issue_title":"RunStatus of mlflow run is \"FINISHED\" instead of \"FAILED\" when the kedro run fails",
        "Issue_created_time":1605982845000,
        "Issue_closed_time":1606515096000,
        "Issue_body":"## Description\r\n\r\nWhen I launch `kedro run` and the run fails, the `on_pipeline_error` closes all the mlflow runs (to avoid interactions with further runs)\r\n\r\n## Context\r\n\r\nI cannot distinguish failed runs from sucessful ones in the mlflow ui.\r\n\r\n## Steps to Reproduce\r\n\r\nLaunch a failing pipeline with kedro run.\r\n\r\n## Expected Result\r\n\r\nThe mlflow ui should display the run with a red cross\r\n\r\n## Actual Result\r\n\r\nThe mlflow ui displays the run with a green tick\r\n\r\n\r\n## Does the bug also happen with the last version on develop?\r\n\r\nYes.\r\n\r\n## Potential solution: \r\n\r\nReplace these lines:\r\n\r\n`https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/blob\/63dcd501bfe98bebc81f25f70020ff4141c1e91c\/kedro_mlflow\/framework\/hooks\/pipeline_hook.py#L193-L194`\r\n\r\nwith \r\n\r\n```python\r\nwhile mlflow.active_run():\r\n    mlflow.end_run(mlflow.entities.RunStatus.FAILED)\r\n```\r\nor even better, retrieve current run status from mlflow?\r\n",
        "Issue_answer_count":2,
        "Issue_self_closed":1.0,
        "Answer_body":"Good catch ! \r\nSince we catch the Error and manually end the run, mlflow do not receive the \"error code 1\" of the current process. If we no longer end run manually, mlflow will tag the run as FAILED. But since we want to control the pipeline error, we can apply your suggestion (specifiying the status as failed) Yes, but we need to terminate the run manually when it failed and one use it interactively (in CLI, tis makes no difference because it gets the error code as you say) to avoid further interference.",
        "Tool":"Kedro",
        "Platform":"Github",
        "Issue_original_content":"runstatu run finish instead fail run fail descript launch run run fail pipelin error close run avoid interact run context distinguish fail run sucess on step reproduc launch fail pipelin run expect result displai run red cross actual result displai run green tick bug happen version develop ye potenti solut replac line http github com galileo galilei blob dcdbfebebcffffcec framework hook pipelin hook python activ run end run entiti runstatu fail better retriev current run statu",
        "Issue_preprocessed_content":"runstatu run finish instead fail run fail descript launch run fail close run context distinguish fail run on step reproduc launch fail pipelin run expect result displai run red actual result displai run tick bug version develop ye potenti solut replac line retriev run statu",
        "Issue_gpt_summary_original":"The user is encountering a warning message when calling \"kedro mlflow init\" which states that the project is not initialized yet and that the command must be called before any other command. However, this warning can be ignored as the command works as intended. The issue is due to the dynamic creation of the command.",
        "Issue_gpt_summary":"user encount warn messag call init state project initi command call command warn ignor command work intend issu dynam creation command",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/issues\/119",
        "Issue_title":"PipelineML objects in `hooks.py` breaks all kedro-viz versions with kedro template>=0.16.5",
        "Issue_created_time":1605718283000,
        "Issue_closed_time":1605720463000,
        "Issue_body":"## Description\r\n\r\nIf I create a PipelineML objects  and I return it in the `hooks.py`:\r\n\r\n\r\n```python\r\nclass ProjectHooks:\r\n    @hook_impl\r\n    def register_pipelines(self) -> Dict[str, Pipeline]:\r\n        \"\"\"Register the project's pipeline.\r\n        Returns:\r\n            A mapping from a pipeline name to a ``Pipeline`` object.\r\n        \"\"\"\r\n       ml_pipeline=create_ml_pipeline()\r\n        training_pipeline = pipeline_ml_factory(training=ml_pipeline.only_nodes_with_tags(\"training\"), inference=ml_pipeline.only_nodes_with_tags(\"inference\"), input_name=\"instances\")\r\n\r\n        return {\r\n            \"training\": training_pipeline,\r\n            \"__default__\": other_pipeline\r\n        }\r\n````\r\n\r\n`kedro run` command works fine, but `kedro viz` and `kedro pipeline list` fail.\r\n\r\n## Context\r\n\r\nI was trying to visualise a pipeline with kedro-viz==3.7.0 (I also tried 3.4.0 and 3.0.0), and kedro==0.16.6\r\n\r\n## Steps to Reproduce\r\n\r\n1. Create a PipelineMl object with pipeline_ml_factory in `hooks;py`\r\n2. Launch `kedro viz` in terminal\r\n\r\n## Expected Result\r\nKedro viz should be launched on localhost:5000\r\n\r\n## Actual Result\r\nTell us what happens instead.\r\n\r\n```\r\n-- If you received an error, place it here.\r\n```\r\n\r\n```\r\n-- Separate them if you have more than one.\r\n```\r\n\r\n## Your Environment\r\nInclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* `kedro` and `kedro-mlflow` version used (`pip show kedro` and `pip show kedro-mlflow`):\r\n* Python version used (`python -V`):\r\n* Operating system and version:\r\n\r\n*Note: everything works fine with the older template (`kedro<=0.16.4`) and the `pipeline.py` file instead of `hooks.py`*\r\n\r\n## Does the bug also happen with the last version on develop?\r\n\r\nYes\r\n\r\n## Potential solution: \r\n\r\nIt seems the `__add__` method of the `PipelineML` class must be implemented.",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"The issue is not confirmed and was due to adding a Pipeline and a PipelineML object.\r\nI close it.",
        "Tool":"Kedro",
        "Platform":"Github",
        "Issue_original_content":"pipelineml object hook break viz version templat descript creat pipelineml object return hook python class projecthook hook impl def regist pipelin self dict str pipelin regist project pipelin return map pipelin pipelin object pipelin creat pipelin train pipelin pipelin factori train pipelin node tag train infer pipelin node tag infer input instanc return train train pipelin default pipelin run command work fine viz pipelin list fail context try visualis pipelin viz tri step reproduc creat pipelineml object pipelin factori hook launch viz termin expect result viz launch localhost actual result tell happen instead receiv error place separ environ includ relev detail environ experienc bug version pip pip python version python oper version note work fine older templat pipelin file instead hook bug happen version develop ye potenti solut add method pipelineml class implement",
        "Issue_preprocessed_content":"pipelineml object break viz version descript creat pipelineml object return run viz pipelin list viz pip pip python file instead bug version develop ye potenti solut method implement",
        "Issue_gpt_summary_original":"The user is facing issues with the introduction of namespaces in kedro 0.17.7, which are not properly handled in kfp artifacts. This causes errors when running or updating the pipeline, and can be resolved by disabling the function to create kfp artifacts in the `kubeflow.yaml` config.",
        "Issue_gpt_summary":"user face issu introduct namespac properli handl kfp artifact caus error run updat pipelin resolv disabl function creat kfp artifact kubeflow yaml config",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/issues\/78",
        "Issue_title":"TypeError in _generate_kedro_command when debugging run in VSCode",
        "Issue_created_time":1601890192000,
        "Issue_closed_time":1601893558000,
        "Issue_body":"`TypeError: object of type 'NoneType' has no len()` happens when suggested [VSCode configuration for kedro](https:\/\/kedro.readthedocs.io\/en\/stable\/09_development\/01_set_up_vscode.html) is used for debugging. The error is due to commandline arguments being `None` when running pipeline directly through `run.py`.\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"\/Users\/olszewk2\/miniconda3\/envs\/pyzypad-example-env\/lib\/python3.7\/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"\/Users\/olszewk2\/miniconda3\/envs\/pyzypad-example-env\/lib\/python3.7\/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"\/Users\/olszewk2\/.vscode\/extensions\/ms-python.python-2020.8.105369\/pythonFiles\/lib\/python\/debugpy\/__main__.py\", line 45, in <module>\r\n    cli.main()\r\n  File \"\/Users\/olszewk2\/.vscode\/extensions\/ms-python.python-2020.8.105369\/pythonFiles\/lib\/python\/debugpy\/..\/debugpy\/server\/cli.py\", line 430, in main\r\n    run()\r\n  File \"\/Users\/olszewk2\/.vscode\/extensions\/ms-python.python-2020.8.105369\/pythonFiles\/lib\/python\/debugpy\/..\/debugpy\/server\/cli.py\", line 267, in run_file\r\n    runpy.run_path(options.target, run_name=compat.force_str(\"__main__\"))\r\n  File \"\/Users\/olszewk2\/miniconda3\/envs\/pyzypad-example-env\/lib\/python3.7\/runpy.py\", line 263, in run_path\r\n    pkg_name=pkg_name, script_name=fname)\r\n  File \"\/Users\/olszewk2\/miniconda3\/envs\/pyzypad-example-env\/lib\/python3.7\/runpy.py\", line 96, in _run_module_code\r\n    mod_name, mod_spec, pkg_name, script_name)\r\n  File \"\/Users\/olszewk2\/miniconda3\/envs\/pyzypad-example-env\/lib\/python3.7\/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"\/Users\/olszewk2\/dev\/pyzypad-example\/src\/pyzypad_example\/run.py\", line 75, in <module>\r\n    run_package()\r\n  File \"\/Users\/olszewk2\/dev\/pyzypad-example\/src\/pyzypad_example\/run.py\", line 71, in run_package\r\n    project_context.run()\r\n  File \"\/Users\/olszewk2\/miniconda3\/envs\/pyzypad-example-env\/lib\/python3.7\/site-packages\/kedro\/framework\/context\/context.py\", line 725, in run\r\n    run_params=record_data, pipeline=filtered_pipeline, catalog=catalog\r\n  File \"\/Users\/olszewk2\/miniconda3\/envs\/pyzypad-example-env\/lib\/python3.7\/site-packages\/pluggy\/hooks.py\", line 286, in __call__\r\n    return self._hookexec(self, self.get_hookimpls(), kwargs)\r\n  File \"\/Users\/olszewk2\/miniconda3\/envs\/pyzypad-example-env\/lib\/python3.7\/site-packages\/pluggy\/manager.py\", line 93, in _hookexec\r\n    return self._inner_hookexec(hook, methods, kwargs)\r\n  File \"\/Users\/olszewk2\/miniconda3\/envs\/pyzypad-example-env\/lib\/python3.7\/site-packages\/pluggy\/manager.py\", line 87, in <lambda>\r\n    firstresult=hook.spec.opts.get(\"firstresult\") if hook.spec else False,\r\n  File \"\/Users\/olszewk2\/miniconda3\/envs\/pyzypad-example-env\/lib\/python3.7\/site-packages\/pluggy\/callers.py\", line 208, in _multicall\r\n    return outcome.get_result()\r\n  File \"\/Users\/olszewk2\/miniconda3\/envs\/pyzypad-example-env\/lib\/python3.7\/site-packages\/pluggy\/callers.py\", line 80, in get_result\r\n    raise ex[1].with_traceback(ex[2])\r\n  File \"\/Users\/olszewk2\/miniconda3\/envs\/pyzypad-example-env\/lib\/python3.7\/site-packages\/pluggy\/callers.py\", line 187, in _multicall\r\n    res = hook_impl.function(*args)\r\n  File \"\/Users\/olszewk2\/dev\/pyzypad-example\/src\/kedro-mlflow\/kedro_mlflow\/framework\/hooks\/pipeline_hook.py\", line 85, in before_pipeline_run\r\n    pipeline_name=run_params[\"pipeline_name\"],\r\n  File \"\/Users\/olszewk2\/dev\/pyzypad-example\/src\/kedro-mlflow\/kedro_mlflow\/framework\/hooks\/pipeline_hook.py\", line 136, in _generate_kedro_command\r\n    if len(from_inputs) > 0:\r\nTypeError: object of type 'NoneType' has no len()\r\n```",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"I see its fixed now so I'm closing this issue.",
        "Tool":"Kedro",
        "Platform":"Github",
        "Issue_original_content":"typeerror gener command debug run vscode typeerror object type nonetyp len happen suggest vscode configur http readthedoc stabl develop set vscode html debug error commandlin argument run pipelin directli run traceback recent file user olszewk miniconda env pyzypad exampl env lib python runpi line run modul main main mod spec file user olszewk miniconda env pyzypad exampl env lib python runpi line run code exec code run global file user olszewk vscode extens python python pythonfil lib python debugpi main line cli main file user olszewk vscode extens python python pythonfil lib python debugpi debugpi server cli line main run file user olszewk vscode extens python python pythonfil lib python debugpi debugpi server cli line run file runpi run path option target run compat forc str main file user olszewk miniconda env pyzypad exampl env lib python runpi line run path pkg pkg script fname file user olszewk miniconda env pyzypad exampl env lib python runpi line run modul code mod mod spec pkg script file user olszewk miniconda env pyzypad exampl env lib python runpi line run code exec code run global file user olszewk dev pyzypad exampl src pyzypad exampl run line run packag file user olszewk dev pyzypad exampl src pyzypad exampl run line run packag project context run file user olszewk miniconda env pyzypad exampl env lib python site packag framework context context line run run param record data pipelin filter pipelin catalog catalog file user olszewk miniconda env pyzypad exampl env lib python site packag pluggi hook line return self hookexec self self hookimpl kwarg file user olszewk miniconda env pyzypad exampl env lib python site packag pluggi manag line hookexec return self inner hookexec hook method kwarg file user olszewk miniconda env pyzypad exampl env lib python site packag pluggi manag line firstresult hook spec opt firstresult hook spec fals file user olszewk miniconda env pyzypad exampl env lib python site packag pluggi caller line multical return outcom result file user olszewk miniconda env pyzypad exampl env lib python site packag pluggi caller line result rais traceback file user olszewk miniconda env pyzypad exampl env lib python site packag pluggi caller line multical re hook impl function arg file user olszewk dev pyzypad exampl src framework hook pipelin hook line pipelin run pipelin run param pipelin file user olszewk dev pyzypad exampl src framework hook pipelin hook line gener command len input typeerror object type nonetyp len",
        "Issue_preprocessed_content":"run vscode argument pipelin directli",
        "Issue_gpt_summary_original":"The user is encountering an issue where the plugin they are using is only compatible with kedro-mlflow version less than 0.8.0, and the `context` package has been moved or refactored, causing an exception to be thrown.",
        "Issue_gpt_summary":"user encount issu plugin compat version context packag move refactor caus except thrown",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/issues\/14",
        "Issue_title":"Warning message appears when calling ``kedro mlflow init``",
        "Issue_created_time":1593379921000,
        "Issue_closed_time":1600718139000,
        "Issue_body":"The warning claims that the project is not initialised yet, and that you must call ``kedro mlflow init`` before calling any command while you are calling ``kedro mlflow init``. It can be safely ignored because the command works as intended. This bug is due to the dynamic creation of command.",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"Kedro",
        "Platform":"Github",
        "Issue_original_content":"warn messag appear call init warn cl project initialis init call command call init safe ignor command work intend bug dynam creation command",
        "Issue_preprocessed_content":"warn warn cl project initialis safe ignor work intend bug dynam creation",
        "Issue_gpt_summary_original":"Kedro Telemetry breaks packaged projects due to assuming that the `pyproject.toml` file exists, which is only a recipe for building the project and should not be assumed to be existing in the current folder in all cases. This problem was introduced with a recent update and occurs when deploying Kedro projects with Kedro Telemetry installed. An exception is thrown when running the project in a folder where only the `conf\/` is present.",
        "Issue_gpt_summary":"telemetri break packag project assum pyproject toml file exist recip build project assum exist current folder case problem introduc recent updat occur deploi project telemetri instal except thrown run project folder conf present",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/getindata\/kedro-kubeflow\/issues\/160",
        "Issue_title":"Add support for kedro namespaces in data catalog",
        "Issue_created_time":1658927398000,
        "Issue_closed_time":null,
        "Issue_body":"Since kedro 0.17.7(?) there have been introduced namespaces which cause issues in kfp artifacts, as they are not properly handled.\r\n\r\nUnless the function to create kfp artifacts is disabled in `kubeflow.yaml` config:\r\n```yaml\r\nstore_kedro_outputs_as_kfp_artifacts: False\r\n```\r\nIt causes issues like:\r\n```\r\nValueError: Only letters, numbers, spaces, \"_\", and \"-\" are allowed in name. Must begin with a letter. Got name: data_science.active_modelling_pipeline.X_train\r\n```\r\nwhen trying to run or update the pipeline.\r\n",
        "Issue_answer_count":0,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Kedro",
        "Platform":"Github",
        "Issue_original_content":"add support namespac data catalog introduc namespac caus issu kfp artifact properli handl function creat kfp artifact disabl kubeflow yaml config yaml store output kfp artifact fals caus issu like valueerror letter number space allow begin letter got data scienc activ model pipelin train try run updat pipelin",
        "Issue_preprocessed_content":"namespac data catalog introduc namespac caus kfp artifact properli handl function creat kfp artifact disabl config caus like try run updat pipelin",
        "Issue_gpt_summary_original":"The user has encountered an issue where installing `kedro-datasets[option]` results in a different set of dependencies being installed compared to `kedro[option]`. This is causing a blockage in a GitHub issue and appears to be due to `kedro-datasets[option]` installing the superset of requirements for all datasets. The steps to reproduce involve installing both options and comparing the resulting requirements.",
        "Issue_gpt_summary":"user encount issu instal dataset option result differ set depend instal compar option caus blockag github issu appear dataset option instal superset requir dataset step reproduc involv instal option compar result requir",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/getindata\/kedro-kubeflow\/issues\/102",
        "Issue_title":"Plugin only compatible with kedro-mlflow<0.8.0",
        "Issue_created_time":1643989114000,
        "Issue_closed_time":null,
        "Issue_body":"```python\r\ndef is_mlflow_enabled() -> bool:\r\n    try:\r\n        import mlflow  # NOQA\r\n        from kedro_mlflow.framework.context import get_mlflow_config  # NOQA\r\n        return True\r\n    except ImportError:\r\n        return False\r\n```\r\nalway throws exception since `context` package has been moved or refactored",
        "Issue_answer_count":1,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Kedro",
        "Platform":"Github",
        "Issue_original_content":"plugin compat python def enabl bool try import noqa framework context import config noqa return true importerror return fals alwai throw except context packag move refactor",
        "Issue_preprocessed_content":"plugin compat alwai throw except packag move refactor",
        "Issue_gpt_summary_original":"The user is encountering a ValueError when running an Airflow job with Kedro Airflow plugins. The error message indicates that the pipeline inputs 'X_test', 'y_train', and 'X_train' are not found in the DataCatalog. The code provided includes a KedroOperator that runs a pipeline with three tasks: 'split', 'make-predictions', and 'report-accuracy'.",
        "Issue_gpt_summary":"user encount valueerror run airflow job airflow plugin error messag indic pipelin input test train train datacatalog code provid includ oper run pipelin task split predict report accuraci",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/kedro-org\/kedro-plugins\/issues\/83",
        "Issue_title":"Kedro Telemetry breaks packaged projects due to wrongly assuming `pyproject.toml` exists",
        "Issue_created_time":1669645759000,
        "Issue_closed_time":1670415546000,
        "Issue_body":"## Description\r\nKedro Telemetry installed alongside a packaged and installed Kedro project breaks the project by assuming that the `pyproject.toml` file exists. The `pyproject.toml` is only a recipe for building the project and should not be assumed to be existing in the current folder in all cases.\r\n\r\nThe problem was introduced with https:\/\/github.com\/kedro-org\/kedro-plugins\/pull\/62\r\n\r\n## Context\r\nWhen deploying Kedro projects and if you have installed Kedro Telemetry, it breaks your project.\r\n\r\n## Steps to Reproduce\r\n1. Create a Kedro project\r\n2. Add a dependency on kedro-telemetry\r\n3. Package it through `kedro package`\r\n4. Install it in a different environment\r\n5. Run the project through `.\/<project>` in a folder where only the `conf\/` is\r\n\r\n## Expected Result\r\nThe project should run.\r\n\r\n## Actual Result\r\nAn exception is thrown.\r\n\r\n## Your Environment\r\nInclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* Kedro version used (`pip show kedro` or `kedro -V`): 0.18.x\r\n* Kedro plugin and kedro plugin version used (`pip show kedro-telemetry`): 0.2.2 \r\n* Python version used (`python -V`): Not relevant\r\n* Operating system and version: Not relevant\r\n",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"Kedro",
        "Platform":"Github",
        "Issue_original_content":"telemetri break packag project wrongli assum pyproject toml exist descript telemetri instal alongsid packag instal project break project assum pyproject toml file exist pyproject toml recip build project assum exist current folder case problem introduc http github com org plugin pull context deploi project instal telemetri break project step reproduc creat project add depend telemetri packag packag instal differ environ run project folder conf expect result project run actual result except thrown environ includ relev detail environ experienc bug version pip plugin plugin version pip telemetri python version python relev oper version relev",
        "Issue_preprocessed_content":"telemetri break packag project wrongli exist descript telemetri alongsid packag project break project file exist recip build project exist folder case problem introduc context deploi project telemetri break project step reproduc creat project depend telemetri packag environ run project folder expect result project run actual result except thrown environ includ relev detail environ experienc bug version plugin plugin version python version relev oper version relev",
        "Issue_gpt_summary_original":"The user is facing issues while trying to run a simple spaceflights example with Astrocloud using kedro-airflow. The expected result is a complete Kedro run on local Airflow image, but the actual result is a failure in the local Airflow image with errors related to `BaseSessionStore`, `git describe`, and `Negsignal.SIGKILL`. The user has provided relevant details about the environment, including the Kedro-Airflow plugin version, Airflow version, Kedro version, Python version, and operating system.",
        "Issue_gpt_summary":"user face issu try run simpl spaceflight exampl astrocloud airflow expect result complet run local airflow imag actual result failur local airflow imag error relat basesessionstor git negsign sigkil user provid relev detail environ includ airflow plugin version airflow version version python version oper",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/kedro-org\/kedro-plugins\/issues\/64",
        "Issue_title":"pip installing kedro-datasets[option] causes different dependencies to installing kedro[option]",
        "Issue_created_time":1666866011000,
        "Issue_closed_time":1667929584000,
        "Issue_body":"## Description\nInstalling `kedro-datasets[option]` installs a different set of dependencies than `kedro[option]`. It appears that `kedro-datasets[option]` is installing the superset of requirements for all datasets.\n\n## Context\nThis is currently blocking https:\/\/github.com\/kedro-org\/kedro\/issues\/1495\n\n## Steps to Reproduce\n1. `pip install \"kedro[pandas.CSVDataSet]\"; pip freeze > requirements-kedro.txt`\n2. `pip install \"kedro-datasets[pandas.CSVDataSet]\"; pip freeze > requirements-kedro-datasets.txt`\n3. Compare the requirements\n",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"Kedro",
        "Platform":"Github",
        "Issue_original_content":"pip instal dataset option caus differ depend instal option descript instal dataset option instal differ set depend option appear dataset option instal superset requir dataset context current block http github com org issu step reproduc pip instal panda csvdataset pip freez requir txt pip instal dataset panda csvdataset pip freez requir dataset txt compar requir",
        "Issue_preprocessed_content":"pip dataset caus depend descript set depend superset requir dataset context block step reproduc compar requir",
        "Issue_gpt_summary_original":"The user is encountering a 'charmap' codec error while running the kedro-pipeline \"dp\" via kedro-cli with \"kedro run --pipeline dp\". The error occurs while loading data from the TextDataSet and is caused by the inability of the codec to decode byte 0x81 in position 5899. The user has provided the catalog.yml and python-function used to parse documentation-data. The user is using kedro 0.18.0.",
        "Issue_gpt_summary":"user encount charmap codec error run pipelin cli run pipelin error occur load data textdataset caus inabl codec decod byte posit user provid catalog yml python function pars document data user",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/kedro-org\/kedro-plugins\/issues\/75",
        "Issue_title":"kedro airflow plugins: ValueError Pipeline input(s) not found in the DataCatalog",
        "Issue_created_time":1664420413000,
        "Issue_closed_time":1668830449000,
        "Issue_body":"\r\nwhen I run the Airflow Job\r\nHave this problem\r\n```\r\nValueError: Pipeline input(s) {'X_test', 'y_train', 'X_train'} not found in the DataCatalog\r\n```\r\n\r\n```python\r\nimport sys\r\nfrom collections import defaultdict\r\nfrom datetime import datetime, timedelta\r\nfrom pathlib import Path\r\n\r\nfrom airflow import DAG\r\nfrom airflow.models import BaseOperator\r\nfrom airflow.utils.decorators import apply_defaults\r\nfrom airflow.version import version\r\nfrom kedro.framework.project import configure_project\r\nfrom kedro.framework.session import KedroSession\r\n\r\n\r\nsys.path.append(\"\/Users\/mahao\/airflow\/dags\/pandas_iris_01\/src\")\r\n\r\n\r\n\r\n\r\nclass KedroOperator(BaseOperator):\r\n    @apply_defaults\r\n    def __init__(self, package_name: str, pipeline_name: str, node_name: str,\r\n                 project_path: str, env: str, *args, **kwargs) -> None:\r\n        super().__init__(*args, **kwargs)\r\n        self.package_name = package_name\r\n        self.pipeline_name = pipeline_name\r\n        self.node_name = node_name\r\n        self.project_path = project_path\r\n        self.env = env\r\n\r\n    def execute(self, context):\r\n        configure_project(self.package_name)\r\n        with KedroSession.create(self.package_name,\r\n                                 self.project_path,\r\n                                 env=self.env) as session:\r\n            session.run(self.pipeline_name, node_names=[self.node_name])\r\n\r\n\r\n# Kedro settings required to run your pipeline\r\nenv = \"local\"\r\npipeline_name = \"__default__\"\r\n#project_path = Path.cwd()\r\nproject_path = \"\/Users\/mahao\/airflow\/dags\/pandas_iris_01\"\r\nprint(project_path)\r\n\r\npackage_name = \"pandas_iris_01\"\r\n\r\n# Default settings applied to all tasks\r\ndefault_args = {\r\n    'owner': 'airflow',\r\n    'depends_on_past': False,\r\n    'email_on_failure': False,\r\n    'email_on_retry': False,\r\n    'retries': 1,\r\n    'retry_delay': timedelta(minutes=5)\r\n}\r\n\r\n# Using a DAG context manager, you don't have to specify the dag property of each task\r\nwith DAG(\r\n        \"pandas-iris-01\",\r\n        start_date=datetime(2019, 1, 1),\r\n        max_active_runs=3,\r\n        schedule_interval=timedelta(\r\n            minutes=30\r\n        ),  # https:\/\/airflow.apache.org\/docs\/stable\/scheduler.html#dag-runs\r\n        default_args=default_args,\r\n        catchup=False  # enable if you don't want historical dag runs to run\r\n) as dag:\r\n\r\n    tasks = {}\r\n\r\n    tasks[\"split\"] = KedroOperator(\r\n        task_id=\"split\",\r\n        package_name=package_name,\r\n        pipeline_name=pipeline_name,\r\n        node_name=\"split\",\r\n        project_path=project_path,\r\n        env=env,\r\n    )\r\n\r\n    tasks[\"make-predictions\"] = KedroOperator(\r\n        task_id=\"make-predictions\",\r\n        package_name=package_name,\r\n        pipeline_name=pipeline_name,\r\n        node_name=\"make_predictions\",\r\n        project_path=project_path,\r\n        env=env,\r\n    )\r\n\r\n    tasks[\"report-accuracy\"] = KedroOperator(\r\n        task_id=\"report-accuracy\",\r\n        package_name=package_name,\r\n        pipeline_name=pipeline_name,\r\n        node_name=\"report_accuracy\",\r\n        project_path=project_path,\r\n        env=env,\r\n    )\r\n\r\n    tasks[\"split\"] >> tasks[\"make-predictions\"]\r\n\r\n    tasks[\"split\"] >> tasks[\"report-accuracy\"]\r\n\r\n    tasks[\"make-predictions\"] >> tasks[\"report-accuracy\"]\r\n\r\n```\r\n\r\n\r\n\r\n\r\n\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"I think you are missing the data from the catalog.\r\n\r\n```yml\r\nexample_iris_data:\r\n  type: pandas.CSVDataSet\r\n  filepath: data\/01_raw\/iris.csv\r\nexample_train_x:\r\n  type: pickle.PickleDataSet\r\n  filepath: data\/05_model_input\/example_train_x.pkl\r\nexample_train_y:\r\n  type: pickle.PickleDataSet\r\n  filepath: data\/05_model_input\/example_train_y.pkl\r\nexample_test_x:\r\n  type: pickle.PickleDataSet\r\n  filepath: data\/05_model_input\/example_test_x.pkl\r\nexample_test_y:\r\n  type: pickle.PickleDataSet\r\n  filepath: data\/05_model_input\/example_test_y.pkl\r\nexample_model:\r\n  type: pickle.PickleDataSet\r\n  filepath: data\/06_models\/example_model.pkl\r\nexample_predictions:\r\n  type: pickle.PickleDataSet\r\n  filepath: data\/07_model_output\/example_predictions.pkl\r\n```\r\n\r\nSee https:\/\/kedro.readthedocs.io\/en\/stable\/deployment\/airflow_astronomer.html?highlight=astro-airflow-iris\r\n\r\nCan you provide the steps to reproduce the issue? What versions of `kedro`, `kedro-airflow` are you using and what commands did you run?\r\n",
        "Tool":"Kedro",
        "Platform":"Github",
        "Issue_original_content":"airflow plugin valueerror pipelin input datacatalog run airflow job problem valueerror pipelin input test train train datacatalog python import sy collect import defaultdict datetim import datetim timedelta pathlib import path airflow import dag airflow model import baseoper airflow util decor import appli default airflow version import version framework project import configur project framework session import session sy path append user mahao airflow dag panda iri src class oper baseoper appli default def init self packag str pipelin str node str project path str env str arg kwarg super init arg kwarg self packag packag self pipelin pipelin self node node self project path project path self env env def execut self context configur project self packag session creat self packag self project path env self env session session run self pipelin node name self node set requir run pipelin env local pipelin default project path path cwd project path user mahao airflow dag panda iri print project path packag panda iri default set appli task default arg owner airflow depend past fals email failur fals email retri fals retri retri delai timedelta minut dag context manag specifi dag properti task dag panda iri start date datetim max activ run schedul interv timedelta minut http airflow apach org doc stabl schedul html dag run default arg default arg catchup fals enabl want histor dag run run dag task task split oper task split packag packag pipelin pipelin node split project path project path env env task predict oper task predict packag packag pipelin pipelin node predict project path project path env env task report accuraci oper task report accuraci packag packag pipelin pipelin node report accuraci project path project path env env task split task predict task split task report accuraci task predict task report accuraci",
        "Issue_preprocessed_content":"airflow plugin pipelin input datacatalog run airflow job problem",
        "Issue_gpt_summary_original":"The user is facing an issue where using mlflow without an mlflow writer configured fails silently. The expected behavior is for mlflow integration to write to mlflow by default and warn if missing or inconsistent config is set. The user suggests that whylogs should mention the missing mlflow writer in a warning and automatically add the mlflow writer (with a warning) to draw attention to where the behavior can be modified.",
        "Issue_gpt_summary":"user face issu writer configur fail silent expect behavior integr write default warn miss inconsist config set user suggest whylog mention miss writer warn automat add writer warn draw attent behavior modifi",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/kedro-org\/kedro-plugins\/issues\/13",
        "Issue_title":"Kedro-Airflow not working with Astrocloud",
        "Issue_created_time":1648473272000,
        "Issue_closed_time":null,
        "Issue_body":"Raised by @jweiss-ocurate:\r\n\r\n## Description\r\nI am trying to run a simple spaceflights example with Astrocloud. I wasn't sure if anyone has been able to get it to work. \r\n\r\nHere is the DockerFile:\r\nFROM quay.io\/astronomer\/astro-runtime:4.1.0\r\n\r\nRUN pip install --user new_kedro_project-0.1-py3-none-any.whl --ignore-requires-python\r\n\r\n## Context\r\nI am trying to use kedro-airflow with astrocloud.\r\n\r\n## Steps to Reproduce\r\n\r\n1. Follow directions here https:\/\/kedro.readthedocs.io\/en\/latest\/10_deployment\/11_airflow_astronomer.html\r\n2. Replace the DockerFile with the above mentioned image.\r\n\r\n## Expected Result\r\nComplete Kedro Run on local Airflow image.\r\n\r\n## Actual Result\r\nFailure in local Airflow image.\r\n[2022-02-26, 16:43:26 UTC] {store.py:32} INFO - `read()` not implemented for `BaseSessionStore`. Assuming empty store.\r\n[2022-02-26, 16:43:26 UTC] {session.py:78} WARNING - Unable to git describe \/usr\/local\/airflow\r\n[2022-02-26, 16:43:29 UTC] {local_task_job.py:154} INFO - Task exited with return code Negsignal.SIGKILL\r\n\r\n## Your Environment\r\nInclude as many relevant details about the environment you experienced the bug in:\r\n\r\n* Kedro-Airflow plugin version used (get it by running `pip show kedro-airflow`): 0.4.1\r\n* Airflow version (`airflow --version`):\r\n* Kedro version used (`pip show kedro` or `kedro -V`): 0.17.7\r\n* Python version used (`python -V`): > 2.0.0\r\n* Operating system and version: Ubuntu Linux 20.04",
        "Issue_answer_count":12,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Kedro",
        "Platform":"Github",
        "Issue_original_content":"airflow work astrocloud rais jweiss ocur descript try run simpl spaceflight exampl astrocloud wasn sure abl work dockerfil quai astronom astro runtim run pip instal user new project whl ignor requir python context try us airflow astrocloud step reproduc follow direct http readthedoc latest deploy airflow astronom html replac dockerfil mention imag expect result complet run local airflow imag actual result failur local airflow imag utc store info read implement basesessionstor assum store utc session warn unabl git usr local airflow utc local task job info task exit return code negsign sigkil environ includ relev detail environ experienc bug airflow plugin version run pip airflow airflow version airflow version version pip python version python oper version ubuntu linux",
        "Issue_preprocessed_content":"airflow work astrocloud rais descript try run simpl spaceflight exampl astrocloud wasn sure abl work dockerfil run pip context try us airflow astrocloud step reproduc direct replac dockerfil mention imag expect result complet run local airflow imag actual result failur local airflow imag utc info implement store utc warn unabl git utc info task exit return code environ includ relev detail environ experienc bug airflow plugin version airflow version version python version oper version ubuntu linux",
        "Issue_gpt_summary_original":"The user is facing a challenge while trying to save dataset profiles in JSON format using mlflow. While they can save the profile JSON using mlflow.log_artifact directly, passing a format config to mlflow writer specifying 'json' is not supported and instead uses the protobuf bin format.",
        "Issue_gpt_summary":"user face challeng try save dataset profil json format save profil json log artifact directli pass format config writer specifi json support instead us protobuf bin format",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/quaseldoku\/QuaselDoku\/issues\/1",
        "Issue_title":"Running kedro-pipeline \"dp\" results in \"character maps to <undefined>\"-error",
        "Issue_created_time":1654682698000,
        "Issue_closed_time":null,
        "Issue_body":"### Description\r\nRunning the kedro-pipeline \"dp\" via kedro-cli with \"kedro run --pipeline dp\" results in the following error:\r\n```cmd\r\nkedro.io.core.DataSetError: Failed while loading data from data set TextDataSet(filepath=C:\/EEAA\/Repos\/QuaselDoku\/data\/01_raw\/Doku_v1\/Bedienung\/EasyInsert.html, protocol=file).\r\n'charmap' codec can't decode byte 0x81 in position 5899: character maps to <undefined>\r\n```\r\n\r\n### Steps to reproduce\r\ncatalog.yml:\r\n```yml\r\necu_test_doku:\r\n  type: PartitionedDataSet\r\n  path: data\/01_raw\/Doku_v1\r\n  dataset: text.TextDataSet\r\n  filename_suffix: html\r\n```\r\n\r\npython-function to parse documentation-data:\r\n```python\r\ndef filter_doku(partitioned_input: Dict[str, Callable[[], Any]], params: Dict) -> Dict[str, Callable[[], Any]]:\r\n    \"\"\"\r\n    flatten input where html files can occur on multiple levels, as well as filter out files that match certain string.\r\n    Return new Dictionary with filenames and load functions from which a PartioniedDataset can be created and persisted.\r\n\r\n    Args:\r\n        partitioned_input: A dictionary with partition ids (file path) as keys and load functions as values.\r\n\r\n    Returns:\r\n        Dictionary with the partitions to create.\r\n    \"\"\"\r\n\r\n    result = {}\r\n\r\n    print(\"filtering out relevant html files from doku ...\")\r\n    for partition_key, partition_load_func in tqdm(sorted(partitioned_input.items())):\r\n        \r\n        exclude = False\r\n        for string in params['exclude_docs']:\r\n            \r\n            if string in partition_key:\r\n                \r\n                exclude = True\r\n                break\r\n\r\n        if exclude:\r\n            continue\r\n\r\n        filename = partition_key.replace('\/', ' ')\r\n        filename += 'html'\r\n\r\n        # append new filename with load function to results dictionary\r\n        result[filename] = partition_load_func\r\n\r\n    return result\r\n```\r\n\r\nkedro  0.18.0\r\n\r\nThanks! :)\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Kedro",
        "Platform":"Github",
        "Issue_original_content":"run pipelin result charact map error descript run pipelin cli run pipelin result follow error cmd core dataseterror fail load data data set textdataset filepath eeaa repo quaseldoku data raw doku bedienung easyinsert html protocol file charmap codec decod byte posit charact map step reproduc catalog yml yml ecu test doku type partitioneddataset path data raw doku dataset text textdataset filenam suffix html python function pars document data python def filter doku partit input dict str callabl param dict dict str callabl flatten input html file occur multipl level filter file match certain string return new dictionari filenam load function partionieddataset creat persist arg partit input dictionari partit id file path kei load function valu return dictionari partit creat result print filter relev html file doku partit kei partit load func tqdm sort partit input item exclud fals string param exclud doc string partit kei exclud true break exclud continu filenam partit kei replac filenam html append new filenam load function result dictionari result filenam partit load func return result thank",
        "Issue_preprocessed_content":"pipelin result charact map descript pipelin cli run result step reproduc pars thank",
        "Issue_gpt_summary_original":"The user encountered a \"Session is already closed\" error while trying to create a logger in the MLflow example notebook using WhyLogs. The error occurred when attempting to log data quality metrics for a batch using WhyLogs.",
        "Issue_gpt_summary":"user encount session close error try creat logger exampl notebook whylog error occur attempt log data qualiti metric batch whylog",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/whylabs\/whylogs\/issues\/480",
        "Issue_title":"using mlflow without an mlflow writer configured appears to fail silently",
        "Issue_created_time":1647628309000,
        "Issue_closed_time":1655127386000,
        "Issue_body":"### Summary\r\n\r\nProfiling with mlflow and without an mlflow writer fails silently. \r\n\r\n### Steps to Reproduce it\r\n\r\nuse mlflow with get_or_create_session and no files are written.\r\n\r\n### Example\r\n\r\nThere are examples of how to configure mlflow writer config here: https:\/\/github.com\/whylabs\/whylogs-examples\/blob\/mainline\/python\/.whylogs_mlflow.yaml\r\n\r\nwhylogs should mention the missing mlflow writer in a warning. Maybe we can automatically add the mlflow writer (with a warning), so that it works and draws attention to where the behavior can be modified.\r\n\r\n## What is the current *bug* behavior?\r\n\r\nlogging with mlflow and default configuration appears to fail silently.\r\n\r\n### What is the expected *correct* behavior?\r\n\r\nmlflow integration should write to mlflow by default and warn if missing or inconsistent config is set.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"This issue is stale. Remove stale label or it will be closed tomorrow.",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"writer configur appear fail silent summari profil writer fail silent step reproduc us creat session file written exampl exampl configur writer config http github com whylab whylog exampl blob mainlin python whylog yaml whylog mention miss writer warn mayb automat add writer warn work draw attent behavior modifi current bug behavior log default configur appear fail silent expect correct behavior integr write default warn miss inconsist config set",
        "Issue_preprocessed_content":"writer configur fail silent profil writer fail silent step reproduc us file exampl exampl configur writer config whylog mention writer warn mayb writer work draw behavior modifi bug behavior default configur fail silent expect behavior integr write default warn inconsist config set",
        "Issue_gpt_summary_original":"Users are experiencing problems with mlflow 1.19 and the issue is being tracked for investigation.",
        "Issue_gpt_summary":"user experienc problem issu track investig",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/whylabs\/whylogs\/issues\/458",
        "Issue_title":"Support writing out dataset profiles as json format with mlflow",
        "Issue_created_time":1646156442000,
        "Issue_closed_time":1655127391000,
        "Issue_body":"### Summary\r\n\r\nyou can call mlflow.log_artifact directly and save the profile JSON:\r\n```\r\nsummary = profile.to_summary()\r\nopen(\"local_path\", \"wt\", transport_params=transport_params) as f:\r\n    f.write(message_to_json(summary))\r\nmlflow.log_artifact(\"local_path\", your\/path\")\r\n```\r\n\r\nbut if you pass a format config to mlflow writer specifying 'json' it isn't supported and instead uses the protobuf bin format.\r\n\r\n\r\n",
        "Issue_answer_count":2,
        "Issue_self_closed":0.0,
        "Answer_body":"How can i retrieve the profile while inside the start_run()? This issue is stale. Remove stale label or it will be closed tomorrow.",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"support write dataset profil json format summari log artifact directli save profil json summari profil summari open local path transport param transport param write messag json summari log artifact local path path pass format config writer specifi json isn support instead us protobuf bin format",
        "Issue_preprocessed_content":"write dataset profil json format directli save profil json format config writer specifi json isn instead us protobuf bin format",
        "Issue_gpt_summary_original":"The user is encountering a NameError when trying to import the numbertracker from whylogs.core.statistics due to the optional MLFlow dependency not being installed. The error occurs the first time the import is attempted but works fine on the second attempt.",
        "Issue_gpt_summary":"user encount nameerror try import numbertrack whylog core statist option depend instal error occur time import attempt work fine second attempt",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/whylabs\/whylogs\/issues\/411",
        "Issue_title":"MLflow example: close session error",
        "Issue_created_time":1641941774000,
        "Issue_closed_time":1655127397000,
        "Issue_body":"### Summary\r\n\r\n[<!-- Summarize the bug encountered concisely -->\r\n](https:\/\/github.com\/whylabs\/whylogs-examples\/blob\/mainline\/python\/MLFlow%20Integration%20Example.ipynb)\r\n### Steps to Reproduce it\r\n\r\nUsed Binder to run the above notebook\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n\/tmp\/ipykernel_157\/4031979109.py in <module>\r\n     12 \r\n     13         # use whylogs to log data quality metrics for the current batch\r\n---> 14         mlflow.whylogs.log_pandas(batch)\r\n     15 \r\n     16     # wait a second between runs to create a time series of prediction results\r\n\r\n\/srv\/conda\/envs\/notebook\/lib\/python3.7\/site-packages\/whylogs\/mlflow\/patcher.py in log_pandas(self, df, dataset_name, dataset_timestamp)\r\n     71         :param dataset_name: the name of the dataset (Optional). If not specified, the experiment name is used\r\n     72         \"\"\"\r\n---> 73         ylogs = self._get_or_create_logger(dataset_name, dataset_timestamp=dataset_timestamp)\r\n     74 \r\n     75         if ylogs is None:\r\n\r\n\/srv\/conda\/envs\/notebook\/lib\/python3.7\/site-packages\/whylogs\/mlflow\/patcher.py in _get_or_create_logger(self, dataset_name, dataset_timestamp)\r\n    103         ylogs = self._loggers.get(dataset_name)\r\n    104         if ylogs is None:\r\n--> 105             ylogs = self._create_logger(dataset_name, dataset_timestamp=dataset_timestamp)\r\n    106             self._loggers[dataset_name] = ylogs\r\n    107         return ylogs\r\n\r\n\/srv\/conda\/envs\/notebook\/lib\/python3.7\/site-packages\/whylogs\/mlflow\/patcher.py in _create_logger(self, dataset_name, dataset_timestamp)\r\n     57             tags,\r\n     58         )\r\n---> 59         logger_ = self._session.logger(run_info.run_id, session_timestamp=session_timestamp, dataset_timestamp=dataset_timestamp, tags=tags)\r\n     60         return logger_\r\n     61 \r\n\r\n\/srv\/conda\/envs\/notebook\/lib\/python3.7\/site-packages\/whylogs\/app\/session.py in logger(self, dataset_name, dataset_timestamp, session_timestamp, tags, metadata, segments, profile_full_dataset, with_rotation_time, cache_size, constraints)\r\n    172         \"\"\"\r\n    173         if not self._active:\r\n--> 174             raise RuntimeError(\"Session is already closed. Cannot create more loggers\")\r\n    175 \r\n    176         # Explicitly set the default timezone to utc if none was provided. Helps with equality testing\r\n\r\nRuntimeError: Session is already closed. Cannot create more loggers\r\n```\r\n### Example\r\n\r\n",
        "Issue_answer_count":5,
        "Issue_self_closed":0.0,
        "Answer_body":"The example closes the default session, and then later the mlflow.whylogs wrapper is using that closed session to create loggers. Need to update that example's initial session creation to something like:\r\n```\r\nfrom whylogs import get_or_create_session\r\n\r\nsession = get_or_create_session()\r\nsummary = session.profile_dataframe(train, \"training-data\").flat_summary()['summary']\r\n\r\nsummary\r\n``` Still need to update the example to work in Binder better:\r\n* install dependencies\r\n* coinfigure mlflow writer, currently the default session will just write to local disk Part of the reason is that it picks up the default YAML file with default list of writers - and they don't contain mlflow (for obvious reason): https:\/\/github.com\/whylabs\/whylogs-examples\/blob\/mainline\/python\/.whylogs.yaml\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/26821974\/149250188-154d5b19-348e-44ea-b64a-0c4724b3c0cd.png)\r\n\r\nHere's my fix in the notebook\r\n\r\nNow this poses interesting quesiton:\r\n* Should mlflow writer be allowed if you don't run mlflow? My instinct is to say yes, but you get a big warning. Or exception?\r\n* If you specify a config without mlflow writer, should we implicitly add mlflow writer? Maybe yes.\r\n\r\nHowever so far I'm not a fan of implicit behaviors because it's freaking hard for us to reason about (see this issue - took a bit of debugging to find out that it's config related). My vote is to throw exception with an option to disable that exception if user chooses the path of ignorance. Drop in the code of the two cells:\r\n\r\n```\r\nconfig = \"\"\"\r\nproject: example-project\r\npipeline: example-pipeline\r\nverbose: false\r\nwriters:\r\n# Save to mlflow\r\n- formats:\r\n    - protobuf\r\n  output_path: mlflow\r\n  type: mlflow\r\n\"\"\"\r\ncfg_file = \"mlflow_config.yaml\"\r\n\r\n!echo \"{config}\" > {cfg_file}\r\n\r\nfrom whylogs import get_or_create_session\r\n\r\nsession = get_or_create_session(cfg_file)\r\n\r\nassert whylogs.__version__ >= \"0.1.13\" # we need 0.1.13 or later for MLflow integration\r\nwhylogs.enable_mlflow(session)\r\n``` This issue is stale. Remove stale label or it will be closed tomorrow.",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"exampl close session error summari http github com whylab whylog exampl blob mainlin python integr exampl ipynb step reproduc binder run notebook runtimeerror traceback recent tmp ipykernel us whylog log data qualiti metric current batch whylog log panda batch wait second run creat time seri predict result srv conda env notebook lib python site packag whylog patcher log panda self dataset dataset timestamp param dataset dataset option specifi experi ylog self creat logger dataset dataset timestamp dataset timestamp ylog srv conda env notebook lib python site packag whylog patcher creat logger self dataset dataset timestamp ylog self logger dataset ylog ylog self creat logger dataset dataset timestamp dataset timestamp self logger dataset ylog return ylog srv conda env notebook lib python site packag whylog patcher creat logger self dataset dataset timestamp tag logger self session logger run info run session timestamp session timestamp dataset timestamp dataset timestamp tag tag return logger srv conda env notebook lib python site packag whylog app session logger self dataset dataset timestamp session timestamp tag metadata segment profil dataset rotat time cach size constraint self activ rais runtimeerror session close creat logger explicitli set default timezon utc provid help equal test runtimeerror session close creat logger exampl",
        "Issue_preprocessed_content":"exampl close bug encount concis step reproduc binder run exampl",
        "Issue_gpt_summary_original":"The user is facing an issue with a project template in which the `.drone.yaml` file is referencing a Kubernetes secret named `mlflow-server-secret` that does not exist by default. The solution to this issue is to change the name of the secret to `{{ .ProjectID }}-mlflow-secret`.",
        "Issue_gpt_summary":"user face issu project templat drone yaml file referenc kubernet secret name server secret exist default solut issu chang secret projectid secret",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/whylabs\/whylogs\/issues\/338",
        "Issue_title":"[Bug\/Feature Request] Support mlflow 1.19",
        "Issue_created_time":1634141491000,
        "Issue_closed_time":1634667593000,
        "Issue_body":"Users are reporting issues with mlflow 1.19\r\n\r\nCreating an issue here to track. Details will be added as we investigate further",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"bug featur request support user report issu creat issu track detail ad investig",
        "Issue_preprocessed_content":" user report creat track detail investig",
        "Issue_gpt_summary_original":"The user has encountered an issue where the default value for projectOperator.mlflow.image.tag is set to \"latest\" instead of \"v0.13.2\" on chart release v0.13.2. The user is advised to check the values.yml file to ensure that the correct tag is set.",
        "Issue_gpt_summary":"user encount issu default valu projectoper imag tag set latest instead chart releas user advis check valu yml file ensur correct tag set",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/whylabs\/whylogs\/issues\/72",
        "Issue_title":"MLFlow NameError",
        "Issue_created_time":1603138068000,
        "Issue_closed_time":1603222865000,
        "Issue_body":"When I don't have the optional MLFlow dependency installed I get the following exception the first time I try to import the `numbertracker`.  The second time I run the import, everything works just fine.\r\n\r\n```python\r\nfrom whylogs.core.statistics import numbertracker\r\n\r\n\r\n\r\nFailed to import MLFLow\r\n---------------------------------------------------------------------------\r\nNameError                                 Traceback (most recent call last)\r\n<ipython-input-1-3964e19b3cb4> in <module>\r\n----> 1 from whylogs.core.statistics import numbertracker\r\n\r\n~\/src\/whylogs-github\/src\/whylogs\/__init__.py in <module>\r\n      4 from .app.session import get_or_create_session\r\n      5 from .app.session import reset_default_session\r\n----> 6 from .mlflow import enable_mlflow\r\n      7 \r\n      8 __all__ = [\r\n\r\n~\/src\/whylogs-github\/src\/whylogs\/mlflow\/__init__.py in <module>\r\n----> 1 from .patcher import enable_mlflow\r\n      2 \r\n      3 __all__ = [\"enable_mlflow\"]\r\n\r\n~\/src\/whylogs-github\/src\/whylogs\/mlflow\/patcher.py in <module>\r\n    145 \r\n    146 _active_whylogs = []\r\n--> 147 _original_end_run = mlflow.tracking.fluent.end_run\r\n    148 \r\n    149 \r\n\r\nNameError: name 'mlflow' is not defined\r\n```",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"nameerror option depend instal follow except time try import numbertrack second time run import work fine python whylog core statist import numbertrack fail import nameerror traceback recent whylog core statist import numbertrack src whylog github src whylog init app session import creat session app session import reset default session import enabl src whylog github src whylog init patcher import enabl enabl src whylog github src whylog patcher activ whylog origin end run track fluent end run nameerror defin",
        "Issue_preprocessed_content":" option depend except time try import second time run import work fine",
        "Issue_gpt_summary_original":"The user is facing a challenge where any user can access any MLflow project, and they want to restrict access to only project members.",
        "Issue_gpt_summary":"user face challeng user access project want restrict access project member",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/konstellation-io\/kdl-server\/issues\/810",
        "Issue_title":"Project template mlflow secret bad name",
        "Issue_created_time":1650980403000,
        "Issue_closed_time":1664791991000,
        "Issue_body":"Currently the `.drone.yaml` is referencing the k8s secret `mlflow-server-secret` which doesn't exist by default.\r\n\r\nWe have noticed that `{{ .ProjectID }}-mlflow-secret` secret is created when a `kdlProject` resource is created.\r\n\r\nTo solve this issue the name of the `mlflow-server-secret` must be changed into `{{ .ProjectID }}-mlflow-secret`",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"project templat secret bad current drone yaml referenc secret server secret exist default notic projectid secret secret creat kdlproject resourc creat solv issu server secret chang projectid secret",
        "Issue_preprocessed_content":"project templat secret bad referenc secret exist default notic secret creat resourc creat solv chang",
        "Issue_gpt_summary_original":"The user is facing an issue where the default MLflow artifact folder is not replacing the `$ARTIFACTS_BUCKET` environment variable.",
        "Issue_gpt_summary":"user face issu default artifact folder replac artifact bucket environ variabl",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/konstellation-io\/kdl-server\/issues\/623",
        "Issue_title":"Project operator mlflow image tag is set to \"latest\"",
        "Issue_created_time":1635429600000,
        "Issue_closed_time":1635871931000,
        "Issue_body":"On chart release v0.13.2 the default value for projectOperator.mlflow.image.tag is set to latest when it should be set to v0.13.2.\r\n\r\nCheck values.yml:\r\n\r\n```yaml\r\nprojectOperator:\r\n  image:\r\n    repository: konstellation\/project-operator\r\n    tag: v0.13.2\r\n    pullPolicy: IfNotPresent\r\n  mlflow:\r\n    image:\r\n      repository: konstellation\/mlflow\r\n      tag: latest\r\n      pullPolicy: IfNotPresent\r\n    volume:\r\n      storageClassName: standard\r\n      size: 1Gi\r\n  filebrowser:\r\n    image:\r\n      repository: filebrowser\/filebrowser\r\n      tag: v2\r\n      pullPolicy: IfNotPresent\r\n```",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"project oper imag tag set latest chart releas default valu projectoper imag tag set latest set check valu yml yaml projectoper imag repositori konstel project oper tag pullpolici ifnotpres imag repositori konstel tag latest pullpolici ifnotpres volum storageclassnam standard size filebrows imag repositori filebrows filebrows tag pullpolici ifnotpres",
        "Issue_preprocessed_content":"project oper imag tag set latest chart releas default valu set latest set check",
        "Issue_gpt_summary_original":"The user has encountered an issue where all MLflow experiments are visible to any user. To address this, they suggest creating a separate instance of MLflow for each project. They propose several steps to implement this solution, including creating a project operator, updating the KDL APP API, and adding the operator to the KDL server helm chart. They also plan to publish the project-operator in Docker Hub using GitHub workflows.",
        "Issue_gpt_summary":"user encount issu experi visibl user address suggest creat separ instanc project propos step implement solut includ creat project oper updat kdl app api ad oper kdl server helm chart plan publish project oper docker hub github workflow",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/konstellation-io\/kdl-server\/issues\/404",
        "Issue_title":"Users can access to any MLflow project",
        "Issue_created_time":1619772559000,
        "Issue_closed_time":1620648494000,
        "Issue_body":"Only allow access to project members for the given MLflow.",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"user access project allow access project member given",
        "Issue_preprocessed_content":"user project project member given",
        "Issue_gpt_summary_original":"The user encountered a \"Connection aborted\" error while trying to perform multi-label classification with \"doc_classification_multilabel.py\". The error occurred during the training process and the user confirmed that their internet connection was stable. The error message suggests that the remote end closed the connection without response. The user is seeking clarification on why this error occurred.",
        "Issue_gpt_summary":"user encount connect abort error try perform multi label classif doc classif multilabel error occur train process user confirm internet connect stabl error messag suggest remot end close connect respons user seek clarif error occur",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/konstellation-io\/kdl-server\/issues\/380",
        "Issue_title":"Bad MLflow artifact folder by default",
        "Issue_created_time":1619181542000,
        "Issue_closed_time":1623230636000,
        "Issue_body":"The artifact folder by default is not reemplacing the `$ARTIFACTS_BUCKET` env var",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"This problem has been solved adding the variable of `$ARTIFACTS_BUCKET` between `()` like this `$(ARTIFACTS_BUCKET)` in the deployment.yaml of the project-operator.",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"bad artifact folder default artifact folder default reemplac artifact bucket env var",
        "Issue_preprocessed_content":"bad artifact folder default artifact folder default env var",
        "Issue_gpt_summary_original":"The user encountered a \"PermissionError\" while trying to log models to mlflow on their Mac. The error occurred when the program attempted to create a directory \"\/var\/lib\/mlflow\" and was denied permission. The user is running mlflow version 1.2 on macOS 12.1.",
        "Issue_gpt_summary":"user encount permissionerror try log model mac error occur program attempt creat directori var lib deni permiss user run version maco",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/konstellation-io\/kdl-server\/issues\/379",
        "Issue_title":"All MLflow experiments are visible for any user",
        "Issue_created_time":1619181390000,
        "Issue_closed_time":1623230615000,
        "Issue_body":"We should create a instance of MLflow for each project in order to see the experiments related to the current project.\r\n\r\n- [x] Create project operator to deploy a MLFlow instance for each project.\r\n- [x] Update KDL APP API to create the KDLProject custom resource in k8s.\r\n- [x] Update kdlctl.sh adding project-operator docker image building.\r\n- [x] Add project-operator to KDL server helm chart.\r\n- [x] Add github workflows to publish the project-operator in docker hub.",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"experi visibl user creat instanc project order experi relat current project creat project oper deploi instanc project updat kdl app api creat kdlproject custom resourc updat kdlctl ad project oper docker imag build add project oper kdl server helm chart add github workflow publish project oper docker hub",
        "Issue_preprocessed_content":"experi visibl user creat instanc project order experi relat project creat project oper deploi instanc project updat kdl api creat kdlproject custom resourc updat docker imag build kdl server helm chart github workflow publish docker hub",
        "Issue_gpt_summary_original":"The user is unable to create a model in MLflowCatalog due to an error message stating that the registered model with the given name does not exist.",
        "Issue_gpt_summary":"user unabl creat model catalog error messag state regist model given exist",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/deepset-ai\/FARM\/issues\/217",
        "Issue_title":"MLFlowLogger: \"Connection aborted.\" - RemoteDisconnected Error",
        "Issue_created_time":1580136891000,
        "Issue_closed_time":1580393757000,
        "Issue_body":"**Describe the bug**\r\nI try to do multi-label classification with \"doc_classification_multilabel.py\". It worked at first. However when it came to `\"Train epoch 1\/1:  65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 17251\/26668 [10:19:41<4:04:28,  1.56s\/it]\"`, it stopped and report:\r\n\r\n```\r\n  File \"\/home\/python3.6\/site-packages\/urllib3\/connectionpool.py\", line 672, in urlopen\r\n    chunked=chunked,\r\n  File \"\/home\/python3.6\/site-packages\/urllib3\/connectionpool.py\", line 421, in _make_request\r\n    six.raise_from(e, None)\r\n  File \"<string>\", line 3, in raise_from\r\n  File \"\/home\/python3.6\/site-packages\/urllib3\/connectionpool.py\", line 416, in _make_request\r\n    httplib_response = conn.getresponse()\r\n  File \"\/home\/python3.6\/http\/client.py\", line 1331, in getresponse\r\n    response.begin()\r\n  File \"\/home\/python3.6\/http\/client.py\", line 297, in begin\r\n    version, status, reason = self._read_status()\r\n  File \"\/home\/python3.6\/http\/client.py\", line 266, in _read_status\r\n    raise RemoteDisconnected(\"Remote end closed connection without\"\r\nhttp.client.RemoteDisconnected: Remote end closed connection without response\r\n......\r\nurllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))\r\n```\r\n\r\n  I have checked that the Internet connection was ok. So I was confused why this error occured ?\r\n  \r\n\r\n**Error message**\r\nError that was thrown (if available)\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here, like type of downstream task, part of  etc.. \r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior\r\n\r\n**System:**\r\n - OS: \r\n - GPU\/CPU:\r\n - FARM version:\r\n",
        "Issue_answer_count":2,
        "Issue_self_closed":0.0,
        "Answer_body":"Hey @JiangYanting, \r\n\r\nAre you using our public mlflow server for logging (i.e. `ml_logger = MLFlowLogger(tracking_uri=\"https:\/\/public-mlflow.deepset.ai\/\")\r\n` in doc_classification_multilabel.py)? \r\n\r\nI would assume that your connection to that server was not available when the model tried to log the train_loss at step 17251. \r\n\r\nI see two solutions:\r\n- short term: you can log locally by setting `ml_logger = MLFlowLogger(tracking_uri=\"\")`\r\n- mid term: implementing a fix in FARM, so that we raise only a warning, if the logging doesn't succeed, but let the training continue. Let me know if you are interested in adding a PR for this. Otherwise, we can take care. It would be basically a try \/ catch block here: https:\/\/github.com\/deepset-ai\/FARM\/blob\/master\/farm\/utils.py#L126 @tholor By setting `ml_logger = MLFlowLogger(tracking_uri=\"\")` , it works. Thank you very much ! ^_^",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"logger connect abort remotedisconnect error bug try multi label classif doc classif multilabel work came train epoch line rais file home python site packag urllib connectionpool line request httplib respons conn getrespons file home python http client line getrespons respons begin file home python http client line begin version statu reason self read statu file home python http client line read statu rais remotedisconnect remot end close connect http client remotedisconnect remot end close connect respons urllib except protocolerror connect abort remotedisconnect remot end close connect respons check internet connect confus error occur error messag error thrown avail expect behavior clear concis descript expect happen addit context add context problem like type downstream task reproduc step reproduc behavior gpu cpu farm version",
        "Issue_preprocessed_content":" bug try work came report check internet confus thrown expect behavior clear concis descript expect context context problem like type downstream task reproduc step reproduc behavior farm version",
        "Issue_gpt_summary_original":"The user encountered a \"ModuleNotFoundError\" issue while running tests due to the absence of the \"mlflow\" module, which is required by the \"rikai.spark.sql.codegen.mlflow_logger\" module.",
        "Issue_gpt_summary":"user encount modulenotfounderror issu run test absenc modul requir rikai spark sql codegen logger modul",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/eto-ai\/rikai\/issues\/499",
        "Issue_title":"Permission denied when log models to mlflow on Mac",
        "Issue_created_time":1642469367000,
        "Issue_closed_time":null,
        "Issue_body":"```\r\n  File \"\/Users\/lei\/miniforge3\/envs\/rikai\/lib\/python3.9\/site-packages\/mlflow\/models\/model.py\", line 188, in log\r\n    mlflow.tracking.fluent.log_artifacts(local_path, artifact_path)\r\n  File \"\/Users\/lei\/miniforge3\/envs\/rikai\/lib\/python3.9\/site-packages\/mlflow\/tracking\/fluent.py\", line 584, in log_artifacts\r\n    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)\r\n  File \"\/Users\/lei\/miniforge3\/envs\/rikai\/lib\/python3.9\/site-packages\/mlflow\/tracking\/client.py\", line 977, in log_artifacts\r\n    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)\r\n  File \"\/Users\/lei\/miniforge3\/envs\/rikai\/lib\/python3.9\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py\", line 334, in log_artifacts\r\n    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)\r\n  File \"\/Users\/lei\/miniforge3\/envs\/rikai\/lib\/python3.9\/site-packages\/mlflow\/store\/artifact\/local_artifact_repo.py\", line 57, in log_artifacts\r\n    mkdir(artifact_dir)\r\n  File \"\/Users\/lei\/miniforge3\/envs\/rikai\/lib\/python3.9\/site-packages\/mlflow\/utils\/file_utils.py\", line 113, in mkdir\r\n    raise e\r\n  File \"\/Users\/lei\/miniforge3\/envs\/rikai\/lib\/python3.9\/site-packages\/mlflow\/utils\/file_utils.py\", line 110, in mkdir\r\n    os.makedirs(target)\r\n  File \"\/Users\/lei\/miniforge3\/envs\/rikai\/lib\/python3.9\/os.py\", line 215, in makedirs\r\n    makedirs(head, exist_ok=exist_ok)\r\n  File \"\/Users\/lei\/miniforge3\/envs\/rikai\/lib\/python3.9\/os.py\", line 215, in makedirs\r\n    makedirs(head, exist_ok=exist_ok)\r\n  File \"\/Users\/lei\/miniforge3\/envs\/rikai\/lib\/python3.9\/os.py\", line 215, in makedirs\r\n    makedirs(head, exist_ok=exist_ok)\r\n  [Previous line repeated 2 more times]\r\n  File \"\/Users\/lei\/miniforge3\/envs\/rikai\/lib\/python3.9\/os.py\", line 225, in makedirs\r\n    mkdir(name, mode)\r\nPermissionError: [Errno 13] Permission denied: '\/var\/lib\/mlflow'\r\n```\r\n\r\nEnvironment:\r\n* mlflow==1.2\r\n* macOS 12.1",
        "Issue_answer_count":2,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"permiss deni log model mac file user lei miniforg env rikai lib python site packag model model line log track fluent log artifact local path artifact path file user lei miniforg env rikai lib python site packag track fluent line log artifact client log artifact run local dir artifact path file user lei miniforg env rikai lib python site packag track client line log artifact self track client log artifact run local dir artifact path file user lei miniforg env rikai lib python site packag track track servic client line log artifact self artifact repo run log artifact local dir artifact path file user lei miniforg env rikai lib python site packag store artifact local artifact repo line log artifact mkdir artifact dir file user lei miniforg env rikai lib python site packag util file util line mkdir rais file user lei miniforg env rikai lib python site packag util file util line mkdir makedir target file user lei miniforg env rikai lib python line makedir makedir head exist exist file user lei miniforg env rikai lib python line makedir makedir head exist exist file user lei miniforg env rikai lib python line makedir makedir head exist exist previou line repeat time file user lei miniforg env rikai lib python line makedir mkdir mode permissionerror errno permiss deni var lib environ maco",
        "Issue_preprocessed_content":"deni log model mac environ maco",
        "Issue_gpt_summary_original":"The user is advised to be cautious while updating Pytorch Lightning to version 1.2.0 as it requires a new version of MLflow.",
        "Issue_gpt_summary":"user advis cautiou updat pytorch lightn version requir new version",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/eto-ai\/rikai\/issues\/493",
        "Issue_title":"Can not create model in MLflowCatalog",
        "Issue_created_time":1642187856000,
        "Issue_closed_time":1642206718000,
        "Issue_body":"```\r\n0: jdbc:hive2:\/\/localhost:10001\/default> CREATE MODEL ssd1 using \"mlflow:\/model\/ssd\"\r\n. . . . . . . . . . . . . . . . . . . .> ;\r\nError: org.apache.hive.service.cli.HiveSQLException: Error running query: org.mlflow.tracking.MlflowHttpException: statusCode=404 reasonPhrase=[NOT FOUND] bodyMessage=[{\"error_code\": \"RESOURCE_DOES_NOT_EXIST\", \"message\": \"Registered Model with name=ssd1 not found\"}]\r\n\tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:361)\r\n\tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:263)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties(SparkOperation.scala:78)\r\n\tat org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperti\r\n```",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"Duplicated to #496 ",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"creat model catalog jdbc hive localhost default creat model ssd model ssd error org apach hive servic cli hivesqlexcept error run queri org track httpexcept statuscod reasonphras bodymessag error code resourc exist messag regist model ssd org apach spark sql hive thriftserv sparkexecutestatementoper org apach spark sql hive thriftserv sparkexecutestatementoper execut sparkexecutestatementoper scala org apach spark sql hive thriftserv sparkexecutestatementoper anon anon anonfun run sparkexecutestatementoper scala scala runtim java jfunction mcv appli jfunction mcv java org apach spark sql hive thriftserv sparkoper withlocalproperti sparkoper scala org apach spark sql hive thriftserv sparkoper withlocalproperti",
        "Issue_preprocessed_content":"creat model catalog ",
        "Issue_gpt_summary_original":"The user is encountering a warning message while training mlflow-pytorch 2.0.0, which states that an unexpected error has occurred during autologging and that the argument must be a string or a number, not 'Accuracy'. This warning message is printed after every epoch.",
        "Issue_gpt_summary":"user encount warn messag train pytorch state unexpect error occur autolog argument string number accuraci warn messag print epoch",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/eto-ai\/rikai\/issues\/492",
        "Issue_title":"MlflowCatalog anonymous function is not registered ",
        "Issue_created_time":1642186768000,
        "Issue_closed_time":1642203169000,
        "Issue_body":"Problem:\r\n```\r\n0: jdbc:hive2:\/\/localhost:10001\/default> select image_id, ML_predict(ssd, image) FROM coco limit 1;\r\nError: org.apache.hive.service.cli.HiveSQLException: Error running query: org.apache.spark.sql.AnalysisException: Undefined function: '<anonymous>'. This function is neither a registered temporary function nor a permanent function registered in the database 'default'.; line 1 pos 17\r\n\tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:361)\r\n\tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:263)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties(SparkOperation.scala:78)\r\n\tat org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties$(SparkOperation.scala:62)\r\n\tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:43)\r\n\tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:263)\r\n\tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:258)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\r\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\r\n\tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:272)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n```\r\n\r\nSteps to reproduce:\r\n\r\n1. Register models into mlflow\r\n2. Start Spark thrift server\r\n3. Use `beeline` to connec to the thrift server:  `beeline -u jdbc:hive2:\/\/localhost:10001\/default`\r\n4. run `SELECT ML_PREDICT(ssd, image) FROM coco`",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"catalog anonym function regist problem jdbc hive localhost default select imag predict ssd imag coco limit error org apach hive servic cli hivesqlexcept error run queri org apach spark sql analysisexcept undefin function function regist temporari function perman function regist databas default line po org apach spark sql hive thriftserv sparkexecutestatementoper org apach spark sql hive thriftserv sparkexecutestatementoper execut sparkexecutestatementoper scala org apach spark sql hive thriftserv sparkexecutestatementoper anon anon anonfun run sparkexecutestatementoper scala scala runtim java jfunction mcv appli jfunction mcv java org apach spark sql hive thriftserv sparkoper withlocalproperti sparkoper scala org apach spark sql hive thriftserv sparkoper withlocalproperti sparkoper scala org apach spark sql hive thriftserv sparkexecutestatementoper withlocalproperti sparkexecutestatementoper scala org apach spark sql hive thriftserv sparkexecutestatementoper anon anon run sparkexecutestatementoper scala org apach spark sql hive thriftserv sparkexecutestatementoper anon anon run sparkexecutestatementoper scala java secur accesscontrol doprivileg nativ method javax secur auth subject doa subject java org apach hadoop secur usergroupinform doa usergroupinform java org apach spark sql hive thriftserv sparkexecutestatementoper anon run sparkexecutestatementoper scala java util concurr executor runnableadapt executor java java util concurr futuretask run futuretask java java util concurr threadpoolexecutor runwork threadpoolexecutor java step reproduc regist model start spark thrift server us beelin connec thrift server beelin jdbc hive localhost default run select predict ssd imag coco",
        "Issue_preprocessed_content":"catalog anonym function regist problem step reproduc regist model start spark thrift server us thrift server run",
        "Issue_gpt_summary_original":"The user encountered inconsistent checks in the linter for subprocess.call and mlflow.log_artifact functions, which caused the template create WFs to fail. The user expected these functions to pass and is looking for a solution to fix the issue.",
        "Issue_gpt_summary":"user encount inconsist check linter subprocess log artifact function caus templat creat wf fail user expect function pass look solut fix issu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/eto-ai\/rikai\/issues\/207",
        "Issue_title":"Leaking mlflow dependency",
        "Issue_created_time":1617993087000,
        "Issue_closed_time":1617994925000,
        "Issue_body":"```\r\ntests\/conftest.py:4: in <module>\r\n    from rikai.spark.sql import init\r\n..\/rikai\/python\/rikai\/__init__.py:19: in <module>\r\n    from rikai.spark.sql.codegen import mlflow_logger as mlflow\r\n..\/rikai\/python\/rikai\/spark\/sql\/codegen\/mlflow_logger.py:19: in <module>\r\n    import mlflow\r\nE   ModuleNotFoundError: No module named 'mlflow'\r\n```",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"leak depend test conftest rikai spark sql import init rikai python rikai init rikai spark sql codegen import logger rikai python rikai spark sql codegen logger import modulenotfounderror modul name",
        "Issue_preprocessed_content":"leak depend ",
        "Issue_gpt_summary_original":"The user encountered an MLFlow API Request 409 Conflict error when deploying jobs with the --assets-only option. The error occurred while uploading a local file, and the response indicated that the file already exists and cannot be overwritten. The user updated a few jobs using the latest dbx version, and MLFlow was only used to define a specific experiment path. The user's environment includes dbx version 0.8.x, Databricks Runtime version 10.4 LTS (standard or ML), and Python version 3.8.11.",
        "Issue_gpt_summary":"user encount api request conflict error deploi job asset option error occur upload local file respons indic file exist overwritten user updat job latest dbx version defin specif experi path user environ includ dbx version databrick runtim version lt standard python version",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/mlf-core\/mlf-core\/issues\/270",
        "Issue_title":"Pytorch Lightning 1.2.0 requires new MLflow version",
        "Issue_created_time":1613838919000,
        "Issue_closed_time":null,
        "Issue_body":"Keep it in mind before mindlessly updating\r\n\r\nhttps:\/\/github.com\/mlflow\/mlflow\/pull\/4118",
        "Issue_answer_count":0,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"pytorch lightn requir new version mind mindlessli updat http github com pull",
        "Issue_preprocessed_content":"pytorch lightn requir new version mind updat",
        "Issue_gpt_summary_original":"The user is encountering an issue while trying to deploy dbx due to an mlflow experiment not being found. The command returns an error message stating that the experiment with the given ID does not exist. The user is trying to set up dbx for the first time on a Mac OS M1 2021 with MacOS Monterey 12.5.",
        "Issue_gpt_summary":"user encount issu try deploi dbx experi command return error messag state experi given exist user try set dbx time mac maco monterei",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/mlf-core\/mlf-core\/issues\/229",
        "Issue_title":"Warning when training mlflow-pytorch 2.0.0",
        "Issue_created_time":1612379283000,
        "Issue_closed_time":1613342987000,
        "Issue_body":"`2021\/02\/03 19:07:05 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during autologging: float() argument must be a string or a number, not 'Accuracy'`\r\n\r\nprinted after every epoch!",
        "Issue_answer_count":2,
        "Issue_self_closed":0.0,
        "Answer_body":"Thats new I did not encountered this while I tested it.  Seems to be gone with my latest changes.\r\nPlease verify @Imipenem and close if not observed.",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"warn train pytorch warn util autolog util encount unexpect error autolog float argument string number accuraci print epoch",
        "Issue_preprocessed_content":"warn train pytorch print epoch",
        "Issue_gpt_summary_original":"The user has encountered a bug where the helm fetch command for ai-engine, sdk-helper, and mlflow includes the 22.09 release instead of 22.11. The user has provided the command used and version details but has not provided any relevant log output or environment printout.",
        "Issue_gpt_summary":"user encount bug helm fetch command engin sdk helper includ releas instead user provid command version detail provid relev log output environ printout",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/mlf-core\/mlf-core\/issues\/171",
        "Issue_title":"subprocess.call and mlflow.log_artifact checks inconsistent in linter",
        "Issue_created_time":1608150046000,
        "Issue_closed_time":1613430703000,
        "Issue_body":"**Describe the bug**\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n* ` f'subprocess.call([\\'conda\\', \\'env\\', \\'export\\', \\'--name\\', \\'{self.project_slug_no_hyphen}\\'], stdout=conda_env_filehandler)',`\r\n* ` f'mlflow.log_artifact(f\\'{{reports_output_dir}}\/{self.project_slug_no_hyphen}_conda_environment.yml\\', artifact_path=\\'reports\\')'`\r\n\r\nThose two linting functions caused the template create WFs (and sometimes even local) to fail\r\n\r\n\r\n**Expected behavior**\r\n<!-- A clear and concise description of what you expected to happen. -->\r\nThey should pass. We should discuss why they fail and how to fix!\r\nSo currently they are outcommented!\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"@Emiller88 the linter should for all templates just check that these methods are called in the templates. Ideally you just need to add those two lines to the linter checks.\r\n\r\nI won't explain the original issue here since I just expect it to work :) If it still doesn't I will reassign @Imipenem and me.\r\n",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"subprocess log artifact check inconsist linter bug subprocess conda env export self project slug hyphen stdout conda env filehandl log artifact report output dir self project slug hyphen conda environ yml artifact path report lint function caus templat creat wf local fail expect behavior pass discuss fail fix current outcom",
        "Issue_preprocessed_content":"check inconsist linter bug clear concis descript bug lint function caus templat creat wf fail expect behavior clear concis descript expect fail fix",
        "Issue_gpt_summary_original":"the user encountered a challenge when attempting to start the digital fingerprinting production server, as the database schema was out-of-date and needed to be migrated in order to work properly.",
        "Issue_gpt_summary":"user encount challeng attempt start digit fingerprint product server databas schema date need migrat order work properli",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/databrickslabs\/dbx\/issues\/548",
        "Issue_title":"MLFlow Error 409 when deploying --assets-only",
        "Issue_created_time":1667484803000,
        "Issue_closed_time":null,
        "Issue_body":"## Expected Behavior\r\nDeploy Jobs with --assets-only option\r\n## Current Behavior\r\nMLFlow API Request 409 Conflict \r\n## Steps to Reproduce (for bugs)\r\n[dbx][2022-11-03 12:30:40.370] \ud83d\udd0e Deployment file is not provided, searching in the conf directory\r\n[dbx][2022-11-03 12:30:40.375] \ud83d\udca1 Auto-discovery found deployment file conf\/deployment.json\r\n[dbx][2022-11-03 12:30:40.376] \ud83c\udd97 Deployment file conf\/deployment.json exists and will be used for deployment\r\n[dbx][2022-11-03 12:30:40.377] Starting new deployment for environment dev\r\n[dbx][2022-11-03 12:30:40.378] Using profile provided from the project file\r\n[dbx][2022-11-03 12:30:40.378] Found auth config from provider EnvironmentVariableConfigProvider, verifying it\r\n[dbx][2022-11-03 12:30:40.379] Found auth config from provider EnvironmentVariableConfigProvider, verification successful\r\n[dbx][2022-11-03 12:30:44.897] \r\n                Since v0.7.0 environment configurations should be nested under environments section.\r\n\r\n                Please nest environment configurations under this section to avoid potential issues while using \"build\"\r\n                configuration directive.\r\n            \r\n[dbx][2022-11-03 12:30:44.899] No build logic defined in the deployment file. Default pip-based build logic will be used.\r\n[dbx][2022-11-03 12:30:44.903] Usage of jobs keyword in deployment file is deprecated. Please use workflows instead (simply rename this section to workflows).\r\n[dbx][2022-11-03 12:30:44.906] Workflows ['add-on-chanel-AT', 'add-on-chanel-PL', 'add-on-PL'] were selected for further operations\r\n[dbx][2022-11-03 12:30:44.907] Following the provided build logic\r\n[dbx][2022-11-03 12:30:44.908] \ud83d\udc0d Building a Python-based project\r\n[dbx][2022-11-03 12:30:46.262] \u2705 Python-based project build finished\r\n[dbx][2022-11-03 12:30:46.264] Locating package file\r\n[dbx][2022-11-03 12:30:46.265] Package file located in: dist\/ds_recommenders-1.2.9-py3-none-any.whl\r\n[dbx][2022-11-03 12:30:47.221] Starting the traversal process\r\n[dbx][2022-11-03 12:30:47.222] Processing libraries for workflow add-on-chanel-AT\r\n[dbx][2022-11-03 12:30:47.223] \u2705 Processing libraries for workflow add-on-chanel-AT - done\r\n[dbx][2022-11-03 12:30:47.224] Processing libraries for workflow add-on-chanel-PL\r\n[dbx][2022-11-03 12:30:47.225] \u2705 Processing libraries for workflow add-on-chanel-PL - done\r\n[dbx][2022-11-03 12:30:47.225] Processing libraries for workflow add-on-PL\r\n[dbx][2022-11-03 12:30:47.226] \u2705 Processing libraries for workflow add-on-PL - done\r\n[dbx][2022-11-03 12:30:47.227] \u2b06 Uploading local file src\/jobs\/add_on_products\/add_on_chanel\/chanel_AT.py\r\n[dbx][2022-11-03 12:30:50.412] \u2705 Uploading local file src\/jobs\/add_on_products\/add_on_chanel\/chanel_AT.py\r\n[dbx][2022-11-03 12:30:50.414] \u2b06 Uploading local file src\/jobs\/add_on_products\/add_on_chanel\/chanel_AT.py\r\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\r\n\u2502 \/opt\/hostedtoolcache\/Python\/3.8.11\/x64\/lib\/python3.8\/site-packages\/dbx\/comma \u2502\r\n\u2502 nds\/deploy.py:157 in deploy                                                  \u2502\r\n\u2502                                                                              \u2502\r\n\u2502   154 \u2502   \u2502   \u2502   \u2502   wf_manager = WorkflowDeploymentManager(api_client, ele \u2502\r\n\u2502   155 \u2502   \u2502   \u2502   \u2502   wf_manager.apply()                                     \u2502\r\n\u2502   156 \u2502   \u2502   else:                                                          \u2502\r\n\u2502 \u2771 157 \u2502   \u2502   \u2502   adjuster.traverse(deployable_workflows)                    \u2502\r\n\u2502   158 \u2502   \u2502   \u2502   if not _assets_only:                                       \u2502\r\n\u2502   159 \u2502   \u2502   \u2502   \u2502   wf_manager = WorkflowDeploymentManager(api_client, dep \u2502\r\n\u2502   [16](https:\/\/github.com\/Flaconi\/DS_Recommenders\/actions\/runs\/3385675925\/jobs\/5624102075#step:11:17)0 \u2502   \u2502   \u2502   \u2502   wf_manager.apply()                                     \u2502\r\n\u2502                                                                              \u2502\r\n\u2502 \/opt\/hostedtoolcache\/Python\/3.8.11\/x64\/lib\/python3.8\/site-packages\/dbx\/api\/a \u2502\r\n\u2502 djuster\/adjuster.py:185 in traverse                                          \u2502\r\n\u2502                                                                              \u2502\r\n\u2502   182 \u2502   def traverse(self, workflows: Union[WorkflowList, List[str]]):     \u2502\r\n\u2502   183 \u2502   \u2502   dbx_echo(\"Starting the traversal process\")                     \u2502\r\n\u2502   184 \u2502   \u2502   self.property_adjuster.library_traverse(workflows, self.additi \u2502\r\n\u2502 \u2771 185 \u2502   \u2502   self.property_adjuster.file_traverse(workflows, self.file_adju \u2502\r\n\u2502   186 \u2502   \u2502   self.property_adjuster.property_traverse(workflows)            \u2502\r\n\u2502   187 \u2502   \u2502   self.property_adjuster.cluster_policy_traverse(workflows)      \u2502\r\n\u2502   188 \u2502   \u2502   dbx_echo(\"Traversal process finished, all provided references  \u2502\r\n\u2502                                                                              \u2502\r\n\u2502 \/opt\/hostedtoolcache\/Python\/3.8.11\/x64\/lib\/python3.8\/site-packages\/dbx\/api\/a \u2502\r\n\u2502 djuster\/adjuster.py:168 in file_traverse                                     \u2502\r\n\u2502                                                                              \u2502\r\n\u2502   165 \u2502   \u2502   for element, parent, index in self.traverse(workflows):        \u2502\r\n\u2502   166 \u2502   \u2502   \u2502   if isinstance(element, str):                               \u2502\r\n\u2502   167 \u2502   \u2502   \u2502   \u2502   if element.startswith(\"file:\/\/\") or element.startswith \u2502\r\n\u2502 \u2771 168 \u2502   \u2502   \u2502   \u2502   \u2502   file_adjuster.adjust_file_ref(element, parent, ind \u2502\r\n\u2502   169                                                                        \u2502\r\n\u2502   [17](https:\/\/github.com\/Flaconi\/DS_Recommenders\/actions\/runs\/3385675925\/jobs\/5624102075#step:11:18)0                                                                        \u2502\r\n\u2502   171 class Adjuster:                                                        \u2502\r\n\u2502                                                                              \u2502\r\n\u2502 \/opt\/hostedtoolcache\/Python\/3.8.11\/x64\/lib\/python3.8\/site-packages\/dbx\/api\/a \u2502\r\n\u2502 djuster\/mixins\/file_reference.py:12 in adjust_file_ref                       \u2502\r\n\u2502                                                                              \u2502\r\n\u2502    9 \u2502   \u2502   self._uploader = file_uploader                                  \u2502\r\n\u2502   10 \u2502                                                                       \u2502\r\n\u2502   11 \u2502   def adjust_file_ref(self, element: str, parent: Any, index: Any):   \u2502\r\n\u2502 \u2771 12 \u2502   \u2502   _uploaded = self._uploader.upload_and_provide_path(element)     \u2502\r\n\u2502   13 \u2502   \u2502   self.set_element_at_parent(_uploaded, parent, index)            \u2502\r\n\u2502   14                                                                         \u2502\r\n\u2502                                                                              \u2502\r\n\u2502 \/opt\/hostedtoolcache\/Python\/3.8.11\/x64\/lib\/python3.8\/site-packages\/dbx\/utils \u2502\r\n\u2502 \/file_uploader.py:59 in upload_and_provide_path                              \u2502\r\n\u2502                                                                              \u2502\r\n\u2502   56 \u2502   \u2502   \u2502   self._verify_fuse_support()                                 \u2502\r\n\u2502   57 \u2502   \u2502                                                                   \u2502\r\n\u2502   58 \u2502   \u2502   dbx_echo(f\":arrow_up: Uploading local file {local_file_path}\")  \u2502\r\n\u2502 \u2771 59 \u2502   \u2502   self._upload_file(local_file_path)                              \u2502\r\n\u2502   60 \u2502   \u2502   dbx_echo(f\":white_check_mark: Uploading local file {local_file_ \u2502\r\n\u2502   61 \u2502   \u2502   return self._postprocess_path(local_file_path, as_fuse)         \u2502\r\n\u2502   62                                                                         \u2502\r\n\u2502 \/opt\/hostedtoolcache\/Python\/3.8.11\/x64\/lib\/python3.8\/site-packages\/mlflow\/ut \u2502\r\n\u2502 ils\/rest_utils.py:[19](https:\/\/github.com\/Flaconi\/DS_Recommenders\/actions\/runs\/3385675925\/jobs\/5624102075#step:11:20)9 in http_request_safe                                   \u2502\r\n\u2502                                                                              \u2502\r\n\u2502   196 \u2502   Wrapper around ``http_request`` that also verifies that the reques \u2502\r\n\u2502   197 \u2502   \"\"\"                                                                \u2502\r\n\u2502   198 \u2502   response = http_request(host_creds=host_creds, endpoint=endpoint,  \u2502\r\n\u2502 \u2771 199 \u2502   return verify_rest_response(response, endpoint)                    \u2502\r\n\u2502   [20](https:\/\/github.com\/Flaconi\/DS_Recommenders\/actions\/runs\/3385675925\/jobs\/5624102075#step:11:21)0                                                                        \u2502\r\n\u2502   201                                                                        \u2502\r\n\u2502   202 def verify_rest_response(response, endpoint):                          \u2502\r\n\u2502                                                                              \u2502\r\n\u2502 \/opt\/hostedtoolcache\/Python\/3.8.11\/x64\/lib\/python3.8\/site-packages\/mlflow\/ut \u2502\r\n\u2502 ils\/rest_utils.py:[21](https:\/\/github.com\/Flaconi\/DS_Recommenders\/actions\/runs\/3385675925\/jobs\/5624102075#step:11:22)2 in verify_rest_response                                \u2502\r\n\u2502                                                                              \u2502\r\n\u2502   209 \u2502   \u2502   \u2502   \u2502   endpoint,                                              \u2502\r\n\u2502   210 \u2502   \u2502   \u2502   \u2502   response.status_code,                                  \u2502\r\n\u2502   211 \u2502   \u2502   \u2502   )                                                          \u2502\r\n\u2502 \u2771 212 \u2502   \u2502   \u2502   raise MlflowException(                                     \u2502\r\n\u2502   213 \u2502   \u2502   \u2502   \u2502   \"%s. Response body: '%s'\" % (base_msg, response.text), \u2502\r\n\u2502   214 \u2502   \u2502   \u2502   \u2502   error_code=get_error_code(response.status_code),       \u2502\r\n\u2502   215 \u2502   \u2502   \u2502   )                                                          \u2502\r\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\r\nMlflowException: API request to endpoint \r\n\/dbfs\/Shared\/ds_recommenders\/projects\/ds_recommenders_experiments\/8cfd06c9088742\r\n8b97e6371f9[22](https:\/\/github.com\/Flaconi\/DS_Recommenders\/actions\/runs\/3385675925\/jobs\/5624102075#step:11:23)5de5a\/artifacts\/src\/jobs\/add_on_products\/add_on_chanel\/chanel_AT.py\r\n failed with error code 409 != 200. Response body: '<html>\r\n<head>\r\n<meta http-equiv=\"Content-Type\" content=\"text\/html;charset=ISO-8859-1\"\/>\r\n<title>Error 409 <\/title>\r\n<\/head>\r\n<body>\r\n<h2>HTTP ERROR: 409<\/h2>\r\n<p>Problem accessing \r\n\/dbfs\/Shared\/ds_recommenders\/projects\/ds_recommenders_experiments\/8cfd06c9088742\r\n8b97e6371f92[25](https:\/\/github.com\/Flaconi\/DS_Recommenders\/actions\/runs\/3385675925\/jobs\/5624102075#step:11:26)de5a\/artifacts\/src\/jobs\/add_on_products\/add_on_chanel\/chanel_AT.py\r\n. Reason:\r\n<pre>    File already exists, cannot overwrite: \r\n&apos;\/Shared\/ds_recommenders\/projects\/ds_recommenders_experiments\/8cfd06c908874\r\n[28](https:\/\/github.com\/Flaconi\/DS_Recommenders\/actions\/runs\/3385675925\/jobs\/5624102075#step:11:29)b97e6[37](https:\/\/github.com\/Flaconi\/DS_Recommenders\/actions\/runs\/3385675925\/jobs\/5624102075#step:11:38)1f[92](https:\/\/github.com\/Flaconi\/DS_Recommenders\/actions\/runs\/3385675925\/jobs\/5624102075#step:11:93)25de5a\/artifacts\/src\/jobs\/add_on_products\/add_on_chanel\/chanel_AT.p\r\ny&apos;<\/pre><\/p>\r\n<hr \/>\r\n<\/body>\r\n<\/html>\r\n'\r\nError: Process completed with exit code 1.\r\n\r\n## Context\r\nUpdated few jobs today using the latest dbx version, and at the jobless deployment cicd step I get the error above.\r\nMLFlow is only used to define a specific experiment path. No path related updates or changes here!\r\n## Your Environment\r\n\r\n* dbx version used: 0.8.x\r\n* Databricks Runtime version:  10.4 LTS (standard or ML)\r\n* Python version: 3.8.11",
        "Issue_answer_count":5,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"error deploi asset expect behavior deploi job asset option current behavior api request conflict step reproduc bug dbx deploy file provid search conf directori dbx auto discoveri deploy file conf deploy json dbx deploy file conf deploy json exist deploy dbx start new deploy environ dev dbx profil provid project file dbx auth config provid environmentvariableconfigprovid verifi dbx auth config provid environmentvariableconfigprovid verif success dbx environ configur nest environ section nest environ configur section avoid potenti issu build configur direct dbx build logic defin deploy file default pip base build logic dbx usag job keyword deploy file deprec us workflow instead simpli renam section workflow dbx workflow add chanel add chanel add select oper dbx follow provid build logic dbx build python base project dbx python base project build finish dbx locat packag file dbx packag file locat dist recommend whl dbx start travers process dbx process librari workflow add chanel dbx process librari workflow add chanel dbx process librari workflow add chanel dbx process librari workflow add chanel dbx process librari workflow add dbx process librari workflow add dbx upload local file src job add product add chanel chanel dbx upload local file src job add product add chanel chanel dbx upload local file src job add product add chanel chanel traceback recent opt hostedtoolcach python lib python site packag dbx comma nd deploi deploi manag workflowdeploymentmanag api client el manag appli adjust travers deploy workflow asset manag workflowdeploymentmanag api client dep http github com flaconi recommend action run job step manag appli opt hostedtoolcach python lib python site packag dbx api djuster adjust travers def travers self workflow union workflowlist list str dbx echo start travers process self properti adjust librari travers workflow self additi self properti adjust file travers workflow self file adju self properti adjust properti travers workflow self properti adjust cluster polici travers workflow dbx echo travers process finish provid refer opt hostedtoolcach python lib python site packag dbx api djuster adjust file travers element parent index self travers workflow isinst element str element startswith file element startswith file adjust adjust file ref element parent ind http github com flaconi recommend action run job step class adjust opt hostedtoolcach python lib python site packag dbx api djuster mixin file refer adjust file ref self upload file upload def adjust file ref self element str parent index upload self upload upload provid path element self set element parent upload parent index opt hostedtoolcach python lib python site packag dbx util file upload upload provid path self verifi fuse support dbx echo arrow upload local file local file path self upload file local file path dbx echo white check mark upload local file local file return self postprocess path local file path fuse opt hostedtoolcach python lib python site packag il rest util http github com flaconi recommend action run job step http request safe wrapper http request verifi requ respons http request host cred host cred endpoint endpoint return verifi rest respons respons endpoint http github com flaconi recommend action run job step def verifi rest respons respons endpoint opt hostedtoolcach python lib python site packag il rest util http github com flaconi recommend action run job step verifi rest respons endpoint respons statu code rais except respons bodi base msg respons text error code error code respons statu code except api request endpoint dbf share recommend project recommend experi cfdc bef http github com flaconi recommend action run job step dea artifact src job add product add chanel chanel fail error code respons bodi error http error problem access dbf share recommend project recommend experi cfdc bef http github com flaconi recommend action run job step dea artifact src job add product add chanel chanel reason file exist overwrit apo share recommend project recommend experi cfdc http github com flaconi recommend action run job step http github com flaconi recommend action run job step http github com flaconi recommend action run job step dea artifact src job add product add chanel chanel apo error process complet exit code context updat job todai latest dbx version jobless deploy cicd step error defin specif experi path path relat updat chang environ dbx version databrick runtim version lt standard python version",
        "Issue_preprocessed_content":"deploi expect behavior deploi job option behavior api request conflict step reproduc deploy file provid search conf directori deploy file deploy file exist deploy start new deploy environ dev profil provid project file auth config provid environmentvariableconfigprovid verifi auth config provid environmentvariableconfigprovid verif environ configur nest environ section nest environ configur section avoid potenti build configur direct build logic defin deploy file default build logic usag job keyword deploy file deprec us workflow instead workflow select oper provid build logic build project project build finish locat packag file packag file locat start travers librari workflow librari workflow librari workflow librari workflow librari workflow librari workflow upload local file upload local file upload local file traceback deploi el dep travers def travers travers finish provid refer element parent index isinst parent ind adjust def element str parent index parent index upload local file upload local file return verifi requ respons endpoint endpoint return endpoint def endpoint endpoint rais except except api request endpoint fail code respons bodi head meta titl head bodi problem reason pre file exist overwrit bodi html complet exit code context updat job todai latest dbx version deploy cicd step defin specif experi path path relat updat chang environ dbx version databrick runtim version lt python version",
        "Issue_gpt_summary_original":"The user encountered a bug while using `mlflow deployment create` command, which failed unexpectedly. The error message indicated that the model could not be loaded due to the unavailability of the version. The suggested fix is to delete the mlflow pod and start over. The user was using Kubernetes for Morpheus install on LaunchPad. The MLflow sqlite db may have been corrupted, and there could be an issue with tritonclient.",
        "Issue_gpt_summary":"user encount bug deploy creat command fail unexpectedli error messag indic model load unavail version suggest fix delet pod start user kubernet morpheu instal launchpad sqlite corrupt issu tritoncli",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/databrickslabs\/dbx\/issues\/385",
        "Issue_title":"dbx deploy fails due to mlflow experiment not found",
        "Issue_created_time":1660398516000,
        "Issue_closed_time":1661539227000,
        "Issue_body":"## Expected Behavior\r\n`dbx deploy --environment=default` succeeds\r\n\r\n## Current Behavior\r\nThe command returns \r\n`mlflow.exceptions.RestException: INVALID_PARAMETER_VALUE: Experiment with id '2170254243754186' does not exist.`\r\n\r\n## Steps to Reproduce (for bugs)\r\nFollow the instructions at https:\/\/docs.gcp.databricks.com\/dev-tools\/ide-how-to.html#run-with-dbx\r\n\r\n## Context\r\nTrying to set up dbx for the first time.\r\n\r\n## Your Environment\r\nmac os m1 2021 with macos Monterey 12.5\r\n\r\n* dbx version used: DataBricks eXtensions aka dbx, version ~> 0.6.11\r\n* Databricks Runtime version: Version 0.17.1",
        "Issue_answer_count":8,
        "Issue_self_closed":0.0,
        "Answer_body":"hi @zermelozf , \r\ncould you please provide full stack trace?  Sure, here it is:\r\n\r\n```\r\ndbx deploy --environment=default\r\n[dbx][2022-08-13 22:46:37.005] Starting new deployment for environment default\r\n[dbx][2022-08-13 22:46:37.006] Using profile provided from the project file\r\n[dbx][2022-08-13 22:46:37.006] Found auth config from provider ProfileEnvConfigProvider, verifying it\r\n[dbx][2022-08-13 22:46:37.007] Found auth config from provider ProfileEnvConfigProvider, verification successful\r\n[dbx][2022-08-13 22:46:37.007] Profile DEFAULT will be used for deployment\r\nTraceback (most recent call last):\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/bin\/dbx\", line 8, in <module>\r\n    sys.exit(cli())\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/click\/core.py\", line 1130, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/click\/core.py\", line 1055, in main\r\n    rv = self.invoke(ctx)\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/click\/core.py\", line 1657, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/click\/core.py\", line 1404, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/click\/core.py\", line 760, in invoke\r\n    return __callback(*args, **kwargs)\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/dbx\/commands\/deploy.py\", line 143, in deploy\r\n    api_client = prepare_environment(environment)\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/dbx\/utils\/common.py\", line 38, in prepare_environment\r\n    MlflowStorageConfigurationManager.prepare(info)\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/dbx\/api\/storage\/mlflow_based.py\", line 42, in prepare\r\n    cls._setup_experiment(properties)\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/dbx\/api\/storage\/mlflow_based.py\", line 53, in _setup_experiment\r\n    experiment: Optional[Experiment] = mlflow.get_experiment_by_name(properties.workspace_dir)\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/mlflow\/tracking\/fluent.py\", line 1042, in get_experiment_by_name\r\n    return MlflowClient().get_experiment_by_name(name)\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/mlflow\/tracking\/client.py\", line 566, in get_experiment_by_name\r\n    return self._tracking_client.get_experiment_by_name(name)\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py\", line 226, in get_experiment_by_name\r\n    return self.store.get_experiment_by_name(name)\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 365, in get_experiment_by_name\r\n    raise e\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 351, in get_experiment_by_name\r\n    response_proto = self._call_endpoint(GetExperimentByName, req_body)\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 57, in _call_endpoint\r\n    return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/mlflow\/utils\/rest_utils.py\", line 274, in call_endpoint\r\n    response = verify_rest_response(response, endpoint)\r\n  File \"\/opt\/homebrew\/anaconda3\/envs\/databricks\/lib\/python3.9\/site-packages\/mlflow\/utils\/rest_utils.py\", line 200, in verify_rest_response\r\n    raise RestException(json.loads(response.text))\r\nmlflow.exceptions.RestException: INVALID_PARAMETER_VALUE: Experiment with id '2170254243754186' does not exist.\r\n``` hi @zermelozf , \r\nit seems to me that you're using an old version of `dbx`. Please upgrade to the latest 0.7.0 (or at least to 0.6.12).  hi @renardeinside I had the same issue mentioned here. I upgraded to dbx 0.7.0 and now the error looks like this:\r\nRestException: INVALID_PARAMETER_VALUE: Experiment with id '2624352622693299' does not exist.\r\nIt only happens if you deploy a job for the first time. Deploying changes to an existing job works fine. hi @frida-ah , \r\nwhat's the MLflow version you're using? I'm asking because I'm not running into this issue in any of the tests  could you please also verify that you have correct [databricks profile configured as in Step 3 point 4 of the public doc](https:\/\/docs.gcp.databricks.com\/dev-tools\/ide-how-to.html#step-3-install-the-code-samples-dependencies)?\r\n\r\nif it's still the case, please provide the deploy command with `dbx deploy --debug` option (please feel free to omit the host url)? \r\nReally curious where is this coming from.\r\n Hi @renardeinside I don't have mlflow in my requirements.txt. I can also confirm that I have the correct databricks profile configured in the deployment.json file as such:\r\n\r\n{\r\n  \"environments\": {\r\n    \"default\": {\r\n      \"profile\": \"DEFAULT\",\r\n      \"workspace_dir\": \"\/Shared\/dbx\/projects\/<project_name>\/<...>\",\r\n      \"artifact_location\": \"dbfs:\/Shared\/dbx\/projects\/<project_name>\/<...>\"\r\n    }\r\n  }\r\n}\r\n\r\ndbx deploy --environment default --deployment-file=conf\/deployment.json --jobs=<job_name>\r\n\r\nI have fixed the issue using a workaround - sorry I didn't have more time to invest in this. I created an artifact manually through the UI in the location where the artifact should be. Then I deleted it. And then the artifact was created again through the IDE and GitHub Actions. \r\n\r\nI think the issue is with Databricks having a bug when creating an artifact for the first time.  hi @frida-ah , \r\nstill pretty strange behaviour, but thanks a lot anyways. We're going to change the mlflow client logic accordingly to fix this issue.",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"dbx deploi fail experi expect behavior dbx deploi environ default succe current behavior command return except restexcept invalid paramet valu experi exist step reproduc bug follow instruct http doc gcp databrick com dev tool id html run dbx context try set dbx time environ mac maco monterei dbx version databrick extens aka dbx version databrick runtim version version",
        "Issue_preprocessed_content":"dbx deploi fail experi expect behavior behavior return step reproduc instruct context try set dbx time environ mac maco monterei dbx version databrick extens aka dbx version databrick runtim version version",
        "Issue_gpt_summary_original":"The user is facing an issue with MLFlow while running hyperparameter tuning as it expects an mlruns folder which they have not created. This can be resolved by sticking to the standard and avoiding the need to run `mlflow ui` with the backend store argument.",
        "Issue_gpt_summary":"user face issu run hyperparamet tune expect folder creat resolv stick standard avoid need run backend store argument",
        "Issue_score_count":1
    },
    {
        "Issue_link":"https:\/\/github.com\/nv-morpheus\/Morpheus\/issues\/576",
        "Issue_title":"[BUG]: Helm fetch command for ai-engine,sdk-helper and mlflow includes the 22.09 release instead of 22.11",
        "Issue_created_time":1671535506000,
        "Issue_closed_time":null,
        "Issue_body":"### Version\r\n\r\n22.11\r\n\r\n### Which installation method(s) does this occur on?\r\n\r\n_No response_\r\n\r\n### Describe the bug.\r\n\r\nai-engine fetch command at the 22.11 guide:\r\nhelm fetch https:\/\/helm.ngc.nvidia.com\/nvidia\/morpheus\/charts\/morpheus-ai-engine-**22.09**.tgz --username='$oauthtoken' --password=$API_KEY --untar\r\n\r\nhelm fetch https:\/\/helm.ngc.nvidia.com\/nvidia\/morpheus\/charts\/morpheus-sdk-client-22.09.tgz --username='$oauthtoken' --password=$API_KEY --untar\r\n\r\nhelm fetch https:\/\/helm.ngc.nvidia.com\/nvidia\/morpheus\/charts\/morpheus-mlflow-22.09.tgz --username='$oauthtoken' --password=$API_KEY --untar\r\n\r\n### Minimum reproducible example\r\n\r\n_No response_\r\n\r\n### Relevant log output\r\n\r\n_No response_\r\n\r\n### Full env printout\r\n\r\n_No response_\r\n\r\n### Other\/Misc.\r\n\r\n_No response_\r\n\r\n### Code of Conduct\r\n\r\n- [X] I agree to follow Morpheus' Code of Conduct\r\n- [X] I have searched the [open bugs](https:\/\/github.com\/nv-morpheus\/Morpheus\/issues?q=is%3Aopen+is%3Aissue+label%3Abug) and have found no duplicates for this bug report",
        "Issue_answer_count":0,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"bug helm fetch command engin sdk helper includ releas instead version instal method occur respons bug engin fetch command guid helm fetch http helm ngc nvidia com nvidia morpheu chart morpheu engin tgz usernam oauthtoken password api kei untar helm fetch http helm ngc nvidia com nvidia morpheu chart morpheu sdk client tgz usernam oauthtoken password api kei untar helm fetch http helm ngc nvidia com nvidia morpheu chart morpheu tgz usernam oauthtoken password api kei untar minimum reproduc exampl respons relev log output respons env printout respons misc respons code conduct agre follow morpheu code conduct search open bug http github com morpheu morpheu issu aopen aissu label abug duplic bug report",
        "Issue_preprocessed_content":"helm fetch includ releas instead version method bug fetch guid helm fetch helm fetch helm fetch minimum reproduc exampl relev log output env printout code conduct morpheu code conduct search duplic bug report",
        "Issue_gpt_summary_original":"The issue is that failed ERT (External Resource Tool) subprocesses are not being registered correctly in mlflow. If the subprocess fails for any reason other than what is hard coded, a return code larger than 0 is ignored, resulting in a \"successful\" run in mlflow instead of a failed one.",
        "Issue_gpt_summary":"issu fail ert extern resourc tool subprocess regist correctli subprocess fail reason hard code return code larger ignor result success run instead fail",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/nv-morpheus\/Morpheus\/issues\/512",
        "Issue_title":"[BUG]: Unable to Start DFP Production MLFlow Server",
        "Issue_created_time":1669916494000,
        "Issue_closed_time":1669922495000,
        "Issue_body":"### Version\r\n\r\n23.01\r\n\r\n### Which installation method(s) does this occur on?\r\n\r\nDocker\r\n\r\n### Describe the bug.\r\n\r\nUnable to start the mlflow server when using `branch-22.11` but it works fine with `branch-22.09`\r\n\r\nDowngrading  mlflow version to `<1.29.0` works fine.\r\n\r\n\r\n### Minimum reproducible example\r\n\r\n```shell\r\n$ cd ~\/Morpheus\/examples\/digital_fingerprinting\/production\r\n\r\n$ docker-compose up mlflow\r\n```\r\n\r\n\r\n### Relevant log output\r\n\r\n```shell\r\n[+] Running 3\/3                                                                                                                                               \r\n \u283f Network production_backend      Created                                                                                                               0.0s \r\n \u283f Network production_frontend     Created                                                                                                               0.0s\r\n \u283f Container mlflow_server  Created                                                                                                               0.1s\r\nAttaching to mlflow_server\r\nmlflow_server  | 2022\/12\/01 17:30:28 ERROR mlflow.cli: Error initializing backend store\r\nmlflow_server  | 2022\/12\/01 17:30:28 ERROR mlflow.cli: Detected out-of-date database schema (found version cc1f77228345, but expected 97727af70f4d). Take a backup of your database, then run 'mlflow db upgrade <database_uri>' to migrate your database to the latest schema. NOTE: schema migration may result in database downtime - please consult your database's documentation for more detail.\r\nmlflow_server  | Traceback (most recent call last):\r\nmlflow_server  |   File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/cli.py\", line 392, in server\r\nmlflow_server  |     initialize_backend_stores(backend_store_uri, registry_store_uri, default_artifact_root)\r\nmlflow_server  |   File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/server\/handlers.py\", line 265, in initialize_backend_stores\r\nmlflow_server  |     _get_tracking_store(backend_store_uri, default_artifact_root)\r\nmlflow_server  |   File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/server\/handlers.py\", line 244, in _get_tracking_store\r\nmlflow_server  |     _tracking_store = _tracking_store_registry.get_store(store_uri, artifact_root)\r\nmlflow_server  |   File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/tracking\/_tracking_service\/registry.py\", line 39, in get_store\r\nmlflow_server  |     return self._get_store_with_resolved_uri(resolved_store_uri, artifact_uri)\r\nmlflow_server  |   File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/tracking\/_tracking_service\/registry.py\", line 49, in _get_store_with_resolved_uri\r\nmlflow_server  |     return builder(store_uri=resolved_store_uri, artifact_uri=artifact_uri)\r\nmlflow_server  |   File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/server\/handlers.py\", line 112, in _get_sqlalchemy_store\r\nmlflow_server  |     return SqlAlchemyStore(store_uri, artifact_uri)\r\nmlflow_server  |   File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/store\/tracking\/sqlalchemy_store.py\", line 150, in __init__\r\nmlflow_server  |     mlflow.store.db.utils._verify_schema(self.engine)\r\nmlflow_server  |   File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/store\/db\/utils.py\", line 71, in _verify_schema\r\nmlflow_server  |     raise MlflowException(\r\nmlflow_server  | mlflow.exceptions.MlflowException: Detected out-of-date database schema (found version cc1f77228345, but expected 97727af70f4d). Take a backup of your database, then run 'mlflow db upgrade <database_uri>' to migrate your database to the latest schema. NOTE: schema migration may result in database downtime - please consult your database's documentation for more detail.\r\nmlflow_server exited with code 1\r\n```\r\n\r\n\r\n### Full env printout\r\n\r\n```shell\r\n<details><summary>Click here to see environment details<\/summary><pre>\r\n     \r\n     **git***\r\n     commit 9619c0e3a5ddbdd476aba9331f288aac855da7cd (HEAD -> dfp-pipeline-module, origin\/dfp-pipeline-module)\r\n     Author: bsuryadevara <bhargavsuryadevara@gmail.com>\r\n     Date:   Wed Nov 30 17:13:05 2022 -0600\r\n     \r\n     used dill to persist source and preprocess schema\r\n     **git submodules***\r\n     -27efc4fd1c984332920db2a2d6ab1f84d3cb55cd external\/morpheus-visualizations\r\n     \r\n     ***OS Information***\r\n     DGX_NAME=\"DGX Server\"\r\n     DGX_PRETTY_NAME=\"NVIDIA DGX Server\"\r\n     DGX_SWBUILD_DATE=\"2020-03-04\"\r\n     DGX_SWBUILD_VERSION=\"4.4.0\"\r\n     DGX_COMMIT_ID=\"ee09ebc\"\r\n     DGX_PLATFORM=\"DGX Server for DGX-1\"\r\n     DGX_SERIAL_NUMBER=\"QTFCOU7140058-R1\"\r\n     DISTRIB_ID=Ubuntu\r\n     DISTRIB_RELEASE=18.04\r\n     DISTRIB_CODENAME=bionic\r\n     DISTRIB_DESCRIPTION=\"Ubuntu 18.04.6 LTS\"\r\n     NAME=\"Ubuntu\"\r\n     VERSION=\"18.04.6 LTS (Bionic Beaver)\"\r\n     ID=ubuntu\r\n     ID_LIKE=debian\r\n     PRETTY_NAME=\"Ubuntu 18.04.6 LTS\"\r\n     VERSION_ID=\"18.04\"\r\n     HOME_URL=\"https:\/\/www.ubuntu.com\/\"\r\n     SUPPORT_URL=\"https:\/\/help.ubuntu.com\/\"\r\n     BUG_REPORT_URL=\"https:\/\/bugs.launchpad.net\/ubuntu\/\"\r\n     PRIVACY_POLICY_URL=\"https:\/\/www.ubuntu.com\/legal\/terms-and-policies\/privacy-policy\"\r\n     VERSION_CODENAME=bionic\r\n     UBUNTU_CODENAME=bionic\r\n     Linux dgx04 4.15.0-162-generic #170-Ubuntu SMP Mon Oct 18 11:38:05 UTC 2021 x86_64 x86_64 x86_64 GNU\/Linux\r\n     \r\n     ***GPU Information***\r\n     Thu Dec  1 17:37:05 2022\r\n     +-----------------------------------------------------------------------------+\r\n     | NVIDIA-SMI 495.29.05    Driver Version: 495.29.05    CUDA Version: 11.5     |\r\n     |-------------------------------+----------------------+----------------------+\r\n     | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n     | Fan  Temp  Perf  Pwr:Usage\/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n     |                               |                      |               MIG M. |\r\n     |===============================+======================+======================|\r\n     |   0  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |\r\n     | N\/A   32C    P0    56W \/ 300W |  11763MiB \/ 32510MiB |      0%      Default |\r\n     |                               |                      |                  N\/A |\r\n     +-------------------------------+----------------------+----------------------+\r\n     |   1  Tesla V100-SXM2...  On   | 00000000:07:00.0 Off |                    0 |\r\n     | N\/A   32C    P0    43W \/ 300W |      3MiB \/ 32510MiB |      0%      Default |\r\n     |                               |                      |                  N\/A |\r\n     +-------------------------------+----------------------+----------------------+\r\n     |   2  Tesla V100-SXM2...  On   | 00000000:0A:00.0 Off |                    0 |\r\n     | N\/A   30C    P0    42W \/ 300W |      3MiB \/ 32510MiB |      0%      Default |\r\n     |                               |                      |                  N\/A |\r\n     +-------------------------------+----------------------+----------------------+\r\n     |   3  Tesla V100-SXM2...  On   | 00000000:0B:00.0 Off |                    0 |\r\n     | N\/A   28C    P0    41W \/ 300W |      3MiB \/ 32510MiB |      0%      Default |\r\n     |                               |                      |                  N\/A |\r\n     +-------------------------------+----------------------+----------------------+\r\n     |   4  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |\r\n     | N\/A   29C    P0    44W \/ 300W |      3MiB \/ 32510MiB |      0%      Default |\r\n     |                               |                      |                  N\/A |\r\n     +-------------------------------+----------------------+----------------------+\r\n     |   5  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |\r\n     | N\/A   31C    P0    42W \/ 300W |      3MiB \/ 32510MiB |      0%      Default |\r\n     |                               |                      |                  N\/A |\r\n     +-------------------------------+----------------------+----------------------+\r\n     |   6  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |\r\n     | N\/A   32C    P0    42W \/ 300W |      3MiB \/ 32510MiB |      0%      Default |\r\n     |                               |                      |                  N\/A |\r\n     +-------------------------------+----------------------+----------------------+\r\n     |   7  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |\r\n     | N\/A   30C    P0    42W \/ 300W |      3MiB \/ 32510MiB |      0%      Default |\r\n     |                               |                      |                  N\/A |\r\n     +-------------------------------+----------------------+----------------------+\r\n     \r\n     +-----------------------------------------------------------------------------+\r\n     | Processes:                                                                  |\r\n     |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n     |        ID   ID                                                   Usage      |\r\n     |=============================================================================|\r\n     |    0   N\/A  N\/A     31232      C   ...da\/envs\/rapids\/bin\/python      303MiB |\r\n     |    0   N\/A  N\/A     41206      C   ...da\/envs\/rapids\/bin\/python     7051MiB |\r\n     |    0   N\/A  N\/A     52497      C   ...nda3\/envs\/venv\/bin\/python     3137MiB |\r\n     |    0   N\/A  N\/A     55973      C   tritonserver                     1267MiB |\r\n     +-----------------------------------------------------------------------------+\r\n     \r\n     ***CPU***\r\n     Architecture:        x86_64\r\n     CPU op-mode(s):      32-bit, 64-bit\r\n     Byte Order:          Little Endian\r\n     CPU(s):              80\r\n     On-line CPU(s) list: 0-79\r\n     Thread(s) per core:  2\r\n     Core(s) per socket:  20\r\n     Socket(s):           2\r\n     NUMA node(s):        2\r\n     Vendor ID:           GenuineIntel\r\n     CPU family:          6\r\n     Model:               79\r\n     Model name:          Intel(R) Xeon(R) CPU E5-2698 v4 @ 2.20GHz\r\n     Stepping:            1\r\n     CPU MHz:             3267.078\r\n     CPU max MHz:         3600.0000\r\n     CPU min MHz:         1200.0000\r\n     BogoMIPS:            4390.17\r\n     Virtualization:      VT-x\r\n     L1d cache:           32K\r\n     L1i cache:           32K\r\n     L2 cache:            256K\r\n     L3 cache:            51200K\r\n     NUMA node0 CPU(s):   0-19,40-59\r\n     NUMA node1 CPU(s):   20-39,60-79\r\n     Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 cdp_l3 invpcid_single pti intel_ppin ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap intel_pt xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts md_clear flush_l1d\r\n     \r\n     ***CMake***\r\n     \/usr\/bin\/cmake\r\n     cmake version 3.10.2\r\n     \r\n     CMake suite maintained and supported by Kitware (kitware.com\/cmake).\r\n     \r\n     ***g++***\r\n     \/usr\/bin\/g++\r\n     g++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\r\n     Copyright (C) 2017 Free Software Foundation, Inc.\r\n     This is free software; see the source for copying conditions.  There is NO\r\n     warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n     \r\n     \r\n     ***nvcc***\r\n     \/usr\/local\/cuda\/bin\/nvcc\r\n     nvcc: NVIDIA (R) Cuda compiler driver\r\n     Copyright (c) 2005-2021 NVIDIA Corporation\r\n     Built on Thu_Nov_18_09:45:30_PST_2021\r\n     Cuda compilation tools, release 11.5, V11.5.119\r\n     Build cuda_11.5.r11.5\/compiler.30672275_0\r\n     \r\n     ***Python***\r\n     \/usr\/bin\/python\r\n     Python 2.7.17\r\n     \r\n     ***Environment Variables***\r\n     PATH                            : \/usr\/local\/cuda\/bin:\/opt\/bin\/:\/usr\/local\/sbin:\/usr\/local\/bin:\/usr\/sbin:\/usr\/bin:\/sbin:\/bin:\/usr\/games:\/usr\/local\/games:\/snap\/bin:\/home\/nfs\/bsuryadevara:\/home\/nfs\/bsuryadevara\r\n     LD_LIBRARY_PATH                 :\r\n     NUMBAPRO_NVVM                   :\r\n     NUMBAPRO_LIBDEVICE              :\r\n     CONDA_PREFIX                    :\r\n     PYTHON_PATH                     :\r\n     \r\n     conda not found\r\n     ***pip packages***\r\n     \/usr\/bin\/pip\r\n\/usr\/lib\/python2.7\/dist-packages\/OpenSSL\/crypto.py:12: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.\r\n  from cryptography import x509\r\nDEPRECATION: The default format will switch to columns in the future. You can use --format=(legacy|columns) (or define a format=(legacy|columns) in your pip.conf under the [list] section) to disable this warning.\r\n     ansible (2.9.9)\r\n     asn1crypto (0.24.0)\r\n     backports.functools-lru-cache (1.6.4)\r\n     backports.shutil-get-terminal-size (1.0.0)\r\n     bcrypt (3.1.7)\r\n     beautifulsoup4 (4.9.3)\r\n     boto3 (1.17.112)\r\n     botocore (1.20.112)\r\n     bs4 (0.0.1)\r\n     certifi (2018.1.18)\r\n     cffi (1.11.5)\r\n     chardet (3.0.4)\r\n     click (7.1.2)\r\n     configparser (4.0.2)\r\n     contextlib2 (0.6.0.post1)\r\n     cryptography (3.3.2)\r\n     decorator (4.1.2)\r\n     defusedxml (0.6.0)\r\n     distro (1.6.0)\r\n     dnspython (1.15.0)\r\n     docker (4.4.4)\r\n     docopt (0.6.2)\r\n     enum34 (1.1.10)\r\n     fastrlock (0.8)\r\n     flake8 (3.9.2)\r\n     functools32 (3.2.3.post2)\r\n     futures (3.3.0)\r\n     gssapi (1.4.1)\r\n     gyp (0.1)\r\n     html-to-json (2.0.0)\r\n     html2text (2019.8.11)\r\n     html5lib (0.999999999)\r\n     http (0.2)\r\n     httplib2 (0.14.0)\r\n     httpserver (1.1.0)\r\n     idna (2.6)\r\n     importlib-metadata (2.1.3)\r\n     ipaclient (4.6.90rc1+git20180411)\r\n     ipaddress (1.0.17)\r\n     ipalib (4.6.90rc1+git20180411)\r\n     ipaplatform (4.6.90rc1+git20180411)\r\n     ipapython (4.6.90rc1+git20180411)\r\n     Jinja2 (2.10)\r\n     jmespath (0.10.0)\r\n     lxml (4.2.1)\r\n     MarkupSafe (1.0)\r\n     mccabe (0.6.1)\r\n     netaddr (0.7.19)\r\n     netifaces (0.10.4)\r\n     numpy (1.16.6)\r\n     ofed-le-utils (1.0.3)\r\n     olefile (0.45.1)\r\n     pandas (0.24.2)\r\n     paramiko (2.11.0)\r\n     pathlib2 (2.3.7.post1)\r\n     Pillow (5.1.0)\r\n     pip (9.0.1)\r\n     ply (3.11)\r\n     pyasn1 (0.4.2)\r\n     pyasn1-modules (0.2.1)\r\n     pycodestyle (2.7.0)\r\n     pycparser (2.18)\r\n     pycrypto (2.6.1)\r\n     pyflakes (2.3.1)\r\n     pygobject (3.26.1)\r\n     PyNaCl (1.4.0)\r\n     pyOpenSSL (17.5.0)\r\n     python-apt (1.6.5+ubuntu0.7)\r\n     python-augeas (0.5.0)\r\n     python-dateutil (2.8.2)\r\n     python-dotenv (0.18.0)\r\n     python-ldap (3.0.0)\r\n     python-yubico (1.3.2)\r\n     pytz (2022.4)\r\n     pyusb (1.0.0)\r\n     PyYAML (5.4.1)\r\n     qrcode (5.3)\r\n     requests (2.27.1)\r\n     s3fs (0.2.2)\r\n     s3transfer (0.4.2)\r\n     scandir (1.10.0)\r\n     setuptools (39.0.1)\r\n     six (1.16.0)\r\n     soupsieve (1.9.6)\r\n     splunk-sdk (1.7.2)\r\n     subprocess32 (3.5.4)\r\n     tqdm (4.60.0)\r\n     typing (3.10.0.0)\r\n     urllib3 (1.26.12)\r\n     webencodings (0.5)\r\n     yapf (0.32.0)\r\n     zipp (1.2.0)\r\n     \r\n<\/pre><\/details>\r\n```\r\n\r\n\r\n### Other\/Misc.\r\n\r\n_No response_\r\n\r\n### Code of Conduct\r\n\r\n- [X] I agree to follow Morpheus' Code of Conduct\r\n- [X] I have searched the [open bugs](https:\/\/github.com\/nv-morpheus\/Morpheus\/issues?q=is%3Aopen+is%3Aissue+label%3Abug) and have found no duplicates for this bug report",
        "Issue_answer_count":2,
        "Issue_self_closed":1.0,
        "Answer_body":"yeah, MLflow recently has started enforcing db schema checks at startup\r\n After removing docker volumes that are related to MLFlow and restarted `mlflow_server`. Now it's working as expected.\r\n```\r\ndocker volume rm production_mlflow_data\r\ndocker volume rm production_db_data\r\n```\r\n\r\n```\r\nmlflow_server        |   worker_int: <function WorkerInt.worker_int at 0x7faaa8f90dc0>\r\nmlflow_server        |   worker_abort: <function WorkerAbort.worker_abort at 0x7faaa8f90ee0>\r\nmlflow_server        |   pre_exec: <function PreExec.pre_exec at 0x7faaa8fa6040>\r\nmlflow_server        |   pre_request: <function PreRequest.pre_request at 0x7faaa8fa6160>\r\nmlflow_server        |   post_request: <function PostRequest.post_request at 0x7faaa8fa61f0>\r\nmlflow_server        |   child_exit: <function ChildExit.child_exit at 0x7faaa8fa6310>\r\nmlflow_server        |   worker_exit: <function WorkerExit.worker_exit at 0x7faaa8fa6430>\r\nmlflow_server        |   nworkers_changed: <function NumWorkersChanged.nworkers_changed at 0x7faaa8fa6550>\r\nmlflow_server        |   on_exit: <function OnExit.on_exit at 0x7faaa8fa6670>\r\nmlflow_server        |   proxy_protocol: False\r\nmlflow_server        |   proxy_allow_ips: ['127.0.0.1']\r\nmlflow_server        |   keyfile: None\r\nmlflow_server        |   certfile: None\r\nmlflow_server        |   ssl_version: 2\r\nmlflow_server        |   cert_reqs: 0\r\nmlflow_server        |   ca_certs: None\r\nmlflow_server        |   suppress_ragged_eofs: True\r\nmlflow_server        |   do_handshake_on_connect: False\r\nmlflow_server        |   ciphers: None\r\nmlflow_server        |   raw_paste_global_conf: []\r\nmlflow_server        |   strip_header_spaces: False\r\nmlflow_server        | [2022-12-01 19:16:23 +0000] [30] [INFO] Starting gunicorn 20.1.0\r\nmlflow_server        | [2022-12-01 19:16:23 +0000] [30] [DEBUG] Arbiter booted\r\nmlflow_server        | [2022-12-01 19:16:23 +0000] [30] [INFO] Listening at: http:\/\/0.0.0.0:5000 (30)\r\nmlflow_server        | [2022-12-01 19:16:23 +0000] [30] [INFO] Using worker: sync\r\n```",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"bug unabl start dfp product server version instal method occur docker bug unabl start server branch work fine branch downgrad version migrat databas latest schema note schema migrat result databas downtim consult databas document server traceback recent server file usr local lib python site packag cli line server server initi backend store backend store uri registri store uri default artifact root server file usr local lib python site packag server handler line initi backend store server track store backend store uri default artifact root server file usr local lib python site packag server handler line track store server track store track store registri store store uri artifact root server file usr local lib python site packag track track servic registri line store server return self store resolv uri resolv store uri artifact uri server file usr local lib python site packag track track servic registri line store resolv uri server return builder store uri resolv store uri artifact uri artifact uri server file usr local lib python site packag server handler line sqlalchemi store server return sqlalchemystor store uri artifact uri server file usr local lib python site packag store track sqlalchemi store line init server store util verifi schema self engin server file usr local lib python site packag store util line verifi schema server rais except server except except detect date databas schema version ccf expect affd backup databas run upgrad migrat databas latest schema note schema migrat result databas downtim consult databas document server exit code env printout shell click environ detail git commit ceaddbddabafaacdacd head dfp pipelin modul origin dfp pipelin modul author bsuryadevara date wed nov dill persist sourc preprocess schema git submodul efcfdcdbadabfdcbcd extern morpheu visual inform dgx dgx server dgx pretti nvidia dgx server dgx swbuild date dgx swbuild version dgx commit eeebc dgx platform dgx server dgx dgx serial number qtfcou distrib ubuntu distrib releas distrib codenam bionic distrib descript ubuntu lt ubuntu version lt bionic beaver ubuntu like debian pretti ubuntu lt version home url http www ubuntu com support url http help ubuntu com bug report url http bug launchpad net ubuntu privaci polici url http www ubuntu com legal term polici privaci polici version codenam bionic ubuntu codenam bionic linux dgx gener ubuntu smp mon oct utc gnu linux gpu inform thu dec nvidia smi driver version cuda version gpu persist bu disp volatil uncorr ecc fan temp perf pwr usag cap memori usag gpu util comput mig tesla sxm mib mib default tesla sxm mib mib default tesla sxm mib mib default tesla sxm mib mib default tesla sxm mib mib default tesla sxm mib mib default tesla sxm mib mib default tesla sxm mib mib default process gpu pid type process gpu memori usag env rapid bin python mib env rapid bin python mib nda env venv bin python mib tritonserv mib cpu architectur cpu mode bit bit byte order littl endian cpu line cpu list thread core core socket socket numa node vendor genuineintel cpu famili model model intel xeon cpu ghz step cpu mhz cpu max mhz cpu min mhz bogomip virtual cach cach cach cach numa node cpu numa node cpu flag fpu vme pse tsc msr pae mce apic sep mtrr pge mca cmov pat pse clflush dt acpi mmx fxsr sse sse pbe syscal pdpegb rdtscp constant tsc arch perfmon peb bt rep good nopl xtopolog nonstop tsc cpuid aperfmperf pni pclmulqdq dte monitor cpl vmx smx est ssse sdbg fma xtpr pdcm pcid dca sse sse xapic movb popcnt tsc deadlin timer ae xsave avx rdrand lahf abm dnowprefetch cpuid fault epb cat cdp invpcid singl pti intel ppin ssbd ibr ibpb stibp tpr shadow vnmi flexprior ept vpid fsgsbase tsc adjust bmi hle avx smep bmi erm invpcid rtm cqm rdt rdseed adx smap intel xsaveopt cqm llc cqm occup llc cqm mbm total cqm mbm local dtherm ida arat pln pt clear flush cmake usr bin cmake cmake version cmake suit maintain support kitwar kitwar com cmake usr bin ubuntu ubuntu copyright free softwar foundat free softwar sourc copi condit warranti merchant fit particular purpos nvcc usr local cuda bin nvcc nvcc nvidia cuda compil driver copyright nvidia corpor built thu nov pst cuda compil tool releas build cuda compil python usr bin python python environ variabl path usr local cuda bin opt bin usr local sbin usr local bin usr sbin usr bin sbin bin usr game usr local game snap bin home nf bsuryadevara home nf bsuryadevara librari path numbapro nvvm numbapro libdevic conda prefix python path conda pip packag usr bin pip usr lib python dist packag openssl crypto cryptographydeprecationwarn python longer support python core team support deprec cryptographi remov releas cryptographi import deprec default format switch column futur us format legaci column defin format legaci column pip conf list section disabl warn ansibl asncrypto backport functool lru cach backport shutil termin size bcrypt beautifulsoup boto botocor certifi cffi chardet click configpars contextlib post cryptographi decor defusedxml distro dnspython docker docopt enum fastrlock flake functool post futur gssapi gyp html json htmltext htmllib http httplib httpserver idna importlib metadata ipacli git ipaddress ipalib git ipaplatform git ipapython git jinja jmespath lxml markupsaf mccabe netaddr netifac numpi of util olefil panda paramiko pathlib post pillow pip ply pyasn pyasn modul pycodestyl pycpars pycrypto pyflak pygobject pynacl pyopenssl python apt ubuntu python augea python dateutil python dotenv python ldap python yubico pytz pyusb pyyaml qrcode request sf stransfer scandir setuptool soupsiev splunk sdk subprocess tqdm type urllib webencod yapf zipp misc respons code conduct agre follow morpheu code conduct search open bug http github com morpheu morpheu issu aopen aissu label abug duplic bug report",
        "Issue_preprocessed_content":"unabl start dfp product server version method docker bug unabl start server work fine downgrad version work fine minimum reproduc exampl relev log output env printout code conduct morpheu code conduct search duplic bug report",
        "Issue_gpt_summary_original":"The user is facing an issue with logging modified parameters on Mlflow while using Hydra for parameter modification during experiment runs. The default parameters set with Hydra are logged correctly, but the modified parameters are not being logged on Mlflow.",
        "Issue_gpt_summary":"user face issu log modifi paramet hydra paramet modif experi run default paramet set hydra log correctli modifi paramet log",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/nv-morpheus\/Morpheus\/issues\/125",
        "Issue_title":"[BUG] mlflow deployments create can fail (k8s\/Helm)",
        "Issue_created_time":1653424629000,
        "Issue_closed_time":1654018977000,
        "Issue_body":"**Describe the bug**\r\nFor some reason, `mlflow deployment create ...` can fail unexpectedly. \r\n\r\n```\r\nmlflow deployments create -t triton --flavor triton --name sid-minibert-onnx -m models:\/sid-minibert-onnx\/1 -C \"version=1\"\r\nCopied \/mlflow\/artifacts\/0\/41f4069628e5429eb5c75728486a247a\/artifacts\/triton\/sid-minibert-onnx to \/common\/triton-model-repo\/sid-minibert-onnx\r\nSaved mlflow-meta.json to \/common\/triton-model-repo\/sid-minibert-onnx\r\nTraceback (most recent call last):\r\n  File \"\/opt\/conda\/envs\/mlflow\/lib\/python3.8\/site-packages\/mlflow_triton\/deployments.py\", line 109, in create_deployment\r\n    self.triton_client.load_model(name)\r\n  File \"\/opt\/conda\/envs\/mlflow\/lib\/python3.8\/site-packages\/tritonclient\/http\/__init__.py\", line 622, in load_model\r\n    _raise_if_error(response)\r\n  File \"\/opt\/conda\/envs\/mlflow\/lib\/python3.8\/site-packages\/tritonclient\/http\/__init__.py\", line 64, in _raise_if_error\r\n    raise error\r\ntritonclient.utils.InferenceServerException: failed to load 'sid-minibert-onnx', no version is available\r\n```\r\n\r\nFix is to delete the mlflow pod and start over.\r\n\r\n**Steps\/Code to reproduce bug**\r\nFollow steps in docs\/source\/morpheus_quickstart_guide.md#model-deployment\r\n\r\n**Expected behavior**\r\nSuccessful deployment as described at docs\/source\/morpheus_quickstart_guide.md#model-deployment\r\n\r\n**Environment overview (please complete the following information)**\r\n - Environment location: LaunchPad\r\n - Method of Morpheus install: Kubernetes\r\n\r\n**Environment details**\r\nLaunchPad Helm deployment on A30. Unfortunately, unable to capture the print_env.sh output from ipykernel there.\r\n\r\n**Additional context**\r\nMLflow sqlite db likely gets corrupted or otherwise \"confused\". Possibly an issue in tritonclient?\r\nTriton logging complains about unable to read config.pbtxt\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"Error in LaunchPad notebooks. There was a change in the triton upstream where you previously didn't need to specify the model suffix as the path. Now you do. ",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"bug deploy creat fail helm bug reason deploy creat fail unexpectedli deploy creat triton flavor triton sid minibert onnx model sid minibert onnx version copi artifact feebcaa artifact triton sid minibert onnx common triton model repo sid minibert onnx save meta json common triton model repo sid minibert onnx traceback recent file opt conda env lib python site packag triton deploy line creat deploy self triton client load model file opt conda env lib python site packag tritoncli http init line load model rais error respons file opt conda env lib python site packag tritoncli http init line rais error rais error tritoncli util inferenceserverexcept fail load sid minibert onnx version avail fix delet pod start step code reproduc bug follow step doc sourc morpheu quickstart guid model deploy expect behavior success deploy describ doc sourc morpheu quickstart guid model deploy environ overview complet follow inform environ locat launchpad method morpheu instal kubernet environ detail launchpad helm deploy unfortun unabl captur print env output ipykernel addit context sqlite like get corrupt confus possibl issu tritoncli triton log complain unabl read config pbtxt",
        "Issue_preprocessed_content":"deploy creat fail bug reason fail unexpectedli fix delet pod start reproduc bug step expect behavior deploy describ environ overview environ locat launchpad method morpheu kubernet environ detail launchpad helm deploy unfortun unabl captur output ipykernel context sqlite like get confus tritoncli triton complain unabl read",
        "Issue_gpt_summary_original":"The issue is related to the failure of MlflowArtifactDataset.load() when both artifact_path and run_id are specified. An error is encountered when the artifact_path is not None and run_id is specified.",
        "Issue_gpt_summary":"issu relat failur artifactdataset load artifact path run specifi error encount artifact path run specifi",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/equinor\/flownet\/issues\/408",
        "Issue_title":"MLFlow expecting mlruns folder",
        "Issue_created_time":1621607539000,
        "Issue_closed_time":null,
        "Issue_body":"When running hyperparameter tuning, MLflow expects an mlruns folder - which we don't create. If we stick with the standard we can ommit having to run `mlflow ui` with the backend store argument.",
        "Issue_answer_count":0,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"expect folder run hyperparamet tune expect folder creat stick standard ommit have run backend store argument",
        "Issue_preprocessed_content":"expect folder hyperparamet tune expect folder creat stick standard have run backend store argument",
        "Issue_gpt_summary_original":"The user is facing an issue with MLFlow while running hyperparameter tuning as it expects an mlruns folder which they have not created. This can be resolved by sticking to the standard and avoiding the need to run `mlflow ui` with the backend store argument.",
        "Issue_gpt_summary":"user face issu run hyperparamet tune expect folder creat resolv stick standard avoid need run backend store argument",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/equinor\/flownet\/issues\/269",
        "Issue_title":"Failed ERT runs are not registered correctly in mlflow",
        "Issue_created_time":1606471214000,
        "Issue_closed_time":1606475795000,
        "Issue_body":"If an ERT subprocess has failed for any other reason than what is hard coded in the subprocess call, a returncode larger than 0 is ignored. This will then lead to a \"successful\" run in mlflow, whereas it should be registered as a failed run.",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"fail ert run regist correctli ert subprocess fail reason hard code subprocess returncod larger ignor lead success run regist fail run",
        "Issue_preprocessed_content":"fail ert run regist ert fail reason hard code returncod larger ignor lead run regist fail run",
        "Issue_gpt_summary_original":"The user is encountering an issue where an invalid metric is being logged, which is breaking the Mlflow UI. They are trying to create a custom metric indicator, but it is not being displayed when they use the Mlflow UI. They are using Kedro and Kedro-mlflow version 0.10.0, Python version 3.9.0, and operating system Windows 10.",
        "Issue_gpt_summary":"user encount issu invalid metric log break try creat custom metric indic displai us version python version oper window",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/NRCan\/geo-deep-learning\/issues\/440",
        "Issue_title":"Fix logging of parameters on Mlflow",
        "Issue_created_time":1671594369000,
        "Issue_closed_time":null,
        "Issue_body":"Logging of parameters on Mlflow works as expected with default parameters set with Hydra; However hydra allows modification of parameters per experiment run, but modified parameters are not logged on Mlflow.  ",
        "Issue_answer_count":0,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"fix log paramet log paramet work expect default paramet set hydra hydra allow modif paramet experi run modifi paramet log",
        "Issue_preprocessed_content":"fix paramet paramet work expect default paramet set hydra hydra modif paramet experi run modifi paramet",
        "Issue_gpt_summary_original":"The user is facing an issue with logging modified parameters on Mlflow while using Hydra for parameter modification during experiment runs. The default parameters set with Hydra are logged correctly, but the modified parameters are not being logged on Mlflow.",
        "Issue_gpt_summary":"user face issu log modifi paramet hydra paramet modif experi run default paramet set hydra log correctli modifi paramet log",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/issues\/362",
        "Issue_title":"MlflowArtifactDataset.load() fails if artifact_path is not None and run_id is specified",
        "Issue_created_time":1664829089000,
        "Issue_closed_time":1665079955000,
        "Issue_body":"## Description\r\n\r\nWhen you try to specify an artifact path and a run_id in an ``MlflowArtifactDataSet``, you get an error. \r\n\r\nThis works:\r\n```python\r\nmlflow_csv_dataset = MlflowArtifactDataSet(\r\n    data_set=dict(type=CSVDataSet, filepath=\"path\/to\/df.csv\"),\r\n    artifact_path=None,\r\n    run_id=\"1234\",\r\n)\r\nmlflow_csv_dataset .load()\r\n```\r\n\r\nwhile this :\r\n```python\r\nmlflow_csv_dataset = MlflowArtifactDataSet(\r\n    data_set=dict(type=CSVDataSet, filepath=\"path\/to\/df.csv\"),\r\n    artifact_path=\"folder\", # this is the difference\r\n    run_id=\"1234\",\r\n)\r\nmlflow_csv_dataset .load()\r\n```\r\nraises the following error: ``unsupported operand type(s) for \/: 'str' and 'str'``:\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"The issue is still here when there is nested artifact_path: if the file does not exists, it is downloaded to ``self._filepath \/artifact_path\/filename.pkl`` and cannot be loaded (due to the ``artifact_path`` suffix)",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"artifactdataset load fail artifact path run specifi descript try specifi artifact path run artifactdataset error work python csv dataset artifactdataset data set dict type csvdataset filepath path csv artifact path run csv dataset load python csv dataset artifactdataset data set dict type csvdataset filepath path csv artifact path folder differ run csv dataset load rais follow error unsupport operand type str str",
        "Issue_preprocessed_content":"fail specifi descript try specifi artifact path work rais",
        "Issue_gpt_summary_original":"The issue is related to the failure of MlflowArtifactDataset.load() when both artifact_path and run_id are specified. An error is encountered when the artifact_path is not None and run_id is specified.",
        "Issue_gpt_summary":"issu relat failur artifactdataset load artifact path run specifi error encount artifact path run specifi",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/issues\/361",
        "Issue_title":"kedro mlflow ui gets a FileNotFoundError",
        "Issue_created_time":1664539296000,
        "Issue_closed_time":1664786016000,
        "Issue_body":"Firstly I'd like to apologize if this is a dummy question.\r\nI'm following the tutorial to get introduced to kedro mlflow,; after running the command \"kedro mlflow init\" I tried to run the command \"kedro mlflofw ui\" but I get an error:\r\n\r\nINFO     The 'mlflow_tracking_uri' key in mlflow.yml is relative ('server.mlflow_tracking_uri = mlruns'). It is converted to a valid uri: 'file:\/\/\/C:\/Users\/e107338\/PycharmProjects\/mlflow\/kedro-mlflow-example\/mlruns'                                                   kedro_mlflow_config.py:202\r\n\r\nAfter the Traceback I get an error: FileNotFoundErrror\r\n",
        "Issue_answer_count":2,
        "Issue_self_closed":1.0,
        "Answer_body":"Hi, \r\n\r\nI am sorry to see you are experiencing issues. this is not a dummy question, it sounds like a bug. \r\n\r\nI've just ran this: \r\n\r\n```bash\r\nconda create -n km-361 python=3.9 -y\r\nconda activate km-361\r\npip install kedro==0.18.3\r\npip install mlflow==1.29.0\r\npip install kedro-mlflow==0.11.3\r\nkedro new --starter=pandas-iris\r\ncd iris\r\nkedro mlflow init\r\nkedro mlflow ui\r\n```\r\n\r\nthen I opened ``http:\/\/127.0.0.1:5000`` and th UI opened as expected. \r\n\r\nCan you tell me: \r\n- your python version\r\n- your OS\r\n- your ``kedro`` \/ ``mlflow`` \/ ``kedro-mlflow`` version\r\n- the project using\r\n- the exact error message\r\n- check if you have a ``MLFLOW_TRACKING_URI`` environment set It turned out fine  after trying again! Sorry and thanks for your consideration!",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"get filenotfounderror firstli like apolog dummi question follow tutori introduc run command init tri run command mlflofw error info track uri kei yml rel server track uri convert valid uri file user pycharmproject exampl config traceback error filenotfounderrror",
        "Issue_preprocessed_content":"get firstli like apolog question tutori introduc init tri run mlflofw info kei yml rel convert valid uri traceback",
        "Issue_gpt_summary_original":"The user is unable to store a PartitionedDataSet as an mlflow artifact with the MlflowArtifactDataSet. The user tried to save a dict with many small result tables to mlflow using PartitionedDataSet, but an error \"dataset has not attribute '_filepath'\" was raised. The bug also happens with the last version on master. A potential solution is to add a better condition to default to \"path\" if there is no \"filepath\" attribute.",
        "Issue_gpt_summary":"user unabl store partitioneddataset artifact artifactdataset user tri save dict small result tabl partitioneddataset error dataset attribut filepath rais bug happen version master potenti solut add better condit default path filepath attribut",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/issues\/346",
        "Issue_title":"MlflowMetricsDataSet logs invalid metric which breaks mlflow UI",
        "Issue_created_time":1660281331000,
        "Issue_closed_time":1662408460000,
        "Issue_body":"## Description\r\n\r\nThis happens when i tried to configure my own metric functions. \r\n\r\n## Context\r\n\r\nI am trying to create a custom metric indicator, to be logged after each experimentation. When i run `kedro mlflow ui`, this is what I'm getting on the UI.\r\n![image](https:\/\/user-images.githubusercontent.com\/54475793\/184276876-57872dd2-3fb3-41c9-b3a3-edd6a4396aca.png)\r\n\r\n\r\n## Steps to Reproduce\r\n\r\nThis is my nodes.py\r\n```\r\ndef pnl_metrics(df:pd.DataFrame): \r\n    avg_pnl = {}\r\n    avg_pnl[f'{avg_metric}'] = {'trader1': df.pnl.mean()}\r\n    avg_pnl[f'{total_metric}'] = {'trader1': df.pnl.sum(), 'trader2': df.pnl.sum()}\r\n    return avg_pnl\r\n```\r\n\r\n\r\n## Expected Result\r\n\r\nHow do i get the metric to be displayed when i use the Mlflow ui? Are there specific keywords that mlflow is tracking to be logged as metric?\r\n\r\n\r\n## Your Environment\r\n\r\nInclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* `kedro` and `kedro-mlflow` version used (`pip show kedro` and `pip show kedro-mlflow`): **0.10.0**\r\n* Python version used (`python -V`):  **3.9.0** \r\n* Operating system and version: Windows 10\r\n",
        "Issue_answer_count":4,
        "Issue_self_closed":0.0,
        "Answer_body":"Hi @xjlwi, sorry to see that you are facing issues with the plugins. There are two problems here:\r\n- kedro-mlflow logs an incorrect metric. We will solve the problem together. \r\n- mlflow does not complain when the incorrect metric is logged, but it breaks the database and hence the UI => we should open an issue in mlflow repo once we know what is going on. \r\n\r\nWould you mind give me some extra informations: \r\n- ``mlflow`` version\r\n- the catalog entry for ``avg_pnl`` (I guess it is a ``kedro_mlflow.io.metrics.MlflowMetricsDataSet``?) **If yes, check the documentation: [it should return something like ``{'trader1': {'step': 0, 'value': df.pnl.mean()}}``](https:\/\/kedro-mlflow.readthedocs.io\/en\/stable\/source\/04_experimentation_tracking\/05_version_metrics.html#how-to-return-metrics-from-a-node)**\r\n- the type of ``avg_metric`` and ``total_metric``: are they ``float`` instead of string?\r\n- can you check if ``df.pnl.mean()`` and ``df.pnl.sum()`` returns a float and not a single-row ``pandas.Series``?\r\n\r\nIf I can reproduce the bug, I will be able to give you a workaround. \r\n > Hi @xjlwi, sorry to see that you are facing issues with the plugins. There are two problems here:\r\n> \r\n> * kedro-mlflow logs an incorrect metric. We will solve the problem together.\r\n> * mlflow does not complain when the incorrect metric is logged, but it breaks the database and hence the UI => we should open an issue in mlflow repo once we know what is going on.\r\n> \r\n> Would you mind give me some extra informations:\r\n> \r\n> * `mlflow` version: <b> 1.26.1 <\/b>\r\n> * the catalog entry for `avg_pnl` (I guess it is a `kedro_mlflow.io.metrics.MlflowMetricsDataSet`?) **If yes, check the documentation: [it should return something like `{'trader1': {'step': 0, 'value': df.pnl.mean()}}`](https:\/\/kedro-mlflow.readthedocs.io\/en\/stable\/source\/04_experimentation_tracking\/05_version_metrics.html#how-to-return-metrics-from-a-node)** : \r\n\r\nYes it's a `kedro_mlflow.io.metrics.MlflowMetricsDataSet`. \r\n\r\ntype: kedro_mlflow.io.artifacts.MlflowArtifactDataSet \r\ndata_set:\r\n    type: pandas.CSVDataSet \r\n    filepath: \"${ml_model_output}PnL_summary_metrics_${current_date}_${model}.csv\" \r\n    save_args:\r\n      index: True\r\n\r\nMust the keywords for the output be specifically 'step'? This is my current node to return the output.\r\n`\r\ndef pnl_metrics(df:pd.DataFrame): \r\n    avg_pnl = {}\r\n    avg_pnl[f'{avg_metric}'] = {'trader1': df.pnl.mean()}\r\n    avg_pnl[f'{total_metric}'] = {'trader1': df.pnl.sum(), 'trader2': df.pnl.sum()}\r\n    return avg_pnl\r\n`\r\n\r\n> * the type of `avg_metric` and `total_metric`: are they `float` instead of string? Definitely float, because in my local mlruns folder, I am able to see them from the mlruns>metrics folder.\r\n\r\n1660874133345 [{'ml_model_13_logit_pnl_total': 0.0}, {'ml_model_13_logit_pnl_avg': nan}] ml_model_13_logit\r\n1660874133347 [{'ml_model_14_rf_pnl_total': 0.0}, {'ml_model_14_rf_pnl_avg': nan}] ml_model_14_rf\r\n1660874133349 [{'ml_model_15_naive_clf_pnl_total': 0.0}, {'ml_model_15_naive_clf_pnl_avg': nan}] ml_model_15_naive_clf\r\n1660874133352 [{'ml_model_16_svc_pnl_total': 0.0}, {'ml_model_16_svc_pnl_avg': nan}] ml_model_16_svc\r\n1660874133354 [{'ml_model_17_decisison_tree_pnl_total': 0.0}, {'ml_model_17_decisison_tree_pnl_avg': nan}] ml_model_17_decisison_tree\r\n1660874133356 [{'ml_model_18_grad_boost_pnl_total': 0.0}, {'ml_model_18_grad_boost_pnl_avg': nan}] ml_model_18_grad_boost\r\n\r\n> * can you check if `df.pnl.mean()` and `df.pnl.sum()` returns a float and not a single-row `pandas.Series`?\r\n\r\n> If I can reproduce the bug, I will be able to give you a workaround.\r\n\r\n > Must the keywords for the output be specifically 'step'? This is my current node to return the output.\r\n\r\nYes exactly. That's for consistency between loading and saving metrics.\r\n\r\nReplace each entry ``df.pnl.mean()`` by  a dict``{'step': 0, 'value': df.pnl.mean()}``and you will be fine. This adds an extra nested dict level and is not ideal. I let the issue opened to improve the API in the future. Hi, I close the issue but feel free to reopen if needed. ",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"metricsdataset log invalid metric break descript happen tri configur metric function context try creat custom metric indic log experiment run get imag http user imag githubusercont com eddaaca png step reproduc node def pnl metric datafram avg pnl avg pnl avg metric trader pnl mean avg pnl total metric trader pnl sum trader pnl sum return avg pnl expect result metric displai us specif keyword track log metric environ includ relev detail environ experienc bug version pip pip python version python oper version window",
        "Issue_preprocessed_content":"metricsdataset log invalid metric break descript tri configur metric function context try creat custom metric indic experiment run step reproduc expect result metric displai us specif keyword track metric environ includ relev detail environ experienc bug pip pip python oper version window",
        "Issue_gpt_summary_original":"The user is facing an issue where the mlflow experiment specified in mlflow.yml is not being used when setting up the mlflow configuration interactively. Instead, all runs are being stored in the \"Default\" experiment. The user has provided steps to reproduce the issue and suggests using the mlflow \"set_experiment\" method as a potential solution.",
        "Issue_gpt_summary":"user face issu experi specifi yml set configur interact instead run store default experi user provid step reproduc issu suggest set experi method potenti solut",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/issues\/336",
        "Issue_title":"kedro mlflow init displays a wrong sucess message when the env folder does not exist",
        "Issue_created_time":1656532075000,
        "Issue_closed_time":1657139268000,
        "Issue_body":"## Description\r\n\r\nWhen running ``kedro mlflow init --env=xxx``, a success message is displayed even if the env \"xxx\" folder does not exist, instead of an error message. We should move this code : \r\n\r\nhttps:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/blob\/d31820a7d4ea808d0a4460d41966b762a404b5a5\/kedro_mlflow\/framework\/cli\/cli.py#L116-L122\r\n\r\ninside the \"try\" block above.",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"init displai wrong sucess messag env folder exist descript run init env xxx success messag displai env xxx folder exist instead error messag code http github com galileo galilei blob dadeadadbaba framework cli cli insid try block",
        "Issue_preprocessed_content":"init displai wrong env folder exist descript displai env folder exist instead code insid try block",
        "Issue_gpt_summary_original":"The user has encountered an issue where the \"kedro mlflow init\" command displays a success message even if the specified environment folder does not exist, instead of an error message. The suggested solution is to move the relevant code inside the \"try\" block.",
        "Issue_gpt_summary":"user encount issu init command displai success messag specifi environ folder exist instead error messag suggest solut relev code insid try block",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/issues\/309",
        "Issue_title":"kedro-mlflow is broken with kedro==0.18.1",
        "Issue_created_time":1652380533000,
        "Issue_closed_time":1652640252000,
        "Issue_body":"## Description\r\n\r\nThe plugin does not work with projects created with ``kedro==0.18.1``\r\n\r\n## Context\r\n\r\nTry to launch ``kedro run`` in a project with ``kedro==0.18.1`` and kedro-mlflow installed.\r\n\r\n\r\n## Steps to Reproduce\r\n\r\n```python\r\nconda create -n temp python=3.8 -y\r\nconda activate temp\r\npip install kedro==0.18.1 kedro-mlflow==0.9.0\r\nkedro new --starter=pandas-iris\r\ncd pandas-iris\r\nkedro mlflow init\r\nkedro run\r\n```\r\n\r\n## Expected Result\r\n\r\nThis should run the pipeleine and log the parameters.\r\n\r\n## Actual Result\r\n\r\nThis raises the following error:\r\n\r\n```bash\r\nAttributeError: module 'kedro.framework.session.session' has no attribute '_active_session'\r\n```\r\n\r\n## Your Environment\r\n\r\nInclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* `kedro` and `kedro-mlflow` version used (`pip show kedro` and `pip show kedro-mlflow`): ``kedro==0.18.1`` and ``kedro-mlflow<=0.9.0``\r\n* Python version used (`python -V`): All\r\n* Operating system and version: All\r\n\r\n## Does the bug also happen with the last version on master?\r\n\r\nYes\r\n\r\n## Solution\r\n\r\nCurrently, kedro-mlflow uses [the private ``_active_session`` global variable to access the configuration](https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/blob\/e855f59faa76c881b32616880608d41c064c23a0\/kedro_mlflow\/config\/kedro_mlflow_config.py#L233-L247) inside a hook. \r\n\r\nWith kedro==0.18.1, this private attribute was removed and the new recommandation is to use the ``after_context_created`` hook. \r\n\r\nRetrieving the configuration and set it up should be moved to this new hook:\r\n\r\nhttps:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/blob\/963c338d6259dd118232c45801abe0a2b0a463df\/kedro_mlflow\/framework\/hooks\/pipeline_hook.py#L108-L109",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"Closed by #313 ",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"broken descript plugin work project creat context try launch run project instal step reproduc python conda creat temp python conda activ temp pip instal new starter panda iri panda iri init run expect result run pipelein log paramet actual result rais follow error bash attributeerror modul framework session session attribut activ session environ includ relev detail environ experienc bug version pip pip python version python oper version bug happen version master ye solut current us privat activ session global variabl access configur http github com galileo galilei blob effaacbdcca config config insid hook privat attribut remov new recommand us context creat hook retriev configur set move new hook http github com galileo galilei blob cdddcabeabadf framework hook pipelin hook",
        "Issue_preprocessed_content":"broken descript plugin work project creat context try launch project step reproduc expect result run pipelein log paramet actual result rais environ includ relev detail environ experienc bug python version oper version bug version master ye solut us insid privat remov new us retriev configur set move new",
        "Issue_gpt_summary_original":"The user is facing an issue with the kedro-mlflow plugin not working with projects created with kedro==0.18.1. When the user tries to run the pipeline, an error is raised due to the removal of the private attribute '_active_session' in kedro==0.18.1. The solution is to use the 'after_context_created' hook to retrieve and set up the configuration.",
        "Issue_gpt_summary":"user face issu plugin work project creat user tri run pipelin error rais remov privat attribut activ session solut us context creat hook retriev set configur",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/issues\/258",
        "Issue_title":"MlflowArtifactDataSet does not work with PartitionedDataSet",
        "Issue_created_time":1636062318000,
        "Issue_closed_time":1644674290000,
        "Issue_body":"## Description\r\n\r\nIt is not possible to store a ``PartitionedDataSet`` as an mlflow artifact with the ``MlflowArtifactDataSet``.\r\n\r\n## Context\r\n\r\nI had a use case where I need to save a dict with many small result tables to mlflow, and I tried to use ``PartitionedDataSet`` for this.\r\n\r\n## Steps to Reproduce\r\n\r\n```yaml\r\n# catalog.yml\r\n\r\nmy_dataset:\r\n    type: kedro_mlflow.io.artifacts.MlflowArtifactDataSet\r\n    data_set:\r\n        type: PartitionedDataSet  # or any valid kedro DataSet\r\n        path: \/path\/to\/a\/local\/folder # the attribute is \"path\", and not \"filepath\"!\r\n        dataset: \"pandas.CSVDataSet\"\r\n```\r\n\r\nthen save a dict using this dataset:\r\n\r\n```\r\ncatalog.save(\"my_dataset\", dict(\"a\": pd.DataFrame(data=[1,2,3], columns=[\"a\"], \"b\": pd.DataFrame(data=[1,2,3], columns=[\"b\"])\r\n```\r\n## Expected Result\r\n\r\nThe 2 Dataframes should be logged as artifacts in the current mlflow run.\r\n\r\n## Actual Result\r\n\r\nAn error ``dataset has not attribute \"_filepath\"`` is raised.\r\n\r\n## Does the bug also happen with the last version on master?\r\n\r\nYes\r\n\r\n## Potential solution\r\n\r\nThe error comes from this line:\r\n\r\nhttps:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/blob\/904207ad505b71391d78d8088aaed151ca6a011d\/kedro_mlflow\/io\/artifacts\/mlflow_artifact_dataset.py#L53\r\n\r\nmaybe we can add a better condition here to default to \"path\" if there is no \"filepath\" attribute.",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"artifactdataset work partitioneddataset descript possibl store partitioneddataset artifact artifactdataset context us case need save dict small result tabl tri us partitioneddataset step reproduc yaml catalog yml dataset type artifact artifactdataset data set type partitioneddataset valid dataset path path local folder attribut path filepath dataset panda csvdataset save dict dataset catalog save dataset dict datafram data column datafram data column expect result datafram log artifact current run actual result error dataset attribut filepath rais bug happen version master ye potenti solut error come line http github com galileo galilei blob adbddaaedcaad artifact artifact dataset mayb add better condit default path filepath attribut",
        "Issue_preprocessed_content":"artifactdataset work descript store artifact context us case save dict result tabl tri us step reproduc save dict dataset expect result datafram artifact run actual result rais bug version master ye potenti solut come line mayb condit default path filepath",
        "Issue_gpt_summary_original":"The user is unable to store a PartitionedDataSet as an mlflow artifact with the MlflowArtifactDataSet. The user tried to save a dict with many small result tables to mlflow using PartitionedDataSet, but an error \"dataset has not attribute '_filepath'\" was raised. The bug also happens with the last version on master. A potential solution is to add a better condition to default to \"path\" if there is no \"filepath\" attribute.",
        "Issue_gpt_summary":"user unabl store partitioneddataset artifact artifactdataset user tri save dict small result tabl partitioneddataset error dataset attribut filepath rais bug happen version master potenti solut add better condit default path filepath attribut",
        "Issue_score_count":1
    },
    {
        "Issue_link":"https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/issues\/256",
        "Issue_title":"Setting the mlflow experiment does not work in interactive mode",
        "Issue_created_time":1636045277000,
        "Issue_closed_time":1636318265000,
        "Issue_body":"## Description\r\n\r\nIf I specify an experiment in `mlflow.yml`, and the set up the mlflow configuration interactively, all runs should be stored by default in this experiment while they are currently sotred in mlflow \"Default\" (0) experiment. This works when running \"kedro run\" through the CLI.\r\n\r\n## Steps to Reproduce\r\n\r\n```yaml\r\n# mlflow.yml\r\nexperiment:\r\n  name: my_awesome_experiment\r\n  create: True  # if the specified `name` does not exists, should it be created?\r\n```\r\n\r\n```python\r\n# test.py\r\n\r\nfrom kedro.framework.session import KedroSession\r\nfrom kedro.framework.startup import bootstrap_project\r\nfrom kedro_mlflow.config import get_mlflow_config\r\n\r\nbootstrap_project(r\"path\/to\/project\")\r\nwith KedroSession.create(project_path=r\"path\/to\/project\"):\r\n    config=get_mlflow_config()\r\n    config.setup()\r\n    \r\n    mlflow.log_param(\"test_param\",1) # this should be logged in \"my_awesome_experiment\" but is logged in \"Default\".\r\n\r\n```\r\n\r\n## Does the bug also happen with the last version on master?\r\n\r\nYes\r\n\r\n## Potential solution\r\n\r\nThe faulty line is: \r\n\r\nhttps:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/blob\/904207ad505b71391d78d8088aaed151ca6a011d\/kedro_mlflow\/config\/kedro_mlflow_config.py#L100\r\n\r\n[We should use mlflow ``mlflow.set_experiment`` method](https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.set_experiment), but it does not restore deleted experiment. This wil replace part of the logic here: \r\n\r\nhttps:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/blob\/904207ad505b71391d78d8088aaed151ca6a011d\/kedro_mlflow\/config\/kedro_mlflow_config.py#L124-L132",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"set experi work interact mode descript specifi experi yml set configur interact run store default experi current sotr default experi work run run cli step reproduc yaml yml experi awesom experi creat true specifi exist creat python test framework session import session framework startup import bootstrap project config import config bootstrap project path project session creat project path path project config config config setup log param test param log awesom experi log default bug happen version master ye potenti solut faulti line http github com galileo galilei blob adbddaaedcaad config config us set experi method http www org doc latest python api html set experi restor delet experi wil replac logic http github com galileo galilei blob adbddaaedcaad config config",
        "Issue_preprocessed_content":"experi work interact mode descript specifi experi set configur interact run store default experi sotr default experi work run cli step reproduc bug version master ye potenti solut faulti line us restor delet experi wil replac logic",
        "Issue_gpt_summary_original":"The user is facing an issue where the mlflow experiment specified in mlflow.yml is not being set up in interactive mode, resulting in all runs being stored in the \"Default\" experiment instead of the specified experiment. The potential solution involves using the mlflow \"set_experiment\" method to replace the current logic.",
        "Issue_gpt_summary":"user face issu experi specifi yml set interact mode result run store default experi instead specifi experi potenti solut involv set experi method replac current logic",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/issues\/193",
        "Issue_title":"kedro-mlflow CLI is unavailable inside a Kedro project",
        "Issue_created_time":1619193727000,
        "Issue_closed_time":1619987466000,
        "Issue_body":"## Description\r\n\r\nI try to reproduce the minimal example from the Docs: a Kedro project using the starter `pandas-iris` using the `kedro-mlflow` functinality. I do not arrive at initializing the kedro-mlflow project, since the cli commands are not available.\r\n\r\n## Context\r\n\r\nIt is unclear to me if this is connected to #157 \r\nI wanted to start looking into kedro-mlflow, but got immediatle blocked by the initialization of the project. Therefore any advice on where to look to fix this would also be appreciated. \r\n\r\n## Steps to Reproduce\r\n\r\n```\r\nconda create -n kedro_mlflow python=3.8\r\nconda activate kedro_mlflow\r\npip install kedro-mlflow\r\nkedro mlflow -h\r\nkedro new --starter=pandas-iris\r\ncd mlflow_test\/\r\nkedro mlflow -h\r\n> ERROR \"No such command 'mlflow'\"\r\n```\r\n\r\n## Expected Result\r\n\r\n`kedro mlflow` is available in a project directory, i.e. `kedro mlflow -h` gives the same output inside the folder as before\r\n\r\n## Actual Result\r\n\r\ninside the project folder the `mlflow` command is unknown to Kedro\r\n\r\n```\r\n...\/miniconda3\/envs\/kedro_mlflow\/lib\/python3.8\/site-packages\/pkg_resources\/__init__.py:1130: DeprecationWarning: Use of .. or absolute path in a resource path is not allowed and will raise exceptions in a future release.\r\n  return get_provider(package_or_requirement).get_resource_filename(\r\n....\/miniconda3\/envs\/kedro_mlflow\/lib\/python3.8\/site-packages\/mlflow\/types\/schema.py:49: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \r\nDeprecated in NumPy 1.20; for more details and guidance: https:\/\/numpy.org\/devdocs\/release\/1.20.0-notes.html#deprecations\r\n  binary = (7, np.dtype(\"bytes\"), \"BinaryType\", np.object)\r\n2021-04-23 17:49:52,197 - root - INFO - Registered hooks from 2 installed plugin(s): kedro-mlflow-0.7.1\r\nUsage: kedro [OPTIONS] COMMAND [ARGS]...\r\nTry 'kedro -h' for help.\r\n\r\nError: No such command 'mlflow'.\r\n\r\n```\r\n\r\n## Your Environment\r\n\r\nUbuntu 18.04.5\r\n\r\n- Kedro 0.17.3\r\n- kedro-mlflow 0.7.1\r\n- python 3.8.8.\r\n- mlflow 1.15.0\r\n\r\n## Does the bug also happen with the last version on master?\r\n\r\nyes",
        "Issue_answer_count":6,
        "Issue_self_closed":0.0,
        "Answer_body":"Hi, \r\n\r\nI wil try to check it out this weekend, but the `kedro==0.17.3` version is brand new (it was released yesterday), and given my experience with past kedro versions update 2 things might have happened on kedro's side: \r\n- They have broken the auto-discovery mechanism (I've seen in the release note that they change the CLI command discovery to enale overriding project commands by plugins)\r\n- They have not updated their `pandas-iris` starter yet which does not match the new version and is only compliant with `kedro==0.17.2`. \r\n\r\nWhile I am investigating, would you please confirm that :\r\n- `kedro-mlflow` works fine with kedro==0.17.2 with your setup\r\n- `kedro-mlflow` works fine if you don't use the `pandas-iris` starter: try `kedro new` with `kedro==0.17.3` and then add one ode to test the plugin\r\n- I'd be glad to see if another plugin (e.g. `kedro-viz`) is facing the same problem that kedro-mlflow. Would you mind checking?\r\n\r\nOf course there is the possibility that the problem comes from `kedro-mlflow` itself, but I hardly believe it. I'll tell you within 2 days. I am sorry, I am quite busy for now and I will not debug this before next week. Once again, it is very likely kedro's plugin discovery mechanism has been broken in the new release, I strongly suggest you go back to `kedro==0.17.2`.\r\n\r\nNext actions: \r\n- [X] reproduce the bug -> Done, thanks for the very good reproducible example\r\n- [X] Check if it happens with other plugins (say kedro-viz) -> `kedro viz` global command is properly discovered\r\n- [X] Check if hooks are properly loaded -> everything works fine if I add a `mlflow.yml` manually in the `conf\/local` folder (or any folder in `conf\/` actually). -> **This is a short term solution for you**,e ven if it is not very convenient. You can find allowed keys [in the documentation](https:\/\/kedro-mlflow.readthedocs.io\/en\/latest\/source\/04_experimentation_tracking\/01_configuration.html#the-mlflow-yml-file) or irectly [copy paste it from the code](https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/blob\/master\/kedro_mlflow\/template\/project\/mlflow.yml)\r\n- [X] Check if the tests pass with kedro==0.17.3 -> *Some tests are failing, but not the one related to the CLI commands which seems discovered. I need to investigate further*.\r\n- [x] Check if other plugins with *local* commands are discovered\r\n- [x] Check if it also happens it an empty project (i.e. *not* a starter)\r\n First of all, thank you for looking so quickly into it!\r\n\r\nFrom how I read your second message you already know that, but to answer your questions:\r\n- detecting `kedro mlflow` works fine with `kedro==0.17.2`\r\n- the problem is consistent with kedro==0.17.3 independent if I use the pandas-iris starter or not\r\n- `kedro viz` is found also with `kedro=0.17.3`\r\n\r\nAgain, thank you for providing workarounds directly on Monday morning, I can nicely work with those! A question for my understanding of the plugin: As long as the hooks are loaded, the mlflow functionality depends only on a `mlflow.yml` to be present, and all that `kedro mlflow init` does is copy this file from the template into `conf\/local`, is this correct? TL;DR: \r\n\r\nInstall this version for now, it should make the command available again:\r\n\r\n```console\r\npip uninstall kedro-mlflow\r\npip install git+https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow.git@bug\/no-cli\r\n```\r\n**Beware:** it is very important to uninstall your existing version of kedro-mlflow before reinstalling because the patch has the same version number that the current release.\r\n\r\nIf you confirm this works for you, I will deploy the patch to PyPI before kedro provides a patch on their side.\r\n_____________________________\r\n\r\nHi, some follow-up about this bug:\r\n\r\n- I've figured out *what* is going on but not *why* it happens. The `mlflow` group of command exists both at global (`new`) and project (`init`, `ui`) levels and for an unknown reason, `kedro` takes into account only one group of command in its `0.17.3` version. This is a bug I will report to the core team. However, it does not affect their other plugins (kedro-viz, kedro-docker, kedro-airflow) because none of them has both global and project commands.\r\n- The quickest (hacky) fix is to remove the global group of command to the make the project ones available. I've done this in the branch `bug\/no-cli` of the repo.\r\n\r\nTo answer your question: \r\n\r\n> A question for my understanding of the plugin: As long as the hooks are loaded, the mlflow functionality depends only on a mlflow.yml to be present, and all that kedro mlflow init does is copy this file from the template into conf\/local, is this correct?\r\n\r\nExactly: the `init` command renders the template (i.e. copy paste it + replace the jinja tags with dynamic values like the name of your project) to a folder in your `conf\/` folder (by default `local`, but you can specify an environment like this: `kedro mlflow init --env=<your-env-folder>`). The hooks contain all the code logic  and this mlflow.yml file is just here to pass parameters to them. \r\n\r\nThe other project command is `kedro mlflow ui` which is just a wrapper of \"mlflow ui\" with the parameters (mlflow_tracking_uri, port, host) defined in your `mlflow.yml` file.\r\n thanks, form a quick test I would say: the patch works like a charm! Hi @dmb23, I've just deployed the patch to PyPI. You can use `pip install kedro_mlflow==0.7.2`` and it should be ok for now. I close the issue, but feel free to reopen if you still encounter any issue in this new version.",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"cli unavail insid project descript try reproduc minim exampl doc project starter panda iri functin arriv initi project cli command avail context unclear connect want start look got immediatl block initi project advic look fix appreci step reproduc conda creat python conda activ pip instal new starter panda iri test error command expect result avail project directori give output insid folder actual result insid project folder command unknown miniconda env lib python site packag pkg resourc init deprecationwarn us absolut path resourc path allow rais except futur releas return provid packag requir resourc filenam miniconda env lib python site packag type schema deprecationwarn object deprec alia builtin object silenc warn us object modifi behavior safe deprec numpi detail guidanc http numpi org devdoc releas note html deprec binari dtype byte binarytyp object root info regist hook instal plugin usag option command arg try help error command environ ubuntu python bug happen version master ye",
        "Issue_preprocessed_content":"cli unavail insid project descript try reproduc minim exampl doc project starter functin initi project cli avail context unclear want start got block initi project advic fix step reproduc expect result avail project directori give output insid folder actual result insid project folder deprec alia builtin silenc warn us modifi behavior safe deprec numpi detail guidanc binari binarytyp info regist plugin usag try help environ ubuntu python bug version master ye",
        "Issue_gpt_summary_original":"The user is unable to initialize the kedro-mlflow project as the CLI commands are not available. The user has tried to create a Kedro project using the starter `pandas-iris` and install kedro-mlflow functionality, but the `kedro mlflow` command is unknown to Kedro inside the project folder. The user is seeking advice on how to fix this issue. The bug also happens with the last version on master.",
        "Issue_gpt_summary":"user unabl initi project cli command avail user tri creat project starter panda iri instal function command unknown insid project folder user seek advic fix issu bug happen version master",
        "Issue_score_count":2
    },
    {
        "Issue_link":"https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/issues\/187",
        "Issue_title":"kedro mlflow ui does not use arguments from mlflow.yml",
        "Issue_created_time":1617627646000,
        "Issue_closed_time":1618006798000,
        "Issue_body":"## Description\r\n\r\nAs described in [this stackoverflow question](https:\/\/stackoverflow.com\/questions\/66917129\/specify-host-and-port-in-mlflow-yml-and-run-kedro-mlflow-ui-but-host-and-port), the `ui` command does not use the options\r\n\r\n## Context & Steps to Reproduce\r\n\r\n- Create a kedro project\r\n- Call `kedro mlflow init`\r\n- Modify the port in `mlflow.yml` to 5001\r\n- Launch `kedro mlflow ui`\r\n\r\n## Expected Result\r\n\r\nThe mlflow UI should open in port 5001.\r\n\r\n## Actual Result\r\n\r\nIt opens on port 5000 (the default).\r\n\r\n## Your Environment\r\n\r\nInclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* `kedro` version: 0.17.0\r\n* `kedro-mlflow` version: 0.6.0\r\n* Python version used (`python -V`): 3.6.8\r\n* Operating system and version: Windows\r\n\r\n## Does the bug also happen with the last version on master?\r\n\r\nYes\r\n\r\n## Solution\r\n\r\nWe should pass the arguments in the command: \r\n\r\nhttps:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/blob\/477147f6aa2dbf59c67f916b2002dea2de74d1fd\/kedro_mlflow\/framework\/cli\/cli.py#L149-L151",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"us argument yml descript describ stackoverflow question http stackoverflow com question specifi host port yml run host port command us option context step reproduc creat project init modifi port yml launch expect result open port actual result open port default environ includ relev detail environ experienc bug version version python version python oper version window bug happen version master ye solut pass argument command http github com galileo galilei blob faadbfcfbdeadedfd framework cli cli",
        "Issue_preprocessed_content":"us argument yml descript describ us option context step reproduc creat project modifi port launch expect result open port actual result open port environ includ relev detail environ experienc bug python oper version window bug version master ye solut argument",
        "Issue_gpt_summary_original":"The user encountered a TypeError when using MlflowArtifactDataSet with MlflowModelSaverDataSet, resulting in an unsupported operand type(s) for \/: 'str' and 'str'. The expected result was to save the model locally and in MLflow run at the same time. The bug occurred in kedro 0.16.6 and kedro-mlflow 0.4.0 on Python 3.7.7 and MacOS Catalina. The bug also happened with the last version on develop.",
        "Issue_gpt_summary":"user encount typeerror artifactdataset modelsaverdataset result unsupport operand type str str expect result save model local run time bug occur python maco catalina bug happen version develop",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/issues\/157",
        "Issue_title":"kedro mlflow cli is broken if configuration is declared in pyproject.toml",
        "Issue_created_time":1610404594000,
        "Issue_closed_time":1615716614000,
        "Issue_body":"## Description\r\n\r\nKedro enable to declare configuration either in ``.kedro.yml`` or in ``pyproject.toml`` (in the ``[tool.kedro]`` section). We claim to support both, but the CLI commands are not accessible if the project contains only a ``pyproject.toml file``.\r\n\r\n## Steps to Reproduce\r\n\r\nCall ``kedro mlflow init`` inside a project with no ``.kedro.yml`` file but only a ``pyproject.toml``.\r\n\r\n## Expected Result\r\n\r\nThe cli commands should be available (``init``)\r\n\r\n## Actual Result\r\nOnly the ``new`` command is available. This is not considered as a kedro project.\r\n\r\n```\r\n-- Separate them if you have more than one.\r\n```\r\n\r\n## Your Environment\r\n\r\n* `kedro` and `kedro-mlflow` version used (`pip show kedro` and `pip show kedro-mlflow`): kedro==16.6, kedro-mlflow==0.4.1\r\n* Python version used (`python -V`): 3.7.9\r\n* Operating system and version: Windows 7\r\n\r\n## Does the bug also happen with the last version on develop?\r\n\r\nYes\r\n\r\n## Solution\r\n\r\nThe error comes from the ``is_kedro_project`` function which does not consider that a folder is the root of a kdro project if it does not contain a ``.kedro.yml``.",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"This will wait the migration to `kedro>=0.17.0` (cf. #144) in milestone 0.6.0 because kedro has bradnd new utilities to handle this part. This will remove boilerplate code from the plugin and ensure consistency with future kedro changes.",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"cli broken configur declar pyproject toml descript enabl declar configur yml pyproject toml tool section support cli command access project contain pyproject toml file step reproduc init insid project yml file pyproject toml expect result cli command avail init actual result new command avail consid project separ environ version pip pip python version python oper version window bug happen version develop ye solut error come project function consid folder root kdro project contain yml",
        "Issue_preprocessed_content":"cli broken configur declar descript enabl declar configur cli project contain step reproduc insid project file expect result cli avail actual result avail consid project environ function consid folder kdro project contain",
        "Issue_gpt_summary_original":"The MlflowMetricsDataSet ignores the specified run_id when the prefix is not specified in the catalog, and instead uses the name in the catalog. This results in the current run_id overriding the specified run_id, causing the metric to be logged in a new run instead of the expected run. The bug also occurs in the latest version on develop.",
        "Issue_gpt_summary":"metricsdataset ignor specifi run prefix specifi catalog instead us catalog result current run overrid specifi run caus metric log new run instead expect run bug occur latest version develop",
        "Issue_score_count":1
    },
    {
        "Issue_link":"https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/issues\/122",
        "Issue_title":"A KedroPipelineModel cannot be loaded from mlflow if its catalog contains non deepcopy-able DataSets",
        "Issue_created_time":1605983313000,
        "Issue_closed_time":1606599848000,
        "Issue_body":"## Description\r\n\r\nI tried to load a KedroPipelineModel from mlflow, and I got a \"cannot pickle context artifacts\" error, which is due do the \r\n\r\n## Context\r\n\r\nI cannot load a previously saved KedroPipelineModel generated by pipeline_ml_factory.\r\n\r\n## Steps to Reproduce\r\n\r\nSave A KedroPipelineModel with a dataset that contains an object which cannot be deepcopied (for me, a keras tokenizer)\r\n\r\n## Expected Result\r\n\r\nThe model should be loaded\r\n\r\n## Actual Result\r\n\r\nAn error is raised\r\n\r\n## Your Environment\r\nInclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* `kedro` and `kedro-mlflow` version used: 0.16.5 and 0.4.0\r\n* Python version used (`python -V`): 3.6.8\r\n* Windows 10 & CentOS were tested\r\n\r\n## Does the bug also happen with the last version on develop?\r\n\r\nYes\r\n\r\n# Potential solution\r\n\r\nThe faulty line is:\r\n\r\nhttps:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/blob\/63dcd501bfe98bebc81f25f70020ff4141c1e91c\/kedro_mlflow\/mlflow\/kedro_pipeline_model.py#L45",
        "Issue_answer_count":2,
        "Issue_self_closed":1.0,
        "Answer_body":"Does removing the faulty line and using directly the initial_catalog make the model loadable again ? if Yes, we have two options :\r\n\r\n* We no longer deepcopy the initial_catalog\r\n* We copy each DataSet of the catalog with his own loader (for example, we use tf.keras.models.clone_model for keras model DataSet ...)\r\n\r\nKnowing that the `KedroPipelineModel` is intented to be used in a separated process (at inference-time), we can just remove the deepcopy part (there won't be a conflict with another function using the same catalog)\r\n After some investigation, the issues comes from the MLflowAbstractModelDataSet, and particularly the `self._mlflow_model_module` attribute which is a module and not deepcopiable by nature. I suggest to store it as a string, and have a property attribute to load the module on the fly.\r\n\r\nNote that this is a problem which occurs only when the DataSet is not deepcopiable (and not the underlying value the DataSet can load(), so we can quite safely assume that it should not occur often). If it does, we should consider a more radical solution among the ones you suggest.",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"pipelinemodel load catalog contain non deepcopi abl dataset descript tri load pipelinemodel got pickl context artifact error context load previous save pipelinemodel gener pipelin factori step reproduc save pipelinemodel dataset contain object deepcopi kera token expect result model load actual result error rais environ includ relev detail environ experienc bug version python version python window cento test bug happen version develop ye potenti solut faulti line http github com galileo galilei blob dcdbfebebcffffcec pipelin model",
        "Issue_preprocessed_content":"pipelinemodel load catalog contain non abl dataset descript tri load pipelinemodel got pickl context artifact context load previous save pipelinemodel gener step reproduc save pipelinemodel dataset contain object expect result model load actual result rais environ includ relev detail environ experienc bug python window cento test bug version develop ye potenti solut faulti line",
        "Issue_gpt_summary_original":"The user is facing an issue with the `kedro mlflow init` command, which is not compatible with the `pyproject.toml` configuration file introduced in kedro project version 0.16.5. The suggested solution is to remove the `_get_project_globals` util function in kedromlflow and use `kedro.framework.context import get_static_project_data`, which will only work with kedro>=0.16.5 and break retrocompatibility. The expected result is the creation of the mlflow.yml file, but the actual result is an error being raised.",
        "Issue_gpt_summary":"user face issu init command compat pyproject toml configur file introduc project version suggest solut remov project global util function us framework context import static project data work break retrocompat expect result creation yml file actual result error rais",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/issues\/121",
        "Issue_title":"RunStatus of mlflow run is \"FINISHED\" instead of \"FAILED\" when the kedro run fails",
        "Issue_created_time":1605982845000,
        "Issue_closed_time":1606515096000,
        "Issue_body":"## Description\r\n\r\nWhen I launch `kedro run` and the run fails, the `on_pipeline_error` closes all the mlflow runs (to avoid interactions with further runs)\r\n\r\n## Context\r\n\r\nI cannot distinguish failed runs from sucessful ones in the mlflow ui.\r\n\r\n## Steps to Reproduce\r\n\r\nLaunch a failing pipeline with kedro run.\r\n\r\n## Expected Result\r\n\r\nThe mlflow ui should display the run with a red cross\r\n\r\n## Actual Result\r\n\r\nThe mlflow ui displays the run with a green tick\r\n\r\n\r\n## Does the bug also happen with the last version on develop?\r\n\r\nYes.\r\n\r\n## Potential solution: \r\n\r\nReplace these lines:\r\n\r\n`https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/blob\/63dcd501bfe98bebc81f25f70020ff4141c1e91c\/kedro_mlflow\/framework\/hooks\/pipeline_hook.py#L193-L194`\r\n\r\nwith \r\n\r\n```python\r\nwhile mlflow.active_run():\r\n    mlflow.end_run(mlflow.entities.RunStatus.FAILED)\r\n```\r\nor even better, retrieve current run status from mlflow?\r\n",
        "Issue_answer_count":2,
        "Issue_self_closed":1.0,
        "Answer_body":"Good catch ! \r\nSince we catch the Error and manually end the run, mlflow do not receive the \"error code 1\" of the current process. If we no longer end run manually, mlflow will tag the run as FAILED. But since we want to control the pipeline error, we can apply your suggestion (specifiying the status as failed) Yes, but we need to terminate the run manually when it failed and one use it interactively (in CLI, tis makes no difference because it gets the error code as you say) to avoid further interference.",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"runstatu run finish instead fail run fail descript launch run run fail pipelin error close run avoid interact run context distinguish fail run sucess on step reproduc launch fail pipelin run expect result displai run red cross actual result displai run green tick bug happen version develop ye potenti solut replac line http github com galileo galilei blob dcdbfebebcffffcec framework hook pipelin hook python activ run end run entiti runstatu fail better retriev current run statu",
        "Issue_preprocessed_content":"runstatu run finish instead fail run fail descript launch run fail close run context distinguish fail run on step reproduc launch fail pipelin run expect result displai run red actual result displai run tick bug version develop ye potenti solut replac line retriev run statu",
        "Issue_gpt_summary_original":"The user is facing an issue with MlflowDataSet failing to log on remote storage when the underlying dataset filepath is converted as a PurePosixPath. The error occurs when the local path is Linux and the `mlflow_tracking_uri` is an Azure blob storage. The issue can be fixed by replacing `self._filepath` by `self._filepath.as_posix()` in two locations.",
        "Issue_gpt_summary":"user face issu dataset fail log remot storag underli dataset filepath convert pureposixpath error occur local path linux track uri azur blob storag issu fix replac self filepath self filepath posix locat",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/issues\/116",
        "Issue_title":"TypeError: unsupported operand type(s) for \/: 'str' and 'str' when using MlflowArtifactDataSet with MlflowModelSaverDataSet",
        "Issue_created_time":1604666166000,
        "Issue_closed_time":1605715301000,
        "Issue_body":"## Description\r\n\r\n`TypeError: unsupported operand type(s) for \/: 'str' and 'str'` occurs when `MlflowArtifactDataSet` is used with `MlflowModelSaverDataSet`.\r\n\r\n## Context\r\n\r\nLogging locally and to MLflow in one step.\r\n\r\n## Steps to Reproduce\r\n\r\n```yaml\r\nsklearn_model:\r\n    type: kedro_mlflow.io.artifacts.MlflowArtifactDataSet\r\n    data_set:\r\n        type: kedro_mlflow.io.models.MlflowModelSaverDataSet\r\n        flavor: mlflow.sklearn\r\n        filepath: data\/06_models\/sklearn_model\r\n        versioned: true\r\n```\r\n\r\n## Expected Result\r\n\r\nThe model should be saved locally and in MLflow run at the same time.\r\n\r\n## Actual Result\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"\/Users\/olszewk2\/miniconda3\/envs\/pyzypad-example-env\/lib\/python3.7\/site-packages\/kedro\/io\/core.py\", line 240, in save\r\n    self._save(data)\r\n  File \"\/Users\/olszewk2\/dev\/pyzypad-example\/src\/kedro-mlflow\/kedro_mlflow\/io\/artifacts\/mlflow_artifact_dataset.py\", line 40, in _save\r\n    if hasattr(self, \"_version\")\r\n  File \"\/Users\/olszewk2\/miniconda3\/envs\/pyzypad-example-env\/lib\/python3.7\/site-packages\/kedro\/io\/core.py\", line 605, in _get_save_path\r\n    versioned_path = self._get_versioned_path(save_version)  # type: ignore\r\n  File \"\/Users\/olszewk2\/miniconda3\/envs\/pyzypad-example-env\/lib\/python3.7\/site-packages\/kedro\/io\/core.py\", line 616, in _get_versioned_path\r\n    return self._filepath \/ version \/ self._filepath.name\r\nTypeError: unsupported operand type(s) for \/: 'str' and 'str'\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"\/Users\/olszewk2\/miniconda3\/envs\/pyzypad-example-env\/bin\/kedro\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"\/Users\/olszewk2\/miniconda3\/envs\/pyzypad-example-env\/lib\/python3.7\/site-packages\/kedro\/framework\/cli\/cli.py\", line 725, in main\r\n    cli_collection()\r\n  File \"\/Users\/olszewk2\/miniconda3\/envs\/pyzypad-example-env\/lib\/python3.7\/site-packages\/click\/core.py\", line 829, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"\/Users\/olszewk2\/miniconda3\/envs\/pyzypad-example-env\/lib\/python3.7\/site-packages\/click\/core.py\", line 782, in main\r\n    rv = self.invoke(ctx)\r\n  File \"\/Users\/olszewk2\/miniconda3\/envs\/pyzypad-example-env\/lib\/python3.7\/site-packages\/click\/core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"\/Users\/olszewk2\/miniconda3\/envs\/pyzypad-example-env\/lib\/python3.7\/site-packages\/click\/core.py\", line 1066, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"\/Users\/olszewk2\/miniconda3\/envs\/pyzypad-example-env\/lib\/python3.7\/site-packages\/click\/core.py\", line 610, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"\/Users\/olszewk2\/dev\/pyzypad-example\/kedro_cli.py\", line 230, in run\r\n    pipeline_name=pipeline,\r\n  File \"\/Users\/olszewk2\/miniconda3\/envs\/pyzypad-example-env\/lib\/python3.7\/site-packages\/kedro\/framework\/context\/context.py\", line 767, in run\r\n    raise exc\r\n  File \"\/Users\/olszewk2\/miniconda3\/envs\/pyzypad-example-env\/lib\/python3.7\/site-packages\/kedro\/framework\/context\/context.py\", line 759, in run\r\n    run_result = runner.run(filtered_pipeline, catalog, run_id)\r\n  File \"\/Users\/olszewk2\/miniconda3\/envs\/pyzypad-example-env\/lib\/python3.7\/site-packages\/kedro\/runner\/runner.py\", line 101, in run\r\n    self._run(pipeline, catalog, run_id)\r\n  File \"\/Users\/olszewk2\/miniconda3\/envs\/pyzypad-example-env\/lib\/python3.7\/site-packages\/kedro\/runner\/sequential_runner.py\", line 90, in _run\r\n    run_node(node, catalog, self._is_async, run_id)\r\n  File \"\/Users\/olszewk2\/miniconda3\/envs\/pyzypad-example-env\/lib\/python3.7\/site-packages\/kedro\/runner\/runner.py\", line 213, in run_node\r\n    node = _run_node_sequential(node, catalog, run_id)\r\n  File \"\/Users\/olszewk2\/miniconda3\/envs\/pyzypad-example-env\/lib\/python3.7\/site-packages\/kedro\/runner\/runner.py\", line 249, in _run_node_sequential\r\n    catalog.save(name, data)\r\n  File \"\/Users\/olszewk2\/miniconda3\/envs\/pyzypad-example-env\/lib\/python3.7\/site-packages\/kedro\/io\/data_catalog.py\", line 448, in save\r\n    func(data)\r\n  File \"\/Users\/olszewk2\/miniconda3\/envs\/pyzypad-example-env\/lib\/python3.7\/site-packages\/kedro\/io\/core.py\", line 625, in save\r\n    super().save(data)\r\n  File \"\/Users\/olszewk2\/miniconda3\/envs\/pyzypad-example-env\/lib\/python3.7\/site-packages\/kedro\/io\/core.py\", line 247, in save\r\n    raise DataSetError(message) from exc\r\nkedro.io.core.DataSetError: Failed while saving data to data set MlflowMlflowModelSaverDataSet(filepath=\/Users\/olszewk2\/dev\/pyzypad-example\/data\/06_models\/pclass_encoder, flavor=mlflow.sklearn, load_args={}, save_args={}, version=Version(load=None, save='2020-11-06T12.28.57.593Z')).\r\nunsupported operand type(s) for \/: 'str' and 'str'\r\n```\r\n\r\n## Your Environment\r\nInclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* kedro 0.16.6\r\n* kedro-mlflow 0.4.0\r\n* Python 3.7.7\r\n* MacOS Catalina\r\n\r\n## Does the bug also happen with the last version on develop?\r\n\r\nYes.",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"typeerror unsupport operand type str str artifactdataset modelsaverdataset descript typeerror unsupport operand type str str occur artifactdataset modelsaverdataset context log local step step reproduc yaml sklearn model type artifact artifactdataset data set type model modelsaverdataset flavor sklearn filepath data model sklearn model version true expect result model save local run time actual result traceback recent file user olszewk miniconda env pyzypad exampl env lib python site packag core line save self save data file user olszewk dev pyzypad exampl src artifact artifact dataset line save hasattr self version file user olszewk miniconda env pyzypad exampl env lib python site packag core line save path version path self version path save version type ignor file user olszewk miniconda env pyzypad exampl env lib python site packag core line version path return self filepath version self filepath typeerror unsupport operand type str str except direct caus follow except traceback recent file user olszewk miniconda env pyzypad exampl env bin line sy exit main file user olszewk miniconda env pyzypad exampl env lib python site packag framework cli cli line main cli collect file user olszewk miniconda env pyzypad exampl env lib python site packag click core line return self main arg kwarg file user olszewk miniconda env pyzypad exampl env lib python site packag click core line main self invok ctx file user olszewk miniconda env pyzypad exampl env lib python site packag click core line invok return process result sub ctx command invok sub ctx file user olszewk miniconda env pyzypad exampl env lib python site packag click core line invok return ctx invok self callback ctx param file user olszewk miniconda env pyzypad exampl env lib python site packag click core line invok return callback arg kwarg file user olszewk dev pyzypad exampl cli line run pipelin pipelin file user olszewk miniconda env pyzypad exampl env lib python site packag framework context context line run rais exc file user olszewk miniconda env pyzypad exampl env lib python site packag framework context context line run run result runner run filter pipelin catalog run file user olszewk miniconda env pyzypad exampl env lib python site packag runner runner line run self run pipelin catalog run file user olszewk miniconda env pyzypad exampl env lib python site packag runner sequenti runner line run run node node catalog self async run file user olszewk miniconda env pyzypad exampl env lib python site packag runner runner line run node node run node sequenti node catalog run file user olszewk miniconda env pyzypad exampl env lib python site packag runner runner line run node sequenti catalog save data file user olszewk miniconda env pyzypad exampl env lib python site packag data catalog line save func data file user olszewk miniconda env pyzypad exampl env lib python site packag core line save super save data file user olszewk miniconda env pyzypad exampl env lib python site packag core line save rais dataseterror messag exc core dataseterror fail save data data set modelsaverdataset filepath user olszewk dev pyzypad exampl data model pclass encod flavor sklearn load arg save arg version version load save unsupport operand type str str environ includ relev detail environ experienc bug python maco catalina bug happen version develop ye",
        "Issue_preprocessed_content":"operand type str str artifactdataset modelsaverdataset descript context step step reproduc expect result model save run time actual result environ includ relev detail environ experienc bug python maco catalina bug version develop ye",
        "Issue_gpt_summary_original":"The user is facing an issue where the global variable in the mlflow.yml file is not replaced by its value even after registering a TemplatedConfigLoader in the project. This is due to get_mlflow_config() manually recreating the default ConfigLoader. The issue is expected to be fixed by #66.",
        "Issue_gpt_summary":"user face issu global variabl yml file replac valu regist templatedconfigload project config manual recreat default configload issu expect fix",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/issues\/102",
        "Issue_title":"MlflowMetricsDataSet ignores run_id when prefix is not specified",
        "Issue_created_time":1603488238000,
        "Issue_closed_time":1603665805000,
        "Issue_body":"## Description\r\nWhen `MlflowMetricsDataset` has no \"prefix\" specified, the name in the catalog is used instead. However, when the run_id is specified, it is overriden by the current run id when the prefix is automatically set.\r\n\r\n## Steps to Reproduce\r\n\r\n1. Create a mlflow run interactively: \r\n```python\r\nmlflow.start_run()\r\nmlflow.end_run()\r\n```\r\nAnd browse the ui to retrieve the run_id\r\n\r\n2. Declare a `MlflowMetricsDataset` in the `catalog.yml`: with no prefix and an existing run_id.\r\n```python\r\nmy_metrics:\r\n    type: kedro_mlflow.io.MlflowMetricsDataSet\r\n    run_id: 123456789 # existing run_id\r\n```\r\n\r\n3. Launch the pipeline which saves this catalog: `kedro run`\r\n\r\n## Expected Result\r\n\r\nA metric should be loggedin run \"1346579\".\r\n\r\n## Actual Result\r\n\r\nThe metric is logged is a new run.\r\n\r\n## Does the bug also happen with the last version on develop?\r\n\r\nYes",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"metricsdataset ignor run prefix specifi descript metricsdataset prefix specifi catalog instead run specifi overriden current run prefix automat set step reproduc creat run interact python start run end run brows retriev run declar metricsdataset catalog yml prefix exist run python metric type metricsdataset run exist run launch pipelin save catalog run expect result metric loggedin run actual result metric log new run bug happen version develop ye",
        "Issue_preprocessed_content":"metricsdataset ignor prefix specifi descript prefix specifi catalog instead specifi run prefix set step reproduc creat run interact brows retriev declar prefix exist launch pipelin save catalog expect result metric run actual result metric new run bug version develop ye",
        "Issue_gpt_summary_original":"The issue is that when the \"get_mlflow_config\" function is called within \"load_context\", it uses the working directory instead of the given path. This can cause problems when used in interactive mode outside of the kedro project root.",
        "Issue_gpt_summary":"issu config function call load context us work directori instead given path caus problem interact mode outsid project root",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/issues\/96",
        "Issue_title":"Make mlflow init work when configuration is in pyproject.toml",
        "Issue_created_time":1603011348000,
        "Issue_closed_time":1603658563000,
        "Issue_body":"## Description\r\n\r\nSince 0.16.5, kedro project can [now be configured with a `pyproject.toml` config file](https:\/\/github.com\/quantumblacklabs\/kedro\/issues\/439) instead of a `.kedro.yml` at the root of the projects. This breaks the `kedro mlflow init` command which is only compatible with `.kedro.yml` configuration file.\r\n\r\n## Context\r\nWe should remove the `_get_project_globals` util function in kedromlflow and use `kedro.framework.context import get_static_project_data` as suggested in #86. **Beware: this will break retrocompatibilty and work only with kedro>=0.16.5**\r\n\r\n## Steps to Reproduce\r\n\r\nLaunch `kedro mlflow init` with no `.kedro.yml` config file in your project but a valid `pyproject.toml`.\r\n\r\n## Expected Result\r\nThe mlflow.yml file should be created\r\n\r\n## Actual Result\r\nAn error is raised.",
        "Issue_answer_count":2,
        "Issue_self_closed":1.0,
        "Answer_body":"Well spoted ! We can already solve this, by bundling kedro's `get_static_project_data` inside kedro_mlflow as long as we keep kedro < 0.16.5 retrocompatibility. We can switch then to `kedro.framework.context import get_static_project_data` when we drop this compatibility in the futur. I can add it to [Migrate 0.16.5 pull request](https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/pull\/94) Ok let's do this!",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"init work configur pyproject toml descript project configur pyproject toml config file http github com quantumblacklab issu instead yml root project break init command compat yml configur file context remov project global util function us framework context import static project data suggest bewar break retrocompatibilti work step reproduc launch init yml config file project valid pyproject toml expect result yml file creat actual result error rais",
        "Issue_preprocessed_content":"init work configur descript project instead project break compat configur file context remov util function us bewar break retrocompatibilti work step reproduc launch config file project valid expect result yml file creat actual result rais",
        "Issue_gpt_summary_original":"The user is facing an issue with the `kedro mlflow init` command, which is not compatible with the `pyproject.toml` configuration file introduced in kedro project version 0.16.5. The suggested solution is to remove the `_get_project_globals` util function in kedromlflow and use `kedro.framework.context import get_static_project_data`, which will only work with kedro>=0.16.5 and break retrocompatibility. The expected result is the creation of the mlflow.yml file, but the actual result is an error being raised.",
        "Issue_gpt_summary":"user face issu init command compat pyproject toml configur file introduc project version suggest solut remov project global util function us framework context import static project data work break retrocompat expect result creation yml file actual result error rais",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/issues\/74",
        "Issue_title":"MlflowDataSet fails to log on remote storage when underlying dataset filepath is converted as a PurePosixPath",
        "Issue_created_time":1601476316000,
        "Issue_closed_time":1602278580000,
        "Issue_body":"When I register a dataset in the catalog.yml\r\n\r\n```yaml\r\nmy_dataset:\r\n  type : kedro_mlflow.io.MlflowDataSet \r\n  data_set : \r\n    type: pickle.PickleDataSet\r\n    filepath: data\/02_intermediate\/my_dataset.pkl\r\n```\r\n\r\nand I run `kedro run` I got a `expected string or bytes-like object` when **the local path is linux AND the `mlflow_tracking_uri` is an Azure blob storage (it works locally)**. I don't know really why this append, but it can be fied by replacing `self._filepath` by `self._filepath.as_posix()` in these 2 locations: \r\n\r\nhttps:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/blob\/94bae3df9a054c85dfc0bf13de8db876363de475\/kedro_mlflow\/io\/mlflow_dataset.py#L51\r\n\r\nhttps:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/blob\/94bae3df9a054c85dfc0bf13de8db876363de475\/kedro_mlflow\/io\/mlflow_dataset.py#L55\r\n\r\n@kaemo @akruszewski did you experience some issues with S3 too?\r\n\r\n**EDIT**: @akruszewski it is [the very same issue you encountered here](https:\/\/github.com\/akruszewski\/kedro-mlflow\/commit\/41e9e3fdd2c54a774cca69e1cb52e26cadf50b1e)",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"dataset fail log remot storag underli dataset filepath convert pureposixpath regist dataset catalog yml yaml dataset type dataset data set type pickl pickledataset filepath data intermedi dataset pkl run run got expect string byte like object local path linux track uri azur blob storag work local know append fi replac self filepath self filepath posix locat http github com galileo galilei blob baedfacdfcbfdedbd dataset http github com galileo galilei blob baedfacdfcbfdedbd dataset kaemo akruszewski experi issu edit akruszewski issu encount http github com akruszewski commit eefddcaccaecbecadfb",
        "Issue_preprocessed_content":"dataset fail log remot storag underli dataset filepath convert pureposixpath regist dataset run got local path linux azur blob storag know fi replac locat experi edit",
        "Issue_gpt_summary_original":"The user is encountering an issue where the mlflow run is not closed when a pipeline fails in interactive mode, leading to unintended side effects and a messy mlflow database. The suggested solution is to implement an \"on_pipeline_error\" kedro hook to close the mlflow run when the pipeline fails.",
        "Issue_gpt_summary":"user encount issu run close pipelin fail interact mode lead unintend effect messi databas suggest solut implement pipelin error hook close run pipelin fail",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/issues\/72",
        "Issue_title":"mlflow.yml is not parsed properly when using TemplatedConfigLoader",
        "Issue_created_time":1601411953000,
        "Issue_closed_time":1602948810000,
        "Issue_body":"When you have a global variable in the mlflow.yml file (e.g `mlruns: ${USER}\/mlruns`), the global variable is not replaced by its value even if the user has [registered a TemplatedConfigLoader](https:\/\/kedro.readthedocs.io\/en\/stable\/kedro.config.TemplatedConfigLoader.html) in his project. This is due to `get_mlflow_config()` to manually recreate the default ConfigLoader.\r\n\r\nThis is part of the numerous issues that will  be fixed by #66.\r\n\r\n",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"yml pars properli templatedconfigload global variabl yml file user global variabl replac valu user regist templatedconfigload http readthedoc stabl config templatedconfigload html project config manual recreat default configload numer issu fix",
        "Issue_preprocessed_content":"yml pars properli templatedconfigload global variabl yml file global variabl replac valu user project recreat default configload numer fix",
        "Issue_gpt_summary_original":"The user is facing an issue where running mlflow projects from remote sources since version 1.28 causes a \"mlflow: not found\" error. The expected behavior is for remote-sourced mlflow projects to be supported as previously.",
        "Issue_gpt_summary":"user face issu run project remot sourc version caus error expect behavior remot sourc project support previous",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/issues\/30",
        "Issue_title":"get_mlflow_config use the working directory instead of given path when called within load_context",
        "Issue_created_time":1595365457000,
        "Issue_closed_time":1602948810000,
        "Issue_body":"This may lead to strange behaviour when called in interactive mode in another place thant the kedro project root.",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"config us work directori instead given path call load context lead strang behaviour call interact mode place thant project root",
        "Issue_preprocessed_content":"us work directori instead given path lead strang behaviour interact mode place thant project",
        "Issue_gpt_summary_original":"The user is facing an issue where mlflow experiments do not work if the MLFLOW_TRACKING_URI container variable specifies an incorrect IP address. The execution gets stuck and it is necessary to manage this exception properly.",
        "Issue_gpt_summary":"user face issu experi work track uri contain variabl specifi incorrect address execut get stuck necessari manag except properli",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/issues\/14",
        "Issue_title":"Warning message appears when calling ``kedro mlflow init``",
        "Issue_created_time":1593379921000,
        "Issue_closed_time":1600718139000,
        "Issue_body":"The warning claims that the project is not initialised yet, and that you must call ``kedro mlflow init`` before calling any command while you are calling ``kedro mlflow init``. It can be safely ignored because the command works as intended. This bug is due to the dynamic creation of command.",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"warn messag appear call init warn cl project initialis init call command call init safe ignor command work intend bug dynam creation command",
        "Issue_preprocessed_content":"warn warn cl project initialis safe ignor work intend bug dynam creation",
        "Issue_gpt_summary_original":"the user encountered an error in the pipeline in github actions which caused their tests to not pass when starting a new experiment.",
        "Issue_gpt_summary":"user encount error pipelin github action caus test pass start new experi",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Galileo-Galilei\/kedro-mlflow\/issues\/10",
        "Issue_title":"Close mlflow run when a pipeline fails in interactive mode",
        "Issue_created_time":1591562037000,
        "Issue_closed_time":1598336871000,
        "Issue_body":"# Context\r\nToday, you can execute a kedro pipeline interactively. The logic would be to load the context, and then to run the pipeline.\r\n\r\n```python\r\nfrom kedro.context import load_context\r\nlocal_context = load_context(\".\")\r\nlocal_context.run(pipeline=local_context.pipelines[PIPELINE_NAME],\r\n                             catalog=local_context.catalog)\r\n```\r\n\r\n# Description\r\nIf the execution fails for some reason (bug in the pipeline), the mlflow run is not closed. This creates unintended side effects: for instance, if you rerun the pipeline, the new run will be nested in the failing runs and the mllflow database will become very messy.\r\n\r\nThis bug does not occur when running from the command line since the mlflow run is automatically closed when exiting.\r\n\r\n# Possible Implementation \r\nImplement a [``on_pipeline_error`` kedro ``Hook``](https:\/\/kedro.readthedocs.io\/en\/stable\/04_user_guide\/15_hooks.html?highlight=on_pipeline_error#hook-specification) to close the mlflow run when the pipeline fails.",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"close run pipelin fail interact mode context todai execut pipelin interact logic load context run pipelin python context import load context local context load context local context run pipelin local context pipelin pipelin catalog local context catalog descript execut fail reason bug pipelin run close creat unintend effect instanc rerun pipelin new run nest fail run mllflow databas messi bug occur run command line run automat close exit possibl implement implement pipelin error hook http readthedoc stabl user guid hook html highlight pipelin error hook specif close run pipelin fail",
        "Issue_preprocessed_content":"close run pipelin fail interact mode context todai execut pipelin interact logic load context run pipelin descript execut fail reason run close creat unintend instanc rerun pipelin new run nest fail run databas bug line run close exit implement implement close run pipelin fail",
        "Issue_gpt_summary_original":"The user is encountering an issue where the mlflow run is not closed when a pipeline fails in interactive mode, leading to unintended side effects and a messy mlflow database. The suggested solution is to implement an \"on_pipeline_error\" kedro hook to automatically close the mlflow run when the pipeline fails.",
        "Issue_gpt_summary":"user encount issu run close pipelin fail interact mode lead unintend effect messi databas suggest solut implement pipelin error hook automat close run pipelin fail",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/omegaml\/omegaml\/issues\/258",
        "Issue_title":"running mlflow>1.28 projects causes mlflow not found error",
        "Issue_created_time":1663358103000,
        "Issue_closed_time":null,
        "Issue_body":"*Currently*\n\n* since mlflow 1.28, running mlflow projects form remote sources causes\n  *mlflow: not found* issue on starting the project\n\n*Reproduce*\n\n* run TestMLFlowProjects.test_mlflow_gitproject_remote_https\n\n*Expected*\n\n* running remote-sourced mlflow project is supported as previously",
        "Issue_answer_count":0,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"run project caus error current run project form remot sourc caus issu start project reproduc run testproject test gitproject remot http expect run remot sourc project support previous",
        "Issue_preprocessed_content":"project caus project form remot sourc caus start project reproduc run expect project previous",
        "Issue_gpt_summary_original":"The user is facing an issue with the experiment_gbdt function, which raises an exception when the length of gbdt parameters or cat_columns is long. This is due to mlflow raising an error if the length of key\/value exceeds 250. Possible solutions include catching and ignoring all errors from mlflow or automatically truncating logging parameters.",
        "Issue_gpt_summary":"user face issu experi gbdt function rais except length gbdt paramet cat column long rais error length kei valu exce possibl solut includ catch ignor error automat truncat log paramet",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/ugr-sail\/sinergym\/issues\/101",
        "Issue_title":"Experiments with mlflow don't work if MLFLOW_TRACKING_URI container variable specify an incorrect ip address",
        "Issue_created_time":1639047613000,
        "Issue_closed_time":1639743100000,
        "Issue_body":"Execution get stuck if this case happens. It is necessary to manage this exception properly.",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"experi work track uri contain variabl specifi incorrect address execut stuck case happen necessari manag except properli",
        "Issue_preprocessed_content":"experi work contain variabl specifi execut stuck case manag except properli",
        "Issue_gpt_summary_original":"The user is facing an issue where running \"make one-click-mlflow\" is not working after \"make destroy\" due to the artifacts' bucket still existing, resulting in an error message. The expected behavior is for the second command to work without any issues.",
        "Issue_gpt_summary":"user face issu run click work destroi artifact bucket exist result error messag expect behavior second command work issu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/prinz-nussknacker\/prinz\/issues\/78",
        "Issue_title":"Error when starting new experiment in mlflow",
        "Issue_created_time":1608388229000,
        "Issue_closed_time":1610230183000,
        "Issue_body":"Error in pipeline in GithubActions\r\n`14:25:43.564 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDOUT: Starting Mlflow UI on port 5000\r\n14:25:46.430 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: 2020\/12\/19 14:25:46 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\r\n14:25:46.453 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: 2020\/12\/19 14:25:46 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\r\n14:25:46.468 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: 2020\/12\/19 14:25:46 ERROR mlflow.cli: Error initializing backend store\r\n14:25:46.480 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: ]\r\n14:25:46.483 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \r\n14:25:46.484 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: )\r\n14:25:46.485 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \tFOREIGN KEY(experiment_id) REFERENCES experiments (experiment_id)\r\n14:25:46.487 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \tCONSTRAINT runs_lifecycle_stage CHECK (lifecycle_stage IN ('active', 'deleted')), \r\n14:25:46.489 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \tCONSTRAINT status CHECK (status IN ('SCHEDULED', 'FAILED', 'FINISHED', 'RUNNING')), \r\n14:25:46.491 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \tCONSTRAINT source_type CHECK (source_type IN ('NOTEBOOK', 'JOB', 'LOCAL', 'UNKNOWN', 'PROJECT')), \r\n14:25:46.493 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \tCONSTRAINT run_pk PRIMARY KEY (run_uuid), \r\n14:25:46.495 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \texperiment_id INTEGER, \r\n14:25:46.496 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \tartifact_uri VARCHAR(200), \r\n14:25:46.497 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \tlifecycle_stage VARCHAR(20), \r\n14:25:46.500 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \tsource_version VARCHAR(50), \r\n14:25:46.505 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \tend_time BIGINT, \r\n14:25:46.509 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \tstart_time BIGINT, \r\n14:25:46.509 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \tstatus VARCHAR(20), \r\n14:25:46.509 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \tuser_id VARCHAR(256), \r\n14:25:46.510 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \tentry_point_name VARCHAR(50), \r\n14:25:46.510 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \tsource_name VARCHAR(500), \r\n14:25:46.510 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \tsource_type VARCHAR(20), \r\n14:25:46.510 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \tname VARCHAR(250), \r\n14:25:46.511 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \trun_uuid VARCHAR(32) NOT NULL, \r\n14:25:46.511 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: (Background on this error at: http:\/\/sqlalche.me\/e\/gkpj)\r\n14:25:46.511 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \r\n14:25:46.516 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: The above exception was the direct cause of the following exception:\r\n14:25:46.516 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:     _tracking_store = _tracking_store_registry.get_store(store_uri, artifact_root)\r\n14:25:46.517 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:   File \"\/usr\/local\/lib\/python3.8\/site-packages\/sqlalchemy\/engine\/base.py\", line 1618, in _run_visitor\r\n14:25:46.517 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:     conn._run_visitor(visitorcallable, element, **kwargs)\r\n14:25:46.518 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:     visitorcallable(self.dialect, self, **kwargs).traverse_single(element)\r\n14:25:46.541 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: (Background on this error at: http:\/\/sqlalche.me\/e\/gkpj)\r\n14:25:46.541 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: ]\r\n14:25:46.541 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \r\n14:25:46.541 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: )\r\n14:25:46.542 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \tFOREIGN KEY(experiment_id) REFERENCES experiments (experiment_id)\r\n14:25:46.542 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \tCONSTRAINT runs_lifecycle_stage CHECK (lifecycle_stage IN ('active', 'deleted')), \r\n14:25:46.543 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: 2020\/12\/19 14:25:46 INFO mlflow.store.db.utils: Updating database tables\r\n14:25:46.543 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: INFO  [alembic.runtime.migration] Running upgrade  -> 451aebb31d03, add metric step\r\n14:25:46.543 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: INFO  [alembic.runtime.migration] Will assume transactional DDL.\r\n14:25:46.543 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\r\n14:25:46.543 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \tCONSTRAINT status CHECK (status IN ('SCHEDULED', 'FAILED', 'FINISHED', 'RUNNING')), \r\n14:25:46.543 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \tCONSTRAINT source_type CHECK (source_type IN ('NOTEBOOK', 'JOB', 'LOCAL', 'UNKNOWN', 'PROJECT')), \r\n14:25:46.543 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \tCONSTRAINT run_pk PRIMARY KEY (run_uuid), \r\n14:25:46.543 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \texperiment_id INTEGER, \r\n14:25:46.543 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \tartifact_uri VARCHAR(200), \r\n14:25:46.548 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: INFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\r\n14:25:46.548 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \tlifecycle_stage VARCHAR(20), \r\n14:25:46.548 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \tsource_version VARCHAR(50), \r\n14:25:46.548 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \tend_time BIGINT, \r\n14:25:46.548 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \tstart_time BIGINT, \r\n14:25:46.548 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \tstatus VARCHAR(20), \r\n14:25:46.548 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \tuser_id VARCHAR(256), \r\n14:25:46.548 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \tentry_point_name VARCHAR(50), \r\n14:25:46.548 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \tsource_name VARCHAR(500), \r\n14:25:46.548 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \tsource_type VARCHAR(20), \r\n14:25:46.548 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \tname VARCHAR(250), \r\n14:25:46.548 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \trun_uuid VARCHAR(32) NOT NULL, \r\n14:25:46.548 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: CREATE TABLE runs (\r\n14:25:46.549 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: [SQL: \r\n14:25:46.549 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \r\n14:25:46.549 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: DETAIL:  Key (typname, typnamespace)=(runs, 2200) already exists.\r\n14:25:46.549 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: sqlalchemy.exc.IntegrityError: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"pg_type_typname_nsp_index\"\r\n14:25:46.549 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:     cursor.execute(statement, parameters)\r\n14:25:46.550 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:   File \"\/usr\/local\/lib\/python3.8\/site-packages\/sqlalchemy\/engine\/default.py\", line 588, in do_execute\r\n14:25:46.550 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:     self.dialect.do_execute(\r\n14:25:46.550 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:   File \"\/usr\/local\/lib\/python3.8\/site-packages\/sqlalchemy\/engine\/base.py\", line 1245, in _execute_context\r\n14:25:46.550 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:     raise value.with_traceback(tb)\r\n14:25:46.550 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:   File \"\/usr\/local\/lib\/python3.8\/site-packages\/sqlalchemy\/util\/compat.py\", line 152, in reraise\r\n14:25:46.550 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:     reraise(type(exception), exception, tb=exc_tb, cause=cause)\r\n14:25:46.550 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:   File \"\/usr\/local\/lib\/python3.8\/site-packages\/sqlalchemy\/util\/compat.py\", line 398, in raise_from_cause\r\n14:25:46.550 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:     util.raise_from_cause(sqlalchemy_exception, exc_info)\r\n14:25:46.550 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:   File \"\/usr\/local\/lib\/python3.8\/site-packages\/sqlalchemy\/engine\/base.py\", line 1476, in _handle_dbapi_exception\r\n14:25:46.550 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:     self._handle_dbapi_exception(\r\n14:25:46.550 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:   File \"\/usr\/local\/lib\/python3.8\/site-packages\/sqlalchemy\/engine\/base.py\", line 1249, in _execute_context\r\n14:25:46.550 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:     ret = self._execute_context(\r\n14:25:46.550 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:   File \"\/usr\/local\/lib\/python3.8\/site-packages\/sqlalchemy\/engine\/base.py\", line 1039, in _execute_ddl\r\n14:25:46.550 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:     return connection._execute_ddl(self, multiparams, params)\r\n14:25:46.550 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:   File \"\/usr\/local\/lib\/python3.8\/site-packages\/sqlalchemy\/sql\/ddl.py\", line 72, in _execute_on_connection\r\n14:25:46.550 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:     return meth(self, multiparams, params)\r\n14:25:46.550 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:   File \"\/usr\/local\/lib\/python3.8\/site-packages\/sqlalchemy\/engine\/base.py\", line 982, in execute\r\n14:25:46.550 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:     self.connection.execute(\r\n14:25:46.550 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:   File \"\/usr\/local\/lib\/python3.8\/site-packages\/sqlalchemy\/sql\/ddl.py\", line 821, in visit_table\r\n14:25:46.550 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:     return meth(obj, **kw)\r\n14:25:46.550 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:   File \"\/usr\/local\/lib\/python3.8\/site-packages\/sqlalchemy\/sql\/visitors.py\", line 138, in traverse_single\r\n14:25:46.550 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:     self.traverse_single(\r\n14:25:46.550 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:   File \"\/usr\/local\/lib\/python3.8\/site-packages\/sqlalchemy\/sql\/ddl.py\", line 777, in visit_metadata\r\n14:25:46.550 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:     return meth(obj, **kw)\r\n14:25:46.564 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: INFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\r\n14:25:46.564 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:   File \"\/usr\/local\/lib\/python3.8\/site-packages\/sqlalchemy\/sql\/visitors.py\", line 138, in traverse_single\r\n14:25:46.564 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:   File \"\/usr\/local\/lib\/python3.8\/site-packages\/sqlalchemy\/engine\/base.py\", line 2049, in _run_visitor\r\n14:25:46.564 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:     bind._run_visitor(\r\n14:25:46.564 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:   File \"\/usr\/local\/lib\/python3.8\/site-packages\/sqlalchemy\/sql\/schema.py\", line 4315, in create_all\r\n14:25:46.564 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:     InitialBase.metadata.create_all(engine)\r\n14:25:46.564 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:   File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/store\/db\/utils.py\", line 30, in _initialize_tables\r\n14:25:46.564 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:     mlflow.store.db.utils._initialize_tables(self.engine)\r\n14:25:46.564 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:   File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/store\/tracking\/sqlalchemy_store.py\", line 99, in __init__\r\n14:25:46.564 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:     return SqlAlchemyStore(store_uri, artifact_uri)\r\n14:25:46.564 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:   File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/server\/handlers.py\", line 64, in _get_sqlalchemy_store\r\n14:25:46.564 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:     return builder(store_uri=store_uri, artifact_uri=artifact_uri)\r\n14:25:46.564 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:   File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/tracking\/_tracking_service\/registry.py\", line 37, in get_store\r\n14:25:46.564 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:   File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/server\/handlers.py\", line 91, in _get_tracking_store\r\n14:25:46.564 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:     _get_tracking_store(backend_store_uri, default_artifact_root)\r\n14:25:46.564 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:   File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/server\/handlers.py\", line 105, in initialize_backend_stores\r\n14:25:46.564 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:     initialize_backend_stores(backend_store_uri, default_artifact_root)\r\n14:25:46.565 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:   File \"\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/cli.py\", line 291, in server\r\n14:25:46.565 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: Traceback (most recent call last):\r\n14:25:46.565 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \r\n14:25:46.565 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \r\n14:25:46.565 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: DETAIL:  Key (typname, typnamespace)=(runs, 2200) already exists.\r\n14:25:46.565 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint \"pg_type_typname_nsp_index\"\r\n14:25:46.565 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:     cursor.execute(statement, parameters)\r\n14:25:46.565 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:   File \"\/usr\/local\/lib\/python3.8\/site-packages\/sqlalchemy\/engine\/default.py\", line 588, in do_execute\r\n14:25:46.565 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:     self.dialect.do_execute(\r\n14:25:46.565 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR:   File \"\/usr\/local\/lib\/python3.8\/site-packages\/sqlalchemy\/engine\/base.py\", line 1245, in _execute_context\r\n14:25:46.565 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: Traceback (most recent call last):\r\n14:25:46.565 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: CREATE TABLE runs (\r\n14:25:46.565 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: [SQL: \r\n14:25:46.565 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: \r\n14:25:46.565 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: DETAIL:  Key (typname, typnamespace)=(runs, 2200) already exists.\r\n14:25:46.565 [ducttape-1] DEBUG org.testcontainers.containers.output.WaitingConsumer - STDERR: 2020\/12\/19 14:25:46 ERROR mlflow.cli: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"pg_type_typname_nsp_index\"`\r\nwhich causes test to not pass",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"Already fixed in #79 by introducing delay between mlflow server start and starting experiments in mlflow",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"error start new experi error pipelin githubact ducttap debug org testcontain contain output waitingconsum stdout start port ducttap debug org testcontain contain output waitingconsum stderr info store util creat initi databas tabl ducttap debug org testcontain contain output waitingconsum stderr info store util creat initi databas tabl ducttap debug org testcontain contain output waitingconsum stderr error cli error initi backend store ducttap debug org testcontain contain output waitingconsum stderr ducttap debug org testcontain contain output waitingconsum stderr ducttap debug org testcontain contain output waitingconsum stderr ducttap debug org testcontain contain output waitingconsum stderr foreign kei experi refer experi experi ducttap debug org testcontain contain output waitingconsum stderr constraint run lifecycl stage check lifecycl stage activ delet ducttap debug org testcontain contain output waitingconsum stderr constraint statu check statu schedul fail finish run ducttap debug org testcontain contain output waitingconsum stderr constraint sourc type check sourc type notebook job local unknown project ducttap debug org testcontain contain output waitingconsum stderr constraint run primari kei run uuid ducttap debug org testcontain contain output waitingconsum stderr experi integ ducttap debug org testcontain contain output waitingconsum stderr artifact uri varchar ducttap debug org testcontain contain output waitingconsum stderr lifecycl stage varchar ducttap debug org testcontain contain output waitingconsum stderr sourc version varchar ducttap debug org testcontain contain output waitingconsum stderr end time bigint ducttap debug org testcontain contain output waitingconsum stderr start time bigint ducttap debug org testcontain contain output waitingconsum stderr statu varchar ducttap debug org testcontain contain output waitingconsum stderr user varchar ducttap debug org testcontain contain output waitingconsum stderr entri point varchar ducttap debug org testcontain contain output waitingconsum stderr sourc varchar ducttap debug org testcontain contain output waitingconsum stderr sourc type varchar ducttap debug org testcontain contain output waitingconsum stderr varchar ducttap debug org testcontain contain output waitingconsum stderr run uuid varchar null ducttap debug org testcontain contain output waitingconsum stderr background error http sqlalch gkpj ducttap debug org testcontain contain output waitingconsum stderr ducttap debug org testcontain contain output waitingconsum stderr except direct caus follow except ducttap debug org testcontain contain output waitingconsum stderr track store track store registri store store uri artifact root ducttap debug org testcontain contain output waitingconsum stderr file usr local lib python site packag sqlalchemi engin base line run visitor ducttap debug org testcontain contain output waitingconsum stderr conn run visitor visitorcal element kwarg ducttap debug org testcontain contain output waitingconsum stderr visitorcal self dialect self kwarg travers singl element ducttap debug org testcontain contain output waitingconsum stderr background error http sqlalch gkpj ducttap debug org testcontain contain output waitingconsum stderr ducttap debug org testcontain contain output waitingconsum stderr ducttap debug org testcontain contain output waitingconsum stderr ducttap debug org testcontain contain output waitingconsum stderr foreign kei experi refer experi experi ducttap debug org testcontain contain output waitingconsum stderr constraint run lifecycl stage check lifecycl stage activ delet ducttap debug org testcontain contain output waitingconsum stderr info store util updat databas tabl ducttap debug org testcontain contain output waitingconsum stderr info alemb runtim migrat run upgrad aebbd add metric step ducttap debug org testcontain contain output waitingconsum stderr info alemb runtim migrat assum transact ddl ducttap debug org testcontain contain output waitingconsum stderr info alemb runtim migrat context impl postgresqlimpl ducttap debug org testcontain contain output waitingconsum stderr constraint statu check statu schedul fail finish run ducttap debug org testcontain contain output waitingconsum stderr constraint sourc type check sourc type notebook job local unknown project ducttap debug org testcontain contain output waitingconsum stderr constraint run primari kei run uuid ducttap debug org testcontain contain output waitingconsum stderr experi integ ducttap debug org testcontain contain output waitingconsum stderr artifact uri varchar ducttap debug org testcontain contain output waitingconsum stderr info alemb runtim migrat run upgrad aebbd migrat user column tag ducttap debug org testcontain contain output waitingconsum stderr lifecycl stage varchar ducttap debug org testcontain contain output waitingconsum stderr sourc version varchar ducttap debug org testcontain contain output waitingconsum stderr end time bigint ducttap debug org testcontain contain output waitingconsum stderr start time bigint ducttap debug org testcontain contain output waitingconsum stderr statu varchar ducttap debug org testcontain contain output waitingconsum stderr user varchar ducttap debug org testcontain contain output waitingconsum stderr entri point varchar ducttap debug org testcontain contain output waitingconsum stderr sourc varchar ducttap debug org testcontain contain output waitingconsum stderr sourc type varchar ducttap debug org testcontain contain output waitingconsum stderr varchar ducttap debug org testcontain contain output waitingconsum stderr run uuid varchar null ducttap debug org testcontain contain output waitingconsum stderr creat tabl run ducttap debug org testcontain contain output waitingconsum stderr sql ducttap debug org testcontain contain output waitingconsum stderr ducttap debug org testcontain contain output waitingconsum stderr kei typnam typnamespac run exist ducttap debug org testcontain contain output waitingconsum stderr sqlalchemi exc integrityerror psycopg error uniqueviol duplic kei valu violat uniqu constraint type typnam nsp index ducttap debug org testcontain contain output waitingconsum stderr cursor execut statement paramet ducttap debug org testcontain contain output waitingconsum stderr file usr local lib python site packag sqlalchemi engin default line execut ducttap debug org testcontain contain output waitingconsum stderr self dialect execut ducttap debug org testcontain contain output waitingconsum stderr file usr local lib python site packag sqlalchemi engin base line execut context ducttap debug org testcontain contain output waitingconsum stderr rais valu traceback ducttap debug org testcontain contain output waitingconsum stderr file usr local lib python site packag sqlalchemi util compat line rerais ducttap debug org testcontain contain output waitingconsum stderr rerais type except except exc caus caus ducttap debug org testcontain contain output waitingconsum stderr file usr local lib python site packag sqlalchemi util compat line rais caus ducttap debug org testcontain contain output waitingconsum stderr util rais caus sqlalchemi except exc info ducttap debug org testcontain contain output waitingconsum stderr file usr local lib python site packag sqlalchemi engin base line handl dbapi except ducttap debug org testcontain contain output waitingconsum stderr self handl dbapi except ducttap debug org testcontain contain output waitingconsum stderr file usr local lib python site packag sqlalchemi engin base line execut context ducttap debug org testcontain contain output waitingconsum stderr ret self execut context ducttap debug org testcontain contain output waitingconsum stderr file usr local lib python site packag sqlalchemi engin base line execut ddl ducttap debug org testcontain contain output waitingconsum stderr return connect execut ddl self multiparam param ducttap debug org testcontain contain output waitingconsum stderr file usr local lib python site packag sqlalchemi sql ddl line execut connect ducttap debug org testcontain contain output waitingconsum stderr return meth self multiparam param ducttap debug org testcontain contain output waitingconsum stderr file usr local lib python site packag sqlalchemi engin base line execut ducttap debug org testcontain contain output waitingconsum stderr self connect execut ducttap debug org testcontain contain output waitingconsum stderr file usr local lib python site packag sqlalchemi sql ddl line visit tabl ducttap debug org testcontain contain output waitingconsum stderr return meth obj ducttap debug org testcontain contain output waitingconsum stderr file usr local lib python site packag sqlalchemi sql visitor line travers singl ducttap debug org testcontain contain output waitingconsum stderr self travers singl ducttap debug org testcontain contain output waitingconsum stderr file usr local lib python site packag sqlalchemi sql ddl line visit metadata ducttap debug org testcontain contain output waitingconsum stderr return meth obj ducttap debug org testcontain contain output waitingconsum stderr info alemb runtim migrat run upgrad allow null metric valu ducttap debug org testcontain contain output waitingconsum stderr file usr local lib python site packag sqlalchemi sql visitor line travers singl ducttap debug org testcontain contain output waitingconsum stderr file usr local lib python site packag sqlalchemi engin base line run visitor ducttap debug org testcontain contain output waitingconsum stderr bind run visitor ducttap debug org testcontain contain output waitingconsum stderr file usr local lib python site packag sqlalchemi sql schema line creat ducttap debug org testcontain contain output waitingconsum stderr initialbas metadata creat engin ducttap debug org testcontain contain output waitingconsum stderr file usr local lib python site packag store util line initi tabl ducttap debug org testcontain contain output waitingconsum stderr store util initi tabl self engin ducttap debug org testcontain contain output waitingconsum stderr file usr local lib python site packag store track sqlalchemi store line init ducttap debug org testcontain contain output waitingconsum stderr return sqlalchemystor store uri artifact uri ducttap debug org testcontain contain output waitingconsum stderr file usr local lib python site packag server handler line sqlalchemi store ducttap debug org testcontain contain output waitingconsum stderr return builder store uri store uri artifact uri artifact uri ducttap debug org testcontain contain output waitingconsum stderr file usr local lib python site packag track track servic registri line store ducttap debug org testcontain contain output waitingconsum stderr file usr local lib python site packag server handler line track store ducttap debug org testcontain contain output waitingconsum stderr track store backend store uri default artifact root ducttap debug org testcontain contain output waitingconsum stderr file usr local lib python site packag server handler line initi backend store ducttap debug org testcontain contain output waitingconsum stderr initi backend store backend store uri default artifact root ducttap debug org testcontain contain output waitingconsum stderr file usr local lib python site packag cli line server ducttap debug org testcontain contain output waitingconsum stderr traceback recent ducttap debug org testcontain contain output waitingconsum stderr ducttap debug org testcontain contain output waitingconsum stderr ducttap debug org testcontain contain output waitingconsum stderr kei typnam typnamespac run exist ducttap debug org testcontain contain output waitingconsum stderr psycopg error uniqueviol duplic kei valu violat uniqu constraint type typnam nsp index ducttap debug org testcontain contain output waitingconsum stderr cursor execut statement paramet ducttap debug org testcontain contain output waitingconsum stderr file usr local lib python site packag sqlalchemi engin default line execut ducttap debug org testcontain contain output waitingconsum stderr self dialect execut ducttap debug org testcontain contain output waitingconsum stderr file usr local lib python site packag sqlalchemi engin base line execut context ducttap debug org testcontain contain output waitingconsum stderr traceback recent ducttap debug org testcontain contain output waitingconsum stderr creat tabl run ducttap debug org testcontain contain output waitingconsum stderr sql ducttap debug org testcontain contain output waitingconsum stderr ducttap debug org testcontain contain output waitingconsum stderr kei typnam typnamespac run exist ducttap debug org testcontain contain output waitingconsum stderr error cli psycopg error uniqueviol duplic kei valu violat uniqu constraint type typnam nsp index caus test pass",
        "Issue_preprocessed_content":"start new experi pipelin githubact caus test",
        "Issue_gpt_summary_original":"The user has encountered an issue with MLFlow where the name of the bucket is hardcoded, making it impossible to use MLFlow with AWS S3. This poses a challenge for those using Minio in Gateway mode with MLFlow on AWS as S3 buckets are globally unique.",
        "Issue_gpt_summary":"user encount issu bucket hardcod make imposs us aw pose challeng minio gatewai mode aw bucket global uniqu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/getindata\/kedro-kubeflow\/issues\/102",
        "Issue_title":"Plugin only compatible with kedro-mlflow<0.8.0",
        "Issue_created_time":1643989114000,
        "Issue_closed_time":null,
        "Issue_body":"```python\r\ndef is_mlflow_enabled() -> bool:\r\n    try:\r\n        import mlflow  # NOQA\r\n        from kedro_mlflow.framework.context import get_mlflow_config  # NOQA\r\n        return True\r\n    except ImportError:\r\n        return False\r\n```\r\nalway throws exception since `context` package has been moved or refactored",
        "Issue_answer_count":1,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"plugin compat python def enabl bool try import noqa framework context import config noqa return true importerror return fals alwai throw except context packag move refactor",
        "Issue_preprocessed_content":"plugin compat alwai throw except packag move refactor",
        "Issue_gpt_summary_original":"The user encountered an issue while trying to install the mlflow chart and migrate from an old version to a new one. The mlflow pod failed to start with an error related to an out-of-date database schema. The user suggests that the migration job should run before the mlflow pod upgrade, but it currently runs after the upgrade. The user was able to fix the issue by manually running the migration job with kubectl. The user used helm version v3.9.3 and kubectl version v1.24.3. The mlflow chart version used was 0.6.0.",
        "Issue_gpt_summary":"user encount issu try instal chart migrat old version new pod fail start error relat date databas schema user suggest migrat job run pod upgrad current run upgrad user abl fix issu manual run migrat job kubectl user helm version kubectl version chart version",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/nyanp\/nyaggle\/issues\/19",
        "Issue_title":"experiment_gbdt raise errors with long parameters and mlflow",
        "Issue_created_time":1580251523000,
        "Issue_closed_time":1580353817000,
        "Issue_body":"mlflow raises error if length of key\/value exceeds 250. If the length of gbdt parameters or cat_columns is long, experiment_gbdt will raise an exception.\r\n\r\nPossible option:\r\n- catch and ignore all errors from mlflow\r\n- truncate logging parameters automatically ",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"experi gbdt rais error long paramet rais error length kei valu exce length gbdt paramet cat column long experi gbdt rais except possibl option catch ignor error truncat log paramet automat",
        "Issue_preprocessed_content":"rais long paramet rais length length gbdt paramet long rais except option catch ignor truncat paramet",
        "Issue_gpt_summary_original":"The user installed the mlflow helm chart with changed settings on a local minikube cluster, using bitnami\/postgresql for the db backend and minio for s3 storage. They created an initial bucket named \"mlflow\" in minio and ran a simple training example from mlflow docs in a k8s pod with env variables set. While they can see the metadata about the model in UI, the artifact section in UI is empty and the bucket is also empty. The user expected the artifacts to be in the minio bucket. The user is using helm version v3.9.0 and kubectl version v1.23.3.",
        "Issue_gpt_summary":"user instal helm chart chang set local minikub cluster bitnami postgresql backend minio storag creat initi bucket name minio ran simpl train exampl doc pod env variabl set metadata model artifact section bucket user expect artifact minio bucket user helm version kubectl version",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/artefactory\/one-click-mlflow\/issues\/79",
        "Issue_title":"make one-click-mlflow not working after make destroy because of undeleted bucket",
        "Issue_created_time":1633706491000,
        "Issue_closed_time":null,
        "Issue_body":"**Describe the bug**\r\nProblem encountered by @ucsky. Running ```make one-click-mlflow``` is not working after ```make destroy``` because of the artifacts' bucket which still exists.\r\nGot the following error:\r\n````\r\n\r\nSetting up your GCP project...\r\n\u2577\r\n\u2502 Error: googleapi: Error 409: You already own this bucket. Please select another name., conflict\r\n\u2502 \r\n\u2502   with module.bucket_backend.google_storage_bucket.this,\r\n\u2502   on ..\/modules\/mlflow\/artifacts\/main.tf line 18, in resource \"google_storage_bucket\" \"this\":\r\n\u2502   18: resource \"google_storage_bucket\" \"this\" {\r\n\r\n````\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. run ```make one-click-mlflow``` and finish it\r\n2. run ```make destroy```\r\n3. run ```make one-click-mlflow```\r\n4. See error\r\n\r\n**Expected behavior**\r\nThe second command ```make one-click-mlflow``` should work \r\n\r\n",
        "Issue_answer_count":2,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"click work destroi undelet bucket bug problem encount ucski run click work destroi artifact bucket exist got follow error set gcp project error googleapi error bucket select conflict modul bucket backend googl storag bucket modul artifact main line resourc googl storag bucket resourc googl storag bucket reproduc step reproduc behavior run click finish run destroi run click error expect behavior second command click work",
        "Issue_preprocessed_content":"work destroi undelet bucket bug problem encount work artifact bucket exist got work",
        "Issue_gpt_summary_original":"The user encountered an issue with the MLFlow Helm Chart when including ServiceMonitor and Prometheus metrics along the Deployment. The ServiceMonitor for MLFlow was created correctly but did not work for the user. After debugging, the user manually changed the `targetPort: 80` to `port: http` in the deployed ServiceMonitor manifest, which worked. The user proposes a simple fix to change `targetPort: 80` to `port: http` in `templates\/servicemonitor.yaml` as per the official Prometheus Troubleshooting docs. The user used helm version 3.6.0 and kubectl version 1.19 with the mlflow chart version 0.2.21. No response was given for the other",
        "Issue_gpt_summary":"user encount issu helm chart includ servicemonitor prometheu metric deploy servicemonitor creat correctli work user debug user manual chang targetport port http deploi servicemonitor manifest work user propos simpl fix chang targetport port http templat servicemonitor yaml offici prometheu troubleshoot doc user helm version kubectl version chart version respons given",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/canonical\/mlflow-operator\/issues\/24",
        "Issue_title":"MLFlow hardcoded bucket name - impossible to use MLFlow with AWS S3",
        "Issue_created_time":1646132216000,
        "Issue_closed_time":1647350309000,
        "Issue_body":"https:\/\/github.com\/canonical\/mlflow-operator\/blob\/c856446074868d4735627c95878960d91555f4da\/charms\/mlflow-server\/src\/charm.py#L20\r\n\r\nThe name of the bucket for MLFlow is hardcoded. This is a big issue because this makes using Minio in Gateway mode + MLFlow impossible on AWS (S3 buckets are globally unique).\r\n\r\nIt's a good first issue :)",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"hardcod bucket imposs us aw http github com canon oper blob cdcdfda charm server src charm bucket hardcod big issu make minio gatewai mode imposs aw bucket global uniqu good issu",
        "Issue_preprocessed_content":"hardcod bucket us aw bucket hardcod big make minio gatewai mode aw",
        "Issue_gpt_summary_original":"The mlflow chart has a bug where the newly added staticPrefix parameter under extraArgs breaks the chart when used because it tries to add an extra argument to the mlflow server command that doesn't exist. The user suggests a solution to handle the staticPrefix as a separate argument in the extraEnv when starting up the mlflow server to make it work smoother for the final user. The user is creating a pull request to address this issue.",
        "Issue_gpt_summary":"chart bug newli ad staticprefix paramet extraarg break chart tri add extra argument server command exist user suggest solut handl staticprefix separ argument extraenv start server work smoother final user user creat pull request address issu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/community-charts\/helm-charts\/issues\/35",
        "Issue_title":"[mlflow] Migration Job should run before upgrade",
        "Issue_created_time":1660748480000,
        "Issue_closed_time":1660908206000,
        "Issue_body":"### Describe the bug a clear and concise description of what the bug is.\n\nWhen trying to install mlflow chart I'm trying to migrate from old mlflow version to the new one. I'm using `backendStore.databaseMigration: true` value for that. But mlflow pod failed to start with error:\r\n```\r\nmlflow.exceptions.MlflowException: Detected out-of-date database schema (found version c48cb773bb87, but expected cc1f77228345). Take a backup of your database, then run 'mlflow db upgrade <database_uri>' to migrate your database to the latest schema. NOTE: schema migration may result in database downtime - please consult your database's documentation for more detail.\r\n```\r\n\r\nFrom the looks of things migration Job should have `pre-install,pre-upgrade` hooks instead of `post-install,post-upgrade` but I can be wrong here. \r\n\r\nRunning Job from the chart manually with kubectl fixed this issue for me, but it will probably appear with the next release.\r\n\r\nThanks!\n\n### What's your helm version?\n\nv3.9.3\n\n### What's your kubectl version?\n\nv1.24.3\n\n### Which chart?\n\nmlflow\n\n### What's the chart version?\n\n0.6.0\n\n### What happened?\n\n_No response_\n\n### What you expected to happen?\n\nDB migration job should run before mlflow pod upgrade. \n\n### How to reproduce it?\n\n1. Install mlflow with old DB schema (1.23.1)\r\n2. Try to upgrade with 0.6.0 helm chart\n\n### Enter the changed values of values.yaml?\n\n```\r\nmlflow:\r\n  nodeSelector:\r\n    redacted: Shared\r\n  \r\n  ingress:\r\n    enabled: true\r\n  \r\n  artifactRoot:\r\n    s3:\r\n      enabled: true\r\n      bucket: \"redacted\"\r\n      awsAccessKeyId: \"\"\r\n      awsSecretAccessKey: \"\"\r\n  \r\n  extraEnvVars:\r\n    AWS_DEFAULT_REGION: eu-central-1\r\n    MLFLOW_S3_ENDPOINT_URL: https:\/\/bucket.redacted.s3.eu-central-1.vpce.amazonaws.com\r\n  \r\n  backendStore:\r\n    databaseMigration: true\r\n    databaseConnectionCheck: true\r\n    mysql:\r\n      enabled: true\r\n      host: \"redacted.eu-central-1.rds.amazonaws.com\"\r\n      database: \"mlflow\"\r\n      user: \"\"\r\n      password: \"\"\r\n```\n\n### Enter the command that you execute and failing\/misfunctioning.\n\nhelm upgrade --install --values override.yaml --wait --create-namespace --atomic --timeout 15m0s -f secrets:\/\/secrets.yaml shared-services .\/shared-services\n\n### Anything else we need to know?\n\nChart was installed as a part of another umbrella chart",
        "Issue_answer_count":6,
        "Issue_self_closed":0.0,
        "Answer_body":"Hi @faceless7171 \r\n\r\nThank you very much for reporting the issue. Yes, your suggestion can work. Let me create a PR and test it. Well, we can't use the pre-hook option because we need a configuration file for the DB connection. And I don't want to make secrets visible in the container.\r\n\r\n```console\r\n\u2502 Events:                                                                                                                                                          \u2502\r\n\u2502   Type     Reason       Age               From               Message                                                                                             \u2502\r\n\u2502   ----     ------       ----              ----               -------                                                                                             \u2502\r\n\u2502   Normal   Scheduled    22s               default-scheduler  Successfully assigned default\/mlflow-bzb8s to minikube                                              \u2502\r\n\u2502   Warning  FailedMount  7s (x6 over 22s)  kubelet            MountVolume.SetUp failed for volume \"migrations-config\" : configmap \"mlflow-migrations\" not found   \u2502\r\n\u2502   Warning  FailedMount  7s (x6 over 22s)  kubelet            MountVolume.SetUp failed for volume \"dbchecker\" : configmap \"mlflow-dbchecker\" not found            \u2502\r\n\u2502                                                                                                                                                                  \u2502\r\n```\r\n\r\nSo, we have another option. Maybe we can use the init container pattern for this purpose. Let me try. @all-contributors please add @faceless7171  for bug @burakince \n\nI've put up [a pull request](https:\/\/github.com\/community-charts\/helm-charts\/pull\/37) to add @faceless7171! :tada: Hi @faceless7171 \r\n\r\nCould you please try again with mlflow chart minimum 0.7.0 version? @burakince tested on 0.7.1 version. Everything is working now. Thanks for the fix.",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"migrat job run upgrad bug clear concis descript bug try instal chart try migrat old version new backendstor databasemigr true valu pod fail start error except except detect date databas schema version ccbbb expect ccf backup databas run upgrad migrat databas latest schema note schema migrat result databas downtim consult databas document look thing migrat job pre instal pre upgrad hook instead post instal post upgrad wrong run job chart manual kubectl fix issu probabl appear releas thank helm version kubectl version chart chart version happen respons expect happen migrat job run pod upgrad reproduc instal old schema try upgrad helm chart enter chang valu valu yaml nodeselector redact share ingress enabl true artifactroot enabl true bucket redact awsaccesskeyid awssecretaccesskei extraenvvar aw default region central endpoint url http bucket redact central vpce amazonaw com backendstor databasemigr true databaseconnectioncheck true mysql enabl true host redact central rd amazonaw com databas user password enter command execut fail misfunct helm upgrad instal valu overrid yaml wait creat namespac atom timeout secret secret yaml share servic share servic need know chart instal umbrella chart",
        "Issue_preprocessed_content":"migrat job run upgrad bug clear concis descript bug try chart try migrat old version new valu pod fail start thing migrat job instead wrong job chart kubectl fix probabl releas thank helm version kubectl version chart chart version expect migrat job run pod upgrad reproduc old schema try upgrad helm chart enter chang valu enter execut helm upgrad yaml know chart chart",
        "Issue_gpt_summary_original":"The user encountered an error while running the chart-testing (lint) step in the release.yaml file for the mlflow chart. The error occurred due to an issue with the maintainer name, which should be a GitHub username instead of a real name. The user did not provide any information on what they expected to happen or how to reproduce the issue.",
        "Issue_gpt_summary":"user encount error run chart test lint step releas yaml file chart error occur issu maintain github usernam instead real user provid inform expect happen reproduc issu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/community-charts\/helm-charts\/issues\/32",
        "Issue_title":"[mlflow] model artifacts not saved in remote s3 artifact store",
        "Issue_created_time":1660152345000,
        "Issue_closed_time":1660345866000,
        "Issue_body":"### Describe the bug a clear and concise description of what the bug is.\r\n\r\nI have local minikube cluster. I installed the helm chart with some changed settings. See below for the changed values. Everthing else is same as per default values yaml file. For db backend I am using `bitnami\/postgresql` and for s3 storage minio instance. I also have created a initial bucket named \"mlflow\" in minio. \r\n\r\nAnd then I created a simple k8s pod to run the simple training example from mlflow docs. This pod has env variables set as : `MLFLOW_TRACKING_URI=http:\/\/mlflow.airflow.svc.cluster.local:5000` [Here ](https:\/\/raw.githubusercontent.com\/mlflow\/mlflow\/master\/examples\/sklearn_elasticnet_wine\/train.py) is the link to that code. I can see the metadata about the model in UI however , artifact section in UI is empty and also the bucket is empty. \r\n\r\n### What's your helm version?\r\n\r\nversion.BuildInfo{Version:\"v3.9.0\", GitCommit:\"7ceeda6c585217a19a1131663d8cd1f7d641b2a7\", GitTreeState:\"clean\", GoVersion:\"go1.17.5\"}\r\n\r\n### What's your kubectl version?\r\n\r\nServer Version: version.Info{Major:\"1\", Minor:\"23\", GitVersion:\"v1.23.3\", GitCommit:\"816c97ab8cff8a1c72eccca1026f7820e93e0d25\", GitTreeState:\"clean\", BuildDate:\"2022-01-25T21:19:12Z\", GoVersion:\"go1.17.6\", Compiler:\"gc\", Platform:\"linux\/amd64\"}\r\n\r\n### Which chart?\r\n\r\nmlflow\r\n\r\n### What's the chart version?\r\n\r\nlatest\r\n\r\n### What happened?\r\n\r\n_No response_\r\n\r\n### What you expected to happen?\r\n\r\nI would expect the artifacts in minio bucket.\r\n\r\n### How to reproduce it?\r\n\r\ninstall the helm chart with minio and postgresql config. Run a simple exmple frpom docs. \r\n\r\n### Enter the changed values of values.yaml?\r\n\r\n```\r\nbackendStore:\r\n    databaseMigration: true\r\n    databaseConnectionCheck: true\r\n    postgres:\r\n      enabled: true\r\n      host: mlflow-postgres-postgresql.airflow.svc.cluster.local\r\n      database: mlflow_db\r\n      user: mlflow\r\n      password: mlflow\r\nartifactRoot:\r\n  proxiedArtifactStorage: true\r\n  s3:\r\n    enabled: true\r\n    bucket: mlflow\r\n    awsAccessKeyId: {{ requiredEnv \"MINIO_USERNAME\" }}\r\n    awsSecretAccessKey: {{ requiredEnv \"MINIO_PASSWORD\" }}\r\nextraEnvVars:\r\n  MLFLOW_S3_ENDPOINT_URL: minio.airflow.svc.cluster.local\r\n```\r\n\r\n### Enter the command that you execute and failing\/misfunctioning.\r\n\r\nhelm install mlflow-release community-charts\/mlflow --values values.yaml\r\n\r\n### Anything else we need to know?\r\n\r\n_No response_",
        "Issue_answer_count":5,
        "Issue_self_closed":0.0,
        "Answer_body":"Hi @mohittalele ,\r\n\r\nThank you very much for reporting the error. Could you please share your mlflow pod and training pod logs with me?\r\n\r\nBest,\r\nBurak Hi @mohittalele \r\n\r\nI think you have a misconfiguration. I added a [full example to here](https:\/\/github.com\/community-charts\/examples\/tree\/main\/mlflow-examples\/bitnami-postgresql-and-bitnami-minio-sklearn-training-example). Simply, your `MLFLOW_S3_ENDPOINT_URL` configuration is wrong. URL must be `http:\/\/minio.airflow.svc.cluster.local:9000`. Could you please fix your configuration and try again?\r\n\r\nBest,\r\nBurak @burakince  Here is the log of the training container. Somehow the trining container does not \"know\" of the s3 endpoint and it is using the local path. \r\n\r\n```\r\n[2022-08-11, 13:53:26 CEST] {pod_manager.py:226} INFO - 2022\/08\/11 11:53:26 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\r\n[2022-08-11, 13:53:26 CEST] {pod_manager.py:226} INFO - The git executable must be specified in one of the following ways:\r\n[2022-08-11, 13:53:26 CEST] {pod_manager.py:226} INFO -     - be included in your $PATH\r\n[2022-08-11, 13:53:26 CEST] {pod_manager.py:226} INFO -     - be set via $GIT_PYTHON_GIT_EXECUTABLE\r\n[2022-08-11, 13:53:26 CEST] {pod_manager.py:226} INFO -     - explicitly set via git.refresh()\r\n[2022-08-11, 13:53:26 CEST] {pod_manager.py:226} INFO - \r\n[2022-08-11, 13:53:26 CEST] {pod_manager.py:226} INFO - All git commands will error until this is rectified.\r\n[2022-08-11, 13:53:26 CEST] {pod_manager.py:226} INFO - \r\n[2022-08-11, 13:53:26 CEST] {pod_manager.py:226} INFO - This initial warning can be silenced or aggravated in the future by setting the\r\n[2022-08-11, 13:53:26 CEST] {pod_manager.py:226} INFO - $GIT_PYTHON_REFRESH environment variable. Use one of the following values:\r\n[2022-08-11, 13:53:26 CEST] {pod_manager.py:226} INFO -     - quiet|q|silence|s|none|n|0: for no warning or exception\r\n[2022-08-11, 13:53:26 CEST] {pod_manager.py:226} INFO -     - warn|w|warning|1: for a printed warning\r\n[2022-08-11, 13:53:26 CEST] {pod_manager.py:226} INFO -     - error|e|raise|r|2: for a raised exception\r\n[2022-08-11, 13:53:26 CEST] {pod_manager.py:226} INFO - \r\n[2022-08-11, 13:53:26 CEST] {pod_manager.py:226} INFO - Example:\r\n[2022-08-11, 13:53:26 CEST] {pod_manager.py:226} INFO -     export GIT_PYTHON_REFRESH=quiet\r\n[2022-08-11, 13:53:26 CEST] {pod_manager.py:226} INFO - \r\n[2022-08-11, 13:53:26 CEST] {pod_manager.py:226} INFO - Elasticnet model (alpha=0.500000, l1_ratio=0.500000):\r\n[2022-08-11, 13:53:26 CEST] {pod_manager.py:226} INFO -   RMSE: 0.793164022927685\r\n[2022-08-11, 13:53:26 CEST] {pod_manager.py:226} INFO -   MAE: 0.6271946374319586\r\n[2022-08-11, 13:53:26 CEST] {pod_manager.py:226} INFO -   R2: 0.10862644997792636\r\n[2022-08-11, 13:53:27 CEST] {pod_manager.py:226} INFO - get_artifact_uri ::  .\/mlruns\/0\/3b376331bcaa4894a0723fe4b690658f\/artifacts\r\n[2022-08-11, 13:53:27 CEST] {pod_manager.py:226} INFO - get_registry_uri ::  http:\/\/mlflow.airflow.svc.cluster.local:5000\/\r\n[2022-08-11, 13:53:27 CEST] {pod_manager.py:226} INFO - get_tracking_uri ::  http:\/\/mlflow.airflow.svc.cluster.local:5000\/\r\n[2022-08-11, 13:53:29 CEST] {pod_manager.py:226} INFO - Registered model 'ElasticnetWineModel' already exists. Creating a new version of this model...\r\n[2022-08-11, 13:53:29 CEST] {pod_manager.py:226} INFO - 2022\/08\/11 11:53:29 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: ElasticnetWineModel, version 11\r\n[2022-08-11, 13:53:29 CEST] {pod_manager.py:226} INFO - Created version '11' of model 'ElasticnetWineModel'.\r\n[2022-08-11, 13:53:30 CEST] {kubernetes_pod.py:453} INFO - Deleting pod: mlflow-example-1-7e89c5e6540645e3822fbf34410c6b99\r\n[2022-08-11, 13:53:30 CEST] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=mlflow, task_id=mlflow_example_1, execution_date=20220811T115225, start_date=20220811T115226, end_date=20220811T115330\r\n[2022-08-11, 13:53:30 CEST] {local_task_job.py:156} INFO - Task exited with return code 0\r\n[2022-08-11, 13:53:30 CEST] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check\r\n```\r\n\r\n\r\n\r\nmlflow logs are quite, There is nothing logged there. I will try out the example. Thanks for the example. \r\n\r\nedit : with 9000 port number specifie, there is no improvement @burakince The setup now works. Actually there was problem with VPN setting since I was deploying mlflow behind mlflow. We can close the issue :) Hi @mohittalele,\r\n\r\nI'm glad to hear the problem was resolved. If you need anything else, please don't hesitate to open a new issue.\r\n\r\nBest,\r\nBurak",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"model artifact save remot artifact store bug clear concis descript bug local minikub cluster instal helm chart chang set chang valu everth default valu yaml file backend bitnami postgresql storag minio instanc creat initi bucket name minio creat simpl pod run simpl train exampl doc pod env variabl set track uri http airflow svc cluster local http raw githubusercont com master exampl sklearn elasticnet wine train link code metadata model artifact section bucket helm version version buildinfo version gitcommit ceedacaadcdfdba gittreest clean govers kubectl version server version version info major minor gitvers gitcommit cabcffacecccafe gittreest clean builddat govers compil platform linux amd chart chart version latest happen respons expect happen expect artifact minio bucket reproduc instal helm chart minio postgresql config run simpl exmpl frpom doc enter chang valu valu yaml backendstor databasemigr true databaseconnectioncheck true postgr enabl true host postgr postgresql airflow svc cluster local databas user password artifactroot proxiedartifactstorag true enabl true bucket awsaccesskeyid requiredenv minio usernam awssecretaccesskei requiredenv minio password extraenvvar endpoint url minio airflow svc cluster local enter command execut fail misfunct helm instal releas commun chart valu valu yaml need know respons",
        "Issue_preprocessed_content":"model artifact save remot artifact store bug clear concis descript bug local minikub cluster helm chart chang chang valu everth default valu yaml file backend storag minio instanc creat initi bucket name minio creat simpl pod run simpl train exampl doc pod env variabl set link code metadata model artifact section bucket helm version clean kubectl version server version minor clean compil chart chart version latest expect expect artifact minio bucket reproduc helm chart minio postgresql config run simpl exmpl frpom doc enter chang valu enter execut helm releas chart know",
        "Issue_gpt_summary_original":"The user encountered an error while running the command `mlflow run . --experiement-name=psystock_data_pipelines` in Chapter 7 of a book. The error message indicated that a variable 'x' was not defined. The solution was to delete a line of code that contained a stray `raise` statement referencing the undefined variable.",
        "Issue_gpt_summary":"user encount error run command run experi psystock data pipelin chapter book error messag indic variabl defin solut delet line code contain strai rais statement referenc undefin variabl",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/community-charts\/helm-charts\/issues\/22",
        "Issue_title":"[mlflow] Use port name instead of port number in ServiceMonitor ",
        "Issue_created_time":1658844949000,
        "Issue_closed_time":1658854769000,
        "Issue_body":"### Describe the bug a clear and concise description of what the bug is.\n\nFirst of all, thanks to everyone creating this Helm Chart as it is really good and easy to use.\r\n\r\nHowever, I encountered a problem when choosing to include ServiceMonitor and Prometheus metrics along the Deployment. Generally, the created ServiceMonitor for MLFlow is correct, yet in the current form it does not work for me.\r\nI use the latest Prometheus deployed using the official Helm Chart and the MLFlow metrics did not show up in the Targets, yet it was visible in Service Discovery panel in Prometheus Dashboard, but appeared as `0\/1 active targets`.\r\n\r\nAfter a couple of hours of educated debugging I changed manually the `targetPort: 80` to `port: http` in the deployed ServiceMonitor manifest. It worked straightaway! \r\n\r\n\r\nWhat I propose is a simple fix:\r\nAccording to official Prometheus Troubleshooting docs the port specified in ServiceMonitor should use `name` instead of port number ([Link to docs](https:\/\/github.com\/prometheus-operator\/prometheus-operator\/blob\/main\/Documentation\/troubleshooting.md#using-textual-port-number-instead-of-port-name)) \r\nSimple fix would be to change `targetPort: 80` to `port: http` in `templates\/servicemonitor.yaml`. Port name `http` is already hardcoded, so can be used directly or new parameter could be introduced to give the freedom to choose port name.\r\nI am aware that port number of type Integer should also work...\r\n\n\n### What's your helm version?\n\n3.6.0\n\n### What's your kubectl version?\n\n1.19\n\n### Which chart?\n\nmlflow\n\n### What's the chart version?\n\n0.2.21\n\n### What happened?\n\n_No response_\n\n### What you expected to happen?\n\n_No response_\n\n### How to reproduce it?\n\n_No response_\n\n### Enter the changed values of values.yaml?\n\n_No response_\n\n### Enter the command that you execute and failing\/misfunctioning.\n\n helm install --namespace mlflow mlflow-tracking-server community-charts\/mlflow --set serviceMonitor.enabled=true\n\n### Anything else we need to know?\n\n_No response_",
        "Issue_answer_count":4,
        "Issue_self_closed":0.0,
        "Answer_body":"Hi @mikwieczorek \r\n\r\nThanks to inform us. Yes, probably it's my mistake. I changed it to the name some time ago. Let's write some tests and fix the problem. Well, it looks like your link refers to the port (service port) rather than targetPort (pod's port. This is currently what we use.). But we can even make it optional (port or targetPort selection) and use a name rather than a port number. It looks like it works with the latest version of Prometheus but I think we need to support all versions together.\r\n\r\nAnd [this is the full schema of endpoints field](https:\/\/github.com\/prometheus-operator\/prometheus-operator\/blob\/main\/Documentation\/api.md#monitoring.coreos.com\/v1.Endpoint).\r\n\r\nI will do some additional manual tests and send the PR. Hi @mikwieczorek \r\n\r\nChart version 0.3.0 should solve your problem. If it still accrues, feel free to reopen this issue. You can use the following command to update your deployment without the need for additional changes.\r\n\r\n```\r\nhelm repo update\r\nhelm upgrade --install --namespace mlflow mlflow-tracking-server community-charts\/mlflow --set serviceMonitor.enabled=true\r\n```\r\n\r\nBest,\r\nBurak Thank you @burakince for your prompt fix. It works correctly after the update. \r\nNext time, I will make an MR instead of just reporting the issue",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"us port instead port number servicemonitor bug clear concis descript bug thank creat helm chart good easi us encount problem choos includ servicemonitor prometheu metric deploy gener creat servicemonitor correct current form work us latest prometheu deploi offici helm chart metric target visibl servic discoveri panel prometheu dashboard appear activ target coupl hour educ debug chang manual targetport port http deploi servicemonitor manifest work straightawai propos simpl fix accord offici prometheu troubleshoot doc port specifi servicemonitor us instead port number link doc http github com prometheu oper prometheu oper blob main document troubleshoot textual port number instead port simpl fix chang targetport port http templat servicemonitor yaml port http hardcod directli new paramet introduc freedom choos port awar port number type integ work helm version kubectl version chart chart version happen respons expect happen respons reproduc respons enter chang valu valu yaml respons enter command execut fail misfunct helm instal namespac track server commun chart set servicemonitor enabl true need know respons",
        "Issue_preprocessed_content":"us port instead port number servicemonitor bug clear concis descript bug thank creat helm chart easi us encount problem includ servicemonitor prometheu metric deploy creat servicemonitor form work us latest prometheu deploi helm chart metric target visibl servic discoveri panel prometheu dashboard coupl hour educ chang deploi servicemonitor manifest work straightawai propos simpl fix prometheu doc port specifi servicemonitor us instead port number simpl fix chang port hardcod directli new paramet introduc port awar port number type integ helm version kubectl version chart chart version expect reproduc enter chang valu enter execut helm chart know",
        "Issue_gpt_summary_original":"The user is requesting an improvement in mlflow logging for population by having separate graphs for each individual's performance and sub runs on mlflow.",
        "Issue_gpt_summary":"user request improv log popul have separ graph individu perform sub run",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/community-charts\/helm-charts\/issues\/18",
        "Issue_title":"[mlflow] Extra args broken",
        "Issue_created_time":1657550069000,
        "Issue_closed_time":1657616964000,
        "Issue_body":"### Describe the bug a clear and concise description of what the bug is.\n\nThe new staticPrefix argument being under extraArgs breaks the chart for users that need to use the extraArgs\n\n### What's your helm version?\n\nversion.BuildInfo{Version:\"v3.8.1\", GitCommit:\"5cb9af4b1b271d11d7a97a71df3ac337dd94ad37\", GitTreeState:\"clean\", GoVersion:\"go1.17.8\"}\n\n### What's your kubectl version?\n\nClient Version: version.Info{Major:\"1\", Minor:\"22\", GitVersion:\"v1.22.5\", GitCommit:\"5c99e2ac2ff9a3c549d9ca665e7bc05a3e18f07e\", GitTreeState:\"clean\", BuildDate:\"2021-12-16T08:38:33Z\", GoVersion:\"go1.16.12\", Compiler:\"gc\", Platform:\"darwin\/arm64\"} Server Version: version.Info{Major:\"1\", Minor:\"23\", GitVersion:\"v1.23.3\", GitCommit:\"816c97ab8cff8a1c72eccca1026f7820e93e0d25\", GitTreeState:\"clean\", BuildDate:\"2022-01-25T21:19:12Z\", GoVersion:\"go1.17.6\", Compiler:\"gc\", Platform:\"linux\/arm64\"}\n\n### Which chart?\n\nmlflow\n\n### What's the chart version?\n\n0.2.7\n\n### What happened?\n\nThe newly added staticPrefix parameter under extraArgs breaks the chart when used because it tries to add an extra argument to the mlflow server command that doesnt exist.\n\n### What you expected to happen?\n\n_No response_\n\n### How to reproduce it?\n\n_No response_\n\n### Enter the changed values of values.yaml?\n\n_No response_\n\n### Enter the command that you execute and failing\/misfunctioning.\n\nhelm install -f mlflow\/values.yaml mlflow .\/mlflow\/\n\n### Anything else we need to know?\n\nI am just creating a pull request to address this in a bit different way and havent tested it yet. Just wanted to create a request to highlight a solution.\r\n\r\nYou could also handle the staticPrefix as a separate argument in the extraEnv when starting up the mlflow server to make this work smoother for a final user, but this solution should work as well.",
        "Issue_answer_count":6,
        "Issue_self_closed":1.0,
        "Answer_body":"Hi @subramaniam20jan \r\n\r\nCould you please share your values.yaml file with me? Do you have any additional change in it? Hi @subramaniam20jan \r\n\r\nI really didn't understand the problem. Static prefix is valid argument for mlflow server. You can find more information [here](https:\/\/mlflow.org\/docs\/latest\/cli.html#cmdoption-mlflow-server-static-prefix).\r\n\r\nAlso, it tested with argument and without argument in [the unit tests](https:\/\/github.com\/community-charts\/helm-charts\/blob\/main\/charts\/mlflow\/unittests\/deployment_test.yaml#L65). Also, it tested without argument in the integration test which we run it with [kind here](https:\/\/github.com\/community-charts\/helm-charts\/runs\/7283774204?check_suite_focus=true#step:12:175).\r\n\r\nI'm really not able to recreate the issue. Could you please share the error message? Well, if you use `mlflow ui` command, you must change it to `mlflow server` command for production usage. You can find same explanation from here: https:\/\/mlflow.org\/docs\/latest\/cli.html#mlflow-ui Actually it was my bad. This wasnt really an issue but I appreciate the addition of the extra parameters to the readiness and liveness probe :) btw, @burakince great job on the chart and image! I was something I have made many times in individual assignments and missed having in open source somewhere. Came across your project when I was about to create one myself. Saves me a lot of work :) Thanks @subramaniam20jan :) I just added an example usage to [here](https:\/\/github.com\/community-charts\/examples\/tree\/main\/mlflow-examples\/liveness-probe-and-readiness-probe-example).\r\n\r\nBest",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"extra arg broken bug clear concis descript bug new staticprefix argument extraarg break chart user need us extraarg helm version version buildinfo version gitcommit cbafbbddaadfacddad gittreest clean govers kubectl version client version version info major minor gitvers gitcommit ceacffacdcaebcaef gittreest clean builddat govers compil platform darwin arm server version version info major minor gitvers gitcommit cabcffacecccafe gittreest clean builddat govers compil platform linux arm chart chart version happen newli ad staticprefix paramet extraarg break chart tri add extra argument server command doesnt exist expect happen respons reproduc respons enter chang valu valu yaml respons enter command execut fail misfunct helm instal valu yaml need know creat pull request address bit differ wai havent test want creat request highlight solut handl staticprefix separ argument extraenv start server work smoother final user solut work",
        "Issue_preprocessed_content":"extra arg broken bug clear concis descript bug new staticprefix argument break chart user us helm version clean kubectl version client version minor clean compil server version minor clean compil chart chart version newli staticprefix paramet break chart tri extra argument server doesnt exist expect reproduc enter chang valu enter execut helm know creat request bit wai havent test want creat request highlight solut handl staticprefix separ argument extraenv start server work final user solut work",
        "Issue_gpt_summary_original":"The user is encountering an error while trying to log to a tracking server using MLflow. The error message suggests that there is an issue with the parameters supplied to the MLflowClient().log_batch() function. The user has provided their own modified scripts and is expecting logging to work.",
        "Issue_gpt_summary":"user encount error try log track server error messag suggest issu paramet suppli client log batch function user provid modifi script expect log work",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/community-charts\/helm-charts\/issues\/2",
        "Issue_title":"[mlflow] Run chart-testing (lint) step returns Error validating maintainer 404 Not Found error",
        "Issue_created_time":1656578904000,
        "Issue_closed_time":1656583953000,
        "Issue_body":"### Describe the bug a clear and concise description of what the bug is.\n\nWhen we open a pull request, chart-testing (lint) step in [release.yaml](https:\/\/github.com\/community-charts\/helm-charts\/blob\/main\/.github\/workflows\/release.yml#L60) file getting the following error.\r\n\r\n```\r\nError: Error linting charts: Error processing charts\r\n------------------------------------------------------------------------------------------------------------------------\r\n \u2716\ufe0e mlflow => (version: \"0.1.47\", path: \"charts\/mlflow\") > Error validating maintainer 'Burak Ince': 404 Not Found\r\n------------------------------------------------------------------------------------------------------------------------\r\n```\r\n\r\nBecause of maintainer name for the `ct lint` command must be a GitHub username rather than a real name.\n\n### What's your helm version?\n\nv3.9.0\n\n### What's your kubectl version?\n\nv1.24.2\n\n### Which chart?\n\nmlflow\n\n### What's the chart version?\n\n0.1.47\n\n### What happened?\n\n_No response_\n\n### What you expected to happen?\n\n_No response_\n\n### How to reproduce it?\n\n_No response_\n\n### Enter the changed values of values.yaml?\n\n_No response_\n\n### Enter the command that you execute and failing\/misfunctioning.\n\nct lint --debug --config .\/.github\/configs\/ct-lint.yaml --lint-conf .\/.github\/configs\/lintconf.yaml\n\n### Anything else we need to know?\n\n_No response_",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"run chart test lint step return error valid maintain error bug clear concis descript bug open pull request chart test lint step releas yaml http github com commun chart helm chart blob main github workflow releas yml file get follow error error error lint chart error process chart version path chart error valid maintain burak inc maintain lint command github usernam real helm version kubectl version chart chart version happen respons expect happen respons reproduc respons enter chang valu valu yaml respons enter command execut fail misfunct lint debug config github config lint yaml lint conf github config lintconf yaml need know respons",
        "Issue_preprocessed_content":"run step return valid maintain bug clear concis descript bug open request step file maintain github usernam real helm version kubectl version chart chart version expect reproduc enter chang valu enter execut lint know",
        "Issue_gpt_summary_original":"The user encountered an issue with MLFlow active run not being reported correctly in the MLFlow UI while using the `TrainingArguments` with `report_to=['mlflow']` and `run_name=\"run0\"`. The cause of the issue was identified as an incorrect check for the MLFlow active run in `src\/transformers\/integrations.py`. The expected behavior was for the MLFlow UI to report a run with a Run Name of `run0`.",
        "Issue_gpt_summary":"user encount issu activ run report correctli trainingargu report run run caus issu identifi incorrect check activ run src transform integr expect behavior report run run run",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/PacktPublishing\/Machine-Learning-Engineering-with-MLflow\/issues\/7",
        "Issue_title":"Chapter 7 `mlflow run . --experiement-name=psystock_data_pipelines` fails - BUGFIX",
        "Issue_created_time":1636550432000,
        "Issue_closed_time":1637063606000,
        "Issue_body":"## Instructions \r\nPage 133 of chapter 7 requires the reader to navigate to the following directory and enter the commands below:\r\n\r\n`cd Chapter07\/psystock-data-features-main`\r\n `mlflow run . --experiement-name=psystock_data_pipelines`\r\n\r\n## Problem\r\n\r\nThe following error message appears when running line of code specified above:\r\n``` \r\nTraceback (most recent call last):\r\n  File \"feature_set_generation.py\", line 30, in <module>\r\n    raise Exception('x should not exceed 5. The value of x was: {}'.format(x))\r\nNameError: name 'x' is not defined\r\n```\r\n\r\n## Solution\r\nResolve this by deleting line 30 below in `feature_set_generation.py`\r\n\r\n`30         raise Exception('x should not exceed 5. The value of x was: {}'.format(x))`\r\nThe stray `raise` statement is referencing an undefined variable `x`.\r\n\r\nRemoving this line of code removed the reference to this point and lead to the successful deployment of the experiment. I would consider adding such assertions in the `check_verify_data.py` file instead.\r\n\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"Thanks, invaluable contributions. We will add this to the Errata!!!",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"chapter run experi psystock data pipelin fail bugfix instruct page chapter requir reader navig follow directori enter command chapter psystock data featur main run experi psystock data pipelin problem follow error messag appear run line code specifi traceback recent file featur set gener line rais except exce valu format nameerror defin solut resolv delet line featur set gener rais except exce valu format strai rais statement referenc undefin variabl remov line code remov refer point lead success deploy experi consid ad assert check verifi data file instead",
        "Issue_preprocessed_content":"chapter fail bugfix instruct page chapter requir reader navig directori enter problem line code specifi solut resolv delet line strai statement referenc undefin variabl remov line code remov refer point lead deploy experi consid file instead",
        "Issue_gpt_summary_original":"The MLFlowLogger fails to update the status of a `mlflow.entities.run_info.RunInfo` object to 'FAILED' when an error is raised during training, causing the MLFlow Tracking Server screen to show that the training is still in progress even though it has been terminated with an error. The user has provided a code snippet to reproduce the issue and expects the status of each MLFlow's run to be correctly updated when `pl.Trainer.fit` fails. The PyTorch Lightning version used is 1.4.9, and the MLFlow version is 1.12.0.",
        "Issue_gpt_summary":"logger fail updat statu entiti run info runinfo object fail error rais train caus track server screen train progress termin error user provid code snippet reproduc issu expect statu run correctli updat trainer fit fail pytorch lightn version version",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/sash-a\/es_pytorch\/issues\/8",
        "Issue_title":"Improve mlflow logging for population",
        "Issue_created_time":1601310463000,
        "Issue_closed_time":1601714116000,
        "Issue_body":"Separate each individuals performance into its own graph.\r\n\r\n- [x] graphs for each individual (simply append pop-idx to each graph)\r\n- [x] sub runs on mlflow",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"0332ede5",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"improv log popul separ individu perform graph graph individu simpli append pop idx graph sub run",
        "Issue_preprocessed_content":"improv popul separ individu perform graph graph individu sub run",
        "Issue_gpt_summary_original":"The user has encountered an inconsistency issue with the MLFlowLogger.log_metrics method within steps of a LightningModule. The documentation states that the method should accept a dictionary of metric names and values, but the user found that using log_metrics or log_metric with the dictionary resulted in errors. The user was able to get the method to work by using log_metric with separate arguments for the key and value, but this behavior is not consistent with the documentation. The user has provided a minimum code example to reproduce the bug and has listed their environment details.",
        "Issue_gpt_summary":"user encount inconsist issu logger log metric method step lightningmodul document state method accept dictionari metric name valu user log metric log metric dictionari result error user abl method work log metric separ argument kei valu behavior consist document user provid minimum code exampl reproduc bug list environ detail",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/huggingface\/transformers\/issues\/18146",
        "Issue_title":"MLflow fails to log to a tracking server",
        "Issue_created_time":1657876344000,
        "Issue_closed_time":1662562977000,
        "Issue_body":"### System Info\r\n\r\nPython 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21)\r\n\r\nprint(transformers.__version__)\r\n4.20.1\r\n\r\nprint(mlflow.__version__)\r\n1.27.0\r\n\r\n### Who can help?\r\n\r\n_No response_\r\n\r\n### Information\r\n\r\n- [ ] The official example scripts\r\n- [X] My own modified scripts\r\n\r\n### Tasks\r\n\r\n- [ ] An officially supported task in the `examples` folder (such as GLUE\/SQuAD, ...)\r\n- [ ] My own task or dataset (give details below)\r\n\r\n### Reproduction\r\n\r\n1. Install mlflow\r\n2. Configure a vanilla training job to use a tracking server (os.environ[\"MLFLOW_TRACKING_URI\"]=\"...\")\r\n3. Run the job\r\n\r\nYou should see an error similar to:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"\/home\/ubuntu\/train.py\", line 45, in <module>\r\n    trainer.train()\r\n  File \"\/home\/ubuntu\/.local\/lib\/python3.9\/site-packages\/transformers\/trainer.py\", line 1409, in train\r\n    return inner_training_loop(\r\n  File \"\/home\/ubuntu\/.local\/lib\/python3.9\/site-packages\/transformers\/trainer.py\", line 1580, in _inner_training_loop\r\n    self.control = self.callback_handler.on_train_begin(args, self.state, self.control)\r\n  File \"\/home\/ubuntu\/.local\/lib\/python3.9\/site-packages\/transformers\/trainer_callback.py\", line 347, in on_train_begin\r\n    return self.call_event(\"on_train_begin\", args, state, control)\r\n  File \"\/home\/ubuntu\/.local\/lib\/python3.9\/site-packages\/transformers\/trainer_callback.py\", line 388, in call_event\r\n    result = getattr(callback, event)(\r\n  File \"\/home\/ubuntu\/.local\/lib\/python3.9\/site-packages\/transformers\/integrations.py\", line 856, in on_train_begin\r\n    self.setup(args, state, model)\r\n  File \"\/home\/ubuntu\/.local\/lib\/python3.9\/site-packages\/transformers\/integrations.py\", line 847, in setup\r\n    self._ml_flow.log_params(dict(combined_dict_items[i : i + self._MAX_PARAMS_TAGS_PER_BATCH]))\r\n  File \"\/home\/ubuntu\/.local\/lib\/python3.9\/site-packages\/mlflow\/tracking\/fluent.py\", line 675, in log_params\r\n    MlflowClient().log_batch(run_id=run_id, metrics=[], params=params_arr, tags=[])\r\n  File \"\/home\/ubuntu\/.local\/lib\/python3.9\/site-packages\/mlflow\/tracking\/client.py\", line 918, in log_batch\r\n    self._tracking_client.log_batch(run_id, metrics, params, tags)\r\n  File \"\/home\/ubuntu\/.local\/lib\/python3.9\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py\", line 315, in log_batch\r\n    self.store.log_batch(\r\n  File \"\/home\/ubuntu\/.local\/lib\/python3.9\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 309, in log_batch\r\n    self._call_endpoint(LogBatch, req_body)\r\n  File \"\/home\/ubuntu\/.local\/lib\/python3.9\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 56, in _call_endpoint\r\n    return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)\r\n  File \"\/home\/ubuntu\/.local\/lib\/python3.9\/site-packages\/mlflow\/utils\/rest_utils.py\", line 256, in call_endpoint\r\n    response = verify_rest_response(response, endpoint)\r\n  File \"\/home\/ubuntu\/.local\/lib\/python3.9\/site-packages\/mlflow\/utils\/rest_utils.py\", line 185, in verify_rest_response\r\n    raise RestException(json.loads(response.text))\r\nmlflow.exceptions.RestException: INVALID_PARAMETER_VALUE: Invalid value [{'key': 'logging_nan_inf_filter', 'value': 'True'}, {'key': 'save_strategy', 'value': 'epoch'}, {'key': 'save_steps', 'value': '500'}, {'key': 'save_total_limit', 'value': 'None'}, {'key': 'save_on_each_node', 'value': 'False'}, {'key': 'no_cuda', 'value': 'False'}, {'key': 'seed', 'value': '42'}, {'key': 'data_seed', 'value': 'None'}, {'key': 'jit_mode_eval', 'value': 'False'}, {'key': 'use_ipex', 'value': 'False'}, {'key': 'bf16', 'value': 'False'}, {'key': 'fp16', 'value': 'False'}, {'key': 'fp16_opt_level', 'value': 'O1'}, {'key': 'half_precision_backend', 'value': 'auto'}, {'key': 'bf16_full_eval', 'value': 'False'}, {'key': 'fp16_full_eval', 'value': 'False'}, {'key': 'tf32', 'value': 'None'}, {'key': 'local_rank', 'value': '-1'}, {'key': 'xpu_backend', 'value': 'None'}, {'key': 'tpu_num_cores', 'value': 'None'}, {'key': 'tpu_metrics_debug', 'value': 'False'}, {'key': 'debug', 'value': '[]'}, {'key': 'dataloader_drop_last', 'value': 'False'}, {'key': 'eval_steps', 'value': 'None'}, {'key': 'dataloader_num_workers', 'value': '0'}, {'key': 'past_index', 'value': '-1'}, {'key': 'run_name', 'value': '.\/output'}, {'key': 'disable_tqdm', 'value': 'False'}, {'key': 'remove_unused_columns', 'value': 'True'}, {'key': 'label_names', 'value': 'None'}, {'key': 'load_best_model_at_end', 'value': 'False'}, {'key': 'metric_for_best_model', 'value': 'None'}, {'key': 'greater_is_better', 'value': 'None'}, {'key': 'ignore_data_skip', 'value': 'False'}, {'key': 'sharded_ddp', 'value': '[]'}, {'key': 'fsdp', 'value': '[]'}, {'key': 'fsdp_min_num_params', 'value': '0'}, {'key': 'deepspeed', 'value': 'None'}, {'key': 'label_smoothing_factor', 'value': '0.0'}, {'key': 'optim', 'value': 'adamw_hf'}, {'key': 'adafactor', 'value': 'False'}, {'key': 'group_by_length', 'value': 'False'}, {'key': 'length_column_name', 'value': 'length'}, {'key': 'report_to', 'value': \"['mlflow']\"}, {'key': 'ddp_find_unused_parameters', 'value': 'None'}, {'key': 'ddp_bucket_cap_mb', 'value': 'None'}, {'key': 'dataloader_pin_memory', 'value': 'True'}, {'key': 'skip_memory_metrics', 'value': 'True'}, {'key': 'use_legacy_prediction_loop', 'value': 'False'}, {'key': 'push_to_hub', 'value': 'False'}, {'key': 'resume_from_checkpoint', 'value': 'None'}, {'key': 'hub_model_id', 'value': 'None'}, {'key': 'hub_strategy', 'value': 'every_save'}, {'key': 'hub_token', 'value': '<HUB_TOKEN>'}, {'key': 'hub_private_repo', 'value': 'False'}, {'key': 'gradient_checkpointing', 'value': 'False'}, {'key': 'include_inputs_for_metrics', 'value': 'False'}, {'key': 'fp16_backend', 'value': 'auto'}, {'key': 'push_to_hub_model_id', 'value': 'None'}, {'key': 'push_to_hub_organization', 'value': 'None'}, {'key': 'push_to_hub_token', 'value': '<PUSH_TO_HUB_TOKEN>'}, {'key': '_n_gpu', 'value': '1'}, {'key': 'mp_parameters', 'value': ''}, {'key': 'auto_find_batch_size', 'value': 'False'}, {'key': 'full_determinism', 'value': 'False'}, {'key': 'torchdynamo', 'value': 'None'}, {'key': 'ray_scope', 'value': 'last'}] for parameter 'params' supplied. Hint: Value was of type 'list'. See the API docs for more information about request parameters.\r\n```\r\n\r\nTraining script:\r\n\r\n```\r\nimport os\r\nimport numpy as np\r\nfrom datasets import load_dataset, load_metric\r\nfrom transformers import AutoTokenizer, Trainer, TrainingArguments, AutoModelForSequenceClassification\r\n\r\ntrain_dataset, test_dataset = load_dataset(\"imdb\", split=['train', 'test'])\r\n\r\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased\")\r\n\r\ndef tokenize_function(examples):\r\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\r\n\r\ntrain_dataset = train_dataset.map(tokenize_function, batched=True)\r\ntest_dataset = test_dataset.map(tokenize_function, batched=True)\r\n\r\nmodel = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-cased\", num_labels=2)\r\n\r\nmetric = load_metric(\"accuracy\")\r\n\r\ndef compute_metrics(eval_pred):\r\n    logits, labels = eval_pred\r\n    predictions = np.argmax(logits, axis=-1)\r\n    return metric.compute(predictions=predictions, references=labels)\r\n\r\nos.environ[\"HF_MLFLOW_LOG_ARTIFACTS\"]=\"1\"\r\nos.environ[\"MLFLOW_EXPERIMENT_NAME\"]=\"trainer-mlflow-demo\"\r\nos.environ[\"MLFLOW_FLATTEN_PARAMS\"]=\"1\"\r\n#os.environ[\"MLFLOW_TRACKING_URI\"]=<MY_SERVER IP>\r\n\r\ntraining_args = TrainingArguments(\r\n    num_train_epochs=1,\r\n    output_dir=\".\/output\",\r\n    logging_steps=500,\r\n    save_strategy=\"epoch\",\r\n)\r\n\r\ntrainer = Trainer(\r\n    model=model,\r\n    args=training_args,\r\n    train_dataset=train_dataset,\r\n    eval_dataset=test_dataset,\r\n    compute_metrics=compute_metrics\r\n)\r\n\r\ntrainer.train()\r\n```\r\n\r\n\r\n### Expected behavior\r\n\r\nI would expect logging to work :)",
        "Issue_answer_count":6,
        "Issue_self_closed":0.0,
        "Answer_body":"cc @sgugger  I'm not the one who wrote or supports the ML Flow callback :-) @noise-field wrote the integration two years ago, do you have an idea of why it doesn't seem to work anymore @noise-field? @juliensimon, I had an error message similar (I think). I found that the issue was related to values with empty string values  (https:\/\/github.com\/mlflow\/mlflow\/issues\/6253), and it looks like there is a patch in the upcoming MLFLOW version 1.28 (not yet released)\r\n\r\nIn my case, I had to set `mp_parameters` to `None` instead of leaving it as an empty string (the default value), and I see your error message has `{'key': 'mp_parameters', 'value': ''}`.\r\n\r\nWhile later MLflow version fix will address this issue, I think setting the `mp_parameters` to `None` instead of an empty string is cleaner. However, I'm not sure about the extent of this change.\r\n\r\n OK, I'll give it a try and I'll let you know. This issue has been automatically marked as stale because it has not had recent activity. If you think this still needs to be addressed please comment on this thread.\n\nPlease note that issues that do not follow the [contributing guidelines](https:\/\/github.com\/huggingface\/transformers\/blob\/main\/CONTRIBUTING.md) are likely to be ignored.",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"fail log track server info python packag conda forg main print transform version print version help respons inform offici exampl script modifi script task offici support task exampl folder glue squad task dataset detail reproduct instal configur vanilla train job us track server environ track uri run job error similar traceback recent file home ubuntu train line trainer train file home ubuntu local lib python site packag transform trainer line train return inner train loop file home ubuntu local lib python site packag transform trainer line inner train loop self control self callback handler train begin arg self state self control file home ubuntu local lib python site packag transform trainer callback line train begin return self event train begin arg state control file home ubuntu local lib python site packag transform trainer callback line event result getattr callback event file home ubuntu local lib python site packag transform integr line train begin self setup arg state model file home ubuntu local lib python site packag transform integr line setup self flow log param dict combin dict item self max param tag batch file home ubuntu local lib python site packag track fluent line log param client log batch run run metric param param arr tag file home ubuntu local lib python site packag track client line log batch self track client log batch run metric param tag file home ubuntu local lib python site packag track track servic client line log batch self store log batch file home ubuntu local lib python site packag store track rest store line log batch self endpoint logbatch req bodi file home ubuntu local lib python site packag store track rest store line endpoint return endpoint self host cred endpoint method json bodi respons proto file home ubuntu local lib python site packag util rest util line endpoint respons verifi rest respons respons endpoint file home ubuntu local lib python site packag util rest util line verifi rest respons rais restexcept json load respons text except restexcept invalid paramet valu invalid valu kei log nan inf filter valu true kei save strategi valu epoch kei save step valu kei save total limit valu kei save node valu fals kei cuda valu fals kei seed valu kei data seed valu kei jit mode eval valu fals kei us ipex valu fals kei valu fals kei valu fals kei opt level valu kei half precis backend valu auto kei eval valu fals kei eval valu fals kei valu kei local rank valu kei xpu backend valu kei tpu num core valu kei tpu metric debug valu fals kei debug valu kei dataload drop valu fals kei eval step valu kei dataload num worker valu kei past index valu kei run valu output kei disabl tqdm valu fals kei remov unus column valu true kei label name valu kei load best model end valu fals kei metric best model valu kei greater better valu kei ignor data skip valu fals kei shard ddp valu kei fsdp valu kei fsdp min num param valu kei deepspe valu kei label smooth factor valu kei optim valu adamw kei adafactor valu fals kei group length valu fals kei length column valu length kei report valu kei ddp unus paramet valu kei ddp bucket cap valu kei dataload pin memori valu true kei skip memori metric valu true kei us legaci predict loop valu fals kei push hub valu fals kei resum checkpoint valu kei hub model valu kei hub strategi valu save kei hub token valu kei hub privat repo valu fals kei gradient checkpoint valu fals kei includ input metric valu fals kei backend valu auto kei push hub model valu kei push hub organ valu kei push hub token valu kei gpu valu kei paramet valu kei auto batch size valu fals kei determin valu fals kei torchdynamo valu kei rai scope valu paramet param suppli hint valu type list api doc inform request paramet train script import import numpi dataset import load dataset load metric transform import autotoken trainer trainingargu automodelforsequenceclassif train dataset test dataset load dataset imdb split train test token autotoken pretrain distilbert base case def token function exampl return token exampl text pad max length truncat true train dataset train dataset map token function batch true test dataset test dataset map token function batch true model automodelforsequenceclassif pretrain distilbert base case num label metric load metric accuraci def comput metric eval pred logit label eval pred predict argmax logit axi return metric comput predict predict refer label environ log artifact environ experi trainer demo environ flatten param environ track uri train arg trainingargu num train epoch output dir output log step save strategi epoch trainer trainer model model arg train arg train dataset train dataset eval dataset test dataset comput metric comput metric trainer train expect behavior expect log work",
        "Issue_preprocessed_content":"fail log track server info python packag help inform exampl script modifi script task task folder task dataset reproduct configur train job us track server run job similar train script expect behavior expect work",
        "Issue_gpt_summary_original":"The user encountered an error while using the mlflow logger in PyTorch Lightning. The documentation mentions an argument called \"run_name\" for the mlflow logger, but when the user tried to use it, they received an error message saying that \"run_name\" is an unknown argument to the mlflow logger. The user provided a code snippet to reproduce the error and is using Colab as their environment.",
        "Issue_gpt_summary":"user encount error logger pytorch lightn document mention argument call run logger user tri us receiv error messag sai run unknown argument logger user provid code snippet reproduc error colab environ",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/huggingface\/transformers\/issues\/17066",
        "Issue_title":"Incorrect check for MLFlow active run in MLflowCallback",
        "Issue_created_time":1651602226000,
        "Issue_closed_time":1651758596000,
        "Issue_body":"### System Info\r\n\r\n```shell\r\n- mlflow==1.25.1\r\n- `transformers` version: 4.19.0.dev0\r\n- Platform: Linux-5.10.76-linuxkit-aarch64-with-glibc2.31\r\n- Python version: 3.9.7\r\n- Huggingface_hub version: 0.2.1\r\n- PyTorch version (GPU?): 1.10.2 (False)\r\n```\r\n\r\n\r\n### Who can help?\r\n\r\nShould be fixed by #17067\r\n\r\n### Information\r\n\r\n- [X] The official example scripts\r\n- [ ] My own modified scripts\r\n\r\n### Tasks\r\n\r\n- [X] An officially supported task in the `examples` folder (such as GLUE\/SQuAD, ...)\r\n- [ ] My own task or dataset (give details below)\r\n\r\n### Reproduction\r\n\r\nSteps to reproduce:\r\n1. Follow Training tutorial as per https:\/\/huggingface.co\/docs\/transformers\/training\r\n2. Change the training arguments to use `TrainingArguments(output_dir=\"test_trainer\", report_to=['mlflow'], run_name=\"run0\")`\r\n3. On `trainer.train()` the MLFlow UI should report a run with a Run Name of `run0` which is not currently the case.\r\n\r\nCause of the Issue:\r\n```\r\n>> import mlflow\r\n>> print(mlflow.active_run is None, mlflow.active_run() is None)\r\nFalse True\r\n```\r\n\r\nIn `src\/transformers\/integrations.py` the line `if self._ml_flow.active_run is None:` need to be replaced by `if self._ml_flow.active_run() is None:`\r\n\r\n### Expected behavior\r\n\r\nPR #14894 introduce support for run_name in the MLflowCallback. Though, this does not work as expected since the active run is checked using a method reference that always returns true. Bug introduced by #16131.\r\n",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"incorrect check activ run callback info shell transform version dev platform linux linuxkit aarch glibc python version huggingfac hub version pytorch version gpu fals help fix inform offici exampl script modifi script task offici support task exampl folder glue squad task dataset detail reproduct step reproduc follow train tutori http huggingfac doc transform train chang train argument us trainingargu output dir test trainer report run run trainer train report run run run current case caus issu import print activ run activ run fals true src transform integr line self flow activ run need replac self flow activ run expect behavior introduc support run callback work expect activ run check method refer return true bug introduc",
        "Issue_preprocessed_content":"check activ run info help fix inform exampl script modifi script task task folder task dataset reproduct step reproduc train tutori chang train argument us report run run case caus line replac expect behavior introduc work expect activ run check method refer return true bug introduc",
        "Issue_gpt_summary_original":"The user is facing an issue where the supplementary information about the run, such as git commit sha, user, and filename, is not logged when using `MLFlowLogger` as a logger in pytorch_lightning. The user suggests adding tags internally to resolve the issue seamlessly and expects the pytorch_lightning to manage the mlflow's run.",
        "Issue_gpt_summary":"user face issu supplementari inform run git commit sha user filenam log logger logger pytorch lightn user suggest ad tag intern resolv issu seamlessli expect pytorch lightn manag run",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning\/issues\/10397",
        "Issue_title":"`MLFlowLogger` does not update its status when `trainer.fit` failed",
        "Issue_created_time":1636290176000,
        "Issue_closed_time":1640642583000,
        "Issue_body":"## \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nWhen an error is raised during training with `MLFlowLogger`, status of a `mlflow.entities.run_info.RunInfo` object should be updated to be 'FAILED', while it remains 'RUNNING'.\r\nDue to the problem, when you look at MLFlow Tracking Server screen, It seams as if training is still in progress even though it has been terminated with an error.\r\n\r\n### To Reproduce\r\n\r\n<!--\r\nPlease reproduce using the BoringModel!\r\n\r\nYou can use the following Colab link:\r\nhttps:\/\/colab.research.google.com\/drive\/1HvWVVTK8j2Nj52qU4Q4YCyzOm0_aLQF3?usp=sharing\r\nIMPORTANT: has to be public.\r\n\r\nor this simple template:\r\nhttps:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/blob\/master\/pl_examples\/bug_report_model.py\r\n\r\nIf you could not reproduce using the BoringModel and still think there's a bug, please post here\r\nbut remember, bugs with code are fixed faster!\r\n-->\r\n```py\r\nimport os\r\n\r\nimport torch\r\nfrom torch.utils.data import DataLoader, Dataset\r\n\r\nfrom pytorch_lightning import LightningModule, Trainer\r\nfrom pytorch_lightning.loggers import MLFlowLogger ##### added #####\r\n\r\n\r\nclass RandomDataset(Dataset):\r\n    def __init__(self, size, length):\r\n        self.len = length\r\n        self.data = torch.randn(length, size)\r\n\r\n    def __getitem__(self, index):\r\n        return self.data[index]\r\n\r\n    def __len__(self):\r\n        return self.len\r\n\r\n\r\nclass BoringModel(LightningModule):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.layer = torch.nn.Linear(32, 2)\r\n\r\n    def forward(self, x):\r\n        return self.layer(x)\r\n\r\n    def training_step(self, batch, batch_idx):\r\n        loss = self(batch).sum()\r\n        self.log(\"train_loss\", loss)\r\n        raise Exception ##### added #####\r\n        return {\"loss\": loss}\r\n        \r\n    def validation_step(self, batch, batch_idx):\r\n        loss = self(batch).sum()\r\n        self.log(\"valid_loss\", loss)\r\n\r\n    def test_step(self, batch, batch_idx):\r\n        loss = self(batch).sum()\r\n        self.log(\"test_loss\", loss)\r\n\r\n    def configure_optimizers(self):\r\n        return torch.optim.SGD(self.layer.parameters(), lr=0.1)\r\n\r\n\r\ndef run():\r\n    train_data = DataLoader(RandomDataset(32, 64), batch_size=2)\r\n    val_data = DataLoader(RandomDataset(32, 64), batch_size=2)\r\n    test_data = DataLoader(RandomDataset(32, 64), batch_size=2)\r\n    \r\n    mlf_logger = MLFlowLogger() ##### added #####\r\n\r\n    model = BoringModel()\r\n    trainer = Trainer(\r\n        default_root_dir=os.getcwd(),\r\n        limit_train_batches=1,\r\n        limit_val_batches=1,\r\n        num_sanity_val_steps=0,\r\n        max_epochs=1,\r\n        # enable_model_summary=False,\r\n        logger=mlf_logger ##### added #####\r\n    )\r\n    try:\r\n        trainer.fit(model, train_dataloaders=train_data, val_dataloaders=val_data)\r\n        trainer.test(model, dataloaders=test_data)\r\n    finally:\r\n        print(trainer.logger.experiment.get_run(trainer.logger._run_id).info.status) # This should be 'FAILED'\r\n\r\nif __name__ == \"__main__\":\r\n    run()\r\n```\r\n\r\n### Expected behavior\r\n\r\n<!-- FILL IN -->\r\nStatus of each MLFlow's run is correctly updated when `pl.Trainer.fit` failed.\r\n\r\n### Environment\r\n\r\n<!--\r\nPlease copy and paste the output from our environment collection script:\r\nhttps:\/\/raw.githubusercontent.com\/PyTorchLightning\/pytorch-lightning\/master\/requirements\/collect_env_details.py\r\n(For security purposes, please check the contents of the script before running it)\r\n\r\nYou can get the script and run it with:\r\n```bash\r\nwget https:\/\/raw.githubusercontent.com\/PyTorchLightning\/pytorch-lightning\/master\/requirements\/collect_env_details.py\r\npython collect_env_details.py\r\n```\r\n\r\nYou can also fill out the list below manually.\r\n-->\r\n\r\n- PyTorch Lightning Version: 1.4.9\r\n- MLFlow Version: 1.12.0\r\n\r\n### Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"This issue has been automatically marked as stale because it hasn't had any recent activity. This issue will be closed in 7 days if no further activity occurs. Thank you for your contributions, Pytorch Lightning Team!\n",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"logger updat statu trainer fit fail bug error rais train logger statu entiti run info runinfo object updat fail remain run problem look track server screen seam train progress termin error reproduc import import torch torch util data import dataload dataset pytorch lightn import lightningmodul trainer pytorch lightn logger import logger ad class randomdataset dataset def init self size length self len length self data torch randn length size def getitem self index return self data index def len self return self len class boringmodel lightningmodul def init self super init self layer torch linear def forward self return self layer def train step self batch batch idx loss self batch sum self log train loss loss rais except ad return loss loss def valid step self batch batch idx loss self batch sum self log valid loss loss def test step self batch batch idx loss self batch sum self log test loss loss def configur optim self return torch optim sgd self layer paramet def run train data dataload randomdataset batch size val data dataload randomdataset batch size test data dataload randomdataset batch size mlf logger logger ad model boringmodel trainer trainer default root dir getcwd limit train batch limit val batch num saniti val step max epoch enabl model summari fals logger mlf logger ad try trainer fit model train dataload train data val dataload val data trainer test model dataload test data final print trainer logger experi run trainer logger run info statu fail main run expect behavior statu run correctli updat trainer fit fail environ pytorch lightn version version addit context",
        "Issue_preprocessed_content":"updat statu fail bug clear concis descript bug rais train statu object updat fail remain problem track server seam train termin reproduc reproduc boringmodel us colab link import public simpl templat reproduc boringmodel think bug post rememb bug code fix faster expect behavior statu run updat fail environ copi past output environ script secur purpos check content script script run list pytorch lightn version version context context problem",
        "Issue_gpt_summary_original":"The user is encountering a bug where external MLFlow logging failures cause the training job to fail. When the Databricks updates, the user loses access to MLFlow for a brief period, causing logging to fail. This error not only causes logging to fail but also causes the entire training pipeline to fail, losing progress on a potentially long-running job with limited error handling options currently available. The user is requesting flexibility in PyTorch Lightning to allow users to handle logging errors such that it will not always kill the training job.",
        "Issue_gpt_summary":"user encount bug extern log failur caus train job fail databrick updat user lose access brief period caus log fail error caus log fail caus entir train pipelin fail lose progress potenti long run job limit error handl option current avail user request flexibl pytorch lightn allow user handl log error kill train job",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning\/issues\/9497",
        "Issue_title":"Inconsistency in MLFlowLogger.log_metrics within steps",
        "Issue_created_time":1631568762000,
        "Issue_closed_time":1635553585000,
        "Issue_body":"## \ud83d\udc1b Inconsistency in MLFlowLogger.log_metrics within steps\r\n\r\nThe [documentation](https:\/\/pytorch-lightning.readthedocs.io\/en\/stable\/api\/pytorch_lightning.loggers.mlflow.html) for MLFlowLogger states that it has a method log_metrics which signature is as follows:\r\n\r\n`log_metrics(metrics, step=None)`\r\n\r\nwhere **metrics** (Dict[str, float]) \u2013 Dictionary with metric names as keys and measured quantities as values and \r\n**step** (Optional[int]) \u2013 Step number at which the metrics should be recorded.\r\n\r\nWhen within a training\/validation\/test _step method of a LightningModule:\r\n- Setting `self.logger.experiment.log_metrics({\"train_loss\": loss})` results in the fit method raising `AttributeError: 'MlflowClient' object has no attribute 'log_metrics'`\r\n- Setting `self.logger.experiment.log_metric({\"train_loss\": loss})` results in the fit method raising `TypeError: log_metric() missing 2 required positional arguments: 'key' and 'value'`\r\n- Setting `self.logger.experiment.log_metric(\"train_loss\", loss)` results in the fit method raising `TypeError: log_metric() missing 1 required positional argument: 'value'`\r\n\r\nFound the behavior from the last two options by luck because of a typo. The logger would expect `log_metric` despite the documentation saying the method is called `log_metrics`. Even if I use `log_metric` the method expects parameters other than the Dict[str, float] stated in the documentation.\r\n\r\n### To Reproduce\r\n\r\nThis is the minimum code I found that reproduces the bug:\r\n\r\nhttps:\/\/github.com\/mmazuecos\/pytorch_lightning_mlflow_bug\/blob\/main\/pytorch_lightning_mlflow_bug.py\r\n\r\n### Expected behavior\r\n\r\nThe code should work with the `log_metrics` signature from the documentation.\r\n\r\n### Environment\r\n\r\n* CUDA:\r\n\t- GPU:\r\n\t- available:         False\r\n\t- version:           None\r\n* Packages:\r\n\t- numpy:             1.21.2\r\n\t- pyTorch_debug:     False\r\n\t- pyTorch_version:   1.7.1.post2\r\n\t- pytorch-lightning: 1.4.5\r\n\t- tqdm:              4.62.2\r\n* System:\r\n\t- OS:                Linux\r\n\t- architecture:\r\n\t\t- 64bit\r\n\t\t- ELF\r\n\t- processor:         x86_64\r\n\t- python:            3.8.11\r\n\t- version:           #148-Ubuntu SMP Sat May 8 02:33:43 UTC 2021\r\n",
        "Issue_answer_count":2,
        "Issue_self_closed":0.0,
        "Answer_body":"`log_metrics` is part of the implementation of `LightningLoggerBase` yet using the experiment property returns the MlFlowClient which can be used to access methods specific to mlflow. So simply removing the experiment property from your calls should solve your problem.\r\n\r\nThe log_metric option of the mlflow client requires different args, see [here](https:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/blob\/master\/pytorch_lightning\/loggers\/mlflow.py#L226) This issue has been automatically marked as stale because it hasn't had any recent activity. This issue will be closed in 7 days if no further activity occurs. Thank you for your contributions, Pytorch Lightning Team!\n",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"inconsist logger log metric step inconsist logger log metric step document http pytorch lightn readthedoc stabl api pytorch lightn logger html logger state method log metric signatur follow log metric metric step metric dict str float dictionari metric name kei measur quantiti valu step option int step number metric record train valid test step method lightningmodul set self logger experi log metric train loss loss result fit method rais attributeerror client object attribut log metric set self logger experi log metric train loss loss result fit method rais typeerror log metric miss requir posit argument kei valu set self logger experi log metric train loss loss result fit method rais typeerror log metric miss requir posit argument valu behavior option luck typo logger expect log metric despit document sai method call log metric us log metric method expect paramet dict str float state document reproduc minimum code reproduc bug http github com mmazueco pytorch lightn bug blob main pytorch lightn bug expect behavior code work log metric signatur document environ cuda gpu avail fals version packag numpi pytorch debug fals pytorch version post pytorch lightn tqdm linux architectur bit elf processor python version ubuntu smp sat utc",
        "Issue_preprocessed_content":"inconsist step inconsist step state method signatur metric dictionari metric name kei measur quantiti valu step step number metric record method lightningmodul result fit method rais result fit method rais result fit method rais behavior option luck typo expect despit document sai method us method expect paramet dict state document reproduc minimum code reproduc bug expect behavior code work signatur document environ cuda gpu avail fals version packag numpi fals tqdm linux architectur bit elf python version smp sat utc",
        "Issue_gpt_summary_original":"The MLFlowLogger creates a new run when resuming from an hpc checkpoint, instead of reusing the run ID, which causes runs to be grouped incorrectly on the MLFlow UI. The user suggests that this can be patched using the logger, and is willing to attempt a PR if the owners agree that it's a bug. The issue can be reproduced on a slurm cluster.",
        "Issue_gpt_summary":"logger creat new run resum hpc checkpoint instead reus run caus run group incorrectli user suggest patch logger will attempt owner agre bug issu reproduc slurm cluster",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning\/issues\/8431",
        "Issue_title":"mlflow run_name unexpected argument error",
        "Issue_created_time":1626357881000,
        "Issue_closed_time":1626409391000,
        "Issue_body":"## \ud83d\udc1b Bug\r\nThe [documentation](https:\/\/pytorch-lightning.readthedocs.io\/en\/latest\/api\/pytorch_lightning.loggers.mlflow.html?highlight=logger#mlflow-logger) mentions there is an argument called run_name for the mlflow logger, where the run_name of a given experiment can be provided. Although,run_name is an unknown argument to the mlflow logger\r\n\r\n`TypeError: __init__() got an unexpected keyword argument 'run_name'`\r\n\r\n## Please reproduce using the BoringModel\r\nColab link:  https:\/\/colab.research.google.com\/drive\/1thcmInx6tQDOnkxk2Ir8hoOUx1UrOpIx?usp=sharing\r\n\r\n### To Reproduce\r\n\r\n```\r\nfrom pytorch_lightning.loggers import MLFlowLogger\r\nimport mlflow\r\n\r\nmlf_logger = MLFlowLogger(\r\n    experiment_name=\"test\",\r\n    run_name=\"testrun\",\r\n)\r\n```\r\n### Environment\r\nColab - https:\/\/colab.research.google.com\/drive\/1thcmInx6tQDOnkxk2Ir8hoOUx1UrOpIx?usp=sharing\r\n\r\n",
        "Issue_answer_count":3,
        "Issue_self_closed":1.0,
        "Answer_body":"That's because you are looking at the docs under \"latest\" which is the development version. On the master branch, there is a run_name argument but 1.3.x does not have that. You are probably using Lightning 1.3.x. \r\nIf you want, you can install Lightning rc0 to test the features before the 1.4 release.   Here are the docs for the stable version (1.3.x) https:\/\/pytorch-lightning.readthedocs.io\/en\/stable\/api\/pytorch_lightning.loggers.mlflow.html Okay got it. Thanks for clarifying ",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"run unexpect argument error bug document http pytorch lightn readthedoc latest api pytorch lightn logger html highlight logger logger mention argument call run logger run given experi provid run unknown argument logger typeerror init got unexpect keyword argument run reproduc boringmodel colab link http colab research googl com drive thcminxtqdonkxkirhoouxuropix usp share reproduc pytorch lightn logger import logger import mlf logger logger experi test run testrun environ colab http colab research googl com drive thcminxtqdonkxkirhoouxuropix usp share",
        "Issue_preprocessed_content":"unexpect argument bug mention argument given experi provid unknown argument reproduc boringmodel colab link reproduc environ colab",
        "Issue_gpt_summary_original":"The user is facing an issue with MlflowLogger failing to log parameters longer than 250 characters. The expected behavior is for MlflowLogger to not send parameters longer than 250 characters to mlflow and log a warning to the user. The user is using PyTorch version 1.0 and Python version 3.7. Mlflow only allows parameters to be at most 500 bytes (250 unicode characters).",
        "Issue_gpt_summary":"user face issu logger fail log paramet longer charact expect behavior logger send paramet longer charact log warn user user pytorch version python version allow paramet byte unicod charact",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning\/issues\/6745",
        "Issue_title":"mlflow run context is not logged when using MLFlowLogger",
        "Issue_created_time":1617115654000,
        "Issue_closed_time":1617875123000,
        "Issue_body":"## \ud83d\udc1b Bug\r\nWhen we use the basic mlflow logging via `with mlflow.start_run(): ...` context manager, we get a better supplementary info about the run (git commit sha, user, filename) rendered in the Tracking UI ([system tags](https:\/\/mlflow.org\/docs\/latest\/tracking.html#system-tags))\r\n\r\nBut when we use `MLFlowLogger` as a logger in pytorch_lightning, this info is not logged. As a user, I'd like to have a mirrored functionality out-of-the-box.\r\n\r\nI inspected the `start_run()` method of mlflow and deduced that the only thing is left while creating the run via MLflowClient is to add `resolve_tags` from the `context` package:\r\n```python\r\n# pytorch_lightning\/loggers\/mlflow.py\r\nfrom mlflow.tracking.context.registry import resolve_tags\r\n...\r\n    def experiment(self) -> MLflowClient:\r\n        if self._run_id is None:\r\n            run = self._mlflow_client.create_run(experiment_id=self._experiment_id, tags=resolve_tags(self.tags))\r\n```\r\n\r\nI think it's a better idea to add those tags internally (meaning not to expect users doing that manually) as first - it's as seamless as in the default API, secondly - it's the pytorch_lightning that manages the mlflow's run anyways.\r\n\r\n**PR is following ...**",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"run context log logger bug us basic log start run context manag better supplementari info run git commit sha user filenam render track tag http org doc latest track html tag us logger logger pytorch lightn info log user like mirror function box inspect start run method deduc thing left creat run client add resolv tag context packag python pytorch lightn logger track context registri import resolv tag def experi self client self run run self client creat run experi self experi tag resolv tag self tag think better idea add tag intern mean expect user manual seamless default api secondli pytorch lightn manag run anywai follow",
        "Issue_preprocessed_content":"run context bug us basic context manag info run render track us info user like function inspect method deduc thing left creat run client packag think idea tag default api secondli manag run anywai",
        "Issue_gpt_summary_original":"The user has encountered a bug where using log_gpu_memory with MLFLow logger causes an error due to an unsupported metric name. The expected behavior is for log_gpu_memory to log gpu memory correctly when using an MLFlow logger. The issue was reproduced in a Colab environment with specific versions of CUDA, packages, and system.",
        "Issue_gpt_summary":"user encount bug log gpu memori logger caus error unsupport metric expect behavior log gpu memori log gpu memori correctli logger issu reproduc colab environ specif version cuda packag",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning\/issues\/6641",
        "Issue_title":"External MLFlow logging failures cause training job to fail",
        "Issue_created_time":1616445327000,
        "Issue_closed_time":1619815518000,
        "Issue_body":"## \ud83d\udc1b Bug\r\n\r\nI am using a `pytorch_lightning.loggers.mlflow.MLFlowLogger` during training, with the MLFlow tracking URI hosted in Databricks. When Databricks updates, we sometimes lose access to MLFlow for a brief period. When this happens, logging to MLFlow fails with the following error:\r\n\r\n```python\r\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host=XXX.cloud.databricks.com, port=443): Max retries exceeded with url: \/api\/2.0\/mlflow\/runs\/get?XXX (Caused by NewConnectionError(<urllib3.connection.HTTPSConnection object at 0x7fbbd6096f50>: Failed to establish a new connection: [Errno 111] Connection refused))\r\n```\r\n\r\nNot only does logging fail, but with PyTorch Lightning, an error logging means the entire training pipeline will also fail, losing progress on a potentially long-running job with limited error handling options currently available. \r\n\r\nIdeally, there would be flexibility in PyTorch Lightning to allow users to handle logging errors such that it will not always kill the training job. \r\n\r\n## Please reproduce using the BoringModel\r\n\r\nhttps:\/\/colab.research.google.com\/drive\/17TqdKZ8SjcdpiCWc76N5uQc5IKIgNp7g?usp=sharing \r\n\r\n### To Reproduce\r\n\r\nAttempt to use a logger that fails to log. The training job will fail, losing all progress. \r\n\r\n### Expected behavior\r\n\r\nThere is an option to handle exceptions from the logger such that the job does not automatically die if logging a parameter fails. \r\n\r\n### Environment\r\n\r\n* CUDA:\r\n\t- GPU:\r\n\t\t- Tesla T4\r\n\t- available:         True\r\n\t- version:           10.1\r\n* Packages:\r\n\t- numpy:             1.19.5\r\n\t- pyTorch_debug:     False\r\n\t- pyTorch_version:   1.8.0+cu101\r\n\t- pytorch-lightning: 1.2.4\r\n\t- tqdm:              4.41.1\r\n* System:\r\n\t- OS:                Linux\r\n\t- architecture:\r\n\t\t- 64bit\r\n\t\t- \r\n\t- processor:         x86_64\r\n\t- python:            3.7.10\r\n\t- version:           #1 SMP Thu Jul 23 08:00:38 PDT 2020\r\n\r\n### Additional context\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"This issue has been automatically marked as stale because it hasn't had any recent activity. This issue will be closed in 7 days if no further activity occurs. Thank you for your contributions, Pytorch Lightning Team!\n",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"extern log failur caus train job fail bug pytorch lightn logger logger train track uri host databrick databrick updat lose access brief period happen log fail follow error python urllib except maxretryerror httpsconnectionpool host xxx cloud databrick com port max retri exceed url api run xxx caus newconnectionerror fail establish new connect errno connect refus log fail pytorch lightn error log mean entir train pipelin fail lose progress potenti long run job limit error handl option current avail ideal flexibl pytorch lightn allow user handl log error kill train job reproduc boringmodel http colab research googl com drive tqdkzsjcdpicwcnuqcikignpg usp share reproduc attempt us logger fail log train job fail lose progress expect behavior option handl except logger job automat die log paramet fail environ cuda gpu tesla avail true version packag numpi pytorch debug fals pytorch version pytorch lightn tqdm linux architectur bit processor python version smp thu jul pdt addit context",
        "Issue_preprocessed_content":"extern failur caus train job fail bug train track uri host databrick databrick updat lose brief period fail fail pytorch lightn mean entir train pipelin fail lose job limit handl option avail flexibl pytorch lightn user handl train job reproduc boringmodel reproduc us fail log train job fail lose expect behavior option handl except job die paramet fail environ cuda gpu tesla avail true version packag numpi fals tqdm linux architectur bit python version smp thu jul pdt context",
        "Issue_gpt_summary_original":"The user is encountering an issue with the MLflow logger where the log_param() function requires a 'run_id' argument, which is not consistent with the behavior of the mlflow API. The user has provided a code sample and the environment details.",
        "Issue_gpt_summary":"user encount issu logger log param function requir run argument consist behavior api user provid code sampl environ detail",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning\/issues\/6205",
        "Issue_title":"MLFlow Logger Makes a New Run When Resuming from hpc Checkpoint",
        "Issue_created_time":1614282696000,
        "Issue_closed_time":null,
        "Issue_body":"## \ud83d\udc1b Bug\r\n\r\nCurrently the `MLFlowLogger` creates a new run when resuming from an hpc checkpoint, e.g., after preemption by slurm and requeuing. Runs are an MLFlow concept that groups things in their UI, so when resuming after requeue, it should really be reusing the run ID. I think this can be patched into the hpc checkpoint using the logger which I believe exposes the run ID. This can also be seen on the `v_num` on the progress bar which changes after preemption (in general that `v_num` probably shouldnt be changing in this case). I'm happy to attempt to PR this if the owners agree that it's a bug.\r\n\r\n### To Reproduce\r\n\r\nUse `MLFlowLogger` on a slurm cluster and watch the mlflow UI when preemption happens, there will be a new run created.\r\n\r\n### Expected behavior\r\n\r\nRuns are grouped neatly on the MLFlow UI\r\n\r\n### Environment\r\n\r\n* CUDA:\r\n        - GPU:\r\n        - available:         False\r\n        - version:           10.2\r\n* Packages:\r\n        - numpy:             1.20.1\r\n        - pyTorch_debug:     False\r\n        - pyTorch_version:   1.7.1\r\n        - pytorch-lightning: 1.2.0\r\n        - tqdm:              4.57.0\r\n* System:\r\n        - OS:                Linux\r\n        - architecture:\r\n                - 64bit\r\n                - ELF\r\n        - processor:         x86_64\r\n        - python:            3.8.1\r\n        - version:           #1 SMP Thu Jan 21 16:15:07 EST 2021\r\n\n\ncc @awaelchli @ananthsub @ninginthecloud @rohitgr7 @tchaton @akihironitta",
        "Issue_answer_count":7,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"logger make new run resum hpc checkpoint bug current logger creat new run resum hpc checkpoint preemption slurm requeu run concept group thing resum requeu reus run think patch hpc checkpoint logger believ expos run seen num progress bar chang preemption gener num probabl shouldnt chang case happi attempt owner agre bug reproduc us logger slurm cluster watch preemption happen new run creat expect behavior run group neatli environ cuda gpu avail fals version packag numpi pytorch debug fals pytorch version pytorch lightn tqdm linux architectur bit elf processor python version smp thu jan est awaelchli ananthsub ninginthecloud rohitgr tchaton akihironitta",
        "Issue_preprocessed_content":"make new run resum hpc checkpoint bug creat new run resum hpc checkpoint slurm requeu run concept group thing resum requeu reus run think patch hpc checkpoint believ expos run bar chang owner bug reproduc us slurm cluster watch new run creat expect behavior run group neatli environ cuda gpu avail fals version packag numpi fals tqdm linux architectur bit elf python version smp thu jan est",
        "Issue_gpt_summary_original":"The user is encountering a TypeError while trying to log a model into mlflow using mlflow.pytorch.log_model in a multi-GPU scenario. The error message indicates that the issue is related to pickling _thread.lock objects. The user has tried wrapping the code inside trainer.is_global_zero and trainer.global_rank == 0, as well as using the @rank_zero_only decorator, but none of these solutions have worked. The user's environment includes Ubuntu, torch, pytorch-lightning, torchvision, and mlflow.",
        "Issue_gpt_summary":"user encount typeerror try log model pytorch log model multi gpu scenario error messag indic issu relat pickl thread lock object user tri wrap code insid trainer global zero trainer global rank rank zero decor solut work user environ includ ubuntu torch pytorch lightn torchvis",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning\/issues\/5892",
        "Issue_title":"MlflowLogger fail when logging long parameters",
        "Issue_created_time":1612927107000,
        "Issue_closed_time":1613510526000,
        "Issue_body":"## \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n## Please reproduce using the BoringModel\r\n\r\n\r\n<!-- Please paste your BoringModel colab link here. -->\r\n\r\n### To Reproduce\r\n\r\nLog anything  parameters longer than 250 characters\r\n\r\n\r\n<!-- If you could not reproduce using the BoringModel and still think there's a bug, please post here -->\r\n\r\n### Expected behavior\r\n\r\n<!-- FILL IN -->\r\n\r\nMlflowLogger not sending parameters longer than 250 characters to mlflow and log warning to user\r\n\r\n### Environment\r\n\r\n\r\n - PyTorch Version (e.g., 1.0):\r\n - OS (e.g., Linux): \r\n - How you installed PyTorch (`conda`, `pip`, source): pip\r\n - Build command you used (if compiling from source):\r\n - Python version: 3.7\r\n - CUDA\/cuDNN version:\r\n - GPU models and configuration:\r\n - Any other relevant information:\r\n\r\n### Additional context\r\n\r\nMlflow only allow paramters to be at most 500 bytes (250 unicode characters), their limit in database is 250 characters:\r\nhttps:\/\/www.mlflow.org\/docs\/latest\/rest-api.html#log-param\r\nhttps:\/\/github.com\/mlflow\/mlflow\/issues\/1976\r\nhttps:\/\/github.com\/mlflow\/mlflow\/issues\/3931\r\n\r\n\r\n<!-- Add any other context about the problem here. -->\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"Dear @ducthienbui97,\n\nThanks for opening a PR.\n\nBest,\nT.C",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"logger fail log long paramet bug reproduc boringmodel reproduc log paramet longer charact expect behavior logger send paramet longer charact log warn user environ pytorch version linux instal pytorch conda pip sourc pip build command compil sourc python version cuda cudnn version gpu model configur relev inform addit context allow paramt byte unicod charact limit databas charact http www org doc latest rest api html log param http github com issu http github com issu",
        "Issue_preprocessed_content":"fail long paramet bug clear concis descript bug reproduc boringmodel past boringmodel colab link reproduc log paramet longer charact reproduc boringmodel think bug post expect behavior send paramet longer charact log warn user environ pytorch version pytorch pip build python version version gpu model configur relev inform context paramt byte limit databas charact context problem",
        "Issue_gpt_summary_original":"The MLFlow logger is causing latency and slowing down the training loop, even when logging metrics only per epoch. The issue seems to be caused by the logger communicating with the MLFlow server on each training step. The expected behavior is to avoid the logger from communicating with the server in each training loop. The solution involves modifying the codebase to avoid calling the MLFlow client on each step and storing the experiment within the logger.",
        "Issue_gpt_summary":"logger caus latenc slow train loop log metric epoch issu caus logger commun server train step expect behavior avoid logger commun server train loop solut involv modifi codebas avoid call client step store experi logger",
        "Issue_score_count":4
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning\/issues\/4411",
        "Issue_title":"Using log_gpu_memory with MLFLow logger causes an exception.",
        "Issue_created_time":1603900309000,
        "Issue_closed_time":1605009026000,
        "Issue_body":"## \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nUsing log_gpu_memory with MLFLow logger causes an error. It appears the name of the metric is not supported by MLFLow.\r\n\r\n    MlflowException: Invalid metric name: 'gpu_id: 0\/memory.used (MB)'. Names may only contain alphanumerics, underscores (_), dashes (-), periods (.), spaces ( ), and slashes (\/).\r\n\r\n### To Reproduce\r\nI reproduced the bug with the BoringModel, in the link bellow:\r\nhttps:\/\/colab.research.google.com\/drive\/1P8uhSfjvYhKPMyRZH-QmfbOUOfnePy6G?usp=sharing\r\n\r\n### Expected behavior\r\nlog_gpu_memory should log gpu memory correctly when using an MLFlow logger.\r\n\r\n### Environment\r\nColab environment:\r\n\r\n* CUDA:\r\n\t- GPU:\r\n\t\t- Tesla T4\r\n\t- available:         True\r\n\t- version:           10.1\r\n* Packages:\r\n\t- numpy:             1.18.5\r\n\t- pyTorch_debug:     False\r\n\t- pyTorch_version:   1.6.0+cu101\r\n\t- pytorch-lightning: 1.0.3\r\n\t- tqdm:              4.41.1\r\n* System:\r\n\t- OS:                Linux\r\n\t- architecture:\r\n\t\t- 64bit\r\n\t\t- \r\n\t- processor:         x86_64\r\n\t- python:            3.6.9\r\n\t- version:           #1 SMP Thu Jul 23 08:00:38 PDT 2020\r\n",
        "Issue_answer_count":7,
        "Issue_self_closed":0.0,
        "Answer_body":"This could be fixed removing the parenthesis from the string (as in the linked pr), but requires discussion if you guys want to change this for all loggers. would [MB] work? or should MLFlowLogger sanitize keys automatically by removing the unsupported characters? Seems like MLFlow only wants: \"[...] Names may only contain alphanumerics, underscores (_), dashes (-), periods (.), spaces ( ), and slashes (\/)\".\r\n\r\nMaybe make the GPU memory key different only if MLFlow is being used? Sanitizing mlflow metrics with a warning might also be an option.  I see sanitization directly in the MLFlowLogger as a better long term solution. We already do sanitization for other loggers (for hyperparameters). \r\n I changed the PR to remove parenthesis in the mlflow logger, however i don't know if it makes sense to give a warning, since the metric name for log_gpu_memory is not defined by the user. Should the removing of parenthesis be silent? Maybe do a PR on mlflow github too to support these or do sanitization process :joy: ",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"log gpu memori logger caus except bug log gpu memori logger caus error appear metric support except invalid metric gpu memori name contain alphanumer underscor dash period space slash reproduc reproduc bug boringmodel link bellow http colab research googl com drive puhsfjvyhkpmyrzh qmfbouofnepyg usp share expect behavior log gpu memori log gpu memori correctli logger environ colab environ cuda gpu tesla avail true version packag numpi pytorch debug fals pytorch version pytorch lightn tqdm linux architectur bit processor python version smp thu jul pdt",
        "Issue_preprocessed_content":"caus except bug clear concis descript bug caus metric except invalid metric name contain alphanumer underscor dash period space slash reproduc reproduc bug boringmodel link expect behavior log gpu memori environ colab environ cuda gpu tesla avail true version packag numpi fals tqdm linux architectur bit python version smp thu jul pdt",
        "Issue_gpt_summary_original":"The user is facing an issue where the training loss is not displayed in mlflow until the end of the training run, while the validation loss is updated each epoch. The user suspects that this may be a mlflow issue rather than a pytorch-lightning issue. The user has tried logging with on_epoch=True, which works fine, but the default train logging is delayed.",
        "Issue_gpt_summary":"user face issu train loss displai end train run valid loss updat epoch user suspect issu pytorch lightn issu user tri log epoch true work fine default train log delai",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning\/issues\/3964",
        "Issue_title":"mlflow logger complains about missing run_id",
        "Issue_created_time":1602116192000,
        "Issue_closed_time":1602141183000,
        "Issue_body":"## \ud83d\udc1b Bug\r\nWhen using MLflow logger, log_param() function require `run_id`\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-23-d048545e1854> in <module>\r\n      9 trainer.fit(model=experiment, \r\n     10            train_dataloader=train_dl,\r\n---> 11            val_dataloaders=test_dl)\r\n\r\n~\/anaconda3\/envs\/ns_dl_2020_torch\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/trainer.py in fit(self, model, train_dataloader, val_dataloaders, datamodule)\r\n    452         self.call_hook('on_fit_start')\r\n    453 \r\n--> 454         results = self.accelerator_backend.train()\r\n    455         self.accelerator_backend.teardown()\r\n    456 \r\n\r\n~\/anaconda3\/envs\/ns_dl_2020_torch\/lib\/python3.7\/site-packages\/pytorch_lightning\/accelerators\/gpu_backend.py in train(self)\r\n     51 \r\n     52         # train or test\r\n---> 53         results = self.train_or_test()\r\n     54         return results\r\n     55 \r\n\r\n~\/anaconda3\/envs\/ns_dl_2020_torch\/lib\/python3.7\/site-packages\/pytorch_lightning\/accelerators\/base_accelerator.py in train_or_test(self)\r\n     48             results = self.trainer.run_test()\r\n     49         else:\r\n---> 50             results = self.trainer.train()\r\n     51         return results\r\n     52 \r\n\r\n~\/anaconda3\/envs\/ns_dl_2020_torch\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/trainer.py in train(self)\r\n    499 \r\n    500                 # run train epoch\r\n--> 501                 self.train_loop.run_training_epoch()\r\n    502 \r\n    503                 if self.max_steps and self.max_steps <= self.global_step:\r\n\r\n~\/anaconda3\/envs\/ns_dl_2020_torch\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/training_loop.py in run_training_epoch(self)\r\n    525             # TRAINING_STEP + TRAINING_STEP_END\r\n    526             # ------------------------------------\r\n--> 527             batch_output = self.run_training_batch(batch, batch_idx, dataloader_idx)\r\n    528 \r\n    529             # when returning -1 from train_step, we end epoch early\r\n\r\n~\/anaconda3\/envs\/ns_dl_2020_torch\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/training_loop.py in run_training_batch(self, batch, batch_idx, dataloader_idx)\r\n    660                     opt_idx,\r\n    661                     optimizer,\r\n--> 662                     self.trainer.hiddens\r\n    663                 )\r\n    664 \r\n\r\n~\/anaconda3\/envs\/ns_dl_2020_torch\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/training_loop.py in training_step_and_backward(self, split_batch, batch_idx, opt_idx, optimizer, hiddens)\r\n    739         \"\"\"\r\n    740         # lightning module hook\r\n--> 741         result = self.training_step(split_batch, batch_idx, opt_idx, hiddens)\r\n    742 \r\n    743         if result is None:\r\n\r\n~\/anaconda3\/envs\/ns_dl_2020_torch\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/training_loop.py in training_step(self, split_batch, batch_idx, opt_idx, hiddens)\r\n    300         with self.trainer.profiler.profile('model_forward'):\r\n    301             args = self.build_train_args(split_batch, batch_idx, opt_idx, hiddens)\r\n--> 302             training_step_output = self.trainer.accelerator_backend.training_step(args)\r\n    303             training_step_output = self.trainer.call_hook('training_step_end', training_step_output)\r\n    304 \r\n\r\n~\/anaconda3\/envs\/ns_dl_2020_torch\/lib\/python3.7\/site-packages\/pytorch_lightning\/accelerators\/gpu_backend.py in training_step(self, args)\r\n     59                 output = self.__training_step(args)\r\n     60         else:\r\n---> 61             output = self.__training_step(args)\r\n     62 \r\n     63         return output\r\n\r\n~\/anaconda3\/envs\/ns_dl_2020_torch\/lib\/python3.7\/site-packages\/pytorch_lightning\/accelerators\/gpu_backend.py in __training_step(self, args)\r\n     67         batch = self.to_device(batch)\r\n     68         args[0] = batch\r\n---> 69         output = self.trainer.model.training_step(*args)\r\n     70         return output\r\n     71 \r\n\r\n<ipython-input-21-31b6dc3ffd67> in training_step(self, batch, batch_idx, optimizer_idx)\r\n     28         for key, val in train_loss.items():\r\n     29             self.log(key, val.item())\r\n---> 30             self.logger.experiment.log_param(key=key, value=val.item())\r\n     31 \r\n     32         return train_loss\r\n\r\nTypeError: log_param() missing 1 required positional argument: 'run_id'\r\n```\r\n#### Expected behavior\r\nThe MlflowLogger should behave the same as the mlflow api where only key and value argment is needed for log_param() function\r\n\r\n#### Code sample\r\n```python\r\nmlf_logger = MLFlowLogger(\r\n    experiment_name='test',\r\n    tracking_uri=\"file:.\/ml-runs\"\r\n)\r\n\r\nCllass VAEexperiment(LightningModule):\r\n...\r\n    def training_step(self, batch, batch_idx, optimizer_idx = 0):\r\n        ....\r\n        for key, val in train_loss.items():\r\n            self.logger.experiment.log_param(key=key, value=val.item())\r\n       ....\r\n       return train_loss\r\n\r\ntrainer = Trainer(logger=mlf_logger,\r\n                  default_root_dir='..\/logs',\r\n                  early_stop_callback=False,\r\n                  gpus=1, \r\n                  auto_select_gpus=True,\r\n                  max_epochs=40)\r\n\r\ntrainer.fit(model=experiment, \r\n           train_dataloader=train_dl, \r\n           val_dataloaders=test_dl)\r\n```\r\n\r\n\r\n### Environment\r\n\r\npytorch-lightning==0.10.0\r\ntorch==1.6.0\r\ntorchsummary==1.5.1\r\ntorchvision==0.7.0\r\n\r\n\r\n",
        "Issue_answer_count":6,
        "Issue_self_closed":0.0,
        "Answer_body":"Hi! thanks for your contribution!, great first issue! Here, mlflow logger is actually an MlflowClient object. so you ll need to use the function calls specified in this doc - https:\/\/www.mlflow.org\/docs\/latest\/_modules\/mlflow\/tracking\/client.html . These functions needs run_id as first argument which can be accessed as self.logger.run_id @nazim1021 thx for clarification! @qianyu-berkeley feel free to reopen if needed... Thanks! Same problem here, working with @nazim1021 suggestion. What about adding it to the doc? > What about adding it to the doc?\r\n\r\ngood idea, mind send a PR? :]",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"logger complain miss run bug logger log param function requir run typeerror traceback recent trainer fit model experi train dataload train val dataload test anaconda env torch lib python site packag pytorch lightn trainer trainer fit self model train dataload val dataload datamodul self hook fit start result self acceler backend train self acceler backend teardown anaconda env torch lib python site packag pytorch lightn acceler gpu backend train self train test result self train test return result anaconda env torch lib python site packag pytorch lightn acceler base acceler train test self result self trainer run test result self trainer train return result anaconda env torch lib python site packag pytorch lightn trainer trainer train self run train epoch self train loop run train epoch self max step self max step batch output self run train batch batch batch idx dataload idx return train step end epoch earli anaconda env torch lib python site packag pytorch lightn trainer train loop run train batch self batch batch idx dataload idx opt idx optim self trainer hidden anaconda env torch lib python site packag pytorch lightn trainer train loop train step backward self split batch batch idx opt idx optim hidden lightn modul hook result self train step split batch batch idx opt idx hidden result anaconda env torch lib python site packag pytorch lightn trainer train loop train step self split batch batch idx opt idx hidden self trainer profil profil model forward arg self build train arg split batch batch idx opt idx hidden train step output self trainer acceler backend train step arg train step output self trainer hook train step end train step output anaconda env torch lib python site packag pytorch lightn acceler gpu backend train step self arg output self train step arg output self train step arg return output anaconda env torch lib python site packag pytorch lightn acceler gpu backend train step self arg batch self devic batch arg batch output self trainer model train step arg return output train step self batch batch idx optim idx kei val train loss item self log kei val item self logger experi log param kei kei valu val item return train loss typeerror log param miss requir posit argument run expect behavior logger behav api kei valu argment need log param function code sampl python mlf logger logger experi test track uri file run cllass vaeexperi lightningmodul def train step self batch batch idx optim idx kei val train loss item self logger experi log param kei kei valu val item return train loss trainer trainer logger mlf logger default root dir log earli stop callback fals gpu auto select gpu true max epoch trainer fit model experi train dataload train val dataload test environ pytorch lightn torch torchsummari torchvis",
        "Issue_preprocessed_content":"complain bug function requir expect behavior behav api kei valu argment function code sampl environ",
        "Issue_gpt_summary_original":"The user is encountering a bug with the MLFlowLogger in PyTorch Lightning, where calling `t.logger.experiment_id` throws a `JSONDecodeError` exception. The user has provided a code sample and environment details.",
        "Issue_gpt_summary":"user encount bug logger pytorch lightn call logger experi throw jsondecodeerror except user provid code sampl environ detail",
        "Issue_score_count":2
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning\/issues\/3444",
        "Issue_title":"TypeError: can't pickle _thread.lock objects - Error while logging model into mlflow in multi gpu scenario",
        "Issue_created_time":1599740214000,
        "Issue_closed_time":1605489870000,
        "Issue_body":"## \u2753 Questions and Help\r\n\r\n#### What is your question?\r\nTrying to log model into mlflow using `mlflow.pytorch.log_model` in train end. Getting the above error only in multi gpu scenario. \r\n\r\n#### Code\r\n\r\n\r\nmnist script file - \r\n\r\n```\r\nimport pytorch_lightning as pl\r\nimport torch\r\nfrom argparse import ArgumentParser\r\n#from mlflow.pytorch.pytorch_autolog import __MLflowPLCallback\r\nfrom pytorch_lightning.logging import MLFlowLogger\r\nfrom sklearn.metrics import accuracy_score\r\nfrom torch.nn import functional as F\r\nfrom torch.utils.data import DataLoader, random_split\r\nfrom torchvision import datasets, transforms\r\n\r\n\r\nclass LightningMNISTClassifier(pl.LightningModule):\r\n    def __init__(self):\r\n        \"\"\"\r\n        Initializes the network\r\n        \"\"\"\r\n        super(LightningMNISTClassifier, self).__init__()\r\n\r\n        # mnist images are (1, 28, 28) (channels, width, height)\r\n        self.layer_1 = torch.nn.Linear(28 * 28, 128)\r\n        self.layer_2 = torch.nn.Linear(128, 256)\r\n        self.layer_3 = torch.nn.Linear(256, 10)\r\n\r\n        # transforms for images\r\n        self.transform = transforms.Compose(\r\n            [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\r\n        )\r\n\r\n    @staticmethod\r\n    def add_model_specific_args(parent_parser):\r\n        parser = ArgumentParser(parents=[parent_parser], add_help=False)\r\n        parser.add_argument(\r\n            \"--batch-size\",\r\n            type=int,\r\n            default=64,\r\n            metavar=\"N\",\r\n            help=\"input batch size for training (default: 64)\",\r\n        )\r\n        parser.add_argument(\r\n            \"--num-workers\",\r\n            type=int,\r\n            default=0,\r\n            metavar=\"N\",\r\n            help=\"number of workers (default: 0)\",\r\n        )\r\n        parser.add_argument(\r\n            \"--lr\",\r\n            type=float,\r\n            default=1e-3,\r\n            metavar=\"LR\",\r\n            help=\"learning rate (default: 1e-3)\",\r\n        )\r\n        return parser\r\n\r\n    def forward(self, x):\r\n        \"\"\"\r\n        Forward Function\r\n        \"\"\"\r\n        batch_size, channels, width, height = x.size()\r\n\r\n        # (b, 1, 28, 28) -> (b, 1*28*28)\r\n        x = x.view(batch_size, -1)\r\n\r\n        # layer 1 (b, 1*28*28) -> (b, 128)\r\n        x = self.layer_1(x)\r\n        x = torch.relu(x)\r\n\r\n        # layer 2 (b, 128) -> (b, 256)\r\n        x = self.layer_2(x)\r\n        x = torch.relu(x)\r\n\r\n        # layer 3 (b, 256) -> (b, 10)\r\n        x = self.layer_3(x)\r\n\r\n        # probability distribution over labels\r\n        x = torch.log_softmax(x, dim=1)\r\n\r\n        return x\r\n\r\n    def cross_entropy_loss(self, logits, labels):\r\n        \"\"\"\r\n        Loss Fn to compute loss\r\n        \"\"\"\r\n        return F.nll_loss(logits, labels)\r\n\r\n    def training_step(self, train_batch, batch_idx):\r\n        \"\"\"\r\n        training the data as batches and returns training loss on each batch\r\n        \"\"\"\r\n        x, y = train_batch\r\n        logits = self.forward(x)\r\n        loss = self.cross_entropy_loss(logits, y)\r\n        return {\"loss\": loss}\r\n\r\n    def validation_step(self, val_batch, batch_idx):\r\n        \"\"\"\r\n        Performs validation of data in batches\r\n        \"\"\"\r\n        x, y = val_batch\r\n        logits = self.forward(x)\r\n        loss = self.cross_entropy_loss(logits, y)\r\n        return {\"val_loss\": loss}\r\n\r\n    def validation_epoch_end(self, outputs):\r\n        \"\"\"\r\n        Computes average validation accuracy\r\n        \"\"\"\r\n        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\r\n        tensorboard_logs = {\"val_loss\": avg_loss}\r\n        return {\"avg_val_loss\": avg_loss, \"log\": tensorboard_logs}\r\n\r\n    def test_step(self, test_batch, batch_idx):\r\n        \"\"\"\r\n        Performs test and computes test accuracy\r\n        \"\"\"\r\n        x, y = test_batch\r\n        output = self.forward(x)\r\n        a, y_hat = torch.max(output, dim=1)\r\n        test_acc = accuracy_score(y_hat.cpu(), y.cpu())\r\n        return {\"test_acc\": torch.tensor(test_acc)}\r\n\r\n    def test_epoch_end(self, outputs):\r\n        \"\"\"\r\n        Computes average test accuracy score\r\n        \"\"\"\r\n        avg_test_acc = torch.stack([x[\"test_acc\"] for x in outputs]).mean()\r\n        return {\"avg_test_acc\": avg_test_acc}\r\n\r\n    def prepare_data(self):\r\n        \"\"\"\r\n        Preprocess the input data.\r\n        \"\"\"\r\n        return {}\r\n\r\n    def train_dataloader(self):\r\n        \"\"\"\r\n        Loading training data as batches\r\n        \"\"\"\r\n        mnist_train = datasets.MNIST(\r\n            \"dataset\", download=True, train=True, transform=self.transform\r\n        )\r\n        return DataLoader(\r\n            mnist_train,\r\n            batch_size=64,\r\n            num_workers=1\r\n        )\r\n\r\n    def val_dataloader(self):\r\n        \"\"\"\r\n        Loading validation data as batches\r\n        \"\"\"\r\n        mnist_train = datasets.MNIST(\r\n            \"dataset\", download=True, train=True, transform=self.transform\r\n        )\r\n        mnist_train, mnist_val = random_split(mnist_train, [55000, 5000])\r\n\r\n        return DataLoader(\r\n            mnist_val,\r\n            batch_size=64,\r\n            num_workers=1\r\n        )\r\n\r\n    def test_dataloader(self):\r\n        \"\"\"\r\n        Loading test data as batches\r\n        \"\"\"\r\n        mnist_test = datasets.MNIST(\r\n            \"dataset\", download=True, train=False, transform=self.transform\r\n        )\r\n        return DataLoader(\r\n            mnist_test,\r\n            batch_size=64,\r\n            num_workers=1\r\n        )\r\n\r\n    def configure_optimizers(self):\r\n        \"\"\"\r\n        Creates and returns Optimizer\r\n        \"\"\"\r\n        self.optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\r\n        self.scheduler = {\r\n            \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau(\r\n                self.optimizer,\r\n                mode=\"min\",\r\n                factor=0.2,\r\n                patience=2,\r\n                min_lr=1e-6,\r\n                verbose=True,\r\n            )\r\n        }\r\n        return [self.optimizer], [self.scheduler]\r\n\r\n    def optimizer_step(\r\n        self,\r\n        epoch,\r\n        batch_idx,\r\n        optimizer,\r\n        optimizer_idx,\r\n        second_order_closure=None,\r\n        on_tpu=False,\r\n        using_lbfgs=False,\r\n        using_native_amp=False,\r\n    ):\r\n        self.optimizer.step()\r\n        self.optimizer.zero_grad()\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    from pytorch_autolog import autolog\r\n    autolog()\r\n    model = LightningMNISTClassifier()\r\n    mlflow_logger = MLFlowLogger(\r\n        experiment_name=\"Default\", tracking_uri=\"http:\/\/localhost:5000\/\"\r\n    )\r\n    trainer = pl.Trainer(\r\n        logger=mlflow_logger,\r\n        gpus=2,\r\n        distributed_backend=\"ddp\",\r\n        max_epochs=1\r\n    )\r\n    trainer.fit(model)\r\n    trainer.test()\r\n\r\n```\r\n\r\nSample code from autolog - Callback class. \r\n\r\n```\r\n    class __MLflowPLCallback(pl.Callback):\r\n\r\n        def __init__(self):\r\n            super().__init__()\r\n\r\n        def on_train_end(self, trainer, pl_module):\r\n            \"\"\"\r\n            Logs the model checkpoint into mlflow - models folder on the training end\r\n            \"\"\"\r\n\r\n            mlflow.set_tracking_uri(trainer.logger._tracking_uri )\r\n            mlflow.set_experiment(trainer.logger._experiment_name)\r\n            mlflow.start_run(trainer.logger.run_id)\r\n            mlflow.pytorch.log_model(trainer.model, \"models\")\r\n            mlflow.end_run()\r\n\r\n\r\n```\r\n\r\n\r\n\r\n\r\nStack Trace\r\n\r\n```\r\nTraceback (most recent call last):                                                                                                                                                                          \r\n  File \"mnist.py\", line 231, in <module>\r\n    trainer.fit(model)\r\n  File \"\/home\/ubuntu\/mnist\/pytorch_autolog.py\", line 218, in fit\r\n    return _run_and_log_function(self, original, args, kwargs)\r\n  File \"\/home\/ubuntu\/mnist\/pytorch_autolog.py\", line 209, in _run_and_log_function\r\n    result = original(self, *args, **kwargs)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 992, in fit\r\n    results = self.spawn_ddp_children(model)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/distrib_data_parallel.py\", line 462, in spawn_ddp_children\r\n    results = self.ddp_train(local_rank, q=None, model=model, is_master=True)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/distrib_data_parallel.py\", line 560, in ddp_train\r\n    results = self.run_pretrain_routine(model)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 1213, in run_pretrain_routine\r\n    self.train()\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/training_loop.py\", line 392, in train\r\n    self.run_training_teardown()\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/training_loop.py\", line 872, in run_training_teardown\r\n    self.on_train_end()\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/callback_hook.py\", line 72, in on_train_end\r\n    callback.on_train_end(self, self.get_model())\r\n  File \"\/home\/ubuntu\/mnist\/pytorch_autolog.py\", line 120, in on_train_end\r\n    mlflow.pytorch.log_model(trainer.model, \"models\")\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/site-packages\/mlflow\/pytorch\/__init__.py\", line 179, in log_model\r\n    signature=signature, input_example=input_example, **kwargs)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/site-packages\/mlflow\/models\/model.py\", line 154, in log\r\n    **kwargs)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/site-packages\/mlflow\/pytorch\/__init__.py\", line 300, in save_model\r\n    torch.save(pytorch_model, model_path, pickle_module=pickle_module, **kwargs)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/site-packages\/torch\/serialization.py\", line 370, in save\r\n    _legacy_save(obj, opened_file, pickle_module, pickle_protocol)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/site-packages\/torch\/serialization.py\", line 443, in _legacy_save\r\n    pickler.dump(obj)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/site-packages\/cloudpickle\/cloudpickle.py\", line 491, in dump\r\n    return Pickler.dump(self, obj)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 437, in dump\r\n    self.save(obj)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 549, in save\r\n    self.save_reduce(obj=obj, *rv)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 662, in save_reduce\r\n    save(state)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 504, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 859, in save_dict\r\n    self._batch_setitems(obj.items())\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 885, in _batch_setitems\r\n    save(v)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 549, in save\r\n    self.save_reduce(obj=obj, *rv)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 659, in save_reduce\r\n    self._batch_setitems(dictitems)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 890, in _batch_setitems\r\n    save(v)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 549, in save\r\n    self.save_reduce(obj=obj, *rv)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 662, in save_reduce\r\n    save(state)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 504, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 859, in save_dict\r\n    self._batch_setitems(obj.items())\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 885, in _batch_setitems\r\n    save(v)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 549, in save\r\n    self.save_reduce(obj=obj, *rv)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 662, in save_reduce\r\n    save(state)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 504, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 859, in save_dict\r\n    self._batch_setitems(obj.items())\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 885, in _batch_setitems\r\n    save(v)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 504, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 819, in save_list\r\n    self._batch_appends(obj)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 846, in _batch_appends\r\n    save(tmp[0])\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 549, in save\r\n    self.save_reduce(obj=obj, *rv)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 662, in save_reduce\r\n    save(state)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 504, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 859, in save_dict\r\n    self._batch_setitems(obj.items())\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 885, in _batch_setitems\r\n    save(v)\r\n  File \"\/home\/ubuntu\/anaconda3\/lib\/python3.7\/pickle.py\", line 524, in save\r\n    rv = reduce(self.proto)\r\nTypeError: can't pickle _thread.lock objects\r\n\r\n\r\n```\r\n\r\n\r\n\r\n#### What have you tried?\r\nTried out the possibilities mentioned in the similar thread - https:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/issues\/2186\r\n\r\nTried  wrapping the code inside, `trainer.is_global_zero`  . And also tried `trainer.global_rank == 0`. Also tried decorating the method as `@rank_zero_only`. But no luck. Getting the same error. \r\n\r\n#### What's your environment?\r\n\r\n - OS: Ubuntu\r\n - Packaging - torch, pytorch-lightning, torchvision, mlflow",
        "Issue_answer_count":15,
        "Issue_self_closed":0.0,
        "Answer_body":"Hi! thanks for your contribution!, great first issue! What happens if you don't use the scheduler? Please try commenting out the scheduler definition and return only the optimizer. > What happens if you don't use the scheduler? Please try commenting out the scheduler definition and return only the optimizer.\r\n\r\nThanks for the reply. Sure i will try and update here. > What happens if you don't use the scheduler? Please try commenting out the scheduler definition and return only the optimizer.\r\n\r\nI removed the scheduler part and re-ran the script. Still experiencing the same error.  @lucadiliello @williamFalcon Any suggestions here ? One more observation from my end. In multi gpu scenario when i save the model using `torch.save(trainer.model, PATH)` i get the above mentioned error . However, when i try to save the save dict `torch.save(trainer.model.state_dict(), PATH)` the state dict is successfully getting saved. \r\n\r\nTested with 2 gpus and 0.9 version of pytorch lightning.  This issue has been automatically marked as stale because it hasn't had any recent activity. This issue will be closed in 7 days if no further activity occurs. Thank you for your contributions, Pytorch Lightning Team!\n I have the same error. Training with a single gpu works fine but with multiple the error is raised > I have the same error. Training with a single gpu works fine but with multiple the error is raised\r\n\r\nTraining with single GPU is fine because there is no need to create multiple processes, so you model is not pickled. What happens if you simply load your model in a shell and try to pickle it?\r\nSomething like:\r\n```python\r\n>>> model = MyModel(...)\r\n>>>\r\n>>> import pickle\r\n>>> pickle.dump(model, \"tmp_file.pk\")\r\n```\r\n\r\nIn my little experience, most of the pickle errors are caused by lambda functions or non-global functions. See [here](https:\/\/docs.python.org\/3\/library\/pickle.html#what-can-be-pickled-and-unpickled) the list of what can be pickled. > One more observation from my end. In multi gpu scenario when i save the model using `torch.save(trainer.model, PATH)` i get the above mentioned error . However, when i try to save the save dict `torch.save(trainer.model.state_dict(), PATH)` the state dict is successfully getting saved.\r\n> \r\n> Tested with 2 gpus and 0.9 version of pytorch lightning.\r\n\r\nPlease update to the latest version and let us know whether the error persist. > > I have the same error. Training with a single gpu works fine but with multiple the error is raised\r\n> \r\n> Training with single GPU is fine because there is no need to create multiple processes, so you model is not pickled. What happens if you simply load your model in a shell and try to pickle it?\r\n> Something like:\r\n> \r\n> ```python\r\n> >>> model = MyModel(...)\r\n> >>>\r\n> >>> import pickle\r\n> >>> pickle.dump(model, \"tmp_file.pk\")\r\n> ```\r\n> \r\n> In my little experience, most of the pickle errors are caused by lambda functions or non-global functions. See [here](https:\/\/docs.python.org\/3\/library\/pickle.html#what-can-be-pickled-and-unpickled) the list of what can be pickled.\r\n\r\nI tried adding as suggested:\r\n```\r\n>>> import pickle\r\n>>> pickle.dump(model, \"tmp_file.pk\")\r\n```\r\nHowever, this raise the error: TypeError: file must have a 'write' attribute\r\nI then tried with:\r\n```\r\n>>> import pickle\r\n>>> with open(\"tmp_file.pk\",\"wb\") as f:\r\n>>>         pickle.dump(model, f)\r\n```\r\nThis then again raised TypeError: can't pickle _thread.lock objects\r\nI am on the latest version of pytorch lightning This suggests that the problem is in your model. Can you post it here?\n\nA complete log of the error would also be useful. Thanks I ran into this as well. I wrote a little function to iterate through the model.__dict__.items() and check which caused pickle errors. It looks like there's a model attribute pointing to the trainer, which has that _thread.lock on it. Maybe there's a step that's supposed to clean this up that's being missed somehow? My quick work-around was to `delattr(model, \"trainer\")` before pickling the model, but I haven't actually tried loading the model again, so I this could cause other problems. same problem same problem on 1.2.4, works fine with 1.1.0. any ideas what might be causing the difference between the versions?",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"typeerror pickl thread lock object error log model multi gpu scenario question help question try log model pytorch log model train end get error multi gpu scenario code mnist script file import pytorch lightn import torch argpars import argumentpars pytorch pytorch autolog import plcallback pytorch lightn log import logger sklearn metric import accuraci score torch import function torch util data import dataload random split torchvis import dataset transform class lightningmnistclassifi lightningmodul def init self initi network super lightningmnistclassifi self init mnist imag channel width height self layer torch linear self layer torch linear self layer torch linear transform imag self transform transform compos transform totensor transform normal staticmethod def add model specif arg parent parser parser argumentpars parent parent parser add help fals parser add argument batch size type int default metavar help input batch size train default parser add argument num worker type int default metavar help number worker default parser add argument type float default metavar help learn rate default return parser def forward self forward function batch size channel width height size view batch size layer self layer torch relu layer self layer torch relu layer self layer probabl distribut label torch log softmax dim return def cross entropi loss self logit label loss comput loss return nll loss logit label def train step self train batch batch idx train data batch return train loss batch train batch logit self forward loss self cross entropi loss logit return loss loss def valid step self val batch batch idx perform valid data batch val batch logit self forward loss self cross entropi loss logit return val loss loss def valid epoch end self output comput averag valid accuraci avg loss torch stack val loss output mean tensorboard log val loss avg loss return avg val loss avg loss log tensorboard log def test step self test batch batch idx perform test comput test accuraci test batch output self forward hat torch max output dim test acc accuraci score hat cpu cpu return test acc torch tensor test acc def test epoch end self output comput averag test accuraci score avg test acc torch stack test acc output mean return avg test acc avg test acc def prepar data self preprocess input data return def train dataload self load train data batch mnist train dataset mnist dataset download true train true transform self transform return dataload mnist train batch size num worker def val dataload self load valid data batch mnist train dataset mnist dataset download true train true transform self transform mnist train mnist val random split mnist train return dataload mnist val batch size num worker def test dataload self load test data batch mnist test dataset mnist dataset download true train fals transform self transform return dataload mnist test batch size num worker def configur optim self creat return optim self optim torch optim adam self paramet self schedul schedul torch optim schedul reducelronplateau self optim mode min factor patienc min verbos true return self optim self schedul def optim step self epoch batch idx optim optim idx second order closur tpu fals lbfg fals nativ amp fals self optim step self optim zero grad main pytorch autolog import autolog autolog model lightningmnistclassifi logger logger experi default track uri http localhost trainer trainer logger logger gpu distribut backend ddp max epoch trainer fit model trainer test sampl code autolog callback class class plcallback callback def init self super init def train end self trainer modul log model checkpoint model folder train end set track uri trainer logger track uri set experi trainer logger experi start run trainer logger run pytorch log model trainer model model end run stack trace traceback recent file mnist line trainer fit model file home ubuntu mnist pytorch autolog line fit return run log function self origin arg kwarg file home ubuntu mnist pytorch autolog line run log function result origin self arg kwarg file home ubuntu anaconda lib python site packag pytorch lightn trainer trainer line fit result self spawn ddp children model file home ubuntu anaconda lib python site packag pytorch lightn trainer distrib data parallel line spawn ddp children result self ddp train local rank model model master true file home ubuntu anaconda lib python site packag pytorch lightn trainer distrib data parallel line ddp train result self run pretrain routin model file home ubuntu anaconda lib python site packag pytorch lightn trainer trainer line run pretrain routin self train file home ubuntu anaconda lib python site packag pytorch lightn trainer train loop line train self run train teardown file home ubuntu anaconda lib python site packag pytorch lightn trainer train loop line run train teardown self train end file home ubuntu anaconda lib python site packag pytorch lightn trainer callback hook line train end callback train end self self model file home ubuntu mnist pytorch autolog line train end pytorch log model trainer model model file home ubuntu anaconda lib python site packag pytorch init line log model signatur signatur input exampl input exampl kwarg file home ubuntu anaconda lib python site packag model model line log kwarg file home ubuntu anaconda lib python site packag pytorch init line save model torch save pytorch model model path pickl modul pickl modul kwarg file home ubuntu anaconda lib python site packag torch serial line save legaci save obj open file pickl modul pickl protocol file home ubuntu anaconda lib python site packag torch serial line legaci save pickler dump obj file home ubuntu anaconda lib python site packag cloudpickl cloudpickl line dump return pickler dump self obj file home ubuntu anaconda lib python pickl line dump self save obj file home ubuntu anaconda lib python pickl line save self save reduc obj obj file home ubuntu anaconda lib python pickl line save reduc save state file home ubuntu anaconda lib python pickl line save self obj unbound method explicit self file home ubuntu anaconda lib python pickl line save dict self batch setitem obj item file home ubuntu anaconda lib python pickl line batch setitem save file home ubuntu anaconda lib python pickl line save self save reduc obj obj file home ubuntu anaconda lib python pickl line save reduc self batch setitem dictitem file home ubuntu anaconda lib python pickl line batch setitem save file home ubuntu anaconda lib python pickl line save self save reduc obj obj file home ubuntu anaconda lib python pickl line save reduc save state file home ubuntu anaconda lib python pickl line save self obj unbound method explicit self file home ubuntu anaconda lib python pickl line save dict self batch setitem obj item file home ubuntu anaconda lib python pickl line batch setitem save file home ubuntu anaconda lib python pickl line save self save reduc obj obj file home ubuntu anaconda lib python pickl line save reduc save state file home ubuntu anaconda lib python pickl line save self obj unbound method explicit self file home ubuntu anaconda lib python pickl line save dict self batch setitem obj item file home ubuntu anaconda lib python pickl line batch setitem save file home ubuntu anaconda lib python pickl line save self obj unbound method explicit self file home ubuntu anaconda lib python pickl line save list self batch append obj file home ubuntu anaconda lib python pickl line batch append save tmp file home ubuntu anaconda lib python pickl line save self save reduc obj obj file home ubuntu anaconda lib python pickl line save reduc save state file home ubuntu anaconda lib python pickl line save self obj unbound method explicit self file home ubuntu anaconda lib python pickl line save dict self batch setitem obj item file home ubuntu anaconda lib python pickl line batch setitem save file home ubuntu anaconda lib python pickl line save reduc self proto typeerror pickl thread lock object tri tri possibl mention similar thread http github com pytorchlightn pytorch lightn issu tri wrap code insid trainer global zero tri trainer global rank tri decor method rank zero luck get error environ ubuntu packag torch pytorch lightn torchvis",
        "Issue_preprocessed_content":"pickl object model multi gpu scenario question help question try log model train end multi gpu scenario code mnist script file sampl code autolog stack trace tri tri mention similar thread tri code insid tri tri decor method luck environ ubuntu packag torch torchvis",
        "Issue_gpt_summary_original":"The user is using mlflow instead of tensorboard as a logger and is facing an issue where the checkpoints are being saved in the wrong location. The checkpoints should be in the `\\mlflow` folder, but they are being saved in the `\\1\\\\{guid}\\checkpoints` folder. The user is unsure if this is an mlflow or pytorch-lightning issue and is using pytorch-lightning 0.8.5 on macos running in python 3.7.6.",
        "Issue_gpt_summary":"user instead tensorboard logger face issu checkpoint save wrong locat checkpoint folder save guid checkpoint folder user unsur pytorch lightn issu pytorch lightn maco run python",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning\/issues\/3393",
        "Issue_title":"MLFlow Logger slows training steps dramatically, despite only setting metrics to be logged on epoch",
        "Issue_created_time":1599546516000,
        "Issue_closed_time":1599644307000,
        "Issue_body":"## \ud83d\udc1b Bug\r\n\r\nWhen using the MLFlow logger, with a remote server, logging per step introduces latency which slows the training loop.\r\nI have tried to configure logging of metrics only per epoch, however it seems this still results in much slower performance. I suspect the logger is still communicating with the MLFlow server on each training step.\r\n\r\n### To Reproduce\r\n1. Start an MLFlow server locally\r\n```\r\nmlflow ui\r\n```\r\n2. Run the minimal code example below as is, (with MLFlow logger set to use the default file uri.)\r\n3. Uncomment out the `tracking_uri` to use the local MLFlow server and run the code again. You will see a 2-3 times drop in the iterations per second.\r\n\r\n#### Code sample\r\n```\r\nimport torch\r\nfrom torch.utils.data import TensorDataset, DataLoader\r\nimport pytorch_lightning as pl\r\n\r\nclass MyModel(pl.LightningModule):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.num_examples = 5000\r\n        self.num_valid = 1000\r\n        self.batch_size = 64\r\n        self.lr = 1e-3\r\n        self.wd = 1e-2\r\n        self.num_features = 2\r\n        self.linear = torch.nn.Linear(self.num_features, 1)\r\n        self.loss_func = torch.nn.MSELoss()\r\n        self.X = torch.rand(self.num_examples, self.num_features)\r\n        self.y = self.X.matmul(torch.rand(self.num_features, 1)) + torch.rand(self.num_examples)\r\n        \r\n    def forward(self, x):\r\n        return self.linear(x)\r\n\r\n    def train_dataloader(self): \r\n        ds = TensorDataset(self.X[:-self.num_valid], self.X[:-self.num_valid])\r\n        dl = DataLoader(ds, batch_size=self.batch_size)\r\n        return dl\r\n\r\n    def val_dataloader(self): \r\n        ds = TensorDataset(self.X[-self.num_valid:], self.X[-self.num_valid:])\r\n        dl = DataLoader(ds, batch_size=self.batch_size)\r\n        return dl\r\n\r\n    def configure_optimizers(self):\r\n        return torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.wd)\r\n\r\n    def training_step(self, batch, batch_idx):\r\n        x, y = batch\r\n        yhat = self(x)\r\n        loss = self.loss_func(yhat, y)\r\n        result = pl.TrainResult(minimize=loss)\r\n        result.log('train_loss', loss, on_epoch=True, on_step=False)\r\n        return result\r\n\r\n    def validation_step(self, batch, batch_idx):\r\n        x, y = batch\r\n        yhat = self(x)\r\n        loss = self.loss_func(yhat, y)\r\n        result = pl.EvalResult(early_stop_on=loss)\r\n        result.log('val_loss', loss, on_epoch=True, on_step=False)\r\n        return result\r\n\r\nif __name__ == '__main__':\r\n    from pytorch_lightning.loggers import TensorBoardLogger, MLFlowLogger\r\n    mlf_logger = MLFlowLogger(\r\n        experiment_name=f\"MyModel\",\r\n        # tracking_uri=\"http:\/\/localhost:5000\"\r\n    )\r\n    trainer = pl.Trainer(\r\n        min_epochs=5,\r\n        max_epochs=50,\r\n        early_stop_callback=True,\r\n        logger=mlf_logger\r\n    )\r\n    model = MyModel()\r\n    trainer.fit(model)\r\n```\r\n\r\n### Expected behavior\r\n\r\nWhen using the TrainResult and EvalResult, or manually handling metric logging using the `training_epoch_end` and `validation_epoch_end` callbacks. It should be possible to avoid the MLFlow logger from communicating with the server in each training loop. \r\nThis would make it feasible to implement the MLFlow when a remote server is used for experiment tracking.\r\n\r\n### Environment\r\n```\r\n* CUDA:\r\n\t- GPU:\r\n\t- available:         False\r\n\t- version:           None\r\n* Packages:\r\n\t- numpy:             1.18.2\r\n\t- pyTorch_debug:     False\r\n\t- pyTorch_version:   1.6.0+cpu\r\n\t- pytorch-lightning: 0.9.0\r\n\t- tensorboard:       2.2.0\r\n\t- tqdm:              4.48.2\r\n* System:\r\n\t- OS:                Linux\r\n\t- architecture:\r\n\t\t- 64bit\r\n\t\t-\r\n\t- processor:         x86_64\r\n\t- python:            3.7.9\r\n\t- version:           #1 SMP Tue May 26 11:42:35 UTC 2020\r\n```\r\n### Additional context\r\n\r\nWe host a MLFlow instance in AWS and would like to be able to track experiments without affecting the training speed. \r\nIt appears that in general the MLFlow logger is much less performant than the default Tensorboard Logger, but this would not be much of a problem if we could avoid calls to the logger during the training loop.\r\n\r\n### Solution\r\nI've done a bit of debugging in the codebase and have been able to isolate the cause in two places\r\nhttps:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/blob\/d438ad8a8db3e76d3ed4e3c6bc9b91d6b3266b8e\/pytorch_lightning\/loggers\/mlflow.py#L125-L129\r\nHere `self.experiment` is called regardless of whether `self._run_id` exists. If we add an `if not self._run_id` here we avoid calling `self._mlflow_client.get_experiment_by_name(self._experiment_name)` on each step.\r\nHowever we still call it each time we log metrics to MFlow, because of the property `self.experiment`.\r\n\r\nhttps:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/blob\/d438ad8a8db3e76d3ed4e3c6bc9b91d6b3266b8e\/pytorch_lightning\/loggers\/mlflow.py#L100-L112\r\nHere if we store `expt` within the logger and only call `self._mlflow_client.get_experiment_by_name` when it does not exist, we eliminate all overhead, it runs as fast as fast as the tensorboard logger and all the mlflow logging appears to be working as expected.\r\n\r\nI'd be happy to raise a PR for this fix.",
        "Issue_answer_count":6,
        "Issue_self_closed":0.0,
        "Answer_body":"Hi! thanks for your contribution!, great first issue! have you tried to just increase the row_log_interval, its a trainer flag that controls how often logs are sent to the logger.\r\nI mean, your network is a single linear layer, you probably run through epochs super fast.\r\nI am not yet convinced it is a bug, but I'll try your example code hey @awaelchli, Thanks for replying!\r\nThe model above is a contrived example, upon further testing I have realised that the performance difference between MFLow logger and the Tensorboard logger is not inherent to the MLFlow client.\r\n\r\nI've done some debugging and added a solution section to the issue. It appears to be in in the `experiment` property of the MLFlowLogger. Each time `.experiment` is accessed, `self._mlflow_client.get_experiment_by_name(self._experiment_name)` is called, which communicates with the MLFlow server.\r\n\r\nIt seems we can store the response of this method thereby needing to call it only once, and this seems to resolve the dramatic difference between the Tensorboard and MLFlow Logger. oh ok, that makes sense. Would you like to send a PR with your suggestion and see if the tests pass? Happy to review it.  yeah sure, I'll link it here shortly. Did you encounter this #3392 problem as well?",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"logger slow train step dramat despit set metric log epoch bug logger remot server log step introduc latenc slow train loop tri configur log metric epoch result slower perform suspect logger commun server train step reproduc start server local run minim code exampl logger set us default file uri uncom track uri us local server run code time drop iter second code sampl import torch torch util data import tensordataset dataload import pytorch lightn class mymodel lightningmodul def init self super init self num exampl self num valid self batch size self self self num featur self linear torch linear self num featur self loss func torch mseloss self torch rand self num exampl self num featur self self matmul torch rand self num featur torch rand self num exampl def forward self return self linear def train dataload self tensordataset self self num valid self self num valid dataload batch size self batch size return def val dataload self tensordataset self self num valid self self num valid dataload batch size self batch size return def configur optim self return torch optim adam self paramet self weight decai self def train step self batch batch idx batch yhat self loss self loss func yhat result trainresult minim loss result log train loss loss epoch true step fals return result def valid step self batch batch idx batch yhat self loss self loss func yhat result evalresult earli stop loss result log val loss loss epoch true step fals return result main pytorch lightn logger import tensorboardlogg logger mlf logger logger experi mymodel track uri http localhost trainer trainer min epoch max epoch earli stop callback true logger mlf logger model mymodel trainer fit model expect behavior trainresult evalresult manual handl metric log train epoch end valid epoch end callback possibl avoid logger commun server train loop feasibl implement remot server experi track environ cuda gpu avail fals version packag numpi pytorch debug fals pytorch version cpu pytorch lightn tensorboard tqdm linux architectur bit processor python version smp tue utc addit context host instanc aw like abl track experi affect train speed appear gener logger perform default tensorboard logger problem avoid call logger train loop solut bit debug codebas abl isol caus place http github com pytorchlightn pytorch lightn blob dadadbededecbcbdbb pytorch lightn logger self experi call regardless self run exist add self run avoid call self client experi self experi step time log metric mflow properti self experi http github com pytorchlightn pytorch lightn blob dadadbededecbcbdbb pytorch lightn logger store expt logger self client experi exist elimin overhead run fast fast tensorboard logger log appear work expect happi rais fix",
        "Issue_preprocessed_content":"slow train step despit metric epoch bug remot server step introduc latenc slow train tri configur metric epoch result slower perform suspect server train step reproduc start server run minim code exampl us local server run code time drop iter second code sampl expect behavior trainresult evalresult handl metric avoid server train feasibl implement remot server experi track environ context host instanc aw like abl track experi train gener perform default tensorboard problem avoid train solut bit codebas abl isol caus place exist avoid step time log metric mflow properti store exist elimin overhead run fast fast tensorboard work expect rais fix",
        "Issue_gpt_summary_original":"The user is facing an issue when using Hydra and MLFlow together, where the parameters passed to the LightningModule is a `DictConfig`, causing the condition in the `logger\/base.py` to not be met. This results in an error message when trying to log hyperparameters with MLFlow. The expected behavior is to check whether the instance is `dict` or `DictConfig` in the given line.",
        "Issue_gpt_summary":"user face issu hydra paramet pass lightningmodul dictconfig caus condit logger base met result error messag try log hyperparamet expect behavior check instanc dict dictconfig given line",
        "Issue_score_count":1
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning\/issues\/3392",
        "Issue_title":"mlflow training loss not reported until end of run",
        "Issue_created_time":1599521969000,
        "Issue_closed_time":1599634019000,
        "Issue_body":"I think I'm logging correctly, this is my `training_step`\r\n\r\n        result = pl.TrainResult(loss)\r\n        result.log('loss\/train', loss)\r\n        return result\r\n\r\nand `validation_step`\r\n\r\n        result = pl.EvalResult(loss)\r\n        result.log('loss\/validation', loss)\r\n        return result\r\n\r\nThe validation loss is updated in mlflow each epoch, however the training loss isn't displayed until training has finished. Then it's available for every step. This may be a mlflow rather than pytorch-lighting issue - somewhere along the line it seems to be buffered?\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/5028974\/92420471-d5b56c00-f1b6-11ea-9296-db075c3dcf87.png)\r\n\r\nVersions:\r\n\r\npytorch-lightning==0.9.0\r\nmlflow==1.11.0\r\n\r\nEdit: logging TrainResult with on_epoch=True results in the metric appearing in mlflow during training, it's only the default train logging which gets delayed. i.e.\r\n\r\n        result.log('accuracy\/train', acc, on_epoch=True)\r\n\r\nis fine\r\n\r\n",
        "Issue_answer_count":8,
        "Issue_self_closed":1.0,
        "Answer_body":"When using the minimal example provided in the linked issue, and using the default training logging shown above, I don't see the behaviour described. \r\nI can sometimes see a discrepancy between the reported steps for each metrics, but I suspect this is to do with MLFlow and not the PL logger.\r\n![newplot](https:\/\/user-images.githubusercontent.com\/17157991\/92454951-7120fe00-f204-11ea-99f3-7d2ac09b0f5e.png)\r\n\r\n@david-waterworth could you elaborate on a few points?\r\n1. When you set up the MLFLowLogger, if your `tracking_uri` over `http:` or using `file:`?\r\n2. If `http`, is the tracking server remote?\r\n3. How long does a model training run typically take? \r\n4. does this behaviour consistently happen even when refreshing the MLFlow page?\r\n @patrickorlando \r\n\r\nWhen you set up the MLFLowLogger, if your tracking_uri over http: or using file:?\r\n\r\nI'm using file i.e. `mlflow = loggers.MLFlowLogger(\"Transformer\")`\r\n\r\nHow long does a model training run typically take?\r\n\r\n10-20 minutes\r\n\r\ndoes this behavior consistently happen even when refreshing the MLFlow page?\r\n\r\nYes I've tried to reproduce this but cant seem to. I can confirm that the MLFlow logger is logging metrics at the end of each epoch and for me they show up in the MLFlow UI as I refresh the page. \r\nDo you have a working code sample that can reproduce the issue?\r\n So I can actually see the behaviour you've described, but not when using the minimal example in #3393. I'll try to work out why. So I _think_ this is because of the default behaviour of the `TrainResult` and the way `row_log_interval` works. And it only appears if the number of batches per epoch is less than `row_log_interval`\r\n\r\nBy default TrainResult logs on step and not on epoch.\r\nhttps:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/blob\/aaf26d70c4658e961192ba4c408558f1cf39bb18\/pytorch_lightning\/core\/step_result.py#L510-L517\r\n\r\nWhen logging only per step, the logger connector only logs when the `batch_idx` is a multiple of `row_log_interval`. However if you don't have more than `row_log_interval` batches, the metrics are not logged.\r\nhttps:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/blob\/aaf26d70c4658e961192ba4c408558f1cf39bb18\/pytorch_lightning\/trainer\/logger_connector.py#L229-L237\r\n\r\n@david-waterworth Do you have less than 50 batches per epoch in your model? can you try setting `row_log_interval` to be less than the number of train batches to confirm whether the issue is caused by this?\r\n\r\n @patrickorlando yes I have 38 batches per epoch. I set `row_log_interval=1` and now the training step metrics are being displayed as they're generated. > yes I have 38 batches per epoch. I set row_log_interval=1 and now the training step metrics are being displayed as they're generated.\r\n\r\nThat makes sense now :) \r\n@david-waterworth Should we close this? or is there something left unresolved? Thanks for the assistance, no nothing unresolved.",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"train loss report end run think log correctli train step result trainresult loss result log loss train loss return result valid step result evalresult loss result log loss valid loss return result valid loss updat epoch train loss isn displai train finish avail step pytorch light issu line buffer imag http user imag githubusercont com dbc dbcdcf png version pytorch lightn edit log trainresult epoch true result metric appear train default train log get delai result log accuraci train acc epoch true fine",
        "Issue_preprocessed_content":"train report end run think result return result result return result valid updat epoch train isn displai train finish avail step line version edit trainresult result metric train default train get delai fine",
        "Issue_gpt_summary_original":"Trainer.fit fails with a pickle error when the logger is MLFlowLogger, and distributed_backend='ddp' on GPUs but without SLURM. The error occurs because multiprocessing is attempting to pickle the nested function in MLflow function [_get_rest_store]. The expected behavior is that Trainer.fit runs without error.",
        "Issue_gpt_summary":"trainer fit fail pickl error logger logger distribut backend ddp gpu slurm error occur multiprocess attempt pickl nest function function rest store expect behavior trainer fit run error",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning\/issues\/3046",
        "Issue_title":"MLFlowLogger throws a JSONDecodeError",
        "Issue_created_time":1597814570000,
        "Issue_closed_time":1597848054000,
        "Issue_body":"<!-- \r\n### Common bugs:\r\n1. Tensorboard not showing in Jupyter-notebook see [issue 79](https:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/issues\/79).    \r\n2. PyTorch 1.1.0 vs 1.2.0 support [see FAQ](https:\/\/github.com\/PyTorchLightning\/pytorch-lightning#faq)    \r\n-->\r\n\r\n## \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n### To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n#### Code sample\r\n<!-- Ideally attach a minimal code sample to reproduce the decried issue. \r\nMinimal means having the shortest code but still preserving the bug. -->\r\n\r\n```python\r\nfrom pytorch_lightning import Trainer\r\nfrom pytorch_lightning.loggers import MLFlowLogger\r\nmlflow_logger = MLFlowLogger(experiment_name=\"test-experiment\", tracking_uri=\"URI_HERE\")\r\nt = Trainer(logger=mlflow_logger)\r\nt.logger.experiment_id\r\n```\r\nthrows a `JSONDecodeError` exception.\r\n```python\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"\/envs\/pl_env\/lib\/python3.7\/site-packages\/pytorch_lightning\/loggers\/mlflow.py\", line 120, in experiment_id\r\n    _ = self.experiment\r\n  File \"\/envs\/pl_env\/lib\/python3.7\/site-packages\/pytorch_lightning\/loggers\/base.py\", line 421, in experiment\r\n    return get_experiment() or DummyExperiment()\r\n  File \"\/envs\/pl_env\/lib\/python3.7\/site-packages\/pytorch_lightning\/utilities\/distributed.py\", line 13, in wrapped_fn\r\n    return fn(*args, **kwargs)\r\n  File \"\/envs\/pl_env\/lib\/python3.7\/site-packages\/pytorch_lightning\/loggers\/base.py\", line 420, in get_experiment\r\n    return fn(self)\r\n  File \"\/envs\/pl_env\/lib\/python3.7\/site-packages\/pytorch_lightning\/loggers\/mlflow.py\", line 98, in experiment\r\n    expt = self._mlflow_client.get_experiment_by_name(self._experiment_name)\r\n  File \"\/envs\/pl_env\/lib\/python3.7\/site-packages\/mlflow\/tracking\/client.py\", line 154, in get_experiment_by_name\r\n    return self._tracking_client.get_experiment_by_name(name)\r\n  File \"\/envs\/pl_env\/lib\/python3.7\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py\", line 114, in get_experiment_by_name\r\n    return self.store.get_experiment_by_name(name)\r\n  File \"\/envs\/pl_env\/lib\/python3.7\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 219, in get_experiment_by_name\r\n    response_proto = self._call_endpoint(GetExperimentByName, req_body)\r\n  File \"\/envs\/pl_env\/lib\/python3.7\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 32, in _call_endpoint\r\n    return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)\r\n  File \"\/envs\/pl_env\/lib\/python3.7\/site-packages\/mlflow\/utils\/rest_utils.py\", line 145, in call_endpoint\r\n    js_dict = json.loads(response.text)\r\n  File \"\/envs\/pl_env\/lib\/python3.7\/json\/__init__.py\", line 348, in loads\r\n    return _default_decoder.decode(s)\r\n  File \"\/envs\/pl_env\/lib\/python3.7\/json\/decoder.py\", line 337, in decode\r\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\r\n  File \"\/envs\/pl_env\/lib\/python3.7\/json\/decoder.py\", line 355, in raw_decode\r\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\r\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\r\n```\r\n### Expected behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n### Environment\r\nEnvironment details\r\n```\r\n\r\n - PyTorch Version (e.g., 1.0): 1.6.0\r\n - PyTorch Lightning Version: 0.9.0rc12\r\n - OS (e.g., Linux): Linux\r\n - How you installed PyTorch (`conda`, `pip`, source): conda\r\n - Build command you used (if compiling from source):\r\n - Python version: 3.7.7\r\n - CUDA\/cuDNN version: Not relevant\r\n - GPU models and configuration: Not relevant\r\n - Any other relevant information: Not relevant\r\n\r\n### Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n",
        "Issue_answer_count":3,
        "Issue_self_closed":1.0,
        "Answer_body":"Hi! thanks for your contribution!, great first issue! Hi, thanks for submitting the bug. I don't know what's going on here. I cannot reproduce with your instructions. \r\n\r\nI'm running your sample code \r\n\r\n```python \r\n    mlflow_logger = MLFlowLogger(experiment_name=\"test-experiment\", tracking_uri=\"http:\/\/127.0.0.1:5000\")\r\n    trainer = Trainer(logger=mlflow_logger)\r\n    trainer.logger.experiment_id\r\n```\r\nand the tracking uri I got from running \r\n```bash\r\nmlflow ui\r\n```\r\nThe experiment shows up in the UI and I get no errors. I verified this with the latest version of PL and mlflow, python 3.7.\r\n\r\nIs there any other information you can provide on the issue? Thanks for the quick response, @awaelchli! \r\n\r\nI did nothing different this morning and I am able to log metrics\/parameters to mlflow. I will close this now and in case I encounter this again, I will reopen this issue.",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"logger throw jsondecodeerror bug reproduc step reproduc behavior code sampl python pytorch lightn import trainer pytorch lightn logger import logger logger logger experi test experi track uri uri trainer logger logger logger experi throw jsondecodeerror except python traceback recent file line file env env lib python site packag pytorch lightn logger line experi self experi file env env lib python site packag pytorch lightn logger base line experi return experi dummyexperi file env env lib python site packag pytorch lightn util distribut line wrap return arg kwarg file env env lib python site packag pytorch lightn logger base line experi return self file env env lib python site packag pytorch lightn logger line experi expt self client experi self experi file env env lib python site packag track client line experi return self track client experi file env env lib python site packag track track servic client line experi return self store experi file env env lib python site packag store track rest store line experi respons proto self endpoint getexperimentbynam req bodi file env env lib python site packag store track rest store line endpoint return endpoint self host cred endpoint method json bodi respons proto file env env lib python site packag util rest util line endpoint dict json load respons text file env env lib python json init line load return default decod decod file env env lib python json decod line decod obj end self raw decod idx end file env env lib python json decod line raw decod rais jsondecodeerror expect valu err valu json decod jsondecodeerror expect valu line column char expect behavior environ environ detail pytorch version pytorch lightn version linux linux instal pytorch conda pip sourc conda build command compil sourc python version cuda cudnn version relev gpu model configur relev relev inform relev addit context",
        "Issue_preprocessed_content":"throw bug clear concis descript bug reproduc step reproduc behavior code sampl minim code sampl reproduc decri minim mean have shortest code preserv bug throw except expect behavior clear concis descript expect environ environ detail pytorch version pytorch lightn version linux pytorch conda build python version version relev gpu model configur relev relev inform relev context context problem",
        "Issue_gpt_summary_original":"The user encountered an error while deploying the MLflow UI, specifically an AttributeError related to a missing attribute called 'mlModelFilterPattern'. The user needs to review the configuration parameter being used.",
        "Issue_gpt_summary":"user encount error deploi specif attributeerror relat miss attribut call mlmodelfilterpattern user need review configur paramet",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning\/issues\/2939",
        "Issue_title":"mlflow checkpoints in the wrong location ",
        "Issue_created_time":1597273128000,
        "Issue_closed_time":1597488847000,
        "Issue_body":"I'm not sure if I'm doing something wrong, I'm using mlflow instead of tensorboard as a logger. I've used the defaults i.e.\r\n\r\n```\r\nmlflow = loggers.MLFlowLogger()\r\ntrainer = pl.Trainer.from_argparse_args(args, logger=mlflow)\r\n```\r\n\r\nI'm ending up with the following folder structure\r\n\r\n\\mlflow\r\n\\mlflow\\1\r\n\\mlflow\\1\\\\{guid}\\artifacts\r\n\\mlflow\\1\\\\{guid}\\metrics\r\n\\mlflow\\1\\\\{guid}\\params\r\n\\mlflow\\1\\\\{guid}\\meta.yaml\r\n**\\1\\\\{guid}\\checkpoints**\r\n\r\ni.e. the checkpoints are in the wrong location, they should be in the `\\mlflow` folder. \r\n\r\nPerhaps this is an mlflow rather than pytorch-lightning issue? \r\n\r\nI'm using pytorch-lightning 0.8.5 on macos running in python 3.7.6\r\n",
        "Issue_answer_count":3,
        "Issue_self_closed":0.0,
        "Answer_body":"@david-waterworth mind try the latest 0.9rc12? It was fixed here: #2502 \r\nThe checkpoints subfolder will go here: `mlflow\\1{guid}\\checkpoints`, is that what you want @david-waterworth ?\r\n Thanks @awaelchli  yes that's what I want - thanks!",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"checkpoint wrong locat sure wrong instead tensorboard logger default logger logger trainer trainer argpars arg arg logger end follow folder structur guid artifact guid metric guid param guid meta yaml guid checkpoint checkpoint wrong locat folder pytorch lightn issu pytorch lightn maco run python",
        "Issue_preprocessed_content":"checkpoint wrong locat sure wrong instead tensorboard default end folder structur checkpoint wrong locat folder maco python",
        "Issue_gpt_summary_original":"The user encountered an error when deploying an MLflow registry model to Triton using the mlflow-triton-plugin with the --flavor=onnx flag. The plugin is trying to create a config.pbtxt in the destination folder before creating the model folder itself. The error can be fixed by creating the folder beforehand, but it could also be handled from the plugin side. The error message indicates that the config.pbtxt file is not found in the destination folder.",
        "Issue_gpt_summary":"user encount error deploi registri model triton triton plugin flavor onnx flag plugin try creat config pbtxt destin folder creat model folder error fix creat folder handl plugin error messag indic config pbtxt file destin folder",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning\/issues\/2058",
        "Issue_title":"Hydra MLFlow Clash",
        "Issue_created_time":1591172197000,
        "Issue_closed_time":1592925645000,
        "Issue_body":"<!-- \r\n### Common bugs:\r\n1. Tensorboard not showing in Jupyter-notebook see [issue 79](https:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/issues\/79).    \r\n2. PyTorch 1.1.0 vs 1.2.0 support [see FAQ](https:\/\/github.com\/PyTorchLightning\/pytorch-lightning#faq)    \r\n-->\r\n\r\n## \ud83d\udc1b Bug\r\n\r\nWhen using the MLFlow logger with Hydra, because the parameters passed to the LightningModule is a `DictConfig`, the condition in the `logger\/base.py` is not met.\r\n\r\nhttps:\/\/github.com\/PyTorchLightning\/pytorch-lightning\/blob\/8211256c46430e43e0c27e4f078c72085bb4ea34\/pytorch_lightning\/loggers\/base.py#L177\r\n\r\n### To Reproduce\r\n\r\nUse Hydra and MLFlow together. \r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n```python\r\nTraceback (most recent call last):\r\n  File \"\/home\/siavash\/KroniKare\/kwae2\/kwae_ma\/models\/pl_train_segmentation_model.py\", line 115, in <module>\r\n    main()\r\n  File \"\/home\/siavash\/anaconda3\/envs\/kwae-ma\/lib\/python3.7\/site-packages\/hydra\/main.py\", line 24, in decorated_main\r\n    strict=strict,\r\n  File \"\/home\/siavash\/anaconda3\/envs\/kwae-ma\/lib\/python3.7\/site-packages\/hydra\/_internal\/utils.py\", line 174, in run_hydra\r\n    overrides=args.overrides,\r\n  File \"\/home\/siavash\/anaconda3\/envs\/kwae-ma\/lib\/python3.7\/site-packages\/hydra\/_internal\/hydra.py\", line 86, in run\r\n    job_subdir_key=None,\r\n  File \"\/home\/siavash\/anaconda3\/envs\/kwae-ma\/lib\/python3.7\/site-packages\/hydra\/plugins\/common\/utils.py\", line 109, in run_job\r\n    ret.return_value = task_function(task_cfg)\r\n  File \"\/home\/siavash\/KroniKare\/kwae2\/kwae_ma\/models\/pl_train_segmentation_model.py\", line 111, in main\r\n    trainer.fit(wound_seg_pl)\r\n  File \"\/home\/siavash\/anaconda3\/envs\/kwae-ma\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 765, in fit\r\n    self.single_gpu_train(model)\r\n  File \"\/home\/siavash\/anaconda3\/envs\/kwae-ma\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/distrib_parts.py\", line 492, in single_gpu_train\r\n    self.run_pretrain_routine(model)\r\n  File \"\/home\/siavash\/anaconda3\/envs\/kwae-ma\/lib\/python3.7\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 843, in run_pretrain_routine\r\n    self.logger.log_hyperparams(ref_model.hparams)\r\n  File \"\/home\/siavash\/anaconda3\/envs\/kwae-ma\/lib\/python3.7\/site-packages\/pytorch_lightning\/loggers\/base.py\", line 275, in log_hyperparams\r\n    [logger.log_hyperparams(params) for logger in self._logger_iterable]\r\n  File \"\/home\/siavash\/anaconda3\/envs\/kwae-ma\/lib\/python3.7\/site-packages\/pytorch_lightning\/loggers\/base.py\", line 275, in <listcomp>\r\n    [logger.log_hyperparams(params) for logger in self._logger_iterable]\r\n  File \"\/home\/siavash\/anaconda3\/envs\/kwae-ma\/lib\/python3.7\/site-packages\/pytorch_lightning\/utilities\/distributed.py\", line 10, in wrapped_fn\r\n    return fn(*args, **kwargs)\r\n  File \"\/home\/siavash\/anaconda3\/envs\/kwae-ma\/lib\/python3.7\/site-packages\/pytorch_lightning\/loggers\/mlflow.py\", line 105, in log_hyperparams\r\n    self.experiment.log_param(self.run_id, k, v)\r\n  File \"\/home\/siavash\/anaconda3\/envs\/kwae-ma\/lib\/python3.7\/site-packages\/mlflow\/tracking\/client.py\", line 206, in log_param\r\n    self._tracking_client.log_param(run_id, key, value)\r\n  File \"\/home\/siavash\/anaconda3\/envs\/kwae-ma\/lib\/python3.7\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py\", line 177, in log_param\r\n    _validate_param_name(key)\r\n  File \"\/home\/siavash\/anaconda3\/envs\/kwae-ma\/lib\/python3.7\/site-packages\/mlflow\/utils\/validation.py\", line 120, in _validate_param_name\r\n    INVALID_PARAMETER_VALUE)\r\nmlflow.exceptions.MlflowException: Invalid parameter name: ''. Names may be treated as files in certain cases, and must not resolve to other names when treated as such. This name would resolve to '.'\r\n```\r\n\r\n### Expected behavior\r\n\r\nCheck whether the instance if `dict` or `DictConfig` in the given line. \r\n",
        "Issue_answer_count":2,
        "Issue_self_closed":0.0,
        "Answer_body":"Hi! thanks for your contribution!, great first issue! > Check whether the instance if `dict` or `DictConfig` in the given line.\r\n\r\n@ssakhavi that sounds reasonable solution, mind sending a PR - fix and its test?",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"hydra clash bug logger hydra paramet pass lightningmodul dictconfig condit logger base met http github com pytorchlightn pytorch lightn blob ceecefcbbea pytorch lightn logger base reproduc us hydra python traceback recent file home siavash kronikar kwae kwae model train segment model line main file home siavash anaconda env kwae lib python site packag hydra main line decor main strict strict file home siavash anaconda env kwae lib python site packag hydra intern util line run hydra overrid arg overrid file home siavash anaconda env kwae lib python site packag hydra intern hydra line run job subdir kei file home siavash anaconda env kwae lib python site packag hydra plugin common util line run job ret return valu task function task cfg file home siavash kronikar kwae kwae model train segment model line main trainer fit wound seg file home siavash anaconda env kwae lib python site packag pytorch lightn trainer trainer line fit self singl gpu train model file home siavash anaconda env kwae lib python site packag pytorch lightn trainer distrib part line singl gpu train self run pretrain routin model file home siavash anaconda env kwae lib python site packag pytorch lightn trainer trainer line run pretrain routin self logger log hyperparam ref model hparam file home siavash anaconda env kwae lib python site packag pytorch lightn logger base line log hyperparam logger log hyperparam param logger self logger iter file home siavash anaconda env kwae lib python site packag pytorch lightn logger base line logger log hyperparam param logger self logger iter file home siavash anaconda env kwae lib python site packag pytorch lightn util distribut line wrap return arg kwarg file home siavash anaconda env kwae lib python site packag pytorch lightn logger line log hyperparam self experi log param self run file home siavash anaconda env kwae lib python site packag track client line log param self track client log param run kei valu file home siavash anaconda env kwae lib python site packag track track servic client line log param valid param kei file home siavash anaconda env kwae lib python site packag util valid line valid param invalid paramet valu except except invalid paramet name treat file certain case resolv name treat resolv expect behavior check instanc dict dictconfig given line",
        "Issue_preprocessed_content":"hydra clash bug hydra paramet lightningmodul condit met reproduc us hydra code sampl stack trace provid expect behavior check instanc given line",
        "Issue_gpt_summary_original":"The user encountered an issue while using the `publish_model_to_mlflow.py` script, where if the value given for the `--model_directory` argument has a trailing `\/`, the script will fail with an error. The error message indicates that the file already exists, and the model being used has no effect on the error. The expected behavior is to remove the trailing `\/` in the input provided.",
        "Issue_gpt_summary":"user encount issu publish model script valu given model directori argument trail script fail error error messag indic file exist model effect error expect behavior remov trail input provid",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning\/issues\/630",
        "Issue_title":"Pickle error from Trainer.fit when using MLFlowLogger and distributed data parallel without SLURM",
        "Issue_created_time":1576464430000,
        "Issue_closed_time":1583540837000,
        "Issue_body":"## \ud83d\udc1b Bug\r\n\r\nTrainer.fit fails with a pickle error when the logger is MLFlowLogger, and distributed_backend='ddp' on GPUs but without SLURM.\r\n\r\n### To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Instantiate MLFlowLogger in Pytorch 0.5.3.2 with Pytorch 1.3.1 and MLFlow 1.4.0. The execution environment has environment variables MLFLOW_TRACKING_URI, and also MLFLOW_TRACKING_USERNAME and MLFLOW_TRACKING_PASSWORD to connect to the MLflow tracking server with HTTP Basic Authentication. The MLflow tracking server is also v1.4.0.\r\n2. Instantiate Trainer with MLFlowLogger instance as logger, distributed_backend='ddp' and with the gpus parameter on a machine with NVIDIA GPUs but without SLURM.\r\n3. Run Trainer.fit\r\n\r\nFrom the error output, it looks like multiprocessing is attempting to pickle the nested function in MLflow function [_get_rest_store](https:\/\/github.com\/mlflow\/mlflow\/blob\/v1.4.0\/mlflow\/tracking\/_tracking_service\/utils.py#L81):\r\n```\r\nayla.khan@gpu12:~\/photosynthetic$ python test_mlflow.py\r\nTraceback (most recent call last):\r\n  File \"test_mlflow.py\", line 71, in <module>\r\n    trainer.fit(model)\r\n  File \"\/mnt\/unihome\/home\/CORP\/ayla.khan\/miniconda2\/envs\/photosynthetic\/lib\/python3.6\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 343, in fit\r\n    mp.spawn(self.ddp_train, nprocs=self.num_gpus, args=(model,))\r\n  File \"\/mnt\/unihome\/home\/CORP\/ayla.khan\/miniconda2\/envs\/photosynthetic\/lib\/python3.6\/site-packages\/torch\/multiprocessing\/spawn.py\", line 162, in spawn\r\n    process.start()\r\n  File \"\/mnt\/unihome\/home\/CORP\/ayla.khan\/miniconda2\/envs\/photosynthetic\/lib\/python3.6\/multiprocessing\/process.py\", line 105, in start\r\n    self._popen = self._Popen(self)\r\n  File \"\/mnt\/unihome\/home\/CORP\/ayla.khan\/miniconda2\/envs\/photosynthetic\/lib\/python3.6\/multiprocessing\/context.py\", line 284, in _Popen\r\n    return Popen(process_obj)\r\n  File \"\/mnt\/unihome\/home\/CORP\/ayla.khan\/miniconda2\/envs\/photosynthetic\/lib\/python3.6\/multiprocessing\/popen_spawn_posix.py\", line 32, in __init__\r\n    super().__init__(process_obj)\r\n  File \"\/mnt\/unihome\/home\/CORP\/ayla.khan\/miniconda2\/envs\/photosynthetic\/lib\/python3.6\/multiprocessing\/popen_fork.py\", line 19, in __init__\r\n    self._launch(process_obj)\r\n  File \"\/mnt\/unihome\/home\/CORP\/ayla.khan\/miniconda2\/envs\/photosynthetic\/lib\/python3.6\/multiprocessing\/popen_spawn_posix.py\", line 47, in _launch\r\n    reduction.dump(process_obj, fp)\r\n  File \"\/mnt\/unihome\/home\/CORP\/ayla.khan\/miniconda2\/envs\/photosynthetic\/lib\/python3.6\/multiprocessing\/reduction.py\", line 60, in dump\r\n    ForkingPickler(file, protocol).dump(obj)\r\nAttributeError: Can't pickle local object '_get_rest_store.<locals>.get_default_host_creds'\r\n```\r\n\r\n#### Code sample\r\nSample code tested with a very simple test model ([gist](https:\/\/gist.github.com\/a-y-khan\/8693d2b186227561a4baf4d03ce75c34)):\r\n\r\n```\r\ntest_hparams = Namespace()\r\nmodel = XORGateModel(test_hparams)\r\n\r\nlogger = MLFlowLogger(experiment_name='test_lightning_logger',\r\n                                          tracking_uri=os.environ['MLFLOW_TRACKING_URI'])\r\ntrainer = pl.Trainer(logger=logger, distributed_backend='ddp', gpus='-1')\r\ntrainer.fit(model)\r\n```\r\n\r\n### Expected behavior\r\n\r\nTrainer.fit runs without error.\r\n\r\n### Environment\r\n\r\n```\r\n(photosynthetic) ayla.khan@gpu12:~\/photosynthetic$ python collect_env.py\r\nCollecting environment information...\r\nPyTorch version: 1.3.1\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.1.243\r\n\r\nOS: CentOS Linux 7 (Core)\r\nGCC version: (GCC) 4.8.5 20150623 (Red Hat 4.8.5-39)\r\nCMake version: Could not collect\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: 10.0.130\r\nGPU models and configuration:\r\nGPU 0: GeForce GTX 1080 Ti\r\nGPU 1: GeForce GTX 1080 Ti\r\nGPU 2: GeForce GTX 1080 Ti\r\nGPU 3: GeForce GTX 1080 Ti\r\nGPU 4: GeForce GTX 1080 Ti\r\nGPU 5: GeForce GTX 1080 Ti\r\nGPU 6: GeForce GTX 1080 Ti\r\nGPU 7: GeForce GTX 1080 Ti\r\n\r\nNvidia driver version: 440.33.01\r\ncuDNN version: \/usr\/local\/cuda-10.0\/lib64\/libcudnn.so.7\r\n\r\nVersions of relevant libraries:\r\n[pip] numpy==1.16.4\r\n[pip] pytorch-lightning==0.5.3.2\r\n[pip] pytorch-toolbelt==0.2.1\r\n[pip] torch==1.3.1\r\n[pip] torchsummary==1.5.1\r\n[pip] torchvision==0.4.2\r\n[conda] blas                      1.0                         mkl\r\n[conda] mkl                       2019.4                      243\r\n[conda] mkl-service               2.3.0            py36he904b0f_0\r\n[conda] mkl_fft                   1.0.15           py36ha843d7b_0\r\n[conda] mkl_random                1.1.0            py36hd6b4f25_0\r\n[conda] pytorch                   1.3.1           py3.6_cuda10.1.243_cudnn7.6.3_0    pytorch\r\n[conda] pytorch-lightning         0.5.3.2                  pypi_0    pypi\r\n[conda] pytorch-toolbelt          0.2.1                    pypi_0    pypi\r\n[conda] torchsummary              1.5.1                    pypi_0    pypi\r\n[conda] torchvision               0.4.2                py36_cu101    pytorch\r\n```",
        "Issue_answer_count":9,
        "Issue_self_closed":0.0,
        "Answer_body":"Will investigate. We have a test that is supposed to prevent these problems from sneaking back in, but apparently it's not doing it's job. I imagine everyone is busy with the build failures - but for the record, I am  having a similar problem. Essentially, I cannot get a logger to work using ddp. It's gving me one of those days when I wonder why I ever wanted to write software ;)\r\n\r\nThis is Ubuntu 18.04.2LTS, on a 14 core, 7 gpu machine. Python 3.6.8, pytorch 1.3.1, pytorch-lightning 0.5.3.2, Tensorboard 2.1.0. Everything else standard except pillow isis 6.2.2 due to known bug in 7.0.\r\n\r\nI am working with a tried and true model and hyperparameters. The model and logging work fine as cpu, gpu, or dp - and ddp if I don't log. But not ddp with logging. I am not using SLURM.\r\n\r\nI have tried to get around this several ways: passing a custom logger, not using the logger created by Trainer(), etc. They either fail when called from one of the new processes, with an attribute error in Tensorboard TTDummyFileWriter.get_logdir(), or they fail with a pickle error about thread.locks when being copied to a new process\r\n\r\nI will detail these in a bug report if you think they are NOT due to the recent build issues.\r\n\r\nBut thought you'd want to know ...\r\n\r\ns\r\n @dbczumar,  @smurching? @neggert is this fixed now? Can this issue be re-opened? I'm currently working with Pytorch-Lightning==0.7.6 and am getting an identical pickle issue when using DDP with the MLFLowLogger.\r\n\r\n**Reproducing**\r\n\r\nUsing the script the OP gave led to some other errors (mostly to do with lightning version differences), so a new gist to reproduce in Pytorch-Lightning 0.7.6 can be found [here](https:\/\/gist.github.com\/Polyphenolx\/39424e5673fc029567f7f3ae3551fffb).\r\n\r\nThis is easily reproducible in other projects as well.\r\n\r\n**Error Output**\r\n\r\n```\r\n\/home\/user\/anaconda3\/envs\/pytorch\/lib\/python3.6\/site-packages\/pytorch_lightning\/utilities\/distributed.py:23: DeprecationWarning: `logging` package has been renamed to `loggers` since v0.7.0 The deprecated package name will be removed in v0.9.0.\r\n  warnings.warn(*args, **kwargs)\r\n\/home\/user\/anaconda3\/envs\/pytorch\/lib\/python3.6\/site-packages\/pytorch_lightning\/utilities\/distributed.py:23: DeprecationWarning: `mlflow_logger` module has been renamed to `mlflow` since v0.6.0. The deprecated module name will be removed in v0.8.0.\r\n  warnings.warn(*args, **kwargs)\r\n\/home\/user\/anaconda3\/envs\/pytorch\/lib\/python3.6\/site-packages\/pytorch_lightning\/utilities\/distributed.py:23: DeprecationWarning: `data_loader` decorator deprecated in v0.7.0. Will be removed v0.9.0\r\n  warnings.warn(*args, **kwargs)\r\nGPU available: True, used: True\r\nNo environment variable for node rank defined. Set as 0.\r\nCUDA_VISIBLE_DEVICES: [0,1,2,3]\r\nTraceback (most recent call last):\r\n  File \"mlflow_test.py\", line 65, in <module>\r\n    trainer.fit(model)\r\n  File \"\/home\/user\/anaconda3\/envs\/pytorch\/lib\/python3.6\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 844, in fit\r\n    mp.spawn(self.ddp_train, nprocs=self.num_processes, args=(model,))\r\n  File \"\/home\/user\/anaconda3\/envs\/pytorch\/lib\/python3.6\/site-packages\/torch\/multiprocessing\/spawn.py\", line 200, in spawn\r\n    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\r\n  File \"\/home\/user\/anaconda3\/envs\/pytorch\/lib\/python3.6\/site-packages\/torch\/multiprocessing\/spawn.py\", line 149, in start_processes\r\n    process.start()\r\n  File \"\/home\/user\/anaconda3\/envs\/pytorch\/lib\/python3.6\/multiprocessing\/process.py\", line 105, in start\r\n    self._popen = self._Popen(self)\r\n  File \"\/home\/user\/anaconda3\/envs\/pytorch\/lib\/python3.6\/multiprocessing\/context.py\", line 284, in _Popen\r\n    return Popen(process_obj)\r\n  File \"\/home\/user\/anaconda3\/envs\/pytorch\/lib\/python3.6\/multiprocessing\/popen_spawn_posix.py\", line 32, in __init__\r\n    super().__init__(process_obj)\r\n  File \"\/home\/user\/anaconda3\/envs\/pytorch\/lib\/python3.6\/multiprocessing\/popen_fork.py\", line 19, in __init__\r\n    self._launch(process_obj)\r\n  File \"\/home\/user\/anaconda3\/envs\/pytorch\/lib\/python3.6\/multiprocessing\/popen_spawn_posix.py\", line 47, in _launch\r\n    reduction.dump(process_obj, fp)\r\n  File \"\/home\/user\/anaconda3\/envs\/pytorch\/lib\/python3.6\/multiprocessing\/reduction.py\", line 60, in dump\r\n    ForkingPickler(file, protocol).dump(obj)\r\nAttributeError: Can't pickle local object '_get_rest_store.<locals>.get_default_host_creds'\r\n```\r\n\r\n**Environment**\r\n```\r\n* CUDA:\r\n\t- GPU:\r\n\t\t- GeForce GTX 1080 Ti\r\n\t\t- GeForce GTX 1080 Ti\r\n\t\t- GeForce GTX 1080 Ti\r\n\t\t- GeForce GTX 1080 Ti\r\n\t- available:         True\r\n\t- version:           10.2\r\n* Packages:\r\n\t- numpy:             1.18.5\r\n\t- pyTorch_debug:     False\r\n\t- pyTorch_version:   1.5.0\r\n\t- pytorch-lightning: 0.7.6\r\n\t- tensorboard:       2.2.2\r\n\t- tqdm:              4.46.1\r\n* System:\r\n\t- OS:                Linux\r\n\t- architecture:\r\n\t\t- 64bit\r\n\t\t- \r\n\t- processor:         x86_64\r\n\t- python:            3.6.8\r\n\t- version:           #102-Ubuntu SMP Mon May 11 10:07:26 UTC 2020\r\n``` To add to this, it appears to be a greater issue with MLFLow and how their tracking utilities are coded. They use a higher order function that causes issues with pickling in torches DDP backend. I've created an issue on MLFLow git, and submitted a PR to remedy the problem. \r\n\r\nIn the interim, feel free to implement the fix described in the issue in the MLFlow git as a temporary fix until\/if they review\/merge mine Following up on this: The pickling fix was merged into the master branch of MLFlow a couple days ago (see the bug mention above). Training using DDP is now functional on MLFLow versions installed from master, but it may take them some time to release the fix to PyPi Running into this same issue as are a few others here:\r\nhttps:\/\/github.com\/minimaxir\/aitextgen\/issues\/135\r\n![image](https:\/\/user-images.githubusercontent.com\/4674698\/121708545-8923f780-ca8c-11eb-9483-56740fd6d401.png)\r\n Hi,\r\n I am still getting the below error:\r\n![image](https:\/\/user-images.githubusercontent.com\/57705684\/131129141-fa483cb4-cb95-43a1-b1d3-62bf78711de2.png)\r\n\r\nI am using DP strategy and PT version '1.8.1+cu111' and PL version '1.3.8'.",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"pickl error trainer fit logger distribut data parallel slurm bug trainer fit fail pickl error logger logger distribut backend ddp gpu slurm reproduc step reproduc behavior instanti logger pytorch pytorch execut environ environ variabl track uri track usernam track password connect track server http basic authent track server instanti trainer logger instanc logger distribut backend ddp gpu paramet machin nvidia gpu slurm run trainer fit error output look like multiprocess attempt pickl nest function function rest store http github com blob track track servic util ayla khan gpu photosynthet python test traceback recent file test line trainer fit model file mnt unihom home corp ayla khan miniconda env photosynthet lib python site packag pytorch lightn trainer trainer line fit spawn self ddp train nproc self num gpu arg model file mnt unihom home corp ayla khan miniconda env photosynthet lib python site packag torch multiprocess spawn line spawn process start file mnt unihom home corp ayla khan miniconda env photosynthet lib python multiprocess process line start self popen self popen self file mnt unihom home corp ayla khan miniconda env photosynthet lib python multiprocess context line popen return popen process obj file mnt unihom home corp ayla khan miniconda env photosynthet lib python multiprocess popen spawn posix line init super init process obj file mnt unihom home corp ayla khan miniconda env photosynthet lib python multiprocess popen fork line init self launch process obj file mnt unihom home corp ayla khan miniconda env photosynthet lib python multiprocess popen spawn posix line launch reduct dump process obj file mnt unihom home corp ayla khan miniconda env photosynthet lib python multiprocess reduct line dump forkingpickl file protocol dump obj attributeerror pickl local object rest store default host cred code sampl sampl code test simpl test model gist http gist github com khan dbabafdcec test hparam namespac model xorgatemodel test hparam logger logger experi test lightn logger track uri environ track uri trainer trainer logger logger distribut backend ddp gpu trainer fit model expect behavior trainer fit run error environ photosynthet ayla khan gpu photosynthet python collect env collect environ inform pytorch version debug build cuda build pytorch cento linux core gcc version gcc red hat cmake version collect python version cuda avail ye cuda runtim version gpu model configur gpu geforc gtx gpu geforc gtx gpu geforc gtx gpu geforc gtx gpu geforc gtx gpu geforc gtx gpu geforc gtx gpu geforc gtx nvidia driver version cudnn version usr local cuda lib libcudnn version relev librari pip numpi pip pytorch lightn pip pytorch toolbelt pip torch pip torchsummari pip torchvis conda bla mkl conda mkl conda mkl servic pyhebf conda mkl fft pyhadb conda mkl random pyhdbf conda pytorch cuda cudnn pytorch conda pytorch lightn pypi pypi conda pytorch toolbelt pypi pypi conda torchsummari pypi pypi conda torchvis pytorch",
        "Issue_preprocessed_content":"pickl distribut data slurm bug fail pickl gpu slurm reproduc step reproduc behavior instanti pytorch pytorch execut environ environ variabl track server basic authent track server instanti trainer instanc gpu paramet machin nvidia gpu slurm run output like pickl nest function function code sampl sampl code test simpl test model expect behavior run environ",
        "Issue_gpt_summary_original":"The user has encountered an issue with mlflow byom predictor where arbitrary URLs can be created without checking if an actual mlflow model is served at that URL. The user suggests implementing a check to ensure the validity of the URL before creating or linking the model.",
        "Issue_gpt_summary":"user encount issu byom predictor arbitrari url creat check actual model serv url user suggest implement check ensur valid url creat link model",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/open-metadata\/OpenMetadata\/issues\/7232",
        "Issue_title":"Mlflow UI deployment error",
        "Issue_created_time":1662389970000,
        "Issue_closed_time":1662467440000,
        "Issue_body":"```\r\nAttributeError: 'DatabaseServiceMetadataPipeline' object has no attribute 'mlModelFilterPattern'\r\n```\r\n\r\nWe need to review which configuration param is being sent here",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"sourceConfig type missing to be sent from the UI",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"deploy error attributeerror databaseservicemetadatapipelin object attribut mlmodelfilterpattern need review configur param sent",
        "Issue_preprocessed_content":"deploy review configur param sent",
        "Issue_gpt_summary_original":"The MLFlowLogging is always disabled for training FARMReader models, which prevents the logging of training statistics and metrics to MLFlow. The issue arises due to the initialization of an Inferencer that disables all logging to MLFlow. A workaround is to manually set MLFlowLogger.disable_logging to False before calling the train method.",
        "Issue_gpt_summary":"log disabl train farmread model prevent log train statist metric issu aris initi inferenc disabl log workaround manual set logger disabl log fals call train method",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/triton-inference-server\/server\/issues\/4130",
        "Issue_title":"error creating a triton deployment mlflow plugin",
        "Issue_created_time":1648621921000,
        "Issue_closed_time":1649449895000,
        "Issue_body":"**Description**\r\nError when a MLflow registry model is deployed to triton using **mlflow-triton-plugin** with `--falvor=onnx` flag.\r\nThe plugin is trying to create a `config.pbtxt` in the destination folder before creating that model folder itself.\r\nEasy fix is to create that folder beforehand, but could also be handled from the plugin side.\r\n\r\n```\r\n# create a dir if not exists  \r\nif not os.exists(triton_deployment_dir):\r\n  os.mkdir(triton_deployment_dir)\r\n# then write config to that dir\r\nwith open(os.path.join(triton_deployment_dir, \"config.pbtxt\"),\r\n            \"w\") as cfile:\r\n    cfile.write(config)\r\n```\r\n\r\n**Triton Information**\r\nDocker image: `nvcr.io\/nvidia\/tritonserver:21.12-py3`\r\n\r\n**To Reproduce**\r\n\r\n0. Install mlflow-triton-plugin\r\n1. Log and register an ONNX model to MLflow model registry.\r\n2. Run a triton inference server with these flags: `--model-control-mode=explicit --strict-model-config=false`\r\n3. Create a deployment from mlflow:\r\n `mlflow deployments create -t triton --flavor onnx --name <model-name> -m \"models:\/<model-name>\/1\"`\r\n\r\nError is raised:\r\n```\r\nFile \"mlflow_triton\/deployments.py\", line 105, in create_deployment\r\n  File \"mlflow_triton\/deployments.py\", line 332, in _copy_files_to_triton_repo\r\n  File \"mlflow_triton\/deployments.py\", line 326, in _get_copy_paths\r\nFileNotFoundError: [Errno 2] No such file or directory: '<dest-folder>\/<model-name>\/config.pbtxt'\r\n```\r\n",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"error creat triton deploy plugin descript error registri model deploi triton triton plugin falvor onnx flag plugin try creat config pbtxt destin folder creat model folder easi fix creat folder handl plugin creat dir exist exist triton deploy dir mkdir triton deploy dir write config dir open path join triton deploy dir config pbtxt cfile cfile write config triton inform docker imag nvcr nvidia tritonserv reproduc instal triton plugin log regist onnx model model registri run triton infer server flag model control mode explicit strict model config fals creat deploy deploy creat triton flavor onnx model error rais file triton deploy line creat deploy file triton deploy line copi file triton repo file triton deploy line copi path filenotfounderror errno file directori config pbtxt",
        "Issue_preprocessed_content":"creat triton deploy plugin descript registri model deploi triton flag plugin try creat destin folder creat model folder easi fix creat folder handl plugin triton inform docker imag reproduc log regist model model registri run triton infer server flag creat deploy rais",
        "Issue_gpt_summary_original":"The user is unable to load a pyfunc model in the beta version of BentoML 1.0, even though the model gets successfully stored in the local model store. The loading of the model is failing with an AttributeError. The user has provided the code used to train and log the model to mlflow and the code used to load the model into BentoML.",
        "Issue_gpt_summary":"user unabl load pyfunc model beta version bentoml model get successfulli store local model store load model fail attributeerror user provid code train log model code load model bentoml",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/triton-inference-server\/server\/issues\/4089",
        "Issue_title":"Input to the script for publishing models to mlflow is overly particular with inputs",
        "Issue_created_time":1647959057000,
        "Issue_closed_time":1650643135000,
        "Issue_body":"**Description**\r\nWhen using the `publish_model_to_mlflow.py` script, if the value given for the `--model_directory` argument has a trailing `\/`, the script will bomb in interesting ways.\r\n\r\n**Triton Information**\r\nWhat version of Triton are you using? 2.19.0\r\n\r\nAre you using the Triton container or did you build it yourself? container\r\n\r\n**To Reproduce**\r\n```\r\npython publish_model_to_mlflow.py \\\r\n    --model_name abp-nvsmi-xgb \\\r\n    --model_directory \/common\/models\/abp-nvsmi-xgb\/ \\\r\n    --flavor triton\r\n```\r\n\r\nThis gives the following error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"publish_model_to_mlflow.py\", line 71, in <module>\r\n    publish_to_mlflow()\r\n  File \"\/opt\/conda\/envs\/mlflow\/lib\/python3.8\/site-packages\/click\/core.py\", line 1128, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"\/opt\/conda\/envs\/mlflow\/lib\/python3.8\/site-packages\/click\/core.py\", line 1053, in main\r\n    rv = self.invoke(ctx)\r\n  File \"\/opt\/conda\/envs\/mlflow\/lib\/python3.8\/site-packages\/click\/core.py\", line 1395, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"\/opt\/conda\/envs\/mlflow\/lib\/python3.8\/site-packages\/click\/core.py\", line 754, in invoke\r\n    return __callback(*args, **kwargs)\r\n  File \"publish_model_to_mlflow.py\", line 56, in publish_to_mlflow\r\n    triton_flavor.log_model(\r\n  File \"\/mlflow\/triton-inference-server\/server\/deploy\/mlflow-triton-plugin\/scripts\/triton_flavor.py\", line 100, in log_model\r\n    Model.log(\r\n  File \"\/opt\/conda\/envs\/mlflow\/lib\/python3.8\/site-packages\/mlflow\/models\/model.py\", line 282, in log\r\n    flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)\r\n  File \"\/mlflow\/triton-inference-server\/server\/deploy\/mlflow-triton-plugin\/scripts\/triton_flavor.py\", line 73, in save_model\r\n    shutil.copytree(triton_model_path, model_data_path)\r\n  File \"\/opt\/conda\/envs\/mlflow\/lib\/python3.8\/shutil.py\", line 557, in copytree\r\n    return _copytree(entries=entries, src=src, dst=dst, symlinks=symlinks,\r\n  File \"\/opt\/conda\/envs\/mlflow\/lib\/python3.8\/shutil.py\", line 458, in _copytree\r\n    os.makedirs(dst, exist_ok=dirs_exist_ok)\r\n  File \"\/opt\/conda\/envs\/mlflow\/lib\/python3.8\/os.py\", line 223, in makedirs\r\n    mkdir(name, mode)\r\nFileExistsError: [Errno 17] File exists: '\/tmp\/tmpdg2r5f0_\/model\/'\r\ncommand terminated with exit code 1\r\n```\r\n\r\nThe model being used seems to have no effect on the error.\r\n\r\n**Expected behavior**\r\nThe input provided is syntactically identical to:\r\n```\r\npython publish_model_to_mlflow.py \\\r\n    --model_name abp-nvsmi-xgb \\\r\n    --model_directory \/common\/models\/abp-nvsmi-xgb \\\r\n    --flavor triton\r\n```\r\n\r\nand should provide the same outcome.",
        "Issue_answer_count":2,
        "Issue_self_closed":0.0,
        "Answer_body":"It appears that the bug has been fixed by https:\/\/github.com\/triton-inference-server\/server\/pull\/3828 and I am not able to reproduce it using the model example for the plugin. Can you try the plugin from the latest codebase?\r\n```\r\npython `pwd`\/mlflow-triton-plugin\/scripts\/publish_model_to_mlflow.py \\\r\n    --model_name onnx_float32_int32_int32 \\\r\n    --model_directory `pwd`\/mlflow-triton-plugin\/examples\/onnx_float32_int32_int32\/ \\\r\n    --flavor triton\r\n```\r\nreturns:\r\n```\r\nRegistered model 'onnx_float32_int32_int32' already exists. Creating a new version of this model...\r\n2022\/04\/07 23:03:53 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: onnx_float32_int32_int32, version 3\r\nCreated version '3' of model 'onnx_float32_int32_int32'.\r\n.\/mlruns\/0\/945d5c5d6806470d889248cfc7f10b69\/artifacts\r\n``` Closing due to in-activity.",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"input script publish model overli particular input descript publish model script valu given model directori argument trail script bomb interest wai triton inform version triton triton contain build contain reproduc python publish model model abp nvsmi xgb model directori common model abp nvsmi xgb flavor triton give follow error traceback recent file publish model line publish file opt conda env lib python site packag click core line return self main arg kwarg file opt conda env lib python site packag click core line main self invok ctx file opt conda env lib python site packag click core line invok return ctx invok self callback ctx param file opt conda env lib python site packag click core line invok return callback arg kwarg file publish model line publish triton flavor log model file triton infer server server deploi triton plugin script triton flavor line log model model log file opt conda env lib python site packag model model line log flavor save model path local path model model kwarg file triton infer server server deploi triton plugin script triton flavor line save model shutil copytre triton model path model data path file opt conda env lib python shutil line copytre return copytre entri entri src src dst dst symlink symlink file opt conda env lib python shutil line copytre makedir dst exist dir exist file opt conda env lib python line makedir mkdir mode fileexistserror errno file exist tmp tmpdgrf model command termin exit code model effect error expect behavior input provid syntact ident python publish model model abp nvsmi xgb model directori common model abp nvsmi xgb flavor triton provid outcom",
        "Issue_preprocessed_content":"input script publish model overli particular input descript script valu given argument trail script bomb interest wai triton inform version triton triton contain build contain reproduc give model expect behavior input provid ident provid outcom",
        "Issue_gpt_summary_original":"When pycaret is installed with [full], all runs executed in one script are shown nested recursively in MLflow dashboard. This happens only with [full] installation.",
        "Issue_gpt_summary":"pycaret instal run execut script shown nest recurs dashboard happen instal",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/mindsdb\/mindsdb\/issues\/2043",
        "Issue_title":"[ BYOM MLflow ] Check valid URL when creating predictor",
        "Issue_created_time":1646758611000,
        "Issue_closed_time":1656947080000,
        "Issue_body":"At the moment, an mlflow byom predictor with arbitrary URLs can be created. We should first check whether an actual mlflow model is served at that URL before creating\/linking said model.",
        "Issue_answer_count":2,
        "Issue_self_closed":1.0,
        "Answer_body":"Can we close this @paxcema and @ea-rus  I think we need to merge the above PR after checking there are no conflicts (because it's a bit outdated by now), but once merged we can close this issue.",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"byom check valid url creat predictor moment byom predictor arbitrari url creat check actual model serv url creat link said model",
        "Issue_preprocessed_content":"check valid url creat predictor moment byom predictor arbitrari url creat check actual model serv url said model",
        "Issue_gpt_summary_original":"The user has encountered a bug in pycaret where started runs in MlflowLogger are never ended, resulting in all runs shown in MLflow dashboard being nested recursively. This bug is problematic as it affects the display of deeply nested runs. The user has provided a reproducible example and expected behavior, but the actual display is not as expected. The installed version of pycaret is 2.3.10.",
        "Issue_gpt_summary":"user encount bug pycaret start run logger end result run shown dashboard nest recurs bug problemat affect displai deepli nest run user provid reproduc exampl expect behavior actual displai expect instal version pycaret",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/deepset-ai\/haystack\/issues\/2244",
        "Issue_title":"MLFlowLogging always disabled for training `FARMReader` models",
        "Issue_created_time":1645701717000,
        "Issue_closed_time":1651060598000,
        "Issue_body":"**Describe the bug**\r\nWhen training a Reader model, a user might want to log training statistics and metrics to MLFlow. However, when initializing a `FARMReader`, we initialize an `Inferencer`. There, we call `MLFlowLogger.disable()` on [this line](https:\/\/github.com\/deepset-ai\/haystack\/blob\/15c70bdb9f8cd16511d1eb9ed9b2e9466de65cbf\/haystack\/modeling\/infer.py#L77), which disables all logging to MLFlow. Therefore, when a user is calling the Reader's `train` method after initializing the Reader, no tranining statistics wil be logged.\r\n\r\nAs a workaround, the user can manually set `MLFlowLogger.disable_logging = False` before calling the `train` method.",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"fixed by https:\/\/github.com\/deepset-ai\/haystack\/pull\/2337",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"log disabl train farmread model bug train reader model user want log train statist metric initi farmread initi inferenc logger disabl line http github com deepset haystack blob cbdbfcddebedbedecbf haystack model infer disabl log user call reader train method initi reader tranin statist wil log workaround user manual set logger disabl log fals call train method",
        "Issue_preprocessed_content":"disabl train model bug train reader model user want log train statist metric initi initi disabl user reader method initi reader tranin statist wil workaround user set method",
        "Issue_gpt_summary_original":"The user is facing an issue with MlFlow not logging metrics when integrating pycaret with MlFlow using the parameter `log_experiment` in `setup()`. The user has confirmed that everything else is being stored in the local MlFlow server as planned. The user is unsure if they are doing something wrong or if it is a bug from pycaret's side. The expected behavior is for metrics to be logged, but the actual result is that no metrics are being logged. The user is using PyCaret 3.0.0rc3.",
        "Issue_gpt_summary":"user face issu log metric integr pycaret paramet log experi setup user confirm store local server plan user unsur wrong bug pycaret expect behavior metric log actual result metric log user pycaret",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/bentoml\/BentoML\/issues\/3146",
        "Issue_title":"bug: failed to containerize when using mlflow",
        "Issue_created_time":1666803000000,
        "Issue_closed_time":null,
        "Issue_body":"Trying to integrate Mlflow with my current bentoml workflow and following this example\r\n`https:\/\/github.com\/bentoml\/BentoML\/tree\/main\/examples\/mlflow\/pytorch`\r\nBut getting error when i try to deploy model with docker, \r\n\r\nwhen i run  `bentoml containerize mlflow_pytorch_mnist_demo:latest`\r\n\r\n```Building docker image for Bento(tag=\"mlflow_pytorch_mnist_demo:3utxjn2vbgxh5gbc\")...\r\nERROR: failed to solve: executor failed running [\/bin\/sh -c bash <<EOF\r\nset -euxo pipefail\r\n\r\nif [ -f \/home\/bentoml\/bento\/env\/conda\/environment.yml ]; then\r\n   set pip_interop_enabled to improve conda-pip interoperability. Conda can use\r\n   pip-installed packages to satisfy dependencies.\r\n  echo \"Updating conda base environment with environment.yml\"\r\n  \/opt\/conda\/bin\/conda config --set pip_interop_enabled True\r\n  \/opt\/conda\/bin\/conda env update -n base -f \/home\/bentoml\/bento\/env\/conda\/environment.yml\r\n  \/opt\/conda\/bin\/conda clean --all\r\nfi\r\nEOF]: exit code: 1\r\nFailed building docker image: Command '['docker', 'buildx', 'build', '--progress', 'auto', '--tag', 'mlflow_pytfile', 'env\\\\docker\\\\Dockerfile', '--load', '.']' returned non-zero exit status 1.\r\n```\r\n### To reproduce\r\n\r\nBug recreation steps:\r\nClone the repo `https:\/\/github.com\/bentoml\/BentoML\/tree\/main\/examples\/mlflow\/pytorch` \r\nGoto the folder `examples\/mlflow\/pytorch`\r\n`python mnist.py`\r\n`bentoml build`\r\n`bentoml containerize mlflow_pytorch_mnist_demo:latest`\r\n\r\nP.S. `bentoml serve service.py:svc`  works fine`\r\n\r\n\r\n### Environment\r\n\r\nbentoml version 1.0.7\r\nPython version  3.9.12\r\nDocker Engine 20.10.17",
        "Issue_answer_count":14,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"bug fail container try integr current bentoml workflow follow exampl http github com bentoml bentoml tree main exampl pytorch get error try deploi model docker run bentoml container pytorch mnist demo latest build docker imag bento tag pytorch mnist demo utxjnvbgxhgbc error fail solv executor fail run bin bash eof set euxo pipefail home bentoml bento env conda environ yml set pip interop enabl improv conda pip interoper conda us pip instal packag satisfi depend echo updat conda base environ environ yml opt conda bin conda config set pip interop enabl true opt conda bin conda env updat base home bentoml bento env conda environ yml opt conda bin conda clean eof exit code fail build docker imag command docker buildx build progress auto tag pytfil env docker dockerfil load return non zero exit statu reproduc bug recreat step clone repo http github com bentoml bentoml tree main exampl pytorch goto folder exampl pytorch python mnist bentoml build bentoml container pytorch mnist demo latest bentoml serv servic svc work fine environ bentoml version python version docker engin",
        "Issue_preprocessed_content":"bug fail container try integr bentoml workflow exampl try deploi model docker run reproduc bug recreat step clone repo goto folder work fine environ bentoml version python version docker engin",
        "Issue_gpt_summary_original":"the user encountered a challenge with server integration when attempting to save an xgboost run, resulting in an unfinished status with no metrics or artifacts created.",
        "Issue_gpt_summary":"user encount challeng server integr attempt save xgboost run result unfinish statu metric artifact creat",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/bentoml\/BentoML\/issues\/2160",
        "Issue_title":"MLflow pyfunc model can't be loaded",
        "Issue_created_time":1641482199000,
        "Issue_closed_time":1642711286000,
        "Issue_body":"**Describe the bug**\r\nI can't load a *mlflow* model in the beta version of BentoML 1.0\r\n\r\n**To Reproduce**\r\n1. Train & log a pyfunc model to mflow\r\n```\r\nfrom sklearn import svm, datasets\r\n\r\nimport mlflow\r\n\r\n\r\n# Load training data\r\niris = datasets.load_iris()\r\nX, y = iris.data, iris.target\r\n\r\n# Model Training\r\nclf = svm.SVC()\r\nclf.fit(X, y)\r\n\r\n# Wrap up as a custom pyfunc model\r\nclass ModelPyfunc(mlflow.pyfunc.PythonModel):\r\n    \r\n    def load_context(self, context):\r\n        self.model = clf\r\n    \r\n    def predict(self, context, model_input):\r\n        return self.model.predict(model_input)      \r\n      \r\n# Log model\r\nwith mlflow.start_run() as run:\r\n    model = ModelPyfunc()\r\n    mlflow.pyfunc.log_model(\"model\", python_model=model)\r\n    print(\"run_id: {}\".format(run.info.run_id))\r\n```\r\n\r\n2. Load it into BentoML\r\n```\r\nimport bentoml\r\n\r\nmodel_uri = f\"runs:\/{run.info.run_id}\/model\"\r\n\r\ntag = bentoml.mlflow.import_from_uri(\"model\", model_uri)\r\n\r\nmodel = bentoml.mlflow.load(tag)\r\n```\r\n3. The model gets successfully stored in the local model store (listed in `bentoml models list`), however the loading `model = bentoml.mlflow.load(tag)` is failing to **AttributeError** `module 'mlflow.pyfunc.model' has no attribute 'load_model'`\r\n\r\n**Expected behavior**\r\nPyfunc model should load without issues\r\n\r\n**Screenshots\/Logs**\r\n```\r\nTraceback (most recent call last):\r\n  File \"sandbox.py\", line 11, in <module>\r\n    bentoml.mlflow.load(tag)\r\n  File \"\/Users\/e056232\/opt\/miniconda3\/lib\/python3.8\/site-packages\/simple_di\/__init__.py\", line 124, in _\r\n    return func(*_inject_args(bind.args), **_inject_kwargs(bind.kwargs))\r\n  File \"\/Users\/e056232\/opt\/miniconda3\/lib\/python3.8\/site-packages\/bentoml\/_internal\/frameworks\/mlflow.py\", line 85, in load\r\n    return loader_module.load_model(mlflow_folder)  # noqa\r\nAttributeError: module 'mlflow.pyfunc.model' has no attribute 'load_model'\r\n```\r\n\r\n**Environment:**\r\n - OS: MacOS 11.6\r\n - Python Version Python 3.8.5\r\n - BentoML Version BentoML-1.0.0a1",
        "Issue_answer_count":4,
        "Issue_self_closed":0.0,
        "Answer_body":"I think this version is not yet up-to-date with our 1.0 branch. cc @parano Line 85 is different from `main` branch @alexdivet @aarnphm the new 1.0.0a2 was just released, could you help confirm the issue has been resolved? ![Screenshot 2022-01-20 at 15 39 52](https:\/\/user-images.githubusercontent.com\/29749331\/150418600-d75d6b01-679d-4fa7-9a66-395262c13569.png)\r\nWorks just fine for me\r\nRunning on M1 Max, Python 3.9.10, with Rosetta 2. Please let me know if you still run into problems @alexdivet It works on my end too. Thanks for resolving it \ud83d\ude4f\ud83c\udffb",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"pyfunc model load bug load model beta version bentoml reproduc train log pyfunc model mflow sklearn import svm dataset import load train data iri dataset load iri iri data iri target model train clf svm svc clf fit wrap custom pyfunc model class modelpyfunc pyfunc pythonmodel def load context self context self model clf def predict self context model input return self model predict model input log model start run run model modelpyfunc pyfunc log model model python model model print run format run info run load bentoml import bentoml model uri run run info run model tag bentoml import uri model model uri model bentoml load tag model get successfulli store local model store list bentoml model list load model bentoml load tag fail attributeerror modul pyfunc model attribut load model expect behavior pyfunc model load issu screenshot log traceback recent file sandbox line bentoml load tag file user opt miniconda lib python site packag simpl init line return func inject arg bind arg inject kwarg bind kwarg file user opt miniconda lib python site packag bentoml intern framework line load return loader modul load model folder noqa attributeerror modul pyfunc model attribut load model environ maco python version python bentoml version bentoml",
        "Issue_preprocessed_content":"pyfunc model load bug load model beta version bentoml reproduc train log pyfunc model mflow load bentoml model get store local model store load fail expect behavior pyfunc model load log environ maco python version python bentoml version",
        "Issue_gpt_summary_original":"The user has reported a bug in which mlflow logs the name of both models \"Least Angle Regression\" and \"Lasso Least Angle Regression\" as \"Least Angle Regression\". The `get_logs()` function shows that both models have unique `run_id` but both have the same `tags.mlflow.runName`. The user has provided a reproducible example and the expected behavior is that `tags.mlflow.runName` parameter from `get_logs()` is unique and contains all model names from `compare_models()`. The actual result shows that \"Least Angle Regression\" is there twice and \"Lasso Least Angle Regression\" isn't there at all. The user is using Python version 3.9.5, PyCaret version 3.",
        "Issue_gpt_summary":"user report bug log model angl regress lasso angl regress angl regress log function show model uniqu run tag runnam user provid reproduc exampl expect behavior tag runnam paramet log uniqu contain model name compar model actual result show angl regress twice lasso angl regress isn user python version pycaret version",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/pycaret\/pycaret\/issues\/3059",
        "Issue_title":"[BUG]: Runs recorded in MLflow nests all recursively when [full] installed",
        "Issue_created_time":1667105333000,
        "Issue_closed_time":1669124369000,
        "Issue_body":"### pycaret version checks\r\n\r\n- [X] I have checked that this issue has not already been reported [here](https:\/\/github.com\/pycaret\/pycaret\/issues).\r\n\r\n- [X] I have confirmed this bug exists on the [latest version](https:\/\/github.com\/pycaret\/pycaret\/releases) of pycaret.\r\n\r\n- [ ] I have confirmed this bug exists on the master branch of pycaret (pip install -U git+https:\/\/github.com\/pycaret\/pycaret.git@master).\r\n\r\n\r\n### Issue Description\r\n\r\nWhen pycaret is installed with [full], all runs executed in one script are shown nested recursively in MLflow dashboard.\r\nThis happens only with [full] installation.\r\n\r\n### Reproducible Example\r\n\r\n```python\r\n%pip install -U pip wheel\r\n%pip install --pre pycaret[full]\r\n\r\nimport mlflow\r\nfrom pycaret.classification import *\r\nfrom pycaret.datasets import get_data\r\n\r\nmlflow.set_tracking_uri(\"http:\/\/localhost:5000\")\r\n\r\ndata = get_data(\"diabetes\")\r\nsetup(data, target=\"Class variable\", log_experiment=True)\r\ncompare_models(include=[\"lr\", \"svm\", \"rf\"])\r\nsetup(data, target=\"Class variable\", log_experiment=True)\r\ncompare_models(include=[\"lr\", \"svm\", \"rf\"])\r\n```\r\n\r\n\r\n### Expected Behavior\r\n\r\nExpected display: (when installed without [full])\r\n![OK](https:\/\/user-images.githubusercontent.com\/1991802\/198862894-7a459755-5b94-4abc-a00b-be8d42e1f71c.png)\r\n\r\nActual display: (when installed with [full])\r\n![NG](https:\/\/user-images.githubusercontent.com\/1991802\/198862906-a26034b1-e22b-4d36-a0e5-1f0c5ccdad8c.png)\r\n\r\n\r\n### Actual Results\r\n\r\n```python-traceback\r\nAttached the figure also in 'Expected Behavior'.\r\n```\r\n\r\n\r\n### Installed Versions\r\n\r\n<details>\r\nSystem:\r\n    python: 3.9.5 (default, Nov 23 2021, 15:27:38)  [GCC 9.3.0]\r\nexecutable: \/home\/ak\/sample\/.venv\/bin\/python\r\n   machine: Linux-5.10.102.1-microsoft-standard-WSL2-x86_64-with-glibc2.31\r\n\r\nPyCaret required dependencies:\r\n                 pip: 22.3\r\n          setuptools: 44.0.0\r\n             pycaret: 3.0.0rc4\r\n             IPython: 8.5.0\r\n          ipywidgets: 8.0.2\r\n                tqdm: 4.64.1\r\n               numpy: 1.22.4\r\n              pandas: 1.4.4\r\n              jinja2: 3.1.2\r\n               scipy: 1.8.1\r\n              joblib: 1.2.0\r\n             sklearn: 1.1.3\r\n                pyod: 1.0.6\r\n            imblearn: 0.9.1\r\n   category_encoders: 2.5.1.post0\r\n            lightgbm: 3.3.3\r\n               numba: 0.55.2\r\n            requests: 2.28.1\r\n          matplotlib: 3.5.3\r\n          scikitplot: 0.3.7\r\n         yellowbrick: 1.5\r\n              plotly: 5.11.0\r\n             kaleido: 0.2.1\r\n         statsmodels: 0.13.2\r\n              sktime: 0.13.4\r\n               tbats: 1.1.1\r\n            pmdarima: 1.8.5\r\n              psutil: 5.9.3\r\n\r\nPyCaret optional dependencies:\r\n                shap: 0.41.0\r\n           interpret: 0.2.7\r\n                umap: 0.5.3\r\n    pandas_profiling: 3.4.0\r\n  explainerdashboard: 0.4.0\r\n             autoviz: 0.1.58\r\n           fairlearn: 0.8.0\r\n             xgboost: 1.7.0rc1\r\n            catboost: 1.1\r\n              kmodes: 0.12.2\r\n             mlxtend: 0.21.0\r\n       statsforecast: 1.1.3\r\n        tune_sklearn: 0.4.4\r\n                 ray: 2.0.1\r\n            hyperopt: 0.2.7\r\n              optuna: 3.0.3\r\n               skopt: 0.9.0\r\n              mlflow: 1.30.0\r\n              gradio: 3.8\r\n             fastapi: 0.85.1\r\n             uvicorn: 0.19.0\r\n              m2cgen: 0.10.0\r\n           evidently: 0.1.59.dev2\r\n                nltk: 3.7\r\n            pyLDAvis: Not installed\r\n              gensim: Not installed\r\n               spacy: Not installed\r\n           wordcloud: 1.8.2.2\r\n            textblob: 0.17.1\r\n               fugue: 0.6.6\r\n           streamlit: Not installed\r\n             prophet: Not installed\r\n<\/details>\r\n",
        "Issue_answer_count":3,
        "Issue_self_closed":0.0,
        "Answer_body":"In addition, runs of `compare_models `and `create_model` get nested recursively as well in pycaret > 2.3.6.\r\nSee screenshot below where the red line shows the behaviour in pycaret==2.3.6 (which is the wanted and expected behaviour) and in orange the nested unwanted behaviour in pycaret 2.3.8 , 2.3.9 and 2.3.10\r\n![image](https:\/\/user-images.githubusercontent.com\/50994394\/200543740-0883c8ba-9f4a-4d1f-8abc-560ae7dbd54e.png)\r\n @nagamatz @tdekelver-bd This issue was recently fixed on last rc release. Can you try installing pycaret with `pip install --pre pycaret` and let me know if you still face the issue. It's not yet fixed with 3.0.0rc4. This is the results with the code in the first post. Now, mlflow is 2.0.1\r\n![\u7121\u984c](https:\/\/user-images.githubusercontent.com\/1991802\/206426156-4b19a4cc-b865-4af3-8281-1b89fc099f28.png)\r\n",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"bug run record nest recurs instal pycaret version check check issu report http github com pycaret pycaret issu confirm bug exist latest version http github com pycaret pycaret releas pycaret confirm bug exist master branch pycaret pip instal git http github com pycaret pycaret git master issu descript pycaret instal run execut script shown nest recurs dashboard happen instal reproduc exampl python pip instal pip wheel pip instal pre pycaret import pycaret classif import pycaret dataset import data set track uri http localhost data data diabet setup data target class variabl log experi true compar model includ svm setup data target class variabl log experi true compar model includ svm expect behavior expect displai instal http user imag githubusercont com abc bedefc png actual displai instal http user imag githubusercont com fcccdadc png actual result python traceback attach figur expect behavior instal version python default nov gcc execut home sampl venv bin python machin linux microsoft standard wsl glibc pycaret requir depend pip setuptool pycaret ipython ipywidget tqdm numpi panda jinja scipi joblib sklearn pyod imblearn categori encod post lightgbm numba request matplotlib scikitplot yellowbrick plotli kaleido statsmodel sktime tbat pmdarima psutil pycaret option depend shap interpret umap panda profil explainerdashboard autoviz fairlearn xgboost catboost kmode mlxtend statsforecast tune sklearn rai hyperopt skopt gradio fastapi uvicorn mcgen evid dev nltk pyldavi instal gensim instal spaci instal wordcloud textblob fugu streamlit instal prophet instal",
        "Issue_preprocessed_content":"run record nest recurs pycaret version check check report confirm bug exist pycaret confirm bug exist master branch pycaret descript pycaret run execut script shown nest recurs dashboard reproduc exampl expect behavior expect displai actual displai actual result version detail python execut machin pycaret requir depend pip pycaret ipython ipywidget tqdm numpi panda jinja scipi joblib sklearn pyod imblearn lightgbm numba request matplotlib scikitplot plotli kaleido statsmodel sktime tbat pmdarima psutil pycaret option depend shap interpret umap explainerdashboard autoviz fairlearn kmode mlxtend statsforecast rai hyperopt skopt gradio fastapi uvicorn cgen evid nltk pyldavi gensim spaci wordcloud textblob fugu streamlit prophet detail",
        "Issue_gpt_summary_original":"The user is facing an issue with pycaret and mlflow integration where they are unable to create probabilities in addition to predicted values for binary response models using the scikit learn function \"predict_model\". The issue occurs when they call the calibrated algorithm in a separate notebook for scoring new data. The expected behavior is to see the probabilities model.predict_prob(X), but the code errors out.",
        "Issue_gpt_summary":"user face issu pycaret integr unabl creat probabl addit predict valu binari respons model scikit learn function predict model issu occur calibr algorithm separ notebook score new data expect behavior probabl model predict prob code error",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/pycaret\/pycaret\/issues\/2975",
        "Issue_title":"[BUG]: Runs recorded in MLflow nests all recursively",
        "Issue_created_time":1663557360000,
        "Issue_closed_time":1663775400000,
        "Issue_body":"### pycaret version checks\n\n- [X] I have checked that this issue has not already been reported [here](https:\/\/github.com\/pycaret\/pycaret\/issues).\n\n- [X] I have confirmed this bug exists on the [latest version](https:\/\/github.com\/pycaret\/pycaret\/releases) of pycaret.\n\n- [X] I have confirmed this bug exists on the master branch of pycaret (pip install -U git+https:\/\/github.com\/pycaret\/pycaret.git@master).\n\n\n### Issue Description\n\nAs started runs in MlflowLogger are never ended, all runs shown in MLflow dashboard seem to be nested recursively.\r\nMLflow 1.28.0 fixed the display of deeply nested runs correctly, so the bug is now problematic.\n\n### Reproducible Example\n\n```python\nimport mlflow\r\nfrom pycaret.classification import *\r\nfrom pycaret.datasets import get_data\r\n\r\nmlflow.set_tracking_uri(\"http:\/\/localhost:5000\")\r\n\r\ndata = get_data(\"diabetes\")\r\nsetup(data, target=\"Class variable\", log_experiment=True, silent=True)\r\ncompare_models(include=[\"lr\", \"svm\", \"rf\"])\r\nsetup(data, target=\"Class variable\", log_experiment=True, silent=True)\r\ncompare_models(include=[\"lr\", \"svm\", \"rf\"])\n```\n\n\n### Expected Behavior\n\nExpected display:\r\n![p2](https:\/\/user-images.githubusercontent.com\/1991802\/190944134-3490628a-4eca-490a-af11-c4cdfe41953e.png)\r\n\r\nActual display:\r\n![p1](https:\/\/user-images.githubusercontent.com\/1991802\/190944304-08c41ae2-93fd-4b79-b3ff-ebb594ad2664.png)\r\n\n\n### Actual Results\n\n```python-traceback\nAttached the figure also in 'Expected Behavior'.\n```\n\n\n### Installed Versions\n\n<details>\r\n'2.3.10'\r\n<\/details>\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"Cannot reproduce on master. Please try again with `pip install -U --pre pycaret` @nagamatz and reopen the issue if it persists.",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"bug run record nest recurs pycaret version check check issu report http github com pycaret pycaret issu confirm bug exist latest version http github com pycaret pycaret releas pycaret confirm bug exist master branch pycaret pip instal git http github com pycaret pycaret git master issu descript start run logger end run shown dashboard nest recurs fix displai deepli nest run correctli bug problemat reproduc exampl python import pycaret classif import pycaret dataset import data set track uri http localhost data data diabet setup data target class variabl log experi true silent true compar model includ svm setup data target class variabl log experi true silent true compar model includ svm expect behavior expect displai http user imag githubusercont com eca ccdfee png actual displai http user imag githubusercont com cae bff ebbad png actual result python traceback attach figur expect behavior instal version",
        "Issue_preprocessed_content":"run record nest recurs pycaret version check check report confirm bug exist pycaret confirm bug exist master branch pycaret descript start run end run shown dashboard nest recurs fix displai nest run bug problemat reproduc exampl expect behavior expect displai actual displai actual result version detail detail",
        "Issue_gpt_summary_original":"The user is unable to see any models in the `mlflow ui` during training, despite several models having already converged and logged to the file system. The user has tried both the nightly and release branch and has confirmed the issue on the latest version and develop branch of pycaret. The user has provided a reproducible example and expects to see the models that have already converged in the `mlflow ui` dashboard.",
        "Issue_gpt_summary":"user unabl model train despit model have converg log file user tri nightli releas branch confirm issu latest version develop branch pycaret user provid reproduc exampl expect model converg dashboard",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/pycaret\/pycaret\/issues\/2856",
        "Issue_title":"MlFlow not logging metrics",
        "Issue_created_time":1660651109000,
        "Issue_closed_time":1660653306000,
        "Issue_body":"### pycaret version checks\n\n- [X] I have checked that this issue has not already been reported [here](https:\/\/github.com\/pycaret\/pycaret\/issues).\n\n- [X] I have confirmed this bug exists on the [latest version](https:\/\/github.com\/pycaret\/pycaret\/releases) of pycaret.\n\n- [ ] I have confirmed this bug exists on the master branch of pycaret (pip install -U git+https:\/\/github.com\/pycaret\/pycaret.git@master).\n\n\n### Issue Description\n\nHi,\r\n\r\nI am trying to integrate pycaret with mlflow using your parameter `log_experiment` in `setup()`. When I set it to true, everything is stores as planned in my local MlFlow server, but not the metrics.\r\n\r\nIn the documentation is says the `log_experiment=True` should control everything. So I am not sure if I do something wrong here of if it is a bug from your side.\r\n\r\nWould be glad if you could help!\n\n### Reproducible Example\n\n```python\nfrom pycaret.datasets import get_data\r\nfrom pycaret.regression import *\r\ndf = get_data('bike')\r\nexp = RegressionExperiment()\r\nexp.setup(data=df, log_experiment=True)\r\nmodel = exp.create_model(\"lr\")\r\npred = exp.predict_model(estimator=model)\r\nexp.finalize_model(estimator=model)\n```\n\n\n### Expected Behavior\n\nshould log metrics\n\n### Actual Results\n\n```python-traceback\nNo metrics logged.\n```\n\n\n### Installed Versions\n\n<details>\r\nPyCaret 3.0.0rc3\r\n<\/details>\r\n",
        "Issue_answer_count":2,
        "Issue_self_closed":1.0,
        "Answer_body":"Update:\r\n\r\nWhen I write `exp.get_logs()` I can see some metrics there. But some runs still have the status \"RUNNING\", unsure why.\r\n\r\nAlso, all the runs that exist when I start the server using `!mlflow ui` are missing metrics. Edit: found issue, not on you! Sorry :)",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"log metric pycaret version check check issu report http github com pycaret pycaret issu confirm bug exist latest version http github com pycaret pycaret releas pycaret confirm bug exist master branch pycaret pip instal git http github com pycaret pycaret git master issu descript try integr pycaret paramet log experi setup set true store plan local server metric document sai log experi true control sure wrong bug glad help reproduc exampl python pycaret dataset import data pycaret regress import data bike exp regressionexperi exp setup data log experi true model exp creat model pred exp predict model estim model exp final model estim model expect behavior log metric actual result python traceback metric log instal version pycaret",
        "Issue_preprocessed_content":"metric pycaret version check check report confirm bug exist pycaret confirm bug exist master branch pycaret descript try integr pycaret paramet set true store local server metric document sai control sure wrong bug glad help reproduc exampl expect behavior log metric actual result version detail pycaret detail",
        "Issue_gpt_summary_original":"The user is encountering an error while trying to save plots through MLFLOW. The error message states that \"plot_model() got an unexpected keyword argument 'system'\".",
        "Issue_gpt_summary":"user encount error try save plot error messag state plot model got unexpect keyword argument",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/pycaret\/pycaret\/issues\/2838",
        "Issue_title":"[BUG]: MLflow server integration",
        "Issue_created_time":1660026191000,
        "Issue_closed_time":1660286399000,
        "Issue_body":"### pycaret version checks\n\n- [X] I have checked that this issue has not already been reported [here](https:\/\/github.com\/pycaret\/pycaret\/issues).\n\n- [X] I have confirmed this bug exists on the [latest version](https:\/\/github.com\/pycaret\/pycaret\/releases) of pycaret.\n\n- [ ] I have confirmed this bug exists on the master branch of pycaret (pip install -U git+https:\/\/github.com\/pycaret\/pycaret.git@master).\n\n\n### Issue Description\n\nI have a problem saving xgboost run in mlflow server. The run has a status of UNFINISHED, no metrics or artifacts are created. \r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/101572186\/183577670-53398204-debf-428b-8b0c-3c7ca83f4785.png)\r\n\r\nWhen I use `mlflow ui` everything is fine, but when I run mlflow server with SQLite as backend store the problem occurs.\r\nCommand used to run mlflow server- `mlflow server --host 0.0.0.0 --port 5000 --default-artifact-root \/mlflow\/artifacts\/ --backend-store-uri sqlite:\/\/\/\/\/mlflow\/experiments\/mlflow.db`\n\n### Reproducible Example\n\n```python\nimport mlflow\r\nfrom pycaret.classification import *\r\nimport pandas as pd\r\n\r\nmlflow.set_tracking_uri('http:\/\/localhost:5000')\r\n\r\ndata = pd.DataFrame({'V1': [-1.34419, -1.89211, 1.69421, 0.263328, 0.107918, 0.154241, 0.33468, 1.447778, -0.918269, 0.86319, -1.630049, 1.643798, 1.274341, -1.296742, -0.193585, 1.627422, -0.66805, -1.664491, -1.86911, 0.892885],\r\n                     'V2': [0.85556, -1.70503, -0.02896, 1.746258, -0.084151, 1.673185, 1.113326, -0.23231, 1.054817, -1.407584, 0.474997, 0.150687, -0.738246, -0.045513, 1.58637, 0.984249, 0.624333, 0.298866, 0.662204, 0.967942],\r\n                     'V3': [1.768638, -0.503169, -0.25622, -0.937752, -0.062189, -0.820652, -1.786942, -1.770495, 1.808681, -0.280286, -1.389736, 0.182212, -0.602959, -0.354683, -1.065631, 1.649264, 0.389538, -1.674815, 0.281824, -1.683662],\r\n                     'V4': [1.512828, 1.177697, -1.156862, -1.877876, 1.526013, 1.644001, -1.282481, -0.720543, 0.323963, -1.931616, 1.632839, 1.706752, 1.895627, 1.860705, -1.559702, 1.517466, 1.254323, 1.84415, -1.175013, -1.600652],\r\n                     'V5': [0.820483, -1.20923, -0.012221, 1.682836, 0.104248, 1.258085, 0.404062, 0.18019, 1.352545, -0.497071, 0.771277, 1.614052, -0.693854, 0.002655, 0.277743, -0.977744, -0.97259, -1.501586, -0.731194, -0.551264],\r\n                     'V6': [1.079115, -0.734152, -1.630816, -1.877664, 1.577477, -1.902078, 1.012828, -1.107726, 1.742781, -1.338595, 1.788969, -0.851507, 1.061596, -0.635559, -1.171469, -1.001642, 1.493507, 0.732088, 1.565327, -1.845441],\r\n                     'V7': [1.165929, 1.804607, 0.886589, -0.027458, -1.444197, -0.415643, 0.863924, -1.177661, 1.684514, 1.023797, -1.234116, -0.989024, 0.815575, -0.668453, 0.591911, -0.798925, 1.024032, -1.983963, 1.900752, 1.201001],\r\n                     'V8': [-0.536923, 0.641581, -0.585228, 1.061145, -0.303192, -0.652068, 0.858556, 0.11012, 1.839738, -1.51798, -0.942028, -0.736386, -0.098261, 0.699127, 0.173854, -1.16775, -0.417662, 0.021639, 1.745042, -1.119667],\r\n                     'V9': [0.643498, -1.090347, 0.120182, -0.819219, -1.296763, 0.530723, -1.367664, -0.708116, -1.304274, 1.486166, 1.656498, 1.645308, -0.257558, 0.400849, 1.356781, 1.693433, 0.42606, 0.370683, -0.239278, -0.541334],\r\n                     'V10': [-0.744989, 0.506658, 1.15586, 1.461127, 1.928769, -0.330472, 1.514159, -1.209056, -0.741453, -1.479674, 1.92057, -1.148481, 0.949433, 0.674107, -1.410627, 1.497083, -1.262624, -0.856706, -1.708155, 0.93153],\r\n                     'V11': [0.967242, 1.968385, -1.362337, -0.46194, 0.809224, 0.226177, 1.782128, -0.114595, 0.698243, -0.141743, -0.117251, 1.762656, -0.068839, 0.648945, -1.497037, -1.455443, -0.291242, 1.806048, -1.945438, 0.251282],\r\n                     'V12': [0.010432, -0.101522, -1.764095, 1.326967, -1.299122, -0.549148, 0.807092, -0.75387, 0.955056, 0.640369, -0.917832, 0.250338, 0.624729, 1.566922, 0.118619, 1.907585, -0.919995, 0.868393, -1.103909, 0.347108],\r\n                     'V13': [0.122315, -1.140017, -0.876424, -1.075771, 0.668814, 1.916654, -0.864906, 0.132892, 0.740058, 0.94469, -0.260381, 0.92833, -1.186423, -0.18321, 1.99266, -0.779091, -1.649025, -1.688821, 1.075145, -1.988603],\r\n                     'V14': [-1.494, 0.679776, 0.813194, 1.8687, -0.20273, -0.363265, 1.98902, 0.100025, 1.462866, 0.561017, 0.418922, 1.981837, -1.834009, -1.657952, 0.585069, -0.898764, 0.683234, 0.743215, -0.050289, -0.668302], \r\n                     'V15': [0.199787, 0.81829, 1.200156, -1.684249, 0.847466, 1.326102, 0.323103, -1.010648, -1.868355, -1.204467, 1.777393, 0.375692, -1.654002, 0.50357, -1.372448, -0.522425, 0.360716, 1.007605, 1.009369, -0.353638],\r\n                     'V16': [1.535552, -0.082278, -0.083154, 0.069432, 1.356735, -0.042527, -0.462543, 1.813852, -1.664882, 0.408013, -1.802172, -1.920202, 1.987332, -1.126771, 1.485496, 1.972345, -0.33345, 1.414685, -0.06674, 1.383197],\r\n                     'V17': [-0.249929, 1.668129, 0.860046, 0.013955, 0.085628, 1.285539, -0.754444, -0.306815, -1.244118, -0.61328, 0.711952, 1.384674, 1.710264, 1.337836, -0.029678, -1.382343, -1.963618, 0.088497, -0.110544, 0.954066],\r\n                     'V18': [0.665032, -1.214589, 0.486172, 1.184611, 1.152936, -0.192168, -1.096281, -0.762198, -0.338583, 0.170551, -0.045797, -0.897271, 0.433204, -0.986375, 0.430157, 1.846751, -0.905146, -1.398763, 1.790667, -1.580808],\r\n                     'V19': [1.347637, -0.356925, 0.414118, 0.277104, 0.41587, -1.237646, 0.580625, 1.468221, -0.254781, 0.245683, -1.25356, 0.241325, 1.15677, -1.74525, 1.970698, -0.038675, -0.314979, 0.114507, 1.378524, -0.139709],\r\n                     'V20': [-1.291686, -1.714475, 0.012188, 1.002238, -1.587334, 1.408967, 1.055095, -1.356865, 1.307388, 0.697003, -0.112676, 1.762375, 0.82697, 1.084934, 1.656421, 0.786079, -1.580991, 1.753751, -0.242525, 1.854008],\r\n                     'Class': [1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1]})\r\n\r\nsetup(data = data,\r\ntarget = 'Class', \r\nexperiment_name = 'xgb_test', \r\nfix_imbalance = True,\r\nlog_experiment = True, \r\nsilent=True, \r\nuse_gpu=True,\r\nfold=5,\r\npreprocess=False)\r\n\r\nmodels = ['xgboost','knn','rf']\r\ntop_models = compare_models(include = model)\r\ndd = pull()\n```\n\n\n### Expected Behavior\n\nArtifacts and metrics should be crated. \n\n### Actual Results\n\n```python-traceback\nError from logs.log:\r\n\r\n2022-08-09 06:11:05,384:ERROR:dashboard_logger.log_model() for XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\r\n              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\r\n              early_stopping_rounds=None, enable_categorical=False,\r\n              eval_metric=None, feature_types=None, gamma=0, gpu_id=0,\r\n              grow_policy='depthwise', importance_type=None,\r\n              interaction_constraints='', learning_rate=0.300000012,\r\n              max_bin=256, max_cat_to_onehot=4, max_delta_step=0, max_depth=6,\r\n              max_leaves=0, min_child_weight=1, missing=nan,\r\n              monotone_constraints='()', n_estimators=100, n_jobs=-1,\r\n              num_parallel_tree=1, objective='binary:logistic',\r\n              predictor='auto', random_state=989, ...) raised an exception:\r\n2022-08-09 06:11:05,385:ERROR:Traceback (most recent call last):\r\n  File \"\/home\/vscode\/.local\/lib\/python3.8\/site-packages\/pycaret\/internal\/tabular.py\", line 2362, in compare_models\r\n    dashboard_logger.log_model(\r\n  File \"\/home\/vscode\/.local\/lib\/python3.8\/site-packages\/pycaret\/loggers\/__init__.py\", line 93, in log_model\r\n    logger.log_params(params, model_name=full_name)\r\n  File \"\/home\/vscode\/.local\/lib\/python3.8\/site-packages\/pycaret\/loggers\/mlflow_logger.py\", line 46, in log_params\r\n    mlflow.log_params(params)\r\n  File \"\/usr\/local\/envs\/Jun_24_2022\/lib\/python3.8\/site-packages\/mlflow\/tracking\/fluent.py\", line 675, in log_params\r\n    MlflowClient().log_batch(run_id=run_id, metrics=[], params=params_arr, tags=[])\r\n  File \"\/usr\/local\/envs\/Jun_24_2022\/lib\/python3.8\/site-packages\/mlflow\/tracking\/client.py\", line 918, in log_batch\r\n    self._tracking_client.log_batch(run_id, metrics, params, tags)\r\n  File \"\/usr\/local\/envs\/Jun_24_2022\/lib\/python3.8\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py\", line 315, in log_batch\r\n    self.store.log_batch(\r\n  File \"\/usr\/local\/envs\/Jun_24_2022\/lib\/python3.8\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 309, in log_batch\r\n    self._call_endpoint(LogBatch, req_body)\r\n  File \"\/usr\/local\/envs\/Jun_24_2022\/lib\/python3.8\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 56, in _call_endpoint\r\n    return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)\r\n  File \"\/usr\/local\/envs\/Jun_24_2022\/lib\/python3.8\/site-packages\/mlflow\/utils\/rest_utils.py\", line 256, in call_endpoint\r\n    response = verify_rest_response(response, endpoint)\r\n  File \"\/usr\/local\/envs\/Jun_24_2022\/lib\/python3.8\/site-packages\/mlflow\/utils\/rest_utils.py\", line 185, in verify_rest_response\r\n    raise RestException(json.loads(response.text))\r\nmlflow.exceptions.RestException: INVALID_PARAMETER_VALUE: Invalid value [{'key': 'objective', 'value': 'binary:logistic'}, {'key': 'use_label_encoder', 'value': 'None'}, {'key': 'base_score', 'value': '0.5'}, {'key': 'booster', 'value': 'gbtree'}, {'key': 'callbacks', 'value': 'None'}, {'key': 'colsample_bylevel', 'value': '1'}, {'key': 'colsample_bynode', 'value': '1'}, {'key': 'colsample_bytree', 'value': '1'}, {'key': 'early_stopping_rounds', 'value': 'None'}, {'key': 'enable_categorical', 'value': 'False'}, {'key': 'eval_metric', 'value': 'None'}, {'key': 'feature_types', 'value': 'None'}, {'key': 'gamma', 'value': '0'}, {'key': 'gpu_id', 'value': '0'}, {'key': 'grow_policy', 'value': 'depthwise'}, {'key': 'importance_type', 'value': 'None'}, {'key': 'interaction_constraints', 'value': ''}, {'key': 'learning_rate', 'value': '0.300000012'}, {'key': 'max_bin', 'value': '256'}, {'key': 'max_cat_to_onehot', 'value': '4'}, {'key': 'max_delta_step', 'value': '0'}, {'key': 'max_depth', 'value': '6'}, {'key': 'max_leaves', 'value': '0'}, {'key': 'min_child_weight', 'value': '1'}, {'key': 'missing', 'value': 'nan'}, {'key': 'monotone_constraints', 'value': '()'}, {'key': 'n_estimators', 'value': '100'}, {'key': 'n_jobs', 'value': '-1'}, {'key': 'num_parallel_tree', 'value': '1'}, {'key': 'predictor', 'value': 'auto'}, {'key': 'random_state', 'value': '989'}, {'key': 'reg_alpha', 'value': '0'}, {'key': 'reg_lambda', 'value': '1'}, {'key': 'sampling_method', 'value': 'uniform'}, {'key': 'scale_pos_weight', 'value': '1'}, {'key': 'subsample', 'value': '1'}, {'key': 'tree_method', 'value': 'gpu_hist'}, {'key': 'validate_parameters', 'value': '1'}, {'key': 'verbosity', 'value': '0'}] for parameter 'params' supplied. Hint: Value was of type 'list'. See the API docs for more information about request parameters.\n```\n\n\n### Installed Versions\n\n<details>\r\npycaret- Version: 2.3.10 <\/br>\r\nmlflow- Version: 1.27.0 <\/br>\r\nxgboost-  Version: 2.0.0.dev0 <\/br>\r\n<\/details>\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"With new mlflow release-1.28.0- and **[Tracking \/ Model Registry] Fix an mlflow server bug that rejected parameters and tags with empty string values (https:\/\/github.com\/mlflow\/mlflow\/pull\/6179, @dbczumar)** bug fixed, the problem no longer occurs and artifacts are saved correctly",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"bug server integr pycaret version check check issu report http github com pycaret pycaret issu confirm bug exist latest version http github com pycaret pycaret releas pycaret confirm bug exist master branch pycaret pip instal git http github com pycaret pycaret git master issu descript problem save xgboost run server run statu unfinish metric artifact creat imag http user imag githubusercont com debf ccaf png us fine run server sqlite backend store problem occur command run server server host port default artifact root artifact backend store uri sqlite experi reproduc exampl python import pycaret classif import import panda set track uri http localhost data datafram class setup data data target class experi xgb test fix imbal true log experi true silent true us gpu true fold preprocess fals model xgboost knn model compar model includ model pull expect behavior artifact metric crate actual result python traceback error log log error dashboard logger log model xgbclassifi base score booster gbtree callback colsampl bylevel colsampl bynod colsampl bytre earli stop round enabl categor fals eval metric featur type gamma gpu grow polici depthwis import type interact constraint learn rate max bin max cat onehot max delta step max depth max leav min child weight miss nan monoton constraint estim job num parallel tree object binari logist predictor auto random state rais except error traceback recent file home vscode local lib python site packag pycaret intern tabular line compar model dashboard logger log model file home vscode local lib python site packag pycaret logger init line log model logger log param param model file home vscode local lib python site packag pycaret logger logger line log param log param param file usr local env jun lib python site packag track fluent line log param client log batch run run metric param param arr tag file usr local env jun lib python site packag track client line log batch self track client log batch run metric param tag file usr local env jun lib python site packag track track servic client line log batch self store log batch file usr local env jun lib python site packag store track rest store line log batch self endpoint logbatch req bodi file usr local env jun lib python site packag store track rest store line endpoint return endpoint self host cred endpoint method json bodi respons proto file usr local env jun lib python site packag util rest util line endpoint respons verifi rest respons respons endpoint file usr local env jun lib python site packag util rest util line verifi rest respons rais restexcept json load respons text except restexcept invalid paramet valu invalid valu kei object valu binari logist kei us label encod valu kei base score valu kei booster valu gbtree kei callback valu kei colsampl bylevel valu kei colsampl bynod valu kei colsampl bytre valu kei earli stop round valu kei enabl categor valu fals kei eval metric valu kei featur type valu kei gamma valu kei gpu valu kei grow polici valu depthwis kei import type valu kei interact constraint valu kei learn rate valu kei max bin valu kei max cat onehot valu kei max delta step valu kei max depth valu kei max leav valu kei min child weight valu kei miss valu nan kei monoton constraint valu kei estim valu kei job valu kei num parallel tree valu kei predictor valu auto kei random state valu kei reg alpha valu kei reg lambda valu kei sampl method valu uniform kei scale po weight valu kei subsampl valu kei tree method valu gpu hist kei valid paramet valu kei verbos valu paramet param suppli hint valu type list api doc inform request paramet instal version pycaret version version xgboost version dev",
        "Issue_preprocessed_content":"server integr pycaret version check check report confirm bug exist pycaret confirm bug exist master branch pycaret descript problem save run server run statu unfinish metric artifact creat us fine run server sqlite backend store problem run server reproduc exampl expect behavior artifact metric crate actual result version detail pycaret version version version detail",
        "Issue_gpt_summary_original":"The user is encountering an error while running \"mlflow ui\" which results in a \"FileNotFoundError\". The expected behavior is for it to run without any issues. The version being used is 2.3.10.",
        "Issue_gpt_summary":"user encount error run result filenotfounderror expect behavior run issu version",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/pycaret\/pycaret\/issues\/2811",
        "Issue_title":"[BUG]: mlflow incorrectly logging models \"Lasso Least Angle Regression\" and \"Least Angle Regression\"",
        "Issue_created_time":1659210438000,
        "Issue_closed_time":1670522892000,
        "Issue_body":"### pycaret version checks\n\n- [X] I have checked that this issue has not already been reported [here](https:\/\/github.com\/pycaret\/pycaret\/issues).\n\n- [X] I have confirmed this bug exists on the [latest version](https:\/\/github.com\/pycaret\/pycaret\/releases) of pycaret.\n\n- [X] I have confirmed this bug exists on the master branch of pycaret (pip install -U git+https:\/\/github.com\/pycaret\/pycaret.git@master).\n\n\n### Issue Description\n\nmlflow logs the name of both models \"Least Angle Regression\" and \"Lasso Least Angle Regression\" as \"Least Angle Regression\".\r\n\r\nWhen looking into the `get_logs()` you can see both of those models have unique `run_id` but both have the same `tags.mlflow.runName`.\r\n\r\nPython Version: 3.9.5\r\nPyCaret Version: '3.0.0.rc3'\r\nPandas Version: 1.4.3\r\n\n\n### Reproducible Example\n\n```python\nimport pandas as pd\r\nfrom pycaret.regression import *\r\nfrom pycaret.datasets import get_data\r\ndataset = get_data('diamond')\r\n\r\nEXPERIMENT_NAME = 'diamond_experiment'\r\ns = setup(data=dataset, target='Price', log_experiment=True, experiment_name=EXPERIMENT_NAME, session_id=42, verbose=True)\r\n\r\nmodel = compare_models(verbose=False)\r\n\r\nprint(f\"Notice Least Angle Regression is not unique:\\n{get_logs(experiment_name=EXPERIMENT_NAME)['tags.mlflow.runName'].value_counts()}\")\r\n\r\n# Loop through all models in the `compare_models()` (20 models) function and get the length of the dataframe of that specific model in the logs\r\n# There should be a single unique value for each model\r\nfor model in pull().Model.tolist():\r\n    print(f\"{model} - {len(get_logs(experiment_name=EXPERIMENT_NAME)[get_logs(experiment_name=EXPERIMENT_NAME)['tags.mlflow.runName'] == model])}\")\r\n\r\n# Further investigation: model Least Angle Regression has 2 instances (should be Lasso Least Angle Regression and Least Angle Regression)\r\nget_logs(experiment_name=EXPERIMENT_NAME)[get_logs(experiment_name=EXPERIMENT_NAME)['tags.mlflow.runName'] == 'Least Angle Regression']\r\n```\n```\n\n\n### Expected Behavior\n\n`tags.mlflow.runName` parameter from `get_logs()` is unique (given a single experiment) and contains all model names from `compare_models()`\n\n### Actual Results\n\n```python-traceback\nWhen looking into the `tags.mlflow.runName` you can see they are all unique but Least Angle Regression is there twice and Lasso Least Angle Regression isn't there at all. Could this be logged incorrectly?\r\n\r\nGradient Boosting Regressor - 1\r\nCatBoost Regressor - 1\r\nLight Gradient Boosting Machine - 1\r\nExtreme Gradient Boosting - 1\r\nLasso Regression - 1\r\nRidge Regression - 1\r\nLinear Regression - 1\r\nLasso Least Angle Regression - 0\r\nLeast Angle Regression - 2\r\nExtra Trees Regressor - 1\r\nRandom Forest Regressor - 1\r\nAdaBoost Regressor - 1\r\nDecision Tree Regressor - 1\r\nOrthogonal Matching Pursuit - 1\r\nElastic Net - 1\r\nHuber Regressor - 1\r\nBayesian Ridge - 1\r\nK Neighbors Regressor - 1\r\nDummy Regressor - 1\r\nPassive Aggressive Regressor - 1\n```\n\n\n### Installed Versions\n\n<details>\r\nSystem:\r\n    python: 3.9.5 (v3.9.5:0a7dcbdb13, May  3 2021, 13:17:02)  [Clang 6.0 (clang-600.0.57)]\r\nexecutable: PATH_TO_ENV\/venv\/bin\/python\r\n   machine: macOS-10.16-x86_64-i386-64bit\r\n\r\nPyCaret required dependencies:\r\n                 pip: 21.1.1\r\n          setuptools: 56.0.0\r\n             pycaret: 3.0.0.rc3\r\n             IPython: 8.4.0\r\n          ipywidgets: 8.0.0rc0\r\n                tqdm: 4.64.0\r\n               numpy: 1.21.6\r\n              pandas: 1.4.3\r\n              jinja2: 3.1.2\r\n               scipy: 1.5.4\r\n              joblib: 1.1.0\r\n             sklearn: 1.1.1\r\n                pyod: Installed but version unavailable\r\n            imblearn: 0.9.1\r\n   category_encoders: 2.5.0\r\n            lightgbm: 3.3.2\r\n               numba: 0.55.2\r\n            requests: 2.28.0\r\n          matplotlib: 3.5.2\r\n          scikitplot: 0.3.7\r\n         yellowbrick: 1.4\r\n              plotly: 5.9.0\r\n             kaleido: 0.2.1\r\n         statsmodels: 0.13.2\r\n              sktime: 0.11.4\r\n               tbats: Installed but version unavailable\r\n            pmdarima: 1.8.5\r\n              psutil: 5.9.1\r\n<\/details>\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"@Yard1 Can you give me a hand here? I ended up spending a lot of time in figuring out where is it coming from. The names inside `containers\/regression.py` seems to be fine but even then the run name is wrong.\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/54699234\/204138706-db0d0cc3-9a08-46d3-8037-fbaee414876b.png)\r\n\r\nAny ideas?",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"bug incorrectli log model lasso angl regress angl regress pycaret version check check issu report http github com pycaret pycaret issu confirm bug exist latest version http github com pycaret pycaret releas pycaret confirm bug exist master branch pycaret pip instal git http github com pycaret pycaret git master issu descript log model angl regress lasso angl regress angl regress look log model uniqu run tag runnam python version pycaret version panda version reproduc exampl python import panda pycaret regress import pycaret dataset import data dataset data diamond experi diamond experi setup data dataset target price log experi true experi experi session verbos true model compar model verbos fals print notic angl regress uniqu log experi experi tag runnam valu count loop model compar model model function length datafram specif model log singl uniqu valu model model pull model tolist print model len log experi experi log experi experi tag runnam model investig model angl regress instanc lasso angl regress angl regress log experi experi log experi experi tag runnam angl regress expect behavior tag runnam paramet log uniqu given singl experi contain model name compar model actual result python traceback look tag runnam uniqu angl regress twice lasso angl regress isn log incorrectli gradient boost regressor catboost regressor light gradient boost machin extrem gradient boost lasso regress ridg regress linear regress lasso angl regress angl regress extra tree regressor random forest regressor adaboost regressor decis tree regressor orthogon match pursuit elast net huber regressor bayesian ridg neighbor regressor dummi regressor passiv aggress regressor instal version python adcbdb clang clang execut path env venv bin python machin maco bit pycaret requir depend pip setuptool pycaret ipython ipywidget tqdm numpi panda jinja scipi joblib sklearn pyod instal version unavail imblearn categori encod lightgbm numba request matplotlib scikitplot yellowbrick plotli kaleido statsmodel sktime tbat instal version unavail pmdarima psutil",
        "Issue_preprocessed_content":"model angl angl pycaret version check check report confirm bug exist pycaret confirm bug exist master branch pycaret descript log model angl angl angl model uniqu python version pycaret version panda version reproduc exampl uniqu angl twice angl isn gradient light gradient machin extrem gradient ridg linear angl angl extra random forest decis orthogon match pursuit elast net huber bayesian ridg neighbor version detail python execut machin pycaret requir depend pip pycaret ipython ipywidget tqdm numpi panda jinja scipi joblib sklearn pyod version unavail imblearn lightgbm numba request matplotlib scikitplot plotli kaleido statsmodel sktime tbat version unavail pmdarima psutil detail",
        "Issue_gpt_summary_original":"The user is encountering a bug in the Mlflow Timeseries_beta branch where setting log_plot to True results in an error in the self._mlflow_log_model() function due to a 'bool' object not being iterable.",
        "Issue_gpt_summary":"user encount bug timeseri beta branch set log plot true result error self log model function bool object iter",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/pycaret\/pycaret\/issues\/2801",
        "Issue_title":"[BUG]: pycaret + mlflow integration does not allow probabilities for classification and binary response models",
        "Issue_created_time":1658846256000,
        "Issue_closed_time":1669247416000,
        "Issue_body":"### pycaret version checks\n\n- [X] I have checked that this issue has not already been reported [here](https:\/\/github.com\/pycaret\/pycaret\/issues).\n\n- [X] I have confirmed this bug exists on the [latest version](https:\/\/github.com\/pycaret\/pycaret\/releases) of pycaret.\n\n- [ ] I have confirmed this bug exists on the master branch of pycaret (pip install -U git+https:\/\/github.com\/pycaret\/pycaret.git@master).\n\n\n### Issue Description\n\nWe have been using pycaret 2.2 for the model training procedure and registration to the mlflow server. (python based) My company uses a managed version of this in Azure Databricks. After the registration has been completed, we call the calibrated algorithm in a separate notebook and are trying to score new data with a binary response 0|1. We would also like to leverage the scikit learn function \"predict_model\" to create the probabilities in addition to the predicted value. This is not working in pycaret and appears to be a bug of some sort. It is also important to note that we are able to see the \"predict_model\" during the model training but not when we call the algorithm for a separate scoring function. \n\n### Reproducible Example\n\n```python\n# import mlflow.sklearn\r\n# model = mlflow.sklearn.load_model(production_algorithm)\r\n# model.predict_prob(X)\n```\n\n\n### Expected Behavior\n\nwe should see the probabilities model.predict_prob(X) but this code errors out. Another example would be the following: predictions_prob = production_algorithm.predict_prob(pd.DataFrame(X))\r\n\n\n### Actual Results\n\n```python-traceback\nthe end result of the prediction should be a numeric value between 0 and 1. Ex. 0.4278\n```\n\n\n### Installed Versions\n\n<details>\r\nSystem:\r\n    python: 3.8.10 (default, Mar 15 2022, 12:22:08)  [GCC 9.4.0]\r\nexecutable: \/local_disk0\/.ephemeral_nfs\/envs\/pythonEnv-ca5e1db9-faed-4291-83c9-f55dfcbb8112\/bin\/python\r\n   machine: Linux-5.4.0-1083-azure-x86_64-with-glibc2.29\r\n\r\nPyCaret required dependencies:\r\n                 pip: 21.0.1\r\n          setuptools: 52.0.0\r\n             pycaret: 3.0.0.rc3\r\n             IPython: 7.22.0\r\n          ipywidgets: 7.7.1\r\n                tqdm: 4.64.0\r\n               numpy: 1.21.6\r\n              pandas: 1.4.3\r\n              jinja2: 3.1.2\r\n               scipy: 1.6.2\r\n              joblib: 1.1.0\r\n             sklearn: 1.1.1\r\n                pyod: Installed but version unavailable\r\n            imblearn: 0.8.1\r\n   category_encoders: 2.5.0\r\n            lightgbm: 3.3.2\r\n               numba: 0.55.1\r\n            requests: 2.28.1\r\n          matplotlib: 3.4.2\r\n          scikitplot: 0.3.7\r\n         yellowbrick: 1.4\r\n              plotly: 5.9.0\r\n             kaleido: 0.2.1\r\n         statsmodels: 0.12.2\r\n              sktime: 0.11.4\r\n               tbats: Installed but version unavailable\r\n            pmdarima: 1.8.4\r\n              psutil: 5.9.1\r\n<\/details>\r\n",
        "Issue_answer_count":2,
        "Issue_self_closed":0.0,
        "Answer_body":"@DerekKane We need more details than `code error out` to be able to help. Just tested this scenario with latest pycaret==3.0.0rc4 and it works fine.\r\n\r\nIf you are still facing issue, please feel free to open new ticket.",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"bug pycaret integr allow probabl classif binari respons model pycaret version check check issu report http github com pycaret pycaret issu confirm bug exist latest version http github com pycaret pycaret releas pycaret confirm bug exist master branch pycaret pip instal git http github com pycaret pycaret git master issu descript pycaret model train procedur registr server python base compani us manag version azur databrick registr complet calibr algorithm separ notebook try score new data binari respons like leverag scikit learn function predict model creat probabl addit predict valu work pycaret appear bug sort import note abl predict model model train algorithm separ score function reproduc exampl python import sklearn model sklearn load model product algorithm model predict prob expect behavior probabl model predict prob code error exampl follow predict prob product algorithm predict prob datafram actual result python traceback end result predict numer valu instal version python default mar gcc execut local disk ephemer nf env pythonenv caedb fa fdfcbb bin python machin linux azur glibc pycaret requir depend pip setuptool pycaret ipython ipywidget tqdm numpi panda jinja scipi joblib sklearn pyod instal version unavail imblearn categori encod lightgbm numba request matplotlib scikitplot yellowbrick plotli kaleido statsmodel sktime tbat instal version unavail pmdarima psutil",
        "Issue_preprocessed_content":"pycaret integr probabl binari respons model pycaret version check check report confirm bug exist pycaret confirm bug exist master branch pycaret descript pycaret model train procedur registr server compani us manag version azur databrick registr complet calibr algorithm separ try score new data binari respons like leverag scikit learn function creat probabl predict valu work pycaret bug sort import note abl model train algorithm separ score function reproduc exampl expect behavior probabl code exampl actual result version detail python execut machin pycaret requir depend pip pycaret ipython ipywidget tqdm numpi panda jinja scipi joblib sklearn pyod version unavail imblearn lightgbm numba request matplotlib scikitplot plotli kaleido statsmodel sktime tbat version unavail pmdarima psutil detail",
        "Issue_gpt_summary_original":"The user is facing a bug where some plot types, such as \"calibration\" and \"feature\", are not being saved to the MLFlow experiment artifacts directory. The issue seems to be with inconsistent naming for the saved png for certain plot types. The user expects all plot types to be logged under the MLFlow artifacts directory, but \"feature.png\" and \"calibration.png\" are saved to the working directory. The user suspects that the issue is with inconsistent naming of the file. The user is using Python 3.8.11 and Pycaret 2.3.4.",
        "Issue_gpt_summary":"user face bug plot type calibr featur save experi artifact directori issu inconsist name save png certain plot type user expect plot type log artifact directori featur png calibr png save work directori user suspect issu inconsist name file user python pycaret",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/pycaret\/pycaret\/issues\/2581",
        "Issue_title":"mlflow ui doesn't show any models",
        "Issue_created_time":1653399055000,
        "Issue_closed_time":1653501835000,
        "Issue_body":"### pycaret version checks\n\n- [X] I have checked that this issue has not already been reported [here](https:\/\/github.com\/pycaret\/pycaret\/issues).\n\n- [X] I have confirmed this bug exists on the [latest version](https:\/\/github.com\/pycaret\/pycaret\/releases) of pycaret.\n\n- [X] I have confirmed this bug exists on the develop branch of pycaret (pip install -U git+https:\/\/github.com\/pycaret\/pycaret.git@develop).\n\n\n### Issue Description\n\nI have tried both the nightly and the release branch, and read the issues posted here:\r\nhttps:\/\/github.com\/pycaret\/pycaret\/issues?q=is%3Aissue+mlflow+ui+is%3Aclosed\r\n\r\nI do not see any models in the `mlflow ui` *during training*, while several models have already converged and logged to the file system. I see some models have already reported AUC, MSE, etc. but as shows below, nothing is present in the dashboard\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/31047807\/170046175-c0a85a9b-21e4-4a07-891f-7d58fcc5f579.png)\r\n\r\nThanks!\r\n\n\n### Reproducible Example\n\n```python\ntraining_data = pd.read_pickle(\"\/cached_db\")\r\n\r\n\r\nexp_reg102 = classification.setup(data=training_data, target=args.label, session_id=123,\r\n                                  preprocess=True, feature_selection=True, fix_imbalance=True, \r\n                                  remove_perfect_collinearity=False,\r\n                                  log_experiment=True, \r\n                                  log_plots=True, profile=False, log_profile=False,\r\n                                  silent=True,\r\n                                  n_jobs=-1,\r\n                                  fold=2,\r\n                                  )\r\n\r\nbest_models = classification.compare_models(turbo=True, n_select=3,errors='raise')\n```\n\n\n### Expected Behavior\n\nBeing able to see the models that have already converged\n\n### Actual Results\n\n```python-traceback\nNo model is present in the `mlflow ui` dashboard\n```\n\n\n### Installed Versions\n\n2.3.10",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"Creating a clean env and installing pycaret again solved the issue.",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"model pycaret version check check issu report http github com pycaret pycaret issu confirm bug exist latest version http github com pycaret pycaret releas pycaret confirm bug exist develop branch pycaret pip instal git http github com pycaret pycaret git develop issu descript tri nightli releas branch read issu post http github com pycaret pycaret issu aissu aclos model train model converg log file model report auc mse show present dashboard imag http user imag githubusercont com caab dfccf png thank reproduc exampl python train data read pickl cach exp reg classif setup data train data target arg label session preprocess true featur select true fix imbal true remov perfect collinear fals log experi true log plot true profil fals log profil fals silent true job fold best model classif compar model turbo true select error rais expect behavior abl model converg actual result python traceback model present dashboard instal version",
        "Issue_preprocessed_content":"model pycaret version check check report confirm bug exist pycaret confirm bug exist develop branch pycaret descript tri nightli releas branch read post model train model converg file model report auc mse show present dashboard thank reproduc exampl expect behavior abl model converg actual result version",
        "Issue_gpt_summary_original":"The user is facing an issue with MLFlow logging in the `compare_models` function of time series. While the parameters are logged, metrics and artifacts are not being logged, causing all runs to fail. However, the user is able to use the `create_model` function without any issues.",
        "Issue_gpt_summary":"user face issu log compar model function time seri paramet log metric artifact log caus run fail user abl us creat model function issu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/pycaret\/pycaret\/issues\/2439",
        "Issue_title":"plots are not saving through MLFLOW",
        "Issue_created_time":1650342119000,
        "Issue_closed_time":1650470329000,
        "Issue_body":"This is the error I get  \"plot_model() got an unexpected keyword argument 'system'\"\r\n\r\n",
        "Issue_answer_count":5,
        "Issue_self_closed":0.0,
        "Answer_body":"@akashg116414 We can't help you with this. Can you please describe a little bit more, show the code, show the complete error, etc. this error happens when i install pycaret[full]==2.3.9 and pycaret-ts-alpha both and tried basic classification example\r\nexample:\r\n\r\n```python\r\nfrom pycaret.datasets import get_data\r\ndata = get_data('juice')\r\nfrom pycaret.classification import *\r\nclf1 = setup(data, target = 'Purchase', session_id=123, log_experiment=True, experiment_name='juice1',log_plots=True)\r\n``` > this error happens when i install pycaret[full]==2.3.9 and pycaret-ts-alpha both and tried basic classification example\r\n\r\nAre you installing both of them in the same environment? That should not be done as there may be conflicts at this time (until we officially release the 3.0.0 pycaret version which will have time-series integrated with the main pycaret package).\r\n\r\nTry installing one of them in a fresh (clean) environment and see if it works. @akashg116414 By the way, I am not able to recreate the issue with the information (code) you have provided. It works fine for me (see attached notebook below).\r\n\r\nhttps:\/\/gist.github.com\/ngupta23\/f7f33a5361928cac2f36f855f7398c88\r\n\r\nPlease provide a completely reproducible example that shows the steps to get to the error you are getting. Since we are unable to recreate this and information seems to be missing, we will close this for now. Feel free to create a new issue. We add a new Bug template that will guide you through the process of submitting a reproducible example. \r\n\r\nThanks!",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"plot save error plot model got unexpect keyword argument",
        "Issue_preprocessed_content":"plot save got unexpect keyword argument",
        "Issue_gpt_summary_original":"The user is encountering a bug while trying to store mlflow artifacts in Azure blob storage for new experiments in pycaret. The issue occurs when an experiment name is given to the pycaret setup function, causing the artifacts to be stored in the local directory instead of the Azure blob.",
        "Issue_gpt_summary":"user encount bug try store artifact azur blob storag new experi pycaret issu occur experi given pycaret setup function caus artifact store local directori instead azur blob",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/pycaret\/pycaret\/issues\/2425",
        "Issue_title":"[BUG] mlflow ui never runs",
        "Issue_created_time":1650277642000,
        "Issue_closed_time":1650449956000,
        "Issue_body":"**Describe the bug**\r\nGetting error \"FileNotFoundError: [WinError 2] The system cannot find the file specified\" while running \"mlflow ui\".\r\n\r\n**To Reproduce**\r\nRun \"mlflow ui\"\r\n\r\n\r\n**Expected behavior**\r\nIt should run without any issues\r\n\r\n\r\n**Versions**\r\n2.3.10\r\n\r\nNot sure if this is the right forum to post this issue. If it is not, please ignore.\r\n<!-- Thanks for contributing! -->\r\n",
        "Issue_answer_count":6,
        "Issue_self_closed":0.0,
        "Answer_body":"@maverick-scientist there is not enough information here to recreate or debug the issue. Please provide a complete reproducible example so we can debug. Also, note that if the data is proprietary, you can create a fake dataset yourself to recreate the issue. Refer to the following for more details:\r\n\r\n\ud83d\udccc Overview: http:\/\/ow.ly\/LoIv50IL5RQ\r\n\ud83d\udccc Examples (Do's and Dont's): http:\/\/ow.ly\/AXKm50IL5RR\r\n\r\n- The do's and dont's have an example of how to create the fake data - minimal to reproduce the problem.\r\n- Alternately, you could try to reproduce the issue with a publicly available dataset or one available in pycaret itself.\r\n\r\nThanks!\r\n Hi Nikhil,\nCan we please discuss this over teams call? I can share a python file with\nyou for this issue but I feel if we can discuss this on a call it would\nsave me some time.\n\nWhat do you think?\n\nPlease advise.\n\nOn Mon, 18 Apr 2022 at 22:55, Nikhil Gupta ***@***.***> wrote:\n\n> @maverick-scientist <https:\/\/github.com\/maverick-scientist> there is not\n> enough information here to recreate or debug the issue. Please provide a\n> complete reproducible example so we can debug. Also, note that if the data\n> is proprietary, you can create a fake dataset yourself to recreate the\n> issue. Refer to the following for more details:\n>\n> \ud83d\udccc Overview: http:\/\/ow.ly\/LoIv50IL5RQ\n> \ud83d\udccc Examples (Do's and Dont's): http:\/\/ow.ly\/AXKm50IL5RR\n>\n>    - The do's and dont's have an example of how to create the fake data -\n>    minimal to reproduce the problem.\n>    - Alternately, you could try to reproduce the issue with a publicly\n>    available dataset or one available in pycaret itself.\n>\n> Thanks!\n>\n> \u2014\n> Reply to this email directly, view it on GitHub\n> <https:\/\/github.com\/pycaret\/pycaret\/issues\/2425#issuecomment-1101586641>,\n> or unsubscribe\n> <https:\/\/github.com\/notifications\/unsubscribe-auth\/AUVHRACMIA55LOVAGIZZKPLVFWLKHANCNFSM5TVQ4MTQ>\n> .\n> You are receiving this because you were mentioned.Message ID:\n> ***@***.***>\n>\n @maverick-scientist Honestly, I would prefer not to do that since it sets the wrong precedent for the open-source community and is not sustainable in the long run. The globally accepted best practice is to provide a minimal reproducible example and I would encourage you to do that.\r\n\r\nThanks! Hi Nikhil,\r\nAttaching the code file to reproduce this issue. Could you please check and tell me what's wrong with it or my machine?\r\n\r\nThanks & Regards,\r\nAbhinav\r\n\r\n[Simple MLflow.zip](https:\/\/github.com\/pycaret\/pycaret\/files\/8511837\/Simple.MLflow.zip)\r\n\r\n @maverick-scientist The example that you posted has no reference to pycaret. It is a generic MLFlow example. How is it related to pycaret and this repo? Hi Nikhil,\nThank you for your reply. However, if you read the issue carefully, I\u2019d\nclearly mentioned my dilemma whether it was the right forum to post this\nissue.\n\nAnyways, thanks for your support. I\u2019d try and see what\u2019s preventing the\nMLFlow to run properly on my machine.\n\nOn Wed, 20 Apr 2022 at 15:21, Nikhil Gupta ***@***.***> wrote:\n\n> @maverick-scientist <https:\/\/github.com\/maverick-scientist> The example\n> that you posted has no reference to pycaret. It is a generic MLFlow\n> example. How is it related to pycaret and this repo?\n>\n> \u2014\n> Reply to this email directly, view it on GitHub\n> <https:\/\/github.com\/pycaret\/pycaret\/issues\/2425#issuecomment-1103727978>,\n> or unsubscribe\n> <https:\/\/github.com\/notifications\/unsubscribe-auth\/AUVHRADHBVLOBH4SACXZHNLVF7HTHANCNFSM5TVQ4MTQ>\n> .\n> You are receiving this because you were mentioned.Message ID:\n> ***@***.***>\n>\n",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"bug run bug get error filenotfounderror winerror file specifi run reproduc run expect behavior run issu version sure right forum post issu ignor",
        "Issue_preprocessed_content":"run bug file specifi reproduc run expect behavior run version sure right forum post ignor thank contribut",
        "Issue_gpt_summary_original":"the user encountered challenges with pycaret's clustering module, such as not saving model artifacts and some plots, and the status always failing.",
        "Issue_gpt_summary":"user encount challeng pycaret cluster modul save model artifact plot statu fail",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/pycaret\/pycaret\/issues\/1736",
        "Issue_title":"[BUG] Issue with Mlflow Timeseries_beta branch",
        "Issue_created_time":1634814038000,
        "Issue_closed_time":1635811087000,
        "Issue_body":"if in setup log_plot set True then it is giving error in self._mlflow_log_model() as \r\nfor plot in log_plots:\r\nTypeError: 'bool' object is not iterable",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"bug issu timeseri beta branch setup log plot set true give error self log model plot log plot typeerror bool object iter",
        "Issue_preprocessed_content":"branch setup set true give plot object iter",
        "Issue_gpt_summary_original":"The user encountered an MLFlowException error while trying to compare models using the Titanic dataset in pycaret 2.1. The error message suggests that the issue is related to the mapping of 'np.object' type to MLflow DataType. The same code worked fine in pycaret 2.0.",
        "Issue_gpt_summary":"user encount except error try compar model titan dataset pycaret error messag suggest issu relat map object type datatyp code work fine pycaret",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/pycaret\/pycaret\/issues\/1674",
        "Issue_title":"[BUG] some types plot types are not getting saved to the MLFlow experiment artifacts dir",
        "Issue_created_time":1634052175000,
        "Issue_closed_time":1635405096000,
        "Issue_body":"**Describe the bug**\r\nThank you for creating such a helpful tool!\r\nThe problem i'm facing is that some types plot types (e.g. \"calibration\" and \"feature\") are not getting saved to the MLFlow experiment artifacts dir. I think the issue is with inconsistent naming for the saved png for certain plot types.\r\nThank you for your help!\r\n<!--\r\n-->\r\n\r\n**To Reproduce**\r\n<!--\r\nAdd a Minimal, Complete, and Verifiable example (for more details, see e.g. https:\/\/stackoverflow.com\/help\/mcve\r\n\r\nIf the code is too long, feel free to put it in a public gist and link it in the issue: https:\/\/gist.github.com\r\n-->\r\n\r\n```python\r\nfrom pycaret.classification import *\r\n\r\nfrom pycaret.datasets import get_data\r\ndataset = get_data('credit')\r\n\r\n  pycaret_env = setup(\r\n      data = data, \r\n      target = 'default', \r\n      html=False, \r\n      silent=True,\r\n      verbose=False,\r\n      # for MLFlow logging:\r\n      experiment_name=\"plot_test\",\r\n      log_experiment = True, \r\n      log_plots=['auc', 'feature', 'parameter', 'pr', 'calibration', 'confusion_matrix'],\r\n  )\r\n\r\n  model = create_model(\"lightgbm\")\r\n```\r\n\r\n**Expected behavior**\r\n<!--\r\n-->\r\nI expect ALL of the plot types to be logged under the MLFlow artifacts dir i.e. \/mlruns\/{experiment number}\/{id}\/artifacts\/\r\nHowever, \"feature.png\" and \"calibration.png\" are saved to the working directory.\r\n\r\n**Additional context**\r\n<!--\r\nAdd any other context about the problem here.\r\n-->\r\nI think the issue is with inconsistent naming of the file. Here is a printout of the log when it tries to save the calibration plot:\r\n```\r\n2021-10-11 19:03:19,845:INFO:Saving 'calibration.png'\r\n2021-10-11 19:03:20,064:INFO:Visual Rendered Successfully\r\n2021-10-11 19:03:20,213:INFO:plot_model() succesfully completed......................................\r\n2021-10-11 19:03:20,217:WARNING:[Errno 2] No such file or directory: 'Calibration Curve.png'\r\n```\r\nSo you can see that it is looking for 'Calibration Curve.png', but what actually gets produced is 'calibration.png'.\r\n\r\n**Versions**\r\nPython 3.8.11\r\n\r\n<!--\r\nPlease run the following code snippet and paste the output here:\r\n \r\nimport pycaret\r\npycaret.__version__\r\n\r\n-->\r\nPycaret 2.3.4\r\n\r\n<\/details>\r\n\r\n<!-- Thanks for contributing! -->\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"@ejohnson-amerilife Thank you so much for bringing this up. Would you like to submit a PR for this? ",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"bug type plot type get save experi artifact dir bug thank creat help tool problem face type plot type calibr featur get save experi artifact dir think issu inconsist name save png certain plot type thank help reproduc python pycaret classif import pycaret dataset import data dataset data credit pycaret env setup data data target default html fals silent true verbos fals log experi plot test log experi true log plot auc featur paramet calibr confus matrix model creat model lightgbm expect behavior expect plot type log artifact dir experi number artifact featur png calibr png save work directori addit context think issu inconsist name file printout log tri save calibr plot info save calibr png info visual render successfulli info plot model succesfulli complet warn errno file directori calibr curv png look calibr curv png actual get produc calibr png version python pycaret",
        "Issue_preprocessed_content":"type plot type save experi artifact dir bug thank creat help problem face type plot type save experi artifact dir think inconsist name save png certain plot type thank help reproduc minim complet verifi exampl setup model info save info visual render warn file directori calibr calibr get produc version python run code past output import pycaret pycaret detail thank contribut",
        "Issue_gpt_summary_original":"The user encountered a bug while trying to convert an experiment using the aim convert mlflow command with the experiment ID. The process failed with an error message. However, using the experiment name instead of the ID worked successfully. The expected behavior was to convert the experiment by ID. The user's environment included Aim Version 3.6, Python 3.8.1, pip3, and Ubuntu 20.04.3 LTS.",
        "Issue_gpt_summary":"user encount bug try convert experi convert command experi process fail error messag experi instead work successfulli expect behavior convert experi user environ includ version python pip ubuntu lt",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/pycaret\/pycaret\/issues\/1568",
        "Issue_title":"MLFlow logging issue in compare_models of time_series",
        "Issue_created_time":1631459045000,
        "Issue_closed_time":1634125992000,
        "Issue_body":"MLFlow logging issue in compare_models of time_series\r\n\r\n```\r\nfrom pycaret.datasets import get_data\r\ndata = get_data('airline')\r\n\r\nfrom pycaret.time_series import *\r\ns = setup(data, fold = 5, fh = 12, session_id = 123, log_experiment=True, experiment_name = 'airline')\r\n\r\nbest = compare_models()\r\n\r\n!mlflow ui\r\n```\r\n\r\nCheck localhost:5000:\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/54699234\/132992636-db293fe7-5461-43d9-baed-97d8790fd9bd.png)\r\n\r\nAll the runs fail in `compare_models`. Parameters are logged but metrics and artifacts didn't. \r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/54699234\/132992655-e0d81e16-9a59-49a5-ace3-d22ea2ea10b8.png)\r\n\r\nI cannot reproduce this with `create_model` it means `create_model` works just fine! ",
        "Issue_answer_count":2,
        "Issue_self_closed":1.0,
        "Answer_body":"@moezali1 merged a fix, please recheck  Done.\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/54699234\/137127496-454bff0f-d3a4-410f-9d78-b8e4b1a3f547.png)",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"log issu compar model time seri log issu compar model time seri pycaret dataset import data data data airlin pycaret time seri import setup data fold session log experi true experi airlin best compar model check localhost imag http user imag githubusercont com dbfe ba dfdbd png run fail compar model paramet log metric artifact imag http user imag githubusercont com ed ac deaeab png reproduc creat model mean creat model work fine",
        "Issue_preprocessed_content":" check localhost run fail paramet metric artifact reproduc mean work fine",
        "Issue_gpt_summary_original":"The user encountered an issue where the nyc-taxi-mlflow-deployment.yml file refers to a folder that doesn't exist, causing the code to fail. The expected behavior is to re-add the folder.",
        "Issue_gpt_summary":"user encount issu nyc taxi deploy yml file refer folder exist caus code fail expect behavior add folder",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/pycaret\/pycaret\/issues\/1411",
        "Issue_title":"[BUG]Can we store mlflow artifacts in the Azure blob storage for new experiments in pycaret?",
        "Issue_created_time":1624984139000,
        "Issue_closed_time":null,
        "Issue_body":"I was exploring mlflow with pycaret today. And tried to store the artifacts in the Azure blob using the --default-artifact-root tag. It's working fine when I am not giving a experiment name to pycaret setup function. When a experiment name is given the artifacts are getting stored in the local directory.",
        "Issue_answer_count":0,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"bug store artifact azur blob storag new experi pycaret explor pycaret todai tri store artifact azur blob default artifact root tag work fine give experi pycaret setup function experi given artifact get store local directori",
        "Issue_preprocessed_content":"store artifact azur blob storag new experi pycaret explor pycaret todai tri store artifact azur blob tag work fine give experi pycaret setup function experi given artifact store local directori",
        "Issue_gpt_summary_original":"The user encountered an issue with the MLflow cli endpoint example due to breaking changes in yaml syntax, specifically with the \"name\" parameter no longer being required when specifying model. The deployment fails when using the outdated yaml configuration.",
        "Issue_gpt_summary":"user encount issu cli endpoint exampl break chang yaml syntax specif paramet longer requir specifi model deploy fail outdat yaml configur",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/pycaret\/pycaret\/issues\/931",
        "Issue_title":"MLFlow doesn't save model artifact and some plots - Clustering",
        "Issue_created_time":1607745205000,
        "Issue_closed_time":1620299767000,
        "Issue_body":"I'm using clustering module of pycaret and the integration with mlflow but I have problems because I think it doesn't save all artifacs and the status is always failed.\r\n![image](https:\/\/user-images.githubusercontent.com\/12554263\/101971863-66f70d00-3c02-11eb-9710-01cf228fca1b.png)\r\n\r\nThis is my code:\r\n\r\n```python\r\nfrom pycaret.clustering import *\r\n\r\npostpaid_exp = setup(postpaid_sample,\r\n                     ignore_features=ignore_features,\r\n                     numeric_features=numeric_features,\r\n                     normalize=True,\r\n                     normalize_method='robust',\r\n                     remove_multicollinearity=True,\r\n                     multicollinearity_threshold=0.7,\r\n                     log_experiment=True,\r\n                     log_plots=True,\r\n                     log_profile=True,\r\n                     log_data=True,\r\n                     profile=False,\r\n                     experiment_name='pospatid_segmentation',\r\n                     session_id=123)\r\n\r\n# Create model with six clusters\r\nmodel_kmeans =  create_model(model='kmeans', num_clusters=6)\r\n```\r\nMy logs are the following\r\n\r\n```\r\n2020-12-11 22:39:07,118:INFO:PyCaret Supervised Module\r\n2020-12-11 22:39:07,118:INFO:ML Usecase: clustering\r\n2020-12-11 22:39:07,118:INFO:version 2.2.0\r\n2020-12-11 22:39:07,118:INFO:Initializing setup()\r\n2020-12-11 22:39:07,119:INFO:setup(target=None, ml_usecase=clustering, available_plots={'cluster': 'Cluster PCA Plot (2d)', 'tsne': 'Cluster TSnE (3d)', 'elbow': 'Elbow', 'silhouette': 'Silhouette', 'distance': 'Distance', 'distribution': 'Distribution'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=mode, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=['avg_dias_bancos_3m', 'avg_dias_app_pagos_3m', 'avg_dias_viajes_3m', 'avg_dias_compras_3m', 'avg_dias_mb_total_3m', 'avg_mb_total_3m', 'avg_q_apps_3m', 'ate_wh_sum_dias_3m', 'LEADs_tot_3m', 'tot_dias_appmov_movil_3m', 'avg_days_out_voice_tot_3m', 'meses_pagodig_3m'], numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=['periodo', 'telefono', 'anexo', 'tot_dias_appmov_fija_3m', 'avg_dias_vid_mus_3m'], normalize=True, normalize_method=robust, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=True, multicollinearity_threshold=0.7, remove_perfect_collinearity=False, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=False, data_split_stratify=False, fold_strategy=kfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=123, log_experiment=True, experiment_name=pospatid_segmentation, log_plots=['cluster', 'distribution', 'elbow'], log_profile=True, log_data=True, silent=False, verbose=True, profile=False, display=None)\r\n2020-12-11 22:39:07,119:INFO:Checking environment\r\n2020-12-11 22:39:07,119:INFO:python_version: 3.8.5\r\n2020-12-11 22:39:07,119:INFO:python_build: ('default', 'Aug  5 2020 09:44:06')\r\n2020-12-11 22:39:07,119:INFO:machine: AMD64\r\n2020-12-11 22:39:07,120:INFO:platform: Windows-10-10.0.18362-SP0\r\n2020-12-11 22:39:07,121:WARNING:cannot find psutil installation. memory not traceable. Install psutil using pip to enable memory logging.\r\n2020-12-11 22:39:07,122:INFO:Checking libraries\r\n2020-12-11 22:39:07,122:INFO:pd==1.1.4\r\n2020-12-11 22:39:07,122:INFO:numpy==1.19.4\r\n2020-12-11 22:39:07,122:INFO:sklearn==0.23.2\r\n2020-12-11 22:39:07,156:INFO:xgboost==1.2.0\r\n2020-12-11 22:39:07,156:INFO:lightgbm==3.0.0\r\n2020-12-11 22:39:07,170:INFO:catboost==0.24.1\r\n2020-12-11 22:39:07,901:INFO:mlflow==1.11.0\r\n2020-12-11 22:39:07,901:INFO:Checking Exceptions\r\n2020-12-11 22:39:07,901:INFO:Declaring global variables\r\n2020-12-11 22:39:07,901:INFO:USI: cd5c\r\n2020-12-11 22:39:07,901:INFO:pycaret_globals: {'_available_plots', 'master_model_container', 'display_container', 'imputation_classifier', 'logging_param', 'seed', 'transform_target_param', 'experiment__', 'transform_target_method_param', 'iterative_imputation_iters_param', 'fold_groups_param', 'fix_imbalance_param', 'prep_pipe', 'exp_name_log', '_all_metrics', 'html_param', '_ml_usecase', 'USI', 'imputation_regressor', 'stratify_param', 'fold_generator', 'fix_imbalance_method_param', '_all_models', 'gpu_param', 'target_param', '_gpu_n_jobs_param', 'log_plots_param', 'pycaret_globals', 'fold_shuffle_param', '_all_models_internal', 'fold_param', 'create_model_container', 'data_before_preprocess', '_internal_pipeline', 'X', 'n_jobs_param'}\r\n2020-12-11 22:39:07,901:INFO:Preparing display monitor\r\n2020-12-11 22:39:07,901:INFO:Preparing display monitor\r\n2020-12-11 22:39:07,914:INFO:Importing libraries\r\n2020-12-11 22:39:07,914:INFO:Copying data for preprocessing\r\n2020-12-11 22:39:07,927:INFO:Declaring preprocessing parameters\r\n2020-12-11 22:39:07,940:INFO:Creating preprocessing pipeline\r\n2020-12-11 22:39:08,059:INFO:Preprocessing pipeline created successfully\r\n2020-12-11 22:39:08,060:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.\r\n2020-12-11 22:39:08,060:INFO:Creating global containers\r\n2020-12-11 22:39:08,061:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)\r\n2020-12-11 22:39:10,064:INFO:Creating grid variables\r\n2020-12-11 22:39:10,101:INFO:Logging experiment in MLFlow\r\n2020-12-11 22:39:10,108:WARNING:Couldn't create mlflow experiment. Exception:\r\n2020-12-11 22:39:10,185:WARNING:Traceback (most recent call last):\r\n  File \"C:\\Users\\CARLOS\\Anaconda3\\envs\\dev_models\\lib\\site-packages\\pycaret\\internal\\tabular.py\", line 1668, in setup\r\n    mlflow.create_experiment(exp_name_log)\r\n  File \"C:\\Users\\CARLOS\\Anaconda3\\envs\\dev_models\\lib\\site-packages\\mlflow\\tracking\\fluent.py\", line 365, in create_experiment\r\n    return MlflowClient().create_experiment(name, artifact_location)\r\n  File \"C:\\Users\\CARLOS\\Anaconda3\\envs\\dev_models\\lib\\site-packages\\mlflow\\tracking\\client.py\", line 184, in create_experiment\r\n    return self._tracking_client.create_experiment(name, artifact_location)\r\n  File \"C:\\Users\\CARLOS\\Anaconda3\\envs\\dev_models\\lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py\", line 142, in create_experiment\r\n    return self.store.create_experiment(name=name, artifact_location=artifact_location,)\r\n  File \"C:\\Users\\CARLOS\\Anaconda3\\envs\\dev_models\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 288, in create_experiment\r\n    self._validate_experiment_name(name)\r\n  File \"C:\\Users\\CARLOS\\Anaconda3\\envs\\dev_models\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 281, in _validate_experiment_name\r\n    raise MlflowException(\r\nmlflow.exceptions.MlflowException: Experiment 'pospatid_segmentation' already exists.\r\n\r\n2020-12-11 22:39:10,490:INFO:SubProcess save_model() called ==================================\r\n2020-12-11 22:39:10,501:INFO:Initializing save_model()\r\n2020-12-11 22:39:10,501:INFO:save_model(model=Pipeline(memory=None,\r\n         steps=[('dtypes',\r\n                 DataTypes_Auto_infer(categorical_features=[],\r\n                                      display_types=True,\r\n                                      features_todrop=['periodo', 'telefono',\r\n                                                       'anexo',\r\n                                                       'tot_dias_appmov_fija_3m',\r\n                                                       'avg_dias_vid_mus_3m'],\r\n                                      id_columns=[],\r\n                                      ml_usecase='classification',\r\n                                      numerical_features=['avg_dias_bancos_3m',\r\n                                                          'avg_dias_app_pagos_3m',\r\n                                                          'avg_dias_viajes_3m',\r\n                                                          'avg_dias_compras_3m',\r\n                                                          'av...\r\n                ('dummy', Dummify(target='UNSUPERVISED_DUMMY_TARGET')),\r\n                ('fix_perfect', 'passthrough'),\r\n                ('clean_names', Clean_Colum_Names()),\r\n                ('feature_select', 'passthrough'),\r\n                ('fix_multi',\r\n                 Fix_multicollinearity(correlation_with_target_preference=None,\r\n                                       correlation_with_target_threshold=0.0,\r\n                                       target_variable='UNSUPERVISED_DUMMY_TARGET',\r\n                                       threshold=0.7)),\r\n                ('dfs', 'passthrough'), ('pca', 'passthrough')],\r\n         verbose=False), model_name=Transformation Pipeline, prep_pipe_=Pipeline(memory=None,\r\n         steps=[('dtypes',\r\n                 DataTypes_Auto_infer(categorical_features=[],\r\n                                      display_types=True,\r\n                                      features_todrop=['periodo', 'telefono',\r\n                                                       'anexo',\r\n                                                       'tot_dias_appmov_fija_3m',\r\n                                                       'avg_dias_vid_mus_3m'],\r\n                                      id_columns=[],\r\n                                      ml_usecase='classification',\r\n                                      numerical_features=['avg_dias_bancos_3m',\r\n                                                          'avg_dias_app_pagos_3m',\r\n                                                          'avg_dias_viajes_3m',\r\n                                                          'avg_dias_compras_3m',\r\n                                                          'av...\r\n                ('dummy', Dummify(target='UNSUPERVISED_DUMMY_TARGET')),\r\n                ('fix_perfect', 'passthrough'),\r\n                ('clean_names', Clean_Colum_Names()),\r\n                ('feature_select', 'passthrough'),\r\n                ('fix_multi',\r\n                 Fix_multicollinearity(correlation_with_target_preference=None,\r\n                                       correlation_with_target_threshold=0.0,\r\n                                       target_variable='UNSUPERVISED_DUMMY_TARGET',\r\n                                       threshold=0.7)),\r\n                ('dfs', 'passthrough'), ('pca', 'passthrough')],\r\n         verbose=False), verbose=False)\r\n2020-12-11 22:39:10,501:INFO:Adding model into prep_pipe\r\n2020-12-11 22:39:10,506:WARNING:Only Model saved as it was a pipeline.\r\n2020-12-11 22:39:10,530:INFO:Transformation Pipeline.pkl saved in current working directory\r\n2020-12-11 22:39:10,535:INFO:Pipeline(memory=None,\r\n         steps=[('dtypes',\r\n                 DataTypes_Auto_infer(categorical_features=[],\r\n                                      display_types=True,\r\n                                      features_todrop=['periodo', 'telefono',\r\n                                                       'anexo',\r\n                                                       'tot_dias_appmov_fija_3m',\r\n                                                       'avg_dias_vid_mus_3m'],\r\n                                      id_columns=[],\r\n                                      ml_usecase='classification',\r\n                                      numerical_features=['avg_dias_bancos_3m',\r\n                                                          'avg_dias_app_pagos_3m',\r\n                                                          'avg_dias_viajes_3m',\r\n                                                          'avg_dias_compras_3m',\r\n                                                          'av...\r\n                ('dummy', Dummify(target='UNSUPERVISED_DUMMY_TARGET')),\r\n                ('fix_perfect', 'passthrough'),\r\n                ('clean_names', Clean_Colum_Names()),\r\n                ('feature_select', 'passthrough'),\r\n                ('fix_multi',\r\n                 Fix_multicollinearity(correlation_with_target_preference=None,\r\n                                       correlation_with_target_threshold=0.0,\r\n                                       target_variable='UNSUPERVISED_DUMMY_TARGET',\r\n                                       threshold=0.7)),\r\n                ('dfs', 'passthrough'), ('pca', 'passthrough')],\r\n         verbose=False)\r\n2020-12-11 22:39:10,535:INFO:save_model() succesfully completed......................................\r\n2020-12-11 22:39:10,536:INFO:SubProcess save_model() end ==================================\r\n2020-12-11 22:40:03,332:INFO:create_model_container: 0\r\n2020-12-11 22:40:03,332:INFO:master_model_container: 0\r\n2020-12-11 22:40:03,332:INFO:display_container: 0\r\n2020-12-11 22:40:03,336:INFO:Pipeline(memory=None,\r\n         steps=[('dtypes',\r\n                 DataTypes_Auto_infer(categorical_features=[],\r\n                                      display_types=True,\r\n                                      features_todrop=['periodo', 'telefono',\r\n                                                       'anexo',\r\n                                                       'tot_dias_appmov_fija_3m',\r\n                                                       'avg_dias_vid_mus_3m'],\r\n                                      id_columns=[],\r\n                                      ml_usecase='classification',\r\n                                      numerical_features=['avg_dias_bancos_3m',\r\n                                                          'avg_dias_app_pagos_3m',\r\n                                                          'avg_dias_viajes_3m',\r\n                                                          'avg_dias_compras_3m',\r\n                                                          'av...\r\n                ('dummy', Dummify(target='UNSUPERVISED_DUMMY_TARGET')),\r\n                ('fix_perfect', 'passthrough'),\r\n                ('clean_names', Clean_Colum_Names()),\r\n                ('feature_select', 'passthrough'),\r\n                ('fix_multi',\r\n                 Fix_multicollinearity(correlation_with_target_preference=None,\r\n                                       correlation_with_target_threshold=0.0,\r\n                                       target_variable='UNSUPERVISED_DUMMY_TARGET',\r\n                                       threshold=0.7)),\r\n                ('dfs', 'passthrough'), ('pca', 'passthrough')],\r\n         verbose=False)\r\n2020-12-11 22:40:03,336:INFO:setup() succesfully completed......................................\r\n2020-12-11 22:40:07,628:INFO:Initializing create_model()\r\n2020-12-11 22:40:07,628:INFO:create_model(estimator=kmeans, num_clusters=6, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, verbose=True, system=True, raise_num_clusters=False, display=None, kwargs={})\r\n2020-12-11 22:40:07,628:INFO:Checking exceptions\r\n2020-12-11 22:40:07,629:INFO:Preparing display monitor\r\n2020-12-11 22:40:07,645:INFO:Importing libraries\r\n2020-12-11 22:40:07,652:INFO:Importing untrained model\r\n2020-12-11 22:40:07,662:INFO:K-Means Clustering Imported succesfully\r\n2020-12-11 22:40:07,670:INFO:Fitting Model\r\n2020-12-11 22:42:30,467:INFO:KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\r\n       n_clusters=6, n_init=10, n_jobs=-1, precompute_distances='deprecated',\r\n       random_state=123, tol=0.0001, verbose=0)\r\n2020-12-11 22:42:30,467:INFO:create_models() succesfully completed......................................\r\n2020-12-11 22:42:30,467:INFO:Creating MLFlow logs\r\n2020-12-11 22:42:30,481:INFO:Model: K-Means Clustering\r\n2020-12-11 22:42:30,518:INFO:logged params: {'algorithm': 'auto', 'copy_x': True, 'init': 'k-means++', 'max_iter': 300, 'n_clusters': 6, 'n_init': 10, 'n_jobs': -1, 'precompute_distances': 'deprecated', 'random_state': 123, 'tol': 0.0001, 'verbose': 0}\r\n2020-12-11 22:42:30,557:INFO:SubProcess plot_model() called ==================================\r\n2020-12-11 22:42:30,557:INFO:Initializing plot_model()\r\n2020-12-11 22:42:30,557:INFO:plot_model(plot=cluster, fold=None, verbose=False, display=None, estimator=KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\r\n       n_clusters=6, n_init=10, n_jobs=-1, precompute_distances='deprecated',\r\n       random_state=123, tol=0.0001, verbose=0), feature_name=None, fit_kwargs=None, groups=None, label=False, save=True, scale=1, system=False)\r\n2020-12-11 22:42:30,557:INFO:Checking exceptions\r\n2020-12-11 22:42:30,558:INFO:Preloading libraries\r\n2020-12-11 22:42:30,558:INFO:Copying training dataset\r\n2020-12-11 22:42:30,560:INFO:Plot type: cluster\r\n2020-12-11 22:42:31,493:INFO:SubProcess assign_model() called ==================================\r\n2020-12-11 22:42:31,494:INFO:Initializing assign_model()\r\n2020-12-11 22:42:31,494:INFO:assign_model(model=Pipeline(memory=None,\r\n         steps=[('empty_step', 'passthrough'),\r\n                ('actual_estimator',\r\n                 KMeans(algorithm='auto', copy_x=True, init='k-means++',\r\n                        max_iter=300, n_clusters=6, n_init=10, n_jobs=-1,\r\n                        precompute_distances='deprecated', random_state=123,\r\n                        tol=0.0001, verbose=0))],\r\n         verbose=False), transformation=True, score=True, verbose=False)\r\n2020-12-11 22:42:31,494:INFO:Checking exceptions\r\n2020-12-11 22:42:31,495:INFO:Determining Trained Model\r\n2020-12-11 22:42:31,495:INFO:Trained Model : K-Means Clustering\r\n2020-12-11 22:42:31,495:INFO:Copying data\r\n2020-12-11 22:42:31,496:INFO:Transformation param set to True. Assigned clusters are attached on transformed dataset.\r\n2020-12-11 22:42:31,529:INFO:(90000, 12)\r\n2020-12-11 22:42:31,529:INFO:assign_model() succesfully completed......................................\r\n2020-12-11 22:42:31,530:INFO:SubProcess assign_model() end ==================================\r\n2020-12-11 22:42:31,541:INFO:Fitting PCA()\r\n2020-12-11 22:42:31,908:INFO:Sorting dataframe\r\n2020-12-11 22:42:31,974:INFO:Rendering Visual\r\n2020-12-11 22:42:41,765:INFO:Saving 'Cluster PCA Plot (2d).html' in current active directory\r\n2020-12-11 22:42:41,765:INFO:Visual Rendered Successfully\r\n2020-12-11 22:42:42,286:INFO:plot_model() succesfully completed......................................\r\n2020-12-11 22:42:42,739:INFO:Initializing plot_model()\r\n2020-12-11 22:42:42,739:INFO:plot_model(plot=distribution, fold=None, verbose=False, display=None, estimator=KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\r\n       n_clusters=6, n_init=10, n_jobs=-1, precompute_distances='deprecated',\r\n       random_state=123, tol=0.0001, verbose=0), feature_name=None, fit_kwargs=None, groups=None, label=False, save=True, scale=1, system=False)\r\n2020-12-11 22:42:42,739:INFO:Checking exceptions\r\n2020-12-11 22:42:42,739:INFO:Preloading libraries\r\n2020-12-11 22:42:42,739:INFO:Copying training dataset\r\n2020-12-11 22:42:42,741:INFO:Plot type: distribution\r\n2020-12-11 22:42:42,741:INFO:SubProcess assign_model() called ==================================\r\n2020-12-11 22:42:42,742:INFO:Initializing assign_model()\r\n2020-12-11 22:42:42,742:INFO:assign_model(model=Pipeline(memory=None,\r\n         steps=[('empty_step', 'passthrough'),\r\n                ('actual_estimator',\r\n                 KMeans(algorithm='auto', copy_x=True, init='k-means++',\r\n                        max_iter=300, n_clusters=6, n_init=10, n_jobs=-1,\r\n                        precompute_distances='deprecated', random_state=123,\r\n                        tol=0.0001, verbose=0))],\r\n         verbose=False), transformation=False, score=True, verbose=False)\r\n2020-12-11 22:42:42,742:INFO:Checking exceptions\r\n2020-12-11 22:42:42,742:INFO:Determining Trained Model\r\n2020-12-11 22:42:42,742:INFO:Trained Model : K-Means Clustering\r\n2020-12-11 22:42:42,742:INFO:Copying data\r\n2020-12-11 22:42:42,793:INFO:(90000, 18)\r\n2020-12-11 22:42:42,793:INFO:assign_model() succesfully completed......................................\r\n2020-12-11 22:42:42,794:INFO:SubProcess assign_model() end ==================================\r\n2020-12-11 22:42:42,794:INFO:Sorting dataframe\r\n2020-12-11 22:42:42,925:INFO:Rendering Visual\r\n2020-12-11 22:42:48,837:INFO:Saving 'Distribution.html' in current active directory\r\n2020-12-11 22:42:48,837:INFO:Visual Rendered Successfully\r\n2020-12-11 22:42:48,979:INFO:plot_model() succesfully completed......................................\r\n2020-12-11 22:42:49,583:INFO:Initializing plot_model()\r\n2020-12-11 22:42:49,584:INFO:plot_model(plot=elbow, fold=None, verbose=False, display=None, estimator=KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\r\n       n_clusters=6, n_init=10, n_jobs=-1, precompute_distances='deprecated',\r\n       random_state=123, tol=0.0001, verbose=0), feature_name=None, fit_kwargs=None, groups=None, label=False, save=True, scale=1, system=False)\r\n2020-12-11 22:42:49,584:INFO:Checking exceptions\r\n2020-12-11 22:42:49,584:INFO:Preloading libraries\r\n2020-12-11 22:42:49,584:INFO:Copying training dataset\r\n2020-12-11 22:42:49,586:INFO:Plot type: elbow\r\n2020-12-11 22:42:49,690:INFO:Fitting Model\r\n2020-12-11 22:43:12,604:INFO:Saving 'Elbow.png' in current active directory\r\n2020-12-11 22:43:13,207:INFO:Visual Rendered Successfully\r\n2020-12-11 22:43:13,325:INFO:plot_model() succesfully completed......................................\r\n2020-12-11 22:43:13,340:INFO:SubProcess plot_model() end ==================================\r\n2020-12-11 22:43:13,341:WARNING:Couldn't infer MLFlow signature.\r\n2020-12-11 22:43:13,352:ERROR:_mlflow_log_model() for KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\r\n       n_clusters=6, n_init=10, n_jobs=-1, precompute_distances='deprecated',\r\n       random_state=123, tol=0.0001, verbose=0) raised an exception:\r\n2020-12-11 22:43:13,431:ERROR:Traceback (most recent call last):\r\n  File \"C:\\Users\\CARLOS\\Anaconda3\\envs\\dev_models\\lib\\site-packages\\pycaret\\internal\\tabular.py\", line 2631, in create_model_unsupervised\r\n    _mlflow_log_model(\r\n  File \"C:\\Users\\CARLOS\\Anaconda3\\envs\\dev_models\\lib\\site-packages\\pycaret\\internal\\tabular.py\", line 9942, in _mlflow_log_model\r\n    mlflow.sklearn.log_model(\r\n  File \"C:\\Users\\CARLOS\\Anaconda3\\envs\\dev_models\\lib\\site-packages\\mlflow\\sklearn\\__init__.py\", line 290, in log_model\r\n    return Model.log(\r\n  File \"C:\\Users\\CARLOS\\Anaconda3\\envs\\dev_models\\lib\\site-packages\\mlflow\\models\\model.py\", line 160, in log\r\n    flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)\r\n  File \"C:\\Users\\CARLOS\\Anaconda3\\envs\\dev_models\\lib\\site-packages\\mlflow\\sklearn\\__init__.py\", line 171, in save_model\r\n    _save_example(mlflow_model, input_example, path)\r\n  File \"C:\\Users\\CARLOS\\Anaconda3\\envs\\dev_models\\lib\\site-packages\\mlflow\\models\\utils.py\", line 131, in _save_example\r\n    example = _Example(input_example)\r\n  File \"C:\\Users\\CARLOS\\Anaconda3\\envs\\dev_models\\lib\\site-packages\\mlflow\\models\\utils.py\", line 67, in __init__\r\n    input_example = pd.DataFrame.from_dict(input_example)\r\n  File \"C:\\Users\\CARLOS\\Anaconda3\\envs\\dev_models\\lib\\site-packages\\pandas\\core\\frame.py\", line 1309, in from_dict\r\n    return cls(data, index=index, columns=columns, dtype=dtype)\r\n  File \"C:\\Users\\CARLOS\\Anaconda3\\envs\\dev_models\\lib\\site-packages\\pandas\\core\\frame.py\", line 468, in __init__\r\n    mgr = init_dict(data, index, columns, dtype=dtype)\r\n  File \"C:\\Users\\CARLOS\\Anaconda3\\envs\\dev_models\\lib\\site-packages\\pandas\\core\\internals\\construction.py\", line 283, in init_dict\r\n    return arrays_to_mgr(arrays, data_names, index, columns, dtype=dtype)\r\n  File \"C:\\Users\\CARLOS\\Anaconda3\\envs\\dev_models\\lib\\site-packages\\pandas\\core\\internals\\construction.py\", line 78, in arrays_to_mgr\r\n    index = extract_index(arrays)\r\n  File \"C:\\Users\\CARLOS\\Anaconda3\\envs\\dev_models\\lib\\site-packages\\pandas\\core\\internals\\construction.py\", line 387, in extract_index\r\n    raise ValueError(\"If using all scalar values, you must pass an index\")\r\nValueError: If using all scalar values, you must pass an index\r\n\r\n2020-12-11 22:43:13,432:INFO:Uploading results into container\r\n2020-12-11 22:43:13,435:INFO:Uploading model into container now\r\n2020-12-11 22:43:13,440:INFO:create_model_container: 1\r\n2020-12-11 22:43:13,440:INFO:master_model_container: 1\r\n2020-12-11 22:43:13,440:INFO:display_container: 1\r\n2020-12-11 22:43:13,440:INFO:KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\r\n       n_clusters=6, n_init=10, n_jobs=-1, precompute_distances='deprecated',\r\n       random_state=123, tol=0.0001, verbose=0)\r\n2020-12-11 22:43:13,440:INFO:create_model() succesfully completed......................................\r\n\r\n```\r\n\r\nI'm using Pycaret version : 2.2.0",
        "Issue_answer_count":5,
        "Issue_self_closed":0.0,
        "Answer_body":"@DXcarlos I have tried to reproduce the error on `jewellery` dataset available on our GitHub repository and I couldn't reproduce this error.\r\n\r\nIs it possible for you to share the Notebook along with the dataset so we can reproduce the error and troubleshoot what is causing this?\r\n\r\nI am including @Yard1 in this thread to see if he can understand what's going on with the log file you shared above. Antoni, maybe something specific to the dataset.  @pycaret @Yard1 How can I share you privately? @DXcarlos You can private message on our Slack channel. If you are still not there, you can join using the following link:\r\n\r\nhttps:\/\/join.slack.com\/t\/pycaret\/shared_invite\/zt-kdoe7hee-yvNANPHXPM9VtK7R6Npx4Q\r\n\r\n Stale issue message @DXcarlos , we will close out this issue for now. Please feel free to reopen if you want.",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"save model artifact plot cluster cluster modul pycaret integr problem think save artifac statu fail imag http user imag githubusercont com cffcab png code python pycaret cluster import postpaid exp setup postpaid sampl ignor featur ignor featur numer featur numer featur normal true normal method robust remov multicollinear true multicollinear threshold log experi true log plot true log profil true log data true profil fals experi pospatid segment session creat model cluster model kmean creat model model kmean num cluster log follow info pycaret supervis modul info usecas cluster info version info initi setup info setup target usecas cluster avail plot cluster cluster pca plot tsne cluster tsne elbow elbow silhouett silhouett distanc distanc distribut distribut train size test data preprocess true imput type simpl iter imput iter categor featur categor imput mode categor iter imput lightgbm ordin featur high cardin featur high cardin method frequenc numer featur avg dia banco avg dia app pago avg dia viaj avg dia compra avg dia total avg total avg app at sum dia lead tot tot dia appmov movil avg dai voic tot mese pagodig numer imput mean numer iter imput lightgbm date featur ignor featur periodo telefono anexo tot dia appmov fija avg dia vid mu normal true normal method robust transform fals transform method yeo johnson handl unknown categor true unknown categor method frequent pca fals pca method linear pca compon ignor low varianc fals combin rare level fals rare level threshold bin numer featur remov outlier fals outlier threshold remov multicollinear true multicollinear threshold remov perfect collinear fals creat cluster fals cluster iter polynomi featur fals polynomi degre trigonometri featur fals polynomi threshold group featur group name featur select fals featur select threshold featur select method classic featur interact fals featur ratio fals interact threshold fix imbal fals fix imbal method transform target fals transform target method box cox data split shuffl fals data split stratifi fals fold strategi kfold fold fold shuffl fals fold group job us gpu fals custom pipelin html true session log experi true experi pospatid segment log plot cluster distribut elbow log profil true log data true silent fals verbos true profil fals displai info check environ info python version info python build default aug info machin amd info platform window warn psutil instal memori traceabl instal psutil pip enabl memori log info check librari info info numpi info sklearn info xgboost info lightgbm info catboost info info check except info declar global variabl info usi cdc info pycaret global avail plot master model contain displai contain imput classifi log param seed transform target param experi transform target method param iter imput iter param fold group param fix imbal param prep pipe exp log metric html param usecas usi imput regressor stratifi param fold gener fix imbal method param model gpu param target param gpu job param log plot param pycaret global fold shuffl param model intern fold param creat model contain data preprocess intern pipelin job param info prepar displai monitor info prepar displai monitor info import librari info copi data preprocess info declar preprocess paramet info creat preprocess pipelin info preprocess pipelin creat successfulli error process exit setup interupt user command quit setup rerun info creat global contain info intern pipelin pipelin memori step step passthrough verbos fals info creat grid variabl info log experi warn couldn creat experi except warn traceback recent file user carlo anaconda env dev model lib site packag pycaret intern tabular line setup creat experi exp log file user carlo anaconda env dev model lib site packag track fluent line creat experi return client creat experi artifact locat file user carlo anaconda env dev model lib site packag track client line creat experi return self track client creat experi artifact locat file user carlo anaconda env dev model lib site packag track track servic client line creat experi return self store creat experi artifact locat artifact locat file user carlo anaconda env dev model lib site packag store track file store line creat experi self valid experi file user carlo anaconda env dev model lib site packag store track file store line valid experi rais except except except experi pospatid segment exist info subprocess save model call info initi save model info save model model pipelin memori step dtype datatyp auto infer categor featur displai type true featur todrop periodo telefono anexo tot dia appmov fija avg dia vid mu column usecas classif numer featur avg dia banco avg dia app pago avg dia viaj avg dia compra dummi dummifi target unsupervis dummi target fix perfect passthrough clean name clean colum name featur select passthrough fix multi fix multicollinear correl target prefer correl target threshold target variabl unsupervis dummi target threshold df passthrough pca passthrough verbos fals model transform pipelin prep pipe pipelin memori step dtype datatyp auto infer categor featur displai type true featur todrop periodo telefono anexo tot dia appmov fija avg dia vid mu column usecas classif numer featur avg dia banco avg dia app pago avg dia viaj avg dia compra dummi dummifi target unsupervis dummi target fix perfect passthrough clean name clean colum name featur select passthrough fix multi fix multicollinear correl target prefer correl target threshold target variabl unsupervis dummi target threshold df passthrough pca passthrough verbos fals verbos fals info ad model prep pipe warn model save pipelin info transform pipelin pkl save current work directori info pipelin memori step dtype datatyp auto infer categor featur displai type true featur todrop periodo telefono anexo tot dia appmov fija avg dia vid mu column usecas classif numer featur avg dia banco avg dia app pago avg dia viaj avg dia compra dummi dummifi target unsupervis dummi target fix perfect passthrough clean name clean colum name featur select passthrough fix multi fix multicollinear correl target prefer correl target threshold target variabl unsupervis dummi target threshold df passthrough pca passthrough verbos fals info save model succesfulli complet info subprocess save model end info creat model contain info master model contain info displai contain info pipelin memori step dtype datatyp auto infer categor featur displai type true featur todrop periodo telefono anexo tot dia appmov fija avg dia vid mu column usecas classif numer featur avg dia banco avg dia app pago avg dia viaj avg dia compra dummi dummifi target unsupervis dummi target fix perfect passthrough clean name clean colum name featur select passthrough fix multi fix multicollinear correl target prefer correl target threshold target variabl unsupervis dummi target threshold df passthrough pca passthrough verbos fals info setup succesfulli complet info initi creat model info creat model estim kmean num cluster fraction ground truth round fit kwarg verbos true true rais num cluster fals displai kwarg info check except info prepar displai monitor info import librari info import untrain model info mean cluster import succesfulli info fit model info kmean algorithm auto copi true init mean max iter cluster init job precomput distanc deprec random state tol verbos info creat model succesfulli complet info creat log info model mean cluster info log param algorithm auto copi true init mean max iter cluster init job precomput distanc deprec random state tol verbos info subprocess plot model call info initi plot model info plot model plot cluster fold verbos fals displai estim kmean algorithm auto copi true init mean max iter cluster init job precomput distanc deprec random state tol verbos featur fit kwarg group label fals save true scale fals info check except info preload librari info copi train dataset info plot type cluster info subprocess assign model call info initi assign model info assign model model pipelin memori step step passthrough actual estim kmean algorithm auto copi true init mean max iter cluster init job precomput distanc deprec random state tol verbos verbos fals transform true score true verbos fals info check except info determin train model info train model mean cluster info copi data info transform param set true assign cluster attach transform dataset info info assign model succesfulli complet info subprocess assign model end info fit pca info sort datafram info render visual info save cluster pca plot html current activ directori info visual render successfulli info plot model succesfulli complet info initi plot model info plot model plot distribut fold verbos fals displai estim kmean algorithm auto copi true init mean max iter cluster init job precomput distanc deprec random state tol verbos featur fit kwarg group label fals save true scale fals info check except info preload librari info copi train dataset info plot type distribut info subprocess assign model call info initi assign model info assign model model pipelin memori step step passthrough actual estim kmean algorithm auto copi true init mean max iter cluster init job precomput distanc deprec random state tol verbos verbos fals transform fals score true verbos fals info check except info determin train model info train model mean cluster info copi data info info assign model succesfulli complet info subprocess assign model end info sort datafram info render visual info save distribut html current activ directori info visual render successfulli info plot model succesfulli complet info initi plot model info plot model plot elbow fold verbos fals displai estim kmean algorithm auto copi true init mean max iter cluster init job precomput distanc deprec random state tol verbos featur fit kwarg group label fals save true scale fals info check except info preload librari info copi train dataset info plot type elbow info fit model info save elbow png current activ directori info visual render successfulli info plot model succesfulli complet info subprocess plot model end warn couldn infer signatur error log model kmean algorithm auto copi true init mean max iter cluster init job precomput distanc deprec random state tol verbos rais except error traceback recent file user carlo anaconda env dev model lib site packag pycaret intern tabular line creat model unsupervis log model file user carlo anaconda env dev model lib site packag pycaret intern tabular line log model sklearn log model file user carlo anaconda env dev model lib site packag sklearn init line log model return model log file user carlo anaconda env dev model lib site packag model model line log flavor save model path local path model model kwarg file user carlo anaconda env dev model lib site packag sklearn init line save model save exampl model input exampl path file user carlo anaconda env dev model lib site packag model util line save exampl exampl exampl input exampl file user carlo anaconda env dev model lib site packag model util line init input exampl datafram dict input exampl file user carlo anaconda env dev model lib site packag panda core frame line dict return cl data index index column column dtype dtype file user carlo anaconda env dev model lib site packag panda core frame line init mgr init dict data index column dtype dtype file user carlo anaconda env dev model lib site packag panda core intern construct line init dict return arrai mgr arrai data name index column dtype dtype file user carlo anaconda env dev model lib site packag panda core intern construct line arrai mgr index extract index arrai file user carlo anaconda env dev model lib site packag panda core intern construct line extract index rais valueerror scalar valu pass index valueerror scalar valu pass index info upload result contain info upload model contain info creat model contain info master model contain info displai contain info kmean algorithm auto copi true init mean max iter cluster init job precomput distanc deprec random state tol verbos info creat model succesfulli complet pycaret version",
        "Issue_preprocessed_content":"save model artifact plot cluster cluster modul pycaret integr problem think save artifac statu fail code log pycaret version",
        "Issue_gpt_summary_original":"The user encountered an error while using the pytorch.log_model function in the CIFAR pytorch distributed example. Although the model training was completed and saved, the driver logs showed an unexpected error related to mlflow.utils.environment while inferring pip requirements. The user tried different environment variations but faced the same outcome.",
        "Issue_gpt_summary":"user encount error pytorch log model function cifar pytorch distribut exampl model train complet save driver log show unexpect error relat util environ infer pip requir user tri differ environ variat face outcom",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/pycaret\/pycaret\/issues\/566",
        "Issue_title":"Compare models MLFlowException",
        "Issue_created_time":1598718264000,
        "Issue_closed_time":1598806653000,
        "Issue_body":"Hi. I just upgraded to pycaret 2.1. When I ran the compare_models function with the Titanic dataset, I got the following error:\r\n\r\nMlflowException: Unable to map 'np.object' type to MLflow DataType. np.object canbe mapped iff all values have identical data type which is one of (string, (bytes or byterray),  int, float)\r\n\r\nThe same code worked fine in pycaret 2.0.",
        "Issue_answer_count":9,
        "Issue_self_closed":0.0,
        "Answer_body":"@sagarnildass Hi, Thanks for reporting. This seems like an error from `MLFlow`. I tried to reproduce this out of `pycaret` and I was successful. See below code that throws an error:\r\n\r\n```\r\nimport pandas as pd\r\ndata = pd.read_csv('titanic.csv') #train data from Kaggle\r\nfrom mlflow.models.signature import infer_signature\r\ninfer_signature(data)\r\n```\r\nThis gives the following error:\r\nMlflowException: Unable to map 'np.object' type to MLflow DataType. np.object canbe mapped iff all values have identical data type which is one of (string, (bytes or byterray),  int, float).\r\n\r\nI will log an issue on MLFlow GitHub.\r\n\r\nHere is the issue I logged on MLFlow: https:\/\/github.com\/mlflow\/mlflow\/issues\/3362 Hey\r\n\r\nThanks for the quick reply. \r\n\r\nI found out that presence of null values are a problem. If the dataset contains null values, this error was raised. When I imputed the null values, this problem was solved. Can you also mention this when you log this issue?\r\n\r\nThanks! @sagarnildass Thanks. I have added that in my issue but I don't think so it's 100% True. I have worked with few missing datasets and it worked okay. For example, the `hepatitis` dataset on our repo works fine. Example code:\r\n\r\n```\r\nfrom pycaret.datasets import get_data\r\ndata = get_data('hepatitis')\r\nfrom pycaret.classification import *\r\ns = setup(data, target = 'Class', log_experiment=True, experiment_name = 'hepatitis1')\r\n```\r\n\r\nThis dataset has missing values but it just worked fine. \r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/58118658\/91642055-41991700-e9f6-11ea-9b6f-0f42a86401d9.png)\r\n\r\nCan you investigate more and add your comments on the original issue here: https:\/\/github.com\/mlflow\/mlflow\/issues\/3362\r\n\r\nThanks a lot for helping. @Yard1 I don't know how soon `MLFLow` will be able to fix this but in `2.2` we will have to create some kind of exceptions under `logging_param` chunks to not fail the process even when `infer_signature` fails, as it's not mandatory and has no impact other than the signature file that gets generated under `model` directory when `log_experiment` is set to `True`. @pycaret : I believe object datatypes are a problem. It clearly states: \"np.object canbe mapped iff all values have identical data type which is one of (string, (bytes or byterray), int, float)\". So do you think null values in a object datatype column might be the root  problem here? Because in hepatitis data, all the columns are numeric. @pycaret If we get MLFlow logging into a function then it will be easy to wrap it into a try except block.  @sagarnildass Thanks again for reporting. I am planning to do a bug fix release tomorrow `2.1.1`. For now, I have wrapped this inside `try` and `except` clause to avoid the error. I have tested it on the titanic dataset.\r\n\r\nCan you please sync the `master` and try to see if you can reproduce the error now?\r\n\r\nThanks Done...it's working as expected. @sagarnildass Thanks. I will publish the `2.1.1.` release today. @Yard1 FYI.\r\n\r\nThanks for your help @sagarnildass ",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"compar model except upgrad pycaret ran compar model function titan dataset got follow error except unabl map object type datatyp object canb map iff valu ident data type string byte byterrai int float code work fine pycaret",
        "Issue_preprocessed_content":"compar model except upgrad pycaret ran function titan dataset got except unabl map type datatyp canb valu ident data type int float code work fine pycaret",
        "Issue_gpt_summary_original":"The user is experiencing deployment issues with MLflow 1.13 and suspects that it may have caused a problem with their AzureML example. They have shared a link to their GitHub repository and a related pull request.",
        "Issue_gpt_summary":"user experienc deploy issu suspect caus problem exampl share link github repositori relat pull request",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aimhubio\/aim\/issues\/1415",
        "Issue_title":"aim convert mlflow --experiment fails for experiment id, works for experiment name",
        "Issue_created_time":1645926561000,
        "Issue_closed_time":1649939186000,
        "Issue_body":"## \ud83d\udc1b Bug\r\n\r\ndoing\r\n\r\n`$ aim convert mlflow --tracking_uri 'file:\/\/\/Users\/aim_user\/mlruns' --experiment 61`\r\n\r\nas described here https:\/\/aimstack.readthedocs.io\/en\/latest\/quick_start\/convert_data.html#show-mlflow-logs-in-aim\r\n\r\nfails with the following error\r\n\r\n![Screenshot from 2022-02-27 02-33-17](https:\/\/user-images.githubusercontent.com\/26168435\/155864827-dc7f3acb-0c79-4fab-9c79-a599f1a954ab.png)\r\n\r\nusing the experiment name instead of the experiment id\r\n\r\n![Screenshot from 2022-02-27 02-33-55](https:\/\/user-images.githubusercontent.com\/26168435\/155864887-63c19423-865e-4540-bfb7-c034e123af80.png)\r\n\r\ni.e.\r\n\r\n`$ aim convert mlflow --tracking_uri 'file:\/\/\/Users\/aim_user\/mlruns' --experiment 'ai-vengers-collab'` \r\n\r\nworks:\r\n\r\n![Screenshot from 2022-02-27 02-31-46](https:\/\/user-images.githubusercontent.com\/26168435\/155864881-03434a11-68f8-47e3-90e3-13465cbe86b4.png)\r\n\r\n### To reproduce\r\n\r\nsee above\r\n\r\n### Expected behavior\r\n\r\nconvert the experiment by ID\r\n\r\n### Environment\r\n\r\n- Aim Version 3.6\r\n- Python 3.8.1\r\n- pip3\r\n- Ubuntu 20.04.3 LTS\r\n",
        "Issue_answer_count":6,
        "Issue_self_closed":0.0,
        "Answer_body":"Hey @luisoala, thanks for reporting the issue!\r\n@devfox-se could you please take a look at this? Thanks for reporting this @luisoala, will take a look soon! Hey @luisoala! We've released `v3.6.2` containing the fix for mlflow converter. Please check it out and let me know if there are any issues. thanks @alberttorosyan working through a few other deadlines atm, aiming for a test ~ next tuesday, will share result here @luisoala Hi, have you had a chance to test this?:) Closing due to inactivity, feel free to reopen in case this still persists.",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"convert experi fail experi work experi bug convert track uri file user user experi describ http stack readthedoc latest quick start convert data html log fail follow error screenshot http user imag githubusercont com dcfacb fab afaab png experi instead experi screenshot http user imag githubusercont com bfb ceaf png convert track uri file user user experi venger collab work screenshot http user imag githubusercont com cbeb png reproduc expect behavior convert experi environ version python pip ubuntu lt",
        "Issue_preprocessed_content":"convert fail experi work experi bug describ fail experi instead experi work reproduc expect behavior convert experi environ version python pip ubuntu lt",
        "Issue_gpt_summary_original":"The user is encountering an error while running mlflow.projects.run consistently with etag error. The error is related to Etag conflict on the environment definition.",
        "Issue_gpt_summary":"user encount error run project run consist etag error error relat etag conflict environ definit",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/azureml-examples\/issues\/1899",
        "Issue_title":"nyc-taxi-mlflow-deployment.yml refers to a folder that doesn't exists",
        "Issue_created_time":1669062340000,
        "Issue_closed_time":null,
        "Issue_body":"### Operating System\n\nLinux\n\n### Version Information\n\nAzure cli v2\n\n### Steps to reproduce\n\nThe azureml-example batch endpoint nyc-taxi-mlflow-deployment.yml file, refers to a  .\/autolog_nyc_taxi folder that doesn't exist\n\n### Expected behavior\n\nIt looks like we need to re-add the folder?\n\n### Actual behavior\n\ncode fails because folder doesn't exist\n\n### Addition information\n\n_No response_",
        "Issue_answer_count":1,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"nyc taxi deploy yml refer folder exist oper linux version inform azur cli step reproduc exampl batch endpoint nyc taxi deploy yml file refer autolog nyc taxi folder exist expect behavior look like need add folder actual behavior code fail folder exist addit inform respons",
        "Issue_preprocessed_content":"refer folder exist oper linux version inform azur cli step reproduc exampl batch endpoint file refer folder exist expect behavior like folder actual behavior code fail folder exist inform",
        "Issue_gpt_summary_original":"The user encountered an AttributeError while running a notebook, which states that the 'Workspace' object has no attribute 'get_mlflow_tracking_uri'.",
        "Issue_gpt_summary":"user encount attributeerror run notebook state workspac object attribut track uri",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/azureml-examples\/issues\/1897",
        "Issue_title":"MLflow cli endpoint example out of date with new syntax from breaking changes in yaml (last updated May 11)",
        "Issue_created_time":1669043018000,
        "Issue_closed_time":null,
        "Issue_body":"### Operating System\n\nWindows\n\n### Version Information\n\nlatest cli v2 \n\n### Steps to reproduce\n\nhttps:\/\/github.com\/Azure\/azureml-examples\/blob\/main\/cli\/endpoints\/online\/mlflow\/sklearn-deployment.yaml\r\n\r\nThis yaml is out of date, the model yaml config is wrong. \"name\" is no longer required when specifying model.\n\n### Expected behavior\n\nThat the deployment works based on sklearn-deployment.yml using the cli command `az create deployment`, but it fails. \n\n### Actual behavior\n\nIt fails.\n\n### Addition information\n\n_No response_",
        "Issue_answer_count":2,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"cli endpoint exampl date new syntax break chang yaml updat oper window version inform latest cli step reproduc http github com azur exampl blob main cli endpoint onlin sklearn deploy yaml yaml date model yaml config wrong longer requir specifi model expect behavior deploy work base sklearn deploy yml cli command creat deploy fail actual behavior fail addit inform respons",
        "Issue_preprocessed_content":"cli endpoint exampl date new syntax break chang yaml oper window version inform latest cli step reproduc yaml date model yaml config wrong longer requir specifi model expect behavior deploy work base cli fail actual behavior fail inform",
        "Issue_gpt_summary_original":"The user encountered an error while running an example in qrun, which resulted in a MlflowException due to exceeding the length limit of 500 for a parameter value. The error is caused by repeated calls to an individual run_id event logging. The user is seeking a solution to fix the issue.",
        "Issue_gpt_summary":"user encount error run exampl qrun result except exceed length limit paramet valu error caus repeat call individu run event log user seek solut fix issu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/azureml-examples\/issues\/937",
        "Issue_title":"Mlflow error on pytorch.log_model but model is saved",
        "Issue_created_time":1638959064000,
        "Issue_closed_time":null,
        "Issue_body":"## Which example? Describe the issue\r\n\r\nexample: [CIFAR pytorch distributed](https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/cli\/jobs\/single-step\/pytorch\/cifar-distributed)\r\n\r\ndescription: model training shows completed, model is saved as well but driver logs (`70_driver_log..`.) for the model saving driver has:\r\n \r\n`ERROR mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: \/tmp\/tmpvthoxt0n\/model\/data, flavor: pytorch)\r\nTraceback (most recent call last):\r\n  File \"\/azureml-envs\/pytorch-1.9\/lib\/python3.7\/site-packages\/mlflow\/utils\/environment.py\", line 194, in infer_pip_requirements\r\n    return _infer_requirements(model_uri, flavor)\r\n  File \"\/azureml-envs\/pytorch-1.9\/lib\/python3.7\/site-packages\/mlflow\/utils\/requirements_utils.py\", line 306, in _infer_requirements\r\n    _MODULES_TO_PACKAGES = importlib_metadata.packages_distributions()\r\nAttributeError: module 'importlib_metadata' has no attribute 'packages_distributions'`\r\n\r\n## Additional context\r\n\r\nTried with variations to the environment in `job.yml: azureml:AzureML-pytorch-1.9-ubuntu18.04-py37-cuda11-gpu:11 and azureml:AzureML-pytorch-1.9-ubuntu18.04-py37-cuda11-gpu:6`. Same outcome. \r\n",
        "Issue_answer_count":0,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"error pytorch log model model save exampl issu exampl cifar pytorch distribut http github com azur exampl tree main cli job singl step pytorch cifar distribut descript model train show complet model save driver log driver log model save driver error util environ encount unexpect error infer pip requir model uri tmp tmpvthoxtn model data flavor pytorch traceback recent file env pytorch lib python site packag util environ line infer pip requir return infer requir model uri flavor file env pytorch lib python site packag util requir util line infer requir modul packag importlib metadata packag distribut attributeerror modul importlib metadata attribut packag distribut addit context tri variat environ job yml pytorch ubuntu cuda gpu pytorch ubuntu cuda gpu outcom",
        "Issue_preprocessed_content":"model save exampl exampl descript model train show complet model save driver log model save driver context tri variat environ outcom",
        "Issue_gpt_summary_original":"The user is facing compatibility issues with mlflow v1.28.0 while running a workflow that worked fine with mlflow v1.27.0. The error message suggests that the length of a parameter value exceeded the limit of 500 characters, which is a new feature in mlflow v1.28.0. The user suspects that this issue is related to a recent commit in mlflow and that the parameter value length limit cannot be overwritten.",
        "Issue_gpt_summary":"user face compat issu run workflow work fine error messag suggest length paramet valu exceed limit charact new featur user suspect issu relat recent commit paramet valu length limit overwritten",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/azureml-examples\/issues\/318",
        "Issue_title":"MLflow 1.13 probably broke deployment",
        "Issue_created_time":1609294231000,
        "Issue_closed_time":1609558021000,
        "Issue_body":"\r\n\r\nhttps:\/\/github.com\/Azure\/azureml-examples\/runs\/1618089261?check_suite_focus=true\r\n\r\n@trangevi \r\n\r\nhttps:\/\/github.com\/mlflow\/mlflow\/pull\/3419\/files",
        "Issue_answer_count":3,
        "Issue_self_closed":0.0,
        "Answer_body":"yeah @trangevi the logging statement is guaranteed to bork out: https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/azureml\/__init__.py#L413\r\n\r\n@eedeleon fyi https:\/\/github.com\/mlflow\/mlflow\/pull\/3922\r\n @akshaya-a @eedeleon looks resolved, thanks for investigating! will close this issue ",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"probabl broke deploy http github com azur exampl run check suit focu true trangevi http github com pull file",
        "Issue_preprocessed_content":"probabl broke deploy ",
        "Issue_gpt_summary_original":"the user encountered an exception when running the code in qlib-main\/examples\/workflow_by_code.ipynb, resulting in an invalid experiment id of '.ipynb_checkpoints'.",
        "Issue_gpt_summary":"user encount except run code qlib main exampl workflow code ipynb result invalid experi ipynb checkpoint",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1170",
        "Issue_title":"mlflow.projects.run failing consistently with etag error ",
        "Issue_created_time":1601583593000,
        "Issue_closed_time":1601658581000,
        "Issue_body":"logs: \r\n\r\n```\r\nRun papermill notebooks\/sklearn\/train-diabetes-mlproject.ipynb out.ipynb -k python\r\nInput Notebook:  notebooks\/sklearn\/train-diabetes-mlproject.ipynb\r\nOutput Notebook: out.ipynb\r\n\r\nExecuting:   0%|          | 0\/7 [00:00<?, ?cell\/s]Executing notebook with kernel: python\r\n\r\nExecuting:  14%|\u2588\u258d        | 1\/7 [00:01<00:07,  1.33s\/cell]\r\nExecuting:  29%|\u2588\u2588\u258a       | 2\/7 [00:02<00:07,  1.43s\/cell]\r\nExecuting:  57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 4\/7 [00:05<00:03,  1.32s\/cell]\r\nExecuting:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 6\/7 [00:07<00:01,  1.34s\/cell]\r\nExecuting:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 6\/7 [00:08<00:01,  1.40s\/cell]\r\nTraceback (most recent call last):\r\n  File \"\/opt\/hostedtoolcache\/Python\/3.8.5\/x64\/bin\/papermill\", line 8, in <module>\r\n    sys.exit(papermill())\r\n  File \"\/opt\/hostedtoolcache\/Python\/3.8.5\/x64\/lib\/python3.8\/site-packages\/click\/core.py\", line 829, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"\/opt\/hostedtoolcache\/Python\/3.8.5\/x64\/lib\/python3.8\/site-packages\/click\/core.py\", line 782, in main\r\n    rv = self.invoke(ctx)\r\n  File \"\/opt\/hostedtoolcache\/Python\/3.8.5\/x64\/lib\/python3.8\/site-packages\/click\/core.py\", line 1066, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"\/opt\/hostedtoolcache\/Python\/3.8.5\/x64\/lib\/python3.8\/site-packages\/click\/core.py\", line 610, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"\/opt\/hostedtoolcache\/Python\/3.8.5\/x64\/lib\/python3.8\/site-packages\/click\/decorators.py\", line 21, in new_func\r\n    return f(get_current_context(), *args, **kwargs)\r\n  File \"\/opt\/hostedtoolcache\/Python\/3.8.5\/x64\/lib\/python3.8\/site-packages\/papermill\/cli.py\", line 240, in papermill\r\n    execute_notebook(\r\n  File \"\/opt\/hostedtoolcache\/Python\/3.8.5\/x64\/lib\/python3.8\/site-packages\/papermill\/execute.py\", line 110, in execute_notebook\r\n    raise_for_execution_errors(nb, output_path)\r\n  File \"\/opt\/hostedtoolcache\/Python\/3.8.5\/x64\/lib\/python3.8\/site-packages\/papermill\/execute.py\", line 222, in raise_for_execution_errors\r\n    raise error\r\npapermill.exceptions.PapermillExecutionError: \r\n---------------------------------------------------------------------------\r\nException encountered at \"In [5]\":\r\n---------------------------------------------------------------------------\r\nException                                 Traceback (most recent call last)\r\n<ipython-input-5-ef514d3992f5> in <module>\r\n----> 1 run = mlflow.projects.run(\r\n      2     uri=str(project_uri),\r\n      3     parameters=***\"alpha\": 0.3***,\r\n      4     backend=\"azureml\",\r\n      5     backend_config=backend_config,\r\n\r\n\/opt\/hostedtoolcache\/Python\/3.8.5\/x64\/lib\/python3.8\/site-packages\/mlflow\/projects\/__init__.py in run(uri, entry_point, version, parameters, docker_args, experiment_name, experiment_id, backend, backend_config, use_conda, storage_dir, synchronous, run_id)\r\n    271     )\r\n    272 \r\n--> 273     submitted_run_obj = _run(\r\n    274         uri=uri,\r\n    275         experiment_id=experiment_id,\r\n\r\n\/opt\/hostedtoolcache\/Python\/3.8.5\/x64\/lib\/python3.8\/site-packages\/mlflow\/projects\/__init__.py in _run(uri, experiment_id, entry_point, version, parameters, docker_args, backend_name, backend_config, use_conda, storage_dir, synchronous)\r\n     98         backend = loader.load_backend(backend_name)\r\n     99         if backend:\r\n--> 100             submitted_run = backend.run(\r\n    101                 uri,\r\n    102                 entry_point,\r\n\r\n\/opt\/hostedtoolcache\/Python\/3.8.5\/x64\/lib\/python3.8\/site-packages\/azureml\/mlflow\/_internal\/projects.py in run(self, project_uri, entry_point, params, version, backend_config, tracking_uri, experiment_id)\r\n    240         if compute and compute != _LOCAL and compute != _LOCAL.upper():\r\n    241             remote_environment = _load_remote_environment(mlproject)\r\n--> 242             remote_environment.register(workspace=workspace)\r\n    243             cpu_cluster = _load_compute_target(workspace, backend_config)\r\n    244             src.run_config.target = cpu_cluster.name\r\n\r\n\/opt\/hostedtoolcache\/Python\/3.8.5\/x64\/lib\/python3.8\/site-packages\/azureml\/core\/environment.py in register(self, workspace)\r\n    803         environment_client = EnvironmentClient(workspace.service_context)\r\n    804         environment_dict = Environment._serialize_to_dict(self)\r\n--> 805         response = environment_client._register_environment_definition(environment_dict)\r\n    806         env = Environment._deserialize_and_add_to_object(response)\r\n    807 \r\n\r\n\/opt\/hostedtoolcache\/Python\/3.8.5\/x64\/lib\/python3.8\/site-packages\/azureml\/_restclient\/environment_client.py in _register_environment_definition(self, environment_dict)\r\n     75             message = \"Error registering the environment definition. Code: ***\\n: ***\".format(response.status_code,\r\n     76                                                                                             response.text)\r\n---> 77             raise Exception(message)\r\n     78 \r\n     79     def _get_image_details(self, name, version=None):\r\n\r\nException: Error registering the environment definition. Code: 409\r\n: ***\r\n  \"error\": ***\r\n    \"code\": \"TransientError\",\r\n    \"severity\": null,\r\n    \"message\": \"Etag conflict on 0e149764-3720-4610-b0f3-3e3f974544ac\/8f54aa7d6c05b2722ba149d8ea3185c263ecf5310eb2d7271569d1918c736972 with etag .\",\r\n    \"messageFormat\": null,\r\n    \"messageParameters\": null,\r\n    \"referenceCode\": null,\r\n    \"detailsUri\": null,\r\n    \"target\": null,\r\n    \"details\": [],\r\n    \"innerError\": null,\r\n    \"debugInfo\": null\r\n  ***,\r\n  \"correlation\": ***\r\n    \"operation\": \"db22e6e6bfa07f499f1749f708b798c9\",\r\n    \"request\": \"f470e9430c5ed842\"\r\n  ***,\r\n  \"environment\": \"eastus\",\r\n  \"location\": \"eastus\",\r\n  \"time\": \"2020-10-01T20:17:52.8383774+00:00\",\r\n  \"componentName\": \"environment-management\"\r\n***\r\n\r\nError: Process completed with exit code 1.\r\n```",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"project run fail consist etag error log run papermil notebook sklearn train diabet mlproject ipynb ipynb python input notebook notebook sklearn train diabet mlproject ipynb output notebook ipynb execut sy exit papermil file opt hostedtoolcach python lib python site packag click core line return self main arg kwarg file opt hostedtoolcach python lib python site packag click core line main self invok ctx file opt hostedtoolcach python lib python site packag click core line invok return ctx invok self callback ctx param file opt hostedtoolcach python lib python site packag click core line invok return callback arg kwarg file opt hostedtoolcach python lib python site packag click decor line new func return current context arg kwarg file opt hostedtoolcach python lib python site packag papermil cli line papermil execut notebook file opt hostedtoolcach python lib python site packag papermil execut line execut notebook rais execut error output path file opt hostedtoolcach python lib python site packag papermil execut line rais execut error rais error papermil except papermillexecutionerror except encount except traceback recent run project run uri str project uri paramet alpha backend backend config backend config opt hostedtoolcach python lib python site packag project init run uri entri point version paramet docker arg experi experi backend backend config us conda storag dir synchron run submit run obj run uri uri experi experi opt hostedtoolcach python lib python site packag project init run uri experi entri point version paramet docker arg backend backend config us conda storag dir synchron backend loader load backend backend backend submit run backend run uri entri point opt hostedtoolcach python lib python site packag intern project run self project uri entri point param version backend config track uri experi comput comput local comput local upper remot environ load remot environ mlproject remot environ regist workspac workspac cpu cluster load comput target workspac backend config src run config target cpu cluster opt hostedtoolcach python lib python site packag core environ regist self workspac environ client environmentcli workspac servic context environ dict environ serial dict self respons environ client regist environ definit environ dict env environ deseri add object respons opt hostedtoolcach python lib python site packag restclient environ client regist environ definit self environ dict messag error regist environ definit code format respons statu code respons text rais except messag def imag detail self version except error regist environ definit code error code transienterror sever null messag etag conflict efac faadcbbadeacecfebddc etag messageformat null messageparamet null referencecod null detailsuri null target null detail innererror null debuginfo null correl oper dbeebfafffbc request fece environ eastu locat eastu time componentnam environ manag error process complet exit code",
        "Issue_preprocessed_content":"fail consist etag log",
        "Issue_gpt_summary_original":"The user encountered an MlflowException while running a double ensemble on Google Colab. They were able to solve some issues by cloning the repo and reinstalling numpy, but they are unsure how to solve this particular issue. The error message indicates an invalid value for metric 'IC' and a value error related to duplicate bin edges. The user followed instructions to download cn data and provided a yaml file with configuration details.",
        "Issue_gpt_summary":"user encount except run doubl ensembl googl colab abl solv issu clone repo reinstal numpi unsur solv particular issu error messag indic invalid valu metric valu error relat duplic bin edg user follow instruct download data provid yaml file configur detail",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/776",
        "Issue_title":"AttributeError: 'Workspace' object has no attribute 'get_mlflow_tracking_uri'",
        "Issue_created_time":1581064035000,
        "Issue_closed_time":1581065545000,
        "Issue_body":"I receive the following error when running the following [notebook](https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/4c0cbac8348f18c502a63996fdee59c3fe682b79\/how-to-use-azureml\/track-and-monitor-experiments\/using-mlflow\/train-local\/train-local.ipynb)\r\n\r\n```python\r\nIn [6]: ws.get_mlflow_tracking_uri()\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-6-6c16e13b21e5> in <module>\r\n----> 1 ws.get_mlflow_tracking_uri()\r\n\r\nAttributeError: 'Workspace' object has no attribute 'get_mlflow_tracking_uri'\r\n```",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"attributeerror workspac object attribut track uri receiv follow error run follow notebook http github com azur machinelearningnotebook blob ccbacfcafdeecfeb us track monitor experi train local train local ipynb python track uri attributeerror traceback recent track uri attributeerror workspac object attribut track uri",
        "Issue_preprocessed_content":"workspac object receiv",
        "Issue_gpt_summary_original":"The user is encountering an issue where the Flask application startup fails due to an import error related to NeptuneConfig. The possible solution suggested is to make NeptuneConfig discoverable by the service. The user has followed the guide to set up the service to use Neptune and has deployed a container based on the amundsen-metadata image but is unable to start the app. The user is unable to connect to the Neptune cluster and is seeking assistance.",
        "Issue_gpt_summary":"user encount issu flask applic startup fail import error relat config possibl solut suggest config discover servic user follow guid set servic us deploi contain base amundsen metadata imag unabl start app user unabl connect cluster seek assist",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/qlib\/issues\/1317",
        "Issue_title":"on qrun:\"mlflow.exceptions.MlflowException: Param value .... had length 780, which exceeded length limit of 500 \"",
        "Issue_created_time":1665708717000,
        "Issue_closed_time":1667718001000,
        "Issue_body":"## \ud83d\udc1b Bug Description\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\nwhen I do the example:\r\nqrun qrun benchmarks\\GATs\\workflow_config_gats_Alpha158.yaml\r\n\r\nI got the error info:\r\n\r\n\r\n\r\n(py38) D:\\worksPool\\works2021\\adair2021\\S92\\P4\\qlib-main\\examples>qrun benchmarks\\GATs\\workflow_config_gats_Alpha158_full02.yaml\r\n[7724:MainThread](2022-10-14 07:53:33,890) INFO - qlib.Initialization - [config.py:413] - default_conf: client.\r\n[7724:MainThread](2022-10-14 07:53:33,890) INFO - qlib.workflow - [expm.py:31] - experiment manager uri is at file:D:\\worksPool\\works2021\\adair2021\\S92\\P4\\qlib-main\\examples\\mlruns\r\n[7724:MainThread](2022-10-14 07:53:33,890) INFO - qlib.Initialization - [__init__.py:74] - qlib successfully initialized based on client settings.\r\n[7724:MainThread](2022-10-14 07:53:33,890) INFO - qlib.Initialization - [__init__.py:76] - data_path={'__DEFAULT_FREQ': WindowsPath('C:\/Users\/adair2019\/.qlib\/qlib_data\/cn_data')}\r\n[7724:MainThread](2022-10-14 07:53:33,906) INFO - qlib.workflow - [expm.py:316] - <mlflow.tracking.client.MlflowClient object at 0x0000017B5D406F40>\r\n[7724:MainThread](2022-10-14 07:53:33,906) INFO - qlib.workflow - [exp.py:260] - Experiment 3 starts running ...\r\n[7724:MainThread](2022-10-14 07:53:34,124) INFO - qlib.workflow - [recorder.py:339] - Recorder 41d40d173e614811bad721127a3204b8 starts running under Experiment 3 ...\r\n'git' \u4e0d\u662f\u5185\u90e8\u6216\u5916\u90e8\u547d\u4ee4\uff0c\u4e5f\u4e0d\u662f\u53ef\u8fd0\u884c\u7684\u7a0b\u5e8f\r\n\u6216\u6279\u5904\u7406\u6587\u4ef6\u3002\r\n[7724:MainThread](2022-10-14 07:53:34,140) INFO - qlib.workflow - [recorder.py:372] - Fail to log the uncommitted code of $CWD when run `git diff`\r\n'git' \u4e0d\u662f\u5185\u90e8\u6216\u5916\u90e8\u547d\u4ee4\uff0c\u4e5f\u4e0d\u662f\u53ef\u8fd0\u884c\u7684\u7a0b\u5e8f\r\n\u6216\u6279\u5904\u7406\u6587\u4ef6\u3002\r\n[7724:MainThread](2022-10-14 07:53:34,158) INFO - qlib.workflow - [recorder.py:372] - Fail to log the uncommitted code of $CWD when run `git status`\r\n'git' \u4e0d\u662f\u5185\u90e8\u6216\u5916\u90e8\u547d\u4ee4\uff0c\u4e5f\u4e0d\u662f\u53ef\u8fd0\u884c\u7684\u7a0b\u5e8f\r\n\u6216\u6279\u5904\u7406\u6587\u4ef6\u3002\r\n[7724:MainThread](2022-10-14 07:53:34,164) INFO - qlib.workflow - [recorder.py:372] - Fail to log the uncommitted code of $CWD when run `git diff --cached`\r\nException in thread Thread-1:\r\nTraceback (most recent call last):\r\n  File \"d:\\ProgramData\\Anaconda3\\envs\\py38\\lib\\site-packages\\mlflow-1.29.0-py3.8.egg\\mlflow\\tracking\\_tracking_service\\client.py\", line 301, in log_param\r\n    self.store.log_param(run_id, param)\r\n  File \"d:\\ProgramData\\Anaconda3\\envs\\py38\\lib\\site-packages\\mlflow-1.29.0-py3.8.egg\\mlflow\\store\\tracking\\file_store.py\", line 887, in log_param\r\n    _validate_param(param.key, param.value)\r\n  File \"d:\\ProgramData\\Anaconda3\\envs\\py38\\lib\\site-packages\\mlflow-1.29.0-py3.8.egg\\mlflow\\utils\\validation.py\", line 148, in _validate_param\r\n    _validate_length_limit(\"Param value\", MAX_PARAM_VAL_LENGTH, value)\r\n  File \"d:\\ProgramData\\Anaconda3\\envs\\py38\\lib\\site-packages\\mlflow-1.29.0-py3.8.egg\\mlflow\\utils\\validation.py\", line 269, in _validate_length_limit\r\n    raise MlflowException(\r\nmlflow.exceptions.MlflowException: Param value '[{'class': 'SignalRecord', 'module_path': 'qlib.workflow.record_temp', 'kwargs': {'model': '<MODEL>', 'dataset': '<DATASET>'}}, {'class': 'SigAnaRecord', 'module_path': 'qlib.workflow.record_temp', 'kwargs': {'ana_long_short': False, 'ann_scaler': 25' had length 780, which exceeded length limit of 500\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"d:\\ProgramData\\Anaconda3\\envs\\py38\\lib\\threading.py\", line 932, in _bootstrap_inner\r\n    self.run()\r\n  File \"d:\\ProgramData\\Anaconda3\\envs\\py38\\lib\\threading.py\", line 870, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"d:\\ProgramData\\Anaconda3\\envs\\py38\\lib\\site-packages\\pyqlib-0.8.6.99-py3.8-win-amd64.egg\\qlib\\utils\\paral.py\", line 91, in run\r\n    data()\r\n  File \"d:\\ProgramData\\Anaconda3\\envs\\py38\\lib\\site-packages\\pyqlib-0.8.6.99-py3.8-win-amd64.egg\\qlib\\workflow\\recorder.py\", line 441, in log_params\r\n    self.client.log_param(self.id, name, data)\r\n  File \"d:\\ProgramData\\Anaconda3\\envs\\py38\\lib\\site-packages\\mlflow-1.29.0-py3.8.egg\\mlflow\\tracking\\client.py\", line 858, in log_param\r\n    self._tracking_client.log_param(run_id, key, value)\r\n  File \"d:\\ProgramData\\Anaconda3\\envs\\py38\\lib\\site-packages\\mlflow-1.29.0-py3.8.egg\\mlflow\\tracking\\_tracking_service\\client.py\", line 305, in log_param\r\n    raise MlflowException(msg, INVALID_PARAMETER_VALUE)\r\nmlflow.exceptions.MlflowException: Param value '[{'class': 'SignalRecord', 'module_path': 'qlib.workflow.record_temp', 'kwargs': {'model': '<MODEL>', 'dataset': '<DATASET>'}}, {'class': 'SigAnaRecord', 'module_path': 'qlib.workflow.record_temp', 'kwargs': {'ana_long_short': False, 'ann_scaler': 25' had length 780, which exceeded length limit of 500\r\n\r\nThe cause of this error is typically due to repeated calls\r\nto an individual run_id event logging.\r\n\r\nIncorrect Example:\r\n---------------------------------------\r\nwith mlflow.start_run():\r\n    mlflow.log_param(\"depth\", 3)\r\n    mlflow.log_param(\"depth\", 5)\r\n---------------------------------------\r\n\r\nWhich will throw an MlflowException for overwriting a\r\nlogged parameter.\r\n\r\nCorrect Example:\r\n---------------------------------------\r\nwith mlflow.start_run():\r\n    with mlflow.start_run(nested=True):\r\n        mlflow.log_param(\"depth\", 3)\r\n    with mlflow.start_run(nested=True):\r\n        mlflow.log_param(\"depth\", 5)\r\n---------------------------------------\r\n\r\nWhich will create a new nested run for each individual\r\nmodel and prevent parameter key collisions within the\r\ntracking store.'\r\n[7724:MainThread](2022-10-14 07:53:35,515) INFO - qlib.GATs - [pytorch_gats_ts.py:81] - GATs pytorch version...\r\n[7724:MainThread](2022-10-14 07:53:35,562) INFO - qlib.GATs - [pytorch_gats_ts.py:100] - GATs parameters setting:\r\nd_feat : 158\r\nhidden_size : 64\r\nnum_layers : 2\r\ndropout : 0.7\r\nn_epochs : 200\r\nlr : 0.0001\r\nmetric : loss\r\nearly_stop : 10\r\noptimizer : adam\r\nloss_type : mse\r\nbase_model : LSTM\r\nmodel_path : None\r\nvisible_GPU : 0\r\nuse_GPU : True\r\nseed : None\r\n[7724:MainThread](2022-10-14 07:53:35,562) INFO - qlib.GATs - [pytorch_gats_ts.py:146] - model:\r\nGATModel(\r\n  (rnn): LSTM(158, 64, num_layers=2, batch_first=True, dropout=0.7)\r\n  (transformation): Linear(in_features=64, out_features=64, bias=True)\r\n  (fc): Linear(in_features=64, out_features=64, bias=True)\r\n  (fc_out): Linear(in_features=64, out_features=1, bias=True)\r\n  (leaky_relu): LeakyReLU(negative_slope=0.01)\r\n  (softmax): Softmax(dim=1)\r\n)\r\n\r\n\r\n\r\n\r\nThen the program re-run again.\r\nI am wondering how to fix it.\r\nThanks a lot.\r\n\r\n\r\n\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1.\r\n1.\r\n1.\r\n\r\n\r\n## Expected Behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n## Screenshot\r\n\r\n<!-- A screenshot of the error message or anything shouldn't appear-->\r\n\r\n## Environment\r\n\r\n**Note**: User could run `cd scripts && python collect_info.py all` under project directory to get system information\r\nand paste them here directly.\r\n\r\n - Qlib version:\r\n - 0.8.6.99'\r\n - Python version:\r\n - 3.8.5\r\n - OS (`Windows`, `Linux`, `MacOS`):\r\n - windows 10\r\n - Commit number (optional, please provide it if you are using the dev version):\r\n\r\n## Additional Notes\r\n\r\n<!-- Add any other information about the problem here. -->\r\n",
        "Issue_answer_count":4,
        "Issue_self_closed":1.0,
        "Answer_body":"I had the same problem TT Same for all the example in `benchmarks\/LightGBM`. This is because mlflow limits the length of params since 1.28.0.\r\nWhile waiting the official qlib developers to find some way to accommodate this, downgrading mlflow to 1.27.0 can be a temp solution. > This is because mlflow limits the length of params since 1.28.0. While waiting the official qlib developers to find some way to accommodate this, downgrading mlflow to 1.27.0 can be a temp solution.\r\n\r\nThank you for help. Wish you have a good day.",
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"qrun except except param valu length exceed length limit bug descript exampl qrun qrun benchmark gat workflow config gat alpha yaml got error info workspool work adair qlib main exampl qrun benchmark gat workflow config gat alpha yaml mainthread info qlib initi config default conf client mainthread info qlib workflow expm experi manag uri file workspool work adair qlib main exampl mainthread info qlib initi init qlib successfulli initi base client set mainthread info qlib initi init data path default freq windowspath user adair qlib qlib data data mainthread info qlib workflow expm mainthread info qlib workflow exp experi start run mainthread info qlib workflow record record ddebadab start run experi git mainthread info qlib workflow record fail log uncommit code cwd run git diff git mainthread info qlib workflow record fail log uncommit code cwd run git statu git mainthread info qlib workflow record fail log uncommit code cwd run git diff cach except thread thread traceback recent file programdata anaconda env lib site packag egg track track servic client line log param self store log param run param file programdata anaconda env lib site packag egg store track file store line log param valid param param kei param valu file programdata anaconda env lib site packag egg util valid line valid param valid length limit param valu max param val length valu file programdata anaconda env lib site packag egg util valid line valid length limit rais except except except param valu class signalrecord modul path qlib workflow record temp kwarg model dataset class siganarecord modul path qlib workflow record temp kwarg ana long short fals ann scaler length exceed length limit handl except except occur traceback recent file programdata anaconda env lib thread line bootstrap inner self run file programdata anaconda env lib thread line run self target self arg self kwarg file programdata anaconda env lib site packag pyqlib win amd egg qlib util paral line run data file programdata anaconda env lib site packag pyqlib win amd egg qlib workflow record line log param self client log param self data file programdata anaconda env lib site packag egg track client line log param self track client log param run kei valu file programdata anaconda env lib site packag egg track track servic client line log param rais except msg invalid paramet valu except except param valu class signalrecord modul path qlib workflow record temp kwarg model dataset class siganarecord modul path qlib workflow record temp kwarg ana long short fals ann scaler length exceed length limit caus error typic repeat call individu run event log incorrect exampl start run log param depth log param depth throw except overwrit log paramet correct exampl start run start run nest true log param depth start run nest true log param depth creat new nest run individu model prevent paramet kei collis track store mainthread info qlib gat pytorch gat gat pytorch version mainthread info qlib gat pytorch gat gat paramet set feat hidden size num layer dropout epoch metric loss earli stop optim adam loss type mse base model lstm model path visibl gpu us gpu true seed mainthread info qlib gat pytorch gat model gatmodel rnn lstm num layer batch true dropout transform linear featur featur bia true linear featur featur bia true linear featur featur bia true leaki relu leakyrelu neg slope softmax softmax dim program run wonder fix thank lot reproduc step reproduc behavior expect behavior screenshot environ note user run script python collect info project directori inform past directli qlib version python version window linux maco window commit number option provid dev version addit note",
        "Issue_preprocessed_content":"param valu length length limit bug descript clear concis descript bug exampl qrun qrun got info info client info experi manag uri info qlib initi base client info info info experi start info record bad start experi git info fail log code cwd run git info fail log code cwd run git info fail log code cwd run except thread traceback file line param file line file line valu valu file line rais except file line file line run file line run data file line data file line kei valu file line rais except param valu info gat pytorch info gat paramet dropout metric optim adam mse lstm true info model gatmodel lstm bia true bia true bia true softmax program wonder fix thank lot reproduc step reproduc behavior expect behavior clear concis descript expect shouldn environ note user run project directori inform past directli qlib version python version window number note inform problem",
        "Issue_gpt_summary_original":"The user encountered a 500 internal server error when using the metadata docker image to interact with the Neptune database. When testing locally, the user found two problems: an error with the read_timeout argument and a MalformedQueryException error. The user suggests removing the read_timeout and write_timeout arguments and replacing Order.decr with Order.desc to fix the issues.",
        "Issue_gpt_summary":"user encount intern server error metadata docker imag interact databas test local user problem error read timeout argument malformedqueryexcept error user suggest remov read timeout write timeout argument replac order decr order desc fix issu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/qlib\/issues\/1298",
        "Issue_title":"not compatible with mlflow v1.28.0",
        "Issue_created_time":1663557425000,
        "Issue_closed_time":null,
        "Issue_body":"when run workflow:\r\n```\r\nqrun ALSTM_workflow_config_alstm_Alpha158.yaml\r\n```  \r\nmlflow v1.27.0 work fine,but failed when with mlflow v1.28.0:\r\n```\r\nFile \"miniconda3\/envs\/qlibdev\/lib\/python3.8\/site-packages\/pyqlib-0.8.6.99-py3.8-linux-x86_64.egg\/qlib\/workflow\/recorder.py\", line 441, in log_params\r\n    self.client.log_param(self.id, name, data)\r\n  File \"miniconda3\/envs\/qlibdev\/lib\/python3.8\/site-packages\/mlflow-1.28.0-py3.8.egg\/mlflow\/tracking\/client.py\", line 852, in log_param\r\n    self._tracking_client.log_param(run_id, key, value)\r\n  File \"miniconda3\/envs\/qlibdev\/lib\/python3.8\/site-packages\/mlflow-1.28.0-py3.8.egg\/mlflow\/tracking\/_tracking_service\/client.py\", line 305, in log_param\r\n    raise MlflowException(msg, INVALID_PARAMETER_VALUE)\r\nmlflow.exceptions.MlflowException: Param value '[{'class': 'SignalRecord', 'module_path': 'qlib.workflow.record_temp', 'kwargs': {'model': '<MODEL>', 'dataset': '<DATASET>'}}, {'class': 'SigAnaRecord', 'module_path': 'qlib.workflow.record_temp', 'kwargs': {'ana_long_short': False, 'ann_scaler': 25' had length 778, which exceeded length limit of 500\r\n```\r\ni think the new mflow feature cause this bug.mlflow limit param valu lengh to 500,by read code ,it can not be overwrite.\r\nmaybe relate with this [issue](https:\/\/github.com\/mlflow\/mlflow\/commit\/d4109d00079355459a9a3df1821f0878877e42a8)\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"compat run workflow qrun alstm workflow config alstm alpha yaml work fine fail file miniconda env qlibdev lib python site packag pyqlib linux egg qlib workflow record line log param self client log param self data file miniconda env qlibdev lib python site packag egg track client line log param self track client log param run kei valu file miniconda env qlibdev lib python site packag egg track track servic client line log param rais except msg invalid paramet valu except except param valu class signalrecord modul path qlib workflow record temp kwarg model dataset class siganarecord modul path qlib workflow record temp kwarg ana long short fals ann scaler length exceed length limit think new mflow featur caus bug limit param valu lengh read code overwrit mayb relat issu http github com commit ddaadffea",
        "Issue_preprocessed_content":"compat run workflow work fine fail think new mflow featur caus bug limit param valu lengh read code overwrit mayb relat",
        "Issue_gpt_summary_original":"The user has encountered an elasticsearch exception while trying to create an index with unsupported parameters for the root mapping definition. The error message indicates that the schema, cluster, description, display_name, column_descriptions, programmatic_descriptions, tags, badges, database, total_usage, name, last_updated_timestamp, unique_usage, column_names, and key fields have unsupported parameters. The user has used Amunsen version Databuilder: 6.7.1 Common 0.26.0 Amundsen-Gremlin 0.0.13 AWS ES: 6.8.",
        "Issue_gpt_summary":"user encount elasticsearch except try creat index unsupport paramet root map definit error messag indic schema cluster descript displai column descript programmat descript tag badg databas total usag updat timestamp uniqu usag column name kei field unsupport paramet user amunsen version databuild common amundsen gremlin aw",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/qlib\/issues\/1035",
        "Issue_title":"run the example workflow_by_code.ipynb, caused MlflowException: Invalid experiment ID: '.ipynb_checkpoints' ",
        "Issue_created_time":1649238776000,
        "Issue_closed_time":null,
        "Issue_body":"## \ud83d\udc1b Bug Description\r\nwhen I run the code below in qlib-main\/examples\/workflow_by_code.ipynb\uff0cit caused MlflowException: Invalid experiment ID: '.ipynb_checkpoints' \r\n###################################\r\n# train model\r\n###################################\r\ndata_handler_config = {\r\n    \"start_time\": \"2008-01-01\",\r\n    \"end_time\": \"2020-08-01\",\r\n    \"fit_start_time\": \"2008-01-01\",\r\n    \"fit_end_time\": \"2014-12-31\",\r\n    \"instruments\": market,\r\n}\r\n\r\ntask = {\r\n    \"model\": {\r\n        \"class\": \"LGBModel\",\r\n        \"module_path\": \"qlib.contrib.model.gbdt\",\r\n        \"kwargs\": {\r\n            \"loss\": \"mse\",\r\n            \"colsample_bytree\": 0.8879,\r\n            \"learning_rate\": 0.0421,\r\n            \"subsample\": 0.8789,\r\n            \"lambda_l1\": 205.6999,\r\n            \"lambda_l2\": 580.9768,\r\n            \"max_depth\": 8,\r\n            \"num_leaves\": 210,\r\n            \"num_threads\": 20,\r\n        },\r\n    },\r\n    \"dataset\": {\r\n        \"class\": \"DatasetH\",\r\n        \"module_path\": \"qlib.data.dataset\",\r\n        \"kwargs\": {\r\n            \"handler\": {\r\n                \"class\": \"Alpha158\",\r\n                \"module_path\": \"qlib.contrib.data.handler\",\r\n                \"kwargs\": data_handler_config,\r\n            },\r\n            \"segments\": {\r\n                \"train\": (\"2008-01-01\", \"2014-12-31\"),\r\n                \"valid\": (\"2015-01-01\", \"2016-12-31\"),\r\n                \"test\": (\"2017-01-01\", \"2020-08-01\"),\r\n            },\r\n        },\r\n    },\r\n}\r\n\r\n# model initiaiton\r\nmodel = init_instance_by_config(task[\"model\"])\r\ndataset = init_instance_by_config(task[\"dataset\"])\r\n\r\n# start exp to train model\r\nwith R.start(experiment_name=\"train_model\"):\r\n    R.log_params(**flatten_dict(task))\r\n    model.fit(dataset)\r\n    R.save_objects(trained_model=model)\r\n    rid = R.get_recorder().id\r\n\r\n=====================\r\nThe whole error message is below\uff1a\r\n[2607:MainThread](2022-04-06 17:38:12,377) INFO - qlib.timer - [log.py:113] - Time cost: 18.919s | Loading data Done\r\n[2607:MainThread](2022-04-06 17:38:12,737) INFO - qlib.timer - [log.py:113] - Time cost: 0.147s | DropnaLabel Done\r\n\/Users\/yzwu\/DevEnv\/miniconda3\/envs\/quant_py38_arm\/lib\/python3.8\/site-packages\/qlib\/data\/dataset\/processor.py:310: SettingWithCopyWarning: \r\nA value is trying to be set on a copy of a slice from a DataFrame.\r\nTry using .loc[row_indexer,col_indexer] = value instead\r\n\r\nSee the caveats in the documentation: https:\/\/pandas.pydata.org\/pandas-docs\/stable\/user_guide\/indexing.html#returning-a-view-versus-a-copy\r\n  df[cols] = df[cols].groupby(\"datetime\").apply(self.zscore_func)\r\n[2607:MainThread](2022-04-06 17:38:14,387) INFO - qlib.timer - [log.py:113] - Time cost: 1.650s | CSZScoreNorm Done\r\n[2607:MainThread](2022-04-06 17:38:14,387) INFO - qlib.timer - [log.py:113] - Time cost: 2.010s | fit & process data Done\r\n[2607:MainThread](2022-04-06 17:38:14,388) INFO - qlib.timer - [log.py:113] - Time cost: 20.930s | Init data Done\r\n[2607:MainThread](2022-04-06 17:38:14,399) INFO - qlib.workflow - [expm.py:315] - <mlflow.tracking.client.MlflowClient object at 0x2859099a0>\r\n[2607:MainThread](2022-04-06 17:38:14,402) WARNING - qlib.workflow - [expm.py:195] - No valid experiment found. Create a new experiment with name train_model.\r\n---------------------------------------------------------------------------\r\nMlflowException                           Traceback (most recent call last)\r\nFile ~\/DevEnv\/miniconda3\/envs\/quant_py38_arm\/lib\/python3.8\/site-packages\/qlib\/workflow\/expm.py:391, in MLflowExpManager._get_exp(self, experiment_id, experiment_name)\r\n    390 try:\r\n--> 391     exp = self.client.get_experiment_by_name(experiment_name)\r\n    392     if exp is None or exp.lifecycle_stage.upper() == \"DELETED\":\r\n\r\nFile ~\/DevEnv\/miniconda3\/envs\/quant_py38_arm\/lib\/python3.8\/site-packages\/mlflow\/tracking\/client.py:462, in MlflowClient.get_experiment_by_name(self, name)\r\n    432 \"\"\"\r\n    433 Retrieve an experiment by experiment name from the backend store\r\n    434 \r\n   (...)\r\n    460     Lifecycle_stage: active\r\n    461 \"\"\"\r\n--> 462 return self._tracking_client.get_experiment_by_name(name)\r\n\r\nFile ~\/DevEnv\/miniconda3\/envs\/quant_py38_arm\/lib\/python3.8\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py:167, in TrackingServiceClient.get_experiment_by_name(self, name)\r\n    163 \"\"\"\r\n    164 :param name: The experiment name.\r\n    165 :return: :py:class:`mlflow.entities.Experiment`\r\n    166 \"\"\"\r\n--> 167 return self.store.get_experiment_by_name(name)\r\n\r\nFile ~\/DevEnv\/miniconda3\/envs\/quant_py38_arm\/lib\/python3.8\/site-packages\/mlflow\/store\/tracking\/abstract_store.py:76, in AbstractStore.get_experiment_by_name(self, experiment_name)\r\n     67 \"\"\"\r\n     68 Fetch the experiment by name from the backend store.\r\n     69 This is a base implementation using ``list_experiments``, derived classes may have\r\n   (...)\r\n     74 :return: A single :py:class:`mlflow.entities.Experiment` object if it exists.\r\n     75 \"\"\"\r\n---> 76 for experiment in self.list_experiments(ViewType.ALL):\r\n     77     if experiment.name == experiment_name:\r\n\r\nFile ~\/DevEnv\/miniconda3\/envs\/quant_py38_arm\/lib\/python3.8\/site-packages\/mlflow\/store\/tracking\/file_store.py:261, in FileStore.list_experiments(self, view_type, max_results, page_token)\r\n    259 try:\r\n    260     # trap and warn known issues, will raise unexpected exceptions to caller\r\n--> 261     experiment = self._get_experiment(exp_id, view_type)\r\n    262     if experiment:\r\n\r\nFile ~\/DevEnv\/miniconda3\/envs\/quant_py38_arm\/lib\/python3.8\/site-packages\/mlflow\/store\/tracking\/file_store.py:337, in FileStore._get_experiment(self, experiment_id, view_type)\r\n    336 self._check_root_dir()\r\n--> 337 _validate_experiment_id(experiment_id)\r\n    338 experiment_dir = self._get_experiment_path(experiment_id, view_type)\r\n\r\nFile ~\/DevEnv\/miniconda3\/envs\/quant_py38_arm\/lib\/python3.8\/site-packages\/mlflow\/utils\/validation.py:267, in _validate_experiment_id(exp_id)\r\n    266 if exp_id is not None and _EXPERIMENT_ID_REGEX.match(exp_id) is None:\r\n--> 267     raise MlflowException(\r\n    268         \"Invalid experiment ID: '%s'\" % exp_id, error_code=INVALID_PARAMETER_VALUE\r\n    269     )\r\n\r\nMlflowException: Invalid experiment ID: '.ipynb_checkpoints'\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nValueError                                Traceback (most recent call last)\r\nFile ~\/DevEnv\/miniconda3\/envs\/quant_py38_arm\/lib\/python3.8\/site-packages\/qlib\/workflow\/expm.py:189, in ExpManager._get_or_create_exp(self, experiment_id, experiment_name)\r\n    187 try:\r\n    188     return (\r\n--> 189         self._get_exp(experiment_id=experiment_id, experiment_name=experiment_name),\r\n    190         False,\r\n    191     )\r\n    192 except ValueError:\r\n\r\nFile ~\/DevEnv\/miniconda3\/envs\/quant_py38_arm\/lib\/python3.8\/site-packages\/qlib\/workflow\/expm.py:397, in MLflowExpManager._get_exp(self, experiment_id, experiment_name)\r\n    396 except MlflowException as e:\r\n--> 397     raise ValueError(\r\n    398         \"No valid experiment has been found, please make sure the input experiment name is correct.\"\r\n    399     ) from e\r\n\r\nValueError: No valid experiment has been found, please make sure the input experiment name is correct.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nMlflowException                           Traceback (most recent call last)\r\nInput In [6], in <cell line: 51>()\r\n     48 dataset = init_instance_by_config(task[\"dataset\"])\r\n     50 # start exp to train model\r\n---> 51 with R.start(experiment_name=\"train_model\"):\r\n     52     R.log_params(**flatten_dict(task))\r\n     53     model.fit(dataset)\r\n\r\nFile ~\/DevEnv\/miniconda3\/envs\/quant_py38_arm\/lib\/python3.8\/contextlib.py:113, in _GeneratorContextManager.__enter__(self)\r\n    111 del self.args, self.kwds, self.func\r\n    112 try:\r\n--> 113     return next(self.gen)\r\n    114 except StopIteration:\r\n    115     raise RuntimeError(\"generator didn't yield\") from None\r\n\r\nFile ~\/DevEnv\/miniconda3\/envs\/quant_py38_arm\/lib\/python3.8\/site-packages\/qlib\/workflow\/__init__.py:69, in QlibRecorder.start(self, experiment_id, experiment_name, recorder_id, recorder_name, uri, resume)\r\n     25 @contextmanager\r\n     26 def start(\r\n     27     self,\r\n   (...)\r\n     34     resume: bool = False,\r\n     35 ):\r\n     36     \"\"\"\r\n     37     Method to start an experiment. This method can only be called within a Python's `with` statement. Here is the example code:\r\n     38 \r\n   (...)\r\n     67         whether to resume the specific recorder with given name under the given experiment.\r\n     68     \"\"\"\r\n---> 69     run = self.start_exp(\r\n     70         experiment_id=experiment_id,\r\n     71         experiment_name=experiment_name,\r\n     72         recorder_id=recorder_id,\r\n     73         recorder_name=recorder_name,\r\n     74         uri=uri,\r\n     75         resume=resume,\r\n     76     )\r\n     77     try:\r\n     78         yield run\r\n\r\nFile ~\/DevEnv\/miniconda3\/envs\/quant_py38_arm\/lib\/python3.8\/site-packages\/qlib\/workflow\/__init__.py:125, in QlibRecorder.start_exp(self, experiment_id, experiment_name, recorder_id, recorder_name, uri, resume)\r\n     84 def start_exp(\r\n     85     self,\r\n     86     *,\r\n   (...)\r\n     92     resume=False,\r\n     93 ):\r\n     94     \"\"\"\r\n     95     Lower level method for starting an experiment. When use this method, one should end the experiment manually\r\n     96     and the status of the recorder may not be handled properly. Here is the example code:\r\n   (...)\r\n    123     An experiment instance being started.\r\n    124     \"\"\"\r\n--> 125     return self.exp_manager.start_exp(\r\n    126         experiment_id=experiment_id,\r\n    127         experiment_name=experiment_name,\r\n    128         recorder_id=recorder_id,\r\n    129         recorder_name=recorder_name,\r\n    130         uri=uri,\r\n    131         resume=resume,\r\n    132     )\r\n\r\nFile ~\/DevEnv\/miniconda3\/envs\/quant_py38_arm\/lib\/python3.8\/site-packages\/qlib\/workflow\/expm.py:339, in MLflowExpManager.start_exp(self, experiment_id, experiment_name, recorder_id, recorder_name, uri, resume)\r\n    337 if experiment_name is None:\r\n    338     experiment_name = self._default_exp_name\r\n--> 339 experiment, _ = self._get_or_create_exp(experiment_id=experiment_id, experiment_name=experiment_name)\r\n    340 # Set up active experiment\r\n    341 self.active_experiment = experiment\r\n\r\nFile ~\/DevEnv\/miniconda3\/envs\/quant_py38_arm\/lib\/python3.8\/site-packages\/qlib\/workflow\/expm.py:202, in ExpManager._get_or_create_exp(self, experiment_id, experiment_name)\r\n    200 if pr.scheme == \"file\":\r\n    201     with FileLock(os.path.join(pr.netloc, pr.path, \"filelock\")):  # pylint: disable=E0110\r\n--> 202         return self.create_exp(experiment_name), True\r\n    203 # NOTE: for other schemes like http, we double check to avoid create exp conflicts\r\n    204 try:\r\n\r\nFile ~\/DevEnv\/miniconda3\/envs\/quant_py38_arm\/lib\/python3.8\/site-packages\/qlib\/workflow\/expm.py:362, in MLflowExpManager.create_exp(self, experiment_name)\r\n    360     if e.error_code == ErrorCode.Name(RESOURCE_ALREADY_EXISTS):\r\n    361         raise ExpAlreadyExistError() from e\r\n--> 362     raise e\r\n    364 experiment = MLflowExperiment(experiment_id, experiment_name, self.uri)\r\n    365 experiment._default_name = self._default_exp_name\r\n\r\nFile ~\/DevEnv\/miniconda3\/envs\/quant_py38_arm\/lib\/python3.8\/site-packages\/qlib\/workflow\/expm.py:358, in MLflowExpManager.create_exp(self, experiment_name)\r\n    356 # init experiment\r\n    357 try:\r\n--> 358     experiment_id = self.client.create_experiment(experiment_name)\r\n    359 except MlflowException as e:\r\n    360     if e.error_code == ErrorCode.Name(RESOURCE_ALREADY_EXISTS):\r\n\r\nFile ~\/DevEnv\/miniconda3\/envs\/quant_py38_arm\/lib\/python3.8\/site-packages\/mlflow\/tracking\/client.py:507, in MlflowClient.create_experiment(self, name, artifact_location, tags)\r\n    464 def create_experiment(\r\n    465     self,\r\n    466     name: str,\r\n    467     artifact_location: Optional[str] = None,\r\n    468     tags: Optional[Dict[str, Any]] = None,\r\n    469 ) -> str:\r\n    470     \"\"\"Create an experiment.\r\n    471 \r\n    472     :param name: The experiment name. Must be unique.\r\n   (...)\r\n    505         Lifecycle_stage: active\r\n    506     \"\"\"\r\n--> 507     return self._tracking_client.create_experiment(name, artifact_location, tags)\r\n\r\nFile ~\/DevEnv\/miniconda3\/envs\/quant_py38_arm\/lib\/python3.8\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py:182, in TrackingServiceClient.create_experiment(self, name, artifact_location, tags)\r\n    179 _validate_experiment_name(name)\r\n    180 _validate_experiment_artifact_location(artifact_location)\r\n--> 182 return self.store.create_experiment(\r\n    183     name=name,\r\n    184     artifact_location=artifact_location,\r\n    185     tags=[ExperimentTag(key, value) for (key, value) in tags.items()] if tags else [],\r\n    186 )\r\n\r\nFile ~\/DevEnv\/miniconda3\/envs\/quant_py38_arm\/lib\/python3.8\/site-packages\/mlflow\/store\/tracking\/file_store.py:321, in FileStore.create_experiment(self, name, artifact_location, tags)\r\n    319 def create_experiment(self, name, artifact_location=None, tags=None):\r\n    320     self._check_root_dir()\r\n--> 321     self._validate_experiment_name(name)\r\n    322     # Get all existing experiments and find the one with largest numerical ID.\r\n    323     # len(list_all(..)) would not work when experiments are deleted.\r\n    324     experiments_ids = [\r\n    325         int(e.experiment_id)\r\n    326         for e in self.list_experiments(ViewType.ALL)\r\n    327         if e.experiment_id.isdigit()\r\n    328     ]\r\n\r\nFile ~\/DevEnv\/miniconda3\/envs\/quant_py38_arm\/lib\/python3.8\/site-packages\/mlflow\/store\/tracking\/file_store.py:303, in FileStore._validate_experiment_name(self, name)\r\n    299 if name is None or name == \"\":\r\n    300     raise MlflowException(\r\n    301         \"Invalid experiment name '%s'\" % name, databricks_pb2.INVALID_PARAMETER_VALUE\r\n    302     )\r\n--> 303 experiment = self.get_experiment_by_name(name)\r\n    304 if experiment is not None:\r\n    305     if experiment.lifecycle_stage == LifecycleStage.DELETED:\r\n\r\nFile ~\/DevEnv\/miniconda3\/envs\/quant_py38_arm\/lib\/python3.8\/site-packages\/mlflow\/store\/tracking\/abstract_store.py:76, in AbstractStore.get_experiment_by_name(self, experiment_name)\r\n     66 def get_experiment_by_name(self, experiment_name):\r\n     67     \"\"\"\r\n     68     Fetch the experiment by name from the backend store.\r\n     69     This is a base implementation using ``list_experiments``, derived classes may have\r\n   (...)\r\n     74     :return: A single :py:class:`mlflow.entities.Experiment` object if it exists.\r\n     75     \"\"\"\r\n---> 76     for experiment in self.list_experiments(ViewType.ALL):\r\n     77         if experiment.name == experiment_name:\r\n     78             return experiment\r\n\r\nFile ~\/DevEnv\/miniconda3\/envs\/quant_py38_arm\/lib\/python3.8\/site-packages\/mlflow\/store\/tracking\/file_store.py:261, in FileStore.list_experiments(self, view_type, max_results, page_token)\r\n    258 for exp_id in rsl:\r\n    259     try:\r\n    260         # trap and warn known issues, will raise unexpected exceptions to caller\r\n--> 261         experiment = self._get_experiment(exp_id, view_type)\r\n    262         if experiment:\r\n    263             experiments.append(experiment)\r\n\r\nFile ~\/DevEnv\/miniconda3\/envs\/quant_py38_arm\/lib\/python3.8\/site-packages\/mlflow\/store\/tracking\/file_store.py:337, in FileStore._get_experiment(self, experiment_id, view_type)\r\n    335 def _get_experiment(self, experiment_id, view_type=ViewType.ALL):\r\n    336     self._check_root_dir()\r\n--> 337     _validate_experiment_id(experiment_id)\r\n    338     experiment_dir = self._get_experiment_path(experiment_id, view_type)\r\n    339     if experiment_dir is None:\r\n\r\nFile ~\/DevEnv\/miniconda3\/envs\/quant_py38_arm\/lib\/python3.8\/site-packages\/mlflow\/utils\/validation.py:267, in _validate_experiment_id(exp_id)\r\n    265 \"\"\"Check that `experiment_id`is a valid string or None, raise an exception if it isn't.\"\"\"\r\n    266 if exp_id is not None and _EXPERIMENT_ID_REGEX.match(exp_id) is None:\r\n--> 267     raise MlflowException(\r\n    268         \"Invalid experiment ID: '%s'\" % exp_id, error_code=INVALID_PARAMETER_VALUE\r\n    269     )\r\n\r\nMlflowException: Invalid experiment ID: '.ipynb_checkpoints'\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. just rerun the code in my envirment\r\n\r\n\r\n## Expected Behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n## Screenshot\r\n\r\n<!-- A screenshot of the error message or anything shouldn't appear-->\r\n\r\n## Environment\r\n\r\n**Note**: User could run `cd scripts && python collect_info.py all` under project directory to get system information\r\nand paste them here directly.\r\n\r\nDarwin\r\narm64\r\nmacOS-12.2.1-arm64-arm-64bit\r\nDarwin Kernel Version 21.3.0: Wed Jan  5 21:37:58 PST 2022; root:xnu-8019.80.24~20\/RELEASE_ARM64_T6000\r\n\r\nPython version: 3.8.11 (default, Jul 29 2021, 14:57:32)  [Clang 12.0.0 ]\r\n\r\nQlib version: 0.8.4.99\r\nnumpy==1.22.3\r\npandas==1.4.2\r\nscipy==1.8.0\r\nrequests==2.25.1\r\nsacred==0.8.2\r\npython-socketio==5.5.2\r\nredis==4.2.2\r\npython-redis-lock==3.7.0\r\nschedule==1.1.0\r\ncvxpy==1.1.18\r\nhyperopt==0.1.2\r\nfire==0.4.0\r\nstatsmodels==0.13.2\r\nxlrd==2.0.1\r\nplotly==5.6.0\r\nmatplotlib==3.5.1\r\ntables==3.7.0\r\npyyaml==6.0\r\nmlflow==1.24.0\r\ntqdm==4.61.2\r\nloguru==0.6.0\r\nlightgbm==3.3.2\r\ntornado==6.1\r\njoblib==1.1.0\r\nfire==0.4.0\r\nruamel.yaml==0.17.21\r\n\r\n\r\n## Additional Notes\r\n\r\nI installed qlib from source, and my conda env is the version for arm64\r\n",
        "Issue_answer_count":2,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"run exampl workflow code ipynb caus except invalid experi ipynb checkpoint bug descript run code qlib main exampl workflow code ipynbit caus except invalid experi ipynb checkpoint train model data handler config start time end time fit start time fit end time instrument market task model class lgbmodel modul path qlib contrib model gbdt kwarg loss mse colsampl bytre learn rate subsampl lambda lambda max depth num leav num thread dataset class dataseth modul path qlib data dataset kwarg handler class alpha modul path qlib contrib data handler kwarg data handler config segment train valid test model initiaiton model init instanc config task model dataset init instanc config task dataset start exp train model start experi train model log param flatten dict task model fit dataset save object train model model rid record error messag mainthread info qlib timer log time cost load data mainthread info qlib timer log time cost dropnalabel user yzwu devenv miniconda env quant arm lib python site packag qlib data dataset processor settingwithcopywarn valu try set copi slice datafram try loc row index col index valu instead caveat document http panda pydata org panda doc stabl user guid index html return view versu copi col col groupbi datetim appli self zscore func mainthread info qlib timer log time cost cszscorenorm mainthread info qlib timer log time cost fit process data mainthread info qlib timer log time cost init data mainthread info qlib workflow expm mainthread warn qlib workflow expm valid experi creat new experi train model except traceback recent file devenv miniconda env quant arm lib python site packag qlib workflow expm expmanag exp self experi experi try exp self client experi experi exp exp lifecycl stage upper delet file devenv miniconda env quant arm lib python site packag track client client experi self retriev experi experi backend store lifecycl stage activ return self track client experi file devenv miniconda env quant arm lib python site packag track track servic client trackingservicecli experi self param experi return class entiti experi return self store experi file devenv miniconda env quant arm lib python site packag store track abstract store abstractstor experi self experi fetch experi backend store base implement list experi deriv class return singl class entiti experi object exist experi self list experi viewtyp experi experi file devenv miniconda env quant arm lib python site packag store track file store filestor list experi self view type max result page token try trap warn known issu rais unexpect except caller experi self experi exp view type experi file devenv miniconda env quant arm lib python site packag store track file store filestor experi self experi view type self check root dir valid experi experi experi dir self experi path experi view type file devenv miniconda env quant arm lib python site packag util valid valid experi exp exp experi regex match exp rais except invalid experi exp error code invalid paramet valu except invalid experi ipynb checkpoint except direct caus follow except valueerror traceback recent file devenv miniconda env quant arm lib python site packag qlib workflow expm expmanag creat exp self experi experi try return self exp experi experi experi experi fals valueerror file devenv miniconda env quant arm lib python site packag qlib workflow expm expmanag exp self experi experi except rais valueerror valid experi sure input experi correct valueerror valid experi sure input experi correct handl except except occur except traceback recent input dataset init instanc config task dataset start exp train model start experi train model log param flatten dict task model fit dataset file devenv miniconda env quant arm lib python contextlib generatorcontextmanag enter self del self arg self kwd self func try return self gen stopiter rais runtimeerror gener yield file devenv miniconda env quant arm lib python site packag qlib workflow init qlibrecord start self experi experi record record uri resum contextmanag def start self resum bool fals method start experi method call python statement exampl code resum specif record given given experi run self start exp experi experi experi experi record record record record uri uri resum resum try yield run file devenv miniconda env quant arm lib python site packag qlib workflow init qlibrecord start exp self experi experi record record uri resum def start exp self resum fals lower level method start experi us method end experi manual statu record handl properli exampl code experi instanc start return self exp manag start exp experi experi experi experi record record record record uri uri resum resum file devenv miniconda env quant arm lib python site packag qlib workflow expm expmanag start exp self experi experi record record uri resum experi experi self default exp experi self creat exp experi experi experi experi set activ experi self activ experi experi file devenv miniconda env quant arm lib python site packag qlib workflow expm expmanag creat exp self experi experi scheme file filelock path join netloc path filelock pylint disabl return self creat exp experi true note scheme like http doubl check avoid creat exp conflict try file devenv miniconda env quant arm lib python site packag qlib workflow expm expmanag creat exp self experi error code errorcod resourc exist rais expalreadyexisterror rais experi experi experi experi self uri experi default self default exp file devenv miniconda env quant arm lib python site packag qlib workflow expm expmanag creat exp self experi init experi try experi self client creat experi experi except error code errorcod resourc exist file devenv miniconda env quant arm lib python site packag track client client creat experi self artifact locat tag def creat experi self str artifact locat option str tag option dict str str creat experi param experi uniqu lifecycl stage activ return self track client creat experi artifact locat tag file devenv miniconda env quant arm lib python site packag track track servic client trackingservicecli creat experi self artifact locat tag valid experi valid experi artifact locat artifact locat return self store creat experi artifact locat artifact locat tag experimenttag kei valu kei valu tag item tag file devenv miniconda env quant arm lib python site packag store track file store filestor creat experi self artifact locat tag def creat experi self artifact locat tag self check root dir self valid experi exist experi largest numer len list work experi delet experi id int experi self list experi viewtyp experi isdigit file devenv miniconda env quant arm lib python site packag store track file store filestor valid experi self rais except invalid experi databrick invalid paramet valu experi self experi experi experi lifecycl stage lifecyclestag delet file devenv miniconda env quant arm lib python site packag store track abstract store abstractstor experi self experi def experi self experi fetch experi backend store base implement list experi deriv class return singl class entiti experi object exist experi self list experi viewtyp experi experi return experi file devenv miniconda env quant arm lib python site packag store track file store filestor list experi self view type max result page token exp rsl try trap warn known issu rais unexpect except caller experi self experi exp view type experi experi append experi file devenv miniconda env quant arm lib python site packag store track file store filestor experi self experi view type def experi self experi view type viewtyp self check root dir valid experi experi experi dir self experi path experi view type experi dir file devenv miniconda env quant arm lib python site packag util valid valid experi exp check experi valid string rais except isn exp experi regex match exp rais except invalid experi exp error code invalid paramet valu except invalid experi ipynb checkpoint reproduc step reproduc behavior rerun code envir expect behavior screenshot environ note user run script python collect info project directori inform past directli darwin arm maco arm arm bit darwin kernel version wed jan pst root xnu releas arm python version default jul clang qlib version numpi panda scipi request python socketio redi python redi lock schedul cvxpy hyperopt statsmodel xlrd plotli matplotlib tabl pyyaml tqdm loguru lightgbm tornado joblib ruamel yaml addit note instal qlib sourc conda env version arm",
        "Issue_preprocessed_content":"run exampl caus except invalid experi bug descript run code caus except invalid experi train model task dataset segment model initiaiton model dataset start exp train model rid info time cost load data info time cost dropnalabel valu try set copi slice datafram try valu instead caveat document info time cost cszscorenorm info time cost fit data info time cost init data info warn valid experi creat new experi except traceback file try exp exp delet file retriev experi experi backend store activ return file param experi return return file fetch experi backend store base implement deriv return singl object exist experi file try trap warn known rais unexpect except experi experi file file rais except except invalid experi except direct caus except traceback file try return fals file except rais valid experi sure input experi handl except except except traceback input dataset start exp train model file del try return stopiter rais file uri resum def start resum fals method start experi method python statement exampl code resum specif record given given experi run uri uri resum resum try yield run file uri resum def self resum fals lower level method start experi us method end experi statu record handl properli exampl code experi instanc start return uri uri resum resum file uri resum experi set activ experi experi file file filelock pylint disabl return true note scheme like doubl check avoid creat exp conflict try file rais rais experi file init experi try except file tag def self str option tag option str creat experi param experi uniqu activ return tag file tag return tag tag file tag def tag exist experi largest numer work experi delet file rais except experi experi file def fetch experi backend store base implement deriv return singl object exist experi return experi file rsl try trap warn known rais unexpect except experi experi file def file check valid string rais except rais except except invalid experi reproduc step reproduc behavior rerun code envir expect behavior clear concis descript expect shouldn environ note user run project directori inform past directli darwin arm darwin kernel version wed jan pst python version qlib version note qlib sourc conda env version arm",
        "Issue_gpt_summary_original":"The issue is with the `NeptuneBulkLoaderApi` constructing the IAM role ARN incorrectly for AWS regions other than global, which causes problems when using Amundsen in AWS China. The expected behavior is for the IAM role ARN to take the AWS partition into account or for there to be an option to pass the IAM role ARN directly. Two possible solutions are proposed: adding the partition into the current code or adding an option to pass the IAM role ARN directly. The user suggests a fix for the first solution, but it may not work in all situations. The second solution involves adding a new config key, which may not be backward compatible. The user encountered an error when trying to load data into Neptune due to the incorrect IAM",
        "Issue_gpt_summary":"issu bulkloaderapi construct iam role arn incorrectli aw region global caus problem amundsen aw china expect behavior iam role arn aw partit account option pass iam role arn directli possibl solut propos ad partit current code ad option pass iam role arn directli user suggest fix solut work situat second solut involv ad new config kei backward compat user encount error try load data incorrect iam",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/microsoft\/qlib\/issues\/369",
        "Issue_title":"Double Ensemble MlflowException",
        "Issue_created_time":1616595419000,
        "Issue_closed_time":null,
        "Issue_body":"hi, so i ran a cn data on google colab. alstm worked fine but double ensemble keep giving issues, i manage to solve some by cloning the repo and install via setup.py and uninstalling \/ reinstalling numpy. but this one i do not know how to solve:\r\nMlflowException: Got invalid value Series([], dtype: float64) for metric 'IC' (timestamp=1616595157552). Please specify value as a valid double (64-bit floating point)\r\n\r\nif i have only sh000300 in my instruments, it's gonna produce the following value error:\r\nValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]).\r\nYou can drop duplicate edges by setting the 'duplicates' kwarg\r\n\r\ni followed instructions on data collector's markdown page to download cn data up until 03\/01\/2021. my yaml file looks like this:\r\nqlib_init:\r\n    provider_uri: \"\/content\/gdrive\/MyDrive\/qlib\/qlib_data\/qlib_cn_1d\"\r\n    region: cn\r\nmarket: &market \r\nbenchmark: &benchmark SH000300\r\ndata_handler_config: &data_handler_config\r\n    start_time: 2008-01-01\r\n    end_time: 2021-03-01\r\n    fit_start_time: 2008-01-01\r\n    fit_end_time: 2018-12-31\r\n    instruments: ['SH000300', 'SH000903']\r\nport_analysis_config: &port_analysis_config\r\n    strategy:\r\n        class: TopkDropoutStrategy\r\n        module_path: qlib.contrib.strategy.strategy\r\n        kwargs:\r\n            topk: 50\r\n            n_drop: 5\r\n    backtest:\r\n        verbose: True\r\n        limit_threshold: 0.095\r\n        account: 50000\r\n        benchmark: *benchmark\r\n        deal_price: close\r\n        open_cost: 0.0005\r\n        close_cost: 0.0015\r\n        min_cost: 5\r\ntask:\r\n    model:\r\n        class: DEnsembleModel\r\n        module_path: qlib.contrib.model.double_ensemble\r\n        kwargs:\r\n            base_model: \"gbm\"\r\n            loss: mse\r\n            num_models: 6\r\n            enable_sr: True\r\n            enable_fs: True\r\n            alpha1: 1\r\n            alpha2: 1\r\n            bins_sr: 10\r\n            bins_fs: 5\r\n            decay: 0.5\r\n            sample_ratios:\r\n                - 0.8\r\n                - 0.7\r\n                - 0.6\r\n                - 0.5\r\n                - 0.4\r\n            sub_weights:\r\n                - 1\r\n                - 0.2\r\n                - 0.2\r\n                - 0.2\r\n                - 0.2\r\n                - 0.2\r\n            epochs: 28\r\n            colsample_bytree: 0.8879\r\n            learning_rate: 0.2\r\n            subsample: 0.8789\r\n            lambda_l1: 205.6999\r\n            lambda_l2: 580.9768\r\n            max_depth: 8\r\n            num_leaves: 210\r\n            num_threads: 20\r\n            verbosity: -1\r\n    dataset:\r\n        class: DatasetH\r\n        module_path: qlib.data.dataset\r\n        kwargs:\r\n            handler:\r\n                class: Alpha158\r\n                module_path: qlib.contrib.data.handler\r\n                kwargs: *data_handler_config\r\n            segments:\r\n                train: [2008-01-01, 2018-12-31]\r\n                valid: [2019-01-01, 2020-07-31]\r\n                test: [2020-08-01, 2020-03-01]\r\n    record:\r\n        - class: SignalRecord\r\n          module_path: qlib.workflow.record_temp\r\n          kwargs: {}\r\n        - class: SigAnaRecord\r\n          module_path: qlib.workflow.record_temp\r\n          kwargs:\r\n            ana_long_short: False\r\n            ann_scaler: 252\r\n        - class: PortAnaRecord\r\n          module_path: qlib.workflow.record_temp\r\n          kwargs:\r\n            config: *port_analysis_config\r\n\r\nthanks for answering in advance.",
        "Issue_answer_count":1,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"MLflow",
        "Platform":"Github",
        "Issue_original_content":"doubl ensembl except ran data googl colab alstm work fine doubl ensembl give issu manag solv clone repo instal setup uninstal reinstal numpi know solv except got invalid valu seri dtype float metric timestamp specifi valu valid doubl bit float point instrument gonna produc follow valu error valueerror bin edg uniqu arrai nan nan nan nan nan nan nan nan nan nan nan drop duplic edg set duplic kwarg follow instruct data collector markdown page download data yaml file look like qlib init provid uri content gdrive mydriv qlib qlib data qlib region market market benchmark benchmark data handler config data handler config start time end time fit start time fit end time instrument port analysi config port analysi config strategi class topkdropoutstrategi modul path qlib contrib strategi strategi kwarg topk drop backtest verbos true limit threshold account benchmark benchmark deal price close open cost close cost min cost task model class densemblemodel modul path qlib contrib model doubl ensembl kwarg base model gbm loss mse num model enabl true enabl true alpha alpha bin bin decai sampl ratio sub weight epoch colsampl bytre learn rate subsampl lambda lambda max depth num leav num thread verbos dataset class dataseth modul path qlib data dataset kwarg handler class alpha modul path qlib contrib data handler kwarg data handler config segment train valid test record class signalrecord modul path qlib workflow record temp kwarg class siganarecord modul path qlib workflow record temp kwarg ana long short fals ann scaler class portanarecord modul path qlib workflow record temp kwarg config port analysi config thank answer advanc",
        "Issue_preprocessed_content":"doubl ensembl except ran data colab alstm work fine doubl ensembl give manag solv clone repo numpi know solv except got invalid valu seri metric specifi valu valid doubl instrument produc valu bin edg uniqu drop duplic edg duplic kwarg instruct data markdown page download data yaml file like region market market benchmark benchmark instrument strategi topkdropoutstrategi kwarg topk backtest verbos true benchmark benchmark close task model densemblemodel kwarg gbm mse true true alpha alpha decai epoch subsampl verbos dataset dataseth kwarg handler alpha kwarg segment train valid test record signalrecord kwarg siganarecord kwarg fals portanarecord kwarg config thank answer advanc",
        "Issue_gpt_summary_original":"The user is facing an issue where configuration options such as `auth_mode` and `region` are not set correctly when using the CN region Neptune endpoint as the host. This is because the code misidentifies the endpoint as a non-AWS endpoint due to an incorrect DNS suffix check. The user needs to change all the checks to \"amazonaws.com\" to resolve the issue.",
        "Issue_gpt_summary":"user face issu configur option auth mode region set correctli region endpoint host code misidentifi endpoint non aw endpoint incorrect dn suffix check user need chang check amazonaw com resolv issu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/amundsen-io\/amundsen\/issues\/2013",
        "Issue_title":"Bug Report: NeptuneConfig import failing - Flask",
        "Issue_created_time":1666114324000,
        "Issue_closed_time":1666184788000,
        "Issue_body":"## Expected Behavior\r\nThe metadata service (using Neptune) to start successfully.\r\n\r\n## Current Behavior\r\nFlask application startup fails due to an import error - `ImportError: module 'metadata_service.config' has no attribute 'NeptuneConfig'`\r\n\r\n## Possible Solution\r\nMake the NeptuneConfig discoverable by the service.\r\n\r\n## Steps to Reproduce\r\n1. Deploy a container based on the amundsen-metadata image (latest)\r\n2. Follow this [guide](https:\/\/github.com\/amundsen-io\/amundsen\/blob\/08839140b774acb50018813511db17cb0056500c\/docs\/tutorials\/how-to-use-amundsen-with-aws-neptune.md) to set up the service to use Neptune i.e. configure env vars\r\n3. Start container and the app is unable to start\r\n\r\n## Screenshots (if appropriate)\r\n![Screenshot 2022-10-18 at 18 31 04](https:\/\/user-images.githubusercontent.com\/36985452\/196503029-9ff2c833-e54f-4be0-a79e-80cfae510fed.png)\r\n\r\n## Context\r\nI cannot start an ECS task based on this image and therefore can't connect to the Neptune cluster.\r\n\r\n## Your Environment\r\n",
        "Issue_answer_count":3,
        "Issue_self_closed":1.0,
        "Answer_body":"Thanks for opening your first issue here!\n Any solution for this? > Any solution for this?\r\n\r\nThe error message was a bit of a red herring. The actual problem was amundsen-gremlin isn't installed as part of the base image creation `amundsendev\/amundsen-metadata`.\r\n\r\nSolution 1 - add the package to the requirements files and rebuild your own Amundsen image\r\n\r\nSolution 2 - build on the base image and add a `RUN pip install amundsen-gremlin` to your bespoke dockerfile. For my use case I've gone with the latter.",
        "Tool":"Neptune",
        "Platform":"Github",
        "Issue_original_content":"bug report config import fail flask expect behavior metadata servic start successfulli current behavior flask applic startup fail import error importerror modul metadata servic config attribut config possibl solut config discover servic step reproduc deploi contain base amundsen metadata imag latest follow guid http github com amundsen amundsen blob bacbdbcbc doc tutori us amundsen aw set servic us configur env var start contain app unabl start screenshot appropri screenshot http user imag githubusercont com ffc cfaef png context start ec task base imag connect cluster environ",
        "Issue_preprocessed_content":"bug report config import fail flask expect behavior metadata servic start behavior flask startup fail import solut config discover servic step reproduc deploi contain base imag set servic us configur env var start contain unabl start context start ec task base imag cluster environ",
        "Issue_gpt_summary_original":"The Neptune ML Export widget is throwing an error when the user tries to export data using a specific command from the Node Classification notebook. The error message states that the credential should be scoped to the correct service, 'execute-api'. The expected behavior is for the export to run to completion.",
        "Issue_gpt_summary":"export widget throw error user tri export data specif command node classif notebook error messag state credenti scope correct servic execut api expect behavior export run complet",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/amundsen-io\/amundsen\/issues\/1946",
        "Issue_title":"Neptune MalformedQueryException",
        "Issue_created_time":1659310549000,
        "Issue_closed_time":1664069854000,
        "Issue_body":"<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Look through existing open and closed issues to see if someone has reported the issue before -->\r\nI started to use amundsen metadata with Neptune database. Initially I used the metadata docker image to interact with the database, but every tested route gave me a 500 internal server error. So I tested it locally, using a VPN to connect to neptune db, and I found 2 problems. I'll do a PR linked to the issue that solves the problems\r\n## Expected Behavior\r\n<!--- Tell us what should happen -->\r\nWhen calling a route of the metadata api for the neptune service, the server should respond without problem\r\n## Current Behavior\r\n<!--- Tell us what happens instead of the expected behavior -->\r\n1. When calling the api to retrieve (for example) a table description, there's an error `got an unexpected keyword argument 'read_timeout'`. This error has already be identified in https:\/\/github.com\/amundsen-io\/amundsen\/issues\/1382\r\n2. After the correction of 1, another error during the same request\r\n```json\r\n{\r\n    \"detailedMessage\": \"Failed to interpret Gremlin query: Query parsing failed at line 1, character position at 208, error message : token recognition error at: 'dec'\",\r\n    \"code\": \"MalformedQueryException\",\r\n    \"requestId\": \"25542307-96bb-40d2-9585-5a340b8d868c\"\r\n}\r\n```\r\n## Possible Solution\r\n<!--- Not obligatory, but suggest a fix\/reason for the bug -->\r\n1. Initialize `TornadoTransport` class properly, removing `read_timeout` and `write_timeout` in  `gremlin_proxy.py` file\r\n2. Move `Order.decr`to `Order.desc` for `_get_table_columns` and `_get_popular_tables_uris` functions in `gremlin_proxy.py` file. The Order.decr and Order.incr are deprecated and don't work with neptune\r\n## Steps to Reproduce\r\n<!--- Provide a link to a live example, or an unambiguous set of steps to -->\r\n<!--- reproduce this bug. Include code to reproduce, if relevant -->\r\n1. Call the `\/table\/{table_uri}` metadata route using the gremlin metadata service with AWS Neptune db\r\n## Screenshots (if appropriate)\r\n\r\n## Context\r\n<!--- How has this issue affected you? -->\r\n<!--- Providing context helps us come up with a solution that is most useful in the real world -->\r\n\r\n## Your Environment\r\n<!--- Include as many relevant details about the environment you experienced the bug in -->\r\n* Amunsen version used: last (metadata-3.10.0)\r\n* Data warehouse stores: snowflake\r\n* Deployment (k8s or native):\r\n* Link to your fork or repository: https:\/\/github.com\/ggirodda\/amundsen\/tree\/main",
        "Issue_answer_count":4,
        "Issue_self_closed":0.0,
        "Answer_body":"Thanks for opening your first issue here!\n The PR that solves the issue in my case https:\/\/github.com\/amundsen-io\/amundsen\/pull\/1947\/files This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs.\n This issue has been automatically closed for inactivity. If you still wish to make these changes, please open a new pull request or reopen this one.\n",
        "Tool":"Neptune",
        "Platform":"Github",
        "Issue_original_content":"malformedqueryexcept start us amundsen metadata databas initi metadata docker imag interact databas test rout gave intern server error test local vpn connect problem link issu solv problem expect behavior call rout metadata api servic server respond problem current behavior call api retriev exampl tabl descript error got unexpect keyword argument read timeout error identifi http github com amundsen amundsen issu correct error request json detailedmessag fail interpret gremlin queri queri pars fail line charact posit error messag token recognit error dec code malformedqueryexcept requestid abdc possibl solut initi tornadotransport class properli remov read timeout write timeout gremlin proxi file order decr order desc tabl column popular tabl uri function gremlin proxi file order decr order incr deprec work step reproduc tabl tabl uri metadata rout gremlin metadata servic aw screenshot appropri context environ amunsen version metadata data warehous store snowflak deploy nativ link fork repositori http github com ggirodda amundsen tree main",
        "Issue_preprocessed_content":"malformedqueryexcept exist open close report start us amundsen metadata databas metadata docker imag interact databas test rout gave intern server test vpn problem link solv problem expect behavior rout metadata api servic server respond problem behavior instead expect behavior api retriev tabl descript identifi request solut obligatori bug initi properli remov file function file deprec work step reproduc provid link live exampl unambigu set step reproduc bug includ code reproduc relev metadata rout gremlin metadata servic aw context provid context help come solut us real world environ includ relev detail environ experienc bug amunsen version data warehous store snowflak deploy link fork repositori",
        "Issue_gpt_summary_original":"The user is facing an issue with the limit parameter in their code, which is not working and throwing an error. The code is related to the introduction to Node Classification Gremlin, and the error message suggests that there may be an issue with the service configuration or query. The user is seeking suggestions on whether there is something wrong with the code mentioned in the document.",
        "Issue_gpt_summary":"user face issu limit paramet code work throw error code relat introduct node classif gremlin error messag suggest issu servic configur queri user seek suggest wrong code mention document",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/amundsen-io\/amundsen\/issues\/1748",
        "Issue_title":"Bug Report elasticsearch exception for sample_neptune_loader",
        "Issue_created_time":1646313579000,
        "Issue_closed_time":1649071896000,
        "Issue_body":"<!--- Provide a general summary of the issue in the Title above -->\r\n<!--- Look through existing open and closed issues to see if someone has reported the issue before -->\r\n\r\n## Expected Behavior\r\n<WARNING:elasticsearch:PUT https:\/\/my aws ES endpoint\/table_a54a9a96-c246-4bcd-b417-2d8c005c3290 [status:400 request:0.069s]\r\nINFO:databuilder.callback.call_back:No callbacks to notify\r\nTraceback (most recent call last):\r\n  File \"example\/scripts\/sample_data_loader_neptune.py\", line 403, in <module>\r\n    job_es_table.launch()\r\n  File \"\/tmp\/amundsen\/venv\/lib\/python3.7\/site-packages\/databuilder\/job\/job.py\", line 76, in launch\r\n    raise e\r\n  File \"\/tmp\/amundsen\/venv\/lib\/python3.7\/site-packages\/databuilder\/job\/job.py\", line 72, in launch\r\n    self.publisher.publish()\r\n  File \"\/tmp\/amundsen\/venv\/lib\/python3.7\/site-packages\/databuilder\/publisher\/base_publisher.py\", line 40, in publish\r\n    raise e\r\n  File \"\/tmp\/amundsen\/venv\/lib\/python3.7\/site-packages\/databuilder\/publisher\/base_publisher.py\", line 37, in publish\r\n    self.publish_impl()\r\n  File \"\/tmp\/damundsen\/venv\/lib\/python3.7\/site-packages\/databuilder\/publisher\/elasticsearch_publisher.py\", line 93, in publish_impl\r\n    self.elasticsearch_client.indices.create(index=self.elasticsearch_new_index, body=self.elasticsearch_mapping)\r\n  File \"\/tmp\/amundsen\/venv\/lib\/python3.7\/site-packages\/elasticsearch\/client\/utils.py\", line 347, in _wrapped\r\n    return func(*args, params=params, headers=headers, **kwargs)\r\n  File \"\/tmp\/amundsen\/venv\/lib\/python3.7\/site-packages\/elasticsearch\/client\/indices.py\", line 146, in create\r\n    \"PUT\", _make_path(index), params=params, headers=headers, body=body\r\n  File \"\/tmp\/amundsen\/venv\/lib\/python3.7\/site-packages\/elasticsearch\/transport.py\", line 466, in perform_request\r\n    raise e\r\n  File \"\/tmp\/damundsen\/venv\/lib\/python3.7\/site-packages\/elasticsearch\/transport.py\", line 434, in perform_request\r\n    timeout=timeout,\r\n  File \"\/tmp\/amundsen\/venv\/lib\/python3.7\/site-packages\/elasticsearch\/connection\/http_requests.py\", line 216, in perform_request\r\n    self._raise_error(response.status_code, raw_data)\r\n  File \"\/tmp\/amundsen\/venv\/lib\/python3.7\/site-packages\/elasticsearch\/connection\/base.py\", line 329, in _raise_error\r\n    status_code, error_message, additional_info\r\n\r\n\r\nelasticsearch.exceptions.RequestError: RequestError(400, 'mapper_parsing_exception', 'Root mapping definition has unsupported parameters:  [schema : {analyzer=simple, type=text, fields={raw={type=keyword}}}] [cluster : {analyzer=simple, type=text, fields={raw={type=keyword}}}] [description : {analyzer=simple, type=text}] [display_name : {type=keyword}] [column_descriptions : {analyzer=simple, type=text}] [programmatic_descriptions : {analyzer=simple, type=text}] [tags : {type=keyword}] [badges : {type=keyword}] [database : {analyzer=simple, type=text, fields={raw={type=keyword}}}] [total_usage : {type=long}] [name : {analyzer=simple, type=text, fields={raw={type=keyword}}}] [last_updated_timestamp : {format=epoch_second, type=date}] [unique_usage : {type=long}] [column_names : {analyzer=simple, type=text, fields={raw={normalizer=column_names_normalizer, type=keyword}}}] [key : {type=keyword}]')->\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n* Amunsen version used: Databuilder: 6.7.1 Common 0.26.0 Amundsen-Gremlin 0.0.13 AWS ES : 6.8\r\n",
        "Issue_answer_count":7,
        "Issue_self_closed":1.0,
        "Answer_body":"Thanks for opening your first issue here!\n This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs.\n Same problem here, does you solved? @amandeep848 could you fix the problem? @amandeep848 could you fix the problem? Hello!\r\n\r\nI have been fixed the problem by putting the version of amundsen-common to 0.24.1\r\n\r\n- My `requirements.txt` file is setup as shown below:\r\n\r\n```text\r\namundsen-databuilder==6.5.2\r\namundsen-gremlin==0.0.13\r\ngremlinpython==3.4.10\r\nrequests-aws4auth==1.1.1\r\nboto3==1.21.23\r\nbotocore==1.24.23\r\ntyping-extensions==4.1.1\r\noverrides==6.1.0\r\namundsen-common==0.24.1\r\n```\r\n\r\n- My Glue databuilder script:\r\n\r\n```python\r\nimport logging\r\nimport os\r\nimport uuid\r\nimport boto3\r\nimport textwrap\r\nimport json\r\n\r\nfrom datetime import date\r\n\r\nfrom elasticsearch import Elasticsearch\r\nfrom pyhocon import ConfigFactory\r\n\r\nfrom databuilder.clients.neptune_client import NeptuneSessionClient\r\nfrom databuilder.extractor.es_last_updated_extractor import EsLastUpdatedExtractor\r\nfrom databuilder.extractor.neptune_search_data_extractor import NeptuneSearchDataExtractor\r\n\r\nfrom databuilder.job.job import DefaultJob\r\nfrom databuilder.loader.file_system_elasticsearch_json_loader import FSElasticsearchJSONLoader\r\nfrom databuilder.loader.file_system_neptune_csv_loader import FSNeptuneCSVLoader\r\nfrom databuilder.publisher.elasticsearch_constants import (\r\n    DASHBOARD_ELASTICSEARCH_INDEX_MAPPING, USER_ELASTICSEARCH_INDEX_MAPPING,\r\n)\r\nfrom databuilder.publisher.elasticsearch_publisher import ElasticsearchPublisher\r\nfrom databuilder.publisher.neptune_csv_publisher import NeptuneCSVPublisher\r\nfrom databuilder.task.task import DefaultTask\r\nfrom databuilder.transformer.base_transformer import ChainedTransformer, NoopTransformer\r\nfrom databuilder.transformer.dict_to_model import MODEL_CLASS, DictToModel\r\nfrom databuilder.transformer.generic_transformer import (\r\n    CALLBACK_FUNCTION, FIELD_NAME, GenericTransformer,\r\n)\r\n\r\nfrom databuilder.extractor.glue_extractor import GlueExtractor\r\nfrom databuilder.task.neptune_staleness_removal_task import NeptuneStalenessRemovalTask\r\n\r\n\r\nes_host = os.getenv('ES_HOST')\r\n\r\nneptune_host = os.getenv('NEPTUNE_HOST')\r\nneptune_port = os.getenv('NEPTUNE_PORT', 8182)\r\nneptune_iam_role_name = os.getenv('NEPTUNE_IAM_ROLE')\r\n\r\nS3_BUCKET_NAME = os.getenv('S3_BUCKET_NAME')\r\ntoday = date.today()\r\nS3_DATA_PATH = f'amundsen_data\/glue_extractor\/year={today.year}\/month={today.month}\/day={today.day}'\r\n\r\nAWS_REGION = os.getenv('AWS_REGION')\r\nGLUE_DATABASE_IDENTIFIER = os.getenv('GLUE_DATABASE_IDENTIFIER')\r\n\r\nes = Elasticsearch(\r\n    '{}'.format(es_host),\r\n    scheme=\"https\",\r\n    port=443,\r\n)\r\n\r\nNEPTUNE_ENDPOINT = '{}:{}'.format(neptune_host, neptune_port)\r\n\r\nLOGGER = logging.getLogger(__name__)\r\n\r\n\r\ndef run_glue_job(job_name):\r\n    \"\"\"Run Glue metadata extraction\r\n\r\n    Args:\r\n        job_name (string): job name\r\n    \"\"\"\r\n\r\n    tmp_folder = '\/var\/tmp\/amundsen\/{job_name}'.format(job_name=job_name)\r\n    node_files_folder = '{tmp_folder}\/nodes'.format(tmp_folder=tmp_folder)\r\n    relationship_files_folder = '{tmp_folder}\/relationships'.format(tmp_folder=tmp_folder)\r\n\r\n    loader = FSNeptuneCSVLoader()\r\n    publisher = NeptuneCSVPublisher()\r\n\r\n    with open(\"databases.json\") as jsonFile:\r\n\r\n        filters = json.load(jsonFile)\r\n\r\n    job_config = ConfigFactory.from_dict({\r\n        f'extractor.glue.{GlueExtractor.CLUSTER_KEY}': GLUE_DATABASE_IDENTIFIER,\r\n        f'extractor.glue.{GlueExtractor.FILTER_KEY}': filters,\r\n        loader.get_scope(): {\r\n            FSNeptuneCSVLoader.NODE_DIR_PATH: node_files_folder,\r\n            FSNeptuneCSVLoader.RELATION_DIR_PATH: relationship_files_folder,\r\n            FSNeptuneCSVLoader.SHOULD_DELETE_CREATED_DIR: True,\r\n            FSNeptuneCSVLoader.JOB_PUBLISHER_TAG: 'unique_tag'\r\n        },\r\n        publisher.get_scope(): {\r\n            NeptuneCSVPublisher.NODE_FILES_DIR: node_files_folder,\r\n            NeptuneCSVPublisher.RELATION_FILES_DIR: relationship_files_folder,\r\n            NeptuneCSVPublisher.AWS_S3_BUCKET_NAME: S3_BUCKET_NAME,\r\n            NeptuneCSVPublisher.AWS_BASE_S3_DATA_PATH: S3_DATA_PATH,\r\n            NeptuneCSVPublisher.NEPTUNE_HOST: NEPTUNE_ENDPOINT,\r\n            NeptuneCSVPublisher.AWS_IAM_ROLE_NAME: neptune_iam_role_name,\r\n            NeptuneCSVPublisher.AWS_REGION: AWS_REGION\r\n        },\r\n    })\r\n\r\n    DefaultJob(\r\n        conf=job_config,\r\n        task=DefaultTask(\r\n            extractor=GlueExtractor(),\r\n            loader=loader,\r\n            transformer=NoopTransformer()\r\n        ),\r\n        publisher=publisher\r\n    ).launch()\r\n\r\ndef create_remove_stale_data_job():\r\n    \"\"\"Run remove stale data from Neptune\r\n\r\n    Returns:\r\n        NeptuneStalenessRemovalTask: Neptune stateleness data job\r\n    \"\"\"\r\n\r\n    target_relations = ['DESCRIPTION', 'DESCRIPTION_OF', 'COLUMN', 'COLUMN_OF', 'TABLE', 'TABLE_OF']\r\n    target_nodes = ['Table', 'Column', 'Programmatic_Description', \"Schema\"]\r\n\r\n    staleness_max_pct = 5\r\n\r\n    while True:\r\n\r\n        try:\r\n\r\n            LOGGER.info(f'Delete stale data at threshold - {staleness_max_pct}%')\r\n\r\n            job_config = ConfigFactory.from_dict({\r\n                'task.remove_stale_data': {\r\n                    NeptuneStalenessRemovalTask.TARGET_RELATIONS: target_relations,\r\n                    NeptuneStalenessRemovalTask.TARGET_NODES: target_nodes,\r\n                    NeptuneStalenessRemovalTask.STALENESS_CUT_OFF_IN_SECONDS: 86400,  # 1 day\r\n                    NeptuneStalenessRemovalTask.STALENESS_MAX_PCT: staleness_max_pct,\r\n                    'neptune.client': {\r\n                        NeptuneSessionClient.NEPTUNE_HOST_NAME: NEPTUNE_ENDPOINT,\r\n                        NeptuneSessionClient.AWS_REGION: AWS_REGION,\r\n                    }\r\n                }\r\n            })\r\n\r\n            job = DefaultJob(\r\n                conf=job_config,\r\n                task=NeptuneStalenessRemovalTask()\r\n            )\r\n\r\n            job.launch()\r\n\r\n            break\r\n\r\n        except Exception as ex:\r\n\r\n            LOGGER.error(ex)\r\n            LOGGER.info(f'Increase stale data threshold')\r\n\r\n            staleness_max_pct += 5\r\n\r\n            if staleness_max_pct == 105:\r\n\r\n                break\r\n\r\n\r\ndef create_es_publisher_job(elasticsearch_index_alias='table_search_index',\r\n                            elasticsearch_doc_type_key='table',\r\n                            model_name='databuilder.models.table_elasticsearch_document.TableESDocument',\r\n                            entity_type='table',\r\n                            elasticsearch_mapping=None):\r\n    \"\"\"\r\n    :param elasticsearch_index_alias:  alias for Elasticsearch used in\r\n                                       amundsensearchlibrary\/search_service\/config.py as an index\r\n    :param elasticsearch_doc_type_key: name the ElasticSearch index is prepended with. Defaults to `table` resulting in\r\n                                       `table_{uuid}`\r\n    :param model_name:                 the Databuilder model class used in transporting between Extractor and Loader\r\n    :param entity_type:                Entity type handed to the `Neo4jSearchDataExtractor` class, used to determine\r\n                                       Cypher query to extract data from Neo4j. Defaults to `table`.\r\n    :param elasticsearch_mapping:      Elasticsearch field mapping \"DDL\" handed to the `ElasticsearchPublisher` class,\r\n                                       if None is given (default) it uses the `Table` query baked into the Publisher\r\n    \"\"\"\r\n    # loader saves data to this location and publisher reads it from here\r\n    extracted_search_data_path = '\/var\/tmp\/amundsen\/search_data.json'\r\n    loader = FSElasticsearchJSONLoader()\r\n    extractor = NeptuneSearchDataExtractor()\r\n\r\n    task = DefaultTask(\r\n        loader=loader,\r\n        extractor=extractor,\r\n        transformer=NoopTransformer()\r\n    )\r\n\r\n    # elastic search client instance\r\n    elasticsearch_client = es\r\n\r\n    # unique name of new index in Elasticsearch\r\n    elasticsearch_new_index_key = '{}_'.format(elasticsearch_doc_type_key) + str(uuid.uuid4())\r\n\r\n    publisher = ElasticsearchPublisher()\r\n\r\n    session = boto3.Session(region_name=AWS_REGION)\r\n\r\n    aws_creds = session.get_credentials()\r\n    aws_access_key = aws_creds.access_key\r\n    aws_access_secret = aws_creds.secret_key\r\n    aws_token = aws_creds.token\r\n\r\n    job_config = ConfigFactory.from_dict({\r\n        extractor.get_scope(): {\r\n            NeptuneSearchDataExtractor.ENTITY_TYPE_CONFIG_KEY: entity_type,\r\n            NeptuneSearchDataExtractor.MODEL_CLASS_CONFIG_KEY: model_name,\r\n            'neptune.client': {\r\n                NeptuneSessionClient.NEPTUNE_HOST_NAME: NEPTUNE_ENDPOINT,\r\n                NeptuneSessionClient.AWS_REGION: AWS_REGION,\r\n                NeptuneSessionClient.AWS_ACCESS_KEY: aws_access_key,\r\n                NeptuneSessionClient.AWS_SECRET_ACCESS_KEY: aws_access_secret,\r\n                NeptuneSessionClient.AWS_SESSION_TOKEN: aws_token\r\n            }\r\n        },\r\n        'loader.filesystem.elasticsearch.file_path': extracted_search_data_path,\r\n        'loader.filesystem.elasticsearch.mode': 'w',\r\n        publisher.get_scope(): {\r\n            'file_path': extracted_search_data_path,\r\n            'mode': 'r',\r\n            'client': elasticsearch_client,\r\n            'new_index': elasticsearch_new_index_key,\r\n            'doc_type': elasticsearch_doc_type_key,\r\n            'alias': elasticsearch_index_alias\r\n        }\r\n    })\r\n\r\n    # only optionally add these keys, so need to dynamically `put` them\r\n    if elasticsearch_mapping:\r\n        job_config.put('publisher.elasticsearch.{}'.format(ElasticsearchPublisher.ELASTICSEARCH_MAPPING_CONFIG_KEY),\r\n                       elasticsearch_mapping)\r\n\r\n    job = DefaultJob(\r\n        conf=job_config,\r\n        task=task,\r\n        publisher=ElasticsearchPublisher()\r\n    )\r\n\r\n    return job\r\n\r\n\r\nif __name__ == \"__main__\":\r\n\r\n    logging.basicConfig(level=logging.INFO)\r\n\r\n    LOGGER.info('ES Host: ' +  es_host)\r\n    LOGGER.info('Neptune Host: ' + neptune_host)\r\n    LOGGER.info('Neptune Port: ' + str(neptune_port))\r\n    LOGGER.info('Neptune IAM Role Name: ' + neptune_iam_role_name)\r\n    LOGGER.info('S3 Bucket Name: ' + S3_BUCKET_NAME)\r\n    LOGGER.info('S3 Data Path: ' + S3_DATA_PATH)\r\n    LOGGER.info('AWS Region: ' + AWS_REGION)\r\n\r\n    logging.info('>>> Running Remove Stale Data Job <<<')\r\n\r\n    create_remove_stale_data_job()\r\n\r\n    logging.info('>>> Running Glue Extractor <<<')\r\n\r\n    run_glue_job('amundsen_glue_extractor')\r\n\r\n    logging.info('>>> Running ES Publisher <<<')\r\n\r\n    job_es_table = create_es_publisher_job(\r\n        elasticsearch_index_alias='table_search_index',\r\n        elasticsearch_doc_type_key='table',\r\n        entity_type='table',\r\n        model_name='databuilder.models.table_elasticsearch_document.TableESDocument'\r\n    )\r\n    job_es_table.launch()\r\n```\r\n\r\n- databases.json\r\n\r\n```json\r\n[]\r\n```\r\n\r\n- .env\r\n\r\n```env\r\nES_HOST=<ES_HOST>\r\nNEPTUNE_HOST=<NEPTUNE_HOST>\r\nNEPTUNE_PORT=8182\r\nNEPTUNE_IAM_ROLE=<NEPTUNE_IAM_ROLE>\r\nS3_BUCKET_NAME=<S3_BUCKET_NAME>\r\nAWS_REGION=<AWS_REGION>\r\nSECRET_NAME=<SECRET_NAME>\r\nGLUE_DATABASE_IDENTIFIER=<GLUE_DATABASE_IDENTIFIER>\r\n```\r\n\r\n\r\nHope this help!\r\n\r\nBest Regards.\r\nBill\r\n I encountered this issue, too, as I installed data builder from codebase with `python setup.py install`, and after rebase with the main branch, the previous version was not clean up when we simply rerun `python setup.py install`, the way out was to do `pip uninstall amundsen-databuilder` and `pip uninstall amundsen-common` until non of packages existed(there could be multiple versions left, more than once per each package could be required).\r\n\r\nThen the expected elastic-related code is up to date w\/o this error anymore.",
        "Tool":"Neptune",
        "Platform":"Github",
        "Issue_original_content":"bug report elasticsearch except sampl loader expect behavior job tabl launch file tmp amundsen venv lib python site packag databuild job job line launch rais file tmp amundsen venv lib python site packag databuild job job line launch self publish publish file tmp amundsen venv lib python site packag databuild publish base publish line publish rais file tmp amundsen venv lib python site packag databuild publish base publish line publish self publish impl file tmp damundsen venv lib python site packag databuild publish elasticsearch publish line publish impl self elasticsearch client indic creat index self elasticsearch new index bodi self elasticsearch map file tmp amundsen venv lib python site packag elasticsearch client util line wrap return func arg param param header header kwarg file tmp amundsen venv lib python site packag elasticsearch client indic line creat path index param param header header bodi bodi file tmp amundsen venv lib python site packag elasticsearch transport line perform request rais file tmp damundsen venv lib python site packag elasticsearch transport line perform request timeout timeout file tmp amundsen venv lib python site packag elasticsearch connect http request line perform request self rais error respons statu code raw data file tmp amundsen venv lib python site packag elasticsearch connect base line rais error statu code error messag addit info elasticsearch except requesterror requesterror mapper pars except root map definit unsupport paramet schema analyz simpl type text field raw type keyword cluster analyz simpl type text field raw type keyword descript analyz simpl type text displai type keyword column descript analyz simpl type text programmat descript analyz simpl type text tag type keyword badg type keyword databas analyz simpl type text field raw type keyword total usag type long analyz simpl type text field raw type keyword updat timestamp format epoch second type date uniqu usag type long column name analyz simpl type text field raw normal column name normal type keyword kei type keyword amunsen version databuild common amundsen gremlin aw",
        "Issue_preprocessed_content":"bug report elasticsearch except exist open close report expect behavior warn elasticsearch aw notifi traceback file line file line launch rais file line launch file line publish rais file line publish file line file line return func file line creat param param header header bodi bodi file line rais file line timeout timeout file line file line amunsen version databuild aw",
        "Issue_gpt_summary_original":"Neptune ML notebooks have a bug where the genre returned for a node classification task on `Toy Story` is incorrectly stated as `Comedy` instead of `Drama`.",
        "Issue_gpt_summary":"notebook bug genr return node classif task toi stori incorrectli state comedi instead drama",
        "Issue_score_count":1
    },
    {
        "Issue_link":"https:\/\/github.com\/amundsen-io\/amundsen\/issues\/1430",
        "Issue_title":"Databuilder `NeptuneBulkLoaderApi` constructs wrong IAM role ARN for AWS other than global",
        "Issue_created_time":1628591009000,
        "Issue_closed_time":1671067447000,
        "Issue_body":"For uploading data to AWS Neptune we use `NeptuneCSVPublisher`, which internally uses `NeptuneBulkLoaderApi`. The current configuration uses config key `NeptuneCSVPublisher.AWS_IAM_ROLE_NAME`, which provides name of IAM role for the loader to be able to use S3 and Neptune. The issue is that `NeptuneBulkLoaderApi` constructs IAM role ARN from name as follows: \r\n\r\n```python\r\naccount_id = self.session.client('sts').get_caller_identity()['Account']\r\nself.iam_role_arn = f'arn:aws:iam::{account_id}:role\/{iam_role_name}'\r\n```\r\n\r\nwhereas, [second element of ARN aka partition](https:\/\/docs.aws.amazon.com\/general\/latest\/gr\/aws-arns-and-namespaces.html) can be currently:\r\n* `aws` -AWS Regions\r\n* `aws-cn` - China Regions\r\n* `aws-us-gov` - AWS GovCloud (US) Regions\r\n\r\nSince we use Amundsen also in AWS China, the above ARN is not valid. \r\n\r\n## Expected Behavior\r\n\r\nIAM role ARN either takes into account AWS partition or there is a possibility of passing IAM role ARN instead of name directly.\r\n\r\n## Current Behavior\r\n\r\nIAM role ARN is constructed incorrectly outside of AWS Global.\r\n\r\n## Possible Solutions\r\n\r\nIAM role ARN should take partition into account. There are two solutions:\r\n1. Add partition into current code\r\n2. Add option of passing IAM role ARN directly which supersedes IAM role name \r\n\r\n### Solution 1\r\n\r\nSince I didn't know or found any good way to get the AWS partition, we can use caller identity and ARN there to get the partition, e.g.:\r\n\r\n```python\r\nidentity = self.session.client('sts').get_caller_identity()\r\naccount_id = identity['Account']\r\npartition = identity['Arn'].split(':')[1]\r\nself.iam_role_arn = f'arn:{partition}:iam::{account_id}:role\/{iam_role_name}'\r\n```\r\n\r\nThis is smaller fix but it is a bit hacky and I'm not sure it'll work in all situation, but it should I guess.\r\n\r\n### Solution 2\r\n\r\nAdd config key `NeptuneCSVPublisher.AWS_IAM_ROLE_ARN` which either supersedes `NeptuneCSVPublisher.AWS_IAM_ROLE_NAME` in a way that in constructor we would have something like:\r\n\r\n```python\r\nif iam_role_arn:\r\n    self.iam_role_arn = iam_role_arn\r\nelse:\r\n   ...\r\n   self.iam_role_arn = f'arn:{partition}:iam::{account_id}:role\/{iam_role_name}'\r\n```\r\n\r\nOr even replace `NeptuneCSVPublisher.AWS_IAM_ROLE_NAME` with `NeptuneCSVPublisher.AWS_IAM_ROLE_ARN`, which is IMO cleaner, but would be not backward compatible. \r\n\r\n## Steps to Reproduce\r\nDeploy Amundsen in AWS China with Neptune and try to use Databuilder to upload CSV data from S3. \r\n\r\n## Screenshots (if appropriate)\r\n\r\n## Context\r\nCurrently we are unable to load data into Neptune as the IAM role ARN setting is hidden and we get an error:\r\n\r\n```\r\n[ERROR] Exception: Failed to load csv. Response: {'detailedMessage': \"Failed to start new load from the source s3:\/\/amundsenBucket\/amundsen\/2021_08_10_01_01_28. Couldn't find the aws credential for iam_role_arn: arn:aws:iam::111111111:role\/RoleForNeptune111111-2222\", 'code': 'InvalidParameterException', 'requestId': 'xxx'}\r\nTraceback (most recent call last):\r\n\u00a0\u00a0File \"\/var\/task\/ctw\/jobs\/synchronize_redshift_metadata.py\", line 49, in lambda_handler\r\n\u00a0\u00a0\u00a0\u00a0redshift_to_neptune_job.launch()\r\n\u00a0\u00a0File \"\/var\/task\/databuilder\/job\/job.py\", line 76, in launch\r\n\u00a0\u00a0\u00a0\u00a0raise e\r\n\u00a0\u00a0File \"\/var\/task\/databuilder\/job\/job.py\", line 72, in launch\r\n\u00a0\u00a0\u00a0\u00a0self.publisher.publish()\r\n\u00a0\u00a0File \"\/var\/task\/databuilder\/publisher\/base_publisher.py\", line 40, in publish\r\n\u00a0\u00a0\u00a0\u00a0raise e\r\n\u00a0\u00a0File \"\/var\/task\/databuilder\/publisher\/base_publisher.py\", line 37, in publish\r\n\u00a0\u00a0\u00a0\u00a0self.publish_impl()\r\n\u00a0\u00a0File \"\/var\/task\/databuilder\/publisher\/neptune_csv_publisher.py\", line 109, in publish_impl\r\n\u00a0\u00a0\u00a0\u00a0raise Exception(\"Failed to load csv. Response: {0}\".format(str(bulk_upload_response)))\r\n```\r\n\r\n## Your Environment\r\n* Amunsen version used: `amundsen-databuilder==4.3.1`\r\n* Data warehouse stores: AWS Neptune\r\n* Deployment (k8s or native): AWS Step Functions (k8s for backend but unrelated for now)\r\n* Link to your fork or repository:",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs.\n",
        "Tool":"Neptune",
        "Platform":"Github",
        "Issue_original_content":"databuild bulkloaderapi construct wrong iam role arn aw global upload data aw us csvpublish intern us bulkloaderapi current configur us config kei csvpublish aw iam role provid iam role loader abl us issu bulkloaderapi construct iam role arn follow python account self session client st caller ident account self iam role arn arn aw iam account role iam role second element arn aka partit http doc aw amazon com gener latest aw arn namespac html current aw aw region aw china region aw gov aw govcloud region us amundsen aw china arn valid expect behavior iam role arn take account aw partit possibl pass iam role arn instead directli current behavior iam role arn construct incorrectli outsid aw global possibl solut iam role arn partit account solut add partit current code add option pass iam role arn directli supersed iam role solut know good wai aw partit us caller ident arn partit python ident self session client st caller ident account ident account partit ident arn split self iam role arn arn partit iam account role iam role smaller fix bit hacki sure work situat guess solut add config kei csvpublish aw iam role arn supersed csvpublish aw iam role wai constructor like python iam role arn self iam role arn iam role arn self iam role arn arn partit iam account role iam role replac csvpublish aw iam role csvpublish aw iam role arn imo cleaner backward compat step reproduc deploi amundsen aw china try us databuild upload csv data screenshot appropri context current unabl load data iam role arn set hidden error error except fail load csv respons detailedmessag fail start new load sourc amundsenbucket amundsen couldn aw credenti iam role arn arn aw iam role rolefor code invalidparameterexcept requestid xxx traceback recent file var task ctw job synchron redshift metadata line lambda handler redshift job launch file var task databuild job job line launch rais file var task databuild job job line launch self publish publish file var task databuild publish base publish line publish rais file var task databuild publish base publish line publish self publish impl file var task databuild publish csv publish line publish impl rais except fail load csv respons format str bulk upload respons environ amunsen version amundsen databuild data warehous store aw deploy nativ aw step function backend unrel link fork repositori",
        "Issue_preprocessed_content":"databuild construct wrong iam role arn aw global upload data aw us us configur us config kei provid iam role loader abl us construct iam role arn aw region china region aw govcloud region us amundsen aw china arn valid expect behavior iam role arn take aw partit iam role arn instead directli behavior iam role arn construct outsid aw global solut iam role arn partit solut partit code option iam role arn directli supersed iam role solut know wai aw partit us ident arn partit fix bit hacki sure work situat solut config kei supersed wai constructor like replac imo cleaner backward compat step reproduc deploi amundsen aw china try us databuild upload csv data context unabl load data iam role arn environ amunsen version data warehous store aw deploy aw step function link fork repositori",
        "Issue_gpt_summary_original":"The Neptune_ML widget is encountering an error in version 2.0.9 where the json values being passed in are resulting in a JSONDecodeError. This issue occurs when running through the 01-Introduction-to-Node-Classification-Gremlin notebook during the export step. The problem is not present in version 2.0.7.",
        "Issue_gpt_summary":"widget encount error version json valu pass result jsondecodeerror issu occur run introduct node classif gremlin notebook export step problem present version",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws\/graph-notebook\/issues\/222",
        "Issue_title":"Configuration options not being set correctly when using CN region Neptune endpoint as host",
        "Issue_created_time":1635879966000,
        "Issue_closed_time":1635986654000,
        "Issue_body":"**Describe the bug**\r\nThere are several areas in the code where we have an explicit check for the `neptune.amazonaws.com` DNS suffix; this is used to determine if we need to use Neptune-specific configuration options and request URI elements. \r\n\r\nHowever, these checks misidentify endpoints of Neptune clusters in AWS CN regions, which use the `neptune.<region>.amazonaws.com.cn` DNS suffix instead, as non-AWS endpoints. As a result, required config options such as `auth_mode` and `region` are not set correctly.\r\n\r\nAll of the following checks need to be changed to \"amazonaws.com\":\r\nhttps:\/\/github.com\/aws\/graph-notebook\/blob\/a5818452d152ba51b7f7e26b6cf8e188dca54693\/src\/graph_notebook\/magics\/graph_magic.py#L160\r\nhttps:\/\/github.com\/aws\/graph-notebook\/blob\/a5818452d152ba51b7f7e26b6cf8e188dca54693\/src\/graph_notebook\/neptune\/client.py#L129\r\nhttps:\/\/github.com\/aws\/graph-notebook\/blob\/a5818452d152ba51b7f7e26b6cf8e188dca54693\/src\/graph_notebook\/configuration\/generate_config.py#L54\r\nhttps:\/\/github.com\/aws\/graph-notebook\/blob\/68e888def530be70e08b5250c8146292fb49cfa1\/src\/graph_notebook\/configuration\/get_config.py#L14",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"Resolved as of release 3.0.8",
        "Tool":"Neptune",
        "Platform":"Github",
        "Issue_original_content":"configur option set correctli region endpoint host bug area code explicit check amazonaw com dn suffix determin need us specif configur option request uri element check misidentifi endpoint cluster aw region us amazonaw com dn suffix instead non aw endpoint result requir config option auth mode region set correctli follow check need chang amazonaw com http github com aw graph notebook blob adbabfebcfedca src graph notebook magic graph magic http github com aw graph notebook blob adbabfebcfedca src graph notebook client http github com aw graph notebook blob adbabfebcfedca src graph notebook configur gener config http github com aw graph notebook blob edefbeebcfbcfa src graph notebook configur config",
        "Issue_preprocessed_content":"configur option set region endpoint host bug area code explicit check dn determin us specif configur option request uri element check misidentifi endpoint cluster aw region us dn instead endpoint result requir config option set check chang",
        "Issue_gpt_summary_original":"The user has encountered a bug where there is missing documentation on how to connect to Neptune from a MacOS device. The user suggests adding the missing details to the documentation on connecting to Neptune via ssh-tunnel. One important missing detail is the need to create a host alias to ensure proper functionality.",
        "Issue_gpt_summary":"user encount bug miss document connect maco devic user suggest ad miss detail document connect ssh tunnel import miss need creat host alia ensur proper function",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws\/graph-notebook\/issues\/167",
        "Issue_title":"[BUG] Neptune ML Export widget throwing error",
        "Issue_created_time":1627938048000,
        "Issue_closed_time":1628716798000,
        "Issue_body":"**Describe the bug**\r\nWhen using the Neptune ML widget to export data like the command below from the 01- Node Classification notebook:\r\n```\r\n%%neptune_ml export start --export-url {neptune_ml.get_export_service_host()} --export-iam --wait --store-to export_results\r\n${export_params}\r\n```\r\nThe following error is thrown\r\n```\r\n{\r\n  \"message\": \"Credential should be scoped to correct service: 'execute-api'. \"\r\n}  \r\n```\r\n\r\n**Expected behavior**\r\nThe export should run to completion\r\n\r\n\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"This issue occurs on a cluster created using the default CFN script with IAM disabled\r\n",
        "Tool":"Neptune",
        "Platform":"Github",
        "Issue_original_content":"bug export widget throw error bug widget export data like command node classif notebook export start export url export servic host export iam wait store export result export param follow error thrown messag credenti scope correct servic execut api expect behavior export run complet",
        "Issue_preprocessed_content":"export widget throw bug widget export data like node thrown expect behavior export run complet",
        "Issue_gpt_summary_original":"The user is facing an issue while connecting a local notebook to a remote Neptune with SSL enabled. The user has set up an SSH tunnel via bastion to the Neptune cluster and started the graph-notebook. However, when running a command, the user is getting an SSL error. The user expects to be able to connect to the remote Neptune with SSL enabled.",
        "Issue_gpt_summary":"user face issu connect local notebook remot ssl enabl user set ssh tunnel bastion cluster start graph notebook run command user get ssl error user expect abl connect remot ssl enabl",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws\/graph-notebook\/issues\/144",
        "Issue_title":"Limit issue .with(\"Neptune#ml.limit\",3)",
        "Issue_created_time":1626912970000,
        "Issue_closed_time":1632957644000,
        "Issue_body":"Hi\r\n\r\nAs per the below code It is allowing only default limit as 1 and the limit 3 is not working and throwing error for Introduction to Node Classification Gremlin\r\n\r\n%%gremlin\r\ng.with(\"Neptune#ml.endpoint\",\"node-cla-2021-07-15-15-13-940000-endpoint\").with( \"Neptune#ml.limit\", 3 ).V().has('title', 'Toy Story (1995)').properties(\"genre\").with(\"Neptune#ml.classification\").value()\r\n\r\nError\r\n{\r\n  \"requestId\": \"fbab9b0a-176c-47f8-accc-969fc4580792\",\r\n  \"detailedMessage\": \"Incompatible data from external service. Please check your service configuration and query again.\",\r\n  \"code\": \"ConstraintViolationException\"\r\n}\r\n\r\nCan some one suggest is there something wrong with the code which was mentioned in the document\r\n\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"Hi @Roshin29, thank you for the bug report! \r\n\r\nThe machine learning sample notebooks received substantial revisions in [Release 3.0.1](https:\/\/github.com\/aws\/graph-notebook\/releases\/tag\/v3.0.1). This release also included a number of changes under the hood to support the general availability release of Amazon Neptune ML.\r\n\r\nThe Gremlin query listed is only seen in older versions of the `Neptune-ML-01-Introduction-to-Node-Classification-Gremlin` sample notebook, and is now replaced by the one below:\r\n```\r\n%%gremlin\r\ng.with(\"Neptune#ml.endpoint\",\"${endpoint}\").\r\n  with(\"Neptune#ml.limit\",3).\r\n  V().has('title', 'Apollo 13 (1995)').properties(\"genre\").with(\"Neptune#ml.classification\").value()\r\n\r\n```\r\nI am not able to reproduce the listed exception when running this query using graph-notebook v3.0.6, so the issue appears to have been resolved with the latest changes.\r\n\r\nClosing this issue out, as there are no further action items at this time. Please feel free to re-open if you have any further questions.",
        "Tool":"Neptune",
        "Platform":"Github",
        "Issue_original_content":"limit issu limit code allow default limit limit work throw error introduct node classif gremlin gremlin endpoint node cla endpoint limit titl toi stori properti genr classif valu error requestid fbabba accc detailedmessag incompat data extern servic check servic configur queri code constraintviolationexcept suggest wrong code mention document",
        "Issue_preprocessed_content":"limit code default limit limit work throw introduct node gremlin gremlin toi stori requestid incompat data extern servic check servic configur queri code constraintviolationexcept wrong code mention document",
        "Issue_gpt_summary_original":"The user is experiencing issues with Neptune_catalyst.ipynb failing and suspects that there may be a typo or missing `run` object.",
        "Issue_gpt_summary":"user experienc issu catalyst ipynb fail suspect typo miss run object",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws\/graph-notebook\/issues\/116",
        "Issue_title":"[BUG] Neptune ML notebooks have incorrect Genre stated in the text",
        "Issue_created_time":1619195852000,
        "Issue_closed_time":null,
        "Issue_body":"For the  01 notebooks for Neptune ML the text in the notebook incorrectly specifies that the genre returned for a node classification task on `Toy Story` is `Comedy` when it should be `Drama`",
        "Issue_answer_count":0,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Neptune",
        "Platform":"Github",
        "Issue_original_content":"bug notebook incorrect genr state text notebook text notebook incorrectli specifi genr return node classif task toi stori comedi drama",
        "Issue_preprocessed_content":"genr state text text specifi genr return node task",
        "Issue_gpt_summary_original":"The user has encountered a bug where the Neptune guide's quick launch link is pointing to the full launcher instead of the minimal launcher, which is the expected behavior.",
        "Issue_gpt_summary":"user encount bug guid quick launch link point launcher instead minim launcher expect behavior",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws\/graph-notebook\/issues\/81",
        "Issue_title":"[BUG] Neptune_ML widget error in 2.0.9",
        "Issue_created_time":1615509404000,
        "Issue_closed_time":1620330541000,
        "Issue_body":"**Describe the bug**\r\nStarting in version 2.0.9 the neptune_ml widget is having an issue where the json values being passed in are getting the following error \r\n```\r\n{'error': JSONDecodeError('Expecting value: line 1 column 1 (char 0)',)}\r\n```\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Run through the 01-Introduction-to-Node-Classification-Gremlin notebook\r\n2. When you get to the export step the error occurs\r\n\r\n**Additional context**\r\nThis is not a problem in version 2.0.7",
        "Issue_answer_count":25,
        "Issue_self_closed":0.0,
        "Answer_body":"This appears to be an issue with the versions of `ipython` that SageMaker is using.  If you update the Lifecycle start script by putting the following code at the bottom (just before EOF) and stopping and starting the notebook.\r\n```\r\nsource activate JupyterSystemEnv\r\npip install --upgrade ipython==7.16.1\r\nsource \/home\/ec2-user\/anaconda3\/bin\/deactivate\r\n``` Hi, i have updated the Lifecycle scripts as suggested and that works - but then it fails on the training:\r\n\r\n`\"status\": \"Failed\",\r\n    \"failureReason\": \"ClientError: Failed to download data`\r\n\r\n...\r\npreloading-2021-04-05-17-33-3910000\/preloading-output\/graph.bin has an illegal char sub-sequence '\/\/' in it\"`\r\n\r\ni just used the movie lens database and steps in the notebook. it adds an extra '\\' in the \"outputLocation\"...?\r\n\r\ncan you help?  \r\n Hi @Kristof-Neys, can you give a screenshot of the error so we can confirm\/reproduce?  > Hi @Kristof-Neys, can you give a screenshot of the error so we can confirm\/reproduce?\r\n\r\n\r\n<img width=\"1103\" alt=\"error_train_screen\" src=\"https:\/\/user-images.githubusercontent.com\/10049871\/113705359-4123d580-96d5-11eb-9b65-59e38f3e5140.png\">\r\n > > Hi @Kristof-Neys, can you give a screenshot of the error so we can confirm\/reproduce?\r\n> \r\n> <img alt=\"error_train_screen\" width=\"1103\" src=\"https:\/\/user-images.githubusercontent.com\/10049871\/113705359-4123d580-96d5-11eb-9b65-59e38f3e5140.png\">\r\n\r\n<img width=\"1117\" alt=\"image\" src=\"https:\/\/user-images.githubusercontent.com\/10049871\/113705546-73cdce00-96d5-11eb-81fa-633c14942847.png\">\r\n > Hi @Kristof-Neys, can you give a screenshot of the error so we can confirm\/reproduce?\r\n\r\nhi @austinkline  - thanks for helping me out. So as you can see from the screenshots, it fails to download the data and seems to be adding an extra slash...\r\n\r\nso I changed the script: `--s3-processed-uri {str(s3_bucket_uri)}preloading \"\"\"` \r\nand it then ran fine.... perhaps you want to correct that in the notebook?\r\n\r\nbut when making the prediction I am getting:\r\n\r\n<img width=\"1120\" alt=\"image\" src=\"https:\/\/user-images.githubusercontent.com\/10049871\/113713442-42f29680-96df-11eb-8dc8-131e8377fa4c.png\">\r\n\r\n\r\nso Toy Story comes up as 'Thriller\" and not 'Comedy' as  per the notebook\r\n\r\n\r\nhow can I see which actual model the classification is using? Is it a graph convolutional network, I recall seeing that in the notebooks in the repository. It would be good to see the actual DGL model & code. \r\n\r\nThanks!!\r\n Thanks for the info. I'll spend some time reproducing and get back to you I was not able to reproduce this issue after running a fresh notebook created via cloud-formation found in our public docs\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/8711160\/113755017-afac6780-96c4-11eb-86ee-42798d595609.png)\r\n\r\n@Kristof-Neys I wonder if the state of the notebook got mixed up somehow? I would suggest creating a fresh notebook instance and trying again. The bug which needed the workaround lifecycle configuration has been resolved and released to pypi so that is not needed anymore > I was not able to reproduce this issue after running a fresh notebook created via cloud-formation found in our public docs\r\n> \r\n> ![image](https:\/\/user-images.githubusercontent.com\/8711160\/113755017-afac6780-96c4-11eb-86ee-42798d595609.png)\r\n> \r\n> @Kristof-Neys I wonder if the state of the notebook got mixed up somehow? I would suggest creating a fresh notebook instance and trying again. The bug which needed the workaround lifecycle configuration has been resolved and released to pypi so that is not needed anymore\r\n\r\nthank you @austinkline . I'll re-run everything from fresh... - meanwhile, how can I figure out which GNN model is actually used and the model specifics in DGL?  > thank you @austinkline . I'll re-run everything from fresh... - meanwhile, how can I figure out which GNN model is actually used and the model specifics in DGL?\r\n\r\nChecked with the team about this, you should be able to find this information in cloudwatch logs for that particular job in the Sagemaker console. \r\n > > thank you @austinkline . I'll re-run everything from fresh... - meanwhile, how can I figure out which GNN model is actually used and the model specifics in DGL?\r\n> \r\n> Checked with the team about this, you should be able to find this information in cloudwatch logs for that particular job in the Sagemaker console.\r\n\r\nyeah thanks - just found it in the S3, says rgcn which presumably stands for the relational graph convolutional network > > > thank you @austinkline . I'll re-run everything from fresh... - meanwhile, how can I figure out which GNN model is actually used and the model specifics in DGL?\r\n> > \r\n> > \r\n> > Checked with the team about this, you should be able to find this information in cloudwatch logs for that particular job in the Sagemaker console.\r\n> \r\n> yeah thanks - just found it in the S3, says rgcn which presumably stands for the relational graph convolutional network\r\n\r\nyes. that's correct. Hi @Kristof-Neys and updates? Did recreating work for you? Hi @austinkline - thanks for reaching out. I have been caught up in another project but was just about to look at it. I'll update you guys probably tomorrow.  hi @austinkline & Team, i am finally getting around to this. I started everything new but now I cannot export the configuration any more, I get the following error:\r\n`{'error': ConnectionError(MaxRetryError(\"HTTPSConnectionPool(host='none', port=443): Max retries exceeded with url: \/neptune-export (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f28f5e81748>: Failed to establish a new connection: [Errno -2] Name or service not known',))\",),)}`\r\n\r\nUPdate: when I re-started everything and used the notebook of last week... i get\r\n\r\n`403 \"Missing Authentication Token\" `\r\n\r\n\r\n\r\nany ideas? Thanks!!\r\n     Let's start by gathering what version you're running again and what your configuration looks like. What we want to figure out is whether the exporter or Neptune is throwing the exception provided. That is to say, was the exporter unable to be called due to a missing auth token, or did the exporter start and then it was unable to communicate with Neptune. You also could take a look at cloudwatch logs for your api gateway on the corresponding exporter resource and see if it has any additional info you can point to. I'll go ahead and provision a fresh stack and see if I get the same issue once we've confirmed your auth setting.\r\n\r\nCan you provide your notebook version and configuration by running the following:\r\n\r\n1. What cell did you execute that gave you the above mentioned error?\r\n\r\n2. What version of `graph-notebook` are you running?\r\n```\r\n%graph_notebook_version\r\n```\r\n\r\n3. What is your configuration? Really we just care about the authentication setting\r\n**NOTE: PLEASE ERASE OR BLOCK OUT YOUR HOST ENDPOINT FROM YOUR CONFIGURATION WHEN PROVIDING THIS INFO**\r\n\r\n```\r\n%graph_notebook_config\r\n```\r\n > Let's start by gathering what version you're running again and what your configuration looks like. What we want to figure out is whether the exporter or Neptune is throwing the exception provided. That is to say, was the exporter unable to be called due to a missing auth token, or did the exporter start and then it was unable to communicate with Neptune. You also could take a look at cloudwatch logs for your api gateway on the corresponding exporter resource and see if it has any additional info you can point to. I'll go ahead and provision a fresh stack and see if I get the same issue once we've confirmed your auth setting.\r\n> \r\n> Can you provide your notebook version and configuration by running the following:\r\n> \r\n>     1. What cell did you execute that gave you the above mentioned error?\r\n> \r\n>     2. What version of `graph-notebook` are you running?\r\n> \r\n> \r\n> ```\r\n> %graph_notebook_version\r\n> ```\r\n> \r\n>     1. What is your configuration? Really we just care about the authentication setting\r\n>        **NOTE: PLEASE ERASE OR BLOCK OUT YOUR HOST ENDPOINT FROM YOUR CONFIGURATION WHEN PROVIDING THIS INFO**\r\n> \r\n> \r\n> ```\r\n> %graph_notebook_config\r\n> ```\r\n\r\n@austinkline thank you! Very much appreciate taking time & effort. Ok, so these are the detail:\r\n\r\ncell that I am running:\r\n`%%neptune_ml export start --export-url {neptune_ml.get_export_service_host()} --export-iam --wait --store-to export_results\r\n${export_params}`\r\n=> this gives me error: \r\n`{\r\n  \"message\": \"Missing Authentication Token\"\r\n}`\r\n\r\n\r\nVersion graph-notebook: 2.1.0\r\n\r\n%graph_notebook_config:\r\n`{\r\n  \"host\": \"neptunedbcluster-xxxxxx.....xxxxxx.us-east-1.neptune.amazonaws.com\",\r\n  \"port\": 8182,\r\n  \"auth_mode\": \"DEFAULT\",\r\n  \"load_from_s3_arn\": \"arn:aws:iam::504028651370:role\/neptuneml-NeptuneBaseStack-Y-NeptuneLoadFromS3Role-1UBUI982ZI077\",\r\n  \"ssl\": true,\r\n  \"aws_region\": \"us-east-1\",\r\n  \"sparql\": {\r\n    \"path\": \"sparql\"\r\n  }\r\n}`\r\n\r\nThe strange thing is that all worked well two weeks ago, altho I did get wrong predictions, but at least the export worked and I could train model and get predictions etc. Now I cannot get beyond the export.... \r\n\r\nthank you again\r\n\r\n @Kristof-Neys I believe I found the bug we're dealing with. Can you flip IAM auth on in your config and see if the exporter\/other components work?\r\n\r\n```\r\n%%graph_notebook_config\r\n{\r\n  \"host\": \"neptunedbcluster-xxxxxx.....xxxxxx.us-east-1.neptune.amazonaws.com\",\r\n  \"port\": 8182,\r\n  \"auth_mode\": \"IAM\",\r\n  \"load_from_s3_arn\": \"arn:aws:iam::504028651370:role\/neptuneml-NeptuneBaseStack-Y-NeptuneLoadFromS3Role-1UBUI982ZI077\",\r\n  \"ssl\": true,\r\n  \"aws_region\": \"us-east-1\",\r\n  \"sparql\": {\r\n    \"path\": \"sparql\"\r\n  }\r\n}\r\n```\r\n\r\nNote that we're changing the auth mode to IAM > @Kristof-Neys I believe I found the bug we're dealing with. Can you flip IAM auth on in your config and see if the exporter\/other components work?\r\n> \r\n> ```\r\n> %%graph_notebook_config\r\n> {\r\n>   \"host\": \"neptunedbcluster-xxxxxx.....xxxxxx.us-east-1.neptune.amazonaws.com\",\r\n>   \"port\": 8182,\r\n>   \"auth_mode\": \"IAM\",\r\n>   \"load_from_s3_arn\": \"arn:aws:iam::504028651370:role\/neptuneml-NeptuneBaseStack-Y-NeptuneLoadFromS3Role-1UBUI982ZI077\",\r\n>   \"ssl\": true,\r\n>   \"aws_region\": \"us-east-1\",\r\n>   \"sparql\": {\r\n>     \"path\": \"sparql\"\r\n>   }\r\n> }\r\n> ```\r\n> \r\n> Note that we're changing the auth mode to IAM\r\nhey @austinkline  - that worked!, export and training went fine....but still predicting the wrong genre.... - how can this be??\r\n\r\n<img width=\"904\" alt=\"image\" src=\"https:\/\/user-images.githubusercontent.com\/10049871\/115867858-82d1b180-a433-11eb-809c-a1aa733e5d90.png\">\r\n\r\n\r\n @Kristof-Neys The issue you are seeing is actually one where the text in the notebook is incorrect.  Drama is what is coming back from the model that is generated .  I have created an issue to track this https:\/\/github.com\/aws\/graph-notebook\/issues\/116 and will address this with the additional feedback on those notebooks in the near future.  > @Kristof-Neys The issue you are seeing is actually one where the text in the notebook is incorrect. Drama is what is coming back from the model that is generated . I have created an issue to track this #116 and will address this with the additional feedback on those notebooks in the near future.\r\n\r\nok understood - thank you\r\n Closing this out since we're tracking the reported issue of notebooks being out of date in #116. Please cut us a new ticket if you run into any further issues! Hi guys, I'm facing a similar issue, I applied your fix(setting \"auth_mode\": \"IAM\") but did not work, any suggestions? Hi @llealgt , is this referring to the same issue mentioned at https:\/\/github.com\/aws\/graph-notebook\/issues\/445#issuecomment-1426192856? Hi @michaelnchin, nope, it's not the same, this happens when running notebook \r\nNeptune-ML-01-Introduction-to-Node-Classification-Gremlin\r\nThe other errors happen in notebook \r\nNeptune-ML-00-Getting-Started-with-Neptune-ML-Gremlin\r\nI guess it is related but they are different errors in different notebooks.",
        "Tool":"Neptune",
        "Platform":"Github",
        "Issue_original_content":"bug widget error bug start version widget have issu json valu pass get follow error error jsondecodeerror expect valu line column char reproduc step reproduc behavior run introduct node classif gremlin notebook export step error occur addit context problem version",
        "Issue_preprocessed_content":"widget bug start version widget have json valu reproduc step reproduc behavior run export step context problem version",
        "Issue_gpt_summary_original":"The user is encountering a bug with AWS Neptune templates for p3.2 and p3.16, which fail to start and stall out during the formation process, resulting in auto-deletion. The issue is being investigated, and it is suspected that it may be related to V100 GPU services.",
        "Issue_gpt_summary":"user encount bug aw templat fail start stall format process result auto delet issu investig suspect relat gpu servic",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws\/graph-notebook\/issues\/42",
        "Issue_title":"[BUG] Missing documentation on connecting to Neptune from MacOS",
        "Issue_created_time":1607104372000,
        "Issue_closed_time":1608658157000,
        "Issue_body":"**Describe the bug**\r\nThere are some missing details for how to connect to Neptune from a MacOS device, we should add them to our doc on connecting to neptune via ssh-tunnel found [here](https:\/\/github.com\/aws\/graph-notebook\/tree\/main\/additional-databases\/neptune)\r\n\r\nOne main piece that we are missing is that a host alias needs to be made in order to get things working properly.\r\n\r\n**Additional context**\r\nThis is coming from a bug report from connectivity not working as found in #40 ",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"Neptune",
        "Platform":"Github",
        "Issue_original_content":"bug miss document connect maco bug miss detail connect maco devic add doc connect ssh tunnel http github com aw graph notebook tree main addit databas main piec miss host alia need order thing work properli addit context come bug report connect work",
        "Issue_preprocessed_content":"document maco bug detail maco devic doc main piec host alia order thing work properli context come bug report work",
        "Issue_gpt_summary_original":"The user is encountering an AttributeError when using PyTorchLightningPruningCallback to search for the best hyperparameters. The error message states that the 'AcceleratorConnector' object has no attribute 'distributed_backend'. The user has provided a code snippet and expects the code to run without any errors. The user has provided the environment details, including the PyTorch Lightning version, PyTorch version, Python version, OS, and CUDA\/cuDNN version.",
        "Issue_gpt_summary":"user encount attributeerror pytorchlightningpruningcallback search best hyperparamet error messag state acceleratorconnector object attribut distribut backend user provid code snippet expect code run error user provid environ detail includ pytorch lightn version pytorch version python version cuda cudnn version",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/aws\/graph-notebook\/issues\/40",
        "Issue_title":"[BUG] No documentation on how to connect local notebook to remote Neptune SSL",
        "Issue_created_time":1606948478000,
        "Issue_closed_time":1607104425000,
        "Issue_body":"**SSL Connection to remote Neptune not working**\r\nI am unable to figure out how can I specify the correct certificate SFSRootCAG2.pem when running queries against SSL-enabled Neptune.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. I set up SSH tunnel via bastion to the Neptune cluster '_ssh -i keypairfilename.pem ec2-user@yourec2instanceendpoint -N -L 8182:yourneptuneendpoint:8182_'\r\n2. I start graph-notebook as '_jupyter notebook notebook\/destination_neptune_'. This gives me the output _Jupyter Notebook 6.1.5 is running at: http:\/\/localhost:8888\/?token=13b2761a59217f9246aed1dab73e70c3ae42973c4339f328_\r\n3. I open my notebook and run the following magic commands \r\n_'%%graph_notebook_config\r\n{\r\n  \"host\": \"localhost\",\r\n  \"port\": 8182,\r\n  \"auth_mode\": \"DEFAULT\",\r\n  \"iam_credentials_provider_type\": \"ROLE\",\r\n  \"load_from_s3_arn\": \"\",\r\n  \"aws_region\": <myregion>,\r\n  **\"ssl\": true**\r\n}'_\r\n4. I run the command \r\n_%%sparql        \r\nSELECT * WHERE {?s ?p ?o} LIMIT 1_\r\n\r\n5. It gives me the error\r\n**{'error': SSLError(MaxRetryError('HTTPSConnectionPool(host=\\'localhost\\', port=8182): Max retries exceeded with url: \/sparql (Caused by SSLError(SSLCertVerificationError(\"hostname \\'localhost\\' doesn\\'t match either of \\'*.............**\r\n\r\n**Expected behavior**\r\nI expect to be able to connect to a remote neptune that has ssl enabled.\r\n\r\n**Screenshots**\r\nNone\r\n\r\n**Desktop (please complete the following information):**\r\n - macOS 10.15.7 Catalina\r\n - Browser Chrome\r\n - Version 86.0.4240.198 (Official Build) (x86_64)\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.None",
        "Issue_answer_count":3,
        "Issue_self_closed":0.0,
        "Answer_body":"Looks like we have a missing piece in our walkthrough for connecting to Neptune:\r\n\r\nhttps:\/\/github.com\/aws\/graph-notebook\/tree\/main\/additional-databases\/neptune\r\n\r\nCould you set your hostname from localhost to your Neptune endpoint:\r\n\r\n```\r\n%graph_notebook_host <your endpoint here>\r\n```\r\n\r\nAnd give it a try? I  updated \/etc\/hosts on my Mac and added an alias for localhost as\r\n\r\n> _27.0.0.1       localhost    yourneptuneendpoint_\r\n\r\nFlushed DNS cache.\r\nSet the hostname in Jupyter notebook graph_notebook_config command to **yourneptuneendpoint**.\r\nRan sparql query and it successfully completed.\r\n\r\n\r\n Glad it worked! I have filed an issue for us to expand our documentation to cover the steps you had to take. Closing this but feel free to open or submit a new issue if you need further assistance",
        "Tool":"Neptune",
        "Platform":"Github",
        "Issue_original_content":"bug document connect local notebook remot ssl ssl connect remot work unabl figur specifi correct certif sfsrootcag pem run queri ssl enabl reproduc step reproduc behavior set ssh tunnel bastion cluster ssh keypairfilenam pem user yourecinstanceendpoint yourendpoint start graph notebook jupyt notebook notebook destin give output jupyt notebook run http localhost token bafaeddabecaecf open notebook run follow magic command graph notebook config host localhost port auth mode default iam credenti provid type role load arn aw region ssl true run command sparql select limit give error error sslerror maxretryerror httpsconnectionpool host localhost port max retri exceed url sparql caus sslerror sslcertverificationerror hostnam localhost match expect behavior expect abl connect remot ssl enabl screenshot desktop complet follow inform maco catalina browser chrome version offici build addit context add context problem",
        "Issue_preprocessed_content":"document local remot remot work unabl figur specifi certif queri enabl reproduc step reproduc behavior set bastion cluster start give output open run magic host localhost port default role true run select limit give max retri url sparql maco catalina browser chrome version context context problem",
        "Issue_gpt_summary_original":"The user encountered a broken notebook due to missing permission and is unsure if there are more issues. They are creating an issue to keep track of it and the severity is medium.",
        "Issue_gpt_summary":"user encount broken notebook miss permiss unsur issu creat issu track sever medium",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/neptune-ai\/examples\/issues\/42",
        "Issue_title":"Neptune_catalyst.ipynb fails",
        "Issue_created_time":1624893279000,
        "Issue_closed_time":1625030635000,
        "Issue_body":"Seems that the Neptune_catalyst.ipynb is failing. \r\nPerhaps there is some type as it seems to be missing the `run` object. \r\nhttps:\/\/github.com\/neptune-ai\/examples\/runs\/2932574924?check_suite_focus=true",
        "Issue_answer_count":3,
        "Issue_self_closed":0.0,
        "Answer_body":"on it. #43 fixing here fixed in #43 ",
        "Tool":"Neptune",
        "Platform":"Github",
        "Issue_original_content":"catalyst ipynb fail catalyst ipynb fail type miss run object http github com exampl run check suit focu true",
        "Issue_preprocessed_content":"fail fail type object",
        "Issue_gpt_summary_original":"The user encountered an issue while running a ray tune job using the Sigopt suggester on a remote cluster. The Sigopt suggester object was found to be unserializable, but the stack trace did not indicate this. The severity of the issue is medium, as it is a significant difficulty but can be worked around.",
        "Issue_gpt_summary":"user encount issu run rai tune job suggest remot cluster suggest object unserializ stack trace indic sever issu medium signific difficulti work",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/graphistry\/graph-app-kit\/issues\/57",
        "Issue_title":"[BUG] neptune minimal launcher link points to full launcher",
        "Issue_created_time":1625774761000,
        "Issue_closed_time":null,
        "Issue_body":"**Describe the bug**\r\nNeptune guide's quicklaunch link points to the full launcher\r\n\r\n**Expected behavior**\r\nShould point to the minimal launcher\r\n\r\n",
        "Issue_answer_count":0,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Neptune",
        "Platform":"Github",
        "Issue_original_content":"bug minim launcher link point launcher bug guid quicklaunch link point launcher expect behavior point minim launcher",
        "Issue_preprocessed_content":"minim launcher link point launcher bug guid quicklaunch link point launcher expect behavior point minim launcher",
        "Issue_gpt_summary_original":"The user is encountering an issue with the Sigopt (multi-metric) API failing with version 1.1.0 of Ray. The error message indicates that the API is trying to hash a list, which is not possible. The issue can be reproduced by running the Sigopt sections that are commented out in the specified file.",
        "Issue_gpt_summary":"user encount issu multi metric api fail version rai error messag indic api try hash list possibl issu reproduc run section comment specifi file",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/graphistry\/graph-app-kit\/issues\/45",
        "Issue_title":"[BUG] AWS neptune templates for p3.2, p3.16 fail to start",
        "Issue_created_time":1615094175000,
        "Issue_closed_time":1615109545000,
        "Issue_body":"**Describe the bug**\r\n\r\nCloud formation for neptune fails on a p3.2 and p3.16 yet succeeds on a g4dn\r\n\r\nReported by a Neptune user\r\n\r\n**To Reproduce**\r\n\r\nRun through Neptune tutorial and use a p3.16\r\n\r\n**Expected behavior**\r\nIt launches\r\n\r\n**Actual behavior**\r\nFormation template stalls out and auto-deletes\r\n\r\nWorking on getting logs. After 10min, GPU services (forge-etl-python + streamgl) failed to start. V100 issue?\r\n\r\n**Screenshots**\r\n\r\n**Browser environment (please complete the following information):**\r\nall\r\n\r\n**PyGraphistry environment**\r\nAll\r\n\r\n**Additional context**\r\nCurrent graph-app-kit",
        "Issue_answer_count":2,
        "Issue_self_closed":1.0,
        "Answer_body":"Slow start, and wrong docker images load, with manual restart required to reach a healthy state:\r\n\r\n```\r\nCONTAINER ID        IMAGE                                    COMMAND                  CREATED             STATUS                             PORTS                                                NAMES\r\n0e32dfece83d        graphistry\/graphistry-nexus:v2.32.4      \"\/entrypoint \/bin\/ba\u2026\"   28 minutes ago      Up 27 minutes (healthy)            8080\/tcp                                             graphistry_nexus_1\r\ndae68b0726e0        graphistry\/graphistry-pivot:v2.32.4      \"\/tini -- \/entrypoin\u2026\"   28 minutes ago      Up 27 minutes (healthy)            8080\/tcp                                             graphistry_pivot_1\r\nffea7ceeb047        graphistry\/etl-server:v2.32.4            \"\/tini -- \/entrypoin\u2026\"   30 minutes ago      Up 27 minutes (healthy)            8080\/tcp                                             graphistry_forge-etl_1\r\nfbbb7924272e        graphistry\/streamgl-gpu:v2.32.4          \"\/tini -- \/entrypoin\u2026\"   30 minutes ago      Up 39 seconds (health: starting)   8080\/tcp                                             graphistry_streamgl-gpu_1\r\n6c1501fe0317        graphistry\/streamgl-sessions:v2.32.4     \"\/tini -- \/entrypoin\u2026\"   30 minutes ago      Up 27 minutes (healthy)            8080\/tcp                                             graphistry_streamgl-sessions_1\r\n485ef6374082        willfarrell\/autoheal:v0.7.0              \"\/docker-entrypoint \u2026\"   30 minutes ago      Up 28 minutes (healthy)            8080\/tcp                                             graphistry_autoheal_1\r\n24e6fd022e1e        graphistry\/graphistry-postgres:v2.32.4   \"docker-entrypoint.s\u2026\"   30 minutes ago      Up 28 minutes (healthy)            5432\/tcp, 8080\/tcp                                   graphistry_postgres_1\r\n6bd0cc9c7a58        graphistry\/streamgl-vgraph-etl:v2.32.4   \"\/tini -- \/entrypoin\u2026\"   30 minutes ago      Up 27 minutes (healthy)            8080\/tcp                                             graphistry_streamgl-vgraph-etl_1\r\n097054def985        graphistry\/etl-server-python:v2.32.4     \"\/tini -- \/entrypoin\u2026\"   30 minutes ago      Up 27 minutes (healthy)            8080\/tcp                                             graphistry_forge-etl-python_1\r\n2e516287f6e5        graphistry\/streamgl-viz:v2.32.4          \"\/tini -- \/entrypoin\u2026\"   30 minutes ago      Up 27 minutes (healthy)            8080\/tcp                                             graphistry_streamgl-viz_1\r\nf16cd890cb6b        graphistry\/caddy:v2.30.28                \"\/usr\/bin\/caddy --co\u2026\"   30 minutes ago      Up 40 seconds (health: starting)   0.0.0.0:80->80\/tcp, 0.0.0.0:443->443\/tcp, 2015\/tcp   graphistry_caddy_1\r\nd14e375955c8        redis:6.0.5                              \"docker-entrypoint.s\u2026\"   30 minutes ago      Up 28 minutes (healthy)            6379\/tcp, 8080\/tcp                                   graphistry_redis_1\r\nub\r\n```\r\n\r\nAMI:\r\n\r\n* ami-088aaa8746bde2e21\r\n* graphistry-standalone-2020-10-14T22-32-56Z-v2.32.4-062c9b47-e144-4bbe-8623-fbf14199f760-ami-0cbffaeee3c800e7a.4\r\n* aws-marketplace\/graphistry-standalone-2020-10-14T22-32-56Z-v2.32.4-062c9b47-e144-4bbe-8623-fbf14199f760-ami-0cbffaeee3c800e7a.4 Likely fixed by https:\/\/github.com\/graphistry\/graph-app-kit\/pull\/49 . Reopen if needed.",
        "Tool":"Neptune",
        "Platform":"Github",
        "Issue_original_content":"bug aw templat fail start bug cloud format fail succe gdn report user reproduc run tutori us expect behavior launch actual behavior format templat stall auto delet work get log min gpu servic forg etl python streamgl fail start issu screenshot browser environ complet follow inform pygraphistri environ addit context current graph app kit",
        "Issue_preprocessed_content":"aw templat fail start bug cloud format fail report user reproduc run tutori us expect behavior launch actual behavior format templat work log min gpu servic fail start browser environ pygraphistri environ context",
        "Issue_gpt_summary_original":"The user is facing an issue with the Sigopt API being outdated in transformers trainer.py, resulting in a warning message and the HPO not working correctly. The user is seeking help from @sgugger to resolve the issue.",
        "Issue_gpt_summary":"user face issu api outdat transform trainer result warn messag hpo work correctli user seek help sgugger resolv issu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning\/issues\/14604",
        "Issue_title":"Optuna integration reports AttributeError",
        "Issue_created_time":1662640213000,
        "Issue_closed_time":1667802669000,
        "Issue_body":"## \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of the bug. -->\r\n\r\nWhen using `PyTorchLightningPruningCallback` to search best hyperparams, it reports `AttributeError: 'AcceleratorConnector' object has no attribute 'distributed_backend'`\r\n\r\n### To Reproduce\r\n\r\n```python\r\nfrom typing import List, Optional\r\n\r\nimport optuna\r\nimport pytorch_lightning as pl\r\nimport torch\r\nimport torch.nn as nn\r\nimport torchmetrics\r\nimport torchvision\r\nfrom optuna.integration.pytorch_lightning import PyTorchLightningPruningCallback\r\nfrom torch.utils.data import random_split, DataLoader\r\n\r\n\r\nclass FashionDataModule(pl.LightningDataModule):\r\n    def __init__(self, data_dir: str, batch_size: int):\r\n        super().__init__()\r\n        self.data_dir = data_dir\r\n        self.batch_size = batch_size\r\n\r\n    def setup(self, stage: Optional[str] = None):\r\n        self.train_set = torchvision.datasets.FashionMNIST(\r\n            self.data_dir, train=True, download=True, transform=torchvision.transforms.ToTensor()\r\n        )\r\n        self.test_set = torchvision.datasets.FashionMNIST(\r\n            self.data_dir, train=False, download=True, transform=torchvision.transforms.ToTensor()\r\n        )\r\n        self.train_set, self.valid_set = random_split(self.train_set, [55000, 5000])\r\n\r\n    def train_dataloader(self) -> DataLoader:\r\n        return DataLoader(self.train_set, batch_size=self.batch_size, shuffle=True, num_workers=4)\r\n\r\n    def val_dataloader(self) -> DataLoader:\r\n        return DataLoader(self.valid_set, batch_size=self.batch_size, shuffle=False, num_workers=4)\r\n\r\n    def test_dataloader(self) -> DataLoader:\r\n        return DataLoader(self.test_set, batch_size=self.batch_size, shuffle=False, num_workers=4)\r\n\r\n\r\nclass SimpleNet(nn.Module):\r\n    def __init__(self, d_hids: List[int], p_drop: float):\r\n        super(SimpleNet, self).__init__()\r\n\r\n        hidden_layers = []\r\n        d_inp = 28 * 28\r\n        for d_hid in d_hids:\r\n            hidden_layers.append(nn.Linear(d_inp, d_hid))\r\n            hidden_layers.append(nn.ReLU())\r\n            hidden_layers.append(nn.Dropout(p_drop))\r\n            d_inp = d_hid\r\n        hidden_layers.append(nn.Linear(d_inp, 10))\r\n\r\n        self.layers = nn.Sequential(*hidden_layers)\r\n\r\n    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\r\n        return self.layers(inputs)\r\n\r\n\r\nclass LitSimpleNet(pl.LightningModule):\r\n    def __init__(self, d_hids: List[int], p_drop: float):\r\n        super().__init__()\r\n        self.model = SimpleNet(d_hids, p_drop)\r\n        self.criterion = nn.CrossEntropyLoss()\r\n        self.accuracy = torchmetrics.Accuracy()\r\n\r\n    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\r\n        return self.model(inputs.view(-1, 28 * 28))\r\n\r\n    def training_step(self, batch, batch_idx) -> torch.Tensor:\r\n        inputs, targets = batch\r\n        outputs = self(inputs)\r\n        return self.criterion(outputs, targets)\r\n\r\n    def validation_step(self, batch, batch_idx):\r\n        inputs, targets = batch\r\n        outputs = self(inputs)\r\n        self.accuracy(outputs, targets)\r\n        self.log(\"valid_acc\", self.accuracy, on_step=False, on_epoch=True, prog_bar=True)\r\n\r\n    def configure_optimizers(self):\r\n        return torch.optim.Adam(self.parameters(), lr=3e-4, weight_decay=1e-5)\r\n\r\n\r\ndef objective(trial: optuna.trial.Trial) -> float:\r\n    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\r\n    p_drop = trial.suggest_float(\"p_drop\", 0.1, 0.5)\r\n    d_hids = [trial.suggest_int(f\"d_hid_{i}\", 16, 128, log=True) for i in range(n_layers)]\r\n\r\n    datamodule = FashionDataModule(\".\", 128)\r\n    model = LitSimpleNet(d_hids, p_drop)\r\n    trainer = pl.Trainer(\r\n        max_epochs=20,\r\n        accelerator=\"gpu\",\r\n        devices=1,\r\n        enable_checkpointing=False,\r\n        logger=True,\r\n        default_root_dir=\".\",\r\n        callbacks=[PyTorchLightningPruningCallback(trial, monitor=\"valid_acc\")]\r\n    )\r\n\r\n    hparams = dict(n_layers=n_layers, d_hids=d_hids, p_drop=p_drop)\r\n    trainer.logger.log_hyperparams(hparams)\r\n    trainer.fit(model, datamodule=datamodule)\r\n    return trainer.callback_metrics[\"valid_acc\"].item()\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    pruner = optuna.pruners.MedianPruner()\r\n    study = optuna.create_study(direction=\"maximize\", pruner=pruner)\r\n    study.optimize(objective, n_trials=100, timeout=1000)\r\n\r\n    print(\"Number of Finished Trials:\", len(study.trials))\r\n\r\n    trial = study.best_trial\r\n    print(\"Best Trial:\")\r\n    print(\"\\tValue:\", trial.value)\r\n    print(\"\\tParams:\")\r\n    for key, value in trial.params.items():\r\n        print(f\"\\t\\t{key}: {value}\")\r\n\r\n```\r\n\r\n```bash\r\n[W 2022-09-08 20:14:45,294] Trial 0 failed because of the following error: AttributeError(\"'AcceleratorConnector' object has no attribute 'distributed_backend'\")\r\nTraceback (most recent call last):\r\n  File \"\/home\/wyn\/miniconda3\/envs\/wyn\/lib\/python3.8\/site-packages\/optuna\/study\/_optimize.py\", line 196, in _run_trial\r\n    value_or_values = func(trial)\r\n  File \"optuna_examples\/optuna_lightning_example.py\", line 89, in objective\r\n    trainer = pl.Trainer(\r\n  File \"\/home\/wyn\/miniconda3\/envs\/wyn\/lib\/python3.8\/site-packages\/pytorch_lightning\/utilities\/argparse.py\", line 345, in insert_env_defaults\r\n    return fn(self, **kwargs)\r\n  File \"\/home\/wyn\/miniconda3\/envs\/wyn\/lib\/python3.8\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 497, in __init__\r\n    self._call_callback_hooks(\"on_init_start\")\r\n  File \"\/home\/wyn\/miniconda3\/envs\/wyn\/lib\/python3.8\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 1585, in _call_callback_hooks\r\n    fn(self, *args, **kwargs)\r\n  File \"\/home\/wyn\/miniconda3\/envs\/wyn\/lib\/python3.8\/site-packages\/optuna\/integration\/pytorch_lightning.py\", line 61, in on_init_start\r\n    trainer._accelerator_connector.distributed_backend is not None  # type: ignore\r\nAttributeError: 'AcceleratorConnector' object has no attribute 'distributed_backend'\r\n```\r\n\r\n<!--\r\nPlease reproduce using the BoringModel!\r\n\r\nYou can use the following Colab link:\r\nhttps:\/\/colab.research.google.com\/github\/Lightning-AI\/lightning\/blob\/master\/examples\/pl_bug_report\/bug_report_model.ipynb\r\nIMPORTANT: has to be public.\r\n\r\nor this simple template:\r\nhttps:\/\/github.com\/Lightning-AI\/lightning\/blob\/master\/examples\/pl_bug_report\/bug_report_model.py\r\n\r\nIf you could not reproduce using the BoringModel and still think there's a bug, please post here\r\nbut remember, bugs with code are fixed faster!\r\n-->\r\n\r\n### Expected behavior\r\n\r\nShould not report any errors.\r\n\r\n### Environment\r\n\r\n<!--\r\nPlease copy and paste the output from our environment collection script:\r\nhttps:\/\/raw.githubusercontent.com\/Lightning-AI\/lightning\/master\/requirements\/collect_env_details.py\r\n(For security purposes, please check the contents of the script before running it)\r\n\r\nYou can get the script and run it with:\r\n```bash\r\nwget https:\/\/raw.githubusercontent.com\/Lightning-AI\/lightning\/master\/requirements\/collect_env_details.py\r\npython collect_env_details.py\r\n\r\n```\r\n\r\n\r\n<details>\r\n  <summary>Details<\/summary>\r\n    Paste the output here and move this toggle outside of the comment block.\r\n<\/details>\r\n\r\n\r\nYou can also fill out the list below manually.\r\n-->\r\n\r\n- Lightning Component:  Trainer\r\n- PyTorch Lightning Version:  1.7.5\r\n- PyTorch Version:  1.12.1\r\n- Python version: 3.8.13\r\n- OS: Linux (Ubuntu 20.04)\r\n- CUDA\/cuDNN version: 11.3.1\r\n- How you installed PyTorch: conda\r\n\r\n\n\ncc @akihironitta",
        "Issue_answer_count":9,
        "Issue_self_closed":0.0,
        "Answer_body":"Hey, @RegiusQuant. \r\n\r\nSide answer, you might be interested by Lightning HPO: https:\/\/github.com\/Lightning-AI\/lightning-hpo. This enables to run Optuna with PyTorch Lightning without friction and scalable in the cloud.\r\n\r\n Hey, @RegiusQuant - Thanks for the question. Can you please point me to the version of `optuna` that you are using?  For reference: https:\/\/github.com\/optuna\/optuna\/issues\/3978 @krshrimali Optuna version\uff1a3.0.0 I'm observing the same issue with Optuna 3.0.2 @hrzn Hi, I'm from the Optuna-dev team. Optuna's pytorch-lightning (PL) integration module doesn't support PL>=1.6 because it broke backwards-compatibility as investigated in https:\/\/github.com\/optuna\/optuna\/issues\/3418. Unfortunately, Optuna team doesn't have time to fix the module soon to support recent PL; we would like to wait for a PR from optuna and PL users.\r\n\r\n@tchaton I believe you can close this issue because the issue comes from Optuna... With Optuna==3.0.2 with lightning==1.5.10, I got \r\n`ValueError: optuna.integration.PyTorchLightningPruningCallback supports only optuna.storages.RDBStorage in DDP.`\r\nAfter downgrading Optuna to 2.0.0 (arbitrary version) while keeping lightning==1.5.10, it ran without any error.  @mikiotada Again, the error does not relate to PL. As the error message said, Optuna's integration does not support DDP without RDBStorage. \r\n\r\n> After downgrading Optuna to 2.0.0 (arbitrary version) while keeping lightning==1.5.10, it ran without any error.\r\n\r\nIn my understanding, Optuna 2.x didn't officially support DDP; it does not work as you expected, I'm afraid even though there was no error. Closing this issue as there seems nothing we can address from our side. Please refer to https:\/\/github.com\/optuna\/optuna\/issues\/3418.",
        "Tool":"Optuna",
        "Platform":"Github",
        "Issue_original_content":"integr report attributeerror bug pytorchlightningpruningcallback search best hyperparam report attributeerror acceleratorconnector object attribut distribut backend reproduc python type import list option import import pytorch lightn import torch import torch import torchmetr import torchvis integr pytorch lightn import pytorchlightningpruningcallback torch util data import random split dataload class fashiondatamodul lightningdatamodul def init self data dir str batch size int super init self data dir data dir self batch size batch size def setup self stage option str self train set torchvis dataset fashionmnist self data dir train true download true transform torchvis transform totensor self test set torchvis dataset fashionmnist self data dir train fals download true transform torchvis transform totensor self train set self valid set random split self train set def train dataload self dataload return dataload self train set batch size self batch size shuffl true num worker def val dataload self dataload return dataload self valid set batch size self batch size shuffl fals num worker def test dataload self dataload return dataload self test set batch size self batch size shuffl fals num worker class simplenet modul def init self hid list int drop float super simplenet self init hidden layer inp hid hid hidden layer append linear inp hid hidden layer append relu hidden layer append dropout drop inp hid hidden layer append linear inp self layer sequenti hidden layer def forward self input torch tensor torch tensor return self layer input class litsimplenet lightningmodul def init self hid list int drop float super init self model simplenet hid drop self criterion crossentropyloss self accuraci torchmetr accuraci def forward self input torch tensor torch tensor return self model input view def train step self batch batch idx torch tensor input target batch output self input return self criterion output target def valid step self batch batch idx input target batch output self input self accuraci output target self log valid acc self accuraci step fals epoch true prog bar true def configur optim self return torch optim adam self paramet weight decai def object trial trial trial float layer trial suggest int layer drop trial suggest float drop hid trial suggest int hid log true rang layer datamodul fashiondatamodul model litsimplenet hid drop trainer trainer max epoch acceler gpu devic enabl checkpoint fals logger true default root dir callback pytorchlightningpruningcallback trial monitor valid acc hparam dict layer layer hid hid drop drop trainer logger log hyperparam hparam trainer fit model datamodul datamodul return trainer callback metric valid acc item main pruner pruner medianprun studi creat studi direct maxim pruner pruner studi optim object trial timeout print number finish trial len studi trial trial studi best trial print best trial print tvalu trial valu print tparam kei valu trial param item print kei valu bash trial fail follow error attributeerror acceleratorconnector object attribut distribut backend traceback recent file home wyn miniconda env wyn lib python site packag studi optim line run trial valu valu func trial file exampl lightn exampl line object trainer trainer file home wyn miniconda env wyn lib python site packag pytorch lightn util argpars line insert env default return self kwarg file home wyn miniconda env wyn lib python site packag pytorch lightn trainer trainer line init self callback hook init start file home wyn miniconda env wyn lib python site packag pytorch lightn trainer trainer line callback hook self arg kwarg file home wyn miniconda env wyn lib python site packag integr pytorch lightn line init start trainer acceler connector distribut backend type ignor attributeerror acceleratorconnector object attribut distribut backend expect behavior report error environ detail past output toggl outsid comment block list manual lightn compon trainer pytorch lightn version pytorch version python version linux ubuntu cuda cudnn version instal pytorch conda akihironitta",
        "Issue_preprocessed_content":"integr report bug clear concis descript bug search best hyperparam report reproduc reproduc boringmodel us colab link import public simpl templat reproduc boringmodel think bug post rememb bug code fix faster expect behavior report environ copi past output environ script secur purpos check content script script run detail past output outsid block detail list lightn compon trainer pytorch lightn version pytorch version python version linux version pytorch conda",
        "Issue_gpt_summary_original":"The user has created a custom docker container to deploy a model on Vertex AI that uses LightGBM. While the user is able to get predictions, they encounter errors while trying to get explainable predictions from the model. The user has followed the Vertex AI guidelines to configure the model for explanations, but the issue persists. The error message suggests that the response field 'predictions' is missing.",
        "Issue_gpt_summary":"user creat custom docker contain deploi model us lightgbm user abl predict encount error try explain predict model user follow guidelin configur model explan issu persist error messag suggest respons field predict miss",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/ray-project\/ray\/issues\/27203",
        "Issue_title":"[AIR] Fix  \/\/doc\/source\/tune\/examples:sigopt_example",
        "Issue_created_time":1659034993000,
        "Issue_closed_time":1659051271000,
        "Issue_body":"### What happened + What you expected to happen\n\nNotebook is broken due to missing permission first, maybe more issues down the road. @Yard1 looked into it earlier and we're creating this issue to keep track of it.\n\n### Versions \/ Dependencies\n\nmaster\n\n### Reproduction script\n\n`bazel test \/\/doc\/source\/tune\/examples:sigopt_example`\n\n### Issue Severity\n\nMedium: It is a significant difficulty but I can work around it.",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"Duplicate of https:\/\/github.com\/ray-project\/ray\/issues\/26567",
        "Tool":"SigOpt",
        "Platform":"Github",
        "Issue_original_content":"air fix doc sourc tune exampl exampl happen expect happen notebook broken miss permiss mayb issu road yard look earlier creat issu track version depend master reproduct script bazel test doc sourc tune exampl exampl issu sever medium signific difficulti work",
        "Issue_preprocessed_content":"fix expect broken mayb road earlier creat track version depend master reproduct script sever medium signific work",
        "Issue_gpt_summary_original":"The user is encountering an error while using Vertex AI Automl training python API with a foreign project's BigQuery table as the source for the dataset. Even though the 'Vertex AI service agent' and 'Vertex AI Custom code service agent' have been added to the BigQuery dataset with 'bigquery data editor' role, the user is receiving a bigquery.tables.get permission denied error when trying to run the automl training job. The user has received a temporary workaround by adding column specification in API call, but they would like to have this fixed in the SDK.",
        "Issue_gpt_summary":"user encount error automl train python api foreign project bigqueri tabl sourc dataset servic agent custom code servic agent ad bigqueri dataset bigqueri data editor role user receiv bigqueri tabl permiss deni error try run automl train job user receiv temporari workaround ad column specif api like fix sdk",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/ray-project\/ray\/issues\/24864",
        "Issue_title":"[tune] SigOptSearch suggester is not serialisable",
        "Issue_created_time":1652740461000,
        "Issue_closed_time":null,
        "Issue_body":"### What happened + What you expected to happen\n\nI tried to run a ray tune job using the Sigopt suggester on a remote cluster. The sigopt suggester object was later found to be unserialisable however the stack trace gave no indication of this.\r\n\r\nThe stack trace looks like this\r\n\r\ndiscussion around this issue can be found here https:\/\/ray-distributed.slack.com\/archives\/CNECXMW22\/p1652417782100299\r\n\r\nThanks to Matthew Deng for finding the issue on this one!\n\n### Versions \/ Dependencies\n\nPython 3.8.12\r\nray==1.12.0\n\n### Reproduction script\n\n```\r\nimport ray\r\nimport numpy as np\r\nimport os\r\nos.environ['SIGOPT_KEY'] = APIKEYHERE\r\n\r\nfrom ray.tune.suggest.sigopt import SigOptSearch\r\nfrom ray import tune\r\nWORKING_DIR = os.getcwd()\r\n\r\n\r\n\r\ndef main():\r\n\r\n\tray.init(\r\n\t\taddress = \"ray:\/\/127.0.0.1:10001\",\r\n\t\t# address = \"auto\",\r\n\t\truntime_env = {\r\n\t\t\t\"working_dir\": WORKING_DIR,\r\n\t\t\t\"pip\": [\"sigopt==5.7.0\"]\r\n\t\t}\r\n\t)\r\n\t\r\n\tn_observations = 20\r\n\r\n\thyperparameter_space = [\r\n          {\r\n              'name': 'learning_rate',\r\n              'type': 'double',\r\n              'bounds': {\r\n                  'max': np.log(0.01),\r\n                  'min': np.log(0.0001)\r\n              },\r\n          },\r\n          {\r\n              'name': 'momentum',\r\n              'type': 'double',\r\n              'bounds': {\r\n                  'min': 0.85,\r\n                  'max': 0.99\r\n              },\r\n          },\r\n      ]\r\n\t\r\n\tsigopt_search = SigOptSearch(\r\n\t\t# OmegaConf.to_container(config.search_space),\r\n        hyperparameter_space,\r\n\t\tname=\"Tune distributed\",\r\n\t\tmax_concurrent=2, \r\n\t\tobservation_budget=n_observations,\r\n\t\tproject=\"sigopt-ray-integration\",\r\n\t\tmetric=[\"val_loss\"],\r\n\t\tmode=[\"min\"]\r\n\t\t# metric=[\"val_loss\", \"training_loss\"],\r\n\t\t# mode=[\"max\", \"min\"]\r\n\t)\r\n\r\n\ttune_config = {\r\n\t\t# \"config\": config\r\n\t}\r\n\tanalysis = tune.run(\r\n\t\ttrain_model,\r\n\t\tmetric=\"val_loss\",\r\n\t\tmode=\"min\",\r\n\t\tconfig=tune_config,\r\n\t\tnum_samples=n_observations,\r\n\t\tname=\"Tune distributed\",\r\n\t\tresources_per_trial={'gpu': 1},\r\n\t\tsearch_alg=sigopt_search,\r\n\t\t# scheduler=FIFOScheduler(),\r\n\t)\r\n\r\n\r\n\r\n\r\ndef train_model(config):\r\n    pass\r\n\r\nmain()\r\n\r\n```\n\n### Issue Severity\n\nMedium: It is a significant difficulty but I can work around it.",
        "Issue_answer_count":0,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"SigOpt",
        "Platform":"Github",
        "Issue_original_content":"tune search suggest serialis happen expect happen tri run rai tune job suggest remot cluster suggest object later unserialis stack trace gave indic stack trace look like discuss issu http rai distribut slack com archiv cnecxmw thank matthew deng find issu version depend python rai reproduct script import rai import numpi import environ kei apikeyher rai tune suggest import search rai import tune work dir getcwd def main rai init address rai address auto runtim env work dir work dir pip observ hyperparamet space learn rate type doubl bound max log min log momentum type doubl bound min max search search omegaconf contain config search space hyperparamet space tune distribut max concurr observ budget observ project rai integr metric val loss mode min metric val loss train loss mode max min tune config config config analysi tune run train model metric val loss mode min config tune config num sampl observ tune distribut resourc trial gpu search alg search schedul fifoschedul def train model config pass main issu sever medium signific difficulti work",
        "Issue_preprocessed_content":"search serialis expect tri run rai tune job remot cluster object later unserialis stack trace gave indic stack trace like thank deng find version depend python reproduct script sever medium signific work",
        "Issue_gpt_summary_original":"The user is unable to import the `aiplatform` module in the Vertex AI Matching Engine sample notebook. They receive a `TypeError` stating that descriptors cannot be created directly. The user has tried to run the notebook in a Vertex AI Workbench running the Python3 image but is still encountering installation issues.",
        "Issue_gpt_summary":"user unabl import aiplatform modul match engin sampl notebook receiv typeerror state descriptor creat directli user tri run notebook workbench run python imag encount instal issu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/ray-project\/ray\/issues\/11581",
        "Issue_title":"[Tune] Sigopt (multi-metric) api fails with 1.1.0 (tries to hash list)",
        "Issue_created_time":1603479422000,
        "Issue_closed_time":1603498330000,
        "Issue_body":"<!--Please include [tune], [rllib], [autoscaler] etc. in the issue title if relevant-->\r\nIf you run \r\n\r\npy_test(\r\n name = \"sigopt_prior_beliefs_example\",\r\n size = \"medium\",\r\n srcs = [\"examples\/sigopt_prior_beliefs_example.py\"],\r\n deps = [\":tune_lib\"],\r\n tags = [\"exclusive\", \"example\"],\r\n args = [\"--smoke-test\"]\r\n)\r\n\r\nin python\/ray\/tune\/build (this part of the testing is commented out since you need a sigopt API key...)\r\nYou get an output that looks like this:\r\n\r\n\"\"\"\r\n...\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/ray\/tune\/trial_runner.py\", line 737, in _process_trial\r\n    self._validate_result_metrics(result)\r\n  File \"\/usr\/local\/lib\/python3.8\/site-packages\/ray\/tune\/trial_runner.py\", line 818, in _validate_result_metrics\r\n    elif search_metric and search_metric not in result:\r\nTypeError: unhashable type: 'list'\r\n...\r\n\"\"\"\r\nray 1.1.0.dev\r\n\r\n### Reproduction (REQUIRED)\r\nin python\/ray\/tune\/build  run the sigopt sections that are commented out.\r\n",
        "Issue_answer_count":3,
        "Issue_self_closed":0.0,
        "Answer_body":"This is a consequence of search metric being able to be multi-metric. cc @krfricke \r\n\r\nAlso, let me ping the sigopt folks for a working API key... Should be fixed on #11583 . We'll pick this onto the release.",
        "Tool":"SigOpt",
        "Platform":"Github",
        "Issue_original_content":"tune multi metric api fail tri hash list run test prior belief exampl size medium src exampl prior belief exampl dep tune lib tag exclus exampl arg smoke test python rai tune build test comment need api kei output look like file usr local lib python site packag rai tune trial runner line process trial self valid result metric result file usr local lib python site packag rai tune trial runner line valid result metric elif search metric search metric result typeerror unhash type list rai dev reproduct requir python rai tune build run section comment",
        "Issue_preprocessed_content":"api fail run size medium src dep tag arg output like file line file line elif result unhash type list rai reproduct run section",
        "Issue_gpt_summary_original":"The user has encountered an issue with Vertex AI endpoint call with JSON, where they are unable to generate the JSON payload for the input of the neural network. They have tried different methods, but all have resulted in an error 400, indicating an invalid JSON payload. The user is unsure if the array needs to be in b64 format and is seeking help to fix\/encode the payload.",
        "Issue_gpt_summary":"user encount issu endpoint json unabl gener json payload input neural network tri differ method result error indic invalid json payload user unsur arrai need format seek help fix encod payload",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/huggingface\/transformers\/issues\/18145",
        "Issue_title":"the Sigopt api is outdated in transformers trainer.py, the old api could not work",
        "Issue_created_time":1657875526000,
        "Issue_closed_time":1658150380000,
        "Issue_body":"### System Info\r\n\r\n- `transformers` version: 4.21.0.dev0\r\n- Platform: Linux-5.8.0-43-generic-x86_64-with-glibc2.29\r\n- Python version: 3.8.10\r\n- Huggingface_hub version: 0.7.0\r\n- PyTorch version (GPU?): 1.11.0+cu113 (True)\r\n- Tensorflow version (GPU?): 2.9.1 (False)\r\n- Flax version (CPU?\/GPU?\/TPU?): 0.5.0 (cpu)\r\n- Jax version: 0.3.6\r\n- JaxLib version: 0.3.5\r\n- Using GPU in script?: <fill in>\r\n- Using distributed or parallel set-up in script?: <fill in>\r\n\r\n\r\n### Who can help?\r\n\r\n@sgugger \r\n\r\n### Information\r\n\r\n- [ ] The official example scripts\r\n- [ ] My own modified scripts\r\n\r\n### Tasks\r\n\r\n- [ ] An officially supported task in the `examples` folder (such as GLUE\/SQuAD, ...)\r\n- [ ] My own task or dataset (give details below)\r\n\r\n### Reproduction\r\n\r\n1.enable sigopt HPO in example and run.\r\n2. work log like\"UserWarning: You're currently using the old SigOpt Experience. Try out the new and improved SigOpt experience by getting started with the docs today. You have until July 2022 to migrate over without experiencing breaking changes.\"\r\n\r\n### Expected behavior\r\n\r\nHPO with sigopt backend could work correctly without warning",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"SigOpt",
        "Platform":"Github",
        "Issue_original_content":"api outdat transform trainer old api work info transform version dev platform linux gener glibc python version huggingfac hub version pytorch version gpu true tensorflow version gpu fals flax version cpu gpu tpu cpu jax version jaxlib version gpu script distribut parallel set script help sgugger inform offici exampl script modifi script task offici support task exampl folder glue squad task dataset detail reproduct enabl hpo exampl run work log like userwarn current old experi try new improv experi get start doc todai juli migrat experienc break chang expect behavior hpo backend work correctli warn",
        "Issue_preprocessed_content":"api outdat transform old api work info version platform python version version pytorch version tensorflow version flax version jax version jaxlib version gpu script distribut script help inform exampl script modifi script task task folder task dataset reproduct enabl hpo exampl run work log like userwarn old experi try new improv experi start doc todai juli migrat experienc break expect behavior hpo backend work warn",
        "Issue_gpt_summary_original":"The user is facing an issue with the ModelUploadOp method from \"Vertex AI Pipelines: model upload using google-cloud-pipeline-components\" while attempting to upload a custom model to Vertex AI models. The logs show that the job is succeeding, but the model never actually gets uploaded. The user has provided code examples that show the method that doesn't work and the one that does work. The user is using Vertex AI Pipelines with Pipeline SDK (Kubeflow Pipelines\/TFX) Version: kfp and Pipelines Version: kfp==1.8.11 on the Google Cloud Vertex AI platform.",
        "Issue_gpt_summary":"user face issu modeluploadop method pipelin model upload googl cloud pipelin compon attempt upload custom model model log job succeed model actual get upload user provid code exampl method work work user pipelin pipelin sdk kubeflow pipelin tfx version kfp pipelin version kfp googl cloud platform",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/googleapis\/python-aiplatform\/issues\/1526",
        "Issue_title":"Error while trying to get explanation from (custom container) model deployed on Vertex AI (Prediction without explanation works fine)",
        "Issue_created_time":1658320562000,
        "Issue_closed_time":1659550833000,
        "Issue_body":"Hi,\r\n\r\nI created a custom docker container to deploy my model on Vertex AI. The model uses LightGBM, so I can't use the pre-built container images available for TF\/SKL\/XGBoost. I was able to deploy the model and get predictions, but I get errors while trying to get **explainable** predictions from the model. I have tried to follow the Vertex AI guidelines to configure the model for explanations.\r\nThe example below shows a simplified version of the model that still reproduces the issue, with only two input features 'A' and 'B'.\r\n\r\nPlease take a look and tell me if the explanation metadata is supposed to be set differently, or if there is something wrong with this approach.\r\n\r\n\r\n#### Environment details\r\n\r\n  - Google Cloud Notebook\r\n  - Python version: 3.7.12\r\n  - pip version: 21.3.1\r\n  - `google-cloud-aiplatform` version: 1.15.0\r\n\r\n#### Reference\r\nhttps:\/\/cloud.google.com\/vertex-ai\/docs\/explainable-ai\/configuring-explanations#custom-container\r\n\r\n#### explanation-metadata.json\r\n(_Model output is unkeyed. The Vertex AI guide suggests using any memorable string for output key._)\r\n```\r\n{\r\n    \"inputs\": {\r\n        \"A\": {},\r\n        \"B\": {}\r\n    },\r\n    \"outputs\": {\r\n        \"Y\": {}\r\n    }\r\n}\r\n```\r\n#### Model upload with explanation parameters and metadata\r\n```\r\n! gcloud ai models upload \\\r\n  --region=$REGION \\\r\n  --display-name=$MODEL_NAME \\\r\n  --container-image-uri=$PRED_IMAGE_URI \\\r\n  --artifact-uri=$ARTIFACT_LOCATION_GCS \\\r\n  --explanation-method=sampled-shapley \\\r\n  --explanation-path-count=10 \\\r\n  --explanation-metadata-file=explanation-metadata.json\r\n```\r\n\r\n#### Prediction\/Explanation Input\r\n```\r\ninstances = [{\"A\": 1.1, \"B\": 20}, {\"A\": 2.2, \"B\": 21}]\r\n# Prediction (works fine):\r\nendpoint.predict(instances=instances)\r\n# Prediction output: predictions=[0, 1], deployed_model_id='<>', model_version_id='', model_resource_name='<>', explanations=None\r\nendpoint.explain(instances=instances) # Returns error (1) shown in stack trace below\r\n\r\n# Another example\r\ninstances_2 = [[1.1,20], [2.2,21]]\r\n# Prediction (works fine):\r\nendpoint.predict(instances=instances_2)\r\n# Prediction output: predictions=[0, 1], deployed_model_id='<>', model_version_id='', model_resource_name='<>', explanations=None\r\nendpoint.explain(instances=instances_2) # Returns error\r\n# Error: Nameless inputs are allowed only if there is a single input in the explanation metadata.\r\n```\r\n#### Prediction Server (Flask)\r\n```python\r\n# Custom Flask server to serve online predictions\r\n# Input for prediction\r\nraw_input = request.get_json()\r\ninput = raw_input['instances']\r\ndf = pd.DataFrame(input, columns = ['A', 'B'])\r\n# Prediction from model (loaded from GCP bucket)\r\npredictions = model.predict(df).tolist() # [0, 1]\r\nresponse = jsonify({\"predictions\": predictions})\r\nreturn response\r\n```\r\n\r\n#### Stack trace of error (1)\r\n```\r\n---------------------------------------------------------------------------\r\n_InactiveRpcError                         Traceback (most recent call last)\r\n\/opt\/conda\/lib\/python3.7\/site-packages\/google\/api_core\/grpc_helpers.py in error_remapped_callable(*args, **kwargs)\r\n     49         try:\r\n---> 50             return callable_(*args, **kwargs)\r\n     51         except grpc.RpcError as exc:\r\n\r\n\/opt\/conda\/lib\/python3.7\/site-packages\/grpc\/_channel.py in __call__(self, request, timeout, metadata, credentials, wait_for_ready, compression)\r\n    945                                       wait_for_ready, compression)\r\n--> 946         return _end_unary_response_blocking(state, call, False, None)\r\n    947 \r\n\r\n\/opt\/conda\/lib\/python3.7\/site-packages\/grpc\/_channel.py in _end_unary_response_blocking(state, call, with_call, deadline)\r\n    848     else:\r\n--> 849         raise _InactiveRpcError(state)\r\n    850 \r\n\r\n_InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\r\n\tstatus = StatusCode.INVALID_ARGUMENT\r\n\tdetails = \"{\"error\": \"Unable to explain the requested instance(s) because: Invalid response from prediction server - the response field predictions is missing. Response: {'error': '400 Bad Request: The browser (or proxy) sent a request that this server could not understand.'}\"}\"\r\n\tdebug_error_string = \"{\"created\":\"@1658310559.755090975\",\"description\":\"Error received from peer ipv4:74.125.133.95:443\",\"file\":\"src\/core\/lib\/surface\/call.cc\",\"file_line\":1069,\"grpc_message\":\"{\"error\": \"Unable to explain the requested instance(s) because: Invalid response from prediction server - the response field predictions is missing. Response: {'error': '400 Bad Request: The browser (or proxy) sent a request that this server could not understand.'}\"}\",\"grpc_status\":3}\"\r\n>\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nInvalidArgument                           Traceback (most recent call last)\r\n\/tmp\/ipykernel_2590\/4024017963.py in <module>\r\n----> 3 print(endpoint.explain(instances=instances, parameters={}))\r\n\r\n~\/.local\/lib\/python3.7\/site-packages\/google\/cloud\/aiplatform\/models.py in explain(self, instances, parameters, deployed_model_id, timeout)\r\n   1563             parameters=parameters,\r\n   1564             deployed_model_id=deployed_model_id,\r\n-> 1565             timeout=timeout,\r\n   1566         )\r\n   1567 \r\n\r\n~\/.local\/lib\/python3.7\/site-packages\/google\/cloud\/aiplatform_v1\/services\/prediction_service\/client.py in explain(self, request, endpoint, instances, parameters, deployed_model_id, retry, timeout, metadata)\r\n    917             retry=retry,\r\n    918             timeout=timeout,\r\n--> 919             metadata=metadata,\r\n    920         )\r\n    921 \r\n\r\n\/opt\/conda\/lib\/python3.7\/site-packages\/google\/api_core\/gapic_v1\/method.py in __call__(self, timeout, retry, *args, **kwargs)\r\n    152             kwargs[\"metadata\"] = metadata\r\n    153 \r\n--> 154         return wrapped_func(*args, **kwargs)\r\n    155 \r\n    156 \r\n\r\n\/opt\/conda\/lib\/python3.7\/site-packages\/google\/api_core\/grpc_helpers.py in error_remapped_callable(*args, **kwargs)\r\n     50             return callable_(*args, **kwargs)\r\n     51         except grpc.RpcError as exc:\r\n---> 52             raise exceptions.from_grpc_error(exc) from exc\r\n     53 \r\n     54     return error_remapped_callable\r\n\r\nInvalidArgument: 400 {\"error\": \"Unable to explain the requested instance(s) because: Invalid response from prediction server - the response field predictions is missing. Response: {'error': '400 Bad Request: The browser (or proxy) sent a request that this server could not understand.'}\"}\r\n---------------------------------------------------------------------------\r\n```",
        "Issue_answer_count":8,
        "Issue_self_closed":0.0,
        "Answer_body":"Hi @jaycee-li,\r\nAny update on this? Would really appreciate your inputs! Hi @pankajrsingla, sorry for the late reply!\r\n\r\nSince instance_2 prediction works for your model, looks like your model takes unkeyed input. Could you please try this metadata setting:\r\n```\r\n{\r\n    \"inputs\": {\r\n        \"X\": {},\r\n    },\r\n    \"outputs\": {\r\n        \"Y\": {}\r\n    }\r\n}\r\n```\r\nThen update the model, endpoint, and try:\r\n```\r\ninstances = [[1.1,20], [2.2,21]]\r\nendpoint.explain(instances=instances)\r\n```\r\n\r\nPlease let me know if this works for you. Hi @jaycee-li,\r\nThank you so much for your response.\r\nI tried your suggestion, but I got the same error as before.\r\n`Invalid response from prediction server - the response field predictions is missing. Response: {'error': '400 Bad Request: The browser (or proxy) sent a request that this server could not understand.'}\"}\"`\r\n\r\nIf you see the code for my prediction server, it can take both unkeyed as well as keyed input (prediction works fine for both cases), since it converts the input to a dataframe. The output is definitely unkeyed. However, I am still confused as to what should be the contents of the explanation-metadata.json file.\r\n\r\nAlso, just to be sure - the same API (predict) in the flask server is supposed to work for both predictions and explanations, right? Or do I need to create a separate API for 'explain'?\r\n\r\nIf you have any other suggestions, I would be more than happy to try them out. \r\n(If that would help, I can also send you the full contents of the Jupyter notebook - all code one place - if you share your email id.)\r\n\r\nPlease let me know!\r\n\r\nThank you! It would be helpful if you can share the notebook to jayceeli@google.com\r\n\r\nThank you very much! Done!\r\nThanks! :) Hi @pankajrsingla ,\r\n\r\nI got `AttributeError: 'Blob' object has no attribute 'open'` for `with blob.open(\"wb\") as f:` in your TRAIN_IMAGE_URI. So I was stuck here and didn't reproduce the error you got. \r\n\r\nYou mixed CLI, gapic API, and SDK in your code. Since I'm not familiar with CLI tool, I'm not very sure what the problem is. Maybe it's due to your PRED_IMAGE_URI? I would suggest you to try a pre-built container(`us-docker.pkg.dev\/vertex-ai\/prediction\/sklearn-cpu.1-0:latest`) when uploading the model.\r\n\r\nI drafted a notebook that used SDK only to train, upload, deploy a same model as yours. And it can successfully make predictions and explanations. I've shared the notebook with you for your reference.\r\n\r\nPlease let me know if you still get the error. Thanks! Hi @pankajrsingla ,\r\n\r\nPlease check this [notebook](https:\/\/github.com\/GoogleCloudPlatform\/vertex-ai-samples\/blob\/main\/notebooks\/community\/ml_ops\/stage6\/get_started_with_xai_and_custom_server.ipynb) (Specifically **Create the model server** and **Build a FastAPI HTTP server** sections) for how to use XAI with a custom container. Thanks a lot, @jaycee-li! This is exactly what I was looking for!\r\nI will give this a try for my model, and will update you once I have the results. This should work.\r\n\r\nThank you!",
        "Tool":"Vertex AI",
        "Platform":"Github",
        "Issue_original_content":"error try explan custom contain model deploi predict explan work fine creat custom docker contain deploi model model us lightgbm us pre built contain imag avail skl xgboost abl deploi model predict error try explain predict model tri follow guidelin configur model explan exampl show simplifi version model reproduc issu input featur look tell explan metadata suppos set differ wrong approach environ detail googl cloud notebook python version pip version googl cloud aiplatform version refer http cloud googl com vertex doc explain configur explan custom contain explan metadata json model output unkei guid suggest memor string output kei input output model upload explan paramet metadata gcloud model upload region region displai model contain imag uri pred imag uri artifact uri artifact locat gc explan method sampl shaplei explan path count explan metadata file explan metadata json predict explan input instanc predict work fine endpoint predict instanc instanc predict output predict deploi model model version model resourc explan endpoint explain instanc instanc return error shown stack trace exampl instanc predict work fine endpoint predict instanc instanc predict output predict deploi model model version model resourc explan endpoint explain instanc instanc return error error nameless input allow singl input explan metadata predict server flask python custom flask server serv onlin predict input predict raw input request json input raw input instanc datafram input column predict model load gcp bucket predict model predict tolist respons jsonifi predict predict return respons stack trace error inactiverpcerror traceback recent opt conda lib python site packag googl api core grpc helper error remap callabl arg kwarg try return callabl arg kwarg grpc rpcerror exc opt conda lib python site packag grpc channel self request timeout metadata credenti wait readi compress wait readi compress return end unari respons block state fals opt conda lib python site packag grpc channel end unari respons block state deadlin rais inactiverpcerror state inactiverpcerror except direct caus follow except invalidargu traceback recent tmp ipykernel print endpoint explain instanc instanc paramet local lib python site packag googl cloud aiplatform model explain self instanc paramet deploi model timeout paramet paramet deploi model deploi model timeout timeout local lib python site packag googl cloud aiplatform servic predict servic client explain self request endpoint instanc paramet deploi model retri timeout metadata retri retri timeout timeout metadata metadata opt conda lib python site packag googl api core gapic method self timeout retri arg kwarg kwarg metadata metadata return wrap func arg kwarg opt conda lib python site packag googl api core grpc helper error remap callabl arg kwarg return callabl arg kwarg grpc rpcerror exc rais except grpc error exc exc return error remap callabl invalidargu error unabl explain request instanc invalid respons predict server respons field predict miss respons error bad request browser proxi sent request server understand",
        "Issue_preprocessed_content":"try explan model deploi creat custom docker contain deploi model model us lightgbm us contain imag avail abl deploi model predict try explain predict model tri guidelin configur model explan exampl show simplifi version model reproduc input featur explan metadata set wrong environ detail cloud python version pip version version refer output unkei guid memor string output model upload explan paramet metadata input predict server stack trace",
        "Issue_gpt_summary_original":"The user encountered an issue with the outdated Vertex AI blog post after the 0.20.0 release. The guide to run a pipeline using Vertex AI fails because ZenML does not have a `metadata-store` stack category. The user tried to run `zenml metadata-store` but received an error message. Without adding the `metadata-store`, the Vertex AI pipeline fails.",
        "Issue_gpt_summary":"user encount issu outdat blog post releas guid run pipelin fail zenml metadata store stack categori user tri run zenml metadata store receiv error messag ad metadata store pipelin fail",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/googleapis\/python-aiplatform\/issues\/1078",
        "Issue_title":"Vertex AI Automl training error when training dataset with foreign project's BQ table as source",
        "Issue_created_time":1647263282000,
        "Issue_closed_time":1649696673000,
        "Issue_body":"### Issue in Vertex AI Automl training python API while using vertex dataset with source as foreign project's BQ table\r\n- What would you like to achieve: I would like to run automl training job(using automl api python) with vertex dataset created from foreign project's BigQuery table.\r\n- Even though 'vertex AI service agent' and 'Vertex AI Custom code service agent' added to respective bigquery dataset with 'bigquery data editor' role, we are receiving bigquery.tables.get persmission denied error when we try run automl training job. \r\n\r\nError:\r\n`INFO:google.cloud.aiplatform.training_jobs:No column transformations provided, so now retrieving columns from dataset in order to set default column transformations. \r\nTraceback (most recent call last): \r\nFile \"\/home\/vsts\/work\/1\/a\/.terraform\/modules\/gcp_automl\/scripts\/train_automl.py\", line 190, in <module> \r\nautoml_tabular = create_training_pipeline_tabular(train_type, project_id, display_name, int(dataset_id), location, model_display_name, float(training_fraction_split), float(validation_fraction_split), float(test_fraction_split), int(budget_milli_node_hours), disable_early_stopping, sync, target_column) \r\nFile \"\/home\/vsts\/work\/1\/a\/.terraform\/modules\/gcp_automl\/scripts\/train_automl.py\", line 57, in create_training_pipeline_tabular \r\nmodel = tabular_job.run( \r\nFile \"\/home\/vsts\/.local\/lib\/python3.8\/site-packages\/google\/cloud\/aiplatform\/training_jobs.py\", line 3461, in run \r\nreturn self._run( \r\nFile \"\/home\/vsts\/.local\/lib\/python3.8\/site-packages\/google\/cloud\/aiplatform\/base.py\", line 730, in wrapper \r\nreturn method(*args, **kwargs) \r\nFile \"\/home\/vsts\/.local\/lib\/python3.8\/site-packages\/google\/cloud\/aiplatform\/training_jobs.py\", line 3645, in _run \r\n) = column_transformations_utils.get_default_column_transformations( \r\nFile \"\/home\/vsts\/.local\/lib\/python3.8\/site-packages\/google\/cloud\/aiplatform\/utils\/column_transformations_utils.py\", line 42, in get_default_column_transformations \r\nfor column_name in dataset.column_names \r\nFile \"\/home\/vsts\/.local\/lib\/python3.8\/site-packages\/google\/cloud\/aiplatform\/datasets\/column_names_dataset.py\", line 81, in column_names \r\nself._retrieve_bq_source_columns( \r\nFile \"\/home\/vsts\/.local\/lib\/python3.8\/site-packages\/google\/cloud\/aiplatform\/datasets\/column_names_dataset.py\", line 241, in _retrieve_bq_source_columns \r\ntable = client.get_table(bq_table_uri) \r\nFile \"\/home\/vsts\/.local\/lib\/python3.8\/site-packages\/google\/cloud\/bigquery\/client.py\", line 1034, in get_table \r\napi_response = self._call_api( \r\nFile \"\/home\/vsts\/.local\/lib\/python3.8\/site-packages\/google\/cloud\/bigquery\/client.py\", line 782, in _call_api \r\nreturn call() \r\nFile \"\/home\/vsts\/.local\/lib\/python3.8\/site-packages\/google\/api_core\/retry.py\", line 283, in retry_wrapped_func \r\nreturn retry_target( \r\nFile \"\/home\/vsts\/.local\/lib\/python3.8\/site-packages\/google\/api_core\/retry.py\", line 190, in retry_target \r\nreturn target() \r\nFile \"\/home\/vsts\/.local\/lib\/python3.8\/site-packages\/google\/cloud\/_http\/__init__.py\", line 480, in api_request \r\nraise exceptions.from_http_response(response) \r\ngoogle.api_core.exceptions.Forbidden: 403 GET https:\/\/bigquery.googleapis.com\/bigquery\/v2\/projects\/<<projectID>>\/datasets\/<<datasetID>>\/tables\/<<tableID>>?prettyPrint=false: Access Denied: Table <<TableID>>: Permission bigquery.tables.get denied on table <<TableID>> (or it may not exist). \r\n`\r\n\r\nAfter raising google support, we got a temporary workaround by adding column specification in API call (reference case# 29535929, 29310889).\r\n**Sample API call of the workaround:**\r\n`job = training_jobs.AutoMLTabularTrainingJob( \r\ndisplay_name=\"my_display_name\", \r\noptimization_prediction_type=\"classification\", \r\noptimization_objective=\"minimize-log-loss\", \r\ncolumn_specs={\"column_1\": \"auto\", \"column_2\": \"numeric\"}, \r\nlabels={'key': 'value'}, \r\n) \r\n`\r\n\r\nWe would want to have this fixed in in SDK. If possible, we would like to have a gcloud command for automl modules.\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"I've updated the docstring to clarify that the service account needs certain permissions when neither `column_transformations` or `column_specs` is set.",
        "Tool":"Vertex AI",
        "Platform":"Github",
        "Issue_original_content":"automl train error train dataset foreign project tabl sourc issu automl train python api vertex dataset sourc foreign project tabl like achiev like run automl train job automl api python vertex dataset creat foreign project bigqueri tabl servic agent custom code servic agent ad respect bigqueri dataset bigqueri data editor role receiv bigqueri tabl persmiss deni error try run automl train job error info googl cloud aiplatform train job column transform provid retriev column dataset order set default column transform traceback recent file home vst work terraform modul gcp automl script train automl line automl tabular creat train pipelin tabular train type project displai int dataset locat model displai float train fraction split float valid fraction split float test fraction split int budget milli node hour disabl earli stop sync target column file home vst work terraform modul gcp automl script train automl line creat train pipelin tabular model tabular job run file home vst local lib python site packag googl cloud aiplatform train job line run return self run file home vst local lib python site packag googl cloud aiplatform base line wrapper return method arg kwarg file home vst local lib python site packag googl cloud aiplatform train job line run column transform util default column transform file home vst local lib python site packag googl cloud aiplatform util column transform util line default column transform column dataset column name file home vst local lib python site packag googl cloud aiplatform dataset column name dataset line column name self retriev sourc column file home vst local lib python site packag googl cloud aiplatform dataset column name dataset line retriev sourc column tabl client tabl tabl uri file home vst local lib python site packag googl cloud bigqueri client line tabl api respons self api file home vst local lib python site packag googl cloud bigqueri client line api return file home vst local lib python site packag googl api core retri line retri wrap func return retri target file home vst local lib python site packag googl api core retri line retri target return target file home vst local lib python site packag googl cloud http init line api request rais except http respons respons googl api core except forbidden http bigqueri googleapi com bigqueri project dataset tabl prettyprint fals access deni tabl permiss bigqueri tabl deni tabl exist rais googl support got temporari workaround ad column specif api refer case sampl api workaround job train job automltabulartrainingjob displai displai optim predict type classif optim object minim log loss column spec column auto column numer label kei valu want fix sdk possibl like gcloud command automl modul",
        "Issue_preprocessed_content":"automl train train dataset foreign project tabl sourc automl train python api vertex dataset sourc foreign project tabl like achiev like run automl train job vertex dataset creat foreign project bigqueri tabl servic agent custom code servic agent respect bigqueri dataset bigqueri data editor role receiv deni try run automl train job rais got temporari workaround column specif api sampl api workaround want fix sdk like gcloud automl modul",
        "Issue_gpt_summary_original":"The user encountered a \"Deadline exceeded\" error while running a demo on their local computer using the `@google-cloud\/aiplatform` version 2.3.0. The error occurred during the prediction process and was displayed in the line `await predictionServiceClient.predict(request);`. The user's environment details include a Mac M1 Pro operating system, Node.js version 16.16.0, and npm version 8.11.0.",
        "Issue_gpt_summary":"user encount deadlin exceed error run demo local googl cloud aiplatform version error occur predict process displai line await predictionservicecli predict request user environ detail includ mac pro oper node version npm version",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/GoogleCloudPlatform\/vertex-ai-samples\/issues\/1315",
        "Issue_title":"Unable to import aiplatform module when running Vertex AI Matching Engine sample notebook",
        "Issue_created_time":1669999872000,
        "Issue_closed_time":null,
        "Issue_body":"## Expected Behavior\r\nI expect the notebook here https:\/\/github.com\/GoogleCloudPlatform\/vertex-ai-samples\/blob\/main\/notebooks\/official\/matching_engine\/sdk_matching_engine_for_indexing.ipynb to work\r\n\r\n\r\n\r\n## Actual Behavior\r\n\r\n, but for some reason whenever I try to import the module `aiplatform` inside a cell of the notebook\r\n```\r\nfrom google.cloud import aiplatform\r\n```\r\n\r\nI get the following error:\r\n\r\n```\r\n\/opt\/conda\/lib\/python3.7\/site-packages\/google\/protobuf\/descriptor.py in __new__(cls, name, index, number, type, options, serialized_options, create_key)\r\n    753                 type=None,  # pylint: disable=redefined-builtin\r\n    754                 options=None, serialized_options=None, create_key=None):\r\n--> 755       _message.Message._CheckCalledFromGeneratedFile()\r\n    756       # There is no way we can build a complete EnumValueDescriptor with the\r\n    757       # given parameters (the name of the Enum is not known, for example).\r\n\r\nTypeError: Descriptors cannot not be created directly.\r\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\r\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\r\n 1. Downgrade the protobuf package to 3.20.x or lower.\r\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\r\n\r\nMore information: https:\/\/developers.google.com\/protocol-buffers\/docs\/news\/2022-05-06#python-updates\r\n```\r\n\r\n\r\n## Steps to Reproduce the Problem\r\n\r\n1. Clone the sample notebook\r\n1. Import it into a vertex AI Workbench running the Python3 image\r\n1. Try to run through the steps and get stuck in installation issues\r\n\r\n## Specifications\r\n\r\n- Version:\r\n- Platform:",
        "Issue_answer_count":3,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Vertex AI",
        "Platform":"Github",
        "Issue_original_content":"unabl import aiplatform modul run match engin sampl notebook expect behavior expect notebook http github com googlecloudplatform vertex sampl blob main notebook offici match engin sdk match engin index ipynb work actual behavior reason try import modul aiplatform insid cell notebook googl cloud import aiplatform follow error opt conda lib python site packag googl protobuf descriptor new cl index number type option serial option creat kei type pylint disabl redefin builtin option serial option creat kei messag messag checkcalledfromgeneratedfil wai build complet enumvaluedescriptor given paramet enum known exampl typeerror descriptor creat directli came file gener code date regener protoc immedi regener proto possibl workaround downgrad protobuf packag lower set protocol buffer python implement python us pure python pars slower inform http develop googl com protocol buffer doc new python updat step reproduc problem clone sampl notebook import workbench run python imag try run step stuck instal issu specif version platform",
        "Issue_preprocessed_content":"unabl import aiplatform modul match engin sampl expect behavior expect work actual behavior reason try import modul insid step reproduc problem clone sampl import workbench python imag try run step stuck specif version platform",
        "Issue_gpt_summary_original":"The user has encountered a bug with the Scikit Learn model in the kubeflow_pipelines\/pipelines directory, which assumes input as Pandas Dataframe and cannot handle JSON from Web API in Vertex AI prediction environment. The user has provided a code snippet that reproduces the issue and suggested rewriting the feature definition part of train.py to resolve the issue. The user has also provided the target files that need to be updated.",
        "Issue_gpt_summary":"user encount bug scikit learn model kubeflow pipelin pipelin directori assum input panda datafram handl json web api predict environ user provid code snippet reproduc issu suggest rewrit featur definit train resolv issu user provid target file need updat",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/GoogleCloudPlatform\/vertex-ai-samples\/issues\/749",
        "Issue_title":"Vertex AI - Endpoint Call with JSON - Invalid JSON payload received",
        "Issue_created_time":1658950752000,
        "Issue_closed_time":1659564318000,
        "Issue_body":"I successfully trained and deployed a Tensorflow Recommender model on Vertex AI, Tensorflow 2.8.\r\n\r\nEverything is online and to predict the output. In the notebook I do:\r\n\r\n    loaded = tf.saved_model.load(path)\r\n    scores, titles = loaded([\"doctor\"])\r\n\r\nThat returns:\r\n\r\n    Recommendations: [b'Nelly & Monsieur Arnaud (1995)'\r\n     b'Three Lives and Only One Death (1996)' b'Critical Care (1997)']\r\n\r\nThat is, the payload (input for the neural network) must be `[\"doctor\"]`\r\n\r\nThen I generate the JSON for payload (the error is here):\r\n\r\n    !echo {\"\\\"\"instances\"\\\"\" : [{\"\\\"\"input_1\"\\\"\" : {[\"\\\"\"doctor\"\\\"\"]}}]} > instances0.json\r\n\r\nAnd submit to the endpoint:\r\n\r\n    !curl -X POST  \\\r\n    -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\r\n    -H \"Content-Type: application\/json\" \\\r\n    https:\/\/us-west1-aiplatform.googleapis.com\/v1\/projects\/my_project\/locations\/us-west1\/endpoints\/123456789:predict \\\r\n    -d @instances0.json > results.json\r\n\r\n... as seen here: https:\/\/colab.research.google.com\/github\/GoogleCloudPlatform\/vertex-ai-samples\/blob\/master\/notebooks\/community\/vertex_endpoints\/tf_hub_obj_detection\/deploy_tfhub_object_detection_on_vertex_endpoints.ipynb#scrollTo=35348dd21acd\r\n\r\nHowever, when I use this payload, I get error 400:\r\n\r\n    code: 400\r\n    message: \"Invalid JSON payload received. Expected an object key or }. s\" : [{\"input_1\" : {[\"doctor\"]}}]} ^\"\r\n    status: \"INVALID_ARGUMENT\"\r\n\r\nThis below don't work either:\r\n\r\n    !echo {\"inputs\": {\"input_1\": [\"doctor\"]}} > instances0.json\r\n\r\nEven with validated JSON Lint, it does not return the proper prediction.\r\n\r\nRunning:\r\n\r\n    !saved_model_cli show --dir \/home\/jupyter\/model --all\r\n\r\nI get:\r\n\r\n    MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\r\n    \r\n    signature_def['__saved_model_init_op']:\r\n      The given SavedModel SignatureDef contains the following input(s):\r\n      The given SavedModel SignatureDef contains the following output(s):\r\n        outputs['__saved_model_init_op'] tensor_info:\r\n            dtype: DT_INVALID\r\n            shape: unknown_rank\r\n            name: NoOp\r\n      Method name is: \r\n    \r\n    signature_def['serving_default']:\r\n      The given SavedModel SignatureDef contains the following input(s):\r\n        inputs['input_1'] tensor_info:\r\n            dtype: DT_STRING\r\n            shape: (-1)\r\n            name: serving_default_input_1:0\r\n      The given SavedModel SignatureDef contains the following output(s):\r\n        outputs['output_1'] tensor_info:\r\n            dtype: DT_FLOAT\r\n            shape: (-1, 10)\r\n            name: StatefulPartitionedCall_1:0\r\n        outputs['output_2'] tensor_info:\r\n            dtype: DT_STRING\r\n            shape: (-1, 10)\r\n            name: StatefulPartitionedCall_1:1\r\n      Method name is: tensorflow\/serving\/predict\r\n\r\n\r\n    Concrete Functions:\r\n      Function Name: '__call__'\r\n        Option #1\r\n          Callable with:\r\n            Argument #1\r\n              input_1: TensorSpec(shape=(None,), dtype=tf.string, name='input_1')\r\n            Argument #2\r\n              DType: NoneType\r\n              Value: None\r\n            Argument #3\r\n              DType: bool\r\n              Value: True\r\n        Option #2\r\n          Callable with:\r\n            Argument #1\r\n              queries: TensorSpec(shape=(None,), dtype=tf.string, name='queries')\r\n            Argument #2\r\n              DType: NoneType\r\n              Value: None\r\n            Argument #3\r\n              DType: bool\r\n              Value: True\r\n        Option #3\r\n          Callable with:\r\n            Argument #1\r\n              input_1: TensorSpec(shape=(None,), dtype=tf.string, name='input_1')\r\n            Argument #2\r\n              DType: NoneType\r\n              Value: None\r\n            Argument #3\r\n              DType: bool\r\n              Value: False\r\n        Option #4\r\n          Callable with:\r\n            Argument #1\r\n              queries: TensorSpec(shape=(None,), dtype=tf.string, name='queries')\r\n            Argument #2\r\n              DType: NoneType\r\n              Value: None\r\n            Argument #3\r\n              DType: bool\r\n              Value: False\r\n    \r\n      Function Name: '_default_save_signature'\r\n        Option #1\r\n          Callable with:\r\n            Argument #1\r\n              input_1: TensorSpec(shape=(None,), dtype=tf.string, name='input_1')\r\n    \r\n      Function Name: 'call_and_return_all_conditional_losses'\r\n        Option #1\r\n          Callable with:\r\n            Argument #1\r\n              input_1: TensorSpec(shape=(None,), dtype=tf.string, name='input_1')\r\n            Argument #2\r\n              DType: NoneType\r\n              Value: None\r\n            Argument #3\r\n              DType: bool\r\n              Value: False\r\n        Option #2\r\n          Callable with:\r\n            Argument #1\r\n              queries: TensorSpec(shape=(None,), dtype=tf.string, name='queries')\r\n            Argument #2\r\n              DType: NoneType\r\n              Value: None\r\n            Argument #3\r\n              DType: bool\r\n              Value: True\r\n        Option #3\r\n          Callable with:\r\n            Argument #1\r\n              queries: TensorSpec(shape=(None,), dtype=tf.string, name='queries')\r\n            Argument #2\r\n              DType: NoneType\r\n              Value: None\r\n            Argument #3\r\n              DType: bool\r\n              Value: False\r\n        Option #4\r\n          Callable with:\r\n            Argument #1\r\n              input_1: TensorSpec(shape=(None,), dtype=tf.string, name='input_1')\r\n            Argument #2\r\n              DType: NoneType\r\n              Value: None\r\n            Argument #3\r\n              DType: bool\r\n              Value: True\r\n\r\nThe point is: I'm passing an array and I'm not sure if it must be in b64 format.\r\n\r\nThis Python code works, but returns a different result than expected:\r\n\r\n    import tensorflow as tf\r\n    import base64\r\n    from google.protobuf import json_format\r\n    from google.protobuf.struct_pb2 import Value\r\n    import numpy as np\r\n    from google.cloud import aiplatform\r\n    import os\r\n    vertex_model = tf.saved_model.load(\"gs:\/\/bucket\/model\")\r\n    \r\n    serving_input = list(\r\n        vertex_model.signatures[\"serving_default\"].structured_input_signature[1].keys()\r\n    )[0]\r\n    \r\n    print(\"Serving input :\", serving_input)\r\n    \r\n    aip_endpoint_name = (\r\n        f\"projects\/my-project\/locations\/us-west1\/endpoints\/12345567\"\r\n    )\r\n    endpoint = aiplatform.Endpoint(aip_endpoint_name)\r\n    \r\n    def encode_input(input):\r\n        return base64.b64encode(np.array(input)).decode(\"utf-8\")\r\n    \r\n    instances_list = [{serving_input: {\"b64\": encode_input(np.array([\"doctor\"]))}}]\r\n    instances = [json_format.ParseDict(s, Value()) for s in instances_list]\r\n    \r\n    results = endpoint.predict(instances=instances)\r\n    print(results.predictions[0][\"output_2\"])\r\n\r\n\r\n    ['8 1\/2 (1963)', 'Sword in the Stone, The (1963)', 'Much Ado About Nothing (1993)', 'Jumanji (1995)', 'As Good As It Gets (1997)', 'Age of Innocence, The (1993)', 'Double vie de V\u00e9ronique, La (Double Life of Veronique, The) (1991)', 'Piano, The (1993)', 'Eat Drink Man Woman (1994)', 'Bullets Over Broadway (1994)']\r\n\r\nAny ideas on how to fix \/ encode the payload ?\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
        "Issue_answer_count":2,
        "Issue_self_closed":0.0,
        "Answer_body":"This works perfectly:\r\n\r\n    def encode_64(input):\r\n        message = input\r\n        message_bytes = message.encode('ascii')\r\n        base64_bytes = base64.b64encode(message_bytes)\r\n        base64_message = base64_bytes.decode('ascii')\r\n        return base64_message\r\n    \r\n    \r\n    instances_list = [{serving_input: {\"b64\": encode_64(\"doctor\")}}]\r\n    instances = [json_format.ParseDict(s, Value()) for s in instances_list]\r\n    \r\n    results = endpoint.predict(instances=instances)\r\n    print(results.predictions[0][\"output_2\"][:3])\r\n\r\n    ['Nelly & Monsieur Arnaud (1995)', 'Three Lives and Only One Death (1996)', 'Critical Care (1997)']\r\n\r\nBut I still have doubts regarding the CURL method. You have extra curly braces around your input data. Try something like:\r\n\r\n```\r\n!echo {\"\\\"\"instances\"\\\"\" : [{\"\\\"\"input_1\"\\\"\" : [\"\\\"\"doctor\"\\\"\"]}]} > instances0.json\r\n```\r\n\r\nAssuming you are using a [GCP prebuilt container](https:\/\/cloud.google.com\/vertex-ai\/docs\/predictions\/pre-built-containers), this is endpoint launches the equivalent of a [TF Serving container](https:\/\/www.tensorflow.org\/tfx\/guide\/serving) and you can test your model locally with a container before pushing to an endpoint to make sure everything is working. Take a look at [this notebook](https:\/\/github.com\/northam-stp-team\/vertexai-apigee\/blob\/master\/notebooks\/Seq2SeqTranslation.ipynb).",
        "Tool":"Vertex AI",
        "Platform":"Github",
        "Issue_original_content":"endpoint json invalid json payload receiv successfulli train deploi tensorflow recommend model tensorflow onlin predict output notebook load save model load path score titl load doctor return recommend nelli monsieur arnaud live death critic care payload input neural network doctor gener json payload error echo instanc input doctor instanc json submit endpoint curl post author bearer gcloud auth print access token content type applic json http west aiplatform googleapi com project project locat west endpoint predict instanc json result json seen http colab research googl com github googlecloudplatform vertex sampl blob master notebook commun vertex endpoint hub obj detect deploi tfhub object detect vertex endpoint ipynb scrollto ddacd us payload error code messag invalid json payload receiv expect object kei input doctor statu invalid argument work echo input input doctor instanc json valid json lint return proper predict run save model cli dir home jupyt model metagraphdef tag set serv contain follow signaturedef signatur def save model init given savedmodel signaturedef contain follow input given savedmodel signaturedef contain follow output output save model init tensor info dtype invalid shape unknown rank noop method signatur def serv default given savedmodel signaturedef contain follow input input input tensor info dtype string shape serv default input given savedmodel signaturedef contain follow output output output tensor info dtype float shape statefulpartitionedcal output output tensor info dtype string shape statefulpartitionedcal method tensorflow serv predict concret function function option callabl argument input tensorspec shape dtype string input argument dtype nonetyp valu argument dtype bool valu true option callabl argument queri tensorspec shape dtype string queri argument dtype nonetyp valu argument dtype bool valu true option callabl argument input tensorspec shape dtype string input argument dtype nonetyp valu argument dtype bool valu fals option callabl argument queri tensorspec shape dtype string queri argument dtype nonetyp valu argument dtype bool valu fals function default save signatur option callabl argument input tensorspec shape dtype string input function return condit loss option callabl argument input tensorspec shape dtype string input argument dtype nonetyp valu argument dtype bool valu fals option callabl argument queri tensorspec shape dtype string queri argument dtype nonetyp valu argument dtype bool valu true option callabl argument queri tensorspec shape dtype string queri argument dtype nonetyp valu argument dtype bool valu fals option callabl argument input tensorspec shape dtype string input argument dtype nonetyp valu argument dtype bool valu true point pass arrai sure format python code work return differ result expect import tensorflow import base googl protobuf import json format googl protobuf struct import valu import numpi googl cloud import aiplatform import vertex model save model load bucket model serv input list vertex model signatur serv default structur input signatur kei print serv input serv input aip endpoint project project locat west endpoint endpoint aiplatform endpoint aip endpoint def encod input input return base bencod arrai input decod utf instanc list serv input encod input arrai doctor instanc json format parsedict valu instanc list result endpoint predict instanc instanc print result predict output sword stone ado jumanji good get ag innoc doubl vie vroniqu doubl life veroniqu piano eat drink man woman bullet broadwai idea fix encod payload",
        "Issue_preprocessed_content":"endpoint json invalid json payload receiv train deploi tensorflow model tensorflow onlin predict output load score titl load return payload gener json payload echo submit endpoint curl post author bearer json us payload code invalid json payload receiv expect object kei statu work echo valid json lint return proper predict metagraphdef serv contain signaturedef given savedmodel signaturedef contain input given savedmodel signaturedef contain output dtype shape method given savedmodel signaturedef contain input dtype shape given savedmodel signaturedef contain output dtype shape dtype shape method concret function function option argument tensorspec argument dtype nonetyp valu argument dtype valu true option argument queri tensorspec queri argument dtype nonetyp valu argument dtype valu true option argument tensorspec argument dtype nonetyp valu argument dtype valu fals option argument queri tensorspec queri argument dtype nonetyp valu argument dtype valu fals function option argument tensorspec function option argument tensorspec argument dtype nonetyp valu argument dtype valu fals option argument queri tensorspec queri argument dtype nonetyp valu argument dtype valu true option argument queri tensorspec queri argument dtype nonetyp valu argument dtype valu fals option argument tensorspec argument dtype nonetyp valu argument dtype valu true point sure format python code work return result expect import tensorflow import base protobuf import import valu import numpi cloud import aiplatform import list print endpoint def return instanc result idea fix encod payload",
        "Issue_gpt_summary_original":"The user is encountering errors with wandb sweeps while running the astral-sweep-1 project. The error message indicates that there is a mismatch between the expected and actual data types for an argument in the code. The user has provided details of the agent's run configuration and the project's tracking and syncing status.",
        "Issue_gpt_summary":"user encount error sweep run astral sweep project error messag indic mismatch expect actual data type argument code user provid detail agent run configur project track sync statu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/GoogleCloudPlatform\/vertex-ai-samples\/issues\/349",
        "Issue_title":"ModelUploadOp from \"Vertex AI Pipelines: model upload using google-cloud-pipeline-components\"  does not work",
        "Issue_created_time":1646182369000,
        "Issue_closed_time":1646371495000,
        "Issue_body":"## Expected Behavior\r\nCode example  from \"Vertex AI Pipelines: model train, upload, and deploy using google-cloud-pipeline-components\" [1] should work as intended.\r\n\r\n## Actual Behavior\r\nCode example below from \"Vertex AI Pipelines: model train, upload, and deploy using google-cloud-pipeline-components\" [1] had issue and does not work\r\n\r\n```\r\nfrom google_cloud_pipeline_components import aiplatform as gcc_aip\r\n    from google.cloud import aiplatform\r\n    aiplatform.init(project=project, location=region)\r\n\r\n    # THIS IS THE METHOD THAT DOESN'T APPEAR TO WORK\r\n    model_upload_op = gcc_aip.ModelUploadOp(\r\n            project=project,\r\n            location=region,\r\n            display_name=model_display_name,\r\n            artifact_uri=model.uri,\r\n            serving_container_image_uri=serving_container_image_uri\r\n            )\r\n```\r\nOn the other hand, the method below worked:\r\n```\r\n # THIS METHOD DOES WORK\r\n    # aiplatform.Model.upload(\r\n    #     display_name=model_display_name,\r\n    #     artifact_uri=model.uri,\r\n    #     serving_container_image_uri=serving_container_image_uri,\r\n    # )\r\n```\r\n\r\nI'm currently using Vertex AI Pipelines to train a model and upload to Vertex AI. Currently in the pipeline, I'm attempting to use the ModelUploadOp class to upload a custom model to Vertex AI models. The logs show the job is succeeding, but the model never actually gets uploaded.\r\n\r\n## Steps to Reproduce the Problem\r\n\r\n1.\r\n1.\r\n1.\r\n\r\n## Specifications\r\n\r\nVersion: \r\n- Pipeline SDK (Kubeflow Pipelines\/TFX) Version: kfp\r\n- Pipelines Version: kfp==1.8.11\r\n- Platform: Google Cloud Vertex AI \r\n\r\n[1]: https:\/\/github.com\/GoogleCloudPlatform\/vertex-ai-samples\/blob\/main\/notebooks\/official\/pipelines\/google_cloud_pipeline_components_model_train_upload_deploy.ipynb",
        "Issue_answer_count":6,
        "Issue_self_closed":0.0,
        "Answer_body":"There was a recent breaking change. Will update notebook accordingly. Notebook has been updated, tested and merged. @andrewferlitsch can we close this issue since the notebook is merged ? yes, I will close it. I thought I had. Hi all,\r\nI saw this thread and the updated notebook - thanks for fixing it. \r\n\r\nI can't help but think that using `artifact_uri=WORKING_DIR` in the Importer Node seems misaligned with Kubeflow's focus on Artifacts and Artifact management. Is it possible to set `artifact_uri` to the Artifact location without hardcoding `WORKING_DIR`?\r\n\r\n```\r\nimport_unmanaged_model_task = importer_node.importer(\r\n        artifact_uri=WORKING_DIR,        <--- Can we set this without hardcoding WORKING_DIR?\r\n        artifact_class=artifact_types.UnmanagedContainerModel,\r\n        metadata={\r\n            \"containerSpec\": {\r\n                \"imageUri\": \"us-docker.pkg.dev\/cloud-aiplatform\/prediction\/tf2-cpu.2-3:latest\",\r\n            },\r\n        },\r\n    )\r\n```\r\n\r\nTo make things simple, let's say that instead of putting the training code in CustomTrainingJobOp, you define a custom function (below). In this case wouldn't it be more Kubeflow-ish to replace save the file to `Output[Model].path` instead of hard coding `WORKING_DIR` , like the following? \r\n\r\n```\r\ndef train_model(dataset: Input[Dataset],  model: Output[Model]):\r\n      ...\r\n\r\n       # then save model\r\n       # model.save(WORKING_DIR)   <---- This is the way outlined in the notebook\r\n       model.save(model.path)         <--- This seems more aligned with KFP than above\r\n```\r\n\r\nThen, when you wanted to upload the model, you would again replace `WORKING_DIR` with the location of the Artifact set by Kubeflow.\r\n\r\n```\r\n@kfp.dsl.pipeline(...)\r\ndef pipeline(...):\r\n        ...\r\n\r\n        # train model\r\n        train_model_op = train_model(...)\r\n\r\n        import_unmanaged_model_task = importer_node.importer(\r\n                artifact_uri=train_model_op.outputs[\"model\"].uri,         <---- USING ARTIFACT LOCATION\r\n                artifact_class=artifact_types.UnmanagedContainerModel,\r\n                metadata={\r\n                     \"containerSpec\": {\r\n                      \"imageUri\": serving_container_image_uri,\r\n                 },\r\n               },\r\n           )\r\n```\r\nBut unfortunately you can't actually do this because you get an error: \"AttributeError: 'PipelinParam' object has no attribute uri'\". To avoid this error, you could also nest the Importer Node into a custom Component that has Input[Model] as one of the parameters. Then you could set `artifact_uri=model.uri`. \r\n\r\n```\r\n@component(...)\r\ndef custom_importer(trained_model: Input[Model], vertex_model: Output[Model]):\r\n     import_unmanaged_model_task = importer_node.importer(\r\n                artifact_uri=trained_model.uri,         <---- USING ARTIFACT LOCATION\r\n                artifact_class=artifact_types.UnmanagedContainerModel,\r\n                metadata={\r\n                     \"containerSpec\": {\r\n                      \"imageUri\": serving_container_image_uri,\r\n                 },\r\n               },\r\n           )\r\n```\r\nUnfortunately, you can't do this as you get \"TypeError: There are no registered serializers for type \"google.UnmanagedContainerModel\".\" @natetsang If you want an easy way to upload models to Vertex Model Registry, you can use my components: https:\/\/github.com\/Ark-kun\/pipeline_components\/tree\/KFPv2_hell\/components\/google-cloud\/Vertex_AI\/Models \r\nExample usage: https:\/\/github.com\/Ark-kun\/pipeline_components\/blob\/05b2f255f8ccd7d8588f8143a76536bf83c2c7c7\/samples\/Google_Cloud_Vertex_AI\/Train_tabular_regression_model_using_TensorFlow_and_import_to_Vertex_AI\/pipeline.py#L51\r\n\r\n```Python\r\nupload_Tensorflow_model_to_Google_Cloud_Vertex_AI_op = components.load_component_from_url(\"https:\/\/raw.githubusercontent.com\/Ark-kun\/pipeline_components\/719783ef44c04348ea23e247a93021d91cfe602d\/components\/google-cloud\/Vertex_AI\/Models\/Upload_Tensorflow_model\/component.yaml\")\r\n\r\n...\r\n    vertex_model_name = upload_Tensorflow_model_to_Google_Cloud_Vertex_AI_op(\r\n        model=model,\r\n    ).outputs[\"model_name\"]\r\n```\r\nWhere `model` is a `TensorflowSavedModel` artifact that was produced by `model.save(model_path)`.\r\n\r\nPlease open an issue in my repo if you have any issues or feature requests for the components I've linked.",
        "Tool":"Vertex AI",
        "Platform":"Github",
        "Issue_original_content":"modeluploadop pipelin model upload googl cloud pipelin compon work expect behavior code exampl pipelin model train upload deploi googl cloud pipelin compon work intend actual behavior code exampl pipelin model train upload deploi googl cloud pipelin compon issu work googl cloud pipelin compon import aiplatform gcc aip googl cloud import aiplatform aiplatform init project project locat region method appear work model upload gcc aip modeluploadop project project locat region displai model displai artifact uri model uri serv contain imag uri serv contain imag uri hand method work method work aiplatform model upload displai model displai artifact uri model uri serv contain imag uri serv contain imag uri current pipelin train model upload current pipelin attempt us modeluploadop class upload custom model model log job succeed model actual get upload step reproduc problem specif version pipelin sdk kubeflow pipelin tfx version kfp pipelin version kfp platform googl cloud http github com googlecloudplatform vertex sampl blob main notebook offici pipelin googl cloud pipelin compon model train upload deploi ipynb",
        "Issue_preprocessed_content":"modeluploadop pipelin model upload work expect behavior code exampl pipelin model train upload deploi work intend actual behavior code exampl pipelin model train upload deploi work hand method work pipelin train model upload pipelin us modeluploadop upload custom model model log job model get upload step reproduc problem specif version pipelin sdk version kfp pipelin version platform cloud",
        "Issue_gpt_summary_original":"The user encountered a RuntimeError while training text classification models using xlnet-large-cased, albert-base-v2, xlnet-base-cased, and wandb enabled. The error occurred in the log_tensor_stats function of wandb_torch.py, where the tensor's view size was not compatible with the input tensor's size and stride. The error message suggests using .reshape() instead of .view().",
        "Issue_gpt_summary":"user encount runtimeerror train text classif model xlnet larg case albert base xlnet base case enabl error occur log tensor stat function torch tensor view size compat input tensor size stride error messag suggest reshap instead view",
        "Issue_score_count":2
    },
    {
        "Issue_link":"https:\/\/github.com\/zenml-io\/zenml\/issues\/1001",
        "Issue_title":"[BUG]: Vertex AI blogpost is outdated after 0.20.0 release",
        "Issue_created_time":1666626693000,
        "Issue_closed_time":1667472145000,
        "Issue_body":"### Contact Details [Optional]\n\nfrancogbocci@gmail.com\n\n### System Information\n\nZenML version: 0.20.5\r\nInstall path: \/Users\/f.bocci\/Library\/Caches\/pypoetry\/virtualenvs\/banana-bMSm4ime-py3.9\/lib\/python3.9\/site-packages\/zenml\r\nPython version: 3.9.6\r\nPlatform information: {'os': 'mac', 'mac_version': '10.15.7'}\r\nEnvironment: native\r\nIntegrations: ['gcp', 'graphviz', 'kubeflow', 'kubernetes', 'scipy', 'sklearn']\n\n### What happened?\n\nTrying to follow the [guide to run a pipeline using Vertex AI](https:\/\/blog.zenml.io\/vertex-ai-blog\/), it fails because ZenML does not now have a `metadata-store` stack category.\r\n\r\n```shell\r\n$ zenml\r\nStack Components:\r\n      alerter                 Commands to interact with alerters.\r\n      annotator               Commands to interact with annotators.\r\n      artifact-store          Commands to interact with artifact stores.\r\n      container-registry      Commands to interact with container registries.\r\n      data-validator          Commands to interact with data validators.\r\n      experiment-tracker      Commands to interact with experiment trackers.\r\n      feature-store           Commands to interact with feature stores.\r\n      model-deployer          Commands to interact with model deployers.\r\n      orchestrator            Commands to interact with orchestrators.\r\n      secrets-manager         Commands to interact with secrets managers.\r\n      step-operator           Commands to interact with step operators.\r\n$ zenml metadata-store\r\nError: No such command 'metadata-store'.\r\n```\n\n### Reproduction steps\n\n1. zenml metadata-store\r\n\r\nIf I don't add it and run the Vertex AI pipeline, it fails.\r\n\n\n### Relevant log output\n\n_No response_\n\n### Code of Conduct\n\n- [X] I agree to follow this project's Code of Conduct",
        "Issue_answer_count":7,
        "Issue_self_closed":0.0,
        "Answer_body":"@francobocciDH Thanks for reporting the issue. We have recently undergone a [big architectural shift](https:\/\/blog.zenml.io\/zenml-revamped\/) and therefore a lot of the blog is a bit outdated! In particular, the metadata store is no longer a required stack component.\r\n\r\nIn order to make the vertex orchestrator work, I would suggest either taking a look at the [updated docs page](https:\/\/docs.zenml.io\/component-gallery\/orchestrators\/gcloud-vertexai), or taking a look at the [migration guide](https:\/\/docs.zenml.io\/guidelines\/migration-zero-twenty) that will help you update that blog's code to  the 0.20.5 world. Hey! Thanks for the quick reply. I followed the updated docs page. I checked the post as well to see if there is something different, but following the docs I'm still getting the error\r\n```\r\nMaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8237): Max retries exceeded with url: \/api\/v1\/login (Caused by \r\nNewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f46e31ea0a0>: Failed to establish a new connection: [Errno 111] Connection refused'))\r\nConnectionError: HTTPConnectionPool(host='127.0.0.1', port=8237): Max retries exceeded with url: \/api\/v1\/login (Caused by \r\nNewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f46e31ea0a0>: Failed to establish a new connection: [Errno 111] Connection refused'))\r\n```\r\n\r\nFor what I saw following the traceback, it's something related to:\r\n`\/usr\/local\/lib\/python3.9\/site-packages\/zenml\/zen_stores\/base_zen_store.py:104`\r\nbut I haven't solved it yet.\r\n\r\nCould you follow the steps on the guide and make it work? I downloaded the image, got into the container and launch the entrypoint being used in Vertex AI:\r\n`python -m zenml.entrypoints.entrypoint --entrypoint_config_source zenml.integrations.gcp.orchestrators.vertex_entrypoint_configuration.VertexEntrypointConfiguration@zenml_0.20.5 --step_name importer --vertex_job_id test1234`\r\n\r\nAnd I got the same error. After that, I ran the ZenML Server (`zenml up`), and I got a different error (so apparently, something's missing?)\r\n\r\nThe error I'm getting now comes from `tfx` package and it's:\r\n```\r\nThe filesystem scheme 'gs:\/\/' is not available for use. For expanded filesystem scheme support, install the `tensorflow` package to enable additional filesystem plugins\r\n```\r\n\r\n I made it work locally. I had to:\r\n1) Register the `artifact-store` using GCS\r\n2) Set it as the artifact-store in the \"default\" stack\r\n3) Start zenml server\r\n\r\nShould this be done in some specific way by the user? @francobocciDH I think the main problem you are suffering from is that you have not deployed ZenML on Google before doing all this. Its our fault as I see that the Vertex orchestrator guide does not make this clear at all (only if you read the docs from the top, it does).\r\n\r\nPlease try [deploying ZenML](https:\/\/docs.zenml.io\/getting-started\/deploying-zenml) to google first. The easiest way to do it is to do:\r\n\r\n```\r\nzenml deploy\r\n```\r\n\r\nAfter you have done this, you can connect to the remote ZenML deployemnt, and re-register your stack as described in the Vertex AI docs, and then run your pipeline. It should work then! @francobocciDH Did this work out? Hey @htahir1 , yes, I deployed it and it worked. It could be clearer in the Vertex AI section of the docs, but it is clearly mentioned in other places of the documentation, so it's my fault for missing this. We can close this from my side. Let me know if there is anything I can help with \ud83d\udc4d ",
        "Tool":"Vertex AI",
        "Platform":"Github",
        "Issue_original_content":"bug blogpost outdat releas contact detail option francogbocci gmail com inform zenml version instal path user bocci librari cach pypoetri virtualenv banana bmsmime lib python site packag zenml python version platform inform mac mac version environ nativ integr gcp graphviz kubeflow kubernet scipi sklearn happen try follow guid run pipelin http blog zenml vertex blog fail zenml metadata store stack categori shell zenml stack compon alert command interact alert annot command interact annot artifact store command interact artifact store contain registri command interact contain registri data valid command interact data valid experi tracker command interact experi tracker featur store command interact featur store model deploy command interact model deploy orchestr command interact orchestr secret manag command interact secret manag step oper command interact step oper zenml metadata store error command metadata store reproduct step zenml metadata store add run pipelin fail relev log output respons code conduct agre follow project code conduct",
        "Issue_preprocessed_content":"blogpost outdat releas contact detail inform zenml version path python version platform inform environ nativ integr try fail zenml stack categori reproduct step zenml run pipelin fail relev log output code conduct project code conduct",
        "Issue_gpt_summary_original":"The user is encountering a bug where the confusion matrix appears in the w&b page without the values after running a model evaluation suite and exploring to wandb using \"to_wandb\" function. The expected behavior is for the confusion matrix in w&b to appear like the confusion matrix in the notebook which has its values shown. The user is using Linux OS, Python version 3.7.1, and Deepchecks version 0.7.2.",
        "Issue_gpt_summary":"user encount bug confus matrix appear page valu run model evalu suit explor function expect behavior confus matrix appear like confus matrix notebook valu shown user linux python version deepcheck version",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/googleapis\/nodejs-ai-platform\/issues\/453",
        "Issue_title":"vertex AI endpoint prediction error, 4 DEADLINE_EXCEEDED: Deadline exceeded",
        "Issue_created_time":1664933940000,
        "Issue_closed_time":1664935217000,
        "Issue_body":"#### Environment details\r\n\r\n  - OS: Mac M1 Pro\r\n  - Node.js version: v16.16.0\r\n  - npm version: 8.11.0\r\n  - `@google-cloud\/aiplatform` version: ^2.3.0\r\n\r\n#### Steps to reproduce\r\n\r\n  1. I've run this demo on my local computer: https:\/\/github.com\/googleapis\/nodejs-ai-platform\/blob\/main\/samples\/predict-text-classification.js\r\n  2. The process paused and shows `4 DEADLINE_EXCEEDED: Deadline exceeded` in the line: `await predictionServiceClient.predict(request);`\r\n\r\n\r\nThanks!\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"> \r\n\r\nWhen I upgrade the nodejs to v16.17.1 and add a call_option\r\n`\r\n      const call_options = {\r\n        timeout: 200000 \/\/ millis\r\n      }\r\n`\r\nproblem solved.\r\n",
        "Tool":"Vertex AI",
        "Platform":"Github",
        "Issue_original_content":"endpoint predict error deadlin exceed deadlin exceed environ detail mac pro node version npm version googl cloud aiplatform version step reproduc run demo local http github com googleapi nodej platform blob main sampl predict text classif process paus show deadlin exceed deadlin exceed line await predictionservicecli predict request thank",
        "Issue_preprocessed_content":"endpoint predict deadlin environ detail mac pro version npm version version step reproduc run demo local paus show line thank",
        "Issue_gpt_summary_original":"The user has encountered a bug where to_wandb is not sectioning by train\/test and overrides runs by checks. When running a suite with train\/test checks and duplicate checks in the suite, the expected behavior is to have sections for each dataset and be able to run a suite with a couple of checks.",
        "Issue_gpt_summary":"user encount bug section train test overrid run check run suit train test check duplic check suit expect behavior section dataset abl run suit coupl check",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/GoogleCloudPlatform\/asl-ml-immersion\/issues\/171",
        "Issue_title":"[Bug] scikit learn model feature definition doesn't work on Vertex AI Prediction.",
        "Issue_created_time":1646626569000,
        "Issue_closed_time":1648259081000,
        "Issue_body":"## Description\r\n\r\nScikit Learn model in [`kubeflow_pipelines\/pipelines` directory](https:\/\/github.com\/GoogleCloudPlatform\/asl-ml-immersion\/blob\/master\/notebooks\/kubeflow_pipelines\/pipelines\/solutions\/trainer_image\/train.py#L46) doesn't work in Vertex AI prediction environment, since it assumes the input as Pandas Dataframe and cannot handle JSON from Web API.\r\n\r\nAfter deploying the model following the labs, this issue can be reproduced with this code snippet.\r\n\r\n```python\r\nendpoint = aiplatform.Endpoint.list()[0]\r\n\r\ninstance = [{'Elevation': [2841.0]},\r\n {'Aspect': [45, 0]},\r\n {'Slope': [0, 0]},\r\n {'Horizontal_Distance_To_Hydrology': [644.0]},\r\n {'Vertical_Distance_To_Hydrology': [282.0]},\r\n {'Horizontal_Distance_To_Roadways': [1376.0]},\r\n {'Hillshade_9am': [218.0]},\r\n {'Hillshade_Noon': [237.0]},\r\n {'Hillshade_3pm': [156.0]},\r\n {'Horizontal_Distance_To_Fire_Points': [1003.0]},\r\n {'Wilderness_Area': ['Commanche']},\r\n {'Soil_Type': ['C4758']}]\r\n\r\nendpoint.predict([instance])\r\n```\r\n\r\nreturns:\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/6895245\/156965179-92e4e873-8f60-411c-86b7-df0685509e4c.png)\r\n\r\n## Approach\r\nRewrite feature definition part of `train.py` from:\r\nhttps:\/\/github.com\/GoogleCloudPlatform\/asl-ml-immersion\/blob\/e87f3514dda440fb381a78f563bda177aa38ad80\/notebooks\/kubeflow_pipelines\/cicd\/solutions\/trainer_image_vertex\/train.py#L43-L63\r\n\r\nto:\r\n```python\r\n    numeric_feature_indexes = slice(0, 10)\r\n    categorical_feature_indexes = slice(10, 12)\r\n\r\n    preprocessor = ColumnTransformer(\r\n    transformers=[\r\n        ('num', StandardScaler(), numeric_feature_indexes),\r\n        ('cat', OneHotEncoder(), categorical_feature_indexes) \r\n    ])\r\n```\r\n\r\nAnd it should run with this \r\n\r\n```python\r\nendpoint = aiplatform.Endpoint.list()[0]\r\n\r\ninstance = [\r\n    2841.0,\r\n    45.0,\r\n    0.0,\r\n    644.0,\r\n    282.0,\r\n    1376.0,\r\n    218.0,\r\n    237.0,\r\n    156.0,\r\n    1003.0,\r\n    \"Commanche\",\r\n    \"C4758\",\r\n]\r\nendpoint.predict([instance])\r\n```\r\n\r\nOutput:\r\n```\r\nPrediction(predictions=[1.0], deployed_model_id='4516996077043318784', explanations=None)\r\n```\r\n\r\n## Target Files\r\n[These 8 files ](https:\/\/github.com\/GoogleCloudPlatform\/asl-ml-immersion\/search?q=numeric_features+%3D+%5B+++++++++%22Elevation%22%2C) should be update.",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"Vertex AI",
        "Platform":"Github",
        "Issue_original_content":"bug scikit learn model featur definit work predict descript scikit learn model kubeflow pipelin pipelin directori http github com googlecloudplatform asl immers blob master notebook kubeflow pipelin pipelin solut trainer imag train work predict environ assum input panda datafram handl json web api deploi model follow lab issu reproduc code snippet python endpoint aiplatform endpoint list instanc elev aspect slope horizont distanc hydrolog vertic distanc hydrolog horizont distanc roadwai hillshad hillshad noon hillshad horizont distanc point wilder area commanch soil type endpoint predict instanc return imag http user imag githubusercont com dfec png approach rewrit featur definit train http github com googlecloudplatform asl immers blob efddafbafbdaaaad notebook kubeflow pipelin cicd solut trainer imag vertex train python numer featur index slice categor featur index slice preprocessor columntransform transform num standardscal numer featur index cat onehotencod categor featur index run python endpoint aiplatform endpoint list instanc commanch endpoint predict instanc output predict predict deploi model explan target file file http github com googlecloudplatform asl immers search numer featur elev updat",
        "Issue_preprocessed_content":"scikit learn model featur definit work predict descript scikit learn model work predict environ input panda datafram handl json web api deploi model lab reproduc code return rewrit featur definit run output target file file updat",
        "Issue_gpt_summary_original":"The user is facing an issue with Weights and Biases logging as it does not differentiate between training and testing modes while using `logbook.write_metric_log({ 'mode': 'train' ... })`.",
        "Issue_gpt_summary":"user face issu log differenti train test mode logbook write metric log mode train",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/ThilinaRajapakse\/simpletransformers\/issues\/993",
        "Issue_title":"Getting Errors with wandb sweeps ",
        "Issue_created_time":1613369681000,
        "Issue_closed_time":1623275505000,
        "Issue_body":"Synced astral-sweep-1: https:\/\/wandb.ai\/sakrah\/humorize\/runs\/peg6pn8y\r\nRun peg6pn8y errored: RuntimeError(\"Expected object of scalar type Long but got scalar type Float for argument #2 'target' in call to _thnn_nll_loss_forward\",)\r\nwandb: ERROR Run peg6pn8y errored: RuntimeError(\"Expected object of scalar type Long but got scalar type Float for argument #2 'target' in call to _thnn_nll_loss_forward\",)\r\nwandb: Agent Starting Run: e8d1m877 with config:\r\nwandb: \tlayer_0-6: 2.581652533230976e-05\r\nwandb: \tlayer_12-18: 3.584294374584665e-05\r\nwandb: \tlayer_18-24: 4.488348372658677e-05\r\nwandb: \tlayer_6-12: 1.0161197251306803e-05\r\nwandb: \tnum_train_epochs: 40\r\nwandb: \tparams_classifier.dense.bias: 0.0005874506018709628\r\nwandb: \tparams_classifier.dense.weight: 0.0003389591868569285\r\nwandb: \tparams_classifier.out_proj.bias: 0.0003078179192499977\r\nwandb: \tparams_classifier.out_proj.weight: 0.0006868779346654171\r\nTracking run with wandb version 0.10.19\r\nSyncing run peach-sweep-2 to Weights & Biases (Documentation).\r\nProject page: https:\/\/wandb.ai\/sakrah\/humorize\r\nSweep page: https:\/\/wandb.ai\/sakrah\/humorize\/sweeps\/4sl6uygs\r\nRun page: https:\/\/wandb.ai\/sakrah\/humorize\/runs\/e8d1m877\r\nRun data is saved locally in \/content\/wandb\/run-20210215_055312-e8d1m877",
        "Issue_answer_count":2,
        "Issue_self_closed":0.0,
        "Answer_body":"I got this error when I tried to run wandb sweeps for a regressionn classifcation. It complained when I included the required num_labels. After removing it, the error is what I get. Are there some additional settings required besides setting regression=True. This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.\n",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"get error sweep sync astral sweep http sakrah humor run pegpni run pegpni error runtimeerror expect object scalar type long got scalar type float argument target thnn nll loss forward error run pegpni error runtimeerror expect object scalar type long got scalar type float argument target thnn nll loss forward agent start run edm config layer layer layer layer num train epoch param classifi dens bia param classifi dens weight param classifi proj bia param classifi proj weight track run version sync run peach sweep document project page http sakrah humor sweep page http sakrah humor sweep sluyg run page http sakrah humor run edm run data save local content run edm",
        "Issue_preprocessed_content":" sync run peg run peg agent start run config track run version sync run project page page run page run data save",
        "Issue_gpt_summary_original":"The user is facing a challenge while using wandb as it shows steps instead of episodes, making it difficult to compare runs with longer durations.",
        "Issue_gpt_summary":"user face challeng show step instead episod make difficult compar run longer durat",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/ThilinaRajapakse\/simpletransformers\/issues\/287",
        "Issue_title":"wandb RuntimeError",
        "Issue_created_time":1585341922000,
        "Issue_closed_time":1591178971000,
        "Issue_body":"When training text classification models using xlnet-large-cased, albert-base-v2, xlnet-base-cased and wandb enabled:\r\n```\r\nFile \"train.py\", line 101, in <module>\r\n    rc=sklearn.metrics.recall_score)\r\n  File \"venv\/lib\/python3.7\/site-packages\/simpletransformers\/classification\/classification_model.py\", line 267, in \r\ntrain_model\r\n    **kwargs,\r\n  File \"venv\/lib\/python3.7\/site-packages\/simpletransformers\/classification\/classification_model.py\", line 374, in train\r\n    scaled_loss.backward()\r\n  File \"venv\/lib\/python3.7\/site-packages\/torch\/tensor.py\", line 195, in backward\r\n    torch.autograd.backward(self, gradient, retain_graph, create_graph)\r\n  File \"venv\/lib\/python3.7\/site-packages\/torch\/autograd\/__init__.py\", line 99, in backward\r\n    allow_unreachable=True)  # allow_unreachable flag\r\n  File \"venv\/lib\/python3.7\/site-packages\/wandb\/wandb_torch.py\", line 256, in <lambda>\r\n    handle = var.register_hook(lambda grad: _callback(grad, log_track))\r\n  File \"venv\/lib\/python3.7\/site-packages\/wandb\/wandb_torch.py\", line 254, in _callback\r\n    self.log_tensor_stats(grad.data, name)\r\n  File \"venv\/lib\/python3.7\/site-packages\/wandb\/wandb_torch.py\", line 165, in log_tensor_stats\r\n    flat = tensor.view(-1)\r\nRuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\r\n```\r\n\r\n",
        "Issue_answer_count":6,
        "Issue_self_closed":0.0,
        "Answer_body":"There does seem to be an issue with XLNet and ALBERT when using wandb. I haven't found the exact cause yet. I'll look into it again when I can. Thank you. Maybe it should be reported to wandb because it is from its `wandb.watch`?\r\nI temporarily fixed this with `wandb.watch(model, log=None)`. Does it still log the metrics when `log` is set to `None`? Yes, but without gradients. This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.\n Was able to fix it for me with `pip install --upgrade wandb`",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"runtimeerror train text classif model xlnet larg case albert base xlnet base case enabl file train line sklearn metric recal score file venv lib python site packag simpletransform classif classif model line train model kwarg file venv lib python site packag simpletransform classif classif model line train scale loss backward file venv lib python site packag torch tensor line backward torch autograd backward self gradient retain graph creat graph file venv lib python site packag torch autograd init line backward allow unreach true allow unreach flag file venv lib python site packag torch line handl var regist hook lambda grad callback grad log track file venv lib python site packag torch line callback self log tensor stat grad data file venv lib python site packag torch line log tensor stat flat tensor view runtimeerror view size compat input tensor size stride dimens span contigu subspac us reshap instead",
        "Issue_preprocessed_content":" train text model enabl",
        "Issue_gpt_summary_original":"The user is encountering errors with the Wandb callback when resuming a training run that is not starting from scratch. The error message indicates that the step must only increase in log calls, and that a step has been dropped.",
        "Issue_gpt_summary":"user encount error callback resum train run start scratch error messag indic step increas log call step drop",
        "Issue_score_count":1
    },
    {
        "Issue_link":"https:\/\/github.com\/deepchecks\/deepchecks\/issues\/1592",
        "Issue_title":"[BUG] Weird behavior with \"to_wandb\" and confusion matrix",
        "Issue_created_time":1654717842000,
        "Issue_closed_time":1657703576000,
        "Issue_body":"**Describe the bug**\r\nAfter running a model evaluation suite and exprorint to wandb using \"to_wandb\" function, the confusion matrix appears in the w&b page without the values\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n\r\n\r\n**Expected behavior**\r\nThe confusion matrix in w&b should appear like the confusion matrix in the notebook which has it values shown\r\n![1654716717893](https:\/\/user-images.githubusercontent.com\/21197955\/172704682-e1097eaa-5371-48b6-96d7-f0df1006c043.jpeg)\r\n\r\n\r\n\r\n**Environment (please complete the following information):**\r\n - OS: linux\r\n - Python Version:3.7.1\r\n - Deepchecks Version:0.7.2\r\n\r\n",
        "Issue_answer_count":4,
        "Issue_self_closed":0.0,
        "Answer_body":"Hey @DL1992,\r\n\r\nFor me the export works fine, can you provide us with some more info about what you did?\r\n\r\n![image](https:\/\/user-images.githubusercontent.com\/9868530\/173320868-74292589-5da2-4a15-9583-0855f592a602.png)\r\n hmmm, literally just result = suite.run follow by result.to_wandb.\r\nmy wandb version is 0.12.9\r\n what is the wandb and plotly version on the wandb server? This issue is stale and we couldn't reproduce it.\r\n@DL1992 feel free to reach out to us if this problem persists and we will try to help personally. Closing for now",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"bug weird behavior confus matrix bug run model evalu suit exprorint function confus matrix appear page valu reproduc step reproduc behavior expect behavior confus matrix appear like confus matrix notebook valu shown http user imag githubusercont com eeaa fdfc jpeg environ complet follow inform linux python version deepcheck version",
        "Issue_preprocessed_content":"weird behavior confus matrix bug model evalu suit exprorint function confus matrix page valu reproduc step reproduc behavior expect behavior confus matrix like confus matrix valu shown environ linux python",
        "Issue_gpt_summary_original":"The user is facing an issue where the WandB callback is changing the unique ID of the train step, but not updating the results.",
        "Issue_gpt_summary":"user face issu callback chang uniqu train step updat result",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/deepchecks\/deepchecks\/issues\/1210",
        "Issue_title":"[BUG] to_wandb not sectioning by train\/test and overrides runs by checks",
        "Issue_created_time":1649320792000,
        "Issue_closed_time":1649580744000,
        "Issue_body":"**Describe the bug**\r\n to_wandb not sectioning by train\/test and overrides runs by checks\r\n\r\n**To Reproduce**\r\nrun a suite with train\/test checks and duplicate checks in suite\r\n\r\n**Expected behavior**\r\nsections for each dataset and being able to run a suite with a couple of checks\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"Initial fix -  from 'name' to 'header', already applied in my local deepchecks environment (screenshots after that fix)\r\n\r\nSee example (note both DataDuplicates and CalibrationScore behavior):\r\n\r\nCode that ran:\r\n`custom_suite = Suite('Custom Evaluation',CalibrationScore(), CalibrationScore(),\r\n                     DataDuplicates(), DataDuplicates(columns=['Total Value']))\r\nsuite_res = custom_suite.run(train_ds, test_ds, rf_clf)\r\nsuite_res.to_wandb(project=PROJECT_NAME, entity=ENTITY_NAME, name=\"my_run\")`\r\n\r\n### Suite Result\r\n#### Calibration Metric\r\n![image](https:\/\/user-images.githubusercontent.com\/33841818\/162167715-0db6398d-4822-4e35-a886-741753982ab5.png)\r\n\r\n#### Data Duplicates - \r\n![image](https:\/\/user-images.githubusercontent.com\/33841818\/162167770-5e0450ce-a2ff-493f-8495-8779379d7a86.png)\r\n\r\n### W&B Logging - Suite Result\r\n#### Data Duplicates - appears 3 times (??)\r\n![image](https:\/\/user-images.githubusercontent.com\/33841818\/162168073-f79f6f3b-33fc-4453-8aff-4ae47652e979.png)\r\n\r\n\r\n#### Calibration Metric\r\nOnly one result (for each, after the above fix applied):\r\n![image](https:\/\/user-images.githubusercontent.com\/33841818\/162169354-b810fb42-2422-4ab5-8e5e-1bd377609fa0.png)\r\n\r\n\r\n\r\n",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"bug section train test overrid run check bug section train test overrid run check reproduc run suit train test check duplic check suit expect behavior section dataset abl run suit coupl check screenshot applic add screenshot help explain problem",
        "Issue_preprocessed_content":"section run check bug section run check reproduc run suit check duplic check suit expect behavior section dataset abl run suit coupl check help explain problem",
        "Issue_gpt_summary_original":"The user encountered an error while testing the resume argument in WandB callbacks due to the resume argument being repeated in both the global and WandB callbacks. The error may also occur with Tensorboard.",
        "Issue_gpt_summary":"user encount error test resum argument callback resum argument repeat global callback error occur tensorboard",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/shagunsodhani\/ml-logger\/issues\/25",
        "Issue_title":"[BUG] Weights & Biases logging does not differentiate between modes",
        "Issue_created_time":1583449225000,
        "Issue_closed_time":1583456108000,
        "Issue_body":"Logging using Weights and Biases does not differentiate between training and testing modes in `logbook.write_metric_log({  'mode': 'train' ... })`",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"@koustuvsinha Thanks for bringing this up. Could you try the new version?\r\n\r\nWhen constructing the logbook, pass an additional parameter:\r\n\r\n```\r\nfrom ml_logger import logbook as ml_logbook\r\nlogbook_config = ml_logbook.make_config(\r\n    logger_file_path = <path to write logs>,\r\n    wandb_config = <wandb config or None>,\r\n    wandb_prefix_key = \"mode\",\r\n)\r\n```",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"bug log differenti mode log differenti train test mode logbook write metric log mode train",
        "Issue_preprocessed_content":"mode train test mode",
        "Issue_gpt_summary_original":"The user is facing an issue with the writing of checkpoints to wandb during training. Despite starting a non-dry run via a notebook, no checkpoints are being uploaded to wandb. The expected behavior is for checkpoints to be uploaded whenever there is a better one available during training. The user is struggling to understand the symlinking model of wandb, which requires checkpoints to be under the project root, making it difficult to run multiple experiments simultaneously.",
        "Issue_gpt_summary":"user face issu write checkpoint train despit start non dry run notebook checkpoint upload expect behavior checkpoint upload better avail train user struggl understand symlink model requir checkpoint project root make difficult run multipl experi simultan",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/MathisFederico\/LearnRL\/issues\/96",
        "Issue_title":"Add episode to wandb",
        "Issue_created_time":1605623692000,
        "Issue_closed_time":1605698611000,
        "Issue_body":"When using wandb, it shows step as X and not episode.\r\n\r\nHence, longer runs have more steps and it makes the comparaison between runs difficult.\r\n\r\n\r\n![photo_2020-11-17_13-47-41](https:\/\/user-images.githubusercontent.com\/13030198\/99403033-5052e400-28ea-11eb-92c0-a3efd14b654a.jpg)\r\n\r\n",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"add episod show step episod longer run step make comparaison run difficult photo http user imag githubusercont com aefdba jpg",
        "Issue_preprocessed_content":"episod show step episod longer run step make comparaison run",
        "Issue_gpt_summary_original":"The user is facing an issue where loading configs from wandb results in incorrect HParams objects, which can be seen when attempting to load the model checkpoint or comparing the object with the info panel for the run on wandb. The user has provided a code snippet to reproduce the issue and has set acceptance criteria for the bug to be fixed.",
        "Issue_gpt_summary":"user face issu load config result incorrect hparam object seen attempt load model checkpoint compar object info panel run user provid code snippet reproduc issu set accept criteria bug fix",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/allenai\/tango\/issues\/152",
        "Issue_title":"Wandb callback prints errors when a training run resumes not from scratch",
        "Issue_created_time":1642918837000,
        "Issue_closed_time":1644017877000,
        "Issue_body":"It prints\r\n```\r\nwandb: WARNING Step must only increase in log calls.  Step 110 < 161; dropping\r\n```",
        "Issue_answer_count":9,
        "Issue_self_closed":1.0,
        "Answer_body":"This is expected. If, for example, you are checkpointing every 50 steps and your training run crashes after step 212, the last checkpoint will have been at step 200. So when you resume training, you start again from step 201, and W&B will warn you about logging duplicate steps until you get to step 213.  Why do we even try to log those earlier steps again? Wandb has an option for resuming runs. Because the W&B callback that was restored from the checkpoint at step 200 does not know that we actually got to step 212 before crashing.\r\n\r\nAnd we are using the `resume` option. Although after just rereading their docs just now, I think we should set `resume` to \"allow\" instead of \"auto\". https:\/\/github.com\/allenai\/tango\/pull\/155\r\n\r\nFrom their [docs](https:\/\/docs.wandb.ai\/ref\/python\/init):\r\n\r\n> \"auto\" (or True): if the preivous run on this machine crashed, automatically resume it. Otherwise, start a new run. - \"allow\": if id is set with init(id=\"UNIQUE_ID\") or WANDB_RUN_ID=\"UNIQUE_ID\" and it is identical to a previous run, wandb will automatically resume the run with that id. Otherwise, wandb will start a new run. \r\n\r\n\"allow\" seems a little more robust for our use case, because maybe W&B won't always know when a run crashed (resulting in the \"auto\" option not working correctly). I'm assuming that what wandb wants is to have `resume=auto`, and then the next step we input into wandb is 201. But I think what happens now is that we resume with step 201 correctly, but we tell wandb that it's step 1 (because it's the first step we're actually running). > but we tell wandb that it's step 1\r\n\r\nNo, we tell W&B that it's step 201. W&B complains for the next 12 steps until we get to step 213. Ah, interesting. The documentation also says that new values will overwrite the old ones (which would be the right behavior), but the warning message clearly says it's dropping the new information. We could probably suppress those warnings though Is there a way we can make it actually overwrite the values? As it is, the values in the gap will be wrong (or at least might be wrong, if there is any non-determinism). > Is there a way we can make it actually overwrite the values?\r\n\r\nI don't think so \ud83d\ude15",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"callback print error train run resum scratch print warn step increas log call step drop",
        "Issue_preprocessed_content":"print train run resum scratch print",
        "Issue_gpt_summary_original":"The user suggests that the `config` parameter in WandBLogger should be more flexible to allow passing configurations directly as a dictionary, instead of being restricted to `args.namespace` type. The user proposes that the conversion should be done outside the logger to make it more general in terms of config input.",
        "Issue_gpt_summary":"user suggest config paramet logger flexibl allow pass configur directli dictionari instead restrict arg namespac type user propos convers outsid logger gener term config input",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/allenai\/tango\/issues\/151",
        "Issue_title":"WandB callback changes the train step's unique ID, but does not change the results",
        "Issue_created_time":1642916994000,
        "Issue_closed_time":1652740320000,
        "Issue_body":"",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"Actually, callbacks can change the result. So we'll close this.",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"callback chang train step uniqu chang result ",
        "Issue_preprocessed_content":"chang train step uniqu chang result ",
        "Issue_gpt_summary_original":"The user is experiencing issues with the `WandbFileSystem.ls` function when trying to access nested directories.",
        "Issue_gpt_summary":"user experienc issu filesystem function try access nest directori",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/kaylode\/theseus\/issues\/33",
        "Issue_title":"Resume error in WandB.",
        "Issue_created_time":1649286157000,
        "Issue_closed_time":1649731891000,
        "Issue_body":"Forgot to create an issue in recent days.\r\nWhen tested with ```resume``` argument in ```WandBCallbacks```, i encountered this error. Here's the log:\r\n```python\r\n\r\n[Errno 2] No such file or directory: 'main'\r\n\/content\/main\r\n2022-04-04 12:21:56 | DEBUG    | opt.py:override:78 - Overriding configuration...\r\n2022-04-04 12:21:56 | INFO     | classification\/pipeline.py:__init__:51 - {\r\n    \"global\": {\r\n        \"exp_name\": null,\r\n        \"exist_ok\": false,\r\n        \"debug\": true,\r\n        \"cfg_transform\": \"configs\/classification\/transform.yaml\",\r\n        \"save_dir\": \"\/content\/main\/runs\",\r\n        \"device\": \"cuda:0\",\r\n        \"use_fp16\": true,\r\n        \"pretrained\": null,\r\n        \"resume\": null\r\n    },\r\n    \"trainer\": {\r\n        \"name\": \"SupervisedTrainer\",\r\n        \"args\": {\r\n            \"num_iterations\": 2000,\r\n            \"clip_grad\": 10.0,\r\n            \"evaluate_interval\": 1,\r\n            \"print_interval\": 20,\r\n            \"save_interval\": 500\r\n        }\r\n    },\r\n    \"model\": {\r\n        \"name\": \"BaseTimmModel\",\r\n        \"args\": {\r\n            \"name\": \"convnext_tiny\",\r\n            \"from_pretrained\": true,\r\n            \"num_classes\": 180\r\n        }\r\n    },\r\n    \"loss\": {\r\n        \"name\": \"FocalLoss\"\r\n    },\r\n    \"callbacks\": [\r\n        {\r\n            \"name\": \"LoggerCallbacks\",\r\n            \"args\": null\r\n        },\r\n        {\r\n            \"name\": \"CheckpointCallbacks\",\r\n            \"args\": {\r\n                \"best_key\": \"bl_acc\"\r\n            }\r\n        },\r\n        {\r\n            \"name\": \"VisualizerCallbacks\",\r\n            \"args\": null\r\n        },\r\n        {\r\n            \"name\": \"TensorboardCallbacks\",\r\n            \"args\": null\r\n        },\r\n        {\r\n            \"name\": \"WandbCallbacks\",\r\n            \"args\": {\r\n                \"username\": \"lannguyen\",\r\n                \"project_name\": \"theseus_classification\",\r\n                \"resume\": true\r\n            }\r\n        }\r\n    ],\r\n    \"metrics\": [\r\n        {\r\n            \"name\": \"Accuracy\",\r\n            \"args\": null\r\n        },\r\n        {\r\n            \"name\": \"BalancedAccuracyMetric\",\r\n            \"args\": null\r\n        },\r\n        {\r\n            \"name\": \"F1ScoreMetric\",\r\n            \"args\": {\r\n                \"average\": \"weighted\"\r\n            }\r\n        },\r\n        {\r\n            \"name\": \"ConfusionMatrix\",\r\n            \"args\": null\r\n        },\r\n        {\r\n            \"name\": \"ErrorCases\",\r\n            \"args\": null\r\n        }\r\n    ],\r\n    \"optimizer\": {\r\n        \"name\": \"AdamW\",\r\n        \"args\": {\r\n            \"lr\": 0.001,\r\n            \"weight_decay\": 0.0005,\r\n            \"betas\": [\r\n                0.937,\r\n                0.999\r\n            ]\r\n        }\r\n    },\r\n    \"scheduler\": {\r\n        \"name\": \"SchedulerWrapper\",\r\n        \"args\": {\r\n            \"scheduler_name\": \"cosine2\",\r\n            \"t_initial\": 7,\r\n            \"t_mul\": 0.9,\r\n            \"eta_mul\": 0.9,\r\n            \"eta_min\": 1e-06\r\n        }\r\n    },\r\n    \"data\": {\r\n        \"dataset\": {\r\n            \"train\": {\r\n                \"name\": \"ImageFolderDataset\",\r\n                \"args\": {\r\n                    \"image_dir\": \"\/content\/main\/data\/food-classification\/train\",\r\n                    \"txt_classnames\": \"configs\/classification\/classes.txt\"\r\n                }\r\n            },\r\n            \"val\": {\r\n                \"name\": \"ImageFolderDataset\",\r\n                \"args\": {\r\n                    \"image_dir\": \"\/content\/main\/data\/food-classification\/val\",\r\n                    \"txt_classnames\": \"configs\/classification\/classes.txt\"\r\n                }\r\n            }\r\n        },\r\n        \"dataloader\": {\r\n            \"train\": {\r\n                \"name\": \"DataLoaderWithCollator\",\r\n                \"args\": {\r\n                    \"batch_size\": 32,\r\n                    \"drop_last\": true,\r\n                    \"shuffle\": false,\r\n                    \"collate_fn\": {\r\n                        \"name\": \"MixupCutmixCollator\",\r\n                        \"args\": {\r\n                            \"mixup_alpha\": 0.4,\r\n                            \"cutmix_alpha\": 1.0,\r\n                            \"weight\": [\r\n                                0.2,\r\n                                0.2\r\n                            ]\r\n                        }\r\n                    },\r\n                    \"sampler\": {\r\n                        \"name\": \"BalanceSampler\",\r\n                        \"args\": null\r\n                    }\r\n                }\r\n            },\r\n            \"val\": {\r\n                \"name\": \"DataLoaderWithCollator\",\r\n                \"args\": {\r\n                    \"batch_size\": 32,\r\n                    \"drop_last\": false,\r\n                    \"shuffle\": true\r\n                }\r\n            }\r\n        }\r\n    }\r\n}\r\n2022-04-04 12:21:56 | DEBUG    | opt.py:load_yaml:36 - Loading config from configs\/classification\/transform.yaml...\r\n2022-04-04 12:21:57 | DEBUG    | classification\/datasets\/folder_dataset.py:_calculate_classes_dist:71 - Calculating class distribution...\r\nDownloading: \"https:\/\/dl.fbaipublicfiles.com\/convnext\/convnext_tiny_1k_224_ema.pth\" to \/root\/.cache\/torch\/hub\/checkpoints\/convnext_tiny_1k_224_ema.pth\r\nTraceback (most recent call last):\r\n  File \"\/content\/main\/configs\/classification\/train.py\", line 9, in <module>\r\n    train_pipeline = Pipeline(opts)\r\n  File \"\/content\/main\/theseus\/classification\/pipeline.py\", line 159, in __init__\r\n    registry=CALLBACKS_REGISTRY\r\n  File \"\/content\/main\/theseus\/utilities\/getter.py\", line 15, in get_instance_recursively\r\n    out = [get_instance_recursively(item, registry=registry, **kwargs) for item in config]\r\n  File \"\/content\/main\/theseus\/utilities\/getter.py\", line 15, in <listcomp>\r\n    out = [get_instance_recursively(item, registry=registry, **kwargs) for item in config]\r\n  File \"\/content\/main\/theseus\/utilities\/getter.py\", line 26, in get_instance_recursively\r\n    return registry.get(config['name'])(**args, **kwargs)\r\nTypeError: type object got multiple values for keyword argument 'resume'\r\n```\r\n\r\nI guess because of the ```resume``` arg is both repeated in ```global``` and ```WandBCallbacks```. Maybe it also happens with ```Tensorboard```.",
        "Issue_answer_count":2,
        "Issue_self_closed":0.0,
        "Answer_body":"I will look into this soon. Crazily busy at the moment. This is not a bug, this happended because WandbCallbacks were used in the wrong way\r\n\r\nIn `pipeline.yaml`\r\n```python\r\n\"name\": \"WandbCallbacks\",\r\n\"args\": {\r\n    \"username\": \"lannguyen\",\r\n    \"project_name\": \"theseus_classification\",\r\n    \"resume\": true # <----- you didnt have to specify this\r\n}\r\n```\r\n\r\nThe repo havent been fully-well documented therefore it will be confusing sometimes.",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"resum error forgot creat issu recent dai test resum argument callback encount error log python errno file directori main content main debug opt overrid overrid configur info classif pipelin init global exp null exist fals debug true cfg transform config classif transform yaml save dir content main run devic cuda us true pretrain null resum null trainer supervisedtrain arg num iter clip grad evalu interv print interv save interv model basetimmmodel arg convnext tini pretrain true num class loss focalloss callback loggercallback arg null checkpointcallback arg best kei acc visualizercallback arg null tensorboardcallback arg null callback arg usernam lannguyen project theseu classif resum true metric accuraci arg null balancedaccuracymetr arg null fscoremetr arg averag weight confusionmatrix arg null errorcas arg null optim adamw arg weight decai beta schedul schedulerwrapp arg schedul cosin initi mul eta mul eta min data dataset train imagefolderdataset arg imag dir content main data food classif train txt classnam config classif class txt val imagefolderdataset arg imag dir content main data food classif val txt classnam config classif class txt dataload train dataloaderwithcol arg batch size drop true shuffl fals collat mixupcutmixcol arg mixup alpha cutmix alpha weight sampler balancesampl arg null val dataloaderwithcol arg batch size drop fals shuffl true debug opt load yaml load config config classif transform yaml debug classif dataset folder dataset calcul class dist calcul class distribut download http fbaipublicfil com convnext convnext tini ema pth root cach torch hub checkpoint convnext tini ema pth traceback recent file content main config classif train line train pipelin pipelin opt file content main theseu classif pipelin line init registri callback registri file content main theseu util getter line instanc recurs instanc recurs item registri registri kwarg item config file content main theseu util getter line instanc recurs item registri registri kwarg item config file content main theseu util getter line instanc recurs return registri config arg kwarg typeerror type object got multipl valu keyword argument resum guess resum arg repeat global callback mayb happen tensorboard",
        "Issue_preprocessed_content":"resum forgot creat recent dai test argument encount log arg repeat mayb",
        "Issue_gpt_summary_original":"The user is encountering an error while trying to create an index name using wandb and is looking for a solution to modify the name to \"modelname + save_folder_name\".",
        "Issue_gpt_summary":"user encount error try creat index look solut modifi modelnam save folder",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/feldberlin\/wavenet\/issues\/9",
        "Issue_title":"Fix writing of checkpoints to wandb",
        "Issue_created_time":1624867819000,
        "Issue_closed_time":1624957138000,
        "Issue_body":"## What\r\n\r\nA clear and concise description of what the bug is.\r\n\r\n## How to reproduce\r\n\r\nReproduce by starting a non-dry run via a notebook\r\n\r\n1. Start the run\r\n2. Look at files on the wandb interface. There are no checkpoints\r\n\r\n## Expected\r\n\r\nCheckpoints should be uploaded to wandb whenever there is a better one available during training.\r\n\r\n## Additional context\r\n\r\nI thought I fixed wandb, but it seems that I don't understand the symlinking model of wandb. Apparently you need to have checkpoints under the project root? But this would mean that you can't run multiple experiements at the same time. ",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"Fixed. See https:\/\/github.com\/feldberlin\/wavenet\/commit\/1125dcc5ce5004386160f3dfe0e1d1dc1e5aed98.",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"fix write checkpoint clear concis descript bug reproduc reproduc start non dry run notebook start run look file interfac checkpoint expect checkpoint upload better avail train addit context thought fix understand symlink model appar need checkpoint project root mean run multipl experi time",
        "Issue_preprocessed_content":"fix write checkpoint clear concis descript bug reproduc reproduc start run start run file interfac checkpoint expect checkpoint upload avail train context thought fix understand symlink model checkpoint project mean run multipl experi time",
        "Issue_gpt_summary_original":"The user is facing an issue with Wandb sweep on their primary notebook as it stalls after the first part of the sweep completes, causing problems.",
        "Issue_gpt_summary":"user face issu sweep primari notebook stall sweep complet caus problem",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/feldberlin\/wavenet\/issues\/5",
        "Issue_title":"Loading configs from wandb yields incorrect parameters",
        "Issue_created_time":1624097966000,
        "Issue_closed_time":1624287268000,
        "Issue_body":"## What\r\n\r\nWhen loading configs from wandb, the resulting HParams objects are not correct. This can be seen when attempting to load the model checkpoint with the given parameters (failure), or when comparing the object with the info panel for the run on wandb.\r\n\r\n## How to Reproduce\r\n\r\nLoad the configs:\r\n\r\n```python\r\nfrom wavenet import utils, model, train\r\n\r\nrun_path = 'purzelrakete\/feldberlin-wavenet\/21ei0tqc'\r\np, ptrain = utils.load_wandb_cfg(run_path)\r\np, ptrain = model.HParams(**p), train.HParams(**ptrain)\r\n```\r\n\r\nValidate against the run [on wandb](https:\/\/wandb.ai\/purzelrakete\/feldberlin-wavenet\/runs\/21ei0tqc\/overview?workspace=user-purzelrakete)\r\n\r\n## Acceptance Criteria\r\n\r\n- [x] Bug has been understood and fixed\r\n- [x] The same config given above can be loaded and is correct",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"load config yield incorrect paramet load config result hparam object correct seen attempt load model checkpoint given paramet failur compar object info panel run reproduc load config python wavenet import util model train run path purzelraket feldberlin wavenet eitqc ptrain util load cfg run path ptrain model hparam train hparam ptrain valid run http purzelraket feldberlin wavenet run eitqc overview workspac user purzelraket accept criteria bug understood fix config given load correct",
        "Issue_preprocessed_content":"load config yield paramet load config result hparam object load model checkpoint given paramet compar object info panel run reproduc load config valid run criteria bug fix config given load",
        "Issue_gpt_summary_original":"The user has encountered a bug with Wandb while running a code from a colab notebook. Wandb views the entire thing as one training session and continues gradient steps indefinitely, instead of ending the training session when the model stops training. The user expected only 28 training steps, but it continued for 80 steps.",
        "Issue_gpt_summary":"user encount bug run code colab notebook view entir thing train session continu gradient step indefinit instead end train session model stop train user expect train step continu step",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/ContinualAI\/avalanche\/issues\/797",
        "Issue_title":"Config type in WandBLogger",
        "Issue_created_time":1635882064000,
        "Issue_closed_time":1635948747000,
        "Issue_body":"This is more like a suggestion than a bug. The `config` parameter to the WandBLogger is supposed to be of type `args.namespace`. Therefore it converts it to a dictionary inside its `arge_parse` function using `vars(.)`. This might be restrictive in some cases if someone wants to pass configs directly as a dictionary (for example when hyperparameters are loaded from a YAML file). Wouldn't it be better to do the conversion outside the logger to make it more general in terms of config input?\r\n\r\nThanks :)",
        "Issue_answer_count":2,
        "Issue_self_closed":0.0,
        "Answer_body":"I agree, we can easily add support for plain dictionary. @digantamisra98 are you still working on the logger right? Can you take care of this? I've made a simple fix to it by removing the conversion inside WandBLogger. It works with plain dictionaries now. I also made a PR just in case.",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"config type logger like suggest bug config paramet logger suppos type arg namespac convert dictionari insid arg pars function var restrict case want pass config directli dictionari exampl hyperparamet load yaml file wouldn better convers outsid logger gener term config input thank",
        "Issue_preprocessed_content":"config type like bug paramet type convert dictionari insid function restrict case want config directli dictionari wouldn convers outsid gener term config input thank",
        "Issue_gpt_summary_original":"The user is facing a bug where the wandb value is not updating, except for the learning rate (lr). The issue seems to be caused by mistakenly indexing a continuously updating list with list[0].",
        "Issue_gpt_summary":"user face bug valu updat learn rate issu caus mistakenli index continu updat list list",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/alvarobartt\/wandbfsspec\/issues\/7",
        "Issue_title":"`WandbFileSystem.ls` not working fine with nested directories",
        "Issue_created_time":1658474901000,
        "Issue_closed_time":1658480572000,
        "Issue_body":"https:\/\/wandb.ai\/alvarobartt\/resnet-pytorch\/runs\/39mhvmwp\/files\/this\/is\/just\/for\/testing",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"filesystem work fine nest directori http alvarobartt resnet pytorch run mhvmwp file test",
        "Issue_preprocessed_content":"work fine nest directori ",
        "Issue_gpt_summary_original":"The user encountered an issue where the test set metrics overwrite the validation set metrics in TensorBoard and are rejected for logging by Weights and Biases (W&B). This results in TensorBoard deleting all the validation metrics, overwriting them with the test loss and perplexity values. W&B refuses to add the test metrics to the charts at all, throwing a warning. The proposed solution is to write test loss and perplexity to their own charts.",
        "Issue_gpt_summary":"user encount issu test set metric overwrit valid set metric tensorboard reject log result tensorboard delet valid metric overwrit test loss perplex valu refus add test metric chart throw warn propos solut write test loss perplex chart",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/boostcampaitech2\/semantic-segmentation-level2-cv-02\/issues\/21",
        "Issue_title":"wandb create index name error",
        "Issue_created_time":1634804027000,
        "Issue_closed_time":1635155013000,
        "Issue_body":"- [x] wandb index name modify\r\n\r\nwandb create index name error and  change name to \"modelname + save_folder_name\"",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"creat index error index modifi creat index error chang modelnam save folder",
        "Issue_preprocessed_content":"creat index index modifi creat index chang modelnam",
        "Issue_gpt_summary_original":"The user is facing an issue with local wandb logging as it assumes the presence of an API key, which is not required for running wandb locally. The user suggests configuring it to work with wandb locally as well.",
        "Issue_gpt_summary":"user face issu local log assum presenc api kei requir run local user suggest configur work local",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/AIStream-Peelout\/flow-forecast\/issues\/162",
        "Issue_title":"Weird memory problem with sweeps Colab Wandb",
        "Issue_created_time":1600976683000,
        "Issue_closed_time":null,
        "Issue_body":"```Problem Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling backward the first time.``` I'm running into this issue with a specific model (e.g. DA-RNN w\/meta-data sweep). If runs truly aren't cleared then sweeps could be corrupting subsequent runs. This behavior hasn't been observed previously however.",
        "Issue_answer_count":2,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"weird memori problem sweep colab problem try backward graph second time save intermedi result freed specifi retain graph true call backward time run issu specif model rnn meta data sweep run truli aren clear sweep corrupt subsequ run behavior hasn observ previous",
        "Issue_preprocessed_content":"weird memori problem colab specif model run truli aren clear subsequ run behavior hasn observ previous",
        "Issue_gpt_summary_original":"The user has encountered an issue with the IceNet version 0.2.0.dev10 where the wandb entity is hardcoded in the `icenet\/model\/train.py` file. The user suggests making it default to $USER, ICENET_WANDB_USER, or be overridden by command line and doing the same for the project.",
        "Issue_gpt_summary":"user encount issu icenet version dev entiti hardcod icenet model train file user suggest make default user icenet user overridden command line project",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/AIStream-Peelout\/flow-forecast\/issues\/154",
        "Issue_title":"Wandb Run stalling",
        "Issue_created_time":1600217910000,
        "Issue_closed_time":1600665871000,
        "Issue_body":"Wandb sweep on our [primary notebook don't](https:\/\/colab.research.google.com\/drive\/1vl6tgH78bNb9A5JP6NcfFHB189TIjy5c#scrollTo=sTDGweZ0d0QP) advance instead they just stall after the first part of the sweep completes. This is causing problems.",
        "Issue_answer_count":3,
        "Issue_self_closed":1.0,
        "Answer_body":"So this appears to be a problem on the Weights and Biases end of things. https:\/\/github.com\/wandb\/client\/issues\/1243 This is fixed see original issue.",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"run stall sweep primari notebook http colab research googl com drive vltghbnbajpncffhbtijyc scrollto stdgwezdqp advanc instead stall sweep complet caus problem",
        "Issue_preprocessed_content":"run advanc instead complet caus problem",
        "Issue_gpt_summary_original":"The user needs to remove the `data\/MNIST` subdirectory from their repo's history as it slipped through `.gitignore`. They plan to use an open-source tool called `bfg` for this purpose and will delete their local clones and clone a fresh, cleaned version from upstream after committing all local changes.",
        "Issue_gpt_summary":"user need remov data mnist subdirectori repo histori slip gitignor plan us open sourc tool call bfg purpos delet local clone clone fresh clean version upstream commit local chang",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/AIStream-Peelout\/flow-forecast\/issues\/35",
        "Issue_title":"Wandb bug when running train long",
        "Issue_created_time":1578034238000,
        "Issue_closed_time":1578199794000,
        "Issue_body":"When running this code https:\/\/github.com\/AIStream-Peelout\/flow-forecast\/commit\/1f67ac4844859e5d60a0f5dba2dbbe8f4c5dbc30 from a colab notebook Wandb views the entire thing as one training session and continue gradient steps indefinitely. Training session should be forced to end when that model stops training not when the meta training loop finishes. Should only be 28 training steps not 80.\r\n<img width=\"1094\" alt=\"image\" src=\"https:\/\/user-images.githubusercontent.com\/3865062\/71710653-65567f80-2dcb-11ea-8558-0f3280c4ab7b.png\">\r\n",
        "Issue_answer_count":3,
        "Issue_self_closed":1.0,
        "Answer_body":"Currently working on this should be fixed. Just need to test it So it seems to not be doing steps anymore on the same model run chart, but the runs are still not terminating until the loop ends. Don't really know if this is a problem or not. Going to close this for now Wandb supports up to 50 concurrent runs. So as long as aren't training on more than 50 rivers at a time this shouldn't be an issue. If it becomes one will revert to the subprocess thing but don't want otherwise as with that it doesn't log debugging. ",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"bug run train long run code http github com aistream peelout flow forecast commit facedafdbadbbefcdbc colab notebook view entir thing train session continu gradient step indefinit train session forc end model stop train meta train loop finish train step",
        "Issue_preprocessed_content":"bug train long code colab view entir thing train continu gradient step indefinit train forc end model stop train meta train finish train step img width alt imag",
        "Issue_gpt_summary_original":"The user encountered an issue while uploading a golden test dataset to Wandb. They changed the structure of the existing dataset to train\/validation but renamed the file from \"training\" to \"train\", which did not apply correctly in Wisdomify. As a result, the data did not load, and the user needs to change the file name to \"train.tsv\" in the data loading section.",
        "Issue_gpt_summary":"user encount issu upload golden test dataset chang structur exist dataset train valid renam file train train appli correctli wisdomifi result data load user need chang file train tsv data load section",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/pstage-ocr-team6\/ocr-teamcode\/issues\/5",
        "Issue_title":"[BUG] wandb value doesn't update",
        "Issue_created_time":1622372396000,
        "Issue_closed_time":1622440667000,
        "Issue_body":"![image](https:\/\/user-images.githubusercontent.com\/37505775\/120101493-4f481c80-c181-11eb-8a20-4a044c2bd51c.png)\r\n\r\n- lr\uc744 \uc81c\uc678\ud558\uace0 \ub098\uba38\uc9c0 value\uac00 \uc5c5\ub370\uc774\ud2b8\uac00 \ub418\uc9c0 \uc54a\ub294 \ubb38\uc81c \ubc1c\uc0dd\r\n- \uacc4\uc18d \uac12\uc774 \ucd94\uac00\ub418\ub294 \ub9ac\uc2a4\ud2b8\uc778 \uc904 \ubaa8\ub974\uace0 list[0]\uc73c\ub85c \uc778\ub371\uc2f1\ud574\uc11c \ubc1c\uc0dd\ud558\ub294 \ubb38\uc81c\ub77c\uace0 \uc0dd\uac01\ub428",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"![image](https:\/\/user-images.githubusercontent.com\/26226101\/120102333-71439e00-c185-11eb-8a20-b113112b0b3f.png)\r\n\r\n\uc544\uc774\uac70 \uc65c \uadf8\ub7f0\uac8c \ud588\ub124\uc694.... \uc218\uc815\ud574 \uc8fc\uc154\uc11c \uac10\uc0ac\ud569\ub2c8\ub2e4!",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"bug valu updat imag http user imag githubusercont com acbdc png valu list",
        "Issue_preprocessed_content":"valu updat valu list",
        "Issue_gpt_summary_original":"The user is encountering an issue with importing wandb due to a module not being found on a server running centOS, specifically the 'six.moves.collections_abc' module. The issue cannot be reproduced on a local Intel i7 system.",
        "Issue_gpt_summary":"user encount issu import modul server run cento specif move collect abc modul issu reproduc local intel",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/EleutherAI\/gpt-neox\/issues\/669",
        "Issue_title":"Test set metrics overwrite validation set metrics in TensorBoard and are rejected for logging by Weights and Biases (W&B)",
        "Issue_created_time":1663015846000,
        "Issue_closed_time":1663248037000,
        "Issue_body":"**Describe the bug**\r\n\r\nAt model train completion, the test set loss is written as iteration 0 to the TensorBoard \/ W&B chart `validation\/lm_loss`, and the test set perplexity is written as iteration 0 to the chart `validation\/lm_loss_ppl`. As the validation loss and perplexity has already been written to this chart, this results in TensorBoard deleting all the validation metrics, overwriting them with the test loss and perplexity values. W&B refuses to add the test metrics to the charts at all, throwing a warning that looks like `wandb: WARNING Step must only increase in log calls.  Step 0 < 32000; dropping {'validation\/lm_loss': 1.715476632118225}.`\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Pip install and setup TensorBoard and W&B\r\n2. Begin training a model with a train, validation, and test set\r\n3. Observe in both TensorBoard and W&B that validation metrics are being logged\r\n4. Allow the model to train to completion\r\n5. Observe that the TensorBoard validation metrics are now gone, overwritten by the test set metrics\r\n6. Observe the W&B error in the text logs \/ program output\r\n\r\n**Expected behavior**\r\nTest metrics should be written to their own charts.\r\n\r\n**Proposed solution**\r\nTest loss and perplexity should be written to their own charts `test\/lm_loss` and `test\/lm_loss_ppl` respectively.\r\n\r\n**Screenshots**\r\n![image](https:\/\/user-images.githubusercontent.com\/6119143\/189752970-3b26dd14-475f-48cb-be84-fae23a99ba10.png)\r\n\r\n**Environment (please complete the following information):**\r\n - GPUs: 4x A100 80 GB\r\n- Configs: (configs that I used to reproduce the bug and test bug fixes are included below)\r\n\r\n```\r\n# GPT-2 pretraining setup\r\n{\r\n   # parallelism settings ( you will want to change these based on your cluster setup, ideally scheduling pipeline stages\r\n   # across the node boundaries )\r\n   \"pipe-parallel-size\": 1,\r\n   \"model-parallel-size\": 1,\r\n\r\n   # model settings\r\n   \"num-layers\": 24,\r\n   \"hidden-size\": 1024,\r\n   \"num-attention-heads\": 16,\r\n   \"seq-length\": 4096,\r\n   \"max-position-embeddings\": 4096,\r\n   \"norm\": \"layernorm\",\r\n   \"pos-emb\": \"rotary\",\r\n   \"no-weight-tying\": true,\r\n\r\n   # these should provide some speedup but takes a while to build, set to true if desired\r\n   \"scaled-upper-triang-masked-softmax-fusion\": false,\r\n   \"bias-gelu-fusion\": false,\r\n\r\n\r\n\r\n   # optimizer settings\r\n   \"optimizer\": {\r\n     \"type\": \"Adam\",\r\n     \"params\": {\r\n       \"lr\": 0.00003,\r\n       \"betas\": [0.9, 0.999],\r\n       \"eps\": 1.0e-8,\r\n     }\r\n   },\r\n   \"zero_optimization\": {\r\n    \"stage\": 1,\r\n    \"allgather_partitions\": True,\r\n    \"allgather_bucket_size\": 500000000,\r\n    \"overlap_comm\": True,\r\n    \"reduce_scatter\": True,\r\n    \"reduce_bucket_size\": 500000000,\r\n    \"contiguous_gradients\": True,\r\n    \"cpu_offload\": False\r\n  },\r\n   # batch \/ data settings\r\n   \"train_micro_batch_size_per_gpu\": 16,\r\n   \"data-impl\": \"mmap\",\r\n   \"split\": \"949,50,1\",\r\n\r\n   # activation checkpointing\r\n   \"checkpoint-activations\": true,\r\n   \"checkpoint-num-layers\": 1,\r\n   \"partition-activations\": true,\r\n   \"synchronize-each-layer\": true,\r\n\r\n   # regularization\r\n   \"gradient_clipping\": 1.0,\r\n   \"weight-decay\": 0.01,\r\n   \"hidden-dropout\": 0,\r\n   \"attention-dropout\": 0,\r\n\r\n   # precision settings\r\n   \"fp16\": {\r\n     \"fp16\": true,\r\n     \"enabled\": true,\r\n     \"loss_scale\": 0,\r\n     \"loss_scale_window\": 1000,\r\n     \"hysteresis\": 2,\r\n     \"min_loss_scale\": 1\r\n   },\r\n\r\n   # misc. training settings\r\n   \"train-iters\": 100,\r\n   \"lr-decay-iters\": 100,\r\n   \"distributed-backend\": \"nccl\",\r\n   \"lr-decay-style\": \"constant\",\r\n   \"warmup\": 0.1,\r\n   \"save-interval\": 25,\r\n   \"eval-interval\": 25,\r\n   \"eval-iters\": 10,\r\n\r\n   # Checkpoint\r\n   \"finetune\": true,\r\n\r\n   # logging\r\n   \"log-interval\": 10,\r\n   \"steps_per_print\": 10,\r\n   \"keep-last-n-checkpoints\": 4,\r\n   \"wall_clock_breakdown\": true,\r\n}\r\n```\r\n\r\n```\r\n# Suggested data paths when using GPT-NeoX locally\r\n{\r\n  \"train-data-paths\": [\"\/mnt\/4TBNVME\/gpt-neox\/data\/preprocessed\/train_text_document\"],\r\n  \"test-data-paths\": [\"\/mnt\/4TBNVME\/gpt-neox\/data\/preprocessed\/test_text_document\"],\r\n  \"valid-data-paths\": [\"\/mnt\/4TBNVME\/gpt-neox\/data\/preprocessed\/val_text_document\"],\r\n\r\n  \"vocab-file\": \"\/mnt\/4TBNVME\/gpt-neox\/data\/gpt2-vocab.json\",\r\n  \"merge-file\": \"\/mnt\/4TBNVME\/gpt-neox\/data\/gpt2-merges.txt\",\r\n\r\n  \"save\": \"\/mnt\/4TBNVME\/checkpoints_test\",\r\n  \"load\": \"\/mnt\/4TBNVME\/checkpoints_test\",\r\n\r\n  \"checkpoint_validation_with_forward_pass\": False,\r\n  \r\n  \"tensorboard-dir\": \"\/mnt\/4TBNVME\/logs\/tensorboard\/bug_fix_test\",\r\n  \"log-dir\": \"\/mnt\/4TBNVME\/logs\/gptneox\/bug_fix_test\",\r\n\r\n  \"use_wandb\": True,\r\n  \"wandb_host\": \"https:\/\/api.wandb.ai\",\r\n  \"wandb_project\": \"neox_test\"\r\n}\r\n```\r\n\r\n```\r\n# Add this to your config for sparse attention every other layer\r\n{\r\n  \"attention_config\": [[[\"local\", \"global\"], \"all\"]],\r\n\r\n  # sparsity config:\r\n  # (these are the defaults for local sliding window sparsity, training will work without this here, but it's left in for\r\n  # illustrative purposes)\r\n  # see https:\/\/www.deepspeed.ai\/tutorials\/sparse-attention\/#how-to-config-sparsity-structures for\r\n  # more detailed config instructions and available parameters\r\n\r\n  \"sparsity_config\": {\r\n    \"block\": 16, # block size\r\n    \"num_local_blocks\": 32,\r\n  }\r\n}\r\n```\r\n\r\n**Additional context**\r\n\r\nI have a bug fix ready, will follow up with it.",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"test set metric overwrit valid set metric tensorboard reject log bug model train complet test set loss written iter tensorboard chart valid loss test set perplex written iter chart valid loss ppl valid loss perplex written chart result tensorboard delet valid metric overwrit test loss perplex valu refus add test metric chart throw warn look like warn step increas log call step drop valid loss reproduc step reproduc behavior pip instal setup tensorboard begin train model train valid test set observ tensorboard valid metric log allow model train complet observ tensorboard valid metric gone overwritten test set metric observ error text log program output expect behavior test metric written chart propos solut test loss perplex written chart test loss test loss ppl respect screenshot imag http user imag githubusercont com bdd faeaba png environ complet follow inform gpu config config reproduc bug test bug fix includ gpt pretrain setup parallel set want chang base cluster setup ideal schedul pipelin stage node boundari pipe parallel size model parallel size model set num layer hidden size num attent head seq length max posit embed norm layernorm po emb rotari weight ty true provid speedup take build set true desir scale upper triang mask softmax fusion fals bia gelu fusion fals optim set optim type adam param beta ep zero optim stage allgath partit true allgath bucket size overlap comm true reduc scatter true reduc bucket size contigu gradient true cpu offload fals batch data set train micro batch size gpu data impl mmap split activ checkpoint checkpoint activ true checkpoint num layer partit activ true synchron layer true regular gradient clip weight decai hidden dropout attent dropout precis set true enabl true loss scale loss scale window hysteresi min loss scale misc train set train iter decai iter distribut backend nccl decai style constant warmup save interv eval interv eval iter checkpoint finetun true log log interv step print checkpoint wall clock breakdown true suggest data path gpt neox local train data path mnt tbnvme gpt neox data preprocess train text document test data path mnt tbnvme gpt neox data preprocess test text document valid data path mnt tbnvme gpt neox data preprocess val text document vocab file mnt tbnvme gpt neox data gpt vocab json merg file mnt tbnvme gpt neox data gpt merg txt save mnt tbnvme checkpoint test load mnt tbnvme checkpoint test checkpoint valid forward pass fals tensorboard dir mnt tbnvme log tensorboard bug fix test log dir mnt tbnvme log gptneox bug fix test us true host http api project neox test add config spars attent layer attent config local global sparsiti config default local slide window sparsiti train work left illustr purpos http www deepspe tutori spars attent config sparsiti structur detail config instruct avail paramet sparsiti config block block size num local block addit context bug fix readi follow",
        "Issue_preprocessed_content":"test set metric overwrit valid set metric tensorboard reject bug model train complet test set iter tensorboard chart test set perplex iter chart valid perplex chart result tensorboard delet valid metric overwrit test perplex valu refus test metric chart throw warn like reproduc step reproduc behavior pip setup tensorboard begin train model train valid test set observ tensorboard valid metric model train complet observ tensorboard valid metric gone test set metric observ text log program output expect behavior test metric chart propos solut test perplex chart respect environ gpu config context bug fix readi",
        "Issue_gpt_summary_original":"The user is facing an issue where the wandb API key is not configured for GitHub CI.",
        "Issue_gpt_summary":"user face issu api kei configur github",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/EleutherAI\/gpt-neox\/issues\/229",
        "Issue_title":"Local wandb logging is borked",
        "Issue_created_time":1618393073000,
        "Issue_closed_time":1624218172000,
        "Issue_body":"our current wandb logging assumes the presence of an API key, which you don't need if you're running wandb locally.\r\n\r\nWe should configure it so it works with wandb locally, too. ",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"local log bork current log assum presenc api kei need run local configur work local",
        "Issue_preprocessed_content":"local bork presenc api kei configur work",
        "Issue_gpt_summary_original":"The user has encountered a bug where the Wandb Logger only works if pytorch is installed. The expected behavior is for the logger to work regardless of pytorch installation. The bug appears in the latest library version and can be reproduced by creating a new environment, installing etna and etna[wandb], and importing WandbLogger. No additional context or environment information was provided.",
        "Issue_gpt_summary":"user encount bug logger work pytorch instal expect behavior logger work regardless pytorch instal bug appear latest librari version reproduc creat new environ instal etna etna import logger addit context environ inform provid",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Lightning-AI\/lightning-hpo\/issues\/17",
        "Issue_title":"Refused to frame 'https:\/\/wandb.ai\/' because an ancestor violates the following Content Security Policy directive: \"frame-ancestors 'self'\".",
        "Issue_created_time":1658586252000,
        "Issue_closed_time":1659198312000,
        "Issue_body":"## \ud83d\udc1b Bug\r\n\r\nRefused to frame 'https:\/\/wandb.ai\/' because an ancestor violates the following Content Security Policy directive: \"frame-ancestors 'self'\".\r\n\r\n\r\n### To Reproduce\r\n\r\n`lightning run app app.py --cloud --env xxxx --env xxx`\r\n\r\n<img width=\"1792\" alt=\"Screen Shot 2022-07-23 at 10 23 34 AM\" src=\"https:\/\/user-images.githubusercontent.com\/6315124\/180609239-6093fcc2-7902-4e36-991a-6ae44e5c329c.png\">\r\n\r\n\r\n#### Code sample\r\n\r\n\r\n### Expected behavior\r\n\r\n\r\n### Environment\r\n\r\n\r\n### Additional context\r\n",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"refus frame http ancestor violat follow content secur polici direct frame ancestor self bug refus frame http ancestor violat follow content secur polici direct frame ancestor self reproduc lightn run app app cloud env xxxx env xxx code sampl expect behavior environ addit context",
        "Issue_preprocessed_content":"refus frame ancestor violat content secur polici direct self bug refus frame ancestor violat content secur polici direct self reproduc img width alt shot code sampl expect behavior environ context",
        "Issue_gpt_summary_original":"The user encountered an exception while using `WandbLogger` in a backtest with `aggregate_metrics=True`. The error occurred in `tslogger.log_backtest_metrics` while constructing `metrics_df` and it was unable to group by \"segment\". The bug appears in both `Pipeline.backtest` and `TimeSeriesCrossValidation` class. The expected behavior is no error.",
        "Issue_gpt_summary":"user encount except logger backtest aggreg metric true error occur tslogger log backtest metric construct metric unabl group segment bug appear pipelin backtest timeseriescrossvalid class expect behavior error",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/icenet-ai\/icenet\/issues\/72",
        "Issue_title":"wandb entity is hardcoded",
        "Issue_created_time":1669459637000,
        "Issue_closed_time":null,
        "Issue_body":"* IceNet version: 0.2.0.dev10\r\n\r\n`icenet\/model\/train.py` has the wandb.init entity hardcoded, oops\r\n\r\nMake this default to $USER, ICENET_WANDB_USER or be overridden by command line (whichever exists right to left... \ud83d\ude09 )\r\n\r\nDo the same for the project too",
        "Issue_answer_count":0,
        "Issue_self_closed":null,
        "Answer_body":null,
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"entiti hardcod icenet version dev icenet model train init entiti hardcod oop default user icenet user overridden command line whichev exist right left project",
        "Issue_preprocessed_content":"entiti hardcod icenet version init entiti hardcod default user line project",
        "Issue_gpt_summary_original":"The user wants to use tensorboard as the default logger and have wandb as an optional feature within their project.",
        "Issue_gpt_summary":"user want us tensorboard default logger option featur project",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/ezeeEric\/DiVAE\/issues\/22",
        "Issue_title":"Remove data\/ and wandb\/ directories and rewrite history",
        "Issue_created_time":1615226514000,
        "Issue_closed_time":1615408051000,
        "Issue_body":"The `data\/MNIST` subdirectory slipped through `.gitignore` and is now part of the repo's history. These binary files should be removed. There's an open-source tool available to do that called `bfg` (https:\/\/rtyley.github.io\/bfg-repo-cleaner\/).\r\n\r\nAt the end of the cleaning process, we need to delete our local clones and clone a fresh, cleaned version from upstream. Let's do that once we have committed all local changes.",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"remov data directori rewrit histori data mnist subdirectori slip gitignor repo histori binari file remov open sourc tool avail call bfg http rtylei github bfg repo cleaner end clean process need delet local clone clone fresh clean version upstream let commit local chang",
        "Issue_preprocessed_content":"remov data directori rewrit histori subdirectori repo histori binari file remov avail end clean delet local clone clone fresh clean version upstream let local chang",
        "Issue_gpt_summary_original":"The user is facing an issue where the hydra config is no longer being saved to the wandb logger's config.yaml file. The user has provided examples of the previous and current states of the file and suspects that it may be related to a specific line of code in their project. The user is seeking advice on how to restore the previous state.",
        "Issue_gpt_summary":"user face issu hydra config longer save logger config yaml file user provid exampl previou current state file suspect relat specif line code project user seek advic restor previou state",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/wisdomify\/wisdomify\/issues\/90",
        "Issue_title":"wrong wandb dataset file name",
        "Issue_created_time":1634910579000,
        "Issue_closed_time":1634915290000,
        "Issue_body":"## TL;DR\r\n\uc644\ub514\ube44\uc5d0 golden test dataset\uc744 \uc5c5\ub85c\ub4dc\ud560 \ub54c, \uae30\uc874 \ub370\uc774\ud130\uc14b\uc758 \uad6c\uc870\ub97c train\/ validation\uc73c\ub85c \ubcc0\uacbd\ud588\ub294\ub370 \r\n\uc774\ub984\uc774 training\uc774 \uc544\ub2c8\ub77c train\uc73c\ub85c \ubc14\uafbc\uac8c wisdomify\uc5d0 \uc81c\ub300\ub85c \uc801\uc6a9\ub418\uc9c0 \uc54a\uc740 \uac83 \uac19\ub2e4.\r\n\r\n## WHY?\r\n\ub370\uc774\ud130\uac00 \ub85c\ub4dc\ub418\uc9c0 \uc54a\uc74c.\r\n\r\n## WHAT?\r\n\ub370\uc774\ud130 \ub85c\ub4dc\ud558\ub294 \ubd80\ubd84\uc5d0 \uac00\uc11c \ud30c\uc77c\uc774\ub984\uc744 train.tsv\ub85c \ubcc0\uacbd\ud558\uc790.\r\n\r\n## TODOs\r\n- [ ] \ub370\uc774\ud130 \ub85c\ub4dc\ud558\ub294 \ubd80\ubd84\uc5d0 \uac00\uc11c \ud30c\uc77c\uc774\ub984\uc744 train.tsv\ub85c \ubcc0\uacbd\ud558\uc790.\r\n\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"feature_68\uc5d0 \uc5c5\ub370\uc774\ud2b8\ub41c \uba54\uc778 \ube0c\ub79c\uce58\uac00 \uc801\uc6a9 \uc548\ub418\uc11c \uadf8\ub7f0\uac83.\r\nPR \uc0dd\uc131\ud574\uc11c \uc218\uc815\ud558\uc790",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"wrong dataset file golden test dataset train valid train train wisdomifi train tsv todo train tsv",
        "Issue_preprocessed_content":"wrong dataset file golden test dataset train valid train train wisdomifi todo",
        "Issue_gpt_summary_original":"The user encountered two problems while running hyperparameter search using the hydra-optuna-sweeper and wandb logger. The first issue was due to a conflict between the versions of hydra-optuna-sweeper in the requirements.txt file and the latest version installed. The second issue was related to the wandb logger, where the first run was successful, but the second run had an error due to a problem communicating with the wandb process. The user is unsure about the parameters to be passed to the pytorch lighting wrapper to avoid this error.",
        "Issue_gpt_summary":"user encount problem run hyperparamet search hydra sweeper logger issu conflict version hydra sweeper requir txt file latest version instal second issu relat logger run success second run error problem commun process user unsur paramet pass pytorch light wrapper avoid error",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/wisdomify\/wisdomify\/issues\/89",
        "Issue_title":"wandb import failure",
        "Issue_created_time":1634732461000,
        "Issue_closed_time":1635333937000,
        "Issue_body":"**Describe the bug**\r\n~~~\r\nfrom six.moves.collections_abc import Mapping, Sequence \r\nModuleNotFoundError: No module named 'six.moves.collections_abc'\r\n~~~\r\n\r\n**To Reproduce**\r\nRun on @ohsuz 's server.\r\n(Cannot reproduce on Intel i7 based local condition.)\r\n\r\n**Expected behavior**\r\nwandb should be properly imported.\r\n\r\n**Server (please complete the following information):**\r\n - OS: centOS\r\n",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"import failur bug move collect abc import map sequenc modulenotfounderror modul name move collect abc reproduc run ohsuz server reproduc intel base local condit expect behavior properli import server complet follow inform cento",
        "Issue_preprocessed_content":"import failur bug import sequenc modul name reproduc run server reproduc intel base local expect behavior properli import server cento",
        "Issue_gpt_summary_original":"The user is facing an issue with the wandb logger while using a wandb-callbacks branch. After running `python train.py logger=wandb`, the user gets an error message stating that the job was cancelled by the user after 130 iterations because the wandb login does not appear. Changing `logger: wandb` in train.yaml does not work either. The user has tried different conda envs with different torch and pl versions but is still unable to resolve the issue.",
        "Issue_gpt_summary":"user face issu logger callback branch run python train logger user get error messag state job cancel user iter login appear chang logger train yaml work user tri differ conda env differ torch version unabl resolv issu",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/johannespischinger\/senti_anal\/issues\/51",
        "Issue_title":"wandb api key for github ci",
        "Issue_created_time":1642148915000,
        "Issue_closed_time":1642173581000,
        "Issue_body":"wandb api key not configured for github ci\r\n\r\nhttps:\/\/github.com\/johannespischinger\/senti_anal\/runs\/4808536333?check_suite_focus=true",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"\/settings\/secrets\r\n\r\n```\r\njobs:\r\n  weekday_job:\r\n    runs-on: ubuntu-latest\r\n    env:\r\n      DAY_OF_WEEK: Mon\r\n    steps:\r\n      - name: \"Hello world when it's Monday\"\r\n        if: ${{ env.DAY_OF_WEEK == 'Mon' }}\r\n        run: echo \"Hello $FIRST_NAME $middle_name $Last_Name, today is Monday!\"\r\n        env:\r\n          WANDB_API_KEY: $github.SECRETS.WANDB_API\r\n          WANDB_NAME: github_ci_tests\r\n          WANDB_NAME: Octocat\r\n```\r\n\r\n\r\nhttps:\/\/docs.wandb.ai\/guides\/track\/advanced\/environment-variables\r\n",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"api kei github api kei configur github http github com johannespisching senti anal run check suit focu true",
        "Issue_preprocessed_content":"api kei github api kei configur github",
        "Issue_gpt_summary_original":"The user is facing an issue where Wandb is only logging one run instead of three runs when using DDP and multirun in their test.py file.",
        "Issue_gpt_summary":"user face issu log run instead run ddp multirun test file",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/tinkoff-ai\/etna\/issues\/335",
        "Issue_title":"[BUG] Wandb Logger does not work unless pytorch is installed ",
        "Issue_created_time":1638280869000,
        "Issue_closed_time":1638449992000,
        "Issue_body":"### \ud83d\udc1b Bug Report\n\nWandbLogger throws error while import if etna[torch] is not installed.\n\n### Expected behavior\n\nWandb Logger should work no matter pytorch installation \n\n### How To Reproduce\n\n1. Create new env\r\n2. install etna and etna[wandb]\r\n3. import WandbLogger\r\n\n\n### Environment\n\n_No response_\n\n### Additional context\n\n_No response_\n\n### Checklist\n\n- [X] Bug appears at the latest library version",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"bug logger work pytorch instal bug report logger throw error import etna torch instal expect behavior logger work matter pytorch instal reproduc creat new env instal etna etna import logger environ respons addit context respons checklist bug appear latest librari version",
        "Issue_preprocessed_content":"work pytorch bug report throw import etna expect behavior work pytorch reproduc creat new env etna etna import environ context checklist bug latest librari version",
        "Issue_gpt_summary_original":"The user is facing an issue where wandb is not compatible with PL 1.6.1 while using Hyperparameter Search, resulting in a FileNotFoundError.",
        "Issue_gpt_summary":"user face issu compat hyperparamet search result filenotfounderror",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/tinkoff-ai\/etna\/issues\/216",
        "Issue_title":"Exception in backtest with `aggregate_metrics=True` when using `WandbLogger`",
        "Issue_created_time":1634647592000,
        "Issue_closed_time":1635943713000,
        "Issue_body":"### \ud83d\udc1b Bug Report\n\nProgram fails when backtest with `aggregate_metrics=True` is used inside `WandbLogger` (if given). With `aggregate_metrics=False` everything is fine.\r\n\r\nException happens in `tslogger.log_backtest_metrics` while constructing `metrics_df`: it can't make `metrics_df.groupby(\"segment\")`. \r\n\r\nException was caught in `Pipeline.backtest`, but it looks like this bug also appears in `TimeSeriesCrossValidation` class.\n\n### Expected behavior\n\nNo error.\n\n### How To Reproduce\n\nRun backtest with WandLogger while setting `aggregate_metrics=True`. \n\n### Environment\n\n_No response_\n\n### Additional context\n\n_No response_\n\n### Checklist\n\n- [X] Bug appears at the latest library version\n- [X] Bug description added\n- [X] Steps to reproduce added\n- [X] Expected behavior added",
        "Issue_answer_count":3,
        "Issue_self_closed":0.0,
        "Answer_body":"The key to solve the bug can be [here](https:\/\/github.com\/tinkoff-ai\/etna-ts\/blob\/d99573326eb9acc3b4dd3148b9e63d2144acc917\/etna\/loggers\/wandb_logger.py#L149) lets discuss it  check that `fold_number` in df.column before drop\r\nhttps:\/\/github.com\/tinkoff-ai\/etna-ts\/blob\/master\/etna\/loggers\/wandb_logger.py#L175",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"except backtest aggreg metric true logger bug report program fail backtest aggreg metric true insid logger given aggreg metric fals fine except happen tslogger log backtest metric construct metric metric groupbi segment except caught pipelin backtest look like bug appear timeseriescrossvalid class expect behavior error reproduc run backtest wandlogg set aggreg metric true environ respons addit context respons checklist bug appear latest librari version bug descript ad step reproduc ad expect behavior ad",
        "Issue_preprocessed_content":"except backtest bug report program fail backtest insid fine except construct except caught like bug expect behavior reproduc run backtest environ context checklist bug latest librari version bug descript step reproduc expect behavior",
        "Issue_gpt_summary_original":"The user encountered an error while running benchmark.py with WandB due to the config being too large, resulting in a 400 error. The error message suggests that the train_selection array may be too big. The user suggests that the data selections may not need to be uploaded to WandB.",
        "Issue_gpt_summary":"user encount error run benchmark config larg result error error messag suggest train select arrai big user suggest data select need upload",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/Visual-Behavior\/aloception-oss\/issues\/4",
        "Issue_title":"Use tensorboard as default logger and get wandb optional within the project ",
        "Issue_created_time":1631000506000,
        "Issue_closed_time":1668696973000,
        "Issue_body":"",
        "Issue_answer_count":5,
        "Issue_self_closed":0.0,
        "Answer_body":"I think it might be interesting to use tensorboard by default instead of wandb: It does not required external services and keep all data away from getting uploaded. Or at least using tensorboard as a fallback if wandb is not installed.\r\n\r\nWhat do you think @ragier ?  Yes, totally agree\r\nTensorboardX is also the default logger of pytorch lightning @thibo73800 We want to force everyone to change their script to `--log wandb` ? Not sure.  I don't",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"us tensorboard default logger option project ",
        "Issue_preprocessed_content":"us tensorboard default option project ",
        "Issue_gpt_summary_original":"The user encountered an error while running train_model from examples after installing graphnet from scratch and signing up to WandB. The error occurred due to the absence of a directory called \"wandb\" and can be fixed by creating the folder manually. The user suggests automatically creating the folder if it is not present.",
        "Issue_gpt_summary":"user encount error run train model exampl instal graphnet scratch sign error occur absenc directori call fix creat folder manual user suggest automat creat folder present",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/ashleve\/lightning-hydra-template\/issues\/478",
        "Issue_title":"Question: How to save hydra config to wandb config.yaml",
        "Issue_created_time":1670626715000,
        "Issue_closed_time":1670781696000,
        "Issue_body":"Hello, \r\n\r\nI'm using `wandb` logger (and `csv` as well), I found recently `hydra` config no longer save to `wandb` 's`config.yaml` file.\r\nBefore:\r\n```\r\nwandb_version: 1\r\n\r\n_wandb:\r\n  desc: null\r\n  value:\r\n    cli_version: 0.13.4\r\n    framework: lightning\r\n    is_jupyter_run: false\r\n    is_kaggle_kernel: false\r\n    m:\r\n    - 1: trainer\/global_step\r\n      6:\r\n      - 3\r\n    - 1: val\/loss\r\n      5: 1\r\n      6:\r\n      - 1\r\n    - 1: val\/acc\r\n      5: 1\r\n      6:\r\n      - 1\r\n    - 1: val\/acc_best\r\n      5: 1\r\n      6:\r\n      - 1\r\n    - 1: epoch\r\n      5: 1\r\n      6:\r\n      - 1\r\n    python_version: 3.9.13\r\n    start_time: 1665409636.577166\r\n    t:\r\n      1:\r\n      - 1\r\n      - 9\r\n      - 41\r\n      - 50\r\n      - 55\r\n      2:\r\n      - 1\r\n      - 9\r\n      - 41\r\n      - 50\r\n      - 55\r\n      3:\r\n      - 2\r\n      - 7\r\n      - 13\r\n      - 23\r\n      4: 3.9.13\r\n      5: 0.13.4\r\n      8:\r\n      - 5\r\ncallbacks\/early_stopping\/_target_:\r\n  desc: null\r\n  value: pytorch_lightning.callbacks.EarlyStopping\r\ncallbacks\/early_stopping\/check_finite:\r\n  desc: null\r\n  value: true\r\ncallbacks\/early_stopping\/check_on_train_epoch_end:\r\n  desc: null\r\n  value: None\r\ncallbacks\/early_stopping\/divergence_threshold:\r\n  desc: null\r\n  value: None\r\ncallbacks\/early_stopping\/min_delta:\r\n  desc: null\r\n  value: 0.0\r\ncallbacks\/early_stopping\/mode:\r\n  desc: null\r\n  value: max\r\ncallbacks\/early_stopping\/monitor:\r\n  desc: null\r\n  value: val\/acc\r\ncallbacks\/early_stopping\/patience:\r\n  desc: null\r\n  value: 100\r\ncallbacks\/early_stopping\/stopping_threshold:\r\n  desc: null\r\n  value: None\r\ncallbacks\/early_stopping\/strict:\r\n  desc: null\r\n  value: true\r\ncallbacks\/early_stopping\/verbose:\r\n  desc: null\r\n  value: false\r\ncallbacks\/model_checkpoint\/_target_:\r\n  desc: null\r\n  value: pytorch_lightning.callbacks.ModelCheckpoint\r\ncallbacks\/model_checkpoint\/auto_insert_metric_name:\r\n  desc: null\r\n  value: false\r\ncallbacks\/model_checkpoint\/dirpath:\r\n  desc: null\r\n  value: \/Users\/caoyu\/Github\/lightning-hydra-template\/logs\/train\/runs\/2022-10-10_14-47-15\/checkpoints\r\ncallbacks\/model_checkpoint\/every_n_epochs:\r\n  desc: null\r\n  value: None\r\ncallbacks\/model_checkpoint\/every_n_train_steps:\r\n  desc: null\r\n  value: None\r\ncallbacks\/model_checkpoint\/filename:\r\n  desc: null\r\n  value: epoch_{epoch:03d}\r\ncallbacks\/model_checkpoint\/mode:\r\n  desc: null\r\n  value: max\r\ncallbacks\/model_checkpoint\/monitor:\r\n  desc: null\r\n  value: val\/acc\r\ncallbacks\/model_checkpoint\/save_last:\r\n  desc: null\r\n  value: true\r\ncallbacks\/model_checkpoint\/save_on_train_epoch_end:\r\n  desc: null\r\n  value: None\r\ncallbacks\/model_checkpoint\/save_top_k:\r\n  desc: null\r\n  value: 1\r\ncallbacks\/model_checkpoint\/save_weights_only:\r\n  desc: null\r\n  value: false\r\ncallbacks\/model_checkpoint\/train_time_interval:\r\n  desc: null\r\n  value: None\r\ncallbacks\/model_checkpoint\/verbose:\r\n  desc: null\r\n  value: false\r\ncallbacks\/model_summary\/_target_:\r\n  desc: null\r\n  value: pytorch_lightning.callbacks.RichModelSummary\r\ncallbacks\/model_summary\/max_depth:\r\n  desc: null\r\n  value: -1\r\ncallbacks\/rich_progress_bar\/_target_:\r\n  desc: null\r\n  value: pytorch_lightning.callbacks.RichProgressBar\r\nckpt_path:\r\n  desc: null\r\n  value: None\r\ndatamodule\/_target_:\r\n  desc: null\r\n  value: src.datamodules.mnist_datamodule.MNISTDataModule\r\ndatamodule\/batch_size:\r\n  desc: null\r\n  value: 128\r\ndatamodule\/data_dir:\r\n  desc: null\r\n  value: \/Users\/caoyu\/Github\/lightning-hydra-template\/data\/\r\ndatamodule\/num_workers:\r\n  desc: null\r\n  value: 0\r\ndatamodule\/pin_memory:\r\n  desc: null\r\n  value: false\r\ndatamodule\/train_val_test_split:\r\n  desc: null\r\n  value:\r\n  - 55000\r\n  - 5000\r\n  - 10000\r\nextras\/enforce_tags:\r\n  desc: null\r\n  value: true\r\nextras\/ignore_warnings:\r\n  desc: null\r\n  value: false\r\nextras\/print_config:\r\n  desc: null\r\n  value: true\r\nmodel\/_target_:\r\n  desc: null\r\n  value: src.models.mnist_module.MNISTLitModule\r\nmodel\/net\/_target_:\r\n  desc: null\r\n  value: src.models.components.simple_dense_net.SimpleDenseNet\r\nmodel\/net\/input_size:\r\n  desc: null\r\n  value: 784\r\nmodel\/net\/lin1_size:\r\n  desc: null\r\n  value: 64\r\nmodel\/net\/lin2_size:\r\n  desc: null\r\n  value: 128\r\nmodel\/net\/lin3_size:\r\n  desc: null\r\n  value: 64\r\nmodel\/net\/output_size:\r\n  desc: null\r\n  value: 10\r\nmodel\/optimizer\/_partial_:\r\n  desc: null\r\n  value: true\r\nmodel\/optimizer\/_target_:\r\n  desc: null\r\n  value: torch.optim.Adam\r\nmodel\/optimizer\/lr:\r\n  desc: null\r\n  value: 0.001\r\nmodel\/optimizer\/weight_decay:\r\n  desc: null\r\n  value: 0.0\r\nmodel\/params\/non_trainable:\r\n  desc: null\r\n  value: 0\r\nmodel\/params\/total:\r\n  desc: null\r\n  value: 67978\r\nmodel\/params\/trainable:\r\n  desc: null\r\n  value: 67978\r\nmodel\/scheduler\/_partial_:\r\n  desc: null\r\n  value: true\r\nmodel\/scheduler\/_target_:\r\n  desc: null\r\n  value: torch.optim.lr_scheduler.ReduceLROnPlateau\r\nmodel\/scheduler\/factor:\r\n  desc: null\r\n  value: 0.1\r\nmodel\/scheduler\/mode:\r\n  desc: null\r\n  value: min\r\nmodel\/scheduler\/patience:\r\n  desc: null\r\n  value: 10\r\nseed:\r\n  desc: null\r\n  value: 123\r\ntags:\r\n  desc: null\r\n  value:\r\n  - dev\r\ntask_name:\r\n  desc: null\r\n  value: train\r\ntrainer\/_target_:\r\n  desc: null\r\n  value: pytorch_lightning.Trainer\r\ntrainer\/accelerator:\r\n  desc: null\r\n  value: cpu\r\ntrainer\/check_val_every_n_epoch:\r\n  desc: null\r\n  value: 1\r\ntrainer\/default_root_dir:\r\n  desc: null\r\n  value: \/Users\/caoyu\/Github\/lightning-hydra-template\/logs\/train\/runs\/2022-10-10_14-47-15\r\ntrainer\/deterministic:\r\n  desc: null\r\n  value: false\r\ntrainer\/devices:\r\n  desc: null\r\n  value: 1\r\ntrainer\/max_epochs:\r\n  desc: null\r\n  value: 3\r\ntrainer\/min_epochs:\r\n  desc: null\r\n  value: 1\r\n```\r\nNow:\r\n```\r\nwandb_version: 1\r\n\r\n_wandb:\r\n  desc: null\r\n  value:\r\n    cli_version: 0.13.6\r\n    framework: lightning\r\n    is_jupyter_run: false\r\n    is_kaggle_kernel: false\r\n    m:\r\n    - 1: trainer\/global_step\r\n      6:\r\n      - 3\r\n    - 1: val\/loss\r\n      5: 1\r\n      6:\r\n      - 1\r\n    - 1: val\/acc\r\n      5: 1\r\n      6:\r\n      - 1\r\n    - 1: val\/acc_best\r\n      5: 1\r\n      6:\r\n      - 1\r\n    - 1: epoch\r\n      5: 1\r\n      6:\r\n      - 1\r\n    - 1: train\/loss\r\n      5: 1\r\n      6:\r\n      - 1\r\n    - 1: train\/acc\r\n      5: 1\r\n      6:\r\n      - 1\r\n    - 1: test\/loss\r\n      5: 1\r\n      6:\r\n      - 1\r\n    - 1: test\/acc\r\n      5: 1\r\n      6:\r\n      - 1\r\n    python_version: 3.8.15\r\n    start_time: 1670583155.275978\r\n    t:\r\n      1:\r\n      - 1\r\n      - 9\r\n      - 41\r\n      - 50\r\n      - 55\r\n      2:\r\n      - 1\r\n      - 9\r\n      - 41\r\n      - 50\r\n      - 55\r\n      3:\r\n      - 2\r\n      - 7\r\n      - 23\r\n      4: 3.8.15\r\n      5: 0.13.6\r\n      8:\r\n      - 5\r\n```\r\nThis may related to:\r\nhttps:\/\/github.com\/ashleve\/lightning-hydra-template\/blob\/16fb9a6a807d278d1797ce4dedc885c7e5e1b7fb\/src\/utils\/utils.py#L172\r\nAny idea how to restore to previous state?",
        "Issue_answer_count":0,
        "Issue_self_closed":0.0,
        "Answer_body":"",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"question save hydra config config yaml hello logger csv recent hydra config longer save config yaml file version desc null valu cli version framework lightn jupyt run fals kaggl kernel fals trainer global step val loss val acc val acc best epoch python version start time callback earli stop target desc null valu pytorch lightn callback earlystop callback earli stop check finit desc null valu true callback earli stop check train epoch end desc null valu callback earli stop diverg threshold desc null valu callback earli stop min delta desc null valu callback earli stop mode desc null valu max callback earli stop monitor desc null valu val acc callback earli stop patienc desc null valu callback earli stop stop threshold desc null valu callback earli stop strict desc null valu true callback earli stop verbos desc null valu fals callback model checkpoint target desc null valu pytorch lightn callback modelcheckpoint callback model checkpoint auto insert metric desc null valu fals callback model checkpoint dirpath desc null valu user caoyu github lightn hydra templat log train run checkpoint callback model checkpoint epoch desc null valu callback model checkpoint train step desc null valu callback model checkpoint filenam desc null valu epoch epoch callback model checkpoint mode desc null valu max callback model checkpoint monitor desc null valu val acc callback model checkpoint save desc null valu true callback model checkpoint save train epoch end desc null valu callback model checkpoint save desc null valu callback model checkpoint save weight desc null valu fals callback model checkpoint train time interv desc null valu callback model checkpoint verbos desc null valu fals callback model summari target desc null valu pytorch lightn callback richmodelsummari callback model summari max depth desc null valu callback rich progress bar target desc null valu pytorch lightn callback richprogressbar ckpt path desc null valu datamodul target desc null valu src datamodul mnist datamodul mnistdatamodul datamodul batch size desc null valu datamodul data dir desc null valu user caoyu github lightn hydra templat data datamodul num worker desc null valu datamodul pin memori desc null valu fals datamodul train val test split desc null valu extra enforc tag desc null valu true extra ignor warn desc null valu fals extra print config desc null valu true model target desc null valu src model mnist modul mnistlitmodul model net target desc null valu src model compon simpl dens net simpledensenet model net input size desc null valu model net lin size desc null valu model net lin size desc null valu model net lin size desc null valu model net output size desc null valu model optim partial desc null valu true model optim target desc null valu torch optim adam model optim desc null valu model optim weight decai desc null valu model param non trainabl desc null valu model param total desc null valu model param trainabl desc null valu model schedul partial desc null valu true model schedul target desc null valu torch optim schedul reducelronplateau model schedul factor desc null valu model schedul mode desc null valu min model schedul patienc desc null valu seed desc null valu tag desc null valu dev task desc null valu train trainer target desc null valu pytorch lightn trainer trainer acceler desc null valu cpu trainer check val epoch desc null valu trainer default root dir desc null valu user caoyu github lightn hydra templat log train run trainer determinist desc null valu fals trainer devic desc null valu trainer max epoch desc null valu trainer min epoch desc null valu version desc null valu cli version framework lightn jupyt run fals kaggl kernel fals trainer global step val loss val acc val acc best epoch train loss train acc test loss test acc python version start time relat http github com ashlev lightn hydra templat blob fbaaddcededcceebfb src util util idea restor previou state",
        "Issue_preprocessed_content":"question save hydra config file relat idea restor previou state",
        "Issue_gpt_summary_original":"The user is facing an issue with the full episode data logging in a random agent script using wandb, where some steps are being skipped. The problem is due to wandb counting the episode reward logging steps made before the full data logging. A potential solution suggested is to add another metric to log the timestep and day proportionally.",
        "Issue_gpt_summary":"user face issu episod data log random agent script step skip problem count episod reward log step data log potenti solut suggest add metric log timestep dai proportion",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/ashleve\/lightning-hydra-template\/issues\/362",
        "Issue_title":"hydra-optuna-sweeper and wandb versions conflict",
        "Issue_created_time":1656590728000,
        "Issue_closed_time":1657912525000,
        "Issue_body":"Hi!\r\n\r\nI have installed all required packages by `pip install -r requrements.txt` and tried to run hyperparametric search using the [file](https:\/\/github.com\/ashleve\/lightning-hydra-template\/blob\/main\/configs\/hparams_search\/mnist_optuna.yaml):\r\n```\r\ntrain.py -m hparams_search=mnist_optuna experiment=example\r\n``` \r\nI faced 2 problems:\r\n\r\n# 1. hydra-optuna-sweeper problem\r\n\r\nI got the following error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\hydra\\_internal\\utils.py\", line 213, in run_and_report\r\n    return func()\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\hydra\\_internal\\utils.py\", line 461, in <lambda>\r\n    lambda: hydra.multirun(\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\hydra\\_internal\\hydra.py\", line 162, in multirun\r\n    ret = sweeper.sweep(arguments=task_overrides)\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\hydra_plugins\\hydra_optuna_sweeper\\optuna_sweeper.py\", line 52, in sweep\r\n    return self.sweeper.sweep(arguments)\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\hydra_plugins\\hydra_optuna_sweeper\\_impl.py\", line 289, in sweep\r\n    assert self.search_space is None\r\nAssertionError\r\n```\r\nThe same error was reported in [this issue](https:\/\/github.com\/facebookresearch\/hydra\/issues\/2253).\r\n\r\nFile [requrements.txt](https:\/\/github.com\/ashleve\/lightning-hydra-template\/blob\/main\/requirements.txt) contains the following versions for hydra-optuna-sweeper:\r\n```\r\n# --------- hydra --------- #\r\nhydra-core>=1.1.0\r\nhydra-colorlog>=1.1.0\r\nhydra-optuna-sweeper>=1.1.0\r\n```\r\nBut the latest versions of the packages are installing:\r\n```\r\nhydra-colorlog==1.2.0\r\nhydra-core==1.2.0\r\nhydra-optuna-sweeper==1.2.0\r\n```\r\n\r\nIf I understand correctly, optuna sweeper's syntax has changed in hydra since version 1.2.0. When I change the syntax to the new version (as it was in mentioned above [issue](https:\/\/github.com\/facebookresearch\/hydra\/issues\/2253)):\r\n```yaml\r\nhydra:\r\n  sweeper:\r\n    ...\r\n    params:\r\n      datamodule.batch_size: choice(32,64,128)\r\n      model.lr: interval(0.0001, 0.2)\r\n      model.net.lin1_size: choice(32, 64, 128, 256, 512)\r\n      model.net.lin2_size: choice(32, 64, 128, 256, 512)\r\n      model.net.lin3_size: choice(32, 64, 128, 256, 512)\r\n```\r\neverything works without errors.\r\n\r\n# 2. wandb problem\r\nAfter the command `pip install -r requrements.txt` wandb==0.12.20 was installed.\r\nWhen running the training process with this logger:\r\n```\r\ntrain.py -m hparams_search=mnist_optuna experiment=example logger=wandb\r\n```\r\nThe first run with the certian parameters combination finished successfully, the second run had the error:\r\n\r\n```\r\nException in thread StreamThr:\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\threading.py\", line 973, in _bootstrap_inner\r\n    self.run()\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\wandb\\sdk\\service\\streams.py\", line 40, in run\r\n    self._target(**self._kwargs)\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\wandb\\sdk\\internal\\internal.py\", line 85, in wandb_internal\r\n    configure_logging(_settings.log_internal, _settings._log_level)\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\wandb\\sdk\\internal\\internal.py\", line 189, in configure_logging\r\n    log_handler = logging.FileHandler(log_fname)\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\logging\\__init__.py\", line 1146, in __init__\r\n    StreamHandler.__init__(self, self._open())\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\logging\\__init__.py\", line 1175, in _open\r\n    return open(self.baseFilename, self.mode, encoding=self.encoding,\r\nFileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\yusip\\\\Desktop\\\\lightning-hydra-template-main\\\\logs\\\\experiments\\\\multiruns\\\\simple_dense_net\\\\2022-06-30_14-36-03\\\\0\\\\wandb\\\\run-2022\r\n0630_143648-2vxuij78\\\\logs\\\\debug-internal.log'\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\runpy.py\", line 197, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\runpy.py\", line 87, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\wandb\\__main__.py\", line 3, in <module>\r\n    cli.cli(prog_name=\"python -m wandb\")\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\click\\core.py\", line 1130, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\click\\core.py\", line 1055, in main\r\n    rv = self.invoke(ctx)\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\click\\core.py\", line 1657, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\click\\core.py\", line 1404, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\click\\core.py\", line 760, in invoke\r\n    return __callback(*args, **kwargs)\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\wandb\\cli\\cli.py\", line 96, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\wandb\\cli\\cli.py\", line 285, in service\r\n    server.serve()\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\wandb\\sdk\\service\\server.py\", line 140, in serve\r\n    mux.loop()\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\wandb\\sdk\\service\\streams.py\", line 332, in loop\r\n    raise e\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\wandb\\sdk\\service\\streams.py\", line 330, in loop\r\n    self._loop()\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\wandb\\sdk\\service\\streams.py\", line 323, in _loop\r\n    self._process_action(action)\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\wandb\\sdk\\service\\streams.py\", line 288, in _process_action\r\n    self._process_add(action)\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\wandb\\sdk\\service\\streams.py\", line 208, in _process_add\r\n    stream.start_thread(thread)\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\wandb\\sdk\\service\\streams.py\", line 68, in start_thread\r\n    self._wait_thread_active()\r\n  File \"C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\wandb\\sdk\\service\\streams.py\", line 73, in _wait_thread_active\r\n    assert result\r\nAssertionError\r\nProblem at: C:\\Users\\yusip\\anaconda3\\envs\\py39\\lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py 357 experiment\r\nwandb: ERROR Error communicating with wandb process\r\nwandb: ERROR try: wandb.init(settings=wandb.Settings(start_method='fork'))\r\nwandb: ERROR or:  wandb.init(settings=wandb.Settings(start_method='thread'))\r\nwandb: ERROR For more info see: https:\/\/docs.wandb.ai\/library\/init#init-start-error\r\nError executing job with overrides: ['datamodule.batch_size=32', 'model.lr=0.09357304154313738', 'model.net.lin1_size=256', 'model.net.lin2_size=512', 'model.net.lin3_size=256', 'hparams_search=mnist_op\r\ntuna', 'experiment=example', 'logger=wandb']\r\nError in call to target 'pytorch_lightning.loggers.wandb.WandbLogger':\r\nUsageError(\"Error communicating with wandb process\\ntry: wandb.init(settings=wandb.Settings(start_method='fork'))\\nor:  wandb.init(settings=wandb.Settings(start_method='thread'))\\nFor more info see: htt\r\nps:\/\/docs.wandb.ai\/library\/init#init-start-error\")\r\nfull_key: logger.wandb\r\n```\r\nIt is not clear, which parameters should be passed to pytorch lighting wrapper when initializinig this logger, to avoid this error.\r\n\r\n\r\n",
        "Issue_answer_count":2,
        "Issue_self_closed":0.0,
        "Answer_body":"Hi @GillianGrayson \r\n\r\nFor **1. hydra-optuna-sweeper problem**, it has been modified in release_1.4. You can find [here](https:\/\/github.com\/ashleve\/lightning-hydra-template\/blob\/7e67c4692590550e7b703655845e59508eb071bb\/configs\/hparams_search\/mnist_optuna.yaml#L49)\r\n\r\n @GillianGrayson ty for reporting, the problems have been fixed on the current `main` branch.",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"hydra sweeper version conflict instal requir packag pip instal requr txt tri run hyperparametr search file http github com ashlev lightn hydra templat blob main config hparam search mnist yaml train hparam search mnist experi exampl face problem hydra sweeper problem got follow error traceback recent file user yusip anaconda env lib site packag hydra intern util line run report return func file user yusip anaconda env lib site packag hydra intern util line lambda hydra multirun file user yusip anaconda env lib site packag hydra intern hydra line multirun ret sweeper sweep argument task overrid file user yusip anaconda env lib site packag hydra plugin hydra sweeper sweeper line sweep return self sweeper sweep argument file user yusip anaconda env lib site packag hydra plugin hydra sweeper impl line sweep assert self search space assertionerror error report issu http github com facebookresearch hydra issu file requr txt http github com ashlev lightn hydra templat blob main requir txt contain follow version hydra sweeper hydra hydra core hydra colorlog hydra sweeper latest version packag instal hydra colorlog hydra core hydra sweeper understand correctli sweeper syntax chang hydra version chang syntax new version mention issu http github com facebookresearch hydra issu yaml hydra sweeper param datamodul batch size choic model interv model net lin size choic model net lin size choic model net lin size choic work error problem command pip instal requr txt instal run train process logger train hparam search mnist experi exampl logger run certian paramet combin finish successfulli second run error except thread streamthr traceback recent file user yusip anaconda env lib thread line bootstrap inner self run file user yusip anaconda env lib site packag sdk servic stream line run self target self kwarg file user yusip anaconda env lib site packag sdk intern intern line intern configur log set log intern set log level file user yusip anaconda env lib site packag sdk intern intern line configur log log handler log filehandl log fname file user yusip anaconda env lib log init line init streamhandl init self self open file user yusip anaconda env lib log init line open return open self basefilenam self mode encod self encod filenotfounderror errno file directori user yusip desktop lightn hydra templat main log experi multirun simpl dens net run vxuij log debug intern log traceback recent file user yusip anaconda env lib runpi line run modul main return run code code main global file user yusip anaconda env lib runpi line run code exec code run global file user yusip anaconda env lib site packag main line cli cli prog python file user yusip anaconda env lib site packag click core line return self main arg kwarg file user yusip anaconda env lib site packag click core line main self invok ctx file user yusip anaconda env lib site packag click core line invok return process result sub ctx command invok sub ctx file user yusip anaconda env lib site packag click core line invok return ctx invok self callback ctx param file user yusip anaconda env lib site packag click core line invok return callback arg kwarg file user yusip anaconda env lib site packag cli cli line wrapper return func arg kwarg file user yusip anaconda env lib site packag cli cli line servic server serv file user yusip anaconda env lib site packag sdk servic server line serv mux loop file user yusip anaconda env lib site packag sdk servic stream line loop rais file user yusip anaconda env lib site packag sdk servic stream line loop self loop file user yusip anaconda env lib site packag sdk servic stream line loop self process action action file user yusip anaconda env lib site packag sdk servic stream line process action self process add action file user yusip anaconda env lib site packag sdk servic stream line process add stream start thread thread file user yusip anaconda env lib site packag sdk servic stream line start thread self wait thread activ file user yusip anaconda env lib site packag sdk servic stream line wait thread activ assert result assertionerror problem user yusip anaconda env lib site packag pytorch lightn logger experi error error commun process error try init set set start method fork error init set set start method thread error info http doc librari init init start error error execut job overrid datamodul batch size model model net lin size model net lin size model net lin size hparam search mnist tuna experi exampl logger error target pytorch lightn logger logger usageerror error commun process ntry init set set start method fork init set set start method thread nfor info htt doc librari init init start error kei logger clear paramet pass pytorch light wrapper initializinig logger avoid error",
        "Issue_preprocessed_content":"version conflict requir packag tri run hyperparametr search face problem problem got report file contain version latest version packag understand syntax chang hydra version chang syntax new version work problem train run certian paramet combin finish second run clear paramet pytorch light initializinig avoid",
        "Issue_gpt_summary_original":"The user has encountered an issue with the requirements.txt file not having the complete dependency tree defined while working with Sorts in Sagemaker. The possible fix is to modify the requirements.txt file to include the complete tree of dependencies and their respective versions.",
        "Issue_gpt_summary":"user encount issu requir txt file have complet depend tree defin work sort possibl fix modifi requir txt file includ complet tree depend respect version",
        "Issue_score_count":1
    },
    {
        "Issue_link":"https:\/\/github.com\/ashleve\/lightning-hydra-template\/issues\/328",
        "Issue_title":"wandb logger not working",
        "Issue_created_time":1654326486000,
        "Issue_closed_time":1654420353000,
        "Issue_body":"Hi there, \r\nthank you for this powerful template! \r\nI run into a problem while trying to use wandb as logger\r\nI used the wandb-callbacks branch and after `python train.py logger=wandb` i get (cancelled by user after 130 iterations cause wandb login does not appear)\r\n\r\n````\r\n$ python train.py logger=wandb\r\n\u250c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502    \u2502 Name          \u2502 Type             \u2502 Params \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502 0  \u2502 model         \u2502 SimpleDenseNet   \u2502  336 K \u2502\r\n\u2502 1  \u2502 model.model   \u2502 Sequential       \u2502  336 K \u2502\r\n\u2502 2  \u2502 model.model.0 \u2502 Linear           \u2502  200 K \u2502\r\n\u2502 3  \u2502 model.model.1 \u2502 BatchNorm1d      \u2502    512 \u2502\r\n\u2502 4  \u2502 model.model.2 \u2502 ReLU             \u2502      0 \u2502\r\n\u2502 5  \u2502 model.model.3 \u2502 Linear           \u2502 65.8 K \u2502\r\n\u2502 6  \u2502 model.model.4 \u2502 BatchNorm1d      \u2502    512 \u2502\r\n\u2502 7  \u2502 model.model.5 \u2502 ReLU             \u2502      0 \u2502\r\n\u2502 8  \u2502 model.model.6 \u2502 Linear           \u2502 65.8 K \u2502\r\n\u2502 9  \u2502 model.model.7 \u2502 BatchNorm1d      \u2502    512 \u2502\r\n\u2502 10 \u2502 model.model.8 \u2502 ReLU             \u2502      0 \u2502\r\n\u2502 11 \u2502 model.model.9 \u2502 Linear           \u2502  2.6 K \u2502\r\n\u2502 12 \u2502 criterion     \u2502 CrossEntropyLoss \u2502      0 \u2502\r\n\u2502 13 \u2502 train_acc     \u2502 Accuracy         \u2502      0 \u2502\r\n\u2502 14 \u2502 val_acc       \u2502 Accuracy         \u2502      0 \u2502\r\n\u2502 15 \u2502 test_acc      \u2502 Accuracy         \u2502      0 \u2502\r\n\u2502 16 \u2502 val_acc_best  \u2502 MaxMetric        \u2502      0 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\nTrainable params: 336 K\r\nNon-trainable params: 0\r\nTotal params: 336 K\r\nTotal estimated model params size (MB): 1\r\nEpoch 0    ----- ---------------------------------- 130\/939 0:00:04 \u2022 0:00:28 29.28it\/s loss: 0.252\r\nError executing job with overrides: ['logger=wandb']\r\n````\r\n_(Note the last line)_\r\n\r\nChanging `logger: wandb` in train.yaml does not work either. I'm a bit confused because i had it working once before but just don't know what to do anymore. I tried out different conda envs with different torch and pl versions. Does anyboady have an idea?\r\n\r\n\r\n**pip list**\r\n```\r\nPackage                 Version\r\n----------------------- ------------\r\nabsl-py                 1.1.0\r\naiohttp                 3.8.1\r\naiosignal               1.2.0\r\nalembic                 1.8.0\r\nantlr4-python3-runtime  4.8\r\nanyio                   3.6.1\r\nargon2-cffi             21.3.0\r\nargon2-cffi-bindings    21.2.0\r\nasttokens               2.0.5\r\nasync-timeout           4.0.2\r\natomicwrites            1.4.0\r\nattrs                   21.4.0\r\nautopage                0.5.1\r\nBabel                   2.10.1\r\nbackcall                0.2.0\r\nbeautifulsoup4          4.11.1\r\nblack                   22.3.0\r\nbleach                  5.0.0\r\ncachetools              5.2.0\r\ncertifi                 2022.5.18.1\r\ncffi                    1.15.0\r\ncfgv                    3.3.1\r\ncharset-normalizer      2.0.12\r\nclick                   8.1.3\r\ncliff                   3.10.1\r\ncmaes                   0.8.2\r\ncmd2                    2.4.1\r\ncolorama                0.4.4\r\ncolorlog                6.6.0\r\ncommonmark              0.9.1\r\ncycler                  0.11.0\r\ndebugpy                 1.6.0\r\ndecorator               5.1.1\r\ndefusedxml              0.7.1\r\ndistlib                 0.3.4\r\ndocker-pycreds          0.4.0\r\nentrypoints             0.4\r\nexecuting               0.8.3\r\nfastjsonschema          2.15.3\r\nfilelock                3.7.1\r\nflake8                  4.0.1\r\nfonttools               4.33.3\r\nfrozenlist              1.3.0\r\nfsspec                  2022.5.0\r\ngitdb                   4.0.9\r\nGitPython               3.1.27\r\ngoogle-auth             2.6.6\r\ngoogle-auth-oauthlib    0.4.6\r\ngreenlet                1.1.2\r\ngrpcio                  1.46.3\r\nhydra-colorlog          1.2.0\r\nhydra-core              1.1.0\r\nhydra-optuna-sweeper    1.2.0\r\nidentify                2.5.1\r\nidna                    3.3\r\nimportlib-metadata      4.11.4\r\nimportlib-resources     5.7.1\r\niniconfig               1.1.1\r\nipykernel               6.13.0\r\nipython                 8.4.0\r\nipython-genutils        0.2.0\r\nisort                   5.10.1\r\njedi                    0.18.1\r\nJinja2                  3.1.2\r\njoblib                  1.1.0\r\njson5                   0.9.8\r\njsonschema              4.6.0\r\njupyter-client          7.3.1\r\njupyter-core            4.10.0\r\njupyter-server          1.17.0\r\njupyterlab              3.4.2\r\njupyterlab-pygments     0.2.2\r\njupyterlab-server       2.14.0\r\nkiwisolver              1.4.2\r\nMako                    1.2.0\r\nMarkdown                3.3.7\r\nMarkupSafe              2.1.1\r\nmatplotlib              3.5.2\r\nmatplotlib-inline       0.1.3\r\nmccabe                  0.6.1\r\nmistune                 0.8.4\r\nmultidict               6.0.2\r\nmypy-extensions         0.4.3\r\nnbclassic               0.3.7\r\nnbclient                0.6.4\r\nnbconvert               6.5.0\r\nnbformat                5.4.0\r\nnest-asyncio            1.5.5\r\nnodeenv                 1.6.0\r\nnotebook                6.4.11\r\nnotebook-shim           0.1.0\r\nnumpy                   1.22.4\r\noauthlib                3.2.0\r\nomegaconf               2.1.2\r\noptuna                  2.10.0\r\npackaging               21.3\r\npandas                  1.4.2\r\npandocfilters           1.5.0\r\nparso                   0.8.3\r\npathspec                0.9.0\r\npathtools               0.1.2\r\npbr                     5.9.0\r\npickleshare             0.7.5\r\nPillow                  9.1.1\r\npip                     21.2.2\r\nplatformdirs            2.5.2\r\npluggy                  1.0.0\r\npre-commit              2.19.0\r\nprettytable             3.3.0\r\nprometheus-client       0.14.1\r\npromise                 2.3\r\nprompt-toolkit          3.0.29\r\nprotobuf                3.20.1\r\npsutil                  5.9.1\r\npudb                    2022.1.1\r\npure-eval               0.2.2\r\npy                      1.11.0\r\npyasn1                  0.4.8\r\npyasn1-modules          0.2.8\r\npycodestyle             2.8.0\r\npycparser               2.21\r\npyDeprecate             0.3.2\r\npyflakes                2.4.0\r\nPygments                2.12.0\r\npyparsing               3.0.9\r\npyperclip               1.8.2\r\npyreadline3             3.4.1\r\npyrsistent              0.18.1\r\npytest                  7.1.2\r\npython-dateutil         2.8.2\r\npython-dotenv           0.20.0\r\npytorch-lightning       1.6.4\r\npytz                    2022.1\r\npywin32                 304\r\npywinpty                2.0.5\r\nPyYAML                  6.0\r\npyzmq                   23.1.0\r\nrequests                2.27.1\r\nrequests-oauthlib       1.3.1\r\nrich                    12.4.4\r\nrsa                     4.8\r\nscikit-learn            1.1.1\r\nscipy                   1.8.1\r\nseaborn                 0.11.2\r\nSend2Trash              1.8.0\r\nsentry-sdk              1.5.12\r\nsetproctitle            1.2.3\r\nsetuptools              61.2.0\r\nsh                      1.14.2\r\nshortuuid               1.0.9\r\nsix                     1.16.0\r\nsmmap                   5.0.0\r\nsniffio                 1.2.0\r\nsoupsieve               2.3.2.post1\r\nSQLAlchemy              1.4.37\r\nstack-data              0.2.0\r\nstevedore               3.5.0\r\ntensorboard             2.9.0\r\ntensorboard-data-server 0.6.1\r\ntensorboard-plugin-wit  1.8.1\r\nterminado               0.15.0\r\nthreadpoolctl           3.1.0\r\ntinycss2                1.1.1\r\ntoml                    0.10.2\r\ntomli                   2.0.1\r\ntorch                   1.11.0+cu113\r\ntorchaudio              0.11.0+cu113\r\ntorchmetrics            0.9.0\r\ntorchvision             0.12.0+cu113\r\ntornado                 6.1\r\ntqdm                    4.64.0\r\ntraitlets               5.2.2.post1\r\ntyping_extensions       4.2.0\r\nurllib3                 1.26.9\r\nurwid                   2.1.2\r\nurwid-readline          0.13\r\nvirtualenv              20.14.1\r\nwandb                   0.12.17\r\nwcwidth                 0.2.5\r\nwebencodings            0.5.1\r\nwebsocket-client        1.3.2\r\nWerkzeug                2.1.2\r\nwheel                   0.37.1\r\nwincertstore            0.2\r\nyarl                    1.7.2\r\nzipp                    3.8.0\r\n```",
        "Issue_answer_count":2,
        "Issue_self_closed":1.0,
        "Answer_body":"`wandb-callbacks` haven't been maintained for a while and it might not work correctly with recent lightning and hydra releases. \r\n\r\nHave you trained using the `main` branch?\r\n\r\nI'm preparing new release and will fix the callbacks when it's ready https:\/\/github.com\/ashleve\/lightning-hydra-template\/issues\/308\r\n So i managed to get it working using a fresh conda environment: \r\ntorch==1.10.0 with CUDA10.2\r\npytorch-lightning==1.6.4\r\nwandb == 0.12.17\r\n\r\nI doesnt check if all the callbacks work properly but my initial problem is solved. Thank you for your help! ",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"logger work thank power templat run problem try us logger callback branch python train logger cancel user iter caus login appear python train logger type param model simpledensenet model model sequenti model model linear model model batchnormd model model relu model model linear model model batchnormd model model relu model model linear model model batchnormd model model relu model model linear criterion crossentropyloss train acc accuraci val acc accuraci test acc accuraci val acc best maxmetr trainabl param non trainabl param total param total estim model param size epoch loss error execut job overrid logger note line chang logger train yaml work bit confus work know anymor tri differ conda env differ torch version anyboadi idea pip list packag version absl aiohttp aiosign alemb antlr python runtim anyio argon cffi argon cffi bind asttoken async timeout atomicwrit attr autopag babel backcal beautifulsoup black bleach cachetool certifi cffi cfgv charset normal click cliff cmae cmd colorama colorlog commonmark cycler debugpi decor defusedxml distlib docker pycr entrypoint execut fastjsonschema filelock flake fonttool frozenlist fsspec gitdb gitpython googl auth googl auth oauthlib greenlet grpcio hydra colorlog hydra core hydra sweeper identifi idna importlib metadata importlib resourc iniconfig ipykernel ipython ipython genutil isort jedi jinja joblib json jsonschema jupyt client jupyt core jupyt server jupyterlab jupyterlab pygment jupyterlab server kiwisolv mako markdown markupsaf matplotlib matplotlib inlin mccabe mistun multidict mypi extens nbclassic nbclient nbconvert nbformat nest asyncio nodeenv notebook notebook shim numpi oauthlib omegaconf packag panda pandocfilt parso pathspec pathtool pbr pickleshar pillow pip platformdir pluggi pre commit prettyt prometheu client promis prompt toolkit protobuf psutil pudb pure eval pyasn pyasn modul pycodestyl pycpars pydeprec pyflak pygment pypars pyperclip pyreadlin pyrsist pytest python dateutil python dotenv pytorch lightn pytz pywin pywinpti pyyaml pyzmq request request oauthlib rich rsa scikit learn scipi seaborn sendtrash sentri sdk setproctitl setuptool shortuuid smmap sniffio soupsiev post sqlalchemi stack data stevedor tensorboard tensorboard data server tensorboard plugin wit terminado threadpoolctl tinycss toml tomli torch torchaudio torchmetr torchvis tornado tqdm traitlet post type extens urllib urwid urwid readlin virtualenv wcwidth webencod websocket client werkzeug wheel wincertstor yarl zipp",
        "Issue_preprocessed_content":"work thank power templat run problem try us branch",
        "Issue_gpt_summary_original":"The user is facing an issue with the wandb logger while using a wandb-callbacks branch. After running the command `python train.py logger=wandb`, the user gets an error message stating that the job was cancelled by the user after 130 iterations because the wandb login does not appear. Changing `logger: wandb` in train.yaml does not work either. The user has tried different conda envs with different torch and pl versions but the issue persists.",
        "Issue_gpt_summary":"user face issu logger callback branch run command python train logger user get error messag state job cancel user iter login appear chang logger train yaml work user tri differ conda env differ torch version issu persist",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/ashleve\/lightning-hydra-template\/issues\/289",
        "Issue_title":"wandb log only 1 run when using ddp and multirun",
        "Issue_created_time":1651909943000,
        "Issue_closed_time":1657910798000,
        "Issue_body":"When I use DDP, wandb and multirun in `test.py` like this \r\n`python test.py -m ckpt_path='~~' +seed=1,2,3 +trainer.strategy=ddp logger=wandb`\r\nWandb does not record 3 runs, but only one run.\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"Try adding `wandb.finish()` after testing to make sure it has closed properly",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"log run ddp multirun us ddp multirun test like python test ckpt path seed trainer strategi ddp logger record run run",
        "Issue_preprocessed_content":"log run multirun us multirun like record run run",
        "Issue_gpt_summary_original":"The user is facing an issue where Wandb is only logging one run instead of three runs when using DDP and multirun in their `test.py` file.",
        "Issue_gpt_summary":"user face issu log run instead run ddp multirun test file",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/ashleve\/lightning-hydra-template\/issues\/285",
        "Issue_title":"Wandb is not compatible with PL 1.6.1",
        "Issue_created_time":1650933722000,
        "Issue_closed_time":1654689077000,
        "Issue_body":"Hi,\r\n\r\nThere may be version conflict between wandb and PL 1.6.1\r\n\r\n**OS:** Ubuntu20.04\r\n**Python:** 3.8.13\r\n**Pytorch:**  1.11.0\r\n**PL:** 1.6.1\r\n**Wandb:** 0.12.11\r\n**hydra-core:** 1.1.2\r\n\r\nwhen I use the Hyperparameter Search, it produces the following error:\r\n\r\n```python\r\nFileNotFoundError: [Errno 2] No such file or directory: '\/**\/logs\/experiments\/multiruns\/**\/time\/0\/wandb\/offline-run-20*\/logs\/debug-internal.log'\r\nProblem at: \/home\/*\/anaconda3\/envs\/*\/lib\/python3.8\/site-packages\/pytorch_lightning\/loggers\/wandb.py 357 experiment\r\n```\r\n",
        "Issue_answer_count":3,
        "Issue_self_closed":0.0,
        "Answer_body":"I have met the same problem. > I have met the same problem.\r\n\r\nInstall PL=1.5.10 for me it's working with 1.6.3 \r\nonly update wandb 0.12.16",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"compat version conflict ubuntu python pytorch hydra core us hyperparamet search produc follow error python filenotfounderror errno file directori log experi multirun time offlin run log debug intern log problem home anaconda env lib python site packag pytorch lightn logger experi",
        "Issue_preprocessed_content":"compat version conflict python pytorch us hyperparamet search produc",
        "Issue_gpt_summary_original":"The user is facing an issue where wandb is not compatible with PL 1.6.1 while using Hyperparameter Search, resulting in a FileNotFoundError. The error occurs while trying to access the debug-internal.log file.",
        "Issue_gpt_summary":"user face issu compat hyperparamet search result filenotfounderror error occur try access debug intern log file",
        "Issue_score_count":1
    },
    {
        "Issue_link":"https:\/\/github.com\/graphnet-team\/graphnet\/issues\/316",
        "Issue_title":"WandB fails when config is too large",
        "Issue_created_time":1666171234000,
        "Issue_closed_time":1666770135000,
        "Issue_body":"I tried to run benchmark.py, with WandB, but got an error because the config is too large, probably due to the train_selection array being too big. `ERROR Error while calling W&B API: run config cannot exceed 15 MB (<Response [400]>)`\r\n\r\nPerhaps the data selections does not need to be uploaded to WandB?\r\n\r\nThe full message is: \r\n```(graphnet) [peter@hep04 northern_tracks]$ python benchmark.py \r\ngraphnet: INFO     2022-10-19 10:33:19 - get_logger - Writing log to logs\/graphnet_20221019-103308.log\r\ngraphnet: WARNING  2022-10-19 10:33:25 - warn_once - `icecube` not available. Some functionality may be missing.\r\nwandb: Currently logged in as: peterandresen (graphnet-team). Use `wandb login --relogin` to force relogin\r\nwandb: wandb version 0.13.4 is available!  To upgrade, please run:\r\nwandb:  $ pip install wandb --upgrade\r\nwandb: Tracking run with wandb version 0.13.1\r\nwandb: Run data is saved locally in .\/wandb\/wandb\/run-20221019_103334-47u9ascy\r\nwandb: Run `wandb offline` to turn off syncing.\r\nwandb: Syncing run woven-water-2\r\nwandb: \u2b50\ufe0f View project at https:\/\/wandb.ai\/graphnet-team\/NortherenTracks_Benchmark\r\nwandb: \ud83d\ude80 View run at https:\/\/wandb.ai\/graphnet-team\/NortherenTracks_Benchmark\/runs\/47u9ascy\r\nwandb: WARNING Serializing object of type list that is 14743672 bytes\r\nwandb: WARNING Serializing object of type list that is 4914592 bytes\r\nwandb: WARNING Serializing object of type list that is 4914600 bytes\r\nwandb: WARNING Serializing object of type list that is 15673400 bytes\r\nwandb: WARNING Serializing object of type list that is 5429640 bytes\r\nwandb: WARNING Serializing object of type list that is 5429640 bytes\r\ngraphnet: INFO     2022-10-19 10:33:54 - train - features: ['dom_x', 'dom_y', 'dom_z', 'dom_time', 'charge', 'rde', 'pmt_area']\r\ngraphnet: INFO     2022-10-19 10:33:54 - train - truth: ['energy', 'energy_track', 'position_x', 'position_y', 'position_z', 'azimuth', 'zenith', 'pid', 'elasticity', 'sim_type', 'interaction_type', 'interaction_time', 'inelasticity']\r\ngraphnet: WARNING  2022-10-19 10:33:54 - SQLiteDataset._remove_missing_columns - Removing the following (missing) truth variables: interaction_time\r\ngraphnet: WARNING  2022-10-19 10:33:54 - SQLiteDataset._remove_missing_columns - Removing the following (missing) truth variables: interaction_time\r\ngraphnet: WARNING  2022-10-19 10:33:54 - SQLiteDataset._remove_missing_columns - Removing the following (missing) truth variables: interaction_time\r\n\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/pytorch_lightning\/core\/lightning.py:22: LightningDeprecationWarning: pytorch_lightning.core.lightning.LightningModule has been deprecated in v1.7 and will be removed in v1.9. Use the equivalent class from the pytorch_lightning.core.module.LightningModule class instead.\r\n  rank_zero_deprecation(\r\nGPU available: True (cuda), used: True\r\nTPU available: False, using: 0 TPU cores\r\nIPU available: False, using: 0 IPUs\r\nHPU available: False, using: 0 HPUs\r\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\r\n\r\n  | Name      | Type            | Params\r\n----------------------------------------------\r\n0 | _detector | IceCubeDeepCore | 0     \r\n1 | _gnn      | DynEdge         | 1.3 M \r\n2 | _tasks    | ModuleList      | 258   \r\n----------------------------------------------\r\n1.3 M     Trainable params\r\n0         Non-trainable params\r\n1.3 M     Total params\r\n5.376     Total estimated model params size (MB)\r\nEpoch  0:   0%|                                                                                                            | 0\/4800 [00:00<?, ? batch(es)\/s]wandb: ERROR Error while calling W&B API: run config cannot exceed 15 MB (<Response [400]>)\r\nThread SenderThread:\r\nTraceback (most recent call last):\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\", line 25, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 1465, in upsert_run\r\n    response = self.gql(\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/sdk\/lib\/retry.py\", line 113, in __call__\r\n    result = self._call_fn(*args, **kwargs)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py\", line 204, in execute\r\n    return self.client.execute(*args, **kwargs)  # type: ignore\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/wandb_gql\/client.py\", line 52, in execute\r\n    result = self._get_result(document, *args, **kwargs)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/wandb_gql\/client.py\", line 60, in _get_result\r\n    return self.transport.execute(document, *args, **kwargs)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/wandb_gql\/transport\/requests.py\", line 39, in execute\r\n    request.raise_for_status()\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/requests\/models.py\", line 1021, in raise_for_status\r\n    raise HTTPError(http_error_msg, response=self)\r\nrequests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https:\/\/api.wandb.ai\/graphql\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 51, in run\r\n    self._run()\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 95, in _run\r\n    self._debounce()\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 316, in _debounce\r\n    self._sm.debounce()\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 387, in debounce\r\n    self._debounce_config()\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py\", line 393, in _debounce_config\r\n    self._api.upsert_run(\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py\", line 27, in wrapper\r\n    raise CommError(err.response, err)\r\nwandb.errors.CommError: <Response [400]>\r\nwandb: ERROR Internal wandb error: file data was not synced\r\nEpoch  0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4800\/4800 [09:03<00:00,  8.83 batch(es)\/s, loss=-1.22]Traceback (most recent call last):\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1200\/1200 [01:17<00:00, 15.53 batch(es)\/s]\r\n  File \"benchmark.py\", line 204, in <module>\r\n    main()\r\n  File \"benchmark.py\", line 200, in main\r\n    train(config)\r\n  File \"benchmark.py\", line 142, in train\r\n    trainer.fit(model, training_dataloader, validation_dataloader)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 696, in fit\r\n    self._call_and_handle_interrupt(\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 650, in _call_and_handle_interrupt\r\n    return trainer_fn(*args, **kwargs)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 735, in _fit_impl\r\n    results = self._run(model, ckpt_path=self.ckpt_path)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 1166, in _run\r\n    results = self._run_stage()\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 1252, in _run_stage\r\n    return self._run_train()\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/pytorch_lightning\/trainer\/trainer.py\", line 1283, in _run_train\r\n    self.fit_loop.run()\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/pytorch_lightning\/loops\/loop.py\", line 200, in run\r\n    self.advance(*args, **kwargs)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/pytorch_lightning\/loops\/fit_loop.py\", line 271, in advance\r\n    self._outputs = self.epoch_loop.run(self._data_fetcher)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/pytorch_lightning\/loops\/loop.py\", line 201, in run\r\n    self.on_advance_end()\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/pytorch_lightning\/loops\/epoch\/training_epoch_loop.py\", line 241, in on_advance_end\r\n    self._run_validation()\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/pytorch_lightning\/loops\/epoch\/training_epoch_loop.py\", line 299, in _run_validation\r\n    self.val_loop.run()\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/pytorch_lightning\/loops\/loop.py\", line 207, in run\r\n    output = self.on_run_end()\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/pytorch_lightning\/loops\/dataloader\/evaluation_loop.py\", line 198, in on_run_end\r\n    self.trainer._logger_connector.log_eval_end_metrics(all_logged_outputs)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/pytorch_lightning\/trainer\/connectors\/logger_connector\/logger_connector.py\", line 142, in log_eval_end_metrics\r\n    self.log_metrics(metrics)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/pytorch_lightning\/trainer\/connectors\/logger_connector\/logger_connector.py\", line 109, in log_metrics\r\n    logger.log_metrics(metrics=scalar_metrics, step=step)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/pytorch_lightning\/utilities\/rank_zero.py\", line 32, in wrapped_fn\r\n    return fn(*args, **kwargs)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/pytorch_lightning\/loggers\/wandb.py\", line 390, in log_metrics\r\n    self.experiment.log(dict(metrics, **{\"trainer\/global_step\": step}))\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_run.py\", line 289, in wrapper\r\n    return func(self, *args, **kwargs)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_run.py\", line 255, in wrapper\r\n    return func(self, *args, **kwargs)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_run.py\", line 1591, in log\r\n    self._log(data=data, step=step, commit=commit)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_run.py\", line 1375, in _log\r\n    self._partial_history_callback(data, step, commit)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_run.py\", line 1259, in _partial_history_callback\r\n    self._backend.interface.publish_partial_history(\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/sdk\/interface\/interface.py\", line 553, in publish_partial_history\r\n    self._publish_partial_history(partial_history)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/sdk\/interface\/interface_shared.py\", line 67, in _publish_partial_history\r\n    self._publish(rec)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/sdk\/interface\/interface_sock.py\", line 51, in _publish\r\n    self._sock_client.send_record_publish(record)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/sdk\/lib\/sock_client.py\", line 150, in send_record_publish\r\n    self.send_server_request(server_req)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/sdk\/lib\/sock_client.py\", line 84, in send_server_request\r\n    self._send_message(msg)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/sdk\/lib\/sock_client.py\", line 81, in _send_message\r\n    self._sendall_with_error_handle(header + data)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/sdk\/lib\/sock_client.py\", line 61, in _sendall_with_error_handle\r\n    sent = self._sock.send(data[total_sent:])\r\nBrokenPipeError: [Errno 32] Broken pipe\r\nError in atexit._run_exitfuncs:\r\nTraceback (most recent call last):\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/sdk\/lib\/sock_client.py\", line 81, in _send_message\r\n    self._sendall_with_error_handle(header + data)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/sdk\/lib\/sock_client.py\", line 61, in _sendall_with_error_handle\r\n    sent = self._sock.send(data[total_sent:])\r\nBrokenPipeError: [Errno 32] Broken pipe```\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":0.0,
        "Answer_body":"Yeah, I wouldn't call this a bug _per se_. It's just that `WandbLogger` has some limitations that we need to navigate.\r\n\r\nI think your options are to:\r\n\r\n1. not log the training selection; \r\n2. log the test selection instead, as it should be considerably smaller; \r\n3. encode the selection in the data pipeline such that the train\/test label is a column in your database rather than a separate array, and then just log this column name; or \r\n4. implement and log the selection as a reproducible prescription (e.g., `test = event_no % 5 == 0` and `train = not test`) rather than as an explicit array of indices. \r\n\r\nI don't think (1) is a good option, but (2-4) could all work and I think they are all pretty straightforward to do.",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"fail config larg tri run benchmark got error config larg probabl train select arrai big error error call api run config exce data select need upload messag graphnet peter hep northern track python benchmark graphnet info logger write log log graphnet log graphnet warn warn icecub avail function miss current log peterandresen graphnet team us login relogin forc relogin version avail upgrad run pip instal upgrad track run version run data save local run uasci run offlin turn sync sync run woven water view project http graphnet team northerentrack benchmark view run http graphnet team northerentrack benchmark run uasci warn serial object type list byte warn serial object type list byte warn serial object type list byte warn serial object type list byte warn serial object type list byte warn serial object type list byte graphnet info train featur dom dom dom dom time charg rde pmt area graphnet info train truth energi energi track posit posit posit azimuth zenith pid elast sim type interact type interact time inelast graphnet warn sqlitedataset remov miss column remov follow miss truth variabl interact time graphnet warn sqlitedataset remov miss column remov follow miss truth variabl interact time graphnet warn sqlitedataset remov miss column remov follow miss truth variabl interact time group icecub peter anaconda env graphnet lib python site packag pytorch lightn core lightn lightningdeprecationwarn pytorch lightn core lightn lightningmodul deprec remov us equival class pytorch lightn core modul lightningmodul class instead rank zero deprec gpu avail true cuda true tpu avail fals tpu core ipu avail fals ipu hpu avail fals hpu local rank cuda visibl devic type param detector icecubedeepcor gnn dynedg task modulelist trainabl param non trainabl param total param total estim model param size epoch thread senderthread traceback recent file group icecub peter anaconda env graphnet lib python site packag api normal line wrapper return func arg kwarg file group icecub peter anaconda env graphnet lib python site packag sdk intern intern api line upsert run respons self gql file group icecub peter anaconda env graphnet lib python site packag sdk lib retri line result self arg kwarg file group icecub peter anaconda env graphnet lib python site packag sdk intern intern api line execut return self client execut arg kwarg type ignor file group icecub peter anaconda env graphnet lib python site packag vendor gql gql client line execut result self result document arg kwarg file group icecub peter anaconda env graphnet lib python site packag vendor gql gql client line result return self transport execut document arg kwarg file group icecub peter anaconda env graphnet lib python site packag vendor gql gql transport request line execut request rais statu file group icecub peter anaconda env graphnet lib python site packag request model line rais statu rais httperror http error msg respons self request except httperror client error bad request url http api graphql handl except except occur traceback recent file group icecub peter anaconda env graphnet lib python site packag sdk intern intern util line run self run file group icecub peter anaconda env graphnet lib python site packag sdk intern intern util line run self debounc file group icecub peter anaconda env graphnet lib python site packag sdk intern intern line debounc self debounc file group icecub peter anaconda env graphnet lib python site packag sdk intern sender line debounc self debounc config file group icecub peter anaconda env graphnet lib python site packag sdk intern sender line debounc config self api upsert run file group icecub peter anaconda env graphnet lib python site packag api normal line wrapper rais commerror err respons err error commerror error intern error file data sync epoch main file benchmark line main train config file benchmark line train trainer fit model train dataload valid dataload file group icecub peter anaconda env graphnet lib python site packag pytorch lightn trainer trainer line fit self handl interrupt file group icecub peter anaconda env graphnet lib python site packag pytorch lightn trainer trainer line handl interrupt return trainer arg kwarg file group icecub peter anaconda env graphnet lib python site packag pytorch lightn trainer trainer line fit impl result self run model ckpt path self ckpt path file group icecub peter anaconda env graphnet lib python site packag pytorch lightn trainer trainer line run result self run stage file group icecub peter anaconda env graphnet lib python site packag pytorch lightn trainer trainer line run stage return self run train file group icecub peter anaconda env graphnet lib python site packag pytorch lightn trainer trainer line run train self fit loop run file group icecub peter anaconda env graphnet lib python site packag pytorch lightn loop loop line run self advanc arg kwarg file group icecub peter anaconda env graphnet lib python site packag pytorch lightn loop fit loop line advanc self output self epoch loop run self data fetcher file group icecub peter anaconda env graphnet lib python site packag pytorch lightn loop loop line run self advanc end file group icecub peter anaconda env graphnet lib python site packag pytorch lightn loop epoch train epoch loop line advanc end self run valid file group icecub peter anaconda env graphnet lib python site packag pytorch lightn loop epoch train epoch loop line run valid self val loop run file group icecub peter anaconda env graphnet lib python site packag pytorch lightn loop loop line run output self run end file group icecub peter anaconda env graphnet lib python site packag pytorch lightn loop dataload evalu loop line run end self trainer logger connector log eval end metric log output file group icecub peter anaconda env graphnet lib python site packag pytorch lightn trainer connector logger connector logger connector line log eval end metric self log metric metric file group icecub peter anaconda env graphnet lib python site packag pytorch lightn trainer connector logger connector logger connector line log metric logger log metric metric scalar metric step step file group icecub peter anaconda env graphnet lib python site packag pytorch lightn util rank zero line wrap return arg kwarg file group icecub peter anaconda env graphnet lib python site packag pytorch lightn logger line log metric self experi log dict metric trainer global step step file group icecub peter anaconda env graphnet lib python site packag sdk run line wrapper return func self arg kwarg file group icecub peter anaconda env graphnet lib python site packag sdk run line wrapper return func self arg kwarg file group icecub peter anaconda env graphnet lib python site packag sdk run line log self log data data step step commit commit file group icecub peter anaconda env graphnet lib python site packag sdk run line log self partial histori callback data step commit file group icecub peter anaconda env graphnet lib python site packag sdk run line partial histori callback self backend interfac publish partial histori file group icecub peter anaconda env graphnet lib python site packag sdk interfac interfac line publish partial histori self publish partial histori partial histori file group icecub peter anaconda env graphnet lib python site packag sdk interfac interfac share line publish partial histori self publish rec file group icecub peter anaconda env graphnet lib python site packag sdk interfac interfac sock line publish self sock client send record publish record file group icecub peter anaconda env graphnet lib python site packag sdk lib sock client line send record publish self send server request server req file group icecub peter anaconda env graphnet lib python site packag sdk lib sock client line send server request self send messag msg file group icecub peter anaconda env graphnet lib python site packag sdk lib sock client line send messag self sendal error handl header data file group icecub peter anaconda env graphnet lib python site packag sdk lib sock client line sendal error handl sent self sock send data total sent brokenpipeerror errno broken pipe error atexit run exitfunc traceback recent file group icecub peter anaconda env graphnet lib python site packag sdk lib sock client line send messag self sendal error handl header data file group icecub peter anaconda env graphnet lib python site packag sdk lib sock client line sendal error handl sent self sock send data total sent brokenpipeerror errno broken pipe",
        "Issue_preprocessed_content":"fail config larg tri run got config larg probabl big data select upload",
        "Issue_gpt_summary_original":"The user encountered an error while running benchmark.py with WandB due to the config being too large, resulting in a 400 error. The error message suggests that the train_selection array may be too big. The user suggests that the data selections may not need to be uploaded to WandB.",
        "Issue_gpt_summary":"user encount error run benchmark config larg result error error messag suggest train select arrai big user suggest data select need upload",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/graphnet-team\/graphnet\/issues\/270",
        "Issue_title":"Running train_model from examples after install needs directory \"wandb\"",
        "Issue_created_time":1661861159000,
        "Issue_closed_time":1661948109000,
        "Issue_body":"After installing graphnet from scratch and signing up to WandB, running train_model from examples yields the following error:\r\n\r\n```\r\n(graphnet) [peter@hep04 examples]$ python train_model.py \r\ngraphnet: INFO     2022-08-30 12:21:56 - get_logger - Writing log to logs\/graphnet_20220830-122156.log\r\ngraphnet: WARNING  2022-08-30 12:21:56 - <module> - icecube package not available.\r\ngraphnet: WARNING  2022-08-30 12:21:56 - <module> - icecube package not available.\r\ngraphnet: WARNING  2022-08-30 12:21:56 - <module> - icecube package not available.\r\ngraphnet: WARNING  2022-08-30 12:21:56 - <module> - icecube package not available.\r\nwandb: Currently logged in as: peterandresen (graphnet-team). Use `wandb login --relogin` to force relogin\r\nwandb: WARNING Path .\/wandb\/wandb\/ wasn't writable, using system temp directory.\r\nTraceback (most recent call last):\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_init.py\", line 1040, in init\r\n    wi.setup(kwargs)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_init.py\", line 287, in setup\r\n    self._log_setup(settings)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_init.py\", line 431, in _log_setup\r\n    filesystem._safe_makedirs(os.path.dirname(settings.log_user))\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/sdk\/lib\/filesystem.py\", line 10, in _safe_makedirs\r\n    os.makedirs(dir_name)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/os.py\", line 213, in makedirs\r\n    makedirs(head, exist_ok=exist_ok)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/os.py\", line 223, in makedirs\r\n    mkdir(name, mode)\r\nPermissionError: [Errno 13] Permission denied: '\/tmp\/wandb\/run-20220830_122200-1qc85fm4'\r\nwandb: ERROR Abnormal program exit\r\nTraceback (most recent call last):\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_init.py\", line 1040, in init\r\n    wi.setup(kwargs)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_init.py\", line 287, in setup\r\n    self._log_setup(settings)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_init.py\", line 431, in _log_setup\r\n    filesystem._safe_makedirs(os.path.dirname(settings.log_user))\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/sdk\/lib\/filesystem.py\", line 10, in _safe_makedirs\r\n    os.makedirs(dir_name)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/os.py\", line 213, in makedirs\r\n    makedirs(head, exist_ok=exist_ok)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/os.py\", line 223, in makedirs\r\n    mkdir(name, mode)\r\nPermissionError: [Errno 13] Permission denied: '\/tmp\/wandb\/run-20220830_122200-1qc85fm4'\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"train_model.py\", line 37, in <module>\r\n    wandb_logger = WandbLogger(\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/pytorch_lightning\/loggers\/wandb.py\", line 315, in __init__\r\n    _ = self.experiment\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/pytorch_lightning\/loggers\/logger.py\", line 54, in experiment\r\n    return get_experiment() or DummyExperiment()\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/pytorch_lightning\/utilities\/rank_zero.py\", line 32, in wrapped_fn\r\n    return fn(*args, **kwargs)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/pytorch_lightning\/loggers\/logger.py\", line 52, in get_experiment\r\n    return fn(self)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/pytorch_lightning\/loggers\/wandb.py\", line 361, in experiment\r\n    self._experiment = wandb.init(**self._wandb_init)\r\n  File \"\/groups\/icecube\/peter\/anaconda3\/envs\/graphnet\/lib\/python3.8\/site-packages\/wandb\/sdk\/wandb_init.py\", line 1081, in init\r\n    raise Exception(\"problem\") from error_seen\r\nException: problem\r\n```\r\n\r\nWhich can be fixed by creating a folder called \"wandb\" in the place where you are running the file from. Would it make sense to automatically create such a folder, if it is not already present?",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"run train model exampl instal need directori instal graphnet scratch sign run train model exampl yield follow error graphnet peter hep exampl python train model graphnet info logger write log log graphnet log graphnet warn icecub packag avail graphnet warn icecub packag avail graphnet warn icecub packag avail graphnet warn icecub packag avail current log peterandresen graphnet team us login relogin forc relogin warn path wasn writabl temp directori traceback recent file group icecub peter anaconda env graphnet lib python site packag sdk init line init setup kwarg file group icecub peter anaconda env graphnet lib python site packag sdk init line setup self log setup set file group icecub peter anaconda env graphnet lib python site packag sdk init line log setup filesystem safe makedir path dirnam set log user file group icecub peter anaconda env graphnet lib python site packag sdk lib filesystem line safe makedir makedir dir file group icecub peter anaconda env graphnet lib python line makedir makedir head exist exist file group icecub peter anaconda env graphnet lib python line makedir mkdir mode permissionerror errno permiss deni tmp run qcfm error abnorm program exit traceback recent file group icecub peter anaconda env graphnet lib python site packag sdk init line init setup kwarg file group icecub peter anaconda env graphnet lib python site packag sdk init line setup self log setup set file group icecub peter anaconda env graphnet lib python site packag sdk init line log setup filesystem safe makedir path dirnam set log user file group icecub peter anaconda env graphnet lib python site packag sdk lib filesystem line safe makedir makedir dir file group icecub peter anaconda env graphnet lib python line makedir makedir head exist exist file group icecub peter anaconda env graphnet lib python line makedir mkdir mode permissionerror errno permiss deni tmp run qcfm except direct caus follow except traceback recent file train model line logger logger file group icecub peter anaconda env graphnet lib python site packag pytorch lightn logger line init self experi file group icecub peter anaconda env graphnet lib python site packag pytorch lightn logger logger line experi return experi dummyexperi file group icecub peter anaconda env graphnet lib python site packag pytorch lightn util rank zero line wrap return arg kwarg file group icecub peter anaconda env graphnet lib python site packag pytorch lightn logger logger line experi return self file group icecub peter anaconda env graphnet lib python site packag pytorch lightn logger line experi self experi init self init file group icecub peter anaconda env graphnet lib python site packag sdk init line init rais except problem error seen except problem fix creat folder call place run file sens automat creat folder present",
        "Issue_preprocessed_content":"exampl directori graphnet scratch sign exampl yield fix creat folder place file sens creat folder present",
        "Issue_gpt_summary_original":"The user encountered an error while running train_model from examples after installing graphnet from scratch and signing up to WandB. The error occurred due to the absence of a directory called \"wandb\" and can be fixed by creating the folder manually. The user suggests automatically creating the folder if it is not present.",
        "Issue_gpt_summary":"user encount error run train model exampl instal graphnet scratch sign error occur absenc directori call fix creat folder manual user suggest automat creat folder present",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/neuro-inc\/mlops-wandb-bucket-ref\/issues\/16",
        "Issue_title":"WandB output overwrites wabucketref's output in case of artifact upload",
        "Issue_created_time":1625736474000,
        "Issue_closed_time":1625736868000,
        "Issue_body":"Example job: job-7acb5d09-e580-46a2-aa11-03ce72ddc0f0\r\n\r\nAt the end of the job run, we upload the artifact, where `set-output` happens, and terminate the job.\r\nHowever, we have:\r\n```\r\n...\r\nINFO:wabucketref.api:Uploading artifact from '\/tmp\/tmpqkuqrluh' to s3:\/\/pca-pipeline\/dataset\/texture-maps\/8154311a-ab2e-45cd-adeb-f7e5270122c1 ...\r\nINFO:wabucketref.api:Artifact uploaded to s3:\/\/pca-pipeline\/dataset\/texture-maps\/8154311a-ab2e-45cd-adeb-f7e5270122c1\r\nINFO:botocore.credentials:Found credentials in shared credentials file: \/var\/secrets\/aws\/credentials-pca-pipeline\r\nwandb: Generating checksum for up to 100000 objects with prefix \"dataset\/texture-maps\/8154311a-ab2e-45cd-adeb-f7e5270122c1\"... Done. 0.0s\r\n::set-output name=artifact_name::texture-maps\r\n::set-output name=artifact_type::dataset\r\nwandb: Waiting for W&B process to finish, PID 75\r\n...\r\n```\r\n\r\nWhile it should be:\r\n```\r\nINFO:wabucketref.api:Uploading artifact from '\/tmp\/tmpqkuqrluh' to s3:\/\/pca-pipeline\/dataset\/texture-maps\/8154311a-ab2e-45cd-adeb-f7e5270122c1 ...\r\nINFO:wabucketref.api:Artifact uploaded to s3:\/\/pca-pipeline\/dataset\/texture-maps\/8154311a-ab2e-45cd-adeb-f7e5270122c1\r\nINFO:botocore.credentials:Found credentials in shared credentials file: \/var\/secrets\/aws\/credentials-pca-pipeline\r\nwandb: Generating checksum for up to 100000 objects with prefix \"dataset\/texture-maps\/8154311a-ab2e-45cd-adeb-f7e5270122c1\"... Done. 0.0s\r\n::set-output name=artifact_name::texture-maps\r\n::set-output name=artifact_type::dataset\r\n::set-output name=artifact_alias::8154311a-ab2e-45cd-adeb-f7e5270122c1\r\nwandb: Waiting for W&B process to finish, PID 75\r\nwandb: Program ended successfully.\r\nwandb:                                                                                \r\n```\r\n\r\nOne line was overwritten by the `wandb: Waiting for W&B process to finish, PID 75`, which, apparently is running in a separate process (`wandb.Settings(start_method=\"fork\")`). ",
        "Issue_answer_count":0,
        "Issue_self_closed":1.0,
        "Answer_body":"",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"output overwrit wabucketref output case artifact upload exampl job job acbd ceddcf end job run upload artifact set output happen termin job info wabucketref api upload artifact tmp tmpqkuqrluh pca pipelin dataset textur map ab adeb fec info wabucketref api artifact upload pca pipelin dataset textur map ab adeb fec info botocor credenti credenti share credenti file var secret aw credenti pca pipelin gener checksum object prefix dataset textur map ab adeb fec set output artifact textur map set output artifact type dataset wait process finish pid info wabucketref api upload artifact tmp tmpqkuqrluh pca pipelin dataset textur map ab adeb fec info wabucketref api artifact upload pca pipelin dataset textur map ab adeb fec info botocor credenti credenti share credenti file var secret aw credenti pca pipelin gener checksum object prefix dataset textur map ab adeb fec set output artifact textur map set output artifact type dataset set output artifact alia ab adeb fec wait process finish pid program end successfulli line overwritten wait process finish pid appar run separ process set start method fork",
        "Issue_preprocessed_content":"output overwrit wabucketref output case artifact upload exampl job end job run upload artifact termin job line separ",
        "Issue_gpt_summary_original":"The issue is that the output of WandB overwrites the output of wabucketref during artifact upload, causing one line to be missing in the output.",
        "Issue_gpt_summary":"issu output overwrit output wabucketref artifact upload caus line miss output",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/github.com\/rdnfn\/beobench\/issues\/67",
        "Issue_title":"In random agent script wandb full episode data logging skips a few steps",
        "Issue_created_time":1649933570000,
        "Issue_closed_time":1650034426000,
        "Issue_body":"### Problem\r\n\r\n In random agent script wandb full episode data logging skips a few steps. This is because wandb counts the epsiode reward logging steps made prior to the full data logging.\r\n\r\n### Potential Solution\r\n\r\nAdd another metric to log that shows timestep and day (proportional).\r\n",
        "Issue_answer_count":1,
        "Issue_self_closed":1.0,
        "Answer_body":"This has been implemented and will be shipped with v0.4.4 \ud83d\ude80",
        "Tool":"Weights & Biases",
        "Platform":"Github",
        "Issue_original_content":"random agent script episod data log skip step problem random agent script episod data log skip step count epsiod reward log step prior data log potenti solut add metric log show timestep dai proport",
        "Issue_preprocessed_content":"random agent script episod data skip step problem random agent script episod data skip step count epsiod reward step prior data potenti solut metric log show timestep dai",
        "Issue_gpt_summary_original":"The user is facing an issue with the full episode data logging in a random agent script using wandb, where some steps are being skipped. The problem is due to wandb counting the episode reward logging steps made before the full data logging. A potential solution suggested is to add another metric to log the timestep and day proportionally.",
        "Issue_gpt_summary":"user face issu episod data log random agent script step skip problem count episod reward log step data log potenti solut suggest add metric log timestep dai proportion",
        "Issue_score_count":0
    },
    {
        "Issue_link":"https:\/\/gitlab.com\/fluidattacks\/universe\/-\/issues\/8382",
        "Issue_title":"[Sorts] Add sagemaker dependencies",
        "Issue_created_time":1671481698985,
        "Issue_closed_time":1675452134148,
        "Issue_body":"<!-- Issues are public, they should not contain confidential information -->\n\n### What is the current _bug_ behavior? how can we reproduce it?\nThe requirements.txt file does not have the entire dependency tree defined\n\n### Possible fixes\nModify the requirements.txt file so that it has the complete tree of dependencies and their respective versions\n### Steps\n\n- [x] Make sure that the\n      [code contributions checklist](https:\/\/docs.fluidattacks.com\/development\/contributing#checklist)\n      has been followed.",
        "Issue_answer_count":13,
        "Issue_self_closed":null,
        "Answer_body":"Added and pinned the additional dependencies. @mriveraatfluid mentioned in commit d54bbb59bc42db6a66848d1cefe4b8ab29f68690 mentioned in merge request !36356 mentioned in commit 24b795e9436ea7c45379486b5541f6a84f967c15 mentioned in commit b3eda78ae28bb6810c052d94edd675a82cff6129 marked the checklist item **Make sure that the** as completed The complete tree of dependencies has been added and pinned properly in the requirements file. @mriveraatfluid mentioned in commit 9ecc0c84c69f7b0422f0a30239d522c031b0d7ab mentioned in merge request !34151 mentioned in commit cf649ea2f6fab7a2e8308aa813e1841bf4d23c95 unassigned @auribeatfluid assigned to @rrodriguezatfluid assigned to @auribeatfluid",
        "Tool":"Amazon SageMaker",
        "Platform":"Gitlab",
        "Issue_original_content":"sort add depend current bug behavior reproduc requir txt file entir depend tree defin possibl fix modifi requir txt file complet tree depend respect version step sure code contribut checklist http doc fluidattack com develop contribut checklist follow",
        "Issue_preprocessed_content":"depend behavior reproduc file entir depend defin fix modifi file complet depend respect version step sure",
        "Issue_gpt_summary_original":"The user has encountered an issue with the requirements.txt file not having the complete dependency tree defined while working with Sagemaker. The possible fix is to modify the requirements.txt file to include the complete tree of dependencies and their respective versions.",
        "Issue_gpt_summary":"user encount issu requir txt file have complet depend tree defin work possibl fix modifi requir txt file includ complet tree depend respect version",
        "Issue_score_count":0
    }
]